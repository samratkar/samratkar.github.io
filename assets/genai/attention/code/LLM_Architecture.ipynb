{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samratkar/samratkar.github.io/blob/main/LLM_Architecture_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IMPiLlbR9PN"
      },
      "source": [
        "#### GPT ARCHITECTURE PART 1: LAYER NORMALIZATION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsqymXyrR9PN",
        "outputId": "5e8dea5a-05f8-4079-a3ad-02fe2a88e310"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.1115,  0.1204, -0.3696, -0.2404, -1.1969],\n",
            "        [ 0.2093, -0.9724, -0.7550,  0.3239, -0.1085]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "torch.manual_seed(123)\n",
        "batch_example = torch.randn(2, 5) #A\n",
        "print(batch_example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAWK9WHxR9PN"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Before we apply layer normalization to these outputs, let's examine the mean and\n",
        "variance:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFMuVouMR9PN",
        "outputId": "515d29fa-18ba-4190-9d3b-d4c7f0a3ed7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean:\n",
            " tensor([[-0.3596],\n",
            "        [-0.2606]])\n",
            "Variance:\n",
            " tensor([[0.2518],\n",
            "        [0.3342]])\n"
          ]
        }
      ],
      "source": [
        "mean = batch_example.mean(dim=-1, keepdim=True)\n",
        "var = batch_example.var(dim=-1, keepdim=True)\n",
        "print(\"Mean:\\n\", mean)\n",
        "print(\"Variance:\\n\", var)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFkLE5x1R9PN"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "The first row in the mean tensor above contains the mean value for the first input row, and\n",
        "the second output row contains the mean for the second input row.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kR8gBObR9PN"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Next, let us apply layer normalization to the layer outputs we obtained earlier. The\n",
        "operation consists of subtracting the mean and dividing by the square root of the variance\n",
        "(also known as standard deviation):\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X78pRhZSR9PN",
        "outputId": "b10ad193-ed10-4d49-8334-c5d910828589"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalized layer outputs:\n",
            " tensor([[ 0.4945,  0.9564, -0.0200,  0.2375, -1.6685],\n",
            "        [ 0.8128, -1.2314, -0.8554,  1.0111,  0.2630]])\n",
            "Mean:\n",
            " tensor([[-2.6822e-08],\n",
            "        [ 2.3842e-08]])\n",
            "Variance:\n",
            " tensor([[1.0000],\n",
            "        [1.0000]])\n"
          ]
        }
      ],
      "source": [
        "out_norm = (batch_example - mean) / torch.sqrt(var)\n",
        "mean = out_norm.mean(dim=-1, keepdim=True)\n",
        "var = out_norm.var(dim=-1, keepdim=True)\n",
        "print(\"Normalized layer outputs:\\n\", out_norm)\n",
        "print(\"Mean:\\n\", mean)\n",
        "print(\"Variance:\\n\", var)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhCZU6ymR9PN"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "To improve readability, we can also turn off the scientific notation when printing tensor\n",
        "values by setting sci_mode to False:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRfAcb-HR9PN"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Let's now encapsulate this process in a PyTorch module that we can use in the GPT\n",
        "model later:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eWiYvlUBR9PN"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JpKRsBAR9PN"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "The variable eps is a\n",
        "small constant (epsilon) added to the variance to prevent division by zero during\n",
        "normalization.\n",
        "\n",
        "The scale and shift are two trainable parameters (of the same dimension\n",
        "as the input) that the LLM automatically adjusts during training if it is determined that\n",
        "doing so would improve the model's performance on its training task.\n",
        "\n",
        "This allows the model\n",
        "to learn appropriate scaling and shifting that best suit the data it is processing.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBZtBOzIR9PO"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Let's now try the LayerNorm module in practice and apply it to the batch input:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn0iTSOuR9PO",
        "outputId": "27f42b18-cafb-435a-8775-76281bb507ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.2103, -0.3908,  0.2350,  0.6653,  0.3528],\n",
            "        [ 0.9728, -0.0386, -0.8861, -0.4709, -0.4269]])\n"
          ]
        }
      ],
      "source": [
        "ln = LayerNorm(emb_dim=5)\n",
        "batch_example = torch.randn(2, 5) #A\n",
        "print(batch_example)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYdM0Ulo1ols",
        "outputId": "23397f2b-1348-4897-a222-39f8c7318315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean:\n",
            " tensor([[ 4.7684e-08],\n",
            "        [-2.3842e-08]], grad_fn=<MeanBackward1>)\n",
            "Variance:\n",
            " tensor([[0.9999],\n",
            "        [1.0000]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ],
      "source": [
        "out_ln = ln(batch_example)\n",
        "mean = out_ln.mean(dim=-1, keepdim=True)\n",
        "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
        "print(\"Mean:\\n\", mean)\n",
        "print(\"Variance:\\n\", var)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHxWmKY-R9PO"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "As we can see based on the results, the layer normalization code works as expected and\n",
        "normalizes the values of each of the two inputs such that they have a mean of 0 and a\n",
        "variance of 1:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkRfl7wjR9PO"
      },
      "source": [
        "## GPT ARCHITECTURE PART 3: FEEDFORWARD NEURAL NETWORK WITH GELU ACTIVATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4r4ZWS7R9PO"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Let's implement the GELU activation function approximation used by GPT-2:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "z-nqLyxtR9PO"
      },
      "outputs": [],
      "source": [
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knsp8E6LR9PO"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "To get an idea of what this GELU function looks like and how it compares to the ReLU\n",
        "function, let's plot these functions side by side:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "mdEZgsjqR9PO",
        "outputId": "848910ad-2148-4a76-a5c4-e711891cc9ae"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "gelu, relu = GELU(), nn.ReLU()\n",
        "\n",
        "# Some sample data\n",
        "x = torch.linspace(-3, 3, 100)\n",
        "y_gelu, y_relu = gelu(x), relu(x)\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
        "    plt.subplot(1, 2, i)\n",
        "    plt.plot(x, y)\n",
        "    plt.title(f\"{label} activation function\")\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(f\"{label}(x)\")\n",
        "    plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg7xNVWmR9PO"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "As we can see in the resulting plot, ReLU is a piecewise linear function that\n",
        "outputs the input directly if it is positive; otherwise, it outputs zero.\n",
        "\n",
        "GELU is a smooth, nonlinear function that approximates ReLU but with a non-zero gradient for negative values.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xwzb4JGvR9PO"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "The smoothness of GELU, as shown in the above figure, can lead to better optimization properties\n",
        "during training, as it allows for more nuanced adjustments to the model's parameters.\n",
        "\n",
        "In contrast, ReLU has a sharp corner at zero, which can sometimes make optimization harder,\n",
        "especially in networks that are very deep or have complex architectures.\n",
        "\n",
        "Moreover, unlike RELU, which outputs zero for any negative input, GELU allows for a small, non-zero output\n",
        "for negative values.\n",
        "\n",
        "This characteristic means that during the training process, neurons that\n",
        "receive negative input can still contribute to the learning process, albeit to a lesser extent\n",
        "than positive inputs.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEXFDyzJR9PO"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Next, let's use the GELU function to implement the small neural network module,\n",
        "FeedForward, that we will be using in the LLM's transformer block later:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "B0lS7qjvR9PO"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyjFh-bjR9PO"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Let's use the GELU function to implement the small neural network module,\n",
        "FeedForward, that we will be using in the LLM's transformer block later:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mjM7i4ppXICj"
      },
      "outputs": [],
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,    # Vocabulary size\n",
        "    \"context_length\": 256, # Context length\n",
        "    \"emb_dim\": 768,         # Embedding dimension\n",
        "    \"n_heads\": 12,          # Number of attention heads\n",
        "    \"n_layers\": 12,         # Number of layers\n",
        "    \"drop_rate\": 0.1,       # Dropout rate\n",
        "    \"qkv_bias\": False       # Query-Key-Value bias\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAaofCetR9PO",
        "outputId": "fae8f273-ce27-4411-e5b9-b7016d9a56dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3, 768])\n"
          ]
        }
      ],
      "source": [
        "ffn = FeedForward(GPT_CONFIG_124M)\n",
        "x = torch.rand(2, 3, 768) #A\n",
        "out = ffn(x)\n",
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arkZ-zx9R9PP"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "The FeedForward module we implemented in this section plays a crucial role in enhancing\n",
        "the model's ability to learn from and generalize the data.\n",
        "\n",
        "\n",
        "Although the input and output dimensions of this module are the same, it internally expands the embedding dimension\n",
        "into a higher-dimensional space through the first linear layer.\n",
        "\n",
        "This expansion is followed by a non-linear GELU activation, and then a contraction back to\n",
        "the original dimension with the second linear transformation.\n",
        "\n",
        "Such a design allows for the\n",
        "exploration of a richer representation space.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQHBqJH9R9PP"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "Moreover, the uniformity in input and output dimensions simplifies the architecture by\n",
        "enabling the stacking of multiple layers, as we will do later, without the need to adjust\n",
        "dimensions between them, thus making the model more scalable.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AxcTqIdR9PP"
      },
      "source": [
        "## GPT ARCHITECTURE PART 4: SHORTCUT CONNECTIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMJaWM4qR9PP"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Let us see how we can add shortcut connections to the forward method:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QVA0YM28R9PP"
      },
      "outputs": [],
      "source": [
        "class ExampleDeepNeuralNetwork(nn.Module):\n",
        "    def __init__(self, layer_sizes, use_shortcut):\n",
        "        super().__init__()\n",
        "        self.use_shortcut = use_shortcut\n",
        "        self.layers = nn.ModuleList([\n",
        "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            # Compute the output of the current layer\n",
        "            layer_output = layer(x)\n",
        "            # Check if shortcut can be applied\n",
        "            if self.use_shortcut and x.shape == layer_output.shape:\n",
        "                x = x + layer_output\n",
        "            else:\n",
        "                x = layer_output\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BKHvao7R9PP"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "The code implements a deep neural network with 5 layers, each consisting of a Linear\n",
        "layer and a GELU activation function.\n",
        "\n",
        "In the forward pass, we iteratively pass the input\n",
        "through the layers and optionally add the shortcut connections  if\n",
        "the self.use_shortcut attribute is set to True.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evaf1W-uR9PP"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Let's use this code to first initialize a neural network without shortcut connections. Here,\n",
        "each layer will be initialized such that it accepts an example with 3 input values and returns\n",
        "3 output values. The last layer returns a single output value:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "o4qu90MvR9PP"
      },
      "outputs": [],
      "source": [
        "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
        "sample_input = torch.tensor([[1., 0., -1.]])\n",
        "torch.manual_seed(123) # specify random seed for the initial weights for reproducibility\n",
        "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
        "layer_sizes, use_shortcut=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOKR1KCsR9PP"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Next, we implement a function that computes the gradients in the the model's backward\n",
        "pass:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bmd6k243R9PP"
      },
      "outputs": [],
      "source": [
        "def print_gradients(model, x):\n",
        "    # Forward pass\n",
        "    output = model(x)\n",
        "    target = torch.tensor([[0.]])\n",
        "\n",
        "    # Calculate loss based on how close the target\n",
        "    # and output are\n",
        "    loss = nn.MSELoss()\n",
        "    loss = loss(output, target)\n",
        "\n",
        "    # Backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            # Print the mean absolute gradient of the weights\n",
        "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLkhZM5PR9PP"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "In the preceding code, we specify a loss function that computes how close the model output\n",
        "and a user-specified target (here, for simplicity, the value 0) are.\n",
        "\n",
        "Then, when calling loss.backward(), PyTorch computes the loss gradient for each layer in the model.\n",
        "\n",
        "We can iterate through the weight parameters via model.named_parameters().\n",
        "\n",
        "Suppose we have a 33 weight parameter matrix for a given layer.\n",
        "\n",
        "In that case, this layer will have 33 gradient values, and we print the mean absolute gradient of these 33 gradient values to\n",
        "obtain a single gradient value per layer to compare the gradients between layers more\n",
        "easily.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCtU4votR9PP"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "In short, the .backward() method is a convenient method in PyTorch that computes loss\n",
        "gradients, which are required during model training, without implementing the math for the\n",
        "gradient calculation ourselves, thereby making working with deep neural networks much\n",
        "more accessible.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnzLDSAZR9PP"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Let's now use the print_gradients function and apply it to the model without skip\n",
        "connections:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YbQjqYYR9PP",
        "outputId": "77af7039-d70a-42d6-8db4-822f7a2a3f62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layers.0.0.weight has gradient mean of 0.00020173590746708214\n",
            "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
            "layers.2.0.weight has gradient mean of 0.0007152042235247791\n",
            "layers.3.0.weight has gradient mean of 0.0013988739810883999\n",
            "layers.4.0.weight has gradient mean of 0.00504964729771018\n"
          ]
        }
      ],
      "source": [
        "print_gradients(model_without_shortcut, sample_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf9JWk8FR9PP"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "As we can see based on the output of the print_gradients function, the gradients become\n",
        "smaller as we progress from the last layer (layers.4) to the first layer (layers.0), which\n",
        "is a phenomenon called the vanishing gradient problem.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7h2O-NNVR9PP"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "Let's now instantiate a model with skip connections and see how it compares:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kp3btXiR9PP",
        "outputId": "576708de-2139-44b3-d49a-f8c9181188d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layers.0.0.weight has gradient mean of 0.22169791162014008\n",
            "layers.1.0.weight has gradient mean of 0.20694102346897125\n",
            "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
            "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
            "layers.4.0.weight has gradient mean of 1.3258541822433472\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
        "layer_sizes, use_shortcut=True\n",
        ")\n",
        "print_gradients(model_with_shortcut, sample_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdpvgR8uR9PQ"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "As we can see, based on the output, the last layer (layers.4) still has a larger gradient\n",
        "than the other layers.\n",
        "\n",
        "However, the gradient value stabilizes as we progress towards the\n",
        "first layer (layers.0) and doesn't shrink to a vanishingly small value.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CptAJoGR9PQ"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "In conclusion, shortcut connections are important for overcoming the limitations posed\n",
        "by the vanishing gradient problem in deep neural networks.\n",
        "\n",
        "Shortcut connections are a core building block of very large models such as LLMs, and they will help facilitate more effective\n",
        "training by ensuring consistent gradient flow across layers when we train the GPT model\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4tw7eA-R9PQ"
      },
      "source": [
        "## GPT ARCHITECTURE PART 5: CODING ATTENTION AND LINEAR LAYERS IN A TRANSFORMER BLOCK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPw7zbaGR9PQ"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "Let us code a transformer block as follows:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7Szb1UeR9PQ"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "Step 1: Shortcut connection for attention block\n",
        "\n",
        "Step 2:  Shortcut connection for feed forward block\n",
        "\n",
        "Step 3: Add the original input back\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wjj_dvylaK9s"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ymcZ6TCwR9PQ"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgcbUzQ6R9PQ"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "The given code defines a TransformerBlock class in PyTorch that includes a multi-head\n",
        "attention mechanism (MultiHeadAttention) and a feed forward network (FeedForward),\n",
        "both configured based on a provided configuration dictionary (cfg), such as\n",
        "GPT_CONFIG_124M\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gkjwi9nBR9PQ"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "Layer normalization (LayerNorm) is applied before each of these two components, and\n",
        "dropout is applied after them to regularize the model and prevent overfitting.\n",
        "\n",
        "This is also known as Pre-LayerNorm.\n",
        "\n",
        "Older architectures, such as the original transformer model,\n",
        "applied layer normalization after the self-attention and feed-forward networks instead,\n",
        "known as Post-LayerNorm, which often leads to worse training dynamics.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hR1NRidR9PQ"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "The class also implements the forward pass, where each component is followed by a\n",
        "shortcut connection that adds the input of the block to its output. This critical feature helps\n",
        "gradients flow through the network during training and improves the learning of deep\n",
        "models\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRT140JpR9PQ"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "Using the GPT_CONFIG_124M dictionary we defined earlier, let's instantiate a transformer\n",
        "block and feed it some sample data\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLxMLNVDR9PQ"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "Create sample input of shape [batch_size, num_tokens, emb_dim]\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFYiqOZVR9PQ",
        "outputId": "fa415c54-c0ef-4380-9894-f5a60c593208"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "x = torch.rand(2, 4, 768) #A\n",
        "block = TransformerBlock(GPT_CONFIG_124M)\n",
        "output = block(x)\n",
        "print(\"Input shape:\", x.shape)\n",
        "print(\"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1nBPNqRR9PQ"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "As we can see from the code output, the transformer block maintains the input dimensions\n",
        "in its output, indicating that the transformer architecture processes sequences of data\n",
        "without altering their shape throughout the network.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEryZ8uER9PQ"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    \n",
        "The preservation of shape throughout the transformer block architecture is not incidental\n",
        "but a crucial aspect of its design.\n",
        "\n",
        "This design enables its effective application across a wide\n",
        "range of sequence-to-sequence tasks, where each output vector directly corresponds to an\n",
        "input vector, maintaining a one-to-one relationship.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFA6ZhKVR9PQ"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "However, the output is a context vector\n",
        "that encapsulates information from the entire input sequence.\n",
        "\n",
        "This means that while the physical dimensions of the sequence (length and feature size)\n",
        "remain unchanged as it passes through the transformer block, the content of each output\n",
        "vector is re-encoded to integrate contextual information from across the entire input\n",
        "sequence.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxW5aCVwR9PQ"
      },
      "source": [
        "## GPT ARCHITECTURE PART 6: ENTIRE GPT MODEL ARCHITECTURE IMPLEMENTATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3bYcPlbR9PR"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "The device setting will allow us to train the model on a CPU or GPU, depending on which device the input\n",
        "data sits\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V-CxtLTbGoK",
        "outputId": "5b54cdce-9db6-45f3-e1d1-3c4cf662213d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tiktoken in c:\\github\\samratkar.github.io\\.venv\\lib\\site-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\github\\samratkar.github.io\\.venv\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in c:\\github\\samratkar.github.io\\.venv\\lib\\site-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\github\\samratkar.github.io\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\github\\samratkar.github.io\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\github\\samratkar.github.io\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\github\\samratkar.github.io\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken\n",
        "import importlib\n",
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "CupjUL2XR9PR"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7kT2p09R9PR"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    \n",
        "The __init__ constructor of this GPTModel class initializes the token and positional\n",
        "embedding layers using the configurations passed in via a Python dictionary, cfg.\n",
        "\n",
        "These\n",
        "embedding layers are responsible for converting input token indices into dense vectors and\n",
        "adding positional information.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL1QW4XpR9PR"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    \n",
        "Next, the __init__ method creates a sequential stack of TransformerBlock modules\n",
        "equal to the number of layers specified in cfg.\n",
        "\n",
        "Following the transformer blocks, a\n",
        "LayerNorm layer is applied, standardizing the outputs from the transformer blocks to\n",
        "stabilize the learning process.\n",
        "\n",
        "Finally, a linear output head without bias is defined, which\n",
        "projects the transformer's output into the vocabulary space of the tokenizer to generate\n",
        "logits for each token in the vocabulary.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x19EZs_sR9PR"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    \n",
        "The forward method takes a batch of input token indices, computes their embeddings,\n",
        "applies the positional embeddings, passes the sequence through the transformer blocks,\n",
        "normalizes the final output, and then computes the logits, representing the next token's\n",
        "unnormalized probabilities. We will convert these logits into tokens and text outputs in the\n",
        "next section.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kel5eZTNR9PR"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "Let's now initialize the 124 million parameter GPT model using the GPT_CONFIG_124M\n",
        "dictionary we pass into the cfg parameter and feed it with the batch text input we created\n",
        "at the beginning of this chapter:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wVfDil08aW8X"
      },
      "outputs": [],
      "source": [
        "batch = []\n",
        "txt1 = \"Every effort moves you\"\n",
        "txt2 = \"Every day holds a\"\n",
        "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
        "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
        "batch = torch.stack(batch, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2Waag3HbRYL",
        "outputId": "4b92c597-2695-4742-d00c-ba4dbd8b6fd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[6109, 3626, 6100,  345],\n",
            "        [6109, 1110, 6622,  257]])\n"
          ]
        }
      ],
      "source": [
        "print(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Okd93gA9R9PR",
        "outputId": "850f6d25-3544-44c6-ccc1-972ebc79048b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input batch:\n",
            " tensor([[6109, 3626, 6100,  345],\n",
            "        [6109, 1110, 6622,  257]])\n",
            "\n",
            "Output shape: torch.Size([2, 4, 50257])\n",
            "tensor([[[-0.4708,  0.5737, -0.5967,  ...,  0.2019, -0.5665,  0.1800],\n",
            "         [-0.3895, -0.1978, -0.8885,  ...,  0.2242, -1.2341,  0.1752],\n",
            "         [ 0.6973, -0.3432, -0.6080,  ...,  0.3747, -0.6967,  0.1088],\n",
            "         [-0.2962, -0.6957, -1.1371,  ...,  0.3579,  0.3058, -0.2915]],\n",
            "\n",
            "        [[-0.1514,  0.3329, -0.9740,  ..., -0.1368, -0.6974, -0.1851],\n",
            "         [-0.4894, -0.3492, -0.9759,  ...,  0.2951, -0.3396,  0.2109],\n",
            "         [ 0.5082, -0.1425,  0.2549,  ...,  0.1618,  0.1304, -0.3092],\n",
            "         [-0.4146, -0.0514, -0.5187,  ..., -0.1869, -0.1303, -0.4969]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "out = model(batch)\n",
        "print(\"Input batch:\\n\", batch)\n",
        "print(\"\\nOutput shape:\", out.shape)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TsTZijZR9PR"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "As we can see, the output tensor has the shape [2, 4, 50257], since we passed in 2 input\n",
        "texts with 4 tokens each. The last dimension, 50,257, corresponds to the vocabulary size of\n",
        "the tokenizer. In the next section, we will see how to convert each of these 50,257-\n",
        "dimensional output vectors back into tokens.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMtmLn3xR9PR"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "Using the numel() method, short for \"number of elements,\" we can collect the total\n",
        "number of parameters in the model's parameter tensors:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2TEjuHdR9PR",
        "outputId": "a87861ee-624e-40ff-bcfc-a3602abaf904"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of parameters: 162,419,712\n"
          ]
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total number of parameters: {total_params:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrLNtDOrR9PR"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\">\n",
        "Earlier, we spoke of initializing a 124\n",
        "million parameter GPT model, so why is the actual number of parameters 163 million, as\n",
        "shown in the preceding code output?\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzHm0pMIR9PR"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    \n",
        "The reason is a concept called weight tying that is used in the original GPT-2\n",
        "architecture, which means that the original GPT-2 architecture is reusing the weights from\n",
        "the token embedding layer in its output layer.\n",
        "\n",
        "To understand what this means, let's take a\n",
        "look at the shapes of the token embedding layer and linear output layer that we initialized\n",
        "on the model via the GPTModel earlier:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nMOcuuhR9PR",
        "outputId": "f35973fb-e29e-4340-f1f6-42542beef744"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token embedding layer shape: torch.Size([50257, 768])\n",
            "Output layer shape: torch.Size([50257, 768])\n"
          ]
        }
      ],
      "source": [
        "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
        "print(\"Output layer shape:\", model.out_head.weight.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkO-ZOK4R9PR"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "As we can see based on the print outputs, the weight tensors for both these layers have the\n",
        "same shape:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05piP5T4R9PR"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "The token embedding and output layers are very large due to the number of rows for the\n",
        "50,257 in the tokenizer's vocabulary. Let's remove the output layer parameter count from\n",
        "the total GPT-2 model count according to the weight tying:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "w8rqxaHqR9PR",
        "outputId": "c4557737-743e-4a55-9351-dd03d56776b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters considering weight tying: 123,822,336\n"
          ]
        }
      ],
      "source": [
        "total_params_gpt2 = total_params - sum(p.numel() for p in model.out_head.parameters())\n",
        "print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9tX7WbcR9PS"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "As we can see, the model is now only 124 million parameters large, matching the original\n",
        "size of the GPT-2 model.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c84mEdnwR9PS"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    \n",
        "Weight tying reduces the overall memory footprint and computational complexity of the\n",
        "model. However, in my experience, using separate token embedding and output layers\n",
        "results in better training and model performance; hence, we are using separate layers in\n",
        "our GPTModel implementation. The same is true for modern LLMs.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzfbgi2kR9PS"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "Lastly, let us compute the memory requirements of the 163 million parameters in our\n",
        "GPTModel object:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXcEJEtKR9PS",
        "outputId": "b70bb644-79b9-4638-d0f4-32e9b00a8ce1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total size of the model: 619.58 MB\n"
          ]
        }
      ],
      "source": [
        "total_size_bytes = total_params * 4 #A\n",
        "total_size_mb = total_size_bytes / (1024 * 1024) #B\n",
        "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3dWmGv3R9PS"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    \n",
        "In conclusion, by calculating the memory requirements for the 163 million parameters in\n",
        "our GPTModel object and assuming each parameter is a 32-bit float taking up 4 bytes, we\n",
        "find that the total size of the model amounts to 621.83 MB, illustrating the relatively large\n",
        "storage capacity required to accommodate even relatively small LLMs.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqbt-ORxR9PS"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    \n",
        "In this section, we implemented the GPTModel architecture and saw that it outputs\n",
        "numeric tensors of shape [batch_size, num_tokens, vocab_size]. In the next section,\n",
        "we will write the code to convert these output tensors into text.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8A7fD3_R9PS"
      },
      "source": [
        "## GPT ARCHITECTURE PART 7: GENERATING TEXT FROM OUTPUT TOKENS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX9auO2QR9PS"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "Let us implement the token-generation process as follows:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Td6ggURPR9PS"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "Step 1: idx is a (batch, n_tokens) array of indices in the current context\n",
        "\n",
        "Step 2: Crop current context if it exceeds the supported context size E.g., if LLM supports only 5 tokens, and the\n",
        "context size is 10 then only the last 5 tokens are used as context\n",
        "\n",
        "Step 3: Focus only on the last time step, so that (batch, n_token, vocab_size) becomes (batch, vocab_size)\n",
        "\n",
        "Step 4: probas has shape (batch, vocab_size)\n",
        "\n",
        "Step 5: idx_next has shape (batch, 1)\n",
        "\n",
        "Step 6: Append sampled index to the running sequence, where idx has shape (batch, n_tokens+1)\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "y5jdYaEOR9PS"
      },
      "outputs": [],
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (batch, n_tokens) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest probability value\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqi8A_QGR9PS"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    \n",
        "In the preceeding code, the generate_text_simple function, we use a softmax function to\n",
        "convert the logits into a probability distribution from which we identify the position with the\n",
        "highest value via torch.argmax.\n",
        "\n",
        "The softmax function is monotonic, meaning it preserves\n",
        "the order of its inputs when transformed into outputs.\n",
        "\n",
        "So, in practice, the softmax step is\n",
        "redundant since the position with the highest score in the softmax output tensor is the\n",
        "same position in the logit tensor.\n",
        "\n",
        "In other words, we could apply the torch.argmax function\n",
        "to the logits tensor directly and get identical results.\n",
        "\n",
        "However, we coded the conversion to\n",
        "illustrate the full process of transforming logits to probabilities, which can add additional\n",
        "intuition, such as that the model generates the most likely next token, which is known as\n",
        "greedy decoding.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqYZW_0kR9PS"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    \n",
        "In the next chapter, when we will implement the GPT training code, we will also\n",
        "introduce additional sampling techniques where we modify the softmax outputs such that\n",
        "the model doesn't always select the most likely token, which introduces variability and\n",
        "creativity in the generated text.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "momOTgckR9PS"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "Let's now try out the generate_text_simple function with the \"Hello, I am\" context\n",
        "as model input\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CQxnULHR9PS"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "First, we encode the input context into token IDs:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYfA1_azR9PS",
        "outputId": "b047a397-e442-49d6-82b0-c957dc110658"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "encoded: [15496, 11, 314, 716]\n",
            "encoded_tensor.shape: torch.Size([1, 4])\n"
          ]
        }
      ],
      "source": [
        "start_context = \"Hello, I am\"\n",
        "encoded = tokenizer.encode(start_context)\n",
        "print(\"encoded:\", encoded)\n",
        "encoded_tensor = torch.tensor(encoded).unsqueeze(0) #A\n",
        "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvHCD4-eR9PS"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "Next, we put the model into .eval() mode, which disables random components like\n",
        "dropout, which are only used during training, and use the generate_text_simple function\n",
        "on the encoded input tensor:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uSB3KKTR9PS"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "We disable dropout since we are not training the model\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMHMdUYFR9PS",
        "outputId": "1338d1d7-dfd3-4aa4-9d76-f7b78008029a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output: tensor([[15496,    11,   314,   716, 13240, 11381,  4307,  7640, 16620, 34991]])\n",
            "Output length: 10\n"
          ]
        }
      ],
      "source": [
        "model.eval() #A\n",
        "out = generate_text_simple(\n",
        "model=model,\n",
        "idx=encoded_tensor,\n",
        "max_new_tokens=6,\n",
        "context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "print(\"Output:\", out)\n",
        "print(\"Output length:\", len(out[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXfbyIUAR9PS"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "Using the .decode method of the tokenizer, we can convert the IDs back into text:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzYrXDWUR9PT",
        "outputId": "8063948b-87cc-4bad-b9aa-fe237eb42653"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello, I am Laur inhab DistrinetalkQueue\n"
          ]
        }
      ],
      "source": [
        "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
        "print(decoded_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ReYdxtVR9PT"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "As we can see, based on the preceding output, the model generated gibberish, which is not\n",
        "at all coherent text.\n",
        "\n",
        "What happened?\n",
        "\n",
        "The reason why the model is unable to produce coherent text is that we haven't trained it yet.\n",
        "\n",
        "So far, we just\n",
        "implemented the GPT architecture and initialized a GPT model instance with initial random\n",
        "weights.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYa4TvD2q26G"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
