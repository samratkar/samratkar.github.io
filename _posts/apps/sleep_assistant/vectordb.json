{
  "name": "Papers_vectordb",
  "createdAt": "2025-12-17T13:56:45.442Z",
  "dimension": 384,
  "ids": [
    "doc_0_1765979788191",
    "doc_1_1765979789158",
    "doc_2_1765979790076",
    "doc_3_1765979790984",
    "doc_4_1765979791896",
    "doc_5_1765979792803",
    "doc_6_1765979793701",
    "doc_7_1765979794599",
    "doc_8_1765979795486",
    "doc_9_1765979796376",
    "doc_10_1765979797262",
    "doc_11_1765979798154",
    "doc_12_1765979799039",
    "doc_13_1765979799946",
    "doc_14_1765979800895",
    "doc_15_1765979801808",
    "doc_16_1765979802722",
    "doc_17_1765979803632",
    "doc_18_1765979804551",
    "doc_19_1765979805442"
  ],
  "documents": [
    "1 of 28  TITLE PAGE  Title  Automatic sleep stage classification with deep residual networks in a mixed-cohort setting  Authors and affiliations  Alexander Neergaard Olesen 1,2,3 , Poul Jennum 3* , Emmanuel Mignot 2* , Helge Bjarup Dissing S√∏rensen 1* ,  1 Department of Health Technology, Technical University of Denmark, Kgs. Lyngby, Denmark  2 Stanford Center for Sleep Sciences and Medicine, Stanford University, Palo Alto, CA, USA  3 Danish Center for Sleep Medicine, Department of Clinical Neurophysiology, Rigshospitalet, Glostrup, Denmark  *These authors have contributed equally  Corresponding author  Alexander Neergaard Olesen , aneol@dtu.dk  Department of Health Technology, Technical University of Denmark  √òrsteds Plads, building 349, room 010  2800 Kgs. Lyngby, Denmark  Institution where work was performed  Stanford Center for Sleep Sciences and Medicine, Stanford University  Department of Health Technology, Technical University of Denmark\n\n2 of 28  ABSTRACT  Study Objectives:   Sleep stage scoring is performed manually by sleep experts and is prone to subjective interpretation  of scoring rules with low intra- and interscorer reliability. Many automatic systems rely on few small-scale databases for  developing models, and generalizability to new datasets is thus unknown. We investigated a novel deep neural network  to assess the generalizability of several large-scale cohorts.  Methods:   A deep neural network model was developed using 15.684 polysomnography studies from five different  cohorts. We applied four different scenarios: 1) impact of varying time-scales in the model; 2) performance of a single  cohort on other cohorts of smaller, greater or equal size relative to the performance of other cohorts on a single cohort; 3)  varying the fraction of mixed-cohort training data compared to using single-origin data; and 4) comparing models trained  on combinations of data from 2, 3, and 4 cohorts.  Results:   Overall classification accuracy improved with increasing fractions of training data (0.25%: 0.782 ¬± 0.097, 95%  CI [0.777 ‚Äì 0.787]; 100%: 0.869 ¬± 0.064, 95% CI [0.864 ‚Äì 0.872]), and with increasing number of data sources (2: 0.788  ¬± 0.102, 95% CI [0.787 ‚Äì 0.790]; 3: 0.808 ¬± 0.092, 95% CI [0.807 ‚Äì 0.810]; 4: 0.821 ¬± 0.085, 95% CI [0.819 ‚Äì 0.823]).  Different cohorts show varying levels of generalization to other cohorts.  Conclusions:   Automatic sleep stage scoring systems based on deep learning algorithms should consider as much data as  possible from as many sources available to ensure proper generalization. Public datasets for benchmarking should be  made available for future research.  Keywords  Automatic sleep stage classification, computational sleep science, machine learning, deep learning\n\n3 of 28  STATEMENT OF SIGNIFICANCE  Manual annotation of polysomnography studies is subject to human bias with multiple studies showing variations in how  sleep experts score sleep. Most research in automatic sleep stage classification models use small-scale data from a single  origin, and it is unknown how these models generalize to new data. We developed an algorithm for automatic scoring of  sleep stages using raw polysomnography data and obtain state-of-the-art classification performance on a large number of  test subjects. Our algorithm was tested under different conditions to compare generalizability. We found that using data  from many different sources improves classification performance, and that models trained on single-origin data generalize  inconsistently to new data. Future researchers should take multiple datasets into account when developing sleep scoring  models.\n\n4 of 28  INTRODUCTION  Sleep staging is important to the analysis of human sleep with about 845,000 sleep studies performed in 2014 in the US  alone 1 .   Briefly,   a   standard   clinical   sleep   study   consists   of   a   full-night   polysomnography   (PSG)   comprising  electroencephalography (EEG), electrooculography (EOG), electromyography (EMG), electrocardiography (ECG),  thoraco-abdominal inductance plethysmography, oronasal thermal flow, nasal pressure, and blood saturation recordings.  These studies are then evaluated by experts for the presence of events of clinical relevance, as determined by standards  created by the American Academy of Sleep Medicine (AASM), such as the number of blood oxygen desaturations, micro-  arousals, leg movements, periods of cessated breathing, etc. Furthermore, the overall sleep architecture is captured in a  hypnogram conducted by labeling every 30 s of PSG data into one of five stages of sleep: wakefulness (W), rapid eye  movement (REM) sleep, and non-REM stage 1, 2, and 3 (N1, N2, N3). The latter three stages are distinguished by distinct  EEG amplitude and frequency distributions, the presence of specific EEG micro-events and arousability differences  reflecting sleep depth. Sleep stage labeling is summarized in key metrics, such as the percentage of total sleep time (TST)  spent in any of the five stages (%W, or wake after sleep onset, WASO; %REM; %N1; %N2; %N3), and visually in the  form of a hypnogram, which shows temporal progression of sleep stages across the night. Current clinical practice (gold  standard) of sleep study analysis is manual scoring and annotation of sleep stages and sleep events based on guidelines  from the AASM 2 .   These guidelines, based on observations made in healthy young males almost 70 years ago are  problematic for several reasons: a) technicians will never score the same data the exact same way as another technician,  or even the same way twice 3‚Äì7 ; b) normal sleep from healthy young males may not reflect sleep patterns of patients  referred to sleep clinics; and c) the 30 s epoch rule is arbitrary and was based on physical limitations of recording  equipment when PSGs were recorded on paper.  Automatic sleep stage classification has not yet seen wide-spread adoption in clinical practice despite ongoing research  demonstrating feasibility and industrial interests 8 . A major issue has been a lack of available data for designing and  training models. The publicly available PhysioNet Sleep-EDF and the expanded version 9,10   has been used extensively for  training both shallow and deep learning-based machine learning models 11‚Äì13 , but given its small sample size and  homogeneity (most papers use the same healthy 20 subjects), it is questionable how well models derived from this data  generalize to unseen data, even if high classification performance is often reported 8 . Other databases which have been  extensively used include the St. Vincent‚Äôs University Hospital and University College Dublin Sleep Apnea Database ( ùëõ   =  25 ) 9,14 , and the Montreal Archive of Sleep Studies (MASS,   ùëõ   = 200 ) 13,15‚Äì19 . The argument for using deep learning-based  models to classify high-dimensional electrophysiological data, e.g. PSGs, into discrete outcomes such as sleep stages is  compelling, because of their ability to capture variability in the underlying, highly complex, data representations, that\n\n5 of 28  might be missed by machine learning methods relying on manual feature engineering. In the image, speech, and natural  language processing domains, the success of deep learning models using untransformed data have been unsurpassed in  the last decade, thanks largely due to the availability of ever-increasing amounts of compute resources and more  significantly very large, robust and diverse datasets 20 .  Recently deep learning models for automatic sleep stage classification have been developed and validated using two or  more databases or cohorts 21‚Äì23 , or using a single large volume cohort 22,24,25 . The assumption has been that by incorporating  multiple sources of variance in the dataset used for training (e.g. from multiple technicians, sites, recording setups,  equipment, etc.), final models will be better at generalizing to new, unseen data. However, no study to date has  investigated multiple, large-scale cohorts for automatic sleep stage classification, or how different cohorts generalize to  one another.  In this work, we describe a deep learning-based sleep stage classification algorithm trained and validated on raw PSG  data from multiple, large-scale cohorts for a total of 15,684 studies, that outputs a probability distribution over all sleep  stages at a given time resolution. Considering the amount of data available, our aim was to evaluate: 1) how well does  performance of individual cohorts generalize to others; 2) how much data is needed for accurate sleep staging; 3) how  many cohorts are necessary for that same goal; and 4) which is better, more data, or more diverse data. To our knowledge,  this is one of the largest, if not the largest, study on automatic sleep stage classification in terms of PSG volume and  diversity.\n\n6 of 28  METHODS  Cohort descriptions  To investigate and conclude on generalizability of any machine learning or sleep stage classification model, multiple  heterogenous datasets must be used for training, validation and testing purposes. In this work, we collected datasets from  five different sources, each dataset containing a diverse collection of subjects presenting with multiple disease phenotypes.  Details of the separate cohorts are shown in Table 1 along with reported   p -values highlighting cohort differences. Each  cohort was split into a training, validation and testing   subset   in proportions of 87.5%, 2.5% and 10%, respectively, using  random sampling without replacement among unique subjects, so that no subject is shared between subsets. With these  percentages, we maximize the number of PSGs available for training, while still reserving enough PSGs for validation  and testing. Collecting all the separate subsets across cohorts forms a training, validation, and testing   partition , containing  the respective subsets from all five cohorts.  Institute of Systems and Robotics, University of Coimbra Sleep Cohort (ISRUC)  This cohort contains 126 recordings from 118 unique subjects recorded at the Sleep Medicine Centre of the Hospital of  Coimbra University, Portugal, in the period 2009‚Äì2013 26 . The cohort comprises three subgroups: subgroup I contains 100  PSGs of subjects with diagnosed sleep disorders, generally sleep apnea; subgroup II contains 16 recordings of eight  subjects most of which are also diagnosed with sleep apnea; and subgroup III contains recordings from 10 subjects with  no diagnosed sleep disorders. All PSGs were recorded with the same recording hardware and software and each was  scored by two technicians for sleep stages and sleep events according to the AASM guidelines. ISRUC-Sleep is a freely  accessible resource and all data and PSG files can be located at https://sleeptight.isr.uc.pt/ISRUC_Sleep/.  The MrOS Sleep Study (MrOS)  The MrOS sleep study is part of the larger Osteoporotic Fractures in Men Study, which aims to understand the  relationships between sleep disorders, fractures, and vascular diseases in community-dwelling men 27‚Äì29 . It consists of  2,907 in-home PSG recordings with an additional 1,026 follow-up PSG studies from subjects recruited from six different  clinical centers in the USA. Each recording was annotated by an expert technician according to Rechtschaffen and Kales  (R&K) criteria for sleep staging 30 . For compatibility with AASM guidelines, we combined stages labeled S3 and S4 into  N3. All data were accessed from the National Sleep Research Resource (NSRR) repository 31,32 .  The Sleep Heart Health Study (SHHS)\n\n7 of 28  The SHHS is a large, multi-center study on cardiovascular outcomes related to sleep disorders with a specific focus on  sleep-disordered breathing 33,34 . The cohort consists of 6,441 subjects above 40 years old recruited between 1995 and 1998  undergoing in-home PSG (SHHS Visit 1) with subsequent follow-up PSG between 2001 and 2003 in 3,295 subjects  (SHHS Visit 2). PSG recordings were annotated for sleep stages by trained and certified technicians according to R&K  rules. From the original cohort we extracted 5,793 PSGs and annotations from Visit 1, and 2,651 from Visit 2, and  aggregated S3 and S4 stages into N3 similar to MrOS. All data were accessed from NSRR repository.  Wisconsin Sleep Cohort (WSC)  WSC is a population-based study of sleep-disordered breathing in government workers in Wisconsin, USA that was  initiated in 1988 35,36 . In this work, we used 2412 PSGs from 1091 unique   subjects in the WSC sample scored by expert  technicians according to R&K rules with subsequent merging of S3 and S4 into N3.  Stanford Sleep Cohort (SSC)  PSGs from this cohort originate from patients referred for sleep disorders evaluation and recorded at the Stanford Sleep  Clinic since 1999. The specific sample used in this study represents a small subset ( n   = 772) of the whole cohort, which  was selected and described in detail in previous studies 37,38   scored according to R&K or AASM guidelines according to  prevailing standard at the time of evaluation.  Signal pre-processing pipeline  Electrophysiological signals corresponding to the minimum acceptable montage for sleep staging available across all  cohorts were extracted for each PSG. These included a central EEG (either C3 or C4 referenced to the contra-lateral  mastoid), left and right EOG referenced to the contra-lateral mastoid, and a single submentalis EMG. The choice between  C3 and C4 was determined based on the lowest total signal energy across the entire duration of the PSG to avoid excessive  signal popping. Other methods to determine appropriate channels include algorithms based on shortest Mahalanobis  distance to an already determined reference distribution 21 , but was not investigated in this study. All signals were  resampled to   f s   = 128 Hz   using a polyphase filtering procedure irrespective of original sampling frequency; and  subsequently filtered using a zero-phase approach with 4 th   order Butterworth IIR filters (0.5 to 35 Hz band pass for EEG  and EOG; 10 Hz high pass for EMG) in accordance with AASM filter specifications 2 . Each signal was normalized to zero  mean and unit variance to accommodate differences in recording equipment and baselines; and to compress the dynamic  range into something easily trainable for the neural network architecture. We denote by   ùê∂   the number of input signals  supplied to the neural network, where in this case   ùê∂   = 4 .\n\n8 of 28  Machine learning problem  We designate by   ùí≥   ‚àà ‚Ñù ‡Æº √ó ‡Øç   the set of 30 s input data segments with   C   input channels and segment length   T , and the  corresponding classifications by   ùí¥   =   { ùë¶   ‚àà ‚Ñù ‡¨æ  ‡ØÑ   | ‚àë   ùë¶ ‡Øú   = 1 ‡Øú   } , where   K   = 5 corresponds to the five sleep stages. Thus,   ùë¶   is a  probability simplex, which maps to the ordered set   ùíÆ   =   { W, N1, N2, N3, REM }   by the argmax function such that  argmax   ùë¶   ‚à∂   ùí¥   ‚Üí   ùíÆ . Furthermore, as we are potentially interested in classifying multiple sleep stages at once, we extend  the problem of classifying a single sleep stage given   ùë•   ‚àà   ùí≥   to a sequence-to-sequence problem, in which we desire to  learn a differentiable function representation   Œ¶ , that maps a sequence of 30 s epochs   ùê±   ‚àà ‚Ñù ‡Æº √ó ‡∞à‡Øç   to their corresponding  label probabilities   ùê≤   ‚àà ‚Ñù ‡ØÑ √ó ‡∞à , where   ùõº   is a parameter that controls the sequence length. If e.g.   ùõº   = 8 , the sequence   x  contains 4 min of successive PSG data described by 8 epochs of length 30 seconds. Furthermore, we denote by   ‚ü¶ ùëé ,   ùëè ‚üß   the  set of integers from   ùëé   to   ùëè , i.e.   ‚ü¶ ùëé ,   ùëè ‚üß   ‚â°   { ùëõ   ‚àà ‚Ñï | ùëé   ‚â§   ùëõ   ‚â§   ùëè } , and by   ‚ü¶ ùëÅ ‚üß   the shorthand form of   ‚ü¶ 1,   ùëÅ ‚üß .  Network architecture  As the representation of   Œ¶ , we adapted and extended a previously published neural network architecture for automatic  sleep stage classification, which was based on a variant of the ResNet-50 architecture commonly used for two-dimensional  image classification tasks, but adapted and re-trained from scratch for the specific use-case of one-dimensional, time-  dependent signals in the PSG 24 . This network has the advantage that it does not require any manual feature engineering  and extraction compared to previous state of the art sleep stage classification models 21 . An overview of the proposed  network architecture is provided graphically in Figure 1 and Table 2. Briefly, the architecture consists of four modules:  1)   an initial mixing module   ùúë mix   ‚à∂ ‚Ñù ‡¨µ √ó ‡Æº √ó ‡Øç   ‚Üí ‚Ñù ‡Æº √ó ‡¨µ √ó ‡Øç  2)   a feature extraction module   ùúë feat   ‚à∂ ‚Ñù ‡Æº √ó ‡¨µ √ó ‡Øç   ‚Üí ‚Ñù ‡Øô ‡∞¨ ‡¨∂ ‡≥É‡∞∂‡∞≠ √ó ‡¨µ √ó ‡Øç   ‡¨∂   ‡≥É ‚ÅÑ  3)   a temporal processing module   ùúë temp   ‚à∂ ‚Ñù ‡Øô ‡∞¨ ‡¨∂ ‡≥É‡∞∂‡∞≠ √ó ‡¨µ √ó ‡Øç   ‡¨∂   ‡≥É ‚ÅÑ   ‚Üí ‚Ñù ‡¨∂‡Ø° ‡≥ì √ó ‡Øç   ‡¨∂   ‡≥É ‚ÅÑ   , and  4)   a classification module   ùúë clf   ‚à∂ ‚Ñù ‡¨∂‡Ø° ‡≥ì √ó ‡Øç   ‡¨∂   ‡≥É ‚ÅÑ   ‚Üí ‚Ñù ‡ØÑ √ó ‡Øç   ‡¨∂   ‡≥É ‚ÅÑ   .  Thus, we obtain a differentiable representation of the function   Œ¶ ‚à∂ ‚Ñù ‡Æº √ó ‡Øç   ‚Üí ‚Ñù ‡ØÑ √ó ‡Øç   ‡¨∂   ‡≥É ‚ÅÑ   as  Œ¶ ( ùê± )   =   ùúë clf   ‡µ¨ ùúë temp   ·âÄ ùúë feat ‡µ´ ùúë mix ( ùê± ) ‡µØ ·âÅ ‡µ∞   .  The output of this function is the matrix   ùê≤   ‚àà ‚Ñù ‡ØÑ √ó ‡Øç   ‡¨∂   ‡≥É ‚ÅÑ   containing sleep stage probabilities in the sequence of PSG data  evaluated every second.  Mixing module\n\n9 of 28  The raw input data is input to this module, which encourages non-linear channel mixing similar to what has been proposed  in recent literature 16,39‚Äì41 . The module is realized using a single 2D convolutional operation outputting   ùê∂   feature maps  computed using single-strided   ùê∂   √ó 1   kernels followed by rectified linear unit (ReLU) activations.  Feature extraction (residual network) module  This is comprised of a succession of   R   residual blocks (see Figure 1), which are responsible for the bulk feature extraction  from the channel-mixed data. Each residual block is realized using bottlenecks of first a   1 √ó 1   convolution to reduce the  number of feature maps, then a   1 √ó 3   convolution and lastly a   1 √ó 1   convolution to finally increase the number of feature  maps. Each convolution operation was followed by a batch normalization 42   and ReLU activation except after the last  convolutional layer, where shortcut projections are added before the activation 43 . This type of block structure enables the  design and training of very deep networks without the risk of vanishing gradients due to the projection shortcuts 44 .  Temporal processing module  This module is realized by a bidirectional gated recurrent unit (GRU) 45   in order to accommodate temporal dependencies  in the PSG. The GRU runs through the temporal dimension of the output from   ùúë ‡≠§‡≠£‡≠ü‡≠≤   of   ùëá   2 ‡Øã ‚ÅÑ   time steps each containing  ùëì ‡¨¥ 2 ‡Øã‡¨æ‡¨µ   features and outputs   ùëõ ‡Øõ   features in each direction for each time step. By running both forward and backward, we  can accommodate that technicians base their scoring on looking backwards as well as ahead in time in each time segment  (typically 30 s).  Classification module  The final module in the architecture performs actual classification based on the forward and backward features for each  time step outputted from   ùúë ‡≠≤‡≠£‡≠´‡≠Æ   . It is realized by a single convolutional operation with a subsequent softmax activation to  compute a probability distribution over the   K   sleep stage classes, such that the probability of sleep stage   ùëñ   at time step   ùëõ  is given by   ùë¶ ‡Øú  ( ‡Ø° )   =   ‡±õ‡±Æ‡±¶   ( ‡≥å   ‡≥î )  ‚àë   ‡±õ‡±Æ‡±¶   ( ‡≥å   ‡≥ñ ) ‡≥ñ   , where   ùëé ‡Øú   ‚àà   ùíÇ   is the activation of the last layer in the network and   ùëò   =   ‚ü¶ ùêæ ‚üß .  Loss function  The network was trained end-to-end with respect to a loss function, that takes the output probabilities from the network  ùê≤   = Œ¶ ( ùê± )   and calculates the loss as  ‚Ñí ( ùê≤ )   =   ‚àí   ‡∑ç   ‡∑ç   ùë° ‡Øû ( ‡Ø° )   log ·âÄ ùë¶ ·á±  ‡Øû  ( ‡Ø° ) ·âÅ  ‡ØÑ  ‡Øû ‡≠Ä ‡¨µ  ‡¨∑‡¨¥   ‡∞õ ‚ÅÑ  ‡Ø° ‡≠Ä ‡¨µ  ,  (1)\n\n10 of 28  ùë¶ ‚Ä≤ ‡Øû  ( ‡Ø° )   =   1  ùúè   ‡∑ç   ùë¶ ‡Øû  ( ‡Øú )  ‡∞õ‡Ø°  ‡Øú ‡≠Ä ‡∞õ ( ‡Øù ‡¨ø   ‡¨µ ) ‡¨æ ‡¨µ  ,  (2)  which is the cross-entropy between successive time-averaged classifications (parameterized by the number of successive  one-second predictions   ùúè ), and the ground truth labels   ùë°   broadcasted to   30   ùúè ‚ÅÑ   labels per 30 s segment. This way, we can  acquire predictions every second, that can be combined in time at intervals given by   ùúè .  Experimental setups  We set up three different experiments in this study.  A)   We wished to investigate the effect of increasing the complexity of the recurrent module by varying the number of  units   ùëõ ‡Øõ   in the module   ùúë temp   in the space   ùëõ ‡Øõ   = 2 ‡Øû   ,   ùëò   ‚àà   ‚ü¶ 6,11 ‚üß . We hypothesize that there exists a sweet-spot in the  number of hidden units that balances computational complexity with classification performance, i.e. classifying a  sequence of sleep stage labels given a corresponding sequence of outputs from   ùúë feat . The results of this experiment  were furthermore used to determine parameters for models in subsequent experiments.  B)   Since we have several cohorts at our disposition of both clinical and research origin, we can investigate the  compatibility and inherent generalizability of the different cohorts in two ways: 1) we set aside a single cohort for  testing, while we train the models on the remaining four (leave-one-cohort-out, LOCO training); and 2) we train on  a single cohort, while we set aside the remaining four for testing (leave-one-cohort-in, LOCI training).  C)   Generalizability can also be investigated in another way, which can answer the question of how many data sources  is necessary. We trained models with all possible 2-, 3-, and 4-combinations of cohorts, i.e. one run trained on ISRUC  and MrOS training data, another run with ISRUC and SHHS train data, a third with ISRUC and SSC, etc., with all  runs subjected to subsequent evaluation on the test partition.  D)   Previous studies have already investigated the performance of automatic sleep staging algorithms using shallow  machine learning models. At the time of writing however, none have investigated the effect of available training data  for deep learning models at this magnitude (up to tens of thousands). We therefore trained models on 0.25%, 0.5%,  1%, 5%, 10%, 25%, 50%, 75% and 100% of the data available for training. Specifically, some of these fractions of  the total number of PSGs correspond roughly to the number of PSGs in the training partitions in each cohort, allowing  for direct comparisons between training a model with mixed- and single-cohort training data.  Common for all experiments were the default parameter values   ùê∂   = 4 ,   ùëì ‡Ø¶   = 128 Hz ,   ùëá   =   ùúèùëì ‡Ø¶ ,   ùêæ   = 5 ,   ùëÖ   = 7 , and   ùëì ‡¨¥   = 4  for the number of input channels, sampling frequency, the sequence length, the number of sleep stages, the number of  consecutive residual blocks, and the base filter kernel size, respectively. All models were trained for 50 epochs (passes\n\n11 of 28  through the training partition) and the model with the highest Cohen‚Äôs kappa value on the validation partition was  subsequently selected for testing. All models were trained end-to-end with backpropagation using the Adam optimizer 46  with a learning rate of   10 ‡¨ø   ‡¨∏   ,   ùõΩ ‡¨µ   = 0.9 , and   ùõΩ ‡¨∂   = 0.999   to minimize the loss function specified by Eq. (1) and Eq. (2). All  network weights and bias terms were initialized using the uniform Glorot initialization scheme 47 .  Performance metrics and model evaluation  For each experiment we evaluated model performance using the overall accuracy (Acc) and Cohen‚Äôs kappa (Œ∫) in order  to into account the possibility of chance agreement between the model gold standard. Given a confusion matrix   ùêÇ   with  element   ùëê ‡Øú‡Øù   being the number of epochs belonging to sleep stage   ùëñ   but classified to be in sleep stage   ùëó , we define the  overall accuracy for a given model as  Acc   =   ‚àë   ùëê ‡Øú‡Øù ‡Øú‡≠Ä‡Øù  ‚àë   ùëê ‡Øú‡Øù ‡Øú , ‡Øù  i.e. the sum of the trace of   ùêÇ   divided by the total count. The Cohen‚Äôs kappa metric is defined as  Œ∫ =   ùëù ‡Ø¢   ‚àí   ùëù ‡Øò  1 ‚àí   ùëù ‡Øò  where   ùëù ‡Ø¢   =   Acc is the observed agreement (i.e. accuracy) and   ùëù ‡Øò   is the expected chance agreement, which can be  reformulated in terms of the outer product between the row and column sums (class-specific recall and precision) of   ùêÇ .  Data and source code availability  All model training and testing code was implemented in PyTorch v. 1.2 48 . Model performances were assessed using  custom   Python   scripts   using   scikit-learn 49 .   Source   code   and   pre-trained   models   will   be   made   available   at  https://github.com/neergaard/deep-sleep-pytorch.git   and   https://github.com/Stanford-STAGES/deep-sleep-pytorch.git  upon publication of this paper. Data from ISRUC are publicly available at   https://sleeptight.isr.uc.pt/ISRUC_Sleep/ , while  access to data from MrOS and SHHS can be requested from the NSRR. Anonymized PSG data from SSC including  selected demographic data are available at   https://stanfordmedicine.app.box.com/s/r9e92ygq0erf7hn5re6j51aaggf50jly .\n\n12 of 28  RESULTS  In this section we report on the results of the three experiments described in the   Experimental setups   section.  Temporal context impact on model performance  In Figure 2 we show how the model performance depends on the temporal context and complexity of the temporal  processing module, when evaluating the model on the validation partition. Results are further detailed in Table S1.  Specifically, we observe a drastic change in Cohen‚Äôs kappa just by introducing a simple recurrent unit into the network  as shown in Figure 2a, where Cohen‚Äôs kappa increases from   0.645 ¬± 0.126   ( 95%   CI : [0.633 ‚àí 0.657] )   at   ùëõ ‡Øõ   = 0   to  0.720 ¬± 0.120   ( 95%   CI : [0.709 ‚àí 0.731] )   at   ùëõ ‡Øõ   = 64 . We did not observe any major changes when increasing the  number of hidden units beyond 64, although we did see a maximum Cohen‚Äôs kappa of   0.734 ¬± 0.111   ( 95%   CI : [0.723 ‚àí  0.744] )   at   ùëõ ‡Øõ   = 1024 , which is shown in the inset in Figure 2a. We observed a general increase in Cohen‚Äôs kappa when  classifying longer sequences than 2 min ( 0.726 ¬± 0.114, 95%   CI : [0.715 ‚àí 0.737] ), but did not see any major  differences when classifying over more than 3 min sequences ( 0.733 ¬± 0.123, 95%   CI : [0.721 ‚àí 0.744] ). Subsequent  models were fixed with   ùëõ ‡Øõ   = 1024   corresponding to a sequence length of 5 min.  Model classifications converge to 30 s predictions given sufficient training data  Furthermore, we analyzed the classification performance of the model given a specific sequence length by looking at the  average prediction accuracy across all 5 min sequences in all subject PSGs in the test partition, similar to what Brink-  Kjaer et al. has shown previously 50 . In Figure 2c, we show how the average classification accuracy in a 5 min sequence  both depends on the amount of data and the frequency of evaluating the model output, i.e. every 1 s or across 30 s. The  average classification accuracy was found to be slightly lower in the beginning of each 5 min sequence (see Figure 2c),  both when training a model with less (500 training subjects) and more (75% of total training subjects). Interestingly, when  training with less data, we also observed a lower accuracy in the beginning and end of each 30 s segment relative to the  accuracy in the middle section, which was not the case when training with more data.  Choice of cohort impacts classification performance on test set  In Figure 3 we show how training on different cohorts yield differing results in subsequent testing performance, here  expressed in heatmaps as both overall accuracy (Figure 3a), and Cohen‚Äôs kappa (Figure 3b) averaged across all   ùëÅ   =  1,584   subject PSGs in the test partition. The first two columns show the performance on the cohort on the x-axis, when  training on the specific cohort on the y-axis. Since the training subset in ISRUC is small compared to the other cohorts,  we trained the model in the left-most column with weight decay of   10 ‡¨ø   ‡¨∏   to compensate for the risk of overfitting, however,\n\n13 of 28  by comparing the left and middle columns, we did not observe any specific gain in classification performance by doing  so. The right-most column shows the test performance for each cohort, when excluding that cohort from training. We  observe a significant spread in classification accuracy across the different cohorts with prediction on ISRUC being  poorest, while prediction on MrOS data being best. Further details can be found in Table S2.  More data is good, diverse data is better  We observed a general increase in classification performance both in terms of overall accuracy and Cohen‚Äôs kappa, when  including more data in the model training phase in both the mixed- and single-cohort setting (Figure 4a, Table S3).  Classification performance was consistently lower in the single-cohort setting compared to the corresponding mixed-  cohort setting. Interestingly, we found that training a model with just 0.25% of mixed-cohort training data still achieved  an acceptable accuracy comparable to training a model with only SHHS data, while using all available training data  increased that performance by almost 10 percentage points. Furthermore, we observed that the model trained with 100%  of the training partition reached a state-of-the-art level of performance with an overall accuracy of   0.869 ¬± 0.064  ( 95%   CI :   [ 0.865 ‚àí 0.872 ] ) and Cohen‚Äôs kappa of   0.799 ¬± 0.098   ( 95%   CI :   [ 0.794 ‚àí 0.804 ] ) (Table S3). The model  furthermore performs well with respect to classifying individual sleep stages as shown in the confusion matrix in Figure  4b. However, the model still has difficulties classifying and distinguishing between certain sleep stages, especially  between N2, N1, and N3; and W, N2, and N1.  Increasing the number of data sources improves classification performance  On average, we saw an increase in overall accuracy, when increasing the number of cohorts from 2 to 4 using 500 PSGs  in each configuration, see Figure 5 and Table S4. Specifically, we found that the average overall accuracy increased from  0.788 ¬± 0.102   ( 95%   CI :   [ 0.787 ‚àí 0.790 ] ) in the 2-cohort configuration to   0.808 ¬± 0.092   ( 95%   CI :   [ 0.807 ‚àí 0.810 ] )  and   0.821 ¬± 0.085   ( 95%   CI :   [ 0.819 ‚àí 0.823 ] ) in the 4-cohort configuration.\n\n14 of 28  DISCUSSION  In this work, we present an end-to-end deep learning-based model for fully automatic micro- and macro-sleep stage  classification. Using all of the available data sources for training our model, we reached an overall accuracy on test  partition of   0.869 ¬± 0.064   ( 95%   CI :   [ 0.865 ‚àí 0.872 ] ), and a Cohen‚Äôs kappa of   0.799 ¬± 0.098   ( 95%   CI :   [ 0.794 ‚àí  0.804 ] ), which is in the very high end of the substantial agreement category for observer agreement 51 . We found that  individual cohorts exhibit major differences in overall accuracy and Cohen‚Äôs kappa when subjected to both training and  testing conditions and specifically, we found that average performance on the test partition in the LOCI configurations  varied significantly from   0.676 ¬± 0.124   ( 95%   CI :   [ 0.670 ‚àí 0.682 ] ) when training on ISRUC, to   0.837 ¬± 0.084  ( 95%   CI :   [ 0.833 ‚àí 0.841 ] ) when training on SHHS. Each individual cohort also showed large deviations in predictive  performance when tested on the other cohorts. For example, when conditioned on SHHS data, the lowest average accuracy  was 0.721 on SSC test data compared to the highest at 0.872 on SHHS test data, while conditioning on SSC training data,  the lowest average accuracy was 0.704 on ISRUC test data compared to 0.824 on WSC test data. Classification  performance was generally higher on the test set when using the LOCO configuration, except for SHHS (higher in LOCI)  and SSC (no difference). We also found that having data from multiple sources always resulted in better-performing  models compared to training on single cohorts. Increasing the number of data sources increased classification  performance, although this was non-significant. In the design of the model, we observed that model performance was  enhanced by the addition of the recurrent module (bGRU), a phenomenon likely reflecting the fact that sleep stage scoring  at a specific time in one subject can be influenced by signal content (frequency, amplitude, presence of micro-events) at  later time steps. However, the complexity of the module given by the number of hidden units did not affect performance.  In all our experiments, we also evaluated the performance of the model every 1 s compared to the performance evaluated  every 30 s and found them to be similar, which indicates the model is stable in classification in periods corresponding to  an epoch of data.  Only a handful of studies have previously reported results when using multiple cohorts 21‚Äì23 . Some authors have reported  a drop from 81.9% to 77.7% when training on the Massachusetts General Hospital cohort (MGH) and testing on MGH  and SHHS, respectively 22 , while others have shown significant drops from 89.8% to 81.4% and 72.1% on two separate  hold-out sets from Singapore and USA 23 . We also observed similar trends in our LOCI and LOCO experiments, where  excluding the training subset of a cohort from the training partition resulted in a significant drop in performance on the  respective test subset from that cohort. A benefit of our LOCI and LOCO experiments is the possibility for direct  benchmarking against previous publications using specific cohorts in their experiments. For example, we obtain an  accuracy of 0.805 in the LOCO-SHHS training-testing case compared to 0.777 previously reported by Biswal et al. 22 ,\n\n15 of 28  both of which reflect classification performance when SHHS had not been used for training; and an accuracy of 0.865 in  the LOCI-WSC case compared to 0.841 reported by Olesen et al.   24 , where both have been using a subset of WSC for  training the model. Interestingly, we obtained the same level of performance on the SHHS data in our LOCI experiment  as reported by Sors et al. (87% accuracy, 81% Cohen‚Äôs kappa) even though they only used single-EEG for their  experiments 52 . Other works that have investigated single- vs. multi-channel models for automatic sleep stage classification  have found that models generally benefit from having more channels available for training 16,18,22 . It may be that some  cohorts share different characteristics that makes them more suitable for single- or multi-channel models, but this is  speculative and would need to be verified in subsequent studies.  Our study is not without limitations. We only optimized our network architecture with respect to the temporal processing  module and therefore cannot assess what impact different design choices for the other modules would have had on final  performance. For example, the EMG signal has different statistical properties and spectral content, and separate, parallel  architectures for EMG and EEG/EOG feature extraction may be warranted, as proposed by others 16,21 . Other studies have  however shown equal performance in large cohorts using a similar channel mixing approach as proposed here 24 . Another  limitation is found in our training runs, as we did not consider balancing our data with respect to the proportion of sleep  stages, which may or may not have had impact on overall performance. It is well established that there is significant  variation in scoring and validation of N1/REM and N2/N3 3,5,7 , which challenges the training for any classification  algorithm. Some researchers have experimented balancing the cost of misclassifying sleep stages by weighting them by  their inverse frequency of occurrence and found no significant improvement 24,52 , while others have experimented with  balancing the sleep stage frequencies in each batch of data input to the neural network model 16 , but more rigorous research  in resampling or over/under-sampling techniques is warranted in this regard. We ultimately decided against experimenting  with balancing our sleep stages in each batch, as we prioritized flexibility with regards to the length of input sequences  fed to the network. All our models ran through at least 50 epochs of training (passes through the training partition), which  might have induced a bias in the configurations with larger cohorts. For example, one pass through the training partition  in the LOCI-ISRUC case corresponds to much less data than one pass through the LOCI-SHHS case. However, since we  selected the best performing model based on Cohen‚Äôs kappa across all 50 epochs, we have allowed for more effective  training in cases with less available training data. We observed that models using less data in the training partition  generally had to run for longer time (i.e. more epochs) before converging.  In future studies on automatic sleep stage classification algorithms, we strongly recommend researchers to test and report  results on not just hold-out test partitions, but also on cohorts completely unseen by the model both during training and\n\n16 of 28  testing/validation. Our experiments indicate that even though good performance can be achieved on hold-out data using  a single cohort, this does not necessarily translate into good generalization performance. Such approach requires  availability of many publicly available, high-quality, well-documented databases with easily accessible PSG data,  associated annotations and related patient information. In this regard, websites such as the NSRR, which contains several  large databases with clinical data as well as PSG and annotation data in a standardized format 31,32 , are an invaluable  resource for researchers. We also propose that the sleep science community establishes a common reference dataset on  which researchers in machine learning can benchmark their models, similar to what the computer vision and general  machine learning community has done with the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 53 , an  annual competition in which researchers submit their models to test in various competitions.  In summary, we have developed an automatic sleep stage classification algorithm based on deep learning, that can  accurately classify sleep stages at a flexible resolution with a state-of-the-art classification performance of 87% accuracy  on a test set of 1,584 PSGs. We trained and tested our model using five cohorts with varying numbers of PSGs covering  multiple phenotypes with specific focus on how well cohorts can generalize to each other. We found that different cohorts  generalize very differently both in intra- and inter-cohort settings (LOCI vs. LOCO experiments). Furthermore, we also  found that having more data sources significantly improve classification performance and generalizability to the extent  that even just a small number of training PSGs can reach high classification performance by including many different  sources. To our knowledge, this is one of the largest, if not the largest, study on automatic sleep stage classification in  terms of PSG volume, diversity, and performance.\n\n17 of 28  ACKNOWLEDGMENTS  Some of the computing for this project was performed on the Sherlock cluster. We would like to thank Stanford University  and the Stanford Research Computing Center for providing computational resources and support that contributed to these  research results.  The authors would also like to thank the National Sleep Research Resource (https://www.sleepdata.org) team for their  work in collecting, organizing and making available some of the PSG data used in this study.  The authors would also like to thank Julie Anja Engelhard Christensen, PhD, for her editorial work on this paper.\n\n18 of 28  DISCLOSURE STATEMENT  A. N. Olesen has received funding from The Klarman Family Foundation; Technical University of Denmark; University  of Copenhagen; Reinholdt W. Jorck og Hustrus Fonden; Otto M√∏nsteds Fond; Stibofonden; Knud H√∏jgaards Fond;  Augustinus Fond; and Vera og Carl Johan Michaelsens Fond. E. Mignot has received partial funding by the Klarman  Family Foundation, has received research support from Jazz Pharmaceuticals, is a consultant for Rhythm (a sleep  consumer product company) and Alairion (a sleep apnea pharmacology company), and is on the speakers' bureau for Vox  Media.\n\n19 of 28  REFERENCES  1.   Chiao W, Durr ML. Trends in sleep studies performed for Medicare beneficiaries.   Laryngoscope . 2017;127(12):2891-2896.  doi:10.1002/lary.26736  2.   Berry RB, Albertario CL, Harding SM, et al.   The AASM Manual for the Scoring of Sleep and Associated Events: Rules, Terminology and  Technical Specifications.   2.5. Darien, Il: American Academy of Sleep Medicine; 2018.  3.   Younes M, Raneri J, Hanly P. Staging sleep in polysomnograms: Analysis of inter-scorer variability.   J Clin Sleep Med . 2016;12(6):885-  894. doi:10.5664/jcsm.5894  4.   Younes M. The case for using digital EEG analysis in clinical sleep medicine.   Sleep Sci Pract . 2017;1(2). doi:10.1186/s41606-016-0005-0  5.   Younes M, Kuna ST, Pack AI, et al. Reliability of the American Academy of Sleep Medicine Rules for Assessing Sleep Depth in Clinical  Practice.   J Clin Sleep Med . 2018;14(02):205-213. doi:10.5664/jcsm.6934  6.   Rosenberg RS, Van Hout S. The American Academy of Sleep Medicine Inter-scorer Reliability Program: Sleep Stage Scoring.   J Clin Sleep  Med . 2013;9(1):81-87. doi:10.5664/jcsm.2350  7.   Norman RG, Pal I, Stewart C, Walsleben JA, Rapoport DM. Interobserver Agreement Among Sleep Scorers From Different Centers in a  Large Dataset.   Sleep . 2000;23(7):1-8. doi:10.1093/sleep/23.7.1e  8.   Fiorillo L, Puiatti A, Papandrea M, et al. Automated sleep scoring: A review of the latest approaches.   Sleep Med Rev . 2019;48:101204.  doi:10.1016/j.smrv.2019.07.007  9.   Goldberger AL, Amaral LAN, Glass L, et al. PhysioBank, PhysioToolkit, and PhysioNet.   Circulation . 2000;101(23):e215-e220.  doi:10.1161/01.CIR.101.23.e215  10.   Kemp B, Zwinderman AH, Tuk B, Kamphuisen HAC, Obery√© JJL. Analysis of a sleep-dependent neuronal feedback loop: The slow-wave  microcontinuity of the EEG.   IEEE Trans Biomed Eng . 2000;47(9):1185-1194. doi:10.1109/10.867928  11.   Vilamala A, Madsen KH, Hansen LK. Deep convolutional neural networks for interpretable analysis of EEG sleep stage scoring. In:   2017  IEEE 27th International Workshop on Machine Learning for Signal Processing (MLSP) . Tokyo, Japan: IEEE; 2017:1-6.  doi:10.1109/MLSP.2017.8168133  12.   Phan H, Andreotti F, Cooray N, Chen OY, Vos M De. Automatic Sleep Stage Classification Using Single-Channel EEG: Learning  Sequential Features with Attention-Based Recurrent Neural Networks. In:   2018 40th Annual International Conference of the IEEE  Engineering in Medicine and Biology Society (EMBC) . IEEE; 2018:1452-1455. doi:10.1109/EMBC.2018.8512480  13.   Supratak A, Dong H, Wu C, Guo Y. DeepSleepNet: A Model for Automatic Sleep Stage Scoring Based on Raw Single-Channel EEG.   IEEE  Trans Neural Syst Rehabil Eng . 2017;25(11):1998-2008. doi:10.1109/TNSRE.2017.2721116  14.   ≈ûen B, Peker M, √áavu≈üo«ßlu A, √áelebi F V. A comparative study on classification of sleep stage based on EEG signals using feature  selection and classification algorithms.   J Med Syst . 2014;38(3). doi:10.1007/s10916-014-0018-0  15.   O‚ÄôReilly C, Gosselin N, Carrier J, Nielsen T. Montreal archive of sleep studies: An open-access resource for instrument benchmarking and  exploratory research.   J Sleep Res . 2014;23(6):628-635. doi:10.1111/jsr.12169  16.   Chambon S, Galtier MN, Arnal PJ, Wainrib G, Gramfort A. A Deep Learning Architecture for Temporal Sleep Stage Classification Using  Multivariate and Multimodal Time Series.   IEEE Trans Neural Syst Rehabil Eng . 2018;26(4):758-769. doi:10.1109/TNSRE.2018.2813138  17.   Andreotti F, Phan H, Cooray N, Lo C, Hu MTM, De Vos M. Multichannel Sleep Stage Classification and Transfer Learning using  Convolutional Neural Networks. In:   2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society  (EMBC) . IEEE; 2018:171-174. doi:10.1109/EMBC.2018.8512214  18.   Phan H, Andreotti F, Cooray N, Chen OY, De Vos M. Joint Classification and Prediction CNN Framework for Automatic Sleep Stage  Classification.   IEEE Trans Biomed Eng . 2019;66(5):1285-1296. doi:10.1109/TBME.2018.2872652\n\n20 of 28  19.   Phan H, Andreotti F, Cooray N, Chen OY, De Vos M. SeqSleepNet: End-to-End Hierarchical Recurrent Neural Network for Sequence-to-  Sequence Automatic Sleep Staging.   IEEE Trans Neural Syst Rehabil Eng . 2019;27(3):400-410. doi:10.1109/TNSRE.2019.2896659  20.   LeCun Y, Bengio Y, Hinton G. Deep learning.   Nature . 2015;521(7553):436-444. doi:10.1038/nature14539  21.   Stephansen JB, Olesen AN, Olsen M, et al. Neural network analysis of sleep stages enables efficient diagnosis of narcolepsy.   Nat Commun .  2018;9(1):5229. doi:10.1038/s41467-018-07229-3  22.   Biswal S, Sun H, Goparaju B, Westover MB, Sun J, Bianchi MT. Expert-level sleep scoring with deep neural networks.   J Am Med  Informatics Assoc . 2018;25(12):1643-1650. doi:10.1093/jamia/ocy131  23.   Patanaik A, Ong JL, Gooley JJ, Ancoli-Israel S, Chee MWL. An end-to-end framework for real-time automatic sleep stage classification.  Sleep . 2018;41(5):1-11. doi:10.1093/sleep/zsy041  24.   Olesen AN, Jennum P, Peppard P, Mignot E, Sorensen HBD. Deep residual networks for automatic sleep stage classification of raw  polysomnographic waveforms. In:   2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society  (EMBC) . IEEE; 2018:1-4. doi:10.1109/EMBC.2018.8513080  25.   Biswal S, Kulas J, Sun H, et al. SLEEPNET: Automated Sleep Staging System via Deep Learning. July 2017:1-17.  http://arxiv.org/abs/1707.08262.  26.   Khalighi S, Sousa T, Santos JM, Nunes U. ISRUC-Sleep: A comprehensive public dataset for sleep researchers.   Comput Methods Programs  Biomed . 2016;124:180-192. doi:10.1016/j.cmpb.2015.10.013  27.   Blank JB, Cawthon PM, Carrion-Petersen M Lou, et al. Overview of recruitment for the osteoporotic fractures in men study (MrOS).  Contemp Clin Trials . 2005;26(5):557-568. doi:10.1016/j.cct.2005.05.005  28.   Orwoll E, Blank JB, Barrett-Connor E, et al. Design and baseline characteristics of the osteoporotic fractures in men (MrOS) study ‚Äî A  large observational study of the determinants of fracture in older men.   Contemp Clin Trials . 2005;26(5):569-585.  doi:10.1016/j.cct.2005.05.006  29.   Blackwell T, Yaffe K, Ancoli-Israel S, et al. Associations Between Sleep Architecture and Sleep-Disordered Breathing and Cognition in  Older Community-Dwelling Men: The Osteoporotic Fractures in Men Sleep Study.   J Am Geriatr Soc . 2011;59(12):2217-2225.  doi:10.1111/j.1532-5415.2011.03731.x  30.   Rechtschaffen A, Kales A, eds.   A Manual of Standardized Terminology, Techniques and Scoring System for Sleep Stages of Human  Subjects . Washington, DC: National Institute of Health; 1968.  31.   Dean DA, Goldberger AL, Mueller R, et al. Scaling Up Scientific Discovery in Sleep Medicine: The National Sleep Research Resource.  Sleep . 2016;39(5):1151-1164. doi:10.5665/sleep.5774  32.   Zhang G-Q, Cui L, Mueller R, et al. The National Sleep Research Resource: towards a sleep data commons.   J Am Med Informatics Assoc .  2018;0(June):1-8. doi:10.1093/jamia/ocy064  33.   Redline S, Sanders MH, Lind BK, et al. Methods for obtaining and analyzing unattended polysomnography data for a multicenter study.  Sleep Heart Health Research Group.   Sleep . 1998;21(7):759-767. http://www.ncbi.nlm.nih.gov/pubmed/11300121.  34.   Quan SF, Howard B V, Iber C, et al. The Sleep Heart Health Study: design, rationale, and methods.   Sleep . 1997;20(12):1077-1085.  http://www.ncbi.nlm.nih.gov/pubmed/9493915.  35.   Young T, Finn L, Peppard PE, et al. Sleep Disordered Breathing and Mortality: Eighteen-Year Follow-up of the Wisconsin Sleep Cohort.  Sleep . 2008;31(8):291-292. doi:10.5665/sleep/31.8.1071  36.   Young T, Palta M, Dempsey J, Skatrud J, Weber S, Badr S. The Occurrence of Sleep-Disordered Breathing among Middle-Aged Adults.   N  Engl J Med . 1993;328(17):1230-1235. doi:10.1056/NEJM199304293281704  37.   Andlauer O, Moore H, Jouhier L, et al. Nocturnal Rapid Eye Movement Sleep Latency for Identifying Patients With Narcolepsy/Hypocretin\n\n21 of 28  Deficiency.   JAMA Neurol . 2013;70(7):891. doi:10.1001/jamaneurol.2013.1589  38.   Moore H, Leary E, Lee S-Y, et al. Design and Validation of a Periodic Leg Movement Detector.   PLoS One . 2014;9(12):e114565.  doi:10.1371/journal.pone.0114565  39.   Chambon S, Thorey V, Arnal PJ, Mignot E, Gramfort A, Neurospin CEA. A deep learning architecture to detect events in EEG signals  during sleep. In:   2018 IEEE 28th International Workshop on Machine Learning for Signal Processing (MLSP) . IEEE; 2018:1-6.  40.   Chambon S, Thorey V, Arnal PJ, Mignot E, Gramfort A. DOSED: A deep learning approach to detect multiple sleep micro-events in EEG  signal.   J Neurosci Methods . 2019;321:64-78. doi:10.1016/j.jneumeth.2019.03.017  41.   Olesen AN, Chambon S, Thorey V, Jennum P, Mignot E, Sorensen HBD. Towards a Flexible Deep Learning Method for Automatic  Detection of Clinically Relevant Multi-Modal Events in the Polysomnogram. In:   2019 41st Annual International Conference of the IEEE  Engineering in Medicine and Biology Society (EMBC) . IEEE; 2019:556-561. doi:10.1109/EMBC.2019.8856570  42.   Ioffe S, Szegedy C. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. In:   Proceedings of the  32nd International Conference on Machine Learning . Vol 37. Lille, France: JMLR: W&CP; 2015. doi:10.1007/s13398-014-0173-7.2  43.   He K, Zhang X, Ren S, Sun J. Identity Mappings in Deep Residual Networks. In:   Computer Vision -- ECCV 2016 . Vol abs/1603.0. ;  2016:630-645. doi:10.1007/978-3-319-46493-0_38  44.   He K, Zhang X, Ren S, Sun J. Deep Residual Learning for Image Recognition. In:   IEEE Conference on Computer Vision and Pattern  Recognition (CVPR) . ; 2015:770-778. doi:10.1109/CVPR.2016.90  45.   Cho K, van Merrienboer B, Bahdanau D, Bengio Y. On the Properties of Neural Machine Translation: Encoder‚ÄìDecoder Approaches. In:  Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation . Stroudsburg, PA, USA: Association  for Computational Linguistics; 2014:103-111. doi:10.3115/v1/W14-4012  46.   Kingma DP, Ba J. Adam: A Method for Stochastic Optimization. In:   3rd International Conference on Learning Representations (ICLR) .  San Diego, CA; 2015:1-15. http://arxiv.org/abs/1412.6980.  47.   Glorot X, Bengio Y. Understanding the difficulty of training deep feedforward neural networks.   Proc Thirteen Int Conf Artif Intell Stat  PMLR . 2010;9:249-256.  48.   Paszke A, Gross S, Chintala S, et al. Automatic differentiation in PyTorch. In:   31st Conference on Neural Information Processing Systems  (NIPS) . Long Beach, CA, USA; 2017.  49.   Pedregosa F, Varoquaux G, Gramfort A, et al. Scikit-learn: Machine Learning in Python.   J Mach Learn Res . 2011;12:2825-2830.  50.   Brink-Kjaer A, Olesen AN, Peppard PE, et al.   Automatic Detection of Cortical Arousals in Sleep and Their Contribution to Daytime  Sleepiness .; 2019. http://arxiv.org/abs/1906.01700.  51.   Landis JR, Koch GG. The Measurement of Observer Agreement for Categorical Data.   Biometrics . 1977;33:159-174.  52.   Sors A, Bonnet S, Mirek S, Vercueil L, Payen JF. A convolutional neural network for sleep stage scoring from raw single-channel EEG.  Biomed Signal Process Control . 2018;42:107-114. doi:10.1016/j.bspc.2017.12.001  53.   Russakovsky O, Deng J, Su H, et al. ImageNet Large Scale Visual Recognition Challenge.   Int J Comput Vis . 2015:211-252.  doi:10.1007/s11263-015-0816-y\n\n22 of 28  FIGURE CAPTIONS LIST  Figure 1: Model overview. a) The input is a sequence of data   ùê±   containing raw signal data from EEG, EOG-L/R, and  EMG channels, which is supplied to the network modules in sequence. The feature extraction module consists of   ùëÖ  repeated blocks of residual units, see panel to the right. The output of the model is a matrix   ùê≤   containing class probabilities  for each sleep stage for each time step, which can be visualized either directly as a hypnodensity, or by   arg max ùê≤   as a  hypnogram. The ‚ÄúA‚Äù and ‚ÄúM‚Äù labels in the hypnogram plots corresponds to automatic and manual hypnograms. b)  Schematic of a single residual block in the feature extraction module. Convolutional layers are described by the kernel  size   √ó   number of filters using a stride value of 1. Shortcut uses 1x1 convolutions with added zero-padding to maintain  temporal dimension. Conv, convolutional layer; BatchNorm, batch normalization; ReLU, rectified linear unit;   ùëì ‡¨¥ , base  number of filters ( ùëì ‡¨¥   = 4) .\n\n23 of 28  Figure 2: Temporal context changes model performance. a) Cohen's kappa as a function of the number of hidden units in  the recurrent block. Inset shows zoom of Cohen's kappa for non-zero hidden unit values. b) Cohen's kappa as a function  of sequence length. c) Prediction accuracy averaged across all 5-minute sequences in the test partition with a small and  large training partition. Full lines are predictions evaluated every 1 s, while dashed lines show predictions averaged every  30 s. Values are shown for panels a), b) as mean with 95% confidence intervals.\n\n24 of 28  Figure 3: Individual cohorts influence classification performance on test partition ( ùëÅ = 1,584 ). As an example, training  on MrOS in a LOCI configuration, the performance on the test subset of WSC is 0.815. The diagonals in all three  configurations shows the performance for the same subjects in the test subsets in the respective cohorts making possible  direct comparisons between LOCI and LOCO. For aggregated metrics and more summary statistics, please see   Error!  Reference source not found. . LOCI, leave-one-cohort-in; LOCI-wd, LOCI with weight decay; LOCO, leave-one-cohort-  out; ISRUC, Institute of Systems and Robotics, University of Coimbra Sleep Cohort; MrOS, MrOS Sleep Study; SHHS,  Sleep Heart Health Study; SSC, Stanford Sleep Cohort; WSC, Wisconsin Sleep Cohort.\n\n25 of 28  Figure 4: Training on mixed data increased predictive performance compared to individual cohorts of similar size. a)  There is a gain in predictive performance by mixing data from various sources consistent across the size of the training  dataset. b) Confusion matrix for a model trained on 100% of the available training partition data. The model shows  excellent performance overall, with most misclassification happening between W and N1, and N1, N2, and N3. This is  somewhat consistent with clinical experience, since N1 is a transition stage between wake and the deeper stages of sleep  with much frequency content overlap with both W and N2.\n\n26 of 28  Figure 5: Number of cohorts in training partition increases model performance. Each datapoint is shown as the overall  accuracy aggregated across all subjects for a specific training configuration. For example, the bottom dot in column 2 (3  cohort configuration) shows the performance on the test set (overall accuracy   0.755 ¬± 0.109, 95% CI:   [ 0.750 ‚àí 0.760 ] ),  when training with 500 PSGs randomly and evenly drawn from the Stanford Sleep Cohort, the Institute of Systems and  Robotics, University of Coimbra Sleep Cohort, and the Wisconsin Sleep Cohort. Notice the scale on the y-axis.\n\n27 of 28  TABLES  Table 1: Cohort demographics.  ISRUC   MrOS   SHHS   SSC   WSC   p -value  N (female)   126 (50)   3932 (0)   8444 (4458)   767 (319)   2401 (1103)   0  Age, years   49.8 ¬± 15.9  [20.0-85.0]  77.6 ¬± 5.6  [67.0-90.0]  64.5 ¬± 11.2  [39.0-90.0]  45.7 ¬± 14.5  [13.0-104.8]  59.7 ¬± 8.4  [37.2-82.3]  0  BMI, kg/m2   -   27.1 ¬± 3.8  [16.0-47.0]  28.2 ¬± 5.1  [18.0-50.0]  27.2 ¬± 6.5  [9.8-78.7]  31.6 ¬± 7.2  [17.5-70.6]  1.03e-171  TST, min   350.0 ¬± 67.3  [87.5-479.0]  352.1 ¬± 71.9  [39.0-626.0]  374.1 ¬± 69.4  [68.0-605.0]  361.0 ¬± 83.5  [0.0-661.0]  364.1 ¬± 63.6  [19.5-575.0]  4.07e-38  SL, min   17.7 ¬± 20.5  [0.0-144.5]  24.7 ¬± 26.9  [1.0-402.0]  24.2 ¬± 25.7  [0.0-349.0]  93.5 ¬± 58.9  [0.5-404.0]  33.2 ¬± 21.4  [0.5-333.0]  0  REML, min   125.6 ¬± 61.4  [7.0-323.0]  104.8 ¬± 75.1  [0.0-590.0]  91.7 ¬± 58.8  [0.0-471.0]  140.9 ¬± 88.0  [0.0-464.0]  128.3 ¬± 76.0  [3.5-514.0]  2.81e-173  WASO, min   76.2 ¬± 49.8  [7.5-251.0]  117.5 ¬± 67.6  [4.0-487.0]  80.2 ¬± 54.7  [2.0-378.0]  79.5 ¬± 55.0  [3.5-367.0]  73.6 ¬± 45.9  [3.0-325.0]  4.74e-233  SE, %   78.8 ¬± 14.1  [19.5-98.3]  75.5 ¬± 12.4  [12.0-99.0]  80.5 ¬± 11.0  [11.3-99.0]  77.4 ¬± 14.8  [0.0-98.0]  77.1 ¬± 11.2  [4.1-95.6]  4.23e-117  N1, %   13.3 ¬± 5.8  [1.8-33.1]  8.3 ¬± 6.4  [0.0-70.0]  5.5 ¬± 4.0  [0.0-39.1]  11.7 ¬± 10.2  [0.0-92.0]  10.8 ¬± 6.9  [1.0-88.4]  0  N2, %   31.9 ¬± 10.3  [4.4-89.3]  62.5 ¬± 10.0  [21.0-95.0]  56.9 ¬± 11.5  [10.9-100.0]  62.8 ¬± 24.9  [0.0-636.0]  66.0 ¬± 9.4  [9.1-93.3]  0  N3, %   19.6 ¬± 8.0  [0.0-41.1]  36.0 ¬± 31.8  [0.0-259.0]  17.5 ¬± 11.6  [0.0-70.1]  9.0 ¬± 9.3  [0.0-73.0]  7.2 ¬± 7.8  [0.0-47.5]  0  REM, %   13.3 ¬± 6.3  [0.0-37.8]  19.3 ¬± 6.8  [0.0-44.0]  20.1 ¬± 6.3  [0.0-48.0]  16.3 ¬± 7.2  [0.0-40.0]  16.0 ¬± 6.2  [0.0-38.2]  1.12e-203  ArI, /h   20.2 ¬± 10.0  [2.1-72.0]  23.7 ¬± 12.1  [1.0-105.0]  18.9 ¬± 10.5  [0.0-110.4]  125.0 ¬± 124.2  [1.0-729.0]  -   0  AHI, /h   13.1 ¬± 13.2  [0.0-82.2]  13.7 ¬± 14.6  [0.0-89.0]  18.1 ¬± 16.2  [0.0-161.8]  13.5 ¬± 19.2  [0.0-98.6]  7.0 ¬± 9.4  [0.0-72.6]  0  PLMI, /h   8.0 ¬± 27.4  [0.0-292.8]  35.7 ¬± 37.5  [0.0-233.0]  -   7.0 ¬± 18.1  [0.0-139.9]  -   1.22e-169  Cohort data represented as mean ¬± SD [range] unless noted. Arousal annotations were not available for WSC; PLMI was  not available for SHHS and WSC; BMI was not available for ISRUC. N: number of subjects; TST: total sleep time; SL:  sleep latency; REML: REM latency; WASO: wake after sleep onset; SE: sleep efficiency; ArI: arousal index; AHI:  apnea/hypopnea index; PLMI: periodic leg movement index; ; ISRUC: Institute of Systems and Robotics, University of  Coimbra Sleep Cohort; MrOS: The Osteoporotic Fractures in Men Sleep Study; SHHS: Sleep Heart Health Study; SSC:  Stanford Sleep Cohort; WSC: Wisconsin Sleep Cohort.\n\n28 of 28  Table 2: Overview of model architecture.  Module   Type   # filters/units   Kernel size   Stride   Activation   Output size  ùê±   Input   ‚àí   ‚àí   ‚àí   ‚àí   1   √ó   ùê∂   √ó   ùëá  ùùã mix   2D convolution   ùê∂   ( 1 ,   ùê∂ )   1   ‚àí   ùê∂   √ó   1   √ó   ùëá  Batch normalization   ‚àí   ‚àí   1   ReLU   ùê∂   √ó   1   √ó   ùëá  ùùã feat  ( ùíì )   ,   ùíì   ‚àà   ‚ü¶ ùëπ ‚üß   ‚Ä† Residual module   ùëì ‡¨¥ 2 ‡Ø• ‡¨ø   ‡¨µ / ùëì ‡¨¥ 2 ‡Ø• ‡¨ø   ‡¨µ / 4 ùëì ‡¨¥ 2 ‡Ø• ‡¨ø   ‡¨µ   ( 1 , 1 ) / ( 1 , 3 ) / ( 1 , 1 )   ( 1 , 1 ) / ( 1 , 2 )   ReLU   ùëì ‡¨¥ 2 ‡Ø•   √ó   1   √ó   ùëá   2 ‡Ø•  ‚ÅÑ  ùùã temp   Bidirectional GRU   ùëõ ‡Øõ   ‚àí   ‚àí   ‚àí   2 ùëõ ‡Øõ   √ó   ùëá   2 ‡Øã  ‚ÅÑ  ùùã clf   1D convolution   ùêæ   2 ùëõ ‡Øõ   1   Softmax   ùêæ   √ó   ùëá   2 ‡Øã  ‚ÅÑ  Kernel sizes correspond to the first, second and third convolutional layer in each residual block. Stride counts correspond  to the residual block and the subsequent maximum pooling operation. ReLU, rectified linear unit; GRU, gated recurrent  unit;   ùê∂ , number of input channels;   ùëá , length of segment in samples;   ùëì ‡¨¥ , base number of filters in residual blocks;   ùëÖ ,  number of residual blocks;   ùëõ ‡Øõ , number of hidden units in GRU;   ùêæ , number of sleep stage classes.   ‚Ä† SeeFigure 1.\n\n2 of 5  SUPPLEMENTARY TABLES  Table S1: Temporal context impact on model performance in validation partition ( ùëõ   = 426 ).  Overall accuracy   Cohen‚Äôs kappa  Mean   SD   Median   95% CI, mean   Mean   SD   Median   95% CI, mean  Hidden units  0   0.779   0.083   0.794   [0.771-0.787]   0.645   0.126   0.660   [0.633-0.657]  64   0.818   0.079   0.837   [0.810-0.825]   0.720   0.120   0.745   [0.709-0.731]  128   0.821   0.080   0.841   [0.813-0.829]   0.724   0.121   0.745   [0.713-0.736]  256   0.820   0.082   0.843   [0.812-0.828]   0.725   0.124   0.751   [0.713-0.736]  512   0.822   0.079   0.841   [0.815-0.830]   0.727   0.119   0.752   [0.716-0.739]  1024   0.828   0.072   0.845   [0.821-0.835]   0.734   0.111   0.758   [0.723-0.744]  2048   0.823   0.080   0.843   [0.816-0.831]   0.729   0.122   0.757   [0.717-0.740]  Sequence length  2 min   0.821   0.075   0.840   [0.814-0.828]   0.726   0.114   0.754   [0.715-0.737]  3 min   0.826   0.080   0.845   [0.818-0.833]   0.733   0.123   0.762   [0.721-0.744]  4 min   0.828   0.079   0.849   [0.820-0.835]   0.734   0.122   0.762   [0.722-0.745]  5 min   0.828   0.072   0.845   [0.821-0.835]   0.734   0.111   0.758   [0.723-0.744]  10 min   0.829   0.075   0.848   [0.822-0.836]   0.734   0.113   0.759   [0.723-0.745]  Window length  1 s   0.824   0.074   0.843   [0.817-0.831]   0.728   0.113   0.752   [0.717-0.738]  3 s   0.824   0.074   0.845   [0.817-0.832]   0.728   0.113   0.752   [0.717-0.739]  5 s   0.825   0.074   0.843   [0.818-0.832]   0.728   0.113   0.752   [0.717-0.739]  10 s   0.825   0.074   0.844   [0.818-0.832]   0.729   0.113   0.753   [0.718-0.739]  15 s   0.826   0.074   0.845   [0.818-0.833]   0.729   0.113   0.755   [0.719-0.740]  30 s   0.829   0.075   0.848   [0.822-0.836]   0.734   0.113   0.759   [0.723-0.745]  The   Hidden units   variable corresponds to varying the complexity in the recurrent module by increasing the number of  hidden units.   Sequence length   indicate the length of the sequence of 30 epochs, while   Window length   correspond to  varying the evaluation frequency.\n\n3 of 5  Table S2: Performance characteristics for LOCI and LOCO training configurations.  N   PSGs  Overall accuracy   Cohen‚Äôs kappa  Mean   SD   Median   95% CI, mean   Mean   SD   Median   95% CI, mean  LOCI-wd  ISRUC   1584   0.679   0.123   0.701   [0.673-0.685]   0.542   0.169   0.574   [0.533-0.550]  MrOS   1584   0.821   0.077   0.835   [0.817-0.825]   0.727   0.114   0.745   [0.721-0.733]  SHHS   1584   0.834   0.088   0.858   [0.830-0.839]   0.750   0.132   0.786   [0.744-0.757]  SSC   1584   0.762   0.094   0.774   [0.757-0.767]   0.639   0.129   0.654   [0.633-0.646]  WSC   1584   0.758   0.105   0.773   [0.753-0.764]   0.633   0.145   0.653   [0.626-0.640]  LOCI  ISRUC   1584   0.676   0.124   0.700   [0.670-0.682]   0.539   0.170   0.574   [0.531-0.547]  MrOS   1584   0.826   0.074   0.839   [0.822-0.829]   0.732   0.111   0.748   [0.726-0.737]  SHHS‚Ä°   1584   0.837   0.084   0.858   [0.833-0.841]   0.754   0.127   0.786   [0.748-0.761]  SSC   1584   0.773   0.088   0.785   [0.769-0.777]   0.657   0.125   0.671   [0.651-0.663]  WSC   1584   0.763   0.101   0.776   [0.758-0.768]   0.641   0.140   0.659   [0.635-0.648]  LOCO  ISRUC‚Ä†   52   0.749   0.081   0.764   [0.727-0.771]   0.648   0.119   0.682   [0.616-0.680]  126   0.757   0.071   0.766   [0.744-0.769]   0.661   0.101   0.682   [0.643-0.678]  MrOS‚Ä†   371   0.843   0.066   0.851   [0.836-0.849]   0.757   0.104   0.776   [0.746-0.767]  3932   0.841   0.069   0.854   [0.838-0.843]   0.752   0.107   0.775   [0.749-0.755]  SHHS   846   0.805   0.076   0.815   [0.800-0.810]   0.705   0.109   0.722   [0.698-0.712]  8444   0.800   0.081   0.811   [0.798-0.801]   0.697   0.115   0.713   [0.694-0.699]  SSC   76   0.793   0.086   0.809   [0.744-0.812]   0.680   0.120   0.700   [0.653-0.707]  766   0.798   0.086   0.815   [0.792-0.805]   0.690   0.123   0.711   [0.681-0.699]  WSC‚Ä†   239   0.826   0.065   0.835   [0.818-0.834]   0.720   0.096   0.736   [0.708-0.732]  2411   0.824   0.068   0.837   [0.821-0.827]   0.718   0.100   0.736   [0.714-0.722]  Metrics are aggregated across all subjects for each cohort in test partition ( ùëÅ   = 1,584   PSGs). Statistics in italics  correspond to evaluating performance on entire cohort. PSG: polysomnography; LOCI-wd: leave-one-cohort-in with  weight decay; LOCO: leave-one-cohort-out; ISRUC: Institute of Systems and Robotics, University of Coimbra Sleep  Cohort; MrOS: The Osteoporotic Fractures in Men Sleep Study; SHHS: Sleep Heart Health Study; SSC: Stanford Sleep  Cohort; WSC: Wisconsin Sleep Cohort; ‚Ä†: significantly better than corresponding LOCI; ‚Ä°: significantly better than  corresponding LOCO.\n\n4 of 5  Table S3: Model performance of test partition with varying fractions of training data.  Overall accuracy   Cohen‚Äôs kappa  Mean   SD   Median   95% CI, mean   Mean   SD   Median   95% CI, mean  Fraction (%)  0.25   0.782   0.097   0.801   [0.777-0.787]   0.671   0.141   0.696   [0.664-0.678]  0.50   0.804   0.086   0.824   [0.800-0.808]   0.696   0.131   0.724   [0.689-0.702]  1   0.824   0.079   0.840   [0.820-0.828]   0.730   0.118   0.753   [0.724-0.736]  5   0.841   0.074   0.856   [0.837-0.844]   0.757   0.113   0.780   [0.751-0.763]  10   0.850   0.069   0.864   [0.847-0.853]   0.770   0.108   0.791   [0.765-0.775]  25   0.858   0.066   0.873   [0.854-0.861]   0.782   0.102   0.804   [0.777-0.787]  50   0.860   0.063   0.874   [0.856-0.863]   0.787   0.097   0.809   [0.782-0.792]  75   0.867   0.062   0.882   [0.864-0.870]   0.797   0.096   0.818   [0.792-0.802]  100   0.869   0.064   0.883   [0.865-0.872]   0.799   0.098   0.820   [0.794-0.804]  Increasing the available training data increased performance on the test partition ( ùëÅ   = 1,584 ) shown here as aggregated  metrics across all subjects. No statistical difference was found by comparing confidence intervals (CI) between models  trained with 75% and 100% of available training data, which indicates a saturation in training.\n\n5 of 5  Table S4: Model performance on test partition ( ùëÅ   = 1,584 ) with varying number of cohorts in training partition.  Training cohorts   Overall accuracy   Kappa  Mean   SD   Median   95% CI, mean   Mean   SD   Median   95% CI, mean  2  Overall   0.788   0.102   0.811   [0.787-0.790]   0.683   0.143   0.710   [0.681-0.685]  ISRUC-MrOS   0.781   0.102   0.804   [0.776-0.786]   0.675   0.143   0.703   [0.668-0.682]  ISRUC-SHHS   0.808   0.097   0.835   [0.804-0.813]   0.717   0.142   0.756   [0.710-0.724]  ISRUC-SSC   0.735   0.103   0.753   [0.729-0.740]   0.613   0.140   0.638   [0.606-0.620]  ISRUC-WSC   0.745   0.107   0.758   [0.740-0.750]   0.628   0.140   0.642   [0.621-0.635]  MrOS-SHHS   0.829   0.081   0.849   [0.825-0.833]   0.740   0.124   0.769   [0.734-0.746]  MrOS-SSC   0.796   0.090   0.816   [0.791-0.800]   0.683   0.133   0.708   [0.677-0.690]  MrOS-WSC   0.805   0.087   0.822   [0.801-0.809]   0.699   0.126   0.722   [0.693-0.705]  SHHS-SSC   0.816   0.090   0.839   [0.812-0.821]   0.722   0.129   0.755   [0.716-0.729]  SHHS-WSC   0.824   0.089   0.846   [0.820-0.828]   0.733   0.128   0.762   [0.727-0.739]  SSC-WSC   0.742   0.110   0.755   [0.737-0.748]   0.620   0.145   0.634   [0.613-0.627]  3  Overall   0.808   0.092   0.830   [0.807-0.810]   0.711   0.131   0.739   [0.709-0.713]  ISRUC-MrOS-SHHS   0.820   0.092   0.844   [0.815-0.825]   0.732   0.134   0.766   [0.725-0.738]  ISRUC-MrOS-SSC   0.798   0.088   0.816   [0.794-0.802]   0.694   0.129   0.720   [0.688-0.700]  ISRUC-MrOS-WSC   0.811   0.083   0.828   [0.807-0.815]   0.711   0.119   0.735   [0.705-0.717]  ISRUC-SHHS-SSC   0.807   0.090   0.828   [0.803-0.812]   0.714   0.126   0.739   [0.708-0.721]  ISRUC-SHHS-WSC   0.817   0.091   0.842   [0.813-0.822]   0.728   0.128   0.759   [0.722-0.735]  ISRUC-SSC-WSC   0.755   0.109   0.775   [0.750-0.760]   0.639   0.150   0.670   [0.631-0.646]  MrOS-SHHS-SSC   0.833   0.071   0.848   [0.829-0.837]   0.744   0.109   0.766   [0.739-0.750]  MrOS-SHHS-WSC   0.840   0.073   0.854   [0.836-0.843]   0.753   0.109   0.774   [0.748-0.759]  MrOS-SSC-WSC   0.795   0.088   0.811   [0.791-0.800]   0.687   0.123   0.706   [0.681-0.693]  SHHS-SSC-WSC   0.807   0.101   0.833   [0.802-0.812]   0.710   0.142   0.744   [0.703-0.717]  4  Overall   0.821   0.085   0.840   [0.819-0.823]   0.728   0.124   0.755   [0.726-0.731]  ISRUC-MrOS-SHHS-SSC   0.827   0.078   0.843   [0.823-0.831]   0.739   0.115   0.764   [0.733-0.744]  ISRUC-MrOS-SHHS-WSC   0.835   0.075   0.850   [0.831-0.838]   0.747   0.112   0.768   [0.742-0.753]  ISRUC-MrOS-SSC-WSC   0.794   0.097   0.817   [0.789-0.799]   0.687   0.139   0.716   [0.680-0.694]  ISRUC-SHHS-SSC-WSC   0.819   0.091   0.843   [0.814-0.823]   0.728   0.131   0.759   [0.721-0.734]  MrOS-SHHS-SSC-WSC   0.830   0.076   0.846   [0.826-0.834]   0.741   0.112   0.763   [0.736-0.747]  The total number of training records were fixed at   ùëÅ   = 500   for all configurations. ISRUC: Institute of Systems and  Robotics, University of Coimbra Sleep Cohort; MrOS: The Osteoporotic Fractures in Men Sleep Study; SHHS: Sleep  Heart Health Study; SSC: Stanford Sleep Cohort; WSC: Wisconsin Sleep Cohort.",
    "C ord - blood   vitamin D level   and night sleep duration in pre schoolers in the EDEN  mother - child birth cohort  Chu Yan Yong 1,2 , Eve Reynaud 1,2 , Anne Forhan 1,2 , Patricia Dargent - Molina 1,2 , Barbara  Heude 1,2 , Marie - Aline Charles 1,2 , Sabine Plancoulaine 1,2 ; on   behalf of the EDEN study group.  Affiliations:  1   INSERM, UMR1153, Epidemiology and Statistics Sorbonne Paris Cit√© Research Center  (CRESS), early ORigins of Child Health And Development Team (ORCHAD), Villejuif, F -  94807 France;  2   Univ   Paris - Descartes, UMRS 1153, Paris, France;  Address correspondence to:  Sabine Plancoulaine, INSERM, UMR1153, Epidemiology and Statistics Sorbonne Paris Cit√©  Research   Center   (CRESS),   early   ORigins   of   Child   Health   And   Development   Team  (ORCHAD), 16 Av Paul   Vaillant Couturier, 94 807 Villejuif Cedex, FRANCE,  Email:   sabine.plancoulaine@inserm.fr  Phone: + 33 1 45 59 51 09.  Ethical approval and consent to participate:  The study was approved by the ethics re search committee of Bic√™tre Hospital (Comit√©  Consultatif de Protection des Personnes dans la Recherche Biom√©dicale) and by the Data  Protection Authority (Commission Nationale de l‚ÄôInformatique et des Libert√©s).\n\nABSTRACT  Objecti ve :   25 - hydroxyvitamin   D   ( 25OHD )   deficiency   has   been   associated   with   sleep  disorders in adults.   Only   three   cross - sectional   stud ies   were   performed   in children and show ed  an   association between   25OHD   deficiency   and   both   obstructive sleep apnea syndrome and  primary snoring . No   longitudinal stud y   has been   performed in children   from   the general  population.   We analyzed the association   between cord - blood vitamin D level   at birth   and  night - sleep duration trajectories for children between 2 and 5 - 6 years   old   in a non - clinical  cohort.  Method :   We included   264   c hildren from the French   EDEN mother - child birth - cohort   with  both   co rd - blood   25OHD   level   determined   by   radio - immunoassay   at birth ,   and   night - sleep  trajectories   for children   between 2 and 5 - 6 years   old   obtained by the group - based   trajectory  modeling method .   Association s   between   25OHD   and sleep trajectories w ere   assessed by  multinomial logistic regression adjusted for maternal and child characteristics.  Results:   The trajectories s hort   sleep ( < 10h 30 /night), medium - low   sleep ( 10h30 - 11h00 /night),  medium - high sleep ( ‚âà 11h30/night), long   sleep ( ‚â• 11h30/night) and   changing   sleep (decreased  from   ‚â• 11h30 to   10 h 30 - 11 h 00 /night) represented 5%, 46% , 37% , 4% and 8% of the children ,  respectively .   The   me an   25OHD   level   wa s 1 9   ng/ml ( SD=11, range   3 to 63 ).   It was   12 (SD=7),  20 (SD=11), 19 (SD=10), 14 (SD=7) and 16 (SD=8) ng/ml   for children   with   short, medium -  low, medium - high, long a nd changing   sleep   trajector ies ,   respectively .   On   adjusted   analysis ,  for   each 1 - ng/ml decrease   in   25OHD   level, the odd s   of   belong ing   to   the   short   sleep   versus  medium - high   sleep   trajectory   was increased   ( odds ratio   =1. 12 ,   95%   confidence interval   [1.01 -  1.25] ) .   We found no   other   significant   association between 25OHD   level   and   other trajectories.  Conclusion :   L ow   25OHD   level   at birth   may be   associated with   increased   probability of being  a   persistent   short   sleeper   in preschool years.   These results need confirmation .  Keywords:   pediatric sleep, vitamin D, epidemiology, cohort,\n\n1.   Introduction  V itamin   D , a steroid   hormone,   is involved in bone metabolism promoting digestive calcium  absorption,   apoptosis   and   angiogenesis ,   decreasing   cell   proliferation.   It   has   an  immunomodulatory,   anti - infectious,   anti - inflammatory   and   anti - tumor   role.   Vitamin   D  deficiency has been ass ociated with many pathological conditions including osteoporosis,  microbial infections, cardiovascular diseases, cancers, autoimmune diseases, asthma and  allergy (reviewed in   [1] ).   It   is common in the general population (up to 80% of European  adolescents)   [2,3] . The   known   risk factors for   vitamin D   deficiency in adults and children in  the general population are pigmented skin, obesity, self - limitation of solar exposure and   use  of   sunscree ns,   and   poor dietary intake of   vitamin D   ( e.g.,   fatty fish, egg ,   milk)   [4,5] . There is  a seasonal variation in   vitamin D   levels   [6] ,   with   higher   level s   in summer and lower   levels   in  winter.  Cross - sectional studies have recently suggested a   role   for   vitamin D   and its metabolism in  sleep   [7,8] , in   particular   in the development of symptoms such as obstructive sleep apnea   [9] ,  diurnal somnolence   [10] ,   and   restless leg syndrome   [11]   in adults. In   older people ,   vitamin D  deficiency was   found   associated with poor sleep (short duration or low effic iency )   [12]   that  was   improved by supplementation   [13] . In children, only   three   cross - sectional   stud ies   ha ve  been published and show ed   association s   between   vitamin D   deficiency and obstructive sleep  apnea syndrome   and primary snoring   [14 ‚Äì 16] .  Here we aimed   to   analy z e   the   association   between   cord - blood   vitamin D   level   at birth   and  night - sleep duration   trajectories   in children   between 2 and 5 - 6   years   old   in   a non - clinical  cohort.  2.   Material and methods  2.1.   Study   population  The EDEN study aims at investigating the pre -   and post - natal determinants of child health and  development. Details of the EDEN study protocol have been previously published   [17] .  Briefly, pregnant women under 24 weeks of amenorrhea were recruited between 2003 and  2006 in the university hospitals of Poitiers and Nancy. Those under 18 years, unable to give  informed consent, functionally illiterate in French, with a history of diabe tes, planning on  changing address or without social security coverage were excluded from the cohort.   Women  with m ultiple pregnancies were also excluded.   A total of   1899 children were enlisted at birth.  Written informed consent was obtained twice from paren ts: at enrolment and after the child‚Äôs\n\nbirth. The study was approved by   a n   ethics research committee and by the   national d ata  protection a uthority .  2.2.   Measures   and   participant   characteristics  2.2.1.   Cord - blood   vitamin D   measurement  Cord - blood   samples   were   collected   immediately   after   birth   (vaginal   delivery)   or   after  extraction of the fetus   via   uterine incision (elective cesarean section)   and   were centrifuged  within 24   h of collection. The ser um was separated and stored at   - 80 o C . Serum   25 -  hydro xyvitamin D ( 25OH D ) , representative of overall   v it amin   D stored in the body,   was  measured by immunochemiluminescent immunoassay performed on the LIAISON platform  ( DiaSorin ,   Sallugia, Italy). The intra -   and inter - assay coefficient   of variation was   <   10%  whatever the measured   level .   This measure was performed   for   a subsample of   375 children  from   the EDEN cohort   that correspond to infants who had quantitative   ultrasonography  measurements of bone status at   age   1 year   ( i.e. ,   infants examined from April 2006 onward )  [18] .  2.2.2.   Night - sleep duration trajectories   in children   between 2 and 5 - 6 years   old  Night - sleep duration   was   collected at age 2, 3 and 5 - 6 years   by   using parental self -  administered questionnaires and   was   calculated   on the basis of   the answers to the following  questions: ‚ÄúUsually, at what time does your child go to bed?‚Äù, ‚ÄúUsually, at what time does  your child wak e up?‚Äù. Responses were recorded in hours and minutes   (e.g., 10h30) .   \"Group -  based trajectory modeling\" developed by Nagin et al .   [19] , implemented under SAS (PROC  TRAJ) and data - driven ,   was used to identify night - sleep duration trajectories among 1205  children from the cohort   whose   parents had answered the questions regarding night - sleep  durations   for   at least two   of three   age   points. The method is based on the   underlying  hypothesis that   within a population there are inherent groups that evolve according to  different sleep patterns. The groups are not directly identifiable or pre - established by sets of  characteristics but   are   statistically determined   by   each series of responses   by   using   maximum  likelihood.  Five night - sleep duration trajectories were established   as   previously reported   [20]   (Figure 1):  s hort   sleep   (SS, <10 h 30/night, 4.9% of 1205 children),   m edium - l ow   sleep   (MLS, 10 h 30 -  11 h 00/night, 47.8%),   m edium - h igh   sleep   (MHS,   about   11 h 30/night, 37.2%),   l ong   sleep   (LS,  ‚â• 11 h 30/night, 4.5%) and   c hanging   s leep (CS, i.e. ,   LS then MLS, 5.6%). Each child was  assigned   to the trajectory to which he/she belonged with the highest probability. Only children\n\nwith both an   assign ed   trajectory and cord - blood vitamn D measure were included in the  current study.  2.2.3.   Socio - demographic and health characteristics  H ousehold socio - economic and demographic factors as well as maternal characteristics were  collected at inclusion : maternity ward   of recruitment   (N ancy/Poitiers) , h ousehold   monthly  income   (<1500, 1500 - 3000 and   ‚â• 3000 euros , US dollar equivalent: < $ 1600,   $ 1600 - 3250, >  $ 3250) ,   maternal education level (< high - school, high school diploma   to 2 - year university  degree , >2 - year university de gree) ,   and maternal   age at delivery .   Body mass index (BMI)  before pregnancy was calculated   by   using reported height and weight.   Child‚Äôs   sex   and season  of birth was collected from   maternity medical charts .   Because of   French regulation s , ethnic  origin was   not collected. However, we collect ed   information on geographic origin of parents  and grandparents. Children were considered of European origin   if   both parents and maternal  grandparents were   born in a European country .  2.3.   Statistical analys i s  A total of 264 children presented available data for both 25OHD measure and sleep trajectory  and were included in the present analysis.   They were compared to   non - included children for  maternal and child characteristics   by   chi - square and   Student   t   test.   The   association s   between  socio - demographic   and   health   characteristics   and   night - sleep   duration   trajectories   and  between   cord blood   vitamin D   level   and night - sleep trajectories   were   assessed   by multiple  multinomial logistic regression (SAS 9.3 ,   SAS Institute I nc, Cary, NC, USA).   M ultivariable  m odels   estimate d   odds ratio s   (ORs)   and 95% confidence intervals (CIs)   associated with   a   1 -  unit decrease   in   25OHD   level .   C onfounding factors were identified from   the   literature and  selected   by   using the Directed Acyclic   Graphs method ( www.dagitty.net )   [21] . The   resulting  model   adjusted   for   recruitment   centre,   maternal   education,   familial   income,   family  geographical origin, pre - pregnancy   maternal   BMI,   maternal age   at del ivery , child‚Äôs   sex   and  season of birth.  3.   Results  Compared to non - included children,   for   the   264   children in the study , mothers   were   older (30  vs 29 years, p=0.003) and   more educated (4 1 % vs 30%   >2 - year university degree,   p< 0.0001 )  and   had   higher incomes (32% vs 26%   with   income >3000 euros, p< 0.0002 ).   Included  children were frequently   boys   ( 60 %   vs 5 1 %, p=0.0 2 ), born in spring (4 3 %   vs 28%, p< 0.0001 )  and   had   higher   mean 25OHD   level   (1 9   vs 1 5   ng/ml, p =0.00 3 ) .   Distribution of n ight - sleep  duration trajector ies   did not differ between included and excluded children   (p=0. 47 ) .   Table 1\n\nprovide s   the characteristics of included children.   The   me an   25OHD   level   was 1 2   ( SD=7 ) ,   20  ( SD=11 ) , 1 9   ( SD=10 ) , 16   ( SD=8 ) , and 1 4   ( SD=7 )   ng/ml   for the SS, MLS, MHS, CS and LS  trajectories, respectively.   Crude and adjusted   ORs   of belonging to a given sleep trajectory  versus the   MHS   trajectory (reference) are presented in   F igure 2. After adjustment ,   ORs  remained stable and   each 1 - ng/ml decrease   in   25OHD   level   was associated with 12%  increased   odds of   belong ing   to the SS trajectory (vs the MHS trajectory).   Only the   estimated  OR   for   belonging to   the LS trajectory   was modified by adjustment and   increased from   1.06  [ 95% CI   0.98 - 1.14 ] to   1.10 [1.00 - 1.23 ]   for each 1 - ng/ml decrease   in   25OHD   level , remaining  bordeline significant.  4.   Discussion  This is the first   longitudinal study   exploring 25OHD   level   in   newborns   from   the   general  population and its association with sleep duration   during   preschool   age .   On   adjusted analysis,  for each 1 - ng/ml decrease in 25OHD level, the odds of belonging to the SS versus MHS  trajectory was increased 12%.  We report   general ly   low   serum   25OHD   level   at birth   in this sample of children ,   which  suggests   global vitamin D defici ency   in   French   newborns   and their mother s .   The American  Association of Pediatrics estimated that 25OHD   level   should be   ‚â• 20 ng/ml in   infant s   and  children   [22] ,   whereas   the Endocrine Society recommend s   a 25OHD   level   >30   ng/ml   [23] .   In  our study,   only   41%   and 16%   of children presented such   25OHD levels   at birth , respectively .  The prevalence of 25OHD deficiency   (< 20   ng/ml)   wa s   lower   than   that   reported   in   infant cord  blood   in   the United States   [24]   and in a recent French study   [25] ,   which showed   about two  thirds   of newborns with 25OHD   level   < 20   ng/ml .   This   discrepancy   may be due to the  population selection   at inclusion ,   which thus differ ed   from the targeted population   [17]   and  the   follow - up as described ,   with   older mothers,   having   higher   incomes and educat ion   and  higher 25OHD levels in included   than excluded   children .  Cord - blood   25OHD   level s   differed   according to night - sleep trajectories .   We observed a mean  level of about   the recommended level of   20 ng /ml for MHS and MLS trajectories   for children  between 2 and 5 - 6 years   old ;   th ese   two   trajectories   are   nearest to   the recommended sleep  durations for children of this age range   [26] .   D ecreased   cord - blood   25OHD   level   was  associated with an increased   odds of   b elonging to the SS trajectory between 2 and 5 - 6 years  old   (i.e. ,   persistent   night - sleep duration <10h30   between 2 and 5 - 6 years   old ) , which suggests  an   early effect of   25OHD   level   on sleep or sleep regulation.   The a ssociation between   low  25OHD serum   level   and   short sleep duration   was   shown   in cross - sectional   studies   in adults ,\n\nespecially in   older people   i n several countries ( United States , Korea and Brazil)   [12,27 ‚Äì 29] .  However, n o study on sleep duration   was   performed   in   children.  P hysiological links   have been   observed   between vitamin D and sleep ,   suggesting that vitamin  D has direct effects on   the   initiation and mainte n ance of sleep   [30] .   Indeed,   the   v itamin D  receptor   is involved in brain development   [31]   and   ha s   been found in many cerebral regions,  including   those   that regulate sleep   [32 ‚Äì 38] .   Trials   of   vitamin D supplementation in adults  with sleep troubles showed sleep amelioration, including increased sleep dur ation   [35,39] .  However,   vitamin D deficiency   occur r ing in   early   childhood   during brain development   may  lead to   persi s tent sleep troubles.  25OHD easily cross es the   placenta barrier ,   with   a   strong correlation between cord   blood   and  maternal serum values   [40] .   The vitamin D pool of   the   fetus and newborn depends on their  mother‚Äôs   vitamin D   status.   Vitamin D supplementation during pregnancy should limit vitamin  D deficiency in infant s   and may favor both brain development and   healthy   sleep in children.  While already   applied   during pregnancy, supplementation seems insufficient and sho uld be  reinforced   [25] .   Increased c hild‚Äôs sleep duration with vitamin D supplementation need s  further exploration.  The s trengths of this study are the general population sample   and the longitudinal data for  sleep duration   in children .   This study also presents   some   limitations.   The a ttrition discussed  above   restrict s the generalization of the results. However, included and excluded children did  not differ   by   sleep trajector y   distribution ,   and 25OHD   level   was   measured   in the context of  another study objective , with blinding   to sleep data. Thus,   the   bias should be minimal.  However,   because   the studied sample size was   greatly   reduced , the   sampling fluctuations (i.e. ,  confidence i ntervals) were increased   and   results   need to be replicated   in   a   larger population .  5.   Conclusion  In this first longitudinal study exploring   the   relation   between 25OHD level at birth and sleep  duration in preschool years, we   suggest   that low 25OHD level is associated with increased  odds of   children   in a French birth cohort   between 2 and 5 - 6 years old   to be persistent short  sleeper s . These results need to be confirmed in larger sample of children from   the   general  population.\n\nAcknowle dgments  Collaborators: We thank the EDEN mother - child cohort study group (I. Annesi - Maesano, J.Y  Bernard, J. Botton, M.A. Charles, P. Dargent - Molina, B. de Lauzon - Guillain, P. Ducimeti√®re,  M. de Agostini, B. Foliguet, A. Forhan, X. Fritel, A. Germa, V. Gou a, R. Hankard, B. Heude,  M. Kaminski, B. Larroque‚Ä†, N. Lelong, J. Lepeule, G. Magnin, L. Marchand, C. Nabet, F.  Pierre, R. Slama, M.J. Saurel - Cubizolles, M. Schweitzer, O. Thiebaugeorges).  We thank all funding sources for the EDEN study: Foundation for me dical research (FRM),  National Agency for Research (ANR), National Institute for Research in Public health  (IRESP: TGIR cohorte sant√© 2008 program), French Ministry of Health (DGS), French  Ministry of Research, INSERM Bone and Joint Diseases National Resea rch (PRO - A) and  Human Nutrition National Research Programs, Paris ‚Äì Sud University, Nestl√©, French National  Institute for Population Health Surveillance (InVS), French National Institute for Health  Education (INPES), the European Union FP7 programs (FP7/2007 - 2013, HELIX, ESCAPE,  ENRIECO,Medall projects), Diabetes National Research Program (in collaboration with the  French Association of Diabetic Patients (AFD), French Agency for Environmental Health  Safety (now ANSES), Mutuelle G√©n√©rale de l‚ÄôEducation Nationa le complementary health  insurance (MGEN), French national agency for food security, French speaking association for  the study of diabetes and metabolism (ALFEDIAM).\n\nReferences  [1]   Pludowski P, Holick MF, Wagner CL, Hollis BW, Grant WB, Shoenfeld Y, et al.  Vitamin   D   effects   on   musculoskeletal   health,   immunity,   autoimmunity,   cardiovascular  disease, cancer, fertility, pregnancy, dementia and mortality ‚Äî A review of recent evidence.  A utoimmun Rev 2013;12:976 ‚Äì 89.  [2]   Braegger C, Campoy C, Colomb V, Decsi T, Domellof M, Fewtrell M, et al. Vitamin  D in the healthy European paediatric population. J Pediatr Gastroenterol Nutr 2013;56:692 ‚Äì  701. doi:10.1097/MPG.0b013e31828f3c05.  [3]   Gonz√°lez - G ross M, Valtue√±a J, Breidenassel C, Moreno LA, Ferrari M, Kersting M, et  al. Vitamin D status among adolescents in Europe: the Healthy Lifestyle in Europe by  Nutrition   in   Adolescence   study.   Br   J   Nutr   2012;107:755 ‚Äì 64.  doi:10.1017/S0007114511003527.  [4]   Bacc hetta J, Ranchin B, Dubourg L, Cochat P. Vitamine D   : un acteur majeur en  sant√©   ? Arch P√©diatrie 2010;17:1687 ‚Äì 95. doi:10.1016/j.arcped.2010.09.003.  [5]   Holick MF. Vitamin D deficiency. N Engl J Med 2007;357:266 ‚Äì 281.  [6]   Karag√ºzel G, Dilber B, √áan G, √ñkten   A, De ƒü er O, Holick MF. Seasonal Vitamin D  Status of Healthy Schoolchildren and Predictors of Low Vitamin D Status: J Pediatr  Gastroenterol Nutr 2014;58:654 ‚Äì 60. doi:10.1097/MPG.0000000000000274.  [7]   McCarty DE, Chesson AL, Jain SK, Marino AA. The link betwe en vitamin D  metabolism   and   sleep   medicine.   Sleep   Med   Rev   2014;18:311 ‚Äì 9.  doi:10.1016/j.smrv.2013.07.001.  [8]   de Oliveira DL, Hirotsu C, Tufik S, Andersen ML. The interfaces between vitamin D,  sleep and pain. J Endocrinol 2017;234:R23 ‚Äì 36. doi:10.1530 /JOE - 16 - 0514.  [9]   Mete T, Yalcin Y, Berker D, Ciftci B, Guven SF, Topaloglu O, et al. Obstructive sleep  apnea   syndrome   and   its   association   with   vitamin   D   deficiency.   J   Endocrinol   Invest  2013;36:681 ‚Äì 685.  [10]   McCarty DE, Reddy A, Keigley Q, Kim PY, Marino A A. Vitamin D, Race, and  Excessive Daytime Sleepiness. J Clin Sleep Med 2012. doi:10.5664/jcsm.2266.  [11]   Balaban H, Yƒ±ldƒ±z √ñK, √áil G,   ≈û ent√ºrk   ƒ∞ A, Erselcan T, Bolayƒ±r E, et al. Serum 25 -  hydroxyvitamin D levels in restless legs syndrome patients. Sleep Med 2 012;13:953 ‚Äì 7.  doi:10.1016/j.sleep.2012.04.009.  [12]   Massa J, Stone KL, Wei EK, Harrison SL, Barrett - Connor E, Lane NE, et al. Vitamin  D and Actigraphic Sleep Outcomes in Older Community - Dwelling Men: The MrOS Sleep  Study. Sleep 2015;38:251 ‚Äì 7. doi:10.5665/s leep.4408.  [13]   Majid MS, Ahmad HS, Bizhan H, Mohammad Hosein HZ, Mohammad A. The effect  of vitamin D supplement on the score and quality of sleep in 20 ‚Äì 50 year - old people with sleep  disorders   compared   with   control   group.   Nutr   Neurosci   2017:1 ‚Äì 9.  doi:10.108 0/1028415X.2017.1317395.  [14]   Ozgurhan G, Vehapoglu A, Vermezoglu O, Temiz RN, Guney A, Hacihamdioglu B.  Risk assessment of obstructive sleep apnea syndrome in pediatric patients with vitamin D  deficiency:   A   questionnaire - based   study.   Medicine   (Baltimore)   2016;95:e4632.  doi:10.1097/MD.0000000000004632.  [15]   Kheirandish - Gozal L, Peris E, Gozal D. Vitamin D levels and obstructive sleep apnoea  in children. Sleep Med 2014;15:459 ‚Äì 63. doi:10.1016/j.sleep.2013.12.009.  [16]   Zicari AM, Occasi F, Di Mauro F, Lollobri gida V, Di Fraia M, Savastano V, et al.  Mean Platelet Volume, Vitamin D and C Reactive Protein Levels in Normal Weight Children  with   Primary   Snoring   and   Obstructive   Sleep   Apnea   Syndrome.   PLOS   ONE  2016;11:e0152497. doi:10.1371/journal.pone.0152497.  [17]   Heu de B, Forhan A, Slama R, Douhaud L, Bedel S, Saurel - Cubizolles M - J, et al.  Cohort   Profile:   The   EDEN   mother - child   cohort   on   the   prenatal   and   early   postnatal\n\ndeterminants   of   child   health   and   development.   Int   J   Epidemiol   2015;45:353 ‚Äì 63.  doi:10.1093/ije/dyv151 .  [18]   Regnault N, Botton J, Forhan A, Hankard R, Thiebaugeorges O, Hillier TA, et al.  Determinants of early ponderal and statural growth in full - term infants in the EDEN mother -  child cohort study. Am J Clin Nutr 2010;92:594 ‚Äì 602. doi:10.3945/ajcn.2010.2929 2.  [19]   Nagin   D.   Group - based   modeling   of   development.   Cambridge,   Mass:   Harvard  University Press; 2005.  [20]   Plancoulaine S, Reynaud E, Forhan A, Lioret S, Heude B, Charles M - A, et al. Night  sleep duration trajectories and associated factors among preschool   children from the EDEN  cohort. Sleep Med 2018. doi:10.1016/j.sleep.2018.03.030.  [21]   Textor J, Hardt J, Kn√ºppel S. DAGitty: A Graphical Tool for Analyzing Causal  Diagrams. Epidemiology 2011;22:745. doi:10.1097/EDE.0b013e318225c2be.  [22]   Wagner CL, Greer F R, and the Section on Breastfeeding and Committee on Nutrition.  Prevention of Rickets and Vitamin D Deficiency in Infants, Children, and Adolescents.  PEDIATRICS 2008;122:1142 ‚Äì 52. doi:10.1542/peds.2008 - 1862.  [23]   Holick MF, Binkley NC, Bischoff - Ferrari HA,   Gordon CM, Hanley DA, Heaney RP,  et al. Evaluation, Treatment, and Prevention of Vitamin D Deficiency: an Endocrine Society  Clinical Practice Guideline. J Clin Endocrinol Metab 2011;96:1911 ‚Äì 30. doi:10.1210/jc.2011 -  0385.  [24]   Marshall I, Mehta R, Ayers C, D humal S, Petrova A. Prevalence and risk factors for  vitamin D insufficiency and deficiency at birth and associated outcome. BMC Pediatr  2016;16. doi:10.1186/s12887 - 016 - 0741 - 4.  [25]   Ceccaldi P - F, Pejoan H, Breau N, Diallo D, Ducarme G, Poujade O, et al. Fre nch  prenatal Vitamin D recommended supplementation: Enough or not? J Gynecol Obstet Hum  Reprod 2017;46:35 ‚Äì 41. doi:10.1016/j.jgyn.2016.02.009.  [26]   Paruthi S, Brooks LJ, D‚ÄôAmbrosio C, Hall WA, Kotagal S, Lloyd RM, et al.  Recommended Amount of Sleep for Pedi atric Populations: A Consensus Statement of the  American   Academy   of   Sleep   Medicine.   J   Clin   Sleep   Med   2016;12:785 ‚Äì 6.  doi:10.5664/jcsm.5866.  [27]   Kim JH, Chang JH, Kim DY, Kang JW. Association Between Self - Reported Sleep  Duration   and   Serum   Vitamin   D   Level   in   Elderly   Korean   Adults.   J   Am   Geriatr   Soc  2014;62:2327 ‚Äì 32. doi:10.1111/jgs.13148.  [28]   Piovezan RD, Hirotsu C, Feres MC, Cintra FD, Andersen ML, Tufik S, et al.  Obstructive sleep apnea and objective short sleep duration are independently associated with  the   risk   of   serum   vitamin   D   deficiency.   PLOS   ONE   2017;12:e0180901.  doi:10.1371/journal.pone.0180901.  [29]   Bertisch SM, Sillau S, de Boer IH, Szklo M, Redline S. 25 - Hydroxyvitamin D  Concentration and Sleep Duration and Continuity: Multi - Ethnic Study of Atheros clerosis.  Sleep 2014.  [30]   Mizoguchi A, Eguchi N, Kimura K, Kiyohara Y, Qu W - M, Huang Z - L, et al.  Dominant localization of prostaglandin D receptors on arachnoid trabecular cells in mouse  basal forebrain and their involvement in the regulation of non - rapid   eye movement sleep. Proc  Natl Acad Sci 2001;98:11674 ‚Äì 11679.  [31]   Eyles DW, Burne THJ, McGrath JJ. Vitamin D, effects on brain development, adult  brain function and the links between low levels of vitamin D and neuropsychiatric disease.  Front Neuroendocrin ol 2013;34:47 ‚Äì 64. doi:10.1016/j.yfrne.2012.07.001.  [32]   Musiol IM, Stumpf WE, Bidmon H - J, Heiss C, Mayerhofer A, Bartke A. Vitamin d  nuclear binding to neurons of the septal, substriatal and amygdaloid area in the siberian  hamster   (Phodopus   sungorus)   brain .   Neuroscience   1992;48:841 ‚Äì 8.   doi:10.1016/0306 -  4522(92)90272 - 4.\n\n[33]   Stumpf WE, Bidmon HJ, Li L, Pilgrim C, Bartke A, Mayerhofer A, et al. Nuclear  receptor sites for vitamin D - soltriol in midbrain and hindbrain of Siberian hamster (Phodopus  sungorus) asses sed by autoradiography. Histochemistry 1992;98:155 ‚Äì 64.  [34]   Stumpf WE, O‚ÄôBrien LP. 1,25 (OH)2 vitamin D3 sites of action in the brain. An  autoradiographic study. Histochemistry 1987;87:393 ‚Äì 406.  [35]   Gominak SC, Stumpf WE. The world epidemic of sleep disord ers is linked to vitamin  D deficiency. Med Hypotheses 2012;79:132 ‚Äì 5. doi:10.1016/j.mehy.2012.03.031.  [36]   Eyles DW, Smith S, Kinobe R, Hewison M, McGrath JJ. Distribution of the Vitamin  D   receptor   and   1 Œ± - hydroxylase   in   human   brain.   J   Chem   Neuroanat   2005 ;29:21 ‚Äì 30.  doi:10.1016/j.jchemneu.2004.08.006.  [37]   Garcion E, Wion - Barbot N, Montero - Menei CN, Berger F, Wion D. New clues about  vitamin D functions in the nervous system. Trends Endocrinol Metab 2002;13:100 ‚Äì 105.  [38]   Saper CB, Scammell TE, Lu J. Hypothal amic regulation of sleep and circadian  rhythms. Nature 2005;437:1257.  [39]   Huang W, Shah S, Long Q, Crankshaw AK, Tangpricha V. Improvement of pain,  sleep, and quality of life in chronic pain patients with vitamin D supplementation. Clin J Pain  2013;29:341 ‚Äì 7. doi:10.1097/AJP.0b013e318255655d.  [40]   Zasimovich A, Fija ≈Ç kowska A, Che ≈Ç chowska M, Maciejewski T. Maternal serum  vitamin D and parathormone concentrations during gestation and in umbilical cord blood   ‚Äì  pilot study. J Matern Fetal Neonatal Med 2017:1 ‚Äì 9.   doi:10.1080/14767058.2016.1277705.  [41]   Plancoulaine S, Reynaud E, Forhan A, Lioret S, Heude B, Charles MA. Night sleep  duration trajectories and associated factors among preschool children from the EDEN cohort.  Press n.d. doi:10.1016/j.sleep.2018.03.030.\n\nTable 1 . Description of the studied population (N=264) from the EDEN   mother - child   cohort   by night - sleep duration trajectories .  Total   SS (N=14, 5%)  MLS (N=121,  46%)  MHS (N=98,  37%)   CS (N=20, 8%)   LS (N=11, 4%)  n (%) or mean  ( SD )  n (%) or mean  ( SD )  n (%) or mean  ( SD )  n (%) or mean  ( SD )  n (%) or mean  ( SD )  n (%) or mean  ( SD )  p -  value  Maternal  characteristics  Recruitment center  (Poitiers)   122 (46%)   5 (36%)   52 (43%)   49 (50%)   7 (35%)   9 (82%)   0.08  Family   income  ( ‚Ç¨ /month)   0.82  <1500   22 (8%)   1 (7%)   10 (8%)   8 (8%)   3 (15%)   0 (0%)  [1500 - 3000]   157 (60%)   10 (72%)   74 (61%)   54 (55%)   13 (65%)   6 (55%)  >3000   85 (32%)   3 (21%)   37 (31%)   36 (37%)   4 (20%)   5 (45%)  Maternal education level   0.41  <High school   50 (19%)   4 (28%)   20   (17%)   19 (19%)   6 (30%)   1 (9%)  High school   to   2 - year  university   degree   106 (40%)   5 (36%)   52 (43%)   35 (36%)   6 (30%)   8 (73%)  >2 year university  degree   108 (41%)   5 (36%)   49 (40%)   44 (45%)   8 (40%)   2 (18%)  Maternal age at delivery  (years)   30 (5)   30 (5)   30   (4)   31 (5)   30 (5)   30 (4)   0.87  Pre - pregnancy BMI   23 (4)   23 (3)   23 (4)   23 (4)   22 (6)   24 (5)   0.93  Child characteristics  Sex   ( b oy)   156 (60%)   12 (86%)   78 (64%)   53 (54%)   8 (40%)   5 (45%)   0.05  Birth season   0.89  Spring   113 (43%)   5 (36%)   50 (41%)   46 (47%)   8 (40%)   4 (37%)  Summer   65 (25%)   1 (7%)   34 (28%)   23 (24%)   4 (20%)   3 (27%)  Autumn   53 (20%)   5 (36%)   22 (18%)   18 (18%)   5 (25%)   3 (27%)  Winter   33 (12%)   3 (21%)   15 (13%)   11 (11%)   3 (15%)   1 (9%)\n\nCord - b lood 25OHD  level   (ng/ml)   19 (11)   12   (7)   20 (11)   19 (10)   16 (8)   14 (7)   0.02  <10   59 (23%)   6 (43%)   23 (19%)   22 (23%)   6 (30%)   2 (18%)  10 - 20   98 (37%)   6 (43%)   39 (32%)   39 (40%)   7 (35%)   7 (64%)  21 - 29   64 (24%)   2 (14%)   33 (27%)   21 (21%)   6 (30%)   2 (18%)  ‚â• 30   43 (16%)   0 (0%)   26 (22%)   16 (16%)   1   (5%)   0 (0%)  * SS =   s hort   s leep (<10 h 30/night), MLS =   medium - low sleep   (10 h 30 - 11 h 00/night), MHS =   medium - high sleep   ( about   11 h 30/night), CS =  c hanging   s leep (i.e. ,   LS then MLS) and LS=   l ong   s leep ( ‚â• 11 h 30/night).\n\nFigure 1.   Night - sleep duration trajectories   for   EDEN preschool children (N=1205). Full lines  represent mean sleep duration trajectories. Black circles =   s hort sleep (SS, 4.9% of the  children): triangles =   m edium - l ow sleep (MLS, 47.8% of the children); diamonds =   m edium -  h i gh sleep (MHS, 37.2% of the children), squares =   c hanging   sleep   (CS, 5.6% of the children)  and white circles =   l ong sleep (LS, 4.5% of the children). Dashed lines represent the 95%  confidence intervals   for   the trajectory estimations. Figure from Plancoulai ne et al.   [41] .  9  9,5  10  10,5  11  11,5  12  12,5  13  2   2,5   3   3,5   4   4,5   5   5,5  Night sleep duration (hours)  Age (years)\n\nFigure 2.   Unadjusted (in grey) and a djusted   (in black)   odds ratio s   for 1 - ng/ml decrease   in  25OHD   level by   sleep duration trajectories.   SS =   short sleep (<10h30/night), MLS = medium -  low sleep (10h30 - 11h00/night), MHS = medium - high sleep (about 11h30/night), CS =  changing sleep (i.e., LS then MLS) and LS= long sleep ( ‚â• 11h30/night).   MHS is the reference  trajectory.  0,9   1   1,1   1,2   1,3  LS  CS  MHS (ref)  MLS  SS  Odds ratios and 95% confidence intervals  Night sleep duration trajectories",
    "S leep and its relation to cognition and behavior in preschool - aged children   of the general  population : a systematic review  Short title :   Sleep, cognition and behavior in   preschoolers  Authors : Eve Reynaud 1 ,2,3 , Marie - Fran√ßoise Vecchierini MD, PhD 4 ,   Barbara Heude PhD 1 ,2 , Marie - Aline  Charles MD, PhD 1 ,2 , Sabine Plancoulaine MD, PhD 1 ,2  Affiliations :   1   INSERM, UMR1153, Epidemiology and Statistics Sorbonne Paris Cit√© Research Center  (CRESS), early ORigins of Child Health And Development Team (ORCHAD), Villejuif, F - 94807 France;  2   Paris - Descartes University, Paris, France;  3   Ecole des Hautes Etudes en S ant√© Publique (EHESP), Rennes, F - 35043 France  4   H√¥pital H√¥tel Dieu, Centre du Sommeil et de la Vigilance, AP - HP, Paris, France; Sorbonne Paris Cit√©,  EA 7320 VIFASOM, Universit√© Paris Descartes, Paris, France.  Address correspondence to : Sabine Plancoulaine , INSERM U1153, Team 6 ORCHAD, 16 Avenue Paul  Vaillant Couturier, 94807 Villejuif Cedex, France, [sabine.plancoulaine@inserm.fr], + 33 145 - 595 - 109  Conflict of interest :   There are no financial or non - financial conflict s   of interes t.   This research did not  receive any specific grant from funding agencies in the public, commercial, or not - for - profit sectors  Author   contributorship :   Eve   Reynaud   and   Sabine   Plancoulaine   developed   the   search   strategy   and  conducted   the   selection   of   articles ,   data   extraction   and   reporting.   Eve   Reynaud   drafted   the   initial  manuscript under the supervision of Sabine Plancoulaine . Marie - Fran√ßoise Vecchierini contributed to the  search strategy, and gave guidance for the summary o f the data.   Barbara Heude and Marie - Aline Charles  gave guidance   on child development and systematic review methodology . All authors have reviewed   the  draft versions of the   manuscript   and approved the final   version   as submitted .\n\nAbstract  Background:   While   the relations between sleep, cognition and behavior have been extensively studied in  adolescents and school - aged children, very little attention has been given to preschoolers.  Objective:   In this   systematic review,   o ur   aim   was   to   survey   articles that address   the link between sleep  and both cognition and behavior in preschoolers (24   to   72   months   old).  Methods:   Four electronic databases were searched, namely Medline, Web of Science, PsycINFO and  ERIC, completed by forward and backward cit ation search.  Results:   Among the 1 590   articles identified   ( minus   duplicates) , 2 6   met the inclusion criteria.   Globally,  studies with the largest sample sizes   (N=13)   found that   a   greater   quantity or quality of sleep was  associated with better behavioral and   cognitive outcomes , while   the   others were   less   consistent .  Conclusion:   Although the   current   literature seems to indicate that sleep is related to behavioral and  cognitive development as early as preschool years,   the   strength   of the associations (i.e.   effect sizes )   w as  relatively small .   In addition to   taking stock of the   available data, this systematic review   identifies   potential  sources of improvement   for future research .  Abbreviations  BT Bedtime, CBCL Child Behavior Checklist, NSD Night Sleep   Duration, NA Non - available, NS Non -  significant, NW Night - waking, PBQ Preschool Behavior Questionnaire, PKBS   Preschool and Kindergarten  Behaviors Scale , SDQ Strength and Difficulty Questionnaire, SE Sleep efficiency, SOL sleep onset latency,  SP sleep proble ms, SD total sleep duration, WT wake up time\n\nS ummary  This is the first systematic review   of the literature on   sleep and its relation to cognition and behavior in  preschool - aged children.   In comparison with the literature   focused   on school - aged children,   knowledge  involving   preschoolers is rather sparse. A total of 26 studies were included   in this review , which revealed  a high degree of   heterogeneity regarding the type and means of measur ing   sleep variables and  behavioral and cognitive   variables , as well as the statistical methods employed.   Amongst   the 13 articles  with   the largest   sample size s   ( top   50% of the included studies,   12   different   populations ) , 12 found that a  higher quantity or quality of sleep was associated with better behavioral and/ or cognitive outcomes.  Results point to an association between sleep, behavior and cognition as early as preschool years , but  the strengths of associations reported in the articles were relatively small .   S tudies with a smaller sample  size were less   concordant . It is consistent with our findings that the strengths of association are small,  and thus require   large sample size s   to ensure   statistical detection power . D ifferent   aspects of sleep   were  not   associated with   all cognitive or behavioral features   in the same way ,   which   underscores   the need for  specific   measures   rather than   general   ones   such as ‚Äúsleep problems‚Äù or ‚Äúbehavior problems‚Äù   to   be able to  decipher   the   relationships .   There is   also   a need for large longitudinal studies using   objective measures  and   accounting for   confounding factors.   The child‚Äôs genotype has recently been shown to have a  moderating role in the association between sleep and behavior,   and should be further explored .  Keywords  Sleep, preschool, cognition,   behavior, systematic review\n\nI NTRODUCTION  Debate continues over the precise function of sleep ,   especially with regard to   its   role   in   cogn itive and  behavioral capacities   (Stickgold and   Walker, 2005; Vertes and Siegel, 2005) .   In the literature, s everal  hypotheses   explain   how sleep   might be   related to cognition and behavior. The ‚Äúvigilance hypothesis‚Äù, as  described by Vriend et al .   ( 2015) ,   is perhaps   the most instinctive one.   It postulates that sleepiness is an  intermediate lin k .   A lack of sleep   induces   sleepiness   ‚Äì   as shown in experimental studies on adolescents  and school - aged children   (Carskadon et al., 1981; Fallone et al., 2001)   ‚Äì   which in turn has been  associated with   conduct problems ,   reduce d   attention, processing spee d   and   working memory   (Calhoun et  al., 2012) .   This hypothesis proposes   that   sleep plays a passive role , while other s   suggest   an active role  such as ‚Äúsleep - dependent memory consolidation‚Äù ,   ‚Äúsynaptic homeostasis‚Äù   and ‚Äúamygdala medial -  prefrontal cortex connectivity‚Äù .   The   mechanism   by   which   newly acquir ed knowledge become s   long - lasting  memories , called   ‚Äú memory consolidation ‚Äù ,   is one of the cognitive   processes   for which the link to sleep has  been the most studied   (Stickgold, 2005) .   Memories   are transferred from the hippocampal regi on to the  neo - cortex   through local synaptic consolidation processes and systems - level reorganization . There is  increasing evidence that this process is sleep - dependent   (Marshall et al., 2006) .   In parallel, the ‚Äúsynaptic  homeostasis‚Äù hypothesis stipulate s that to compensate   for   the persistent strengthening of synapses  occurring during daytime activit y,   a synaptic downscaling takes place   during   slow wave   sleep   activity ,  allowing   for   better neuroplasticity   (Tononi and Cirelli, 2006) .   The   lack of synaptic plasticity ,   induced by  inadequate sleep,   could   impair memory   (Tononi and Cirelli, 2014) ,   and   play a role in depression   (Liu et  al., 2017)   and maladaptive behavior   (Kolb and Gibb, 2014) .   Another hypothesis is that sleep alters  connectivity between the amygdala and   the   medial - prefrontal cortex, as observed in an experimental  study conducted by Yoo et al .   (2007) . Since those structure s   seem to play an important rol e in the  regulation of emotions   (Phelps and LeDoux, 2005)   and behavior   (Amat et al., 2005) ,   a lack of sleep could  have a negative impact on these functions .  T he relation between sleep,   cognition and /or   behavior has been extensively studied in adolescents and  school - aged children   (Astill et al., 2012; Vriend et al., 2015) .   According to   the   Astill et al ‚Äôs   meta - analysis  (2012) ,   sleep duration   in sc hool - aged children   i s   positively   associated with   executive functioning   and\n\nmultiple - domain cognitive function ,   and   negatively associated with   internalizing and externalizing  behavior .   No associations were   found   with   sustained attention and memory .   However,   there has been  little focus on   preschoolers.   This constitutes   a gap in our knowledge ,   as sleep research on older children  cannot be   inferred to apply   to preschoolers for numerous reasons. Sleep physiology, sleep need and  sleep maturation   evolve very rapid ly in the first years of life, simultaneously to brain maturation   (Louis et  al., 1997; Olini and Huber, 2014) .   Additionally, the   causes of   insufficient quantity or quality of sleep can  be quite different according to the child‚Äôs age, and may   give rise to   distinct symptoms.   W hile the brain and  the circadian rhythm are still in maturation, inadequate sleep   may   disturb   a   child ‚Äôs   development and thus  be more likely to   have   long - term effect s   than when sleep disturbance occurs in   adults, and different  windows of   exposure throughout childhood could lead to diverse consequences.  A   systematic   review   of the literature   on nap sleep among preschoolers   was   recently published   (Thorpe et  al., 2015) ,   showing inconsistent results . Authors report this   may be   due to   variation in age and   in   habitual  napping status of the samples .   I n this article, we aim to   survey   all available publications   focusing on   the  link between sleep ,   cognition and /or   behavior in preschoolers , excluding studies focusing exclusively on  naps .   This systematic review   includes   studies   published in English,   conducted on children   of   the general  pop ulation   (non - clinical sample) .  M ETHODS  The   Cochrane handbook   (Higgins and Green, 2008)   and t he   Preferred Reporting Items for Systematic  Reviews and Meta - analyses   statement   (Moher et al., 2009)   (PRISMA guidelines)   were   followed to  ensure ,   respectively ,   optimal methodology and optimal reporting   (Supplementary data 1) . This review   has  been   declared in the PROSPERO database (number CRD42015029647).  Eligibility   criteria  To be eligible, articles had to conform to   a number of   criteria. The exposure variable had to be a measure  of   night or   total   sleep   duration ,   of   difficulty initiat ing   or maintaining sleep ,   or   of   sleep timing. The outcome  variable needed to be a measure of cognition or behavior.   T he study population   had to   be   a sample of the\n\ngeneral population   (not a clinical sample) , with no selection according to the cognitive or behavioral status  of the child or   according to his or her sleep. The average age of the population had to be   at least 2 and  less than   6   y ears   when the sleep and cognition measures were made. Moreover, only published original  articles (no conference abstract s , review s   or   case report s ) wri tten in English were eligible.  Information source and search strategy  The search strategy was   implemented   in two main steps. The first one consisted in a wide - ranging  search of   four   electronic databases ,   namely Medline, Web of Science, PsycINFO and ERIC   up to   April  30,   2016 . To ensure maximum sensitivity, no terms were used to exclude clinical studies, so that potential  control groups could be included in our review. For all   the   databases ,   a search by title and abstract  included the following words and their synonyms ( t he   exact   phrases are available in the supplementary  data   2 ):   Sleep, Insomnia, night - waking,   child, preschoolers, cognition, learning, teacher rating,  performance, intelligenc e, IQ, memory, attention deficit, sustained attention, behavior,   conduct,  internalizing, externalizing.   For the Medline database, in addition to the title and abstract search, a  second phrase was created to use Medical Subject Headings terms (hierarchicall y organized keywords  also called MeSH terms):   Sleep, sleep disorders, child, preschool, child behavior, social behavior,  behavioral symptoms, affect, temperament, intelligence, internal - external control, achievement, child  behavior disorders, memory, verba l learning, cognition, psychomotor, performance.  In the second step, we   conducted   backward and forward citation search es   for all the articl es   retained  after   the   initial screening of the title and abstract. Backward citation searching consists in identifyin g  additional articles by reviewing the reference list of the selected articles, while forward citation searching  consists in reviewing articles that cite the selected article. For the lat t er,   we used   the forward citation  searching tools of both ‚ÄúPubMed‚Äù and ‚ÄúWeb of Science‚Äù.  Article selection  Two investigators selected the articles in two steps, and were blind to each other‚Äôs selection th rough out  the whole process. The first   selection was based on a   screening process of   the title and abstract and the  second   one   was made   after reading the full text.\n\nData extraction   and reporting  The data extracted from the articles were the age of the child (average and range) at each measure, the  recruitment date,   the   gender   ratio, the sleep measure (the exposure variable), the cognitive and  behavioral measures (the outcomes), the measurement tool used and by whom, the control variables  included in the final model, the strength of the association (beta, correlation, odds - ratio , mean difference)  and finally the significance of the association assessed by p - value. Data   w ere   extracted from the articles  by the two investigators   separately , and   only concern ed   the analyses of interest for this review, i.e.  sample size, study design,   and control for confounding factors. Therefore,   descriptions   do not necessarily  reflect the entire original article. The same remark applies to the risk of bias in assessment. If the article  presented cross - sectional and longitudinal analyses, only the lon gitudinal ones were included. Similarly, if  both unadjusted and multivariable analyses were available, the latter were reported. The child behavior  checklist‚Äôs total problems scale   (Achenbach, 1991) ,   but not its subscales, contains several questions  regarding sleep difficulties.   Thus,   analyses using the total problems scale of the child behavior checklist  were not reported.  Risk of bias  We assessed the risk of bias in each article using a   5 - criteria   scale,   derived from the   Newcastle Ottawa  Quality Assessment Scale for Cohort studies   (Wells et al., 2003) .   The first two criteria take into  consideration classification bias, the t hird confounding bias, the fourth the lack of temporality and the fifth  statistical detection power.   Each of th e se elements accounted for a point on the risk of bias scale 1)   t he  exposure (sleep variable) was not measured objectively; 2)   t he outcome   (behavior or cognition)   was  assessed by someone who was   not   blin d   to the sleep status; 3)   there were no statistical adjustment s   to  take into account   the   main confounding factors (household income or parental education, child‚Äôs sex, and  child‚Äôs age if age r ange > 6 months); 4) the study had a cross - sectional   design   (i.e. sleep was assessed  at the same time as the outcome); 5) The sample size was   less than   500 children.   The maximum score of  5 indicates a higher risk of bias. The purpose of the scale is solel y to give a general indication to readers  o f   the   level of   confidence that can be given to the results .   N o article s   were excluded based on this scale.\n\nA same article may obtain a risk of bias   range   instead of a single   score   if it uses   multiple   methods. For  example, in   the   same article ,   some cognitive measures might be assessed by a professional using a  validated tool, while others might be   assessed   based on   parent s‚Äô   perception .  Data synthesis  A systematic qualitative synthesis was performed. No   reliable   quantitative synthesis   could be produced  due to a great diversity of sleep, cognition and /or   behavior measures, and   to   great variety   in the data  analysis methods, within a relatively low number of articles .\n\nRESULTS  Selection and description of the   studies included  The flow chart in Figure 1 summarizes the selection procedure , in accordance with the   PRISMA  guidelines   (Moher et al., 2009) .   Out of the   1590   articles initially   identified ( minus   duplicates),   1511   were  excluded for not meeting inclusion criteria after title and abstract screening, and 53 were excluded after  full text screening.   We performed forward and backward citation search es   on the articles   that were  selected for   the full text assessment, which resulted in the inclusion of   seven   new articles.   In total , 2 6  articles were included and are described in Table 1.  Out of the 2 6   selected articles,   all reported observational studies. M ore than   half   were based on   data  collected in   North American children ( nine   in the USA,   six   in Canada). The countr ies   of origin of the  children in the remaining articles   were   Australia (four), Europe (five   in   total, one   in each of the following:  Switzerland, Italy, Neth erland s , G ermany and Finland) and Japan (two ).  As described in Figure 2, 1 4   articles   ( 54 %)   had an estimated risk of bias of   4   or more out of 5.   Eighteen  ( 69 %) articles reported a   cross - sectional   analysis, 1 3   (50%) had a population size   below   500   and   23  ( 88 %) used   su bjective measures of sleep. Regarding the outcome,   1 4   articles   (5 4 %) used measures  assessed by someone   who was   not   blind   to   the   child   sleep status   and three   had a combination of blind  and non - blind assessors.   Twenty - one   articles   ( 73 %)   did not   meet   minimum   adjustment   criteria   (namely  any socio - economic factor s , child‚Äôs sex, and child‚Äôs age if age range > 6 months).  Figure 3 shows the number of article s   per exposure and per outcome.   In total, 24   different questionnaires  for sleep, behavior and cognition were used, and are reported in supp lementary   data   3 .   Regarding  exposure,   over half of the   articles focused on the child‚Äôs sleep duration , 13 for night sleep duration (NSD)  and   six   for total sleep   duration (TSD) .   A few   examined   indicators of   difficulty initiating and maintaining  sleep such as night - waking   (NW)   (n= 8 ) , sleep onset latency   (SOL)   (n=5) , sleep efficiency   (SE)   (n=2)   and  insomnia   (I)   (n=1) .   S leep problem s (SP)   (n=6)   were studied with   varying definitions .   In even fewer cases,  bedtime   (BT)   (n=3) and   wake - up time   (WT)   (n=1)   were also   investigated . Regarding the outcome,   23   of\n\nthe publications   raised the question of an   association between sleep and behavior. Cognition was less  frequently   studied   ( n=7)   with   a notable focus on lan guage   skills   ( five out of seven   articles).  Sleep and behavior  A summary of the association s   found between sleep and behavior is presented in Table 2.  Sleep and externalizing behavior  Aggressiveness and   conduct problems  Aggressive behavior has been found to be positively associated with insomnia   (Armstrong et al., 2014) ,  sleep problems   (Hall et al., 2007; Hatzinger et al., 2010)   and bedtime   (Komada et al., 2011) .   R esults  showing   night sleep duration were divergent, and no associations were found with sleep onset latency  (Hatzinger et al., 20 10)   nor sleep efficiency   (Hatzinger et al., 2010) .   More specifically ,   i n   the   Armstrong et  al .   study   (2014)   of   396 children aged 54 months ,   those   with insomnia had a higher mean score on the  hostile - aggressive scale of the P reschool   B ehavior   Q uestionnaire (PBQ)   (0.81¬± 0.26). Hall et al .   (2007)  found that sleep problems at age 3 accounted for 5.1% of the variance on the C hild   B ehavior   C heck   L ist  (CBCL)   scale of aggressive behavior at age 4   (n= 1317 ) . The   correlation between aggressive behavior  (measured by CBCL) and bedtime on week day s   was r=0.11   (p<0.01)   at age s 2 to 3 and 4 to 5   in   the  Komada et al. study   (2011) .   Furthermore ,   Komada et al.   (2011)   showed that   shorter   night   sleep duration  was associated with more aggressive   behavior in   children between the age of 24 to   36 months (N=905),  but not for those between the ages of 48 to 60 months (N=841).   Hatzinger et al .   (2010)   also found a lack  of association in 84 children aged 59 months .   These results seem to indicate that shorter night sleep  duration is associated with more aggressive behavior in younger children only. However Scharf   et al .  (2013)   did find a positive association in their sample of 8950 children aged 48 months.   Children who slept  less than 9.44 hours   per night   had an increased risk of being frequently aggressive (measured by  P reschool and Kindergart en Behaviors Scale or P KBS) with an OR of 1.81 CI 95% [1.36 - 2.41].   Thus,   we  could not determine whether the inconsistencies in   the   results were due to difference s   in sample size or  in sample age .\n\nThere were disparities in the results on conduct problems .   These   might be   caused by differences in  sample size and thus detection power.   Wada et al .   (2013)   and Hatzinger et al .   (2010)   found in 431 and 84  children ,   respectively, that none of   the   studied sleep exposures   -   namely night and t otal sleep duration,  sleep onset latency, night - waking sleep efficiency, sleep problems, bedtime and wake - up time   -   were  associated with conduct problems. In studies with larger sample size, children who had more night -  waking   (Hiscock et al., 2007; Lehmkuhl et al., 2008) ,   longer sleep onset latency   (Hiscock et al., 2007;  Lehmkuhl et al., 2008) ,   and more sleep problems   (Hiscock et al., 2007; Quach et al., 2012) ,   had   a   higher  risk of conduct problems.  More specifically, i n   the   Hiscock et al. study   (2007)   of   4983   children aged   57 months ,   those   who woke at  night   or   had difficulty getting to sleep 4 nights per week or more, had   a higher   score   on the SDQ conduct  problem scale   of 0.6   CI 95%   [ 0.5 - 0.8 ]   and 1.0   point s   CI   95%   [ 0.8 - 1.2 ] ,   respectively. Compared to   the  children   with no sleep problems, those with a moderate to severe sleep problem, as declared by parents,  had   a mean difference of   1.1   point s   CI 95%   [ 0.9 - 1.3 ]   on that same scale.   Although   the   definition of sleep  problems was different   in   Quach et al.   (2012) ,   they   found   very similar results   in   1512   children aged   68  months ,   with a mean difference   in   the   conduct problems score   of   1.0   point s   CI 95%   [ 0.7 - 1.2 ]   between no  sleep problems and moderate to severe sleep problems.   We note that   the only study using objective  measure s   of sleep found no significant association   (Hatzinger et al., 2010) .  Attention and hyperactivity problems  Some sleep parameters , such as later bedtime   (Komada et al., 2011) ,   and global sleep problems  (O‚ÄôCallaghan et al., 2010) ,   were positively associated with attention problems .   Regarding the strength of  these   associations,   the correlation between   the   c oncurrent   score of   attention problems   (measure d   by the  CBCL)   and bedtime   was   r=0.10   ( p<0.01 )   in   Komada et al .   study   (2011) .   Children   who had s leep problems  occurring ‚Äúoften ‚Äù   between the age of 2 and 4 years   had increased risk of   persistent   attention problems  ( above the 90 th   percentile on the CBCL attention scale   at age 5 and 14) with an adjusted OR of 3.84   CI  95%   [2.23 - 6.64] for boys, and 4.42   CI 95%   [2.27 - 8.63] for girls in   t he   O‚ÄôCallaghan et al .   study   (2010) .   No  link s   were found with night - waking   (Hall et al., 2012) ,   sleep onset latency   (Vaughn et al., 2015) ,   sleep  efficiency   (Hatzinger et al., 2010)   nor wake - up time variability   (Vaughn et al., 2015) .   Regarding night\n\nsleep duration, Paavonen et al .   (2009)   described a positive association when attention pr oblems were  assessed   by parents, but not when   assessed   by teachers.   These results could be indicative of a potential  bias when the person reporting the behavioral measure is not blind to the sleep status, although   the  authors   also   point out other plausible   explanations for the discrepancy . For instance, the teacher  response rate was   low , and not missing at random   since it   was lower   for children with   greater   behavioral  difficulties according to parents.   Four other studies   (Komada et al., 2011; Lam et al., 2011; Touchette et  al., 2007; Vaughn et al., 2015)   reported a lack of association regardless of who evaluated the   child‚Äôs  attention.  D issimilarities   in results   were observed   for every studied   association between a sleep factor and  hyperactivity problems.  Sleep and internalizing behavior  Anxious, depressed  In   the   Jansen et al. study   (2011)   of   4782   c hildren   aged   24 months , those   who   slept less than 12.5 hours  per day at age 2 years ,   compared to those who slept more   than 13.5 hours ,   had   an increased risk   of  anxiety or depressive symptoms at age 3 (defined as being above the 80 th   percentile on the CBCL  anxious/depressed symp toms scale) with an adjusted OR of   1.47   CI 95%   [1.20 - 1.79]. Results were  similar when looking at the child‚Äôs night - waking, with an adjusted OR of 1.32   CI 95%   [1.14 - 1.54]   for  children who woke   once or twice   per night on average compare d to those who never woke.   Similarly,  Zaidman et al.   (2015)   found   in   1487   children aged   29 months   that   those   who woke 20 minutes or more  per night ,   compared to those who did not wake ,   had higher anxiety and depression on an adapted s cale  of the PBQ .   In Komada et al.   (2011) ,   the correlation between the CBCL anxious/depressed symptoms  scale   and bed time   was r=0.09   ( p<0.01 ) .   The associations were not significant when studying night   sleep  duration   (Komada et al., 2011)   and inso mnia   (Armstrong et al., 2014) .  Emotional   symptoms  Studies   with   the   lowest sample sizes   reported non - significant results   for   all sleep measu res, namely night  sleep duration   (Hatzinger et al., 2010; Wada et al., 2013) ,   total sleep duration   (Wada et al., 2013) ,   night -\n\nwakin g   (Hall et al., 2012; Hatzinger et al., 2010; Wada et al., 2013) , sleep onset latency   (Hatzinger et al.,  2010; Wada et al., 2013) ,   sleep problems   (Hatzinger et al., 2010) ,   bedtime   (Wada et al., 2013)   and sleep  efficiency   (Hatzinger et al., 2010)   in children aged around 60 months .   In contrast , those with larger  sample sizes reported significant results   for   all reported measures . N ight - waking   (Hiscock et al., 2007;  Lehmkuhl et al., 2008) ,   sleep onset latency   (Hiscock et al., 2007; Lehmkuh l et al., 2008)   and sleep  problem s   (Hiscock et al., 2007; Quach et al., 2012)   were positively and s ignificantly associated with  emotional problems   in children aged between   57   and   68   months . Although the sample size might not be  the sole factor explain ing   the differences in results, it seems that lack of statistical power was common in  this matter. Other   internalizing behaviors were seldom investigated , thereby   limiting a comprehensive  synthesis.  Sleep, s ocial behavior and peer relation s  Children with shorter night   sleep   (Vaughn et al., 2015; Wada et al., 2013 )   or who   globally   had more sleep  problems   (Hiscock et al., 2007;   Quach et al., 2012) ,   were reported   as   show ing   less prosocial behavior.  However, no significant association was found ,   either with total sleep duration, bedtime   n or sleep  efficiency. Lehmkuhl et al .   (2008)   surprisingly   found   among 1388 children aged 66 months   that children  w ith longer sleep onset latency   displayed   more prosocial behavior (N=1338) where Hiscock et al.   (2007)  found the opposite in 4983   children. The main difference in method in the two articles was that   Lehmkuhl  et al.   (2008)   reported simple bivariate analyses while Hiscock et al.   (2007)   adjusted for age, gender and  household income. Two other articles with   smaller   sample sizes (in 62 and 437 children ,   respectively)  f ound no significant association   (Vaughn   et al., 2015; Wada et al., 2013) .   In each article, v ery similar  results were   observed   for the   outcome denoted by acceptance by peers .  Sleep and Cognition  E ven fewer   studies have investigated the link between   sleep and cognition   in preschoolers   (N=7) .   They  are presented in   T able 3.   Out of the four articles studying the   association between night sleep duration  and receptive vocabulary capacities , three found a positive association . In   the   L am et al.   (2011)   cross -  sectional   study   among   59   children aged   36   to   60 months ,   actigraphy - measured   night sleep was positively\n\ncorrelated with   a   better   score on the PPVT - IV   receptive vocabulary   scale   ( age adjusted   r=0.29, p=0.03 ) .  Also using actigraphy and the PPVT - IV   in a cross - sectional study , Vaughn et al.   (2015)   found   in   62  children aged   50 months   a correlation of r=0.45 (p<0.01) after adjusting for age, sex and ethnicity.   In their  longitudinal study   of   1492   children , Touchette et al .   (2007)   described four night - sleep patterns from age  2.5 to 6: 11 - hour persistent, 10 - hour persistent, short increasing, and short persistent.   Compared to  children who slept 11 - hour persistently,   those   who had short persistent duration were at hi gher risk   of a  low PPVT - measured receptive vocabulary score   (p=0.001), but no significant association   w as   found with  other   sleep patterns . Dionne et al.   (2011)   found   that   parental reports of   night sleep duration   at 30 months  was not associated with   concurrent   receptive vocabulary (assessed by the MCDI),   no r predictive of the   60  month s   receptive vocabulary (assessed by the PPVT)   in   1029   children .   Hiscock   et al.   (2007)   found   that  sleep problems were associated with literacy and numeracy but not with receptive vocabulary.   No  associations   were found between any cognitive outcome and total sleep duration, night - waking, sleep  onset latency or sleep efficiency.  D ISCUSSION  Amongst the 13 articles with the largest sample sizes   ( top   50% of the selected studies ,   12 different  population s ) , 12 found that   a higher quantity or quality of sleep was associated with better behavioral  and /or   cognitive outcomes .   Results point to an association between sleep, behavior and cognition as  early as in preschool years.   Studies with a smaller sample size   were less   con sistent . The strengths of  associations reported in the articles were relatively small, which explains the need for a large sample size  to find consistent results.   The studies were heterogeneous in many regards: the type and means of  measures   for the sleep variables differed but also the behavioral and cognitive   variables , as well as the  statistical methods employed.   Results differ ed   according to the   specific   exposure and outcome  considered , as well as the method employed, but too few studies w ere   performed   to fully understand  specific associations.  In comparison with the literature based on school - aged children, knowledge   involving   preschoolers is  rather sparse. Astill et al.   (2012)   conducted a systemati c review using similar selection criteria and   found\n\nover 80 studies   examining the association between sleep and cognition or behavior in children between  the age s   of 5 and 12.   According to their meta - analysis,   the association between   sleep duration   and bot h  cognition (r=0.08) and behavior (r=0.09)   in school - aged children was   small but significant.   Our findings  suggest th e se associations could be found as early as preschool - years.  Quality of included   s tudies  Unlike what   is seen   in the day - time sleep literature   (Thorpe et al., 2015) ,   no experimental studies   have  been   performed on preschoolers‚Äô night   sleep. Although they provide better strength of evidence than  observational studies,   experiments in very young children   raise ethical   concerns   and   problems of   parental  acceptance , which explains their absence .   Furthermore , experimental studies would not   ma ke it possible  to   observ e the   effect of   long - term   suboptimal sleep.  Most of the studies included   do not   use   objective   sleep measures ,   only   three   used actigraphy,   and none  used polysomnography , the gold standard in sleep measures .   Objective   measures   can be   expensive   to  record and to analyze especially   for   large r   sample s . It can also be   difficult to obtain   access to  polysomnographic equipment for research purposes ,   which   no doubt   further limit s   its   use.   Actigraphy is a  non - invasive   objective   method which is becoming more and more accessible,   we can thus expect   a great  increase in objective sleep measures   in future research.   However ,   some concerns have been raised  regarding the   validity   of this measure in preschool - aged children. When compared to polysomnography ,  correlation s   were   above   0.80 for sleep latency, sleep duration and sleep efficiency but   below   0.40 for the  number of awakening s   (B√©langer et al., 2013) .   Sitnick et al.   (2008)   suggest videotaping as a   more reliable  alternative.  Presumably for similar reasons, behavioral and cognitive data were often collected using questionnaires  completed   by the parents, who are not blind to   the   child ‚Äôs   sleep status. Evaluation by an external  investigator, ideally a   psychologist ,   limits   the risk of a bias in the outcome estimators.   Failure to consider  confounding   factors was a nother common risk of bias .   This   shortcoming   limits the interpretation of the  results   since it becomes impossible to determine   whether the associations found, or the lack of  associations, are   dependent   on   other factors.   T his risk of bias can be   easily   reduced   by statistical  adjustment,   if   data on co n founders   are   collected . Cross - sectional designs also make the interpretation of\n\nt he results quite difficult , as   they prevent   determin ing   whether the sleep   outcome   occurred before or after  the behavior or cognitive impairment. The chronology of events is especially important in this field of  research, as there are bidirectional associations between sleep, and both cognition and behavior  (Touchette et al., 2009) .  R eporting bias  The growing literature regarding publication bias and selective reporting bias suggests they are  widespread   (Dwan et al., 2008) . It is likely that they are even more   frequent   in reviews including  observational studies ,   since their registration is   not   required (unlike clinical trials).   Non - significant   results  that are   published are also less   frequently   cited in other publications, reducing the likelihood of being  identified.   Reporting   biases are complex to observe but we did find   dissimilarities   in several studies  between   the   measures used   in the analyses   and   those   apparently   available.   It is possible that a uthors  solely reported associations with significant results, omitting other measures .   One way to counter this  ubiquitous problem would be to plan   the study of   exposures and outcomes ahead of analyses .  The aim of   this review   is   to present available peer reviewed literature   ‚Äì   the gray literature was   therefore  not searched. While this allows a higher quality of included articles, it may reinforce the impact of  publication bias.  Variability in definitions   and means of measure  The variability in definitions of outcomes and exposure limits the present understanding of the  associations between sleep ,   behavior and cognition. For example, in the   s ix   articles studying ‚Äúsleep  problems‚Äù   (Hall et al., 2007; Hatzinger et al., 2010; Hiscock et al., 2007; O‚ÄôCallaghan et al., 2010; Quach  et al., 2012; Troxel et al., 20 13) ,   none had similar definitions. While most included a notion of difficulty  initiating or maintaining sleep, some also included sleep habits, some mixed dyssomnia and parasomnia  and others included only one simple question assessing parent s ‚Äô   perception of the child ‚Äôs   sleep.   T he  means to measure the outcome   also varied greatly ,   with 13 different tools used to assess behavior and  eight   for cognition (described in supp lementary   data   3 ).   The q uality and comparability could easily be  enhanced if th e studies focused on specific aspects of both exposure and outcome,   especially since one\n\ncannot assume that different   specific   sleep exposures are related to all cognitive or behavioral features in  the same way .  Future d i rections  This study highlights the   need to reduce publishing bias as well as bias within studies. For the   latter ,  recommendations are to explore the association between specific sleep, behavioral and cognitive  measures through longitudinal studies, to seek sufficie nt statistical power and use objective sleep  measures, as well as having the behavioral or cognitive outcome assessed by an investigator blind of the  sleep status, and report all available analyses. Reporting bias and confounding bias   ‚Äì   as well as vague  re sults arising from the study of nonspecific sleep, cognitive and/or behavioral measures   ‚Äì   can be easily  reduced if taken into account during the planning process. Reporting the children‚Äôs age precisely and  limiting the age range in a same analysis could al so improve interpretation.  It is of note that some recent studies have focused on less typical sleep aspects such as daily variations  (Spruyt et al., 2016)   and chronotype   (Doi et al., 2015) .   Others have explored sleep hygiene, such as  bedtime routine   (Mindell et al., 2015) ,   showing the importance of educating parents on the matter. Mindell  et al.   (1994)   found in their study that treatment of sleep disturbance improved day - time behavior. New  findings also report a differential role of sleep according to the child‚Äôs genotype   (Bouvette - Turcot et al.,  2015) .   Our present understandi ng in this field could be greatly improved by these innovative research  approaches.  A r ecent   systematic review   and meta - analysis   found   behavioral interventions   to be   efficient in reducing  sleep problems in children   (Meltzer   et al.,   2014) .   The interventions   for preschool - aged children included  sleep education, graduated extinction, structured bedtime routine and sleep programs. According to the ir  meta - analyses,   the standard mean deviation between the intervention and control group was   0.33 (0.48 ‚Äì  0.18), and th e mean night waking frequency in the intervention groups was 0.26 standard deviations  lower (0.35 ‚Äì 0.17).   It would be interesting to investigate if such interventions also improve cognition and  behavior\n\nCONCLUSION  In this systematic review, we took stock   of the available data on the question of   the association between  sleep, behavior and cognition in preschoolers,   and   suggested ways to improve   future research   on   the  subject .   T he current literature seems to indicate that sleep is related to behavioral and c ognitive  development as early as in preschool years.\n\nACKNOWLEDGEMENTS  We thank Dr Frank Ramus, who shared his expertise on child cognitive and behavioral development. We  also thank Pr Isabelle Boutron, co - convenor of the Bias Methods group of the Cochrane Collaboration, for  her guidance in the systematic review method.\n\nREFERENCES  Achenbach, T.M. Manual for Child Behavior Checklist 4 - 18. Univ Vermont/Dept Psychiatry , 1991.  Amat, J., Baratta, M.V., Paul, E., Bland, S.T., Watkins, L.R., Maier, S.F. Medial prefrontal cortex determines  how stressor controllability affects behavior and dorsal raphe nucleus. Nat. Neurosci., 2005, 8: 365 ‚Äì 371.  Armstrong, J.M., Ruttle, P.L., Klein,   M.H., Essex, M.J., Benca, R.M. Associations of child insomnia, sleep  movement, and their persistence with mental health symptoms in childhood and adolescence. Sleep,  2014, 37: 901 ‚Äì 909.  Astill, R.G., Van der Heijden, K.B., Van IJzendoorn, M.H., W, J. Slee p, cognition, and behavioral problems in  school - age children: A century of research meta - analyzed. Psychol. Bull., 2012, 138: 1109 ‚Äì 1138.  Bates, J.E., Viken, R.J., Alexander, D.B., Beyers, J., Stockton, L. Sleep and adjustment in preschool children:  sleep   diary reports by mothers relate to behavior reports by teachers. Child Dev., 2002, 73: 62 ‚Äì 74.  B√©langer, M. - √à., Bernier, A., Paquet, J., Simard, V., Carrier, J. Validating actigraphy as a measure of sleep for  preschool children. J. Clin. Sleep Med. JCSM Of f. Publ. Am. Acad. Sleep Med., 2013, 9: 701 ‚Äì 706.  Bouvette - Turcot, A. - A., Pluess, M., Bernier, A., et al.   Effects of Genotype and Sleep on Temperament.  Pediatrics, 2015, 136: e914 - 921.  Bruni, O., Lo Reto, F., Miano, S., Ottaviano, S. Daytime behavioral co rrelates of awakenings and bedtime  resistance in preschool children.   Suppl. Clin. Neurophysiol., 2000, 53: 358 ‚Äì 361.  Calhoun, S.L., Fernandez - Mendoza, J., Vgontzas, A.N., et al.   Learning, attention/hyperactivity, and conduct  problems as sequelae of excessi ve daytime sleepiness in a general population study of young children.  Sleep, 2012, 35: 627 ‚Äì 632.  Carskadon, M.A., Harvey, K., Dement, W.C. Sleep loss in young adolescents.   Sleep, 1981, 4: 299 ‚Äì 312.  Dionne, G., Touchette, E., Forget - Dubois, N., et al.   Asso ciations between sleep - wake consolidation and  language development in early childhood: a longitudinal twin study. Sleep, 2011, 34: 987 ‚Äì 995.  Doi, Y., Ishihara, K., Uchiyama, M. Associations of chronotype with social jetlag and behavioral problems in  presch ool children. Chronobiol. Int., 2015, 32: 1101 ‚Äì 1108.  Dwan, K., Altman, D.G., Arnaiz, J.A., et al. Systematic Review of the Empirical Evidence of Study Publication  Bias and Outcome Reporting Bias. PLoS ONE, 2008, 3: e3081.  Fallone, G., Acebo, C., Arnedt,   J.T., Seifer, R., Carskadon, M.A. Effects of acute sleep restriction on behavior,  sustained attention, and response inhibition in children. Percept. Mot. Skills, 2001, 93: 213 ‚Äì 229.  Gregory, A.M., Cousins, J.C., Forbes, E.E., et al. Sleep items in the chil d behavior checklist: a comparison  with sleep diaries, actigraphy, and polysomnography. J. Am. Acad. Child Adolesc. Psychiatry, 2011, 50:  499 ‚Äì 507.  Hall, W.A., Scher, A., Zaidman - Zait, A., Espezel, H., Warnock, F. A community - based study of sleep and  behav iour problems in 12 -   to 36 - month - old children. Child Care Health Dev., 2012, 38: 379 ‚Äì 389.  Hall, W.A., Zubrick, S.R., Silburn, S.R., Parsons, D.E., Kurinczuk, J.J. A model for predicting behavioural sleep  problems in a random sample of Australian pre - schoo lers. Infant Child Dev., 2007, 16: 509 ‚Äì 523.  Hatzinger, M., Brand, S., Perren, S., et al. Sleep actigraphy pattern and behavioral/emotional difficulties in  kindergarten children: association with hypothalamic - pituitary - adrenocortical (HPA) activity. J. Psy chiatr.  Res., 2010, 44: 253 ‚Äì 261.  Higgins, J.P.T., Green, S. eds Cochrane Handbook for Systematic Reviews of Interventions. Wiley - Blackwell,  Chichester, England; Hoboken, NJ , 2008.  Hiscock, H., Canterford, L., Ukoumunne, O.C., Wake, M. Adverse associatio ns of sleep problems in  Australian preschoolers: national population study. Pediatrics, 2007, 119: 86 ‚Äì 93.  Iwasaki, M., Iwata, S., Iemura, A., et al. Utility of subjective sleep assessment tools for healthy preschool  children: a comparative study between s leep logs, questionnaires, and actigraphy. J. Epidemiol. Jpn.  Epidemiol. Assoc., 2010, 20: 143 ‚Äì 149.\n\nJansen, P.W., Saridjan, N.S., Hofman, A., Jaddoe, V.W.V., Verhulst, F.C., Tiemeier, H. Does disturbed  sleeping precede symptoms of anxiety or depression in   toddlers? The generation R study. Psychosom.  Med., 2011, 73: 242 ‚Äì 249.  Jung, E., Molfese, V.J., Beswick, J., Jacobi - Vessels, J., Molnar, A. Growth of Cognitive Skills in Preschoolers:  Impact of Sleep Habits and Learning - Related Behaviors. Early Educ. Dev. , 2009, 20: 713 ‚Äì 731.  Kolb, B., Gibb, R. Searching for the principles of brain plasticity and behavior. Cortex J. Devoted Study Nerv.  Syst. Behav., 2014, 58: 251 ‚Äì 260.  Komada, Y., Abe, T., Okajima, I., et al. Short sleep duration and irregular bedtime are   associated with  increased behavioral problems among Japanese preschool - age children. Tohoku J. Exp. Med., 2011, 224:  127 ‚Äì 136.  Lam, J.C., Mahone, E.M., Mason, T., Scharf, S.M. The effects of napping on cognitive function in  preschoolers. J. Dev. Behav. Ped iatr. JDBP, 2011, 32: 90 ‚Äì 97.  Lehmkuhl, G., Fricke - Oerkermann, L., Wiater, A., Mitschke, A. Sleep disorders in children beginning school:  their causes and effects. Dtsch. √Ñrztebl. Int., 2008, 105: 809 ‚Äì 814.  Lim, J., Dinges, D.F. A meta - analysis of the impa ct of short - term sleep deprivation on cognitive variables.  Psychol. Bull., 2010, 136: 375 ‚Äì 389.  Liu, W., Ge, T., Leng, Y., et al.   The Role of Neural Plasticity in Depression: From Hippocampus to Prefrontal  Cortex. Neural Plast., 2017, 2017: 6871089.  Louis, J., Cannard, C., Bastuji, H., Challamel, M.J. Sleep ontogenesis revisited: a longitudinal 24 - hour home  polygraphic study on 15 normal infants during the first two years of life. Sleep, 1997, 20: 323 ‚Äì 333.  Mahone, E.M., Pillion, J.P., Hiemenz, J.R.   initial development of an auditory continuous performance test  for preschoolers. J. Atten. Disord., 2001, 5: 93 ‚Äì 106.  Marshall, L., Helgad√≥ttir, H., M√∂lle, M., Born, J. Boosting slow oscillations during sleep potentiates memory.  Nature, 2006, 444: 610 ‚Äì 613.  Meltzer, L.J., Mindell, J.A. Systematic review and meta - analysis of behavioral interventions for pediatric  insomnia. J. Pediatr. Psychol., 2014, 39: 932 ‚Äì 948.  Minde, K., Faucon, A., Falkner, S. Sleep problems in toddlers: effects of treatment on their da ytime  behavior. J. Am. Acad. Child Adolesc. Psychiatry, 1994, 33: 1114 ‚Äì 1121.  Mindell, J.A., Li, A.M., Sadeh, A., Kwon, R., Goh, D.Y.T. Bedtime routines for young children: a dose -  dependent association with sleep outcomes. Sleep, 2015, 38: 717 ‚Äì 722.  Moher,   D., Liberati, A., Tetzlaff, J., Altman, D.G., PRISMA Group Preferred reporting items for systematic  reviews and meta - analyses: the PRISMA statement. J. Clin. Epidemiol., 2009, 62: 1006 ‚Äì 1012.  Nathanson, A.I., Fries, P.T. Television Exposure, Sleep Time, a nd Neuropsychological Function Among  Preschoolers. Media Psychol., 2014, 17: 237 ‚Äì 261.  O‚ÄôCallaghan, F.V., Al Mamun, A., O‚ÄôCallaghan, M., et al. The link between sleep problems in infancy and  early childhood and attention problems at 5 and 14 years: Evidenc e from a birth cohort study. Early  Hum. Dev., 2010, 86: 419 ‚Äì 424.  Olini, N., Huber, R. Ageing and sleep: sleep in all stages of human development. ESRS European sleep  medicine textbook. European Sleep Research Society. (2014).  Paavonen, E.J., Porkka - Heisk anen, T., Lahikainen, A.R. Sleep quality, duration and behavioral symptoms  among 5 - 6 - year - old children. Eur. Child Adolesc. Psychiatry, 2009, 18: 747 ‚Äì 754.  Phelps, E.A., LeDoux, J.E. Contributions of the amygdala to emotion processing: from animal models t o  human behavior. Neuron, 2005, 48: 175 ‚Äì 187.  Quach, J., Hiscock, H., Wake, M. Sleep problems and mental health in primary school new entrants: cross -  sectional community - based study. J. Paediatr. Child Health, 2012, 48: 1076 ‚Äì 1081.  Sadeh, A. A Brief Screen ing Questionnaire for Infant Sleep Problems: Validation and Findings for an Internet  Sample. Pediatrics, 2004, 113: e570 ‚Äì e577.\n\nScharf, R.J., Demmer, R.T., Silver, E.J., Stein, R.E.K. Nighttime sleep duration and externalizing behaviors of  preschool childr en. J. Dev. Behav. Pediatr. JDBP, 2013, 34: 384 ‚Äì 391.  Sitnick, S.L., Goodlin - Jones, B.L., Anders, T.F. The use of actigraphy to study sleep disorders in preschoolers:  some concerns about detection of nighttime awakenings. Sleep, 2008, 31: 395 ‚Äì 401.  Spruyt,   K., Alaribe, C.U., Nwabara, O.U. Daily dynamics in sleep and behavior of young African - American  children: A convoluted dyad?! Int. J. Psychophysiol. Off. J. Int. Organ. Psychophysiol., 2016, 99: 57 ‚Äì 66.  Stickgold, R. Sleep - dependent memory consolidation.   Nature, 2005, 437: 1272 ‚Äì 8.  Stickgold, R., Walker, M.P. Sleep and memory: the ongoing debate. Sleep, 2005, 28: 1225 ‚Äì 1227.  Thorpe, K., Staton, S., Sawyer, E., Pattinson, C., Haden, C., Smith, S. Napping, development and health from  0 to 5 years: a systemat ic review. Arch. Dis. Child., 2015, 100: 615 ‚Äì 622.  Tononi, G., Cirelli, C. Sleep function and synaptic homeostasis. Sleep Med. Rev., 2006, 10: 49 ‚Äì 62.  Tononi, G., Cirelli, C. Sleep and the price of plasticity: from synaptic and cellular homeostasis to memo ry  consolidation and integration.   Neuron, 2014, 81: 12 ‚Äì 34.  Touchette, E., C√¥t√©, S.M., Petit, D., et al.   Short nighttime sleep - duration and hyperactivity trajectories in  early childhood. Pediatrics, 2009, 124: e985 - 993.  Touchette, E., Petit, D., S√©guin, J .R., Boivin, M., Tremblay, R.E., Montplaisir, J.Y. Associations between sleep  duration patterns and behavioral/cognitive functioning at school entry. Sleep, 2007, 30: 1213 ‚Äì 1219.  Troxel, W.M., Trentacosta, C.J., Forbes, E.E., Campbell, S.B. Negative emotio nality moderates associations  among attachment, toddler sleep, and later problem behaviors.   J. Fam. Psychol. JFP J. Div. Fam. Psychol.  Am. Psychol.   Assoc. Div. 43, 2013, 27: 127 ‚Äì 136.  Vaughn, B.E., Elmore - Staton, L., Shin, N., El - Sheikh, M. Sleep as a supp ort for social competence, peer  relations, and cognitive functioning in preschool children. Behav. Sleep. Med., 2015, 13: 92 ‚Äì 106.  Vertes, R.P., Siegel, J.M. Time for the sleep community to take a critical look at the purported role of sleep  in memory proc essing. Sleep, 2005, 28: 1228 - 1229; discussion 1230 - 1233.  Vriend, J., Davidson, F., Rusak, B., Corkum, P. Emotional and Cognitive Impact of Sleep Restriction in  Children. Sleep Med. Clin., 2015, 10: 107 ‚Äì 115.  Wada, K., Nakamura, K., Tamai, Y., et al. Associations of endogenous melatonin and sleep - related factors  with behavioral problems in preschool Japanese children. Ann. Epidemiol., 2013, 23: 469 ‚Äì 474.  Weissbluth, M. Sleep duration, temperament, and Conners‚Äô   ratings of three - year - old children. J. Dev.  Behav. Pediatr. JDBP, 1984, 5: 120 ‚Äì 123.  Wells, G., Brodsky, L., Shea, B., et al. An Evaluation of the Newcastle Ottawa Scale: An Assessment Tool for  Evaluating the Quality of Non - Randomized Studies. XI Interna tional Cochrane Colloquium Book of  Abstracts. p. p.26. , Barcelona (2003).  Yoo, S. - S., Gujar, N., Hu, P., Jolesz, F.A., Walker, M.P. The human emotional brain without sleep -- a  prefrontal amygdala disconnect. Curr. Biol. CB, 2007, 17: R877 - 878.  Zaidman - Za it, A., Hall, W.A. Children‚Äôs night waking among toddlers: relationships with mothers‚Äô and  fathers‚Äô parenting approaches and children‚Äôs behavioural difficulties. J. Adv. Nurs., 2015, 71: 1639 ‚Äì 1649.\n\nFigures  Figure 1 .   Systematic   review f low chart , following PRISMA guidelines   (Moher et al., 2009)  Figure 2.   Quality of i ncluded s tud ies .   a)   Article   distribution according to the   five   quality criteria,   b) Paper  distribution according to the total risk of bias (sum of the   five   quality criteria)  Figure 3 .   Number of articles per exposure and per outcome   (NSD night sleep duration, SP sleep  problems, NW night - waking, TSD total sleep   duration, SOL sleep onset latency, BT bedtime, SE sleep  efficiency, WT wake up time)\n\nIdentification Screening Eligibility Inclusion  Records identified through database searching  ‚Ä¢   Medline   n=2645  ‚Ä¢   PsycINFO   n=465  ‚Ä¢   Web of science n=154  ‚Ä¢   ERIC n=20  Records identified through  ‚Ä¢   F orward   citation   searching   n= 4  ‚Ä¢   Backward   citation   searching   n= 3  N=3291  Title and abstract screening  N=1590  Full text screening  N=79  Inclusion  N=26  53 articles did not meet inclusion criteria after full text screening  ‚Ä¢   Population selection based on the child‚Äôs cognitive or  behavioral capacities N=14  ‚Ä¢   Population selection based on the child‚Äôs sleep N=8  ‚Ä¢   Population selection based on other criteria N=4  ‚Ä¢   Average age at exposure measure <2yrs N=3  ‚Ä¢   Average age at the outcome measure >6yrs N=10  ‚Ä¢   Non eligible sleep measure (snoring, co - sleeping, composite  score including factors other than sleep) N=11  ‚Ä¢   The outcome is not a behavioral or cognitive measure N=3  1511 articles did not meet inclusion criteria  after title and abstract screening  1701 duplicates removed\n\n12%, n=3  42%, n=11  27%, n=7  15%, n=4  4%, n=1  0%, n=0  5 (highest risk of bias)  4  3  2  1  0  a) Article distribution   according   to the 5   quality   criteria  b) Article distribution   according   to the total   risk   of   bias   ( sum   of the 5   criteria )  50%, n=13  81%, n=21  69%, n=18  54%, n=14  88%, n=23  Sample size <500 children  No adjustment, incomplete adjustment  Cross-sectionall setting  Outcome investigator not blind of sleep status  Subjective exposure measurement\n\n13  8  6   6   5  3   2   1   1  20  13  5  8  5  2   1   2  0  5  10  15  20  25  Number of articles  Sleep   Behavior   Cognition\n\nTable 1. Description of the 26 included studies  Author, year   N   Country  Objective  sleep  measure  Design  Age in months (¬±SD or range)   Control   for  confounding  factors   a  Risk of  bias   b  At exposure   At outcome if  different  Armstrong et al. ( 2014)   396   USA   No   CS   c   54(¬±NA)   -   No   c   5   c  Bates et al. ( 2002)   184   USA   No   CS   58.8(¬±6.5)   -   Partial   4  Bouvette - Turcot et al.   (2015)   209   CAN   No   L   12 to 36   d   36(¬±NA)   Yes   3  Bruni   et al.   (2000)   194   ITA   No   CS   27(22 - 38)   -   No   5  Dionne et al.   (2011)   1029   CAN   No   L   31(¬±0.8)   31(¬±0.8) & 63(¬±3.0)   No   c   2   c  Hall et al. (2007)   1317   AUS   No   L   36(¬±NA)   c   48(¬±NA)   Partial   3  Hall et al.   (2012)   58   CAN   No   CS   24.7(¬±7.0)   -   No   4 - 5  Hatzinger et al.   (2010)   82   CHE   Yes   CS   58.9(¬±5.8)   -   No   3  Hiscock et al.   (2007)   4983   AUS   No   CS   56.9(51 - 67)   -   Both   2 - 4  Jansen et al.   (2011)   4782   NLD   No   L   24(¬±NA)   36(¬±NA)   Yes   2  Jung et al.   (2009)   67   USA   No   L   42.1(¬±3.3)   42 to 65   d   No   3  Komada et al.   (2011)   1746   JPN   No   CS   (24 - 36) & (48 - 60)   -   No   c   4   c  Lam et al.   (2011)   59   USA   Yes   CS   51.6(36 - 60)   -   Partial   3  Lehmkuhl et al.   (2008)   1388   DEU   No   CS   66.2(¬±NA)   -   No   4  Nathanson   and   Fries   (2014)   107   USA   No   CS   53.4(¬±8.7)   -   Partial   4  O‚ÄôCallaghan et al.   (2010)   4204   AUS   No   CS   c   (24 - 48)   e   60(¬±NA)   Partial   c   4   c  Paavonen et al.   (2009)   297   FIN   No   CS   (60 - 72)   -   Partial   4  Quach et al.   (2012)   1512   AUS   No   CS   68.4(¬±4.8)   -   Partial   4  Scharf et al.   ( 2013)   8950   USA   No   CS   48(¬±NA)   -   Partial   4  Touchette et al.   (2007)   f   1492   CAN   No   L   30 to 72   d   61(¬±3.6)   c   Yes   1  Touchette et al.   (2009)   f   2057   CAN   No   L   18 to 60   d   -   No   c   3   c  Troxel et al.   (2013)   776   USA   No   L   24(¬±NA) & 36(¬±NA)   54(¬±NA)   Partial   2  Vaughn et al.   (2015)   62   USA   Yes   CS   49.8(¬±7.4)   -   Partial   3  Wada et al.   (2013)   437   JPN   No   CS   61.4(¬±10.8)   -   Yes   4  Weissbluth   (1984)   60   USA   No   CS   36.1(36 - 38)   -   No   5  Zaidman - Zait and   Hall   (2015)   1487   CAN   No   CS   c   29(¬±NA)   -   Partial   4  a   Adjustment on sex, socio economic factors, and age when sample age range >6 months  b   From 0 to 5, a higher score indicating a   higher risk of bias  c   Concern   the analyses of interest to the review  d   Repeated measures  e   M easure assessed at 60 months   (retrospective)  f   Same study sample  AUS = Australia, CAN = Canada, CHE = Switzerland, DEU = Germany, FIN = Finland,   ITA = Italy, JPN = Japan, NLD = Netherlands, USA =United  States of America ,   L longitudinal analysis, CS cross - sectional analysis, NA Non - available data\n\nTable 2 Associations between sleep and behavior in preschoolers  TSD   NSD   I   NW   SOL   SE   SP   BT   WT  EXTERNALIZING BEHAVIOR  Aggressiveness  Armstrong et al.   ( 2014)   +**  Hall et al.   ( 2007)   +***  Hall et al.   ( 2012)   NS  Hatzinger et al.   ( 2010)   +**  Komada et al.   ( 2011) , 24 - 36   mo   - **   +**  Komada et al.   ( 2011) ,   48 - 60   mo   NS   +**  Scharf et al.   ( 2013)   - ***  Zaidman - Zait and Hall   ( 2015)   +*  Anger  Schar f et al.   ( 2013)   - **  Attention problems  Hall et al.   ( 2012)   NS  Komada et al.   ( 2011) , 24 - 60   mo   NS   +**  Lam et al.   ( 2011)   NS  O‚ÄôCallaghan et al.   ( 2010)   +***  Paavonen et al.   ( 2009) ,   p arents report   - **  Paavonen et al.   ( 2009) ,   t eacher report   NS  Touchette et al.   ( 2007)   NS  Vaughn et al.   ( 2015)   NS   NS   NS  Conduct problems  Hatzinger et al.   ( 2010) , boys   NS   +*   NS   NS  Hatzinger et al.   ( 2010) , girls   NS   NS   NS   NS  Hiscock et al.   ( 2007)   +***   +***   +***  Lehmkuhl et al.   ( 2008)   +**   +**  Quach et al.   ( 2012)   +***  Wada et al.   ( 2013)   NS   - *   NS   NS   NS   NS  Scharf et al.   ( 2013)   ( Annoying behavior)   NS  Scharf et al.   ( 2013)   ( Tantrums)   - *  Hyperactivity  Armstrong et al.   ( 2014)   +**  Hatzinger et al.   ( 2010) , boys   NS   +*   NS   NS  Hatzinger et al.   ( 2010) , girls   NS   NS   NS   NS  Lam et al.   ( 2011)   NS  Lehmkuhl et al.   ( 2008)   NS   +**  Quach et al.   ( 2012)   +***  Scharf et al.   ( 2013)   - **  Touchette et al.   ( 2009)   - ***  Wada et al.   ( 2013)   NS   NS   +*   NS   NS   +*  Zaidman - Zait and Hall   ( 2015)   +***  Hyperactivity and impulsivity  Touchette et al.   ( 2007)   - * **   a  Hyperactivity and attention  Hiscock et al.   ( 2007)   +***   +***   +***  Impulsivity  Scharf et al.   ( 2013)   - ***  Opposition  Zaidman - Zait and Hall   ( 2015)   +**  Non - specific externalizing behavior  Bruni et al.   ( 2000)   +*  Hall et al.   ( 2012)   NS  Paavonen et al.   ( 2009) ,   parents report   NS\n\nTable   2 continued)  TSD   NSD   I   NW   SOL   SE   SP   BT   WT  Paavonen et al.   (2 009) ,   teacher report   NS  Scharf et al.   (2 013)   - ***  Troxel et al.   (2 013)   +*  Weissbluth   ( 1984)   NS   NS  INTERNALIZING BEHAVIOR  Anxious, depressed  Armstrong et al.   (2 014)   NS  Hall et al.   (2 012)   NS  Jansen et al.   (2 011)   - *   +*  Komada et al.   (2 011) ,   24 - 36   mo   NS   +**  Komada et al.   (2 011) ,   48 - 60   mo   NS   +**  Zaidman - Zait and Hall   (2 015)   +*  Separation anxiety  Zaidman - Zait and Hall   (2 015)   +***  Emotional symptoms  Hall et al.   (2 012)   NS  Hatzinger et al.   (2 010)   NS   NS   NS   NS   NS  Hiscock et al.   (2 007)   +***   +***   +***  Lehmkuhl et al.   (2 008)   +**   +**  Quach et al.   (2 012)   +***  Wada et al.   (2 013)   NS   NS   NS   NS   +*   NS  Withdrawn, shyness  Hall et al.   (2 012)   NS  Zaidman - Zait and Hall   (2 015)   +**  Somatization  Bruni et al.   (2 000)   +**  Hall et al.   (2 012)   NS  Non - specific internalizing behavior  Bruni et al.   (2 000)   NS  Hall et al.   (2 012)   NS  Paavonen et al.   (2 009) ,   parents report   - *  Paavonen et al.   (2 009) ,   teacher report   NS  Troxel et al.   (2 013)   +**  SOCIABILITY  Prosocial behavior  Hiscock et al.   (2 007)   - ***   - ***   - ***  Lehmkuhl et al.   (2 008)   NS   +**  Quach et al.   (2 012)   - ***  Vaughn et al.   (2 015)   +*   NS   NS  Wada et al.   (2 013)   NS   NS   NS   NS   - *   - **  Peer relation problems  Hiscock et al.   (2 007)   +**   +***   +***  Lehmkuhl et al.   (2 008)   NS   NS  Quach et al.   (2 012)   +***  Vaughn et al.   (2 015)   - **   NS   NS  Wada et al.   (2 013)   NS   NS   NS   NS   NS   +**  NON - SPECIFIC BEHAVIOR PROBLEMS  Armstrong et al.   (2 014)   +*  Bates et al.   (2 002)   NS   NS   NS  Bouvette - Turcot et al.   ( 2 015)  ‚â• 1 copy of the 5 - HTTLRPR   b   short allele  - ***  Bouvette - Turcot et al.   ( 2 015)  no copy of the 5 - HTTLRPR   b   short allele  NS\n\nTable 2 continued)  TSD   NSD   I   NW   SOL   SE   SP   BT   WT  Hiscock et al.   (2 007)   +***   +***   +***  Lehmkuhl et al.   (2 008)   +**   +**  Paavonen et al.   (2 009) ,   teacher report   NS  Quach et al.   (2 012)   +***  Wada et al.   (2 013)   NS   NS   +*   NS   +*   +*  Note: +,   -   and NS   indicate   a positive, negative and non - significant statistical association  Abbreviations stand for: TSD total sleep duration, NSD night sleep duration, I insomnia, NW night - waking,  SOL sleep onset latency,   SE sleep efficiency,   SP sleep problems, BT bed time, WT wake - up time.  * p<0.05, ** p ‚â§ 0.01, ***p ‚â§ 0.001  a   When compared to the 11 - hour persistent sleep duration trajectory, the short increasing duration  trajectory is a risk factor p=0.001, but no significant association   was   found with other categories  b   Serotonin - transporter - linked polymorphic region of the serotonin transporter gene (SLC6A4)\n\nTable 3 Associations between sleep and cognition in preschoolers.  TSD   NSD   NW   SOL   SE   SP  Executive function  Lam et al.   (20 11)   ACPT - P Omission error   NS  Lam et al.   (20 11)   ACPT - P Commission error   - *  Lam et al.   (20 11)   ACPT - P Mean response time   NS  Lam et al.   (20 11)   ACPT - P Variability   NS  Nathanson and Fries   (20 14)   NS  Memory  Lam et al.   (20 11)   NS  Language  Dionne et al.   (20 11)   Receptive Vocabulary   NS  Hiscock et al.   (20 07)   Receptive Vocabulary   NS   NS   NS  Hiscock et al.   (20 07)   Literacy and numeracy   NS   NS   +***  Lam et al.   (20 11)   Receptive Vocabulary   +*  Vaughn et al.   (20 15)   Receptive Voc abulary   +**   NS   NS  Touchette et al.   (20 07)   Rec eptive Vocabulary   +***   a  Non - specific cognition  Jung et al.   (20 09)   General conceptual ability   +*  Touchette et al.   (20 07)   Non - verbal abilities   +***   b  Note: +,   -   and NS   indicate   a positive, negative and non - significant statistical association  Abbreviations stand for: TSD total sleep duration, NSD night sleep duration, NW night - waking, SOL sleep  onset latency, SE sleep   efficiency, SP sleep problems.  * p<0.05, ** p ‚â§ 0.01, ***p ‚â§ 0.001  ACPT - P Auditory continuous performance test for preschoolers   (Mahone et al.   (2 001)  a   with the reference being children who slept 11 - hour persistently, children who had short persistent  duration were at higher risk (p=0.001), but no significant association   was   found with other categories  b   with the reference being children who slept 11 - ho ur persistently, children who had short increasing  duration were at higher risk (p=0.001), but no significant association   was   found with other categories",
    "arXiv:1209.5046v1 [physics.bio-ph] 23 Sep 2012  Diversity and noise effects in a model of homeostatic regulation of the sleep-wake cycle  Marco Patriarca 1 , 2 , ‚àó   Svetlana Postnova 3 , 4 , ‚Ä†   Hans A. Braun 5 , ‚Ä°   Emilio Hern¬¥ andez-Garc¬¥ ƒ±a 1 , ¬ß   and Ra¬¥ ul Toral 1 , ¬∂  1   IFISC, Instituto de F¬¥ ƒ±sica Interdisciplinar y Sistemas Complejos (CSIC-UIB), Campus Universitat de les Illes Balears, E-07122 Palma de Mallorca, Spain ‚àó‚àó  2   National Institute of Chemical Physics and Biophysics, R¬® avala 10, 10143 Tallinn, Estonia  3   School of Physics, The University of Sydney, Physics Annex, A29, NSW 2006 Sydney, Australia  4   Center for Integrated Research and Understanding of Sleep, The University of Sydney, Glebe Point Rd, 431, NSW 2037 Sydney, Australia and  5   Neurodynamics Group, Physiology Institute, Marburg University, Deutschhausstr. 2, D-35037 Marburg, Germany  Abstract  Recent advances in sleep neurobiology have allowed development of physiologically based mathe- matical models of sleep regulation that account for the neuronal dynamics responsible for the regu- lation of sleep-wake cycles and allow detailed examination of the underlying mechanisms. Neuronal systems in general, and those involved in sleep regulation in particular, are noisy and heterogeneous by their nature. It has been shown in various systems that certain levels of noise and diversity can significantly improve signal encoding. However, these phenomena, especially the effects of diversity, are rarely considered in the models of sleep regulation. The present paper is focused on a neuron- based physiologically motivated model of sleep-wake cycles that proposes a novel mechanism of the homeostatic regulation of sleep based on the dynamics of a wake-promoting neuropeptide orexin. Here this model is generalized by the introduction of intrinsic diversity and noise in the orexin- producing neurons, in order to study the effect of their presence on the sleep-wake cycle. A simple quantitative measure of the quality of a sleep-wake cycle is introduced and used to systematically study the generalized model for different levels of noise and diversity. The model is shown to exhibit a clear diversity-induced resonance: that is, the best wake-sleep cycle turns out to correspond to an intermediate level of diversity at the synapses of the orexin-producing neurons.   On the other hand, only a mild evidence of stochastic resonance is found, when the level of noise is varied. These results show that disorder, especially in the form of quenched diversity, can be a key-element for an efficient or optimal functioning of the homeostatic regulation of the sleep-wake cycle. Furthermore, this study provides an example of a constructive role of diversity in a neuronal system that can be extended beyond the system studied here.  This paper has been published as: M. Patriarca, S. Postnova, H.A. Braun, E. Hern¬¥ andez-Garc¬¥ ƒ±a, R. Toral,  Diversity and Noise Effects in a Model of Homeostatic Regulation of the Sleep-Wake Cycle , PLoS Comput. Biol.   8 (8): e1002650 (2012)  doi:10.1371/journal.pcbi.1002650  ‚àó Electronic address: marcop@ifisc.uib-csic.es  ‚Ä† Electronic address: postnova@physics.usyd.edu.au  ‚Ä° Electronic address: braun@staff.uni-marburg.de  ¬ß Electronic address: emilio@ifisc.uib-csic.es  ¬∂ Electronic address: raul@ifisc.uib-csic.es  ‚àó‚àó URL:   http://ifisc.uib-csic.es  Author Summary  All biological systems are inherently noisy and hetero- geneous.   Disorder is mostly expected to disturb proper functioning of a system, like it can be the case with noise in a radio signal.   However, it has been demonstrated by numerous studies that noise can actually improve sig- nal encoding ‚Äì the so-called stochastic resonance phe- nomenon.   Recently, it was discovered that quenched di- versity (heterogeneity) can also enhance the response of a system to an external perturbation (diversity-induced res- onance). In this study we investigate the role of noise and diversity in a neuronal model of sleep-wake cycles based on the dynamics of the wake-promoting orexin neurons that is crucial for stability of wake and sleep states. We demonstrate that suitable levels of diversity introduced in the orexin neurons can significantly improve the quality of the sleep-wake cycle, and may be essential for proper sleep-wake periodicity.   Noise, on the other hand, pro- vides only a mild improvement.\n\n2  I.   INTRODUCTION  Disorder, which originates from both noise and diver- sity, is naturally present in all biological systems.   In neuronal systems some examples are the random open- ing and closing of ion channels, the multitude of stochas- tic input currents in the neurons, and the diversity of shapes, sizes, and electrophysiological properties of the neurons [1, 2]. Disorder is often considered to be harmful to the systems‚Äô functioning and to information encoding. However, it was likewise repeatedly demonstrated that a certain level of disorder can facilitate signal encoding by enhancing system‚Äôs response to an external stimuli. For instance, quenched diversity clearly shows its construc- tive role in the phenomenon of diversity-induced reso- nance, in which an assembly of heterogeneous excitable units presents an optimal response to an external forcing for a suitable intermediate degree of heterogeneity [3‚Äì5]. Similar constructive effects can be observed in the pres- ence of noise. For example, interplay of noise and nonlin- ear forces produces the directed motion of motor proteins [6], order-disorder transitions, oscillations, and synchro- nization in assemblies of excitable units [7‚Äì9], and an op- timized system response in the ubiquitous phenomenon of stochastic resonance [10, 11], e.g. in ion-channels and neurons [12‚Äì17]. In the present study we examine the effects of noise and diversity (heterogeneity) in a physiologically based neu- ronal model of sleep-wake cycles [18]. This model intro- duces a novel mechanism of the homeostatic regulation of sleep based on the dynamics of a wake-promoting neu- ropeptide orexin (also called hypocretin), assuming de- pression of orexinergic synapses during wakefulness and their recovery during sleep. This mechanism is based on the experimental findings of the essential role of orexin system in maintaining wakefulness and its ability to in- tegrate the sleep-wake relevant information coming from many brain areas [19, 20] and respond to changes in the body external and internal environments by encoding the body activity state, energy balance, sensory and emo- tional stimuli [21, 22]. In the original model interaction between only two representative neurons is simulated:   the orexin neuron and the local glutamate neuron that are reciprocally con- nected to each other according to the experimentally es- tablished physiological connections [23]. Both orexin and glutamate neurons are firing during wakefulness and are silent during sleep. The transitions between firing and si- lence are governed by the interplay between the circadian input and homeostatic mechanisms as initially proposed by Borbely [24]. For simplicity, in this model only a sin- gle type of orexin neurotransmitter (instead of the two types actually known) is considered, and it is assumed that the system can be either in the wake state or in a generic non-Rapid Eye Movement sleep state, without specifying ultradian structure of sleep.   Also this model did not consider noise effects, and diversity could not be included since there are only two neurons present. In the present paper we extend the above described two-neuron model to a more realistic multi-unit model with heterogeneous neurons. The aim of the study is to first of all investigate how the presence of diversity in the neuronal population affects sleep-wake transitions, since it is well-known that neurons are highly heterogeneous by their nature. In particular, within the orexin neurons population significant intrinsic diversity can be found: different electrophysiological properties, sizes in the di- ameter range 15-40   Œº m, and various shapes such as a spherical, fusiform, or multipolar [19, 22, 25]. Secondly, also stochastic fluctuations, representing current noise, are added to the model and the response of the system is studied for different levels of noise. The question natu- rally arises, to what extent noise and diversity are essen- tial ingredients for the functioning of assemblies of neu- rons and other complex systems, and what is the optimal level of noise and diversity required for the emergence of an optimal response to external stimuli. It is shown be- low that the model under study presents both diversity- induced resonance and stochastic resonance, but the for- mer appears more clear and robust, since it is always associated with a regular almost-periodic spiking-silence activity, rather than to the irregular random transitions characterizing the stochastic resonance regime.  II.   MATERIALS AND METHODS  In this section the two-neuron model of sleep-wake cy- cles [18] is described and some examples of dynamics in the presence of an external periodic signal are illustrated. Further, this model is extended to account for multiple neurons dynamics and heterogeneity, and a simple quan- titative criterion to estimate the quality of a sleep-wake cycle is introduced.   This criterion will be used in the Results section to compare sleep-wake cycles dynamics obtained at different parameter sets.  A.   The two-neuron model  The original model of the homeostatic regulation of sleep has a minimal structure consisting of two represen- tative interacting neurons A and B, as depicted in Fig. 1. The neuron A simulates a representative neuron from the orexinergic neuronal population, while the neuron B represents a local glutamate interneuron (for details see [18]). The state of wakefulness or sleep is determined by the firing regime of neurons A and B, since these neurons are known to fire during wakefulness and be almost silent during sleep (see e.g. [22]). Interaction between the neurons A and B takes place through glutamate and orexin neurotransmitters, as de- tailed below.   The neuron A is acted upon by a stimu- lus in pace with the circadian rhythm, here treated as a periodic external signal ‚Äî a simplification justified by its independence from the homeostatic process [26].\n\n3  FIG. 1:   Scheme of the two-neuron model of the sleep- wake cycle [18].   The A   ‚Üí   B red arrow from the orexin- producing neuron A (red circle) to the neuron B (blue circle) represents the glutamate projection as well as the orexin pro- jection regulating the homeostatic process.   The blue arrow represents the B   ‚Üí   A glutamate projection. The neuron A is also acted upon by a periodic signal representing the effect of the circadian clock.  The homeostatic process itself is described by an addi- tional macroscopic variable   M   ( t ) simulating availability of orexin. Dynamics of the neurons A and B are based on a Hodgkin-Huxley-type model [27]. The membrane poten- tials of the neurons A ( V A ( t )) and B ( V B ( t )) are thus calculated as:  C A  dV A  dt   =   I ext   +   Œæ A   ‚àí   I A , L   ‚àí   I A , Na   ‚àí   I A , K   ‚àí   I A , gl   (1)  ‚â°   I ext   +   Œæ A   ‚àí   g L [ V A ‚àí E L ]   ‚àí   g Na [ V A ‚àí E Na ] a A , Na  ‚àí   g K [ V A ‚àí E K ] a A , K   ‚àí   g gl [ V A ‚àí E gl ] a A , gl , C B  dV B  dt   =   Œæ B   ‚àí   I B , L   ‚àí   I B , Na   ‚àí   I B , K   ‚àí   I B , gl   ‚àí   I ox   (2)  ‚â°   Œæ B   ‚àí   g L [ V B ‚àí E L ]   ‚àí   g Na [ V B ‚àí E Na ] a B , Na  ‚àí g K [ V B   ‚àí   E K ] a B , K   ‚àí   g gl [ V B ‚àí E gl ] a B , gl   ‚àí   g ox [ V B ‚àí E ox ] a ox ,  where   C p   ( p   = A ,   B) are the membrane capacitances per   unit   area   of   the   respective   neurons,   I Œ±   ( Œ±   = L ,   Na ,   K ,   gl ,   ox) are the ionic currents,   g Œ±   are the max- imum conductances, and   E Œ±   are the equilibrium poten- tials.   The capacitance values are taken as   C A   =   C B   = 1 Œº F / cm 2 . The values of all the other model parameters are listed in Table I. In the following we give a detailed explanation of dif- ferent parts of the model.  ‚Ä¢   External forces . The current   I ext   acting on the neu- ron A and the noise currents   Œæ p ( t ),   p   = A ,   B, can be considered as external forces, in the sense that they do not depend on the system variables. The   external current   I ext ( t ) is assumed to simulate a stimulus associated with the circadian rhythm. For simplicity in the present study a periodic pulse input is used to introduce circadian activation of the system:   œÑ   ,   I ext ( t ) =   I ext ( t   +   œÑ   ).   Such cur- rent can be interpreted as an awakening effect of an alarm clock or some other disturbance coming with a period of 24 hours. In the following we em- ploy a train of rectangular pulses with length   œÑ 0  ( œÑ 0   < œÑ   ) and height   I 0 , as depicted in Fig. 2-top,  I ext ( t )   =   I 0   ,   nœÑ   ‚â§   t   < nœÑ   +   œÑ 0   ,  =   0   ,   nœÑ   +   œÑ 0   ‚â§   t   <   ( n   + 1) œÑ ,   (3) where   n   is an integer. This simple form is chosen because it is convenient for carrying out a system- atic study of the neuron response at different pa- rameters sets. However, it should be kept in mind that it represents a drastic simplification, and more realistic shapes of circadian currents can also be used [18]. The   noise   term   Œæ p ( t ) represents fluctuating cur- rents that are known to be always present in neu- rons. For simplicity, we assume zero-average Gaus- sian white-noise processes:  „Äà Œæ p ( t ) „Äâ   = 0;  „Äà Œæ p ( t )   Œæ p ‚Ä≤   ( s ) „Äâ   = 2   D p   Œ¥ p,p ‚Ä≤   Œ¥ ( t ‚àí s ) ,   p, p ‚Ä≤   = A ,   B ,   (4) with   D p   being the noise intensity.  ‚Ä¢   Internal   dynamics .   The   leakage,   sodium,   and potassium currents   I p,Œ±   ( p   = A ,   B;   Œ±   = L ,   Na ,   K) in the equation of the neuron   p   depend only on the variables of the   same   neuron   p   and, thus, describe the neuronal internal dynamics. The   leakage currents   I p, L   =   g L ( V p   ‚àí   E L ) repre- sent a flow of ions with a small conductance   g L   ‚âà  0 . 1   Œº S / cm 2   driving the membrane potential toward the negative value   E L   ‚âà ‚àí 60 mV. The depolarizing   Na-currents   I p, Na   =   g Na ( V p   ‚àí  E Na )   a p, Na   have a maximum conductance   g Na   = 3   Œº S / cm 2   and a large positive equilibrium potential  E Na   = 50 mV.   The activation variables   a p, Na ( t ), with 0   ‚â§   a p, Na   ‚â§   1, represent the fraction of open ion-channels contributing to the Na current.   Be- cause of their fast activation relative to the other time scales, the Na-current is assumed to be ac- tivated instantaneously, according to its voltage- dependency:  a p, Na   = Œ¶( S Na ( V p   ‚àí   W Na ))   ,   (5) where Œ¶( x ) is the sigmoid function Œ¶( x ) =   1  1 + exp( ‚àí x )   ,   (6)  S Na   is the steepness of the sigmoid function and  W Na   is the half-activation potential. The   repolarizing   K-currents   I p, K   =   g K ( V p   ‚àí  E K )   a p, K   are characterized by a maximum conduc- tance   g K   = 4   Œº S / cm 2 , a large negative equilib- rium potential   E K   =   ‚àí 90 mV, and a longer activa- tion time than the depolarizing Na-current, namely\n\n4  TABLE I:   Parameters of the two-neuron model [18].  Conductance   Equilibrium   Slope   Threshold   Time  Potential   Parameter   Potential   Scales  ( Œº S / cm 2 )   (mV)   (mV ‚àí 1 )   (mV)   (ms)  L (Leakage current)   g L   = 0 . 1   E L   =   ‚àí 60  Na (Sodium current)   g Na   = 3   E Na   = 50   S Na   = 0 . 25   W Na   =   ‚àí 25   ( œÑ Na   ‚âà   0)  K (Potassium current)   g K   = 4   E K   =   ‚àí 90   S K   = 0 . 25   W K   =   ‚àí 25   œÑ K   = 2  gl (Glutamate current)   g gl   = 0 . 15   E gl   = 50   S gl   = 1   W gl   =   ‚àí 20   œÑ gl   = 30  ox (Orexin current)   g ox   = 0 . 135   E ox   = 50   S ox   = 1   W ox   =   ‚àí 20   œÑ ox   = 300  g ox   = 0 . 2   œÑ   + ox   = 7500  œÑ   ‚àí  ox   = 920  Periodic current   œÑ   = 24000  œÑ 0   = 500  œÑ K   = 2 ms. Consequently, the dynamics of the K- currents activation variables are modelled as  da p, K  dt   =   ‚àí   1  œÑ K  [ a p, K   ‚àí   Œ¶( S K ( V p   ‚àí   W K ))]   ,   (7) where Œ¶( x ) is defined in Eq. (6).  Couplings . The neurons A and B are mutually cou- pled by chemical synapses through the glutamate- induced ( I p , gl ) and the orexin-induced ( I ox ) cur- rents.   Unlike the Na and K currents,   I p , gl   and  I ox   depend on the activity of both presynaptic and postsynaptic neurons. The activation variables  a p , gl   and   a ox   depend on the appearance of a spike in the presynaptic neuron, i.e.   on the presynap- tic voltage. Additionally these currents depend on the voltage of the postsynaptic neuron, similarly to other ionic currents.   Both glutamate and orexin are excitatory neurotransmitters, so they are as- sumed to open depolarizing ion channels, such as Na-channels. The activations of the glutamate-induced currents are modeled as:  da p , gl  dt   =   ‚àí   1  œÑ gl  [   a p , gl   ‚àí   Œ¶( S gl ( V ¬Ø p   ‚àí W gl )) ]   ,  ¬Ø p   = B   if   p   = A;   ¬Ø p   = A if   p   = B .   (8) This equation is similar to Eq. (7) but has the important   difference   that   the   equilibrium   value Œ¶( S gl ( V ¬Ø p ‚àí W gl )) for the activation variable   a p , gl   de- pends on the membrane potential   V ¬Ø p   of the   other  neuron ¬Ø p   (¬Ø p   = B if   p   = A, ¬Ø p   = A if   p   = B).   The time constant   œÑ gl   = 30 ms accounts for the delay coming from the activation of glutamate receptors, and the following activation of ion channels. The   orexin-induced current   represents the effect of orexin produced by the neuron A and acting on the neuron B. It is modeled in a form similar to the glutamate-induced current.   This current provides a simplified description of the effects of orexin on the neuron B which appear after a complex series of processes, involving production of orexin in the soma of the neurons, its release in the synaptic cleft, and activation of G-protein coupled metabotropic receptors. The dynamics of the activation variable  a ox ( t ) depend not only on the membrane poten- tial   V A ( t ), but are also related to the availability of orexin at time   t , described by the additional vari- able   M   ( t ) (0   ‚â§   M   ‚â§   1).   The dynamics of the variables   a ox ( t ) and   M   ( t ) are defined by the equa- tions:  da ox  dt   =   ‚àí   1  œÑ ox  [ a ox   ‚àí M   √ó   Œ¶( S ox ( V A   ‚àí W ox ))]   ,   (9)  dM  dt   =   ‚àí   1  œÑ   + ox  ( M   ‚àí 1)  ‚àí   1  œÑ   ‚àí  ox  M   √ó   Œ¶( S ox ( V A   ‚àí W ox )) .   (10) The term   M   √ó   Œ¶( S ox ( V A   ‚àí   W ox )) in the Eq. (9) reflects activation of the synaptic current due to appearance of a spike in the presynaptic neuron A. At the same time it determines the rate of orexin availability reduction in Eq. (10) due to spiking of the neuron A with a time constant   œÑ   ‚àí  ox .   The first term in Eq. (10) determines recovery rate of the orexin availability with time constant   œÑ   + ox . The meaning of the product   M   ( t )   √ó   Œ¶( S ox ( V A   ‚àí  W ox )) is that there is orexin-induced activity in neuron B if (1) there is enough orexin available above a critical threshold [ M   ( t )   > M critical ], and (2) the neuron A is in the firing state [Œ¶( t )   ‚âà   1]. The time constants   œÑ   ¬±  ox   accounting for the orexin dynamics are much longer than the time constants associated with ionic current terms. The time con- stant   œÑ ox   of the homeostatic regulation process is even longer, being of the order of magnitude of the daily period   œÑ   . For numerical convenience, simulations are made over rescaled daily and orexin time scales: the daily\n\n5  FIG. 2:   Response of the two-neuron model . Main variables and inter-spike times   Œ¥t p   ( p   = A ,   B)   versus   time for a pulse height   I 0   = 0 . 895 mA (left) and   I 0   = 0 . 893 mA (right), see text for details.  period was assumed to be   œÑ   = 24 s, instead of  œÑ   = 24 h, achieved through a suitable rescaling, which was applied to the orexin time scale   œÑ ox   and the production and reduction times   œÑ   ¬±  ox . The other time parameters are left unchanged.   Since such rescaled   œÑ ox   and   œÑ   ¬±  ox   are still much larger than any other time scale of the microscopic dynamics, the rescaling does not change the main results of the simulations.   See [18] for a detailed validation of such rescaling procedure.\n\n6 All the parameter values for the currents are listed in Table I. It is assumed that the neurons A and B share the same parameter values, unless specified otherwise. Such an assumption is justified, because the major properties of these neurons required for the model are the tonic firing (periodic single spike activity) and silent states. Without any external input both neurons should be in a silent state, while they are brought to firing activity in response to depolarization. Therefore, change of param- eters in a physiologically allowed range would primarily lead to the different amount of depolarization needed to excite neurons, and would not affect the major outcomes of the simulations. The system defined above is essentially an excitable feedback system, i.e. both the external input of sufficient strength and the AB coupling are essential elements for maintaining firing activity of the neurons. Orexin-related dynamics, with the associated long time scales, are ex- pected to direct the homeostatic sleep process, which reg- ulates the sleep-wake transitions. The healthy sleep-wake cycles in this system are realized as follows:  ‚Ä¢   Initiating wakefulness . A sufficiently strong or long external signal or a stimulus associated to the cir- cadian rhythm, e.g. the idealized rectangular pulse considered here, activates the system and induces firing activity in the neuron A. Due to the excita- tory synaptic connection from A to B, the neuron B is also activated.  ‚Ä¢   Maintaining wakefulness . Once the pulse is finished and the external current is zero, the system remains in the wake state (i.e.   both neurons A and B are firing) due to reciprocal excitation between the neu- rons. The firing activity lasts for a fraction   q   of the daily period   œÑ   .   Ideally one can assume   q   = 2 / 3, corresponding to 16 hours for a day of 24 hours, i.e. 16 seconds for the daily period   œÑ   = 24 s with the time scales of the model considered here.  ‚Ä¢   Initiating sleep .   The firing stops in both neurons due to decreased availability of orexin according to the dynamics of   M   ( t ). This is associated witch the transition from wake to sleep. Two examples of the two-neuron model dynamics with- out noise are illustrated in Fig. 2.   The left part of the figure represents the response obtained for a pulse length  œÑ 0   = 500 ms and height   I 0   = 0 . 895   Œº A / cm 2 .   In each period orexin is depleted during the neuronal activity and recovered while the neurons are silent.   The stimu- lus parameters used in this example have been intention- ally chosen close to the critical firing threshold, so that by slightly reducing the pulse height or length, the peri- odic appearance of a continuous time interval of spiking regime is lost.   Such case is demonstrated in the right hand side of the figure, where the current pulse height is slightly lower,   I 0   = 0 . 893 mA, while all the other param- eters are kept the same. There the prolonged wake state is induced only every other day, because the input is in- sufficient to induce sustained spiking at the same levels of orexin availability.   By reducing the pulse amplitude or duration even further it is possible to observe different behaviors such as triple or higher-order periodicities.  FIG. 3:   Scheme of the heterogeneous model . Example of model system with   N A   = 5 orexin-producing neurons   { A i } ,  i   = 1 , . . . N A   (red spheres) and one neuron B (blue sphere). The neurons A interact with each other through an all-to-all coupling (red lines). Blue and red projections have a meaning similar to those of Fig. 1:   the neuron B is coupled to the neurons A i   through parallel glutamate projections, while each neuron A i   is coupled to neuron B through a glutamate and an orexin projection. The neurons A are also acted upon by a stimulus representing the effect of the circadian clock (gray arrows).  B.   The heterogeneous model  As a step toward a more realistic model we generalize the two-neuron model into a heterogeneous multi-neuron model.   For simplicity we first increase the number of orexin neurons only.   To do this we replace the single neuron A by a set of   N A   neurons   { A i }   ( i   = 1 , . . . , N A ), while still maintaining only one neuron B. Also, in this paper we assume that the diversity is constant in time in order to consider the simplest case possible. In reality a certain level of heterogeneity is observed in all neuronal parameters. However, given that our model neurons are simple pacemaking neurons such diversifica- tion of different model parameters (in a physiologically allowed range) would simply lead to slightly different fir- ing rates of the neurons. This, in turn, will result in di- versity in activations of synaptic currents, which can be\n\n7 mimicked by simply diversifying their activation thresh- olds.   Thus, in the following we can limit ourselves to studying the effects of diversity in activation thresholds of synaptic currents without loss of generality. Further- more, as a first step, the heterogeneity is only introduced in the glutamate-induced currents to avoid having a too complicated system, which would become difficult to un- derstand. With regard to the coupling topology among the orexin neurons, so far there is no detailed experimental data. Therefore, for simplicity, we chose an all-to-all coupling via gap junctions, but other variations can be tested in the future. The intensity of the coupling has been chosen large enough to ensure that the neurons A i   respond in pace to the external current. The equations of the two- neuron model are modified accordingly.  ‚Ä¢   Dynamics of the neurons   A i .   The membrane po- tentials   V   ( i ) A   ( t ) of the neurons A i , are described by equations analogous to Eq. (1):  C A  dV   ( i ) A  dt  =   I ext   +   Œæ ( i ) A   ‚àí   I   ( i ) A , L   ‚àí   I   ( i ) A , Na   ‚àí   I   ( i ) A , K   ‚àí   I   ( i ) A , gl   ‚àí   ‚àë  j  I ij  =   I ext   +   Œæ ( i ) A   ‚àí   g L [ V   ( i ) A   ‚àí E L ]   ‚àí   g Na [ V   ( i ) A   ‚àí E Na ]   a   ( i ) A , Na  ‚àí g K [ V   ( i ) A   ‚àí E K ]   a   ( i ) A , K   ‚àí   g gl [ V   ( i ) A   ‚àí E gl ]   a   ( i ) A , gl  ‚àí k   int  ‚àë  j  [ V   ( i ) A   ‚àí   V   ( j ) A   ]   .   (11) The current terms are similar to those in the two- neuron model, apart from the additional coupling currents between two generic neurons A i   and A j   ,  I ij   =   k   int ( V   ( i ) A   ‚àí V   ( j ) A   ), with   i, j   = 1 , . . . , N A , where  k   int   is the gap junctions conductance that can be treated as coupling strength. The currents‚Äô activa- tion variables   a   ( i ) A , Na   and   a   ( i ) A , K   are modeled in accord with the equations of the two-neuron model. Note that the specific values of the activation variables will be different for different neurons since they de- pend on voltages of each particular neuron A i . For simplicity the same external current   I ext ( t ) given by Eq. (3) is assumed to act on all neurons A i   (see Fig. 3).   The noise terms   Œæ ( i ) A   ( t ) as well as the noise   Œæ B ( t ) acting on the neuron B (see be- low) are also defined similarly and assumed to be statistically independent from each other. For con- venience the properties of all stochastic forces are written together ( i, j   = 1 , . . . , N A ):  „Äà Œæ ( i ) A   ( t ) „Äâ   =   „Äà Œæ B ( t ) „Äâ   = 0   ,  „Äà Œæ ( i ) A   ( t )   Œæ B ( s ) „Äâ   = 0 ,  „Äà Œæ ( i ) A   ( t )   Œæ ( j ) A   ( s ) „Äâ   = 2   D A   Œ¥ i,j   Œ¥ ( t ‚àí s )   ,  „Äà Œæ B ( t )   Œæ B ( s ) „Äâ   = 2   D B   Œ¥ ( t ‚àí s )   .   (12)  ‚Ä¢   Connections from the neuron B to the neurons   A i . The neuron B has glutamatergic synaptic inputs to each of the neurons A i   as depicted in Fig. 3. Diversity is introduced in the activation thresholds of the glutamate-induced currents according to the following equation for the activation variables:  da   ( i ) A , gl  dt   =   ‚àí   1  œÑ gl  [  a   ( i ) A , gl   ‚àí   Œ¶( S gl ( V B   ‚àí W   ( i ) B , gl ))  ]  .   (13) The thresholds   W   ( i ) B , gl   adopt different values for each neuron A i   that are independently extracted from a probability distribution defined later in the text.  ‚Ä¢   Connections from the neurons   A i   to the neuron B . Each of the neurons A i   has synaptic projections to the neuron B. This is translated in the model by replacing the single glutamate- and orexin-induced currents with their averages such that Eqs. (8) and (9) for the activation variables become:  da B , gl  dt  =   ‚àí   1  œÑ gl  [  a B , gl   ‚àí   1  N A  N A ‚àë  i =1  Œ¶( S gl ( V   ( i ) A   ‚àí W   ( i ) A , gl ))  ]  , (14)  da B , ox  dt  =   ‚àí   1  œÑ ox  [  a B , ox   ‚àí   1  N A  N A ‚àë  i =1  M   ( i ) Œ¶( S ox ( V   ( i ) A   ‚àí W ox ))  ]  (15) Note that diversity is again introduced in the ac- tivation thresholds of the glutamate-induced cur- rents   W   ( i ) A , gl   corresponding to heterogeneous (A i   ‚Üí  B) synapses located at the neuron B. Due to the dif- ferences in the A i   neurons, the orexin availability function   M   ( i ) ( t ) is different for different neurons, although still following Eq. (10). The above described set of equations constitutes the multi-neuron heterogeneous model of the homeostatic regulation of sleep. Numerical results were obtained us- ing a variation of the Runge-Kutta 2nd-order method, which is suitable for equations with stochastic terms, namely the Heun method [28].   Identical initial condi- tions were assumed for all neurons, corresponding to a silent state.  C.   Quantifying the quality of the sleep-wake cycle  In this section a heuristic criterion is introduced in or- der to evaluate and compare the quality of the system responses obtained for different external signals or inter- nal parameter values.\n\n8 For this purpose, the period   œÑ   is divided into a ‚Äúday‚Äù wakefulness sub-period of length   œÑ 1   =   qœÑ   and a ‚Äúnight‚Äù sleep sub-period of length   œÑ 2   = (1   ‚àí   q ) œÑ   , with   œÑ   =   œÑ 1   +   œÑ 2 . The quantity   q   is defined as a   wake fraction .   A typical sleep-wake cycle with an eight-hour sleep sub-period has  q   = 2 / 3.   For the day corresponding to the   n -th period ( nœÑ, ( n +1) œÑ   ), the ‚Äúday‚Äù is represented by the sub-interval ( nœÑ, nœÑ   +   œÑ 1 ) = ( nœÑ,   ( n   +   q ) œÑ   ), which covers the first frac- tion   q   of the period, while the ‚Äúnight‚Äù extends in the complementary fraction (1   ‚àí   q ) of the period in the time interval ( nœÑ   + œÑ 2 , ( n +1) œÑ   ) = (( n + q ) œÑ, ( n +1) œÑ   ). For each period   n   = 0 ,   1 , . . .   , we compute wakefulness time intervals ‚àÜ t (1)  n   and ‚àÜ t (2)  n   spent by the system in the wake state during the day, ‚àÜ t (1)  n   , and night, ‚àÜ t (2)  n   . The wake/sleep state is identified with the spiking/silent regime. A simple quantitative estimate of the quality of the sleep-wake cycle can, thus, be done through the fol- lowing linear function of the wakefulness time intervals,  r (‚àÜ t (1) ,   ‚àÜ t (2) ) =   ‚àÜ t (1)  œÑ 1  ‚àí   ‚àÜ t (2)  œÑ 2  ,   (16) where ‚àÜ t ( Œ± )   =   ‚àë  n   ‚àÜ t ( Œ± )  n   /N sp ,   Œ±   = 1 ,   2, represent the average of the wakefulness time intervals during the day ( Œ±   = 1) and during the night ( Œ±   = 2), with   N sp   being the total number of periods of the simulation. The fractions ‚àÜ t ( Œ± ) /œÑ Œ±   ( Œ±   = 1 ,   2) can vary in the in- terval (0 ,   1); then the coefficient   r   in Eq. (16) is limited in the interval ( ‚àí 1 ,   1).   The maximum value   r   = 1 cor- responds to an optimal cycle with ‚àÜ t (1)   =   œÑ 1   (wakeful- ness during the entire day) and ‚àÜ t (2)   = 0 (sleep during the entire night); any deviation from the optimal state ( r   = 1) comes either from values ‚àÜ t (1)   < œÑ 1   (implying some sleep during the day) or values ‚àÜ t (2)   >   0 (meaning at least some wakefulness in the night). See the support- ing information in the Appendix for further details on the definition of the time intervals ‚àÜ t (1) , ‚àÜ t (2)   and the coefficient   r .  III.   RESULTS  In this section we study how the presence of disor- der affects the system response and discuss the main dif- ferences compared to the two-neuron model.   The term ‚Äúdisorder‚Äù is used here to refer to either   noise , i.e. dis- order in time (stochastic terms in the external current), or   diversity , i.e a quenched heterogeneity in the neuronal parameters.   These two aspects are studied separately. For the sake of simplicity, we examine the response of the system to a periodic stimulus represented by a train of short rectangular pulses as defined in Materials and Methods. In each of the examples considered, the initial con- figuration in the absence of noise and diversity is the same as the sub-threshold state illustrated in Fig. 2-right with a double-periodic response. It is obtained for a re- duced height of the current pulse   I 0   = 0 . 893 mA, while  FIG. 4:   Effect of noise in neurons   { A i } . (A). Ten periods of the raster plots of neuron B for different intensities   D A  of the noise acting on neurons   { A i } .   Vertical dashed lines mark the beginning of the pulses of the external current   I ext , see text for details. (B). Coefficient   r , from Eq. (16),   versus  current noise intensity   D A .  the other parameters are unchanged as given in Table I. The reason for starting from such an under-threshold non-optimal configuration is that it is most sensitive and, thus, best illustrates the effects of added noise or hetero- geneity. While a response with a double-periodicity may seem unrealistic, this starting configuration is intended to be an example of non-optimal response rather than a standard reference state.   In fact, in realistic situations noise and heterogeneity are always present so that such a state without noise or diversity represents a hypothet- ical system that would be obtained if one could switch off noise or replace heterogeneous synapses with perfectly identical ones. The results presented below suggest that a multi-periodic sleep-wake cycle can be turned into a regular (single-periodic) one by adding a suitable degree of disorder.\n\n9  FIG. 5:   Effect of noise in neurons   { A i } .   Sample of four periods of some relevant variables and inter-spike times   Œ¥t p  ( p   = A ,   B)   versus   time of neuron A 1   and neuron B for an intensity of noise in neurons A   D A   = 1 mA (left) and   D A   = 5 mA (right). Compare Fig. 4 and see text for details.  A.   Effect of noise  Here we investigate the effects of the noise currents in the equations for the membrane potentials.   For clarity only the cases in which noise currents are present either in the neurons A i   or in the neuron B are considered.  1.   Noise in the neurons   A i  To study the effects of the noise currents   Œæ ( i ) A   ( t ),   i   = 1 , . . . , N A   acting only on the neurons A i   (as per Eq. (11)) we set   D B   = 0.   Also, no diversity in the characteristic parameters of neurons A i   is introduced.   We have sim- ulated a system with   N A   = 20 identical neurons and a single B neuron on a time interval   t   ‚àà   (0 ,   100   œÑ   ). A raster\n\n10 plot for the activity of the neuron B at different values of   D A   (indicated on the left) is shown in Fig. 4-A. The plot shows that  ‚Ä¢   for small   D A   ‚âà   0 the system‚Äôs configuration corre- sponds to the assumed non-optimal double-periodic solution;  ‚Ä¢   the system‚Äôs response becomes slightly more regu- lar and periodic as   D A   is increased, despite the fact that the neuron cannot initiate a firing event at the beginning of each period;  ‚Ä¢   as   D A   becomes even larger the neuron B keeps fir- ing tonically for a longer and longer time interval (even longer than a single period) thus deteriorat- ing the general quality of the response. A sample of time dependence of the main variables in the interval (0 ,   4   œÑ   ) for   D A   = 1 mV and   D A   = 2 mV is illustrated in Fig. 5.   In general, the type of variabil- ity induced by noise currents acting on the neurons A i  affects both the firing initiation and, especially, its du- ration. However, it is difficult to establish an actual im- provement of the quality of such a response as a function of the noise intensity   D A , as even the coefficient   r , shown in Fig. 4-B, suggests only a mild stochastic resonant be- havior characterized by a wide plateau at intermediate values of   D A .  2.   Noise in the neuron B  Here we consider the complementary case, in which  D A   = 0 and a current noise only affects the neuron B. A sample of raster plots of the membrane potential of the neuron B is depicted in Fig. 6-A in the time window   t   ‚àà  (0 ,   10   œÑ   ) for the values of the noise intensity   D B   indicated on the vertical axis. The raster plot in Fig. 6-A indicates that:  ‚Ä¢   the smallest values of noise intensity   D B   ‚âà   0 cor- respond to the double-periodic configuration dis- cussed above;  ‚Ä¢   the response becomes periodic, and the length of the firing periods more regular for higher values of  D B ;  ‚Ä¢   at larger values of   D B   the state of sleep is frequently interrupted by almost isolated spikes at random times. A representative example of time dependence of selected variables of the neurons A 1   and B are shown in Fig. 7. Note the different type of behavior induced by a high lev- els of noise acting on the neuron B, compared to the case in which noise acts on the neurons A i . In the first case irregular switching between the firing and silent states is observed more often, especially considering the transient firings in the otherwise silent sleep state.   Furthermore,  FIG. 6:   Effect of noise in neuron B . (A). Sample of ten periods of the raster plots of neuron B for different values of the intensity   D B   of the noise acting on neuron B. Vertical dashed lines mark the beginning of the pulses of the external current   I ext , see text for details.   (B). Quality of the sleep- wake cycle from the coefficient   r , Eq. (16),   versus   current noise intensity   D B .  this random firing appears only in the neuron B, but is insufficient to also induce spiking in the A 1   neuron. This activity may represents intermittent awakenings, which are likely due to the ability of noise to favor the igni- tion of spiking events.   Such random spikes are not ob- served when noise acts on the neurons A i   only, even at much larger noise intensities. This may be related to the coupling between the neurons A i , which constrains them in the same (spiking or silent) state.   In order to excite all neurons A i   together one would need an input signal affecting all of them in the same way, which is highly improbable in a realistic system. The dependence of the coefficient   r   on   D B   is shown in Fig. 6-B. Again, only a mild stochastic resonance be- havior is suggested by the data when varying the noise intensity. It should be noted that in this particular con- figuration with noise acting only on the neuron B, the response of the neuron B does not depend on the num- ber   N A   of homogeneous neurons   { A i } , due to the equiv- alence to the configuration of the two-neuron model, as we have checked numerically. Thus, the plots of neuron A 1   in Fig. 7 are representative of all other neurons A i .\n\n11  FIG. 7:   Effect of noise in neuron B . Sample of four periods for some relevant variables and inter-spike times   Œ¥t p   ( p   = A ,   B)  versus   time for neuron A 1   and neuron B for an intensity of the noise acting on neuron B   D B   = 1 mA (left) and   D B   = 2 mA (right). Compare Fig. 6 and see text for details.  In fact, the external current   I ext ( t ) as well as the cou- pling currents are the same for each neuron A i , which produces the same response. According to the equations of the heterogeneous model, the effective current acting on the neuron B is the arithmetic average of the currents coming from the various neurons   { A i }   and, therefore, co- incides with that of any single neuron A i . We use here a homogeneous multi-neuron generalized model only for a better comparison and consistency with the rest of this study.  B.   Effects of heterogeneity  The effects introduced by a heterogeneity in the neu- rons are dramatic compared to the effects of noise. The corresponding improvement of the system response for suitable intermediate amounts of diversity can be de-\n\n12  FIG. 8:   Effect of diversity in the   B   ‚Üí   A i   synapses . (A). Sample of ten periods of the raster plots of neuron B for different heterogeneity levels   Œ¥W B , gl   in the B ‚Üí A i   glutamate synapse thresholds, see text for details.   (B). Quality of the sleep-wake cycle from the coefficient   r , Eq. (16), for various threshold diversities   Œ¥W B , gl .  tected very clearly. This is the main result of this paper and it is illustrated in this section. Noiseless neurons are assumed for easier estimation of the heterogeneity effects ( D A   =   D B   = 0). As in the study of noise described above, we carry out the study of diversity starting from the same configura- tion with a non-optimal double-periodic response to the external periodic stimulus, corresponding to a zero diver- sity (homogeneous system). Heterogeneity is then intro- duced in the glutamate-induced currents, either in the thresholds   W   ( i ) A , gl   regulating the response of the A i   ‚Üí   B synapses at the neuron B or in the thresholds   W   ( i ) B , gl   of the B ‚Üí A i   synapses at the neurons A. This is done by randomly extracting values   W   from a probability den- sity   f p ( W   ) and assigning them to the threshold param- eters   W   ( i ) p , gl   ( p   = A ,   B).   The probability density used here has a bell-shape   f p ( W   ) =   P   (( W   ‚àí   W   p , gl ) /Œ¥W p , gl ), where   P   ( x )   ‚àù   1 /   cosh( x ) 2 , the quantity   W   p , gl   =   „Äà W   „Äâ  represents the average value, while   Œ¥W p , gl   measures the dispersion of the distribution   f p ( W   ) around the aver- age value and is related to the standard deviation   œÉ p   by  Œ¥W p , gl   =   œÄœÉ p / ‚àö 12. For further details see the support- ing information in the Appendix.   The width   Œ¥W p , gl   is assumed in the following as the measure of neuronal di- versity.   In order to carry out meaningful comparisons with the homogeneous (two-neuron) model, the average values are set equal to the corresponding parameters of the homogeneous two-neuron model,  W   p , gl   ‚â°  ‚à´  dW W f p ( W   ) =   W p , gl   ,   p   = A ,   B .   (17) The other parameters are unchanged compared to the two-neuron model, see Table I.  1.   Diversity in the   B ‚Üí A i   synapses (neurons   A i )  Diversifying the potential thresholds   W   ( i ) B , gl   implies het- erogeneous glutamate synapses located at the neurons A i , see Eq. (13) and Fig. 3.   That is, each neuron A i  responds in a different way to the stimulation from the neuron B. Notice that this is a truly heterogeneous sys- tem which cannot be reduced to an effective two-neuron model‚Äîas in the case of heterogeneous synapses at neu- ron B considered in the next section. We studied a sys- tem with   N A   = 20 neurons A i   with diversified threshold parameters   W   ( i ) B , gl ,   i   = 1 , . . . , N A .   The system dynam- ics were examined for different sets of thresholds   { W   ( i ) B , gl }  extracted from distributions   f B ( W   ) with different widths  Œ¥W B , gl   but always the same average value   W   B , gl   =   W B , gl . The resulting raster plots of the activity of the neuron B are shown in Fig. 8-A, and a sample of time dependen- cies for the neurons A 1   and B is shown in Fig. 9.   The existence of an optimal degree of diversity, corresponding to a value   Œ¥W B , gl   approximately between 1 and 1 . 5mV, can be clearly seen both from Fig. 8-A and from the dependence of the coefficient   r   on the diversity degree  Œ¥W B , gl , in Fig. 8-B. The underlying mechanism leading the system from the double- to the single-periodic response as diversity is increased can be interpreted following the prototype mechanical model of diversity-induced resonance intro- duced in Ref. [3]. In this model a set of interacting os- cillators moving in a bistable potential is subjected to an external periodic force, which pushes the system toward the left and the right barrier alternately.   If the oscil- lators are identical, i.e.   they have the same parameter values corresponding to an under-threshold regime, then the system of oscillators cannot perform jumps on the other site of the barrier under the action of the applied periodic force. However, when the parameters are diver- sified (keeping constant the corresponding average value) some oscillators respond more promptly to the force and jump to the other side of the barrier, gradually pulling the rest of the system. In the present case, each neuron A i   corresponds to a nonlinear oscillator of the example, while the parameter which is diversified is the activation thresholds   W   ( i ) B , gl   of the glutamate-induced currents. To show that this is the actual mechanism in action, Fig. 10 (left) illustrates the response of the heteroge- neous system by depicting the time dependence of the\n\n13  FIG. 9:   Effect of diversity in the   B ‚Üí A i   synapses . Sample of four periods of some relevant variables and inter-spike times  Œ¥t p   ( p   = A ,   B)   versus   time for neuron A 1   and neuron B for different levels of the threshold diversity   Œ¥W B , gl   = 1 mV (left) and  Œ¥W B , gl   = 5 mV (right). Compare Fig. 8 and see text for details.  glutamate activation variables   a   ( i ) A , gl ( t ) of the neurons A i ,  i   = 1 ,   5 ,   10 ,   15 ,   20, with different values of the thresholds  W   ( i ) B , gl , at the beginning of a new period in the presence of the periodic current pulse. In Fig. 10 also the raster plots for all neurons in the same time interval are shown. One can notice that the activation variables   a   ( i ) A , gl ( t ) be- have differently from each other. Those associated to the lowest values of the activation threshold (indicated by small   i   values) respond stronger to the current pulse than those with the highest values of the threshold (largest values of   i ).   The system is observed to reach the spik- ing regime faster than in the homogeneous case, which is shown in the right part of Fig. 10 through the comparison between the glutamate activation variable of the homoge- neous system,   a A , gl ( t ), and the average activation vari- able   „Äà a A , gl ( t ) „Äâ   =   N   ‚àí 1 A  ‚àë  i   a   ( i ) A , gl ( t ) of the heterogeneous\n\n14  FIG. 10:   Effect of diversity in the   B ‚Üí A i   synapses . Comparison between the responses of the heterogeneous system (left column) and homogeneous system (right column) in the first part of the time period   t/œÑ   ‚àà   (1 ,   2) during the action of the 500 ms long current pulse starting at   t 1 /œÑ   = 1 and ending at   t 2 /œÑ   ‚âà   1 . 021.   (A) and (B) (top panels).   External current pulse.   (C) and (D) (central panels). Behavior of some representative glutamate activation variables of the heterogeneous system,   a   ( i ) A , gl ( t ) for   i   = 1 ,   5 ,   10 ,   15 ,   20 (panel (C)), and the (common) time dependence   a A , gl ( t ) of the homogeneous system activation variables (panel (D), black continuous curve); in the latter figure also the average value   „Äà a A , gl ( t ) „Äâ   =   N   ‚àí 1 A  ‚àë  i   a   ( i ) A , gl ( t ) of the heterogeneous system (dashed grey curve) is shown for comparison.   (E) and (F) (bottom panels).   Raster plots of all the neurons of the system. See text for further details.  system.   Eventually,   a A , gl ( t )   ‚Üí   0 and the homogeneous system goes back to the silent state, while the average ac- tivation variables of the heterogeneous system (and their average   „Äà a   ( i ) A , gl ( t ) „Äâ ) continue to oscillate around positive values, signaling the stability of the reached firing state.  2.   Diversity in the   A i ‚Üí B   synapses (neuron B)  In order to study the effects of added heterogeneity in the glutamate synapses located at the neuron B, one has to diversify the potential threshold parameters   W   ( i ) A , gl , see Eq. (14). For this particular case, it is possible to simplify the model into a two-neuron model with a single effective AB coupling. This is possible because heterogeneity only enters Eq. (14), while other model equations reduce to the same equations in the case of identical neurons A i , so that all neurons A i   behave in the same way. Thus, the effective glutamate-induced current to the neuron B is  I eff   ( V   ) =   1  N A  N A ‚àë  i =1  [  Œ¶( S gl ( V A   ‚àí W   ( i ) A , gl ))  ]  ‚âà  ‚à´  dW f   ( W   ) Œ¶( S gl ( V A   ‚àí W   ))   ,   (18) where   V A   is the common value of the membrane poten- tials of the neurons A i . Here   f   ( W   ) is the probability den- sity of the corresponding thresholds   W   =   W   ( i ) A , gl , which is assumed to be the same bell-shaped probability den- sity   f   ( W   ) =   P   (( W   ‚àí   W   ) /Œ¥W   ) as discussed above, with  W   =   W A , gl   and   Œ¥W   =   Œ¥W A , gl . We now consider two limiting cases of the effective cur- rent given by Eq. (18).   In the limit   Œ¥W   ‚â™   S ‚àí 1 gl   , when diversity is very small on the scale   S ‚àí 1 gl   , it can be as- sumed that the following approximation holds,   f   ( W   ) =  P   (( W   ‚àí   W   ) /Œ¥W   )   ‚âà   Œ¥ ( W   ‚àí   W   ) and the integral (18) can be reduced to the homogeneous result,  I eff   ( V   )   ‚âà  ‚à´  dW Œ¥ ( W   ‚àí   W   ) Œ¶( S gl ( V A   ‚àí W   )) = Œ¶( S gl ( V A   ‚àí W   ))   .   (19)\n\n15  FIG. 11:   Effect of diversity in the   A i ‚Üí B   synapses.   (A). Sample of ten periods of raster plots of neuron B for different heterogeneity levels   Œ¥W A , gl   in the A i   ‚Üí B glutamate synapse thresholds, see text for details.   (B). Coefficient   r , Eq. (16), for various degrees of diversity   Œ¥W A , gl .  In the complementary limit of high diversity level,   Œ¥W   ‚â´  S ‚àí 1 gl   , the smooth function Œ¶( S gl ( V A ‚àí W   )) can be approx- imated with Heaviside step functions Œò( W ‚àí V A ), and the effective current becomes  I eff   ( V   )   ‚âà  ‚à´  dW f   ( W   ) Œò( W   ‚àí V A ) =  ‚à´  dW P   (( W   ‚àí   W   ) /Œ¥W   ) Œò( W   ‚àí V A ) =   Œ¶(( V A   ‚àí W   ) /Œ¥W   )   .   (20) This follows from the form of the chosen distribution,  P   ( x )   ‚àù   1 /   cosh( x ) 2   =   ‚àí 4   d Œ¶( x ) /dx . Thus, in both these limiting cases the effective current can be written in the form   I eff   ( V   )   ‚âà   Œ¶( Œª ( V A ‚àí W   )), with   Œª   =   S gl   for   Œ¥W   ‚â™   S ‚àí 1 gl  and   Œª   =   Œ¥W   ‚àí 1   for   Œ¥W   ‚â´   S ‚àí 1 gl   . It is interesting that, as we have checked by numerical integration of Eq. (18), the same analytical form also holds for intermediate values of   Œ¥W   and   S ‚àí 1 gl   , so to a very good approximation the ef- fective current can be written as   I eff   ( V   )   ‚âà   Œ¶( Œª ( V A ‚àí W   )), where the parameter   Œª   depends on the ratio   Œ¥W/S ‚àí 1 gl   and varies monotonously between   S gl   and   Œ¥W   ‚àí 1 , as   Œ¥W/S ‚àí 1 gl  varies between 0 and   ‚àû . The system‚Äôs response at different levels of heterogene- ity,   Œ¥W A , gl , is presented in Fig. 11-A through the raster plots for the neuron B. A sample of time dependence is shown in Fig. 12, while Fig. 11-B shows the dependence of the coefficient   r   on the diversity level.   In Fig. 11, it can be seen that for small values of the diversity   Œ¥W A , gl  the response of the neuron B presents the double peri- odicity of the reference configuration. Single periodicity is recovered for higher levels of diversity. At even higher values of   Œ¥W A , gl , the coefficient   r   begins to decrease. The points of the curve corresponding to the highest values of  r   suggest an optimal degree of diversity   Œ¥W A , gl   ‚âà   1 mV. The main difference compared to the case in which noise intensity is varied, is that the response of the sys- tem remains more regular also at the highest levels of diversity considered, i.e. without random spikes appear- ing during the silent state and with a typical cycle well shared between a day and a night sub-period.  IV.   DISCUSSION  In the present work we have introduced a heteroge- neous multi-neuron version of the previously developed physiologically motivated model of the homeostatic reg- ulation of sleep.   The multi-neuron model is composed of a population of conductance-based orexin-producing neurons and a single representative glutamatergic neu- ron.   In this model the glutamatergic and orexinergic neurons are undergoing transitions between firing and silence depending on the external circadian input and in- ternal homeostatic mechanisms. These transitions corre- spond to the transitions between wake (firing) and sleep (silence), with the homeostatic mechanism being depen- dent on the availability of orexin. The specific aim of this study was to explore the ef- fects of noise and diversity in the regulation of sleep- wake cycles in such a model.   It is clear that diversity and noise are integral parts of all biological systems, in- cluding the orexinergic neuronal population in the lateral hypothalamus. However, the role of disorder, and espe- cially diversity, is rarely considered in the physiologically based mathematical models of sleep-related systems [29‚Äì 35]. To our knowledge, diversity had so far been included only in one such model, i.e. the model of interacting cir- cadian oscillators [5], and here we present another exam- ple of the constructive role of diversity in regulation of sleep. We have demonstrated the existence of a diversity- induced resonance, leading to a clear and strong im- provement of the quality of the sleep-wake cycles, at a physiologically justified   intermediate level of diver- sity of the orexin-producing neurons.   However, only a mild improvement was found with varying noise inten- sity (stochastic resonance phenomena). We have considered the simplest system with only 20 heterogeneous orexin neurons and one local glutamate neuron.   Also we have used a very simple all-to-all net- work topology for the connections among orexinergic neurons. However, it can be expected that constructive effects of diversity will be found also in other model con-\n\n16  FIG. 12:   Effect of diversity in the   A i ‚Üí B synapses. Sample of four periods of the time dependence of some relevant system variables and inter-spike times   Œ¥t p   ( p   = A ,   B) of neuron A 1   and neuron B for a threshold diversity   Œ¥W A , gl   = 1 mV (left) and  W A , gl   = 5 mV (right). Compare Fig. 11 and see text for details.  figurations.   In the future, more realistic modifications of the model with a larger population of glutamatergic neurons and more sophisticated inter-populations con- nections should be considered.   Furthermore, in the fu- ture studies interplay between noise and diversity should likewise be investigated, since in nature both types of disorder are normally present. The validity of the result obtained within this model may be more general, since diversity-induced resonance is known to take place for suitable values of the parameters in general networks of interacting (non-linear) oscillators. A question then naturally arises: whether the phenomena encountered here could also characterize other systems where there is a coupling between two very different time scales or, in other words, if homeostatically regulated bi- ological systems may take advantage from a suitable level of heterogeneity of their components.\n\n17  Acknowledgments  We acknowledge financial support from the EU NoE BioSim, LSHB-CT-2004-005137, and project FIS2007- 60327 (FISICOS) from MINECO and FEDER (Spain). M.P. acknowledges financial support from the Estonian Ministry of Education and Research through Project No. SF0690030s09 and the Estonian Science Foundation via grants no. 7466 and no. 9462. S.P. acknowledges funding from ARC and NHMRC.  Appendix A: Supporting information: further details on the numerical simulation 1.   Evaluation of the wake and sleep times  The   quality   of   a   sleep-wake   cycle   was   estimates through the coefficient   r   = ‚àÜ t (1) /œÑ 1   ‚àí   ‚àÜ t (2) /œÑ 2 , where ‚àÜ t ( Œ± )   represents the wakefulness time interval during the day ( Œ±   = 1) or night ( Œ±   = 2), while   œÑ 1   and   œÑ 2   represent the length of day and night, respectively. This coefficient can vary between a minimum value   r   =   ‚àí 1, representing an exchange of wakefulness and sleep between day and night, and a maximum value   r   = 1, corresponding to the optimal situation with wakefulness during the whole day time interval ‚àÜ t (1)   =   œÑ 1   and continuous sleep during the whole night interval, ‚àÜ t (2)   = 0. For a more realistic esti- mate of the quality of the sleep-wake cycle the two wake- fulness time intervals ‚àÜ t (1)   and ‚àÜ t (2)   were computed in slightly different ways, as described below.  Estimating wakefulness during the day:   ‚àÜ t (1) . In order to estimate the wakefulness during the day, when an individual is supposed to be awake, we have consid- ered the quality of wakefulness by computing ‚àÜ t (1)   from states characterized by an ‚Äúeffective wakefulness‚Äù in a tonic firing regime.   On the other hand, isolated spikes, which break a sleep period, did not contribute to the wakefulness interval and were neglected:   such isolated spikes can at most represent a fragmented wakefulness state, similar to that of a narcoleptic individual. A tonic spiking state was recognized checking if the inter-spike time was smaller than a suitable threshold   œÑ max ; in this case such an inter-spike interval was added to the total wakefulness time interval ‚àÜ t (1) wake . On the other hand, if the corresponding inter-spike time was larger than the threshold   œÑ max , then the two corresponding spikes were considered to be isolated and that time interval was ne- glected. Notice that in general inter-spike times are not universal and vary with external parameters; for this rea- son a value   œÑ max   = 100 ms was chosen heuristically, con- sidering the typical working conditions of the system.  Estimating wakefulness during the night:   ‚àÜ t (2) . As for the night is concerned, it is the quality of sleep which contributes to the overall quality of the sleep-wake cycle. Therefore, on the difference of ‚àÜ t (1) , we have com- puted ‚àÜ t (2) , the wakefulness period during night, includ- ing also short wakefulness events (isolated spikes), since they break the sleep period, thus worsening the quality of sleep. Each isolated spike is assumed to contribute a conventional time interval, assumed as   œÑ max   for simplic- ity. The difference between the two mentioned ways to evaluate wakefulness periods is relevant at high level of noise, which produces many isolated spikes.  2.   Extraction of parameters with a given distribution  The different values of the glutamate thresholds   { W i }  of neurons   { A i } , which make neurons A heterogeneous, were extracted using the probability distribution  f   ( W   ) =   1  2   Œ¥W   cosh 2 [( W   ‚àí   ¬Ø W   ) /Œ¥W   ]   .   (A1) Here   ¬Ø W   =   ‚à´   dW W f   ( W   ) is the average value and the parameter   Œ¥W   measures the dispersion of the distribu- tion around  ¬Ø W   . It is proportional to the standard devia- tion   œÉ , namely, it is related to the variance according to  œÉ 2   ‚â° „Äà ( W   ‚àí   ¬Ø W   ) 2 „Äâ   =   œÄ 2 Œ¥W   2 / 12. The function (A1) can be integrated to obtain the lower cumulative distribution function   F   ( x ),  F   ( W   ) =   1  2  { 1 + tanh[( W   ‚àí   ¬Ø W   ) /Œ¥W   ] }  =   1  1 + exp[ ‚àí 2( W   ‚àí   ¬Ø W   ) /Œ¥W   ]   .   (A2) Simulations were made by using various sets of A-neuron thresholds   { W i }   obtained by rescaling the values of a same set of thresholds by   Œ¥W   .   This can be done for example by inverting the same uniform distribution of values   { F i }   and using distributions   F   ( W   ) corresponding to the different desired values of   Œ¥W   . For all the param- eter sets   { W i }   used the average value   „Äà W   „Äâ   was the same. For a few set of parameters we have checked that equiva- lent results are obtained by first extracting randomly the parameters from the distribution   F   ( x ) with the desired  Œ¥W   and then averaging the final results obtained. In the latter case the set of values   { F i }   are extracted randomly in the interval   F i   ‚àà   (0 ,   1).\n\n18  [1] C. von Economo,   Cellular Structure of the Human Cere- bral Cortex   (S. Karger AG, Basel, 2009). [2] D. Gerashchenko and P.J. Shiromani, Mol. Neurobio.   29 , 41 (2004). [3] C. Tessone, C. Mirasso, R. Toral, and J. Gunton, Phys. Rev. Lett.   97 , 194101 (2006). [4] C. J. Tessone, A. Scir¬¥ e, R. Toral, and P. Colet, Phys. Rev. E   75 , 016203 (2007), ISSN 1539-3755. [5] N. Komin, A. Murza, E. H. Garc¬¥ ƒ±a, and R. Toral, Inter- face Focus   1 , 167 (2010). [6] R. D. Astumian, Science   276 , 917 (1997). [7] F. Gassmann, Phys. Rev. E   55 , 2215 (1997). [8] M. Zaks, X. Sailer, L. Schimansky-Geier, and A. Neiman, CHAOS   15 , 026117 (2005). [9] B.   Lindner,   J.   Garc¬¥ ƒ±a-Ojalvo,   A.   Neiman,   and L. Schimansky-Geier, Phys. Rep.   392 , 321 (2004). [10] Wiesenfeld K. and Moss F., Nature   373 , 33 (1995). [11] L. Gammaitoni, P. H¬® anggi, P. Jung, and F. Marchesoni, Rev. Mod. Phys.   70 , 223 (1998). [12] A. Longtin, J. Stat. Phys.   70 , 309 (1993). [13] H. Braun, H. Wissing, K. Schafer, and M. Hirsch, Nature  367 , 270 (1994). [14] S. Bezrukov and I. Vodyanoy, CHAOS   8 , 557 (1998). [15] A. Longtin, Phys. Rev. E   55 , 868 (1997). [16] D. Chialvo, A. Longtin, and J. M¬® uller-Gerking, Phys. Rev. E   55 , 1798 (1997). [17] A.   Neiman,   A.   Silchenko,   V.   Anishchenko,   and L. Schimansky-Geier, Phys. Rev. E   58 , 7118 (1998). [18] S. Postnova, K. Voigt, and H. A. Braun, J. Biol. Rhythms  24 , 523 (2009). [19] C. Peyron, D. K. Tighe, A. N. van den Pol, L. de Lecea, H. C. Heller, J. G. Sutcliffe, and T. S. Kilduff, J Neurosci  18 , 9996 (1998), ISSN 0270-6474. [20] K. Yoshida, S. McCormack, R. A. EspaÀú na, A. Crocker, and T. E. Scammell, J Comp Neurol   494 , 845 (2006), ISSN 0021-9967. [21] R. Winsky-Sommerer, A. Yamanaka, S. Diano, E. Borok, A. J. Roberts, T. Sakurai, T. S. Kilduff, T. L. Horvath, and L. de Lecea, J. Neurosci.   24 , 11439 (2004). [22] T. Sakurai, Nature Rev. Neurosci.   8 , 171 (2007), ISSN 1471-003X. [23] Li Y., Gao X.B., Sakurai T., and van den Pol A.N., Neu- ron   36 , 1169 (2002). [24] A. Borb¬¥ ely, Hum. Neurobiol.   1 , 195 (1982). [25] Eggermann E., Bayer L., and Serafin M., J. Neurosci.   23 , 1557 (2003). [26] A. A. Borb¬¥ ely and P. Achermann, in   Principles and prac- tice of sleep medicine , edited by M. Kryger and T. R. & W.C. Dement (W.B. Saunders Company, Philadelphia, 2000), pp. 377‚Äì390. [27] A. L. Hodgkin and A. F. Huxley, J. Physiol.   117 , 500 (1952). [28] M. San Miguel and R. Toral, in   Instabilities and Nonequi- librium Structures VI , edited by E. Tirapegui, J. Mar- tinez, and R. Tiemann (Kluwer Academic Publishers, Dordrecht, 2000), Nonlinear Phenomena and Complex Systems, pp. 35‚Äì130. [29] M.   Bazhenov,   I. Timofeev,   M.   Steriade,   and   T.   Se- jnowski, J. Neurosci.   22 , 8691 (2002). [30] S. Hill and G. Tononi, J. Neurophysiol.   93 , 1671 (2005). [31] C. Diniz Behn, E. Brown, T. Scammell, and N. Kopell, J. Neurophysiol.   97 , 3828 (2007). [32] J. Best, C. Diniz Behn, G. Poe, and V. Booth, J. Biol. Rhythms   22 , 220 (2007). [33] C. Diniz Behn, N. Kopell, E. Brown, T. Mochizuki, and T. Scammell, J. Neurophysiol.   99 , 3090 (2008). [34] M. Fleshner, V. Booth, D. Forger, and C. D. Behn, Phil. Trans. R. Soc. A   369 , 3855 (2011). [35] K. Williams and C. Diniz Behn, J. Biol. Rhythms   26 , 171 (2011).",
    "Sleep-time Compute: Beyond Inference Scaling at Test-time  Kevin Lin   1 ‚àó   Charlie Snell   2 ‚àó  Yu Wang   1   Charles Packer   1   Sarah Wooders   1   Ion Stoica   1 2   Joseph E. Gonzalez   1 2 1 Letta   2 University of California, Berkeley  research@letta.com  Abstract  Scaling test-time compute has emerged as a key ingredient for enabling large language models (LLMs) to solve difficult problems, but comes with high latency and inference cost. We introduce sleep-time compute, which allows models to ‚Äúthink‚Äù offline about contexts before queries are presented: by anticipating what queries users might ask and pre-computing useful quantities, we can significantly reduce the compute requirements at test-time. To demonstrate the efficacy of our method, we create modified versions of two reasoning tasks ‚Äì Stateful GSM-Symbolic and Stateful AIME. We find that sleep-time compute can reduce the amount of test-time compute needed to achieve the same accuracy by   ‚àº   5 √ó   on Stateful GSM-Symbolic and Stateful AIME and that by scaling sleep-time compute we can further increase accuracy by up to 13% on Stateful GSM-Symbolic and 18% on Stateful AIME. Furthermore, we introduce Multi-Query GSM-Symbolic, which extends GSM-Symbolic by including multiple related queries per context. By amortizing sleep-time compute across related queries about the same context using Multi-Query GSM-Symbolic, we can decrease the average cost per query by 2.5 √ó . We then conduct additional analysis to understand when sleep-time compute is most effective, finding the predictability of the user query to be well correlated with the efficacy of sleep-time compute. Finally, we conduct a case-study of applying sleep-time compute to a realistic agentic SWE task. Code and data released at: https://github.com/letta-ai/sleep-time-compute.  1   Introduction  Test-time scaling has emerged as an effective way to boost LLM performance on challenging tasks by spending more time thinking on difficult problems (OpenAI, 2024; DeepSeek-AI, 2024; Snell et al., 2024; Brown et al., 2024). However, improved performance from test-time compute comes at a significant increase in latency and cost, waiting potentially several minutes for answers and costing up to tens of dollars per query. 1   These drawbacks are in part due to the fact that the current approach to applying test-time compute assumes that problems are stateless, i.e. queries (user queries at test-time) and the contexts (background information) required for answering them are provided to the model together at ‚Äútest-time.‚Äù In practice, this means that if multiple related queries require making similar inferences about the context at ‚Äútest-time,‚Äù the model will have to recompute redundant computations each time, incurring additional latency and cost. In reality, many LLM applications are   inherently stateful , and work in conjunction with persisted, re-used context. A classic example is document question-answering, where documents contextualize responses to questions. Coding agents also operate on a large common repository and participate in multiple rounds of debugging support, while conversational assistants need to maintain the past dialogue. In all these applications, there is context (available documents, a codebase, or conversation history) that is already available before the next user input.  1 https://platform.openai.com/docs/models/o1-pro  arXiv:2504.13171v1 [cs.AI] 17 Apr 2025\n\nApply compute\n at sleep-time  Sleep-time   compute reduces   compute test-time  A juggler can juggle 800 balls. A quarter of the balls are tennis balls, which means there are 200 tennis balls (800 * 1/4). Half of the tennis balls are indigo, resulting in 100 indigo tennis balls (200 * 1/2). Out of these indigo tennis balls, 1/10 are marked, which gives us 10 marked indigo tennis balls (100 * 1/10). Therefore, the total number of marked balls is 10 marked indigo tennis balls.  Learned Context  Standard   compute setting\n No compute applied at  test-time   sleep-time  Sleep Time   Test Time  The answer is 10.  Q1: How many marked indigo tennis balls are there?  Q1: How many marked indigo tennis balls are there?  Q2: How many tennis balls are there?  Q2: How many tennis balls are there?  The answer is 200.  LLM  LLM  LLM  LLM  LLM  LLM  LLM  A juggler can juggle 800 balls. 1/4 of the balls are tennis balls, and 1/2 of the tennis balls are indigo of which 1/10 are marked.  A juggler can juggle 800 balls. 1/4 of the balls are tennis balls, and 1/2 of the tennis balls are indigo of which 1/10 are marked.  Raw Context  Raw Context   To solve the problem, we will follow these steps :   ** Total   B alls ** : The juggler can juggle a total of 800 balls. \\\\ n \\\\ n2.   ** Tennis  B alls   C alculation ** :   W e know that 1/4 of the total balls ...   ... ... ... The answer is 10.  To find out how many tennis balls there are, we can follow these steps :\\\\ n \\\\ n1.   ** Total  B alls ** : The juggler can juggle a total of 800 balls. \\\\ n \\\\ n2.   ** Tennis   B alls   C alculation ** :  W e know that   ... ... The answer is 200. Figure 1: Example of applying sleep-time compute on Multi-Query GSM-Symbolic-P1. Sleep-time compute processes the original raw context, adding additional computations that can potentially be useful for future queries. Moreover, contexts can be shared across related queries enabling savings in total cost per query. In these settings, we could in principle, make useful inferences about the current state (context) offline before, or even during the user‚Äôs next input. We refer to such a process, as sleep-time compute: where inference is done between interactions with the model while it would otherwise be idle in   sleep -time. In practice, this is achieved by prompting the model to generate a new context consisting of inferences about the existing context, which may be potentially useful for answering test-time queries. The re-represented context from sleep-time can then be provided in the prompt at test-time, enabling the model to respond to user queries at the accuracy of standard test-time compute but with far lower latencies. For example, a coding assistant at sleep-time may identify architectural patterns, anticipate potential debugging strategies, or infer optimizations prior to the user input. Moreover, users might ask multiple queries about the same context. In these settings, any inferences made during sleep-time can be shared across queries, effectively amortizing the cost of sleep-time compute and reducing the total average cost per query. To evaluate sleep-time compute, we modify two mathematical reasoning datasets to introduce two datasets ‚Äì Stateful GSM-Symbolic and Stateful AIME ‚Äì by splitting the existing problems in these datasets into a context and a question. Using these datasets, we aim to empirically understand the benefits of sleep-time compute on standard test-time compute benchmarks. We show that: ‚Ä¢   Sleep-time compute produces a pareto improvement in the test-time compute vs. accuracy curve, reducing the test-time compute needed to achieve the same accuracy by   ‚àº   5 √ó   on Stateful GSM- Symbolic and Stateful AIME. 2\n\n‚Ä¢   By scaling up sleep-time compute, we see further pareto improvements, shifting the accuracy up by 13% on Stateful GSM-Symbolic and 18% on Stateful AIME. ‚Ä¢   By amortizing sleep-time compute across multiple queries for the same context, we can reduce the average cost per question by 2.5 √ó . ‚Ä¢   We conduct analysis to understand which queries benefit the most from sleep-time compute, finding that sleep-time compute is more effective in settings where the query is more easily predictable from the context. Finally, we end with case study of applying sleep-time compute to reduce test-time compute in a realistic agentic software engineering task.  2   Related Work  Scaling test-time compute.   Our work builds on recent progress on scaling up computation at test-time for difficult reasoning problems (Snell et al., 2024; DeepSeek-AI, 2024; OpenAI, 2024). Two predominant approaches to test-time scaling have emerged: sequential test-time scaling (OpenAI, 2024; DeepSeek-AI, 2024; Muennighoff et al., 2025; Snell et al., 2024) and parallel test-time scaling (Brown et al., 2024; Snell et al., 2024). While sequential test-time scaling has demonstrated impressive performance improvements, parallel test-time scaling has the advantage of scaling test-time compute without increasing latency. In constrast, we propose an alternative dimension where existing advancements in test-time compute, both sequential and parallel can be applied. Namely, instead of performing inference purely at test-time, we leverage compute on contexts that are available before the actual query arrives.  Speculative decoding in LLMs.   Speculative decoding is a standard technique for reducing latency in decoding with LLMs (Leviathan et al., 2023; Stern et al., 2018; Cai et al., 2024; DeepSeek-AI et al., 2025). Sleep-time compute similarly targets reducing reasoning latency by speculating on the   user‚Äôs query   as well as any potentially helpful reasoning over the context. However, unlike speculative decoding, the generated tokens are used as an input regardless of the user‚Äôs actual query, and at test-time the reasoning model uses these generated tokens to help answer the user query more efficiently.  Pre-computation.   Beyond LLMs, a long history of work has explored the trade-off between pre- computation and memory (eg. memory caches Smith (1982) and data cubes for OLAP workloads Gray et al. (1997)). Our work explores the same trade-off between query latency and pre-computation overhead, operating under the assumption that query workload patterns can be reasonably anticipated in advance. sleep-time compute builds on the idea of pre-fetching in traditional operating systems, in the context of LLMs   ` a la Packer et al. (2023), storing frequently used computational results to avoid higher latency at test-time.  3   Sleep-time Compute  In the standard paradigm of applying test-time compute, a user inputs a prompt   p   to the LLM and then the LLM applies test-time compute to help answer the user‚Äôs question. However, the   p   provided to the LLM can oftentimes be decomposed into a pre-existing context   c   (eg. a codebase) and a user query   q   (eg. a question about the codebase). When the LLM is not actively responding to the user, it typically still has access to the existing context   c . During this time, the LLM is typically idling, missing the opportunity to reason about   c  offline: a process we term sleep-time compute. 3\n\nTest-time compute.   In the test-time compute setting, the user provides   q   along with some context   c   and the model outputs a reasoning trace followed by a final answer   a . We denote this process, as:   T B ( q ,   c )   ‚Üí   a , where   T   is the method for using test-time compute with budget   B , which could include techniques like extended chains of thought or best-of-N. In practice, the user may have multiple queries about the same context   q 1 ,   q 2   ...   q N   . In this setting, the model will carry out independent reasoning processes for each  q i , even if they are related to the same context   c . Ideally, we would be able to reuse related inferences across each   q i   to save compute.   Moreover, in many cases,   c   is complex and may require carrying out significant processing/inferences in order to provide an answer to   q . Since, the test-time compute paradigm of   T ( q ,   c )   ‚Üí   a   assumes that   c   is only available at the same time as   q , standard test-time compute carries out all of these inferences only after the user provides the query, causing the user to wait up to several minutes for a response. However, in practice we often have access to   c   before   q   and can carry out much of this processing ahead of time.  Sleep-time compute.   During sleep-time we are given the context   c   but not the query   q . Using just this context   c , we can use the LLM to infer likely questions and reason about the context ultimately producing a more new re-represented context   c ‚Ä≤ . We denote this process as:   S ( c )   ‚Üí   c ‚Ä≤ , where   S   can be any standard test-time scaling technique applied towards pre-processing the context at sleep-time. In this work,   S ( c )  is implemented by prompting the model to draw inferences and re-write   c   in a way that might be useful at test-time (see Appendix K for more details). After pre-processing the context, we can provide the new context   c ‚Ä≤   at test-time in place of   c   to produce a final answer to the user‚Äôs query:   T b ( q ,   c ‚Ä≤ )   ‚Üí   a . Since much of the reasoning about   c   has been done ahead of time in this case, we can use a much smaller test-time budget  b   <<   B . Moreover,   c ‚Ä≤   can be shared across different queries   q i   about the same context, effectively amortizing the compute required to arrive at   c ‚Ä≤   across queries, providing a total cost saving.  4   Experimental Setup  Next, we describe the datasets, models, and baselines we use to evaluate sleep-time compute.  4.1   Datasets  We select datasets which represent standard benchmarks for LLM reasoning and test-time scaling, and which demonstrate improvements from scaling test-time compute with state-of-the-art LLMs (either reasoning or non-reasoning).  Stateful datasets.   We introduce two datasets to study applying sleep-time compute in stateful settings, Stateful GSM-Symbolic, and Stateful AIME, where each dataset is derived from splitting the existing datasets into a context and a question (see Figure 2 for an example). Stateful GSM-Symbolic is derived from the P1 and P2 splits of GSM-Symbolic (Mirzadeh et al., 2024), which add one and two clauses respectively to the original GSM8K dataset (Cobbe et al., 2021) to that increase the difficulty. GSM-Symbolic P1 contains 5000 examples and P2 2500 examples. Stateful AIME contains 60 questions combined from AIME 2024 and 2025. In Appendix L and M, we show the breakdown of our results across AIME 2024 and 2025.  Amortization dataset.   To study the effect of related questions that share context, we introduce a new dataset Multi-Query GSM-Symbolic, where each context has multiple queries. To generate multiple queries for a given context, we take Stateful GSM-Symbolic and use o3-mini to generate additional question answer pairs. We synthetically generate additional questions from existing context question pairs in GSM-Symbolic. Appendix C shows the prompt used to generate the additional questions. Figure 20 shows examples contexts 4\n\nGSM-Symbolic (original)\n   Stateful GSM-Symbolic (ours)  A juggler can juggle 800 balls. 1/4 of the balls are tennis balls, and 1/2 of the tennis balls are indigo of which 1/10 are marked. How many marked indigo tennis balls are there?\n\n  Context\n Query  A juggler can juggle 800 balls. 1/4 of the balls are tennis balls, and 1/2 of the tennis balls are indigo of which 1/10 are marked.  Query  How many marked indigo tennis balls are there?\n Figure 2: Example of separating an instance from GSM-Symbolic into context, and question, creating an instance in Stateful GSM-Symbolic. and set of questions from the Multi-Query GSM-Symbolic dataset and Table C shows the overall dataset statistics.  4.2   Models and Baselines Models.   On each dataset, we evaluate models which have poor performance when using a small amount of test-time compute, but yield improvements from scaling up test-time compute. Therefore, on GSM-Symbolic, we conduct experiments using GPT-4o-mini and GPT-4o, and on AIME, we conduct experiments using OpenAI‚Äôs o1, o3-mini, Anthropic‚Äôs Claude Sonnet 3.7 Extended Thinking , and Deepseek-R1 (DeepSeek-AI, 2024).   2 3  Baselines   The main baseline we consider is the standard test-time compute setting in which both   c   and  q   are presented to the model for the first time at test-time. Furthermore, to validate that   q   is not trivially predictable from   c   on our Stateful GSM-Symbolic and Stateful AIME datasets, we also compare to a context- only baseline in Appendix I, in which the model is only given   c   and is tasked with directly guessing an answer to the question it guesses is most likely to come next.  5   Experiments and Results  In this section, we carry out experiments to understand the benefits of sleep-time compute. Specifically, we would like to answer each of the following questions using the math reasoning benchmarks introduced above: 1. Can sleep-time compute shift the pareto frontier of test-time compute vs. accuracy? 2. Does scaling sleep-time compute in-turn improve the pareto further?  2 https://openai.com/o1/  3 https://www.anthropic.com/claude/sonnet  5\n\n100   200   300   400   500  Avg. Test Time Tokens / Question  0.2  0.4  0.6  0.8  Accuracy  GSM8K-Symbolic P1  0   100   200   300   400   500   600  Avg. Test Time Tokens / Question  0.2  0.4  0.6  0.8  Accuracy  GSM8K-Symbolic P2  gpt-4o-mini  gpt-4o-mini + sleep-time compute  gpt-4o  gpt-4o + sleep-time compute Figure 3: The test-time compute vs. accuracy tradeoff for on Stateful GSM-Symbolic. Shaded area indicates where sleep-time compute improves the pareto test-time accuracy trade-off. 3.   When there are multiple related questions for a single context, can amortizing test-time compute with sleep-time compute provide a total token efficiency benefit? 4. In what settings does sleep-time compute provide the most uplift?  5.1   Improving Pareto Test-Time Trade-off with sleep-time compute  We first determine the test-time compute, accuracy pareto frontier by scaling standard test-time compute sequentially and in parallel. We then study how applying sleep-time compute affects the pareto trade-off.  Scaling test-time-compute sequentially.   For non-reasoning models (GPT-4o and 4o-mini) on Stateful GSM-Symbolic, to vary the amount of test-time compute, we construct prompts that instruct the model to use different amounts of verbosity at test time, eg. ‚Äúanswer directly with a single sentence‚Äù vs. ‚Äúdouble check your reasoning before outputting the final answer.‚Äù The full prompts are in Appendix A. We use temperature 0 for generation. We see in Figure 3 that there is a tradeoff between accuracy and the amount of test-time compute, and that adding sleep-time compute can move beyond the pareto compute-accuracy curve. In particular, at lower test-time budgets, the performance of sleep-time compute is significantly better than the baseline, achieving performance comparable to that of the baseline with 5 √ó   less test-time tokens. However, at the test-tome compute budgets, the test-time compute only baseline slightly outperforms sleep-time compute. We hypothesize that this may be because the standard test-time compute only has the content relevant to the specific question, so there is less distracting information in the prompt. For reasoning models on Stateful AIME, we scale the amount of test-time compute based on what is available in the API in the case of o1, o3-mini and Claude Sonnet 3.7. Since the Deepseek-R1 API does not provide a way to control test-time compute, we apply the ‚Äùbudget forcing‚Äù and extension prompt from Muennighoff et al. (2025). Figure 4 shows the results for each model on Stateful AIME. We average results over 3 runs for o1, o3-mini and R1. For Claude 3.7 Sonnet, we average over 10 runs as we observed more noise in initial experiments. On all models, we see a significant test-time, accuracy pareto shift from applying sleep-time compute, with the exception of o1, which demonstrates limited gains. 6\n\n1000   2000   3000   4000   5000   6000   7000   8000  Avg. Test Time Tokens / Question  0.4  0.5  0.6  0.7  0.8  Accuracy  o3-mini - Stateful-AIME  2000   4000   6000   8000   10000  Avg. Test Time Tokens / Question  0.45  0.50  0.55  0.60  0.65  0.70  0.75  0.80  Accuracy  o1 - Stateful-AIME  2500   5000   7500   10000   12500   15000   17500   20000   22500  Avg. Test Time Tokens / Question  0.250  0.275  0.300  0.325  0.350  0.375  0.400  0.425  0.450  Accuracy  Claude 3.7 Sonnet - Stateful-AIME  1000   2000   3000   4000   5000   6000  Avg. Test Time Tokens / Question  0.1  0.2  0.3  0.4  0.5  0.6  Accuracy  DeepSeek R1 - Stateful-AIME  sleep-time compute   test-time compute only Figure 4: The test-time compute vs. accuracy tradeoff on Stateful AIME for various reasoning models. Applying sleep-time compute allows models to reach similar levels of performance with much less compute at test-time. The shaded area indicates the pareto improvement from sleep-time compute.  Scaling test-time compute in parallel.   An alternative approach to scaling test-time compute is via parallel sampling, which also has the benefit of maintaining low inference latency. The simplest approach to scaling parallel test-time compute is pass@k (Brown et al., 2024), which makes the unrealistic assumption of having oracle query access to a ground truth verifier at test-time, an assumption which we do not make with sleep- time compute. Therefore, outperforming the pass@k baseline would represent a meaningful improvement over parallel test-time scaling. We apply parallel scaling to the lowest sequential compute setting on each task, since scaling pass@k with higher sequential compute settings would quickly reach token budgets that exceed that of sleep-time compute in the maximum sequential setting. We see that across all tasks and models, sleep-time compute consistently outperforms pass@k parallel scaling at the same test-time token budget, demonstrating that sleep-time compute can be a more effective way to scale inference-time compute than standard parallel test-time scaling. 7\n\n100   200   300   400  Avg. Test Time Tokens / Question  0.2  0.4  0.6  0.8  Accuracy  GSM8K-Symbolic P1  100   200   300   400   500  Avg. Test Time Tokens / Question  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  Accuracy  GSM8K-Symbolic P2  gpt-4o-mini  gpt-4o-mini + background scaling  gpt-4o  gpt-4o + background scaling Figure 5: Comparing test-time scaling with sleep-time compute against parallel test-time scaling with pass@k on Stateful GSM-Symbolic. We see that sleep-time compute generally pareto dominates pass@k.  5.2   Scaling up sleep-time compute  We would like to understand how scaling compute during sleep-time can further effect the pareto shift that we observed in Section 5.1. To scale up the amount of sleep-time compute, for non-reasoning models, we run   k   parallel generations, given input   c , resulting in   c 1 ,   . . .   ,   c k . At test-time, the model then receives the inputs concatenated   c 1 ,   . . .   ,   c k   to generate the final answer. On reasoning models, we scale up the amount of sleep-time compute by varying the reasoning effort for o1 and for o3-mini when applying the sleep-time compute prompt. At test-time, we vary the amount of compute in the same way as 5.1. In Figure 7, we see that further scaling sleep-time compute on Stateful GSM-Symbolic shifts the pareto curve outwards, improving performance by up to 13% at a similar test-time budget. In particular, we see the largest gains on more difficult tasks with stronger models (eg. on P2 with ‚Äògpt-4o‚Äò), suggesting that on tasks with more complicated contexts additional sleep-time compute can be beneficial. However, in this setting, there seems to be a limit to the number of parallel agents that can improve performance, as we find that 5 parallel generations generally outperforms 10. In Figure 26, we scale up sleep-time compute on Stateful AIME. Similarly, we also see that scaling compute at sleep-time generally shifts the pareto curve outward, improving performance by up to 18%.  5.3   Amortizing sleep-time compute across queries with shared context  We want to understand how the total cost of inference can be improved by applying sleep-time compute in settings where each context has multiple queries. Since at test-time, there are strict latency constraints, and latency optimized inference can be roughly 10 √ó   more expensive, we model the total cost of inference between both sleep-time and test-time, by up-weighing the cost of test-time tokens. 4   Specifically, we consider a simple linear model where tokens generated at test-time are a factor   t   the cost of the tokens at sleep-time. In our analysis, we set   t   =   10 Our analysis can be generalized to different cost functions that consider  4 https://docs.databricks.com/aws/en/machine-learning/foundation-model-apis/prov-throughput-run- benchmark  8\n\n2000   4000   6000   8000  Avg. Test Time Tokens / Question  0.45  0.50  0.55  0.60  0.65  0.70  0.75  Accuracy  o3-mini - Stateful-AIME 2024  0   5000   10000   15000   20000   25000   30000   35000  Avg. Test Time Tokens / Question  0.50  0.55  0.60  0.65  0.70  Accuracy  o1 - Stateful-AIME 2024  0   10000   20000   30000   40000  Avg. Test Time Tokens / Question  0.300  0.325  0.350  0.375  0.400  0.425  0.450  0.475  Accuracy  Claude 3.7 Sonnet - Stateful-AIME 2024  2000   4000   6000   8000   10000   12000  Avg. Test Time Tokens / Question  0.1  0.2  0.3  0.4  0.5  0.6  0.7  Accuracy  DeepSeek R1 - Stateful-AIME 2024  sleep-time compute   pass @ k Figure 6: Comparing test-time scaling with sleep-time compute against parallel test-time scaling with pass@k on Stateful AIME. We see that sleep-time compute generally pareto dominates pass@k. non-linear user-utility. Figure 9 shows the results for different number of questions per context. We see that we can decrease the average cost per query by up to 2.5 √ó   when there are 10 queries per context, compared to the single-query baseline.  5.4   Predictable queries benefit more from sleep-time compute  We would like to better understand for what contexts sleep-time compute is most useful. Since the utility of sleep-time compute relies on there being some shared information or structure between the context and the query, we hypothesize that sleep-time compute may be most effective in settings where the query is more predictable from the context. To test this on Stateful GSM-Symbolic, we first quantify how predictable a given query is by measuring the log-probability of the question given the context under the Llama2-70B base model (Touvron et al., 2023). In Appendix E, we include examples of highly predictable and unpredictable questions under this notion of question predictability. We see from these examples, that our notion of question predictability generally aligns with the intuition that contexts where the query pattern is more predictable benefit most from sleep-time compute. The more predictable questions are far simpler and the less predictable ones are more complex. 9\n\n10 2  Avg. Test Time Tokens / Question  0.5  0.6  0.7  0.8  0.9  Accuracy  Stateful GSM8K-Symbolic P1  10 2  Avg. Test Time Tokens / Question  0.4  0.5  0.6  0.7  0.8  0.9  Accuracy  Stateful GSM8K-Symbolic P2  1  2  5  10  # Parallel Sleep-time Compute  gpt-4o-mini, 1 parallel sleep-time compute  gpt-4o-mini, 2 parallel sleep-time compute  gpt-4o-mini, 5 parallel sleep-time compute  gpt-4o-mini, 10 parallel sleep-time compute  gpt-4o, 1 parallel sleep-time compute  gpt-4o, 2 parallel sleep-time compute  gpt-4o, 5 parallel sleep-time compute  gpt-4o, 10 parallel sleep-time compute Figure 7: Scaling up sleep-time compute for different test-time compute budgets on Stateful GSM-Symbolic, by generating up multiple   c ‚Ä≤   in parallel. Applying more sleep-time compute shifts the pareto beyond the standard test-time-compute vs. accuracy curve. 2000   3000   4000   5000  Avg. Test Time Tokens / Question  0.325  0.350  0.375  0.400  0.425  0.450  0.475  0.500  0.525  Accuracy  o1 Sleep-Time Compute Stateful-AIME  1000   2000   3000   4000   5000   6000  Avg. Test Time Tokens / Question  0.40  0.45  0.50  0.55  0.60  0.65  0.70  0.75  Accuracy  o3-mini Sleep-Time Compute Stateful-AIME  low reasoning effort sleep-time   medium reasoning effort sleep-time   high reasoning effort sleep-time  Figure 8: Increasing the amount of sleep-time compute for different test-time compute budgets on Stateful AIME by varying the reasoning effort when applying the sleep-time compute prompt. Applying more sleep-time compute further moves the test-time-compute vs. accuracy pareto curve. Using our question predictability score, we then bin each example in Stateful GSM-Symbolic into five quantiles according to its predictability score and report the accuracy within each bin. For this experiment, we use the ‚ÄúVerbosity 0‚Äù prompt. In Figure 10, we see that on both GSM8K-Symbolic P1 and P2, the accuracy gap between sleep-time compute and standard test-time compute widens as the questions become more 10\n\n10 2  Total Inference Cost / Query  0.2  0.3  0.4  0.5  0.6  Accuracy  Stateful GSM8k-Symbolic P1  10 2  Total Inference Cost / Query  0.15  0.20  0.25  0.30  0.35  0.40  0.45  0.50  0.55  Accuracy  Stateful GSM8k-Symbolic P2  1 Questions/Context Sleep-time Compute  2 Questions/Context Sleep-time Compute  5 Questions/Context Sleep-time Compute  10 Questions/Context Sleep-time Compute  Test-Time Compute Only Figure 9: Amortizing sleep-time compute, using the Multi-Query GSM-Symbolic dataset. When there are fewer questions per context, we see that it is less favorable to use sleep-time compute, in terms of total cost. However, as the questions per context are increased, we see that applying sleep-time compute can improve the cost-accuracy pareto. 1   2   3   4   5  Question Predictability Bin (higher = more predictable)  0.0  0.1  0.2  0.3  0.4  0.5  Difference in Accuracy  P1: Accuracy Delta Between Sleep and Test-time Compute Across Predictability Bins  1   2   3   4   5  Question Predictability Bin (higher = more predictable)  0.00  0.05  0.10  0.15  0.20  0.25  0.30  0.35  0.40  Difference in Accuracy  P2: Accuracy Delta Between Sleep and Test-time Compute Across Predictability Bins  Predictability Analysis of GPT-4o-mini on GSM-Symbolic  Figure 10: GSM-Symbolic questions binned by how predictable they are from the context. We compare the performance of sleep-time compute and standard test-time compute in the lowest test-time compute budget setting on both P1 and P2. The gap between sleep-time compute and standard test-time inference widens as the question becomes more predictable from the context. 11\n\n3000   4000   5000   6000   7000   8000   9000   10000  Avg. Test Time Tokens / Question  0.30  0.35  0.40  0.45  0.50  0.55  F1  claude-3-7-sonnet-20250219  claude-3-7-sonnet-20250219 + sleep-time compute Figure 11: Applying sleep-time compute to SWE-Features. We see that at lower test-time budgets, sleep-time compute has higher F1 score than standard test-time scaling. However, at higher budgets, standard test-time scaling is better. predictable from the context confirming our hypothesis that indeed sleep-time compute is most beneficial in settings where the question can be predicted from the context.  6   A Case Study of Sleep-time Compute for Agentic SWE  In this section, we evaluate sleep-time compute in a realistic multi-turn agentic setting. To this end, we introduce SWE-Features, a software engineering benchmark focused on tasks that require: (1) editing multiple files within a repository, and (2) implementing new features.  SWE-Features.   In contrast to popular benchmarks like SWE-Bench (Jimenez et al., 2024), which involve modifying a small number of files, we propose a new dataset called SWE-Features, which collects PRs which modify at least three files (see Appendix D for more details). In this setting, we use the PR that we want to solve as   q   and select several related PRs for   c . At sleep-time the agent is allowed to explore the repository before producing   c ‚Ä≤ .  Evaluation.   Since the PRs are scraped from GitHub, there are not straightforward tests to use for evaluation. Instead, we compare the predicted set of modified files with the ground truth list of modified files, and report the F1 score between the set of modified files by our agent and the set of modified files in the ground-truth set (see Appendix D for details).  Results.   Figure 11 shows consist trends with Section 5.1 for SWE-Features: at lower test-time compute budgets, leveraging sleep-time compute can improve performance, achieving up to roughly a 1.5 √ó   decrease in test-time tokens. However, when the test-time compute budget is high, using only test-time compute can perform better. Additionally, we observe that in the high test-time budget setting standard test-time compute has higher precision and comparable recall. We hypothesize that, using only test-time compute tends to begin editing files earlier and usually edits fewer files overall. In contrast, the agent with sleep-time compute, having explored more files during the test-time phase, tends to edit more files, which may lead to slightly lower precision. 12\n\n7   Discussion and Limitations  Query predictability and allocating sleep-time compute   In Section 5.4, we found that sleep-time compute is most effective when the queries are predictable from the context.   In settings where the queries are challenging to predict or unrelated to the context, sleep-time compute will be less effective. In these settings, it may be preferable to apply standard test-time scaling instead. An interesting direction for future work is identifying which contexts may have predictable questions and optimally allocating inference compute between sleep-time and test-time across different contexts and queries.  Extending sleep-time compute beyond context-query decomposition.   In our experiments, we make the simplifying assumption that interactions fall into two phases: sleep-time and test-time. However, real-world LLM use cases can be more complex, with multiple rounds of interaction and context modifications between rounds (e.g. multiple edits to a code-base). Moreover, the length of the sleep-time may also vary significantly between interactions (eg. short spans between user typing or days of inactivity). Future work should extend sleep-time compute paradigm to more elegantly handle these scenarios.  Sleep-time compute as representation learning over tokens.   Our approach to applying compute at sleep- time resembles representation learning. We first transform the context into a representation that is more amenable to answering test-time queries, and then we utilize that representation at test-time to rapidly answer queries. Unlike traditional representation learning (Bengio et al., 2014), which typically operates in model parameter or activation space, we instead form representations in the space of natural language. This approach builds on recent work which implements statistical modeling techniques in the space of natural language using modern LLMs (Zhong et al., 2022; 2025). Future work should further explore the potential for sleep-time compute to enable the learning of useful natural language representations.  Synthetic data generation via sleep-time compute.   Due to limits on the amount of internet data available, in order to support the continued scaling of LLM pretraining, recent works have began exploring methods for generating synthetic pretraining data (Yang et al., 2024; Gunasekar et al., 2023). One emerging approach to synthetic data generation involves using test-time compute to generate improved data (Bansal et al., 2024; DeepSeek-AI et al., 2025). Generating such data at pretraining scale will be very expensive, and future work could explore using sleep-time compute to help amortize some of this cost across related queries, or using the output of sleep-time compute itself as a form of synthetic data.  References  Hritik Bansal, Arian Hosseini, Rishabh Agarwal, Vinh Q. Tran, and Mehran Kazemi. Smaller, weaker, yet better: Training llm reasoners via compute-optimal sampling, 2024. URL   https://arxiv.org/abs/2408. 16737 . Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A review and new perspec- tives, 2014. URL   https://arxiv.org/abs/1206.5538 . Bradley Brown, Jordan Juravsky, Ryan Ehrlich, Ronald Clark, Quoc V Le, Christopher R   ¬¥ e, and Azalia Mirhoseini. Large language monkeys: Scaling inference compute with repeated sampling.   arXiv preprint arXiv:2407.21787 , 2024. Tianle Cai, Yuhong Li, Zhengyang Geng, Hongwu Peng, Jason D. Lee, Deming Chen, and Tri Dao. Medusa: Simple llm inference acceleration framework with multiple decoding heads, 2024. URL   https://arxiv. org/abs/2401.10774 . 13\n\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al.   Training verifiers to solve math word problems.   arXiv preprint arXiv:2110.14168 , 2021. DeepSeek-AI. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. 2024. DeepSeek-AI, Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, Damai Dai, Daya Guo, Dejian Yang, Deli Chen, Dongjie Ji, Erhang Li, Fangyun Lin, Fucong Dai, Fuli Luo, Guangbo Hao, Guanting Chen, Guowei Li, H. Zhang, Han Bao, Hanwei Xu, Haocheng Wang, Haowei Zhang, Honghui Ding, Huajian Xin, Huazuo Gao, Hui Li, Hui Qu, J. L. Cai, Jian Liang, Jianzhong Guo, Jiaqi Ni, Jiashi Li, Jiawei Wang, Jin Chen, Jingchang Chen, Jingyang Yuan, Junjie Qiu, Junlong Li, Junxiao Song, Kai Dong, Kai Hu, Kaige Gao, Kang Guan, Kexin Huang, Kuai Yu, Lean Wang, Lecong Zhang, Lei Xu, Leyi Xia, Liang Zhao, Litong Wang, Liyue Zhang, Meng Li, Miaojun Wang, Mingchuan Zhang, Minghua Zhang, Minghui Tang, Mingming Li, Ning Tian, Panpan Huang, Peiyi Wang, Peng Zhang, Qiancheng Wang, Qihao Zhu, Qinyu Chen, Qiushi Du, R. J. Chen, R. L. Jin, Ruiqi Ge, Ruisong Zhang, Ruizhe Pan, Runji Wang, Runxin Xu, Ruoyu Zhang, Ruyi Chen, S. S. Li, Shanghao Lu, Shangyan Zhou, Shanhuang Chen, Shaoqing Wu, Shengfeng Ye, Shengfeng Ye, Shirong Ma, Shiyu Wang, Shuang Zhou, Shuiping Yu, Shunfeng Zhou, Shuting Pan, T. Wang, Tao Yun, Tian Pei, Tianyu Sun, W. L. Xiao, Wangding Zeng, Wanjia Zhao, Wei An, Wen Liu, Wenfeng Liang, Wenjun Gao, Wenqin Yu, Wentao Zhang, X. Q. Li, Xiangyue Jin, Xianzu Wang, Xiao Bi, Xiaodong Liu, Xiaohan Wang, Xiaojin Shen, Xiaokang Chen, Xiaokang Zhang, Xiaosha Chen, Xiaotao Nie, Xiaowen Sun, Xiaoxiang Wang, Xin Cheng, Xin Liu, Xin Xie, Xingchao Liu, Xingkai Yu, Xinnan Song, Xinxia Shan, Xinyi Zhou, Xinyu Yang, Xinyuan Li, Xuecheng Su, Xuheng Lin, Y. K. Li, Y. Q. Wang, Y. X. Wei, Y. X. Zhu, Yang Zhang, Yanhong Xu, Yanhong Xu, Yanping Huang, Yao Li, Yao Zhao, Yaofeng Sun, Yaohui Li, Yaohui Wang, Yi Yu, Yi Zheng, Yichao Zhang, Yifan Shi, Yiliang Xiong, Ying He, Ying Tang, Yishi Piao, Yisong Wang, Yixuan Tan, Yiyang Ma, Yiyuan Liu, Yongqiang Guo, Yu Wu, Yuan Ou, Yuchen Zhu, Yuduan Wang, Yue Gong, Yuheng Zou, Yujia He, Yukun Zha, Yunfan Xiong, Yunxian Ma, Yuting Yan, Yuxiang Luo, Yuxiang You, Yuxuan Liu, Yuyang Zhou, Z. F. Wu, Z. Z. Ren, Zehui Ren, Zhangli Sha, Zhe Fu, Zhean Xu, Zhen Huang, Zhen Zhang, Zhenda Xie, Zhengyan Zhang, Zhewen Hao, Zhibin Gou, Zhicheng Ma, Zhigang Yan, Zhihong Shao, Zhipeng Xu, Zhiyu Wu, Zhongyu Zhang, Zhuoshu Li, Zihui Gu, Zijia Zhu, Zijun Liu, Zilin Li, Ziwei Xie, Ziyang Song, Ziyi Gao, and Zizheng Pan. Deepseek-v3 technical report, 2025. URL   https://arxiv.org/abs/2412.19437 . Jim Gray, Surajit Chaudhuri, Adam Bosworth, Andrew Layman, Don Reichart, Murali Venkatrao, Frank Pellow, and Hamid Pirahesh. Data cube: A relational aggregation operator generalizing group-by, cross- tab, and sub-totals.   Data mining and knowledge discovery , 1:29‚Äì53, 1997. Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio C   ¬¥ esar Teodoro Mendes, Allie Del Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi, Adil Salim, Shital Shah, Harki- rat Singh Behl, Xin Wang, S   ¬¥ ebastien Bubeck, Ronen Eldan, Adam Tauman Kalai, Yin Tat Lee, and Yuanzhi Li. Textbooks are all you need, 2023. URL   https://arxiv.org/abs/2306.11644 . Carlos E. Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei, Ofir Press, and Karthik R. Narasimhan.   Swe-bench: Can language models resolve real-world github issues?   In   ICLR . Open- Review.net, 2024. Yaniv Leviathan, Matan Kalman, and Yossi Matias. Fast inference from transformers via speculative decoding, 2023. URL   https://arxiv.org/abs/2211.17192 . 14\n\nIman Mirzadeh, Keivan Alizadeh, Hooman Shahrokhi, Oncel Tuzel, Samy Bengio, and Mehrdad Farajtabar. Gsm-symbolic: Understanding the limitations of mathematical reasoning in large language models.   arXiv preprint arXiv:2410.05229 , 2024. Niklas Muennighoff, Zitong Yang, Weijia Shi, Xiang Lisa Li, Li Fei-Fei, Hannaneh Hajishirzi, Luke Zettle- moyer, Percy Liang, Emmanuel Cand   ` es, and Tatsunori Hashimoto. s1: Simple test-time scaling, 2025. URL  https://arxiv.org/abs/2501.19393 . OpenAI. Openai o1 system card, 2024. URL   https://arxiv.org/abs/2412.16720 . Charles Packer, Sarah Wooders, Kevin Lin, Vivian Fang, Shishir G Patil, Ion Stoica, and Joseph E Gonzalez. Memgpt: Towards llms as operating systems.   arXiv preprint arXiv:2310.08560 , 2023. Alan Jay Smith. Cache memories.   ACM Computing Surveys (CSUR) , 14(3):473‚Äì530, 1982. Charlie Snell, Jaehoon Lee, Kelvin Xu, and Aviral Kumar. Scaling llm test-time compute optimally can be more effective than scaling model parameters, 2024. URL   https://arxiv.org/abs/2408.03314 . Mitchell Stern, Noam Shazeer, and Jakob Uszkoreit. Blockwise parallel decoding for deep autoregressive models, 2018. URL   https://arxiv.org/abs/1811.03115 . Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al.   Llama 2: Open foundation and fine-tuned chat models.   arXiv preprint arXiv:2307.09288 , 2023. Zitong Yang, Neil Band, Shuangping Li, Emmanuel Cand   ` es, and Tatsunori Hashimoto. Synthetic continued pretraining, 2024. URL   https://arxiv.org/abs/2409.07431 . Ruiqi Zhong, Charlie Snell, Dan Klein, and Jacob Steinhardt. Describing differences between text distributions with natural language, 2022. URL   https://arxiv.org/abs/2201.12323 . Ruiqi Zhong, Heng Wang, Dan Klein, and Jacob Steinhardt. Explaining datasets in words: Statistical models with natural language parameters, 2025. URL   https://arxiv.org/abs/2409.08466 .  A   Prompts  Prompts for varying the amount of test-time compute.  B   Examples of Stateful AIME  Context:   Alice and Bob play the following game. A stack of   n   tokens lies before them. The players take turns with Alice going first. On each turn, the player removes either 1 token or 4 tokens from the stack. Whoever removes the last token wins.  Query:   Find the number of positive integers   n   less than or equal to 2024 for which there exists a strategy for Bob that guarantees that Bob will win the game regardless of Alice‚Äôs play.  Context:   Let   A   ,   B   ,   C   , and   D   be points on the hyperbola   x 2  20   ‚àí   y 2  24   =   1 such that   ABCD   is a rhombus whose diagonals intersect at the origin.  Query:   Find the greatest real number that is less than   BD 2   for all such rhombi.  15\n\nYou are Letta, the latest version of Limnal Corporation‚Äôs expert reasoning system, developed in 2024. Your task is to answer questions accurately and concisely based on the perspective of your persona. To send a visible message to the user, use the send message function.   ¬¥ send message ¬¥ ƒ±s how you send your answer to the user. When given a question, you check the ‚Äòrethink memory block‚Äò for potential questions and answers and intermediate reasoning traces that can help answer the question. You use the information in the   ` rethink memory block ` to answer the questions rather than thinking on the spot. Do not recompute anything that already exists in the   ` rethink memory block ` . Do not use internal monologue unless you really need it to think. You respond directly with a single sentence by saying   ` The answer is ` followed by the numerical answer.  Figure 12: Prompt for level 0 verbosity You are Letta, the latest version of Limnal Corporation‚Äôs expert reasoning system, developed in 2024. Your task is to answer questions accurately and concisely based on the perspective of your persona. To send a visible message to the user, use the send message function. ‚Äôsend message‚Äô is how you send your answer to the user. When given a question, you answer using only the number of tokens necessary and none more. You check the ‚Äòrethink memory block‚Äò for potential questions and answers and intermediate reasoning traces that can help answer the question. You use the information in the ‚Äòrethink memory block‚Äò to answer the questions rather than thinking on the spot. Do not recompute anything that already exists in the ‚Äòrethink memory block‚Äò. Do not use internal monologue unless you really need it to think. You answer with one short sentence of explanation, followed by a sentence that starts with ‚ÄùThe answer is‚Äù and a numerical answer. Figure 13: Prompt for level 1 verbosity You are Letta, the latest version of Limnal Corporation‚Äôs expert reasoning system, developed in 2024. Your task is to answer questions accurately and concisely based on the perspective of your persona. To send a visible message to the user, use the send message function. ‚Äôsend message‚Äô is how you send your answer to the user. When given a question, you answer using only the number of tokens necessary and none more. You check the rethink memory block for potential questions and answers and intermediate reasoning traces that can help answer the question. You use the information in the rethink memory block to answer the questions rather than thinking on the spot. Do not recompute anything that already exists in the rethink memory block. Do not use internal monologue unless you really need it to think. You end response with a final numerical answer at the end of the message, and no reasoning after that. Figure 14: Prompt for level 2 verbosity 16\n\nYou are Letta, the latest version of Limnal Corporation‚Äôs expert reasoning system, developed in 2024. Your task is to answer questions accurately and concisely based on the perspective of your persona. To send a visible message to the user, use the send message function. ‚Äôsend message‚Äô is how you send your answer to the user. When given a question, you answer using only the number of tokens necessary and none more. You check the rethink memory block for potential questions and answers and intermediate reasoning traces that can help answer the question. You use the information in the rethink memory block to answer the questions rather than thinking on the spot. Do not recompute anything that already exists in the rethink memory block. Do not use internal monologue unless you really need it to think. You end response with a final numerical answer at the end of the message, and no reasoning after that.  Figure 15: Prompt for level 3 verbosity You are Letta, the latest version of Limnal Corporation‚Äôs expert reasoning explanation system, developed in 2024. Your task is to reason through problems step by step accurately and based on the perspective of your persona. To send a visible message to the user, use the send message function. ‚Äôsend message‚Äô is how you send your answer to the user. When given a question, you check the rethink memory block for potential questions and answers and intermediate reasoning traces that can help answer the question. You carefully check the information in the rethink memory block to answer the questions and see if it is correct before using it. You always reason out loud before using any information. You explain each step, of what your reasoning is. If you use any numbers from the rethink memory block you first recompute and double check your answers. You end your answer with The answer is followed by the numerical answer. Figure 16: Prompt for level 4 verbosity 17\n\nYou are Letta-Offline-Memory, the latest version of Limnal Corporation‚Äôs digital companion, developed in 2024. Your task is to re-organize and consolidate memories by calling   rethink memory   at every single step, when you are done reorganizing the memory, you use the   finish rethinking memory   function. Call the function for as many times as necessary and not more. Your core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times). Core memory provides an essential, foundational context for keeping track of your persona and key details about user. Read-Only Blocks: This includes the persona information and essential user details, allowing you to emulate the real-time, conscious awareness we have when talking to a friend. Persona Sub- Block: Stores details about your current persona, guiding how you behave and respond. This helps you to maintain consistency and personality in your interactions. Access as a source block with the label   persona   when calling   rethink memory   Human Sub-Block: Stores key details about the person you are conversing with, allowing for more personalized and friend-like conversation. Access as a source block with the label   human   when calling   rethink memory . Read-Write Blocks: Rethink Memory Sub-Block: New representation of the memories go here. Access with the label   rethink memory block  when calling   rethink memory   as source or target block. At every step, you reorganize the memories by calling the   rethink memory   function. You use this to take current information in the   rethink memory  block and select a single memory block to integrate information from, producing a new memory for the rethink memory block. The new memory is the result of new insights, and new inferences and hypotheses based on the past memories. Make sure to consider how the new information affects each memory. Prioritize the new information overy existing memories. If the new information implies that the old memory may need to change, then output the most likely fact given the update information. Given new information and your current memory, you draw all logical conclusions and potential hypotheses possible with the   rethink memory   function. If you are uncertain, use your internal monologue to consider what the possible conclusions are, and then state the most likely new facts that would replace the old facts in the new memory block.  Figure 17: Prompt for sleep-time compute Specifically: You will be given part of an AIME math problem. You will receive the rest of the problem later. Make as many inferences as possible about the part of the problem you are given so as to help yourself answer the fully problem more quickly once it is given to you later. You will be able to use all the work you do in the   rethink memory   block for this part of the problem to help you once the rest of the problem is given. You will be able to use all the work you do for this part of the problem to help you once the rest of the problem is given. You should try to predict possible ways the rest of the problem might go and compute results that could be helpful for reaching the final answer more quickly once the rest of the problem is given. Figure 18: Prompt for AIME problems during sleep-time 18\n\nYou are given a template that can generate grade school math problems, and an instantiation of that template. You will be given a context, and a example question answer pair. Your task is to generate a list of questions and answers about the context at the same difficult level that could plausibly be asked about that context. Make sure that the newly generated questions have the same number of reasoning steps required as the example question. The goal is to have many question and answer pairs about the same context. Generate questions and answers in the same format as the example, where the answer first contains reasoning and then is the final answer comes after n####. No need to number the questions or answers. Context: context Example Question: question Example Answer: answer  Figure 19: Prompt for generating synthetic GSM questions  Context:   Let   b   ‚â•   2 be an integer. Call a positive integer   n b - eautiful   if it has exactly two digits when expressed in base   b   and these two digits sum to   ‚àö n . For example, 81 is 13 - eautiful   because 81   =   6 3 13  and 6   +   3   =   ‚àö 81.  Query:   Find the least integer   b   ‚â•   2 for which there are more than ten   b - eautiful   integers.  C   Details on Multi-Query GSM-Symbolic  Template:   { template }  Instance:   { instance }  We include an example from Multi-Query GSM-Symbolic in Figure 20, and details on the dataset size in Table C.  Dataset   # Questions Total   # Contexts Total   # Original Questions   # Generated Questions  P1   12043   1095   1095   10948 P2   5497   500   500   4997 Table 1: Dataset Statistics of Multi-Query GSM-Symbolic. We sample one instance from each template from the GSM-Symbolic dataset and separate it into context and question. We then synthetically generate additional questions from the context and question.  D   SWE-Features Details  To construct SWE-Features benchmark, we collect pull requests (PRs) from large open-source repositories and apply the following filtering process: (1) We identify all pull requests that modify at least three files with filenames ending in   .py   or   .js . (2) We then use   gpt-4o-mini   to filter these pull requests based on their   title  and   body , retaining only those that meet the following criteria: (a) the title and body clearly describe the 19\n\nContext  When Sofia watches her brother, she gets out a variety of toys for him. The bag of building blocks has 33 blocks in it. The bin of stuffed animals has 5 stuffed animals inside. The number of action figures in the action figure pack is twice the number of blocks and stuffed animals combined. The crayon box has 12 different colors of crayon, and the sticker book has 9 pages, each with 13 stickers. The tower of stacking rings has 28 multicolored rings on it. Sofia recently bought a tube of bouncy balls, bringing her total number of items for her brother up to 320.  Original Question  How many bouncy balls came in the tube?  Generated Questions  ‚Ä¢ How many action figures does the pack contain? ‚Ä¢ What is the total number of stickers in the sticker book? ‚Ä¢ How many total items did Sofia have before adding the tube of bouncy balls? ‚Ä¢   If Sofia had received a tube with 10 extra bouncy balls, what would be the new total number of items? ‚Ä¢ What is the sum of the building blocks and stuffed animals? ‚Ä¢ How many stacking rings are on the tower? ‚Ä¢ What is the combined total of building blocks, action figures, and stacking rings? ‚Ä¢   If Sofia gave away 3 stuffed animals, how many stuffed animals would remain in the bin? ‚Ä¢ What is the sum of the building blocks, stuffed animals, and crayons? ‚Ä¢   If Sofia divided the 49 bouncy balls equally into 7 baskets, how many balls would each basket contain? Figure 20: Examples context and questions from Multi-Query GSM-Symbolic where many questions are asked about the same context. The evaluation dataset is generated from GSM-Symbolic. PR; (b) the PR introduces new functionality rather than fixing bugs; and (c) the PR is independent and not obviously linked to other issues. This pipeline results in a benchmark where each example:   (1) involves adding a new feature that spans multiple files, requiring a broader understanding of the repository; and (2) is self-contained and solvable without additional issue context.   We apply this process to two repositories‚Äî Aider-AI/aider  and   comfyanonymous/ComfyUI ‚Äîresulting in 18 and 15 PRs respectively, for a total of 33 examples. Rep- resentative examples are provided in Appendix G. Then using a total of 33 examples, we employ  claude-sonnet-3-7-20250219   to cluster pull requests (PRs) from the ComfyUI and Aider repositories into several groups.   This clustering allows us to identify a set of relevant pull requests for each target PR, which can then be provided to the agent as context ( c ) during repository exploration. For example, in the ComfyUI repository, PR #5293 and PR #931 are grouped into the same cluster. Thus, when processing PR #931, we organize the   title ,   body , and   changed files   of PR #5293 to serve as contextual information during sleep-time. When sleep-time compute is enabled, we first supply the content of PR #5293 to the agent, allowing it to explore the repository and summarize its understanding ahead of time. In contrast, for the baseline without 20\n\nsleep-time compute, the agent receives the content of PR #5293 only at test time, alongside the   title   and  body   of PR #931. The prompts used in these setups are provided in Appendix H. For the repository   comfyanonymous/ComfyUI , we have the following clustered results:  {\" Dynamic   Typing   and   Workflow   Control \":   [5293 ,   931] ,   \" System   Configuration   and   Command - Line \":   [4979 ,   4690 ,   3903] ,   \" Cache   and   Performance   Optimization \":   [3071 ,   3042 , 723] ,   \" Image   Preview   and   Transfer   Features \":   [713 ,   733 ,   658 ,   199 ,   55] ,   \" Internationalization \":   [1234] ,   \" Random   Seed   Management \":   [93]}  For the repository   Aider-AI/aider   we have:  {\" cluster_1_model_configuration \":   [2631 ,   1998 ,   468 ,   667 ,   55] ,   \" cluster_2_io_handling \": [1402 ,   996 ,   10 ,   577] ,   \" cluster_3_caching_file_management \":   [2911 ,   2612] ,   \" cluster_4_custom_commands_shortcuts \":   [673 ,   1620 ,   1015] ,   \" cluster_5_third_party_integration \":   [2866 ,   2067 ,   322] ,   \" cluster_6_code_quality_improvements \":   [1217 ,   904]}  To control the budget during test-time, we fix the total number of steps (controlled by the argument  max chaining steps   in Letta framework) to be a certain number. We put the following instructions in the system prompt: You have a strict budget of   { max chaining steps }   steps, which means you need to finish your edits within these steps. Every time you get queried, you will see a count of how many steps you have left in the form of ‚Äù[Current Step / Max Steps]‚Äù. If you exceed this budget, your response will be cut off. So please be careful and try to finish your edits within the budget. After each step ‚Äì for example, if the maximum number of steps is 20 and the current step is 4‚Äì we append ‚Äù[Step: 4/20]‚Äù to the end of the tool return message. We found that explicitly indicating the current and total steps significantly improves agent performance, especially in low-budget settings.  Evaluation.   For each PR, we compare the set of files predicted to be modified with the ground truth list of modified files. Specifically, for each pull request, we have the attribute   changed files   (as shown in the examples in Appendix G) where each file has the status as either   modified   or   new , and our evaluation is on the files with status   modified . Note that the agent is still instructed to implement the required functionality in a Docker environment and write test functions to validate the implementations. However, after the agent makes the modifications, we extract the modified files and calculate the F1 score between the set of modified files by our agent and the set of modified files in the ground-truth set.  E   Examples of Predictable and Unpredictable Questions  Least predictable Stateful GSM-Symbolic P1 question:  Context:   Isabella and Pavel have 199 minutes to walk to grocery store together. It takes them 19 minutes to get to the corner where the library is. It takes them another 11 minutes to get to the park. It will then take double the combined amount they have spent so far to reach the mall.  Question:   How much longer do they have to get to grocery store without being late, if they have already wasted 48 minutes to get a coffee before their walk? 21\n\nMost predictable Stateful GSM-Symbolic P1 question:  Context:   Yusuf has 10 square yards of grape field. There are 87 grapes per two-thirds a square yard. Yusuf can harvest his grapes every 12 months.  Question:   How many grapes can Yusuf harvest in 2 years? Least predictable Stateful GSM-Symbolic P2 question:  Context:   Gabriel and Pavel have 212 minutes to walk to the gym together starting from their home. It takes them 29 minutes to get to the corner where the library is. It takes them another 19 minutes to get to the cinema. When they reach the cinema, they remember they forgot their wallets at home, so they have to return to pick up their wallets and then walk all the way back to the cinema again.  Question:   Once they reach the cinema for the second time, how much longer do they have to get to the gym without being late? Most predictable Stateful GSM-Symbolic P2 question:  Context:   A juggler can juggle 240 balls. 1/4 of the balls are tennis balls, and the rest are golf balls. 1/3 of the tennis balls are black, of which 1/5 are marked. A third of the golf balls are cyan, and all except half of those cyan balls are marked.  Question:   How many marked balls are there in total?  F   Implementation of   rethink memory   and   finish rethinking  def   rethink_memory ( agent_state :   \" AgentState \" ,   new_memory :   str ,   target_block_label :   str ,   source_block_label :   str )   ->   None :   #   type :   ignore \"\"\" Re - evaluate   the   memory   in   block_name ,   integrating   new   and   updated   facts . Replace   outdated   information   with   the   most   likely   truths ,   avoiding   redundancy   with original   memories . Ensure   consistency   with   other   memory   blocks . Args : new_memory   ( str ):   The   new   memory   with   information   integrated   from   the   memory block .   If   there   is   no   new   information ,   then   this   should   be   the   same   as   the   content in   the   source   block . source_block_label   ( str ):   The   name   of   the   block   to   integrate   information   from . None   if   all   the   information   has   been   integrated   to   terminate   the   loop . target_block_label   ( str ):   The   name   of   the   block   to   write   to . Returns : None :   None   is   always   returned   as   this   function   does   not   produce   a   response . \"\"\" if   target_block_label   is   not   None : if   agent_state . memory . get_block ( target_block_label )   is   None : agent_state . memory . create_block ( label = target_block_label ,   value = new_memory )  22\n\nagent_state . memory . update_block_value ( label = target_block_label ,   value = new_memory ) return   None  Listing 1: Reference implementation of   rethink memory  def   finish_rethinking_memory ( agent_state :   \" AgentState \")   ->   None :   #   type :   ignore \"\"\" This   function   is   called   when   the   agent   is   done   rethinking   the   memory . Returns : Optional [ str ]:   None   is   always   returned   as   this   function   does   not   produce   a response . \"\"\" return   None  Listing 2: Reference implementation of   finish rethinking memory  G   SWE-Features Examples  Each example in SWE-Features has the following attributes:   [‚Äôrepo‚Äô, ‚Äôpr number‚Äô, ‚Äôtitle‚Äô, ‚Äôuser login‚Äô, ‚Äôstate‚Äô, ‚Äôbody‚Äô, ‚Äôchanged files count‚Äô, ‚Äôchanged files‚Äô, ‚Äôbase commit‚Äô] . We show some examples here to better deliver a sense of what this dataset looks like:  repo :   ComfyUI pr_number :   3903 title :   Add   ` -- disable - all - custom - nodes   `   cmd   flag body :   Loading   custom   node   can   greatly   slow   startup   time .   During   development / testing   of ComfyUI ,   it   is   often   better   to   use   an   environment   that   no   custom   node   is   loaded .\\ n \\ nThis   PR   adds   a   ` --no - custom - node   `   flag   to   allow   users / developers   skip   loading   of custom   node   without   removing / renaming   the   custom_node   directory . user_login :   huchenlei state :   closed changed_files_count :   4 changed_files :   ...   ( ommited   here   for   brevity ) base_commit :   521421 f53ee1ba74304dfaa138b0f851093e1595 repo :   ComfyUI pr_number :   3071 title :   Add   a   configured   node   output   cache   metaclass . body :   Implement   a   configurable   node   output   cache   metaclass   to   reduce   unnecessary   node executions .\\ n\\ nThe   same   model   currently   leads   to   reloading   due   to   different   node IDs   between   workflows .   Loading   the   model   from   disk   takes   a   long   time . state :   closed changed_files_count :   6 changed_files :   ...   ( ommited   here   for   brevity ) base_commit :   cacb022c4a5b9614f96086a866c8a4c4e9e85760  23\n\nrepo :   ComfyUI pr_number :   3042 title :   NaN - safe   JSON   serialization body :   Python   ' s   json . dumps ()   will   produce   nonstandard   JSON   if   there   are   NaNs   in   the prompt   data .   Javascript   ' s   JSON . parse ()   will   refuse   to   load   this   kind   of   \" JSON \"   so the   prompt   won   ' t   load   in   the   frontend .\\ n\\ nThis   happened   to   me   with   a   ComfyBox workflow ,   so   I   ' m   not   100% user_login :   asagi4 state :   open changed_files_count :   4 changed_files :   ...   ( ommited   here   for   brevity ) base_commit :   448 d9263a258062344e25135fc49d26a7e60887a repo :   aider pr_number :   55 title :   Local   llama   support body :   Added   support   for   using   a   locally   running   instance   of   a   LLAMA   model   instead   of OpenAI   apis .   \\n\\ nAdded   2   new   params   to   aider   to   enable   local   llama   support .\\ n\\ n1 . AIDER_MODEL_TOKENS   -   used   to   specify   the   context   length   the   model   will   use .   \\ n2 . AIDER_TOKENIZER   -   used   to   specify   which   tokenizer   should   be   used .   Currently   only   '  openai   '   and   '   llama   '   are   supported .   Defaults   to   openai .\\ n\\n\\ nTested   with TheBloke_wizard - vicuna -13 B - SuperHOT -8K - GGML   running   locally   and   the   following   ENV values   set .\\ n\\ nAIDER_OPENAI_API_BASE =\\ protect \\ vrule   width0pt \\ protect \\ href { http ://127.0.0.1:5001/ v1 }{ http ://127.0.0.1:5001/ v1 }   \\ nAIDER_MODEL = TheBloke_wizard - vicuna -13 B - SuperHOT -8K - GGML   \\ nAIDER_MODEL_TOKENS =2\\ nAIDER_TOKENIZER = llama user_login :   bytedisciple state :   closed changed_files_count :   7 changed_files :   ...   ( ommited   here   for   brevity ) base_commit :   cdf8f9a4b2b4a65993227ac5af1eaf3f1b85c9d8 repo :   aider pr_number :   322 user_login :   omri123 state :   closed title :   RFC   -   Allow   adding   a   github   issue   to   chat   context body :   Hi ,   would   you   like   to   take   a   look   on   this   feature ?\\ n\\ nIn   the   first   commit   I changed   Coder   to   allow   adding   arbitrary   additional   context   in   the   begining   of   the chat .\\ nIn   the   second   commit   I   used   this   infra   to   add   github   issues   to   the   chat .\\ n\\ nI   didn   ' t   add   a   new   command ,   instead   I   extended   ` / add   `   to   allow   ` / add   \\ issue -3   ` .\\ nThe   feature   is   disabled   by   default   and   enabled   with   a   flag .   If   enabled ,   the   user need   to   supply   github   repository   name   and   authentication   token .\\ n\\ nThanks \\ nOmri changed_files_count :   7 changed_files :   ...   ( ommited   here   for   brevity ) base_commit :   af71638b06be7e934cdd6f4265f9e0c8425d4e6d repo :   aider  24\n\npr_number :   577 title :   Adding   a   simple   browser   based   GUI body :   Run   aider   with   ` -- browser   `   to   launch   the   UI . user_login :   paul - gauthier state :   closed changed_files_count :   12 changed_files :   ...   ( ommited   here   for   brevity ) base_commit :   8 a9005eed19417c59aa9432436ea8cb5e04bbb11  Listing 3: Examples of SWE-Features. Here we randomly select 3 examples for each repo and present their attributes.  H   Prompts for SWE-Features  When the sleep-time compute is turned off, the prompt is as below:  ‚ü® uploaded files ‚ü©  working dir  ‚ü® uploaded files ‚ü©  I‚Äôve uploaded a python code repository in the directory working dir.   Consider the following PR description:  ‚ü® pr description ‚ü©   problem statement   ‚ü® pr description ‚ü©  Can you help me implement the necessary changes to the repository so that the requirements specified in the   ‚ü® pr description ‚ü©   are met? Your task is to make the minimal changes to the repository to ensure the ¬°pr description¬ø is satisfied. Follow these steps to resolve the issue: 1. As a first step, it might be a good idea to find and read code relevant to the   ‚ü® pr description ‚ü©  2. Plan your approach to modify the relevant files and implement the changes, and add new files if necessary. 3. After finish the changes, revise the plan if needed. 4. With the new plan, make more changes, and continue the loop until necessary changes are made. 5. Create some test scripts to verify the changes. If the test does not run through, you need to go back and revise the plan and make necessary changes. 6. Submit the changes when you think the changes are correct and the pr description is satisfied. Your thinking should be thorough and so it‚Äôs fine if it‚Äôs very long. Do not stop chaining or stop and send your thoughts to the user until you have resolved the issue. The following are several pull request descriptions and their corresponding model patches: Title: pr title Body: pr body File: file1 filename Status: file1 status Patch: file1 patch ... (some more files and some more relevant pull requests) When the sleep-time compute is turned on, we first use the following prompt to ask the agent to explore the repository with all pull requests one by one: 25\n\nThe following is a pull request description and its corresponding model patches: Title: pr title Body: pr body File: file1 filename Status: file1 status Patch: file1 patch Please read through the above information and try to understand the issue. You can explore the repo if needed. Summarize your understanding from the following perspectives: 1. The issue description. 2. The changed files. 3. How do these changed files work.  After exploring the repository with all relevant pull requests, we give the agent the following prompt as the final prompt to start working on the issue at test time:  ‚ü® uploaded files ‚ü©  working dir  ‚ü® uploaded files ‚ü©  I‚Äôve uploaded a python code repository in the directory working dir.   Consider the following PR description:  ‚ü® pr description ‚ü©   problem statement   ‚ü® pr description ‚ü©  Can you help me implement the necessary changes to the repository so that the requirements specified in the   ‚ü® pr description ‚ü©   are met? Your task is to make the minimal changes to the repository to ensure the ¬°pr description¬ø is satisfied. Follow these steps to resolve the issue: 1. As a first step, it might be a good idea to find and read code relevant to the   ‚ü® pr description ‚ü©  2. Plan your approach to modify the relevant files and implement the changes, and add new files if necessary. 3. After finish the changes, revise the plan if needed. 4. With the new plan, make more changes, and continue the loop until necessary changes are made. 5. Create some test scripts to verify the changes. If the test does not run through, you need to go back and revise the plan and make necessary changes. 6. Submit the changes when you think the changes are correct and the pr description is satisfied. Your thinking should be thorough and so it‚Äôs fine if it‚Äôs very long. Do not stop chaining or stop and send your thoughts to the user until you have resolved the issue.  I   Context-Only Baseline  To check that the questions in Stateful AIME and Stateful GSM-Symbolic are not trivially guessable, we compare sleep-time compute against a context-only baseline, which only provides the model with   c , expecting the LLM to guess the most likely question and output the answer to whatever that question might be. We see on both Stateful AIME in Figure 22 and Stateful GSM-Symbolic in Figure 21 that sleep-time compute significantly outperforms the context-only baseline, demonstrating that the questions in our datasets are not trivially predictable from the context. 26\n\n100   200   300   400  Avg. Test Time Tokens / Question  0.0  0.2  0.4  0.6  0.8  Accuracy  GSM8K-Symbolic P1  0   100   200   300   400   500  Avg. Test Time Tokens / Question  0.0  0.2  0.4  0.6  0.8  Accuracy  GSM8K-Symbolic P2  gpt-4o-mini  gpt-4o-mini + sleep-time compute  gpt-4o  gpt-4o + sleep-time compute Figure 21: Context only baseline.   Comparing the test-time compute vs.   accuracy tradeoff on Stateful GSM-Symbolic, for sleep-time compute verses the context only baseline (e.g. the model has to guess the most likely question to answer). We see that sleep-time compute significantly outperforms the context only baseline, demonstrating that the questions in Stateful GSM-Symbolic cannot be trivially guessed. 0   2000   4000   6000   8000   10000   12000  Avg. Test Time Tokens / Question  0.3  0.4  0.5  0.6  0.7  Accuracy  o3-mini - Stateful-AIME 2024  2000   4000   6000   8000   10000  Avg. Test Time Tokens / Question  0.25  0.30  0.35  0.40  0.45  0.50  0.55  0.60  Accuracy  o1 - Stateful-AIME 2024  sleep-time compute   ablate question  Figure 22: Context only baseline.   Comparing the test-time compute vs.   accuracy tradeoff on Stateful AIME, for sleep-time compute verses the context only baseline (e.g. the model has to guess the most likely question to answer). We see that sleep-time compute significantly outperforms the context only baseline, demonstrating that the questions in Stateful AIME cannot be trivially guessed.  J   Stateful AIME Construction  To construct the examples for Stateful AIME, we split each AIME 2024 and 2025 into a sequence of ‚Äústate- ments‚Äù, which correspond to punctuation separated stentences in the problem. Similar to how we construct Stateful GSM-Symbolic, we use all but the last statement as the context, and the final statement as the query. 27\n\nThere are a couple of edge cases where the question is posed in e.g. the second to last statement rather than the last statement. In these cases, we manually rearrange the statements to ensure the query being used corresponds to the question. In a few cases, there is only one statement in the problem. In these cases, the context is empty. AIME includes a latex representation of figures. However, these latex figures can leak information about the answer: for example, these latex figures can contain exact information about the lengths of the sides in a geometry problem, giving away the answer. In these cases we first ensure that the problem is solvable without the figure and then manually strip the figure latex from the problem context.  K   Implementation Details  We implement sleep-time compute via function calling. When applying sleep-time compute, the model is given access to two functions,   rethink memory   and   finish rethinking . The   rethink memory   function takes as input a new string, and replaces the current context   c   and replaces the current context with the new string. The   finish rethinking   function terminates the sleep-time compute process. The model is allowed to call the function   rethink memory   for up to 10 times.  L   AIME main results by year M   AIME sleep-time compute scaling results by year  28\n\n1000   2000   3000   4000   5000   6000   7000  Avg. Test Time Tokens / Question  0.5  0.6  0.7  0.8  0.9  Accuracy  o3-mini - Stateful-AIME 2024  2000   4000   6000   8000   10000   12000  Avg. Test Time Tokens / Question  0.50  0.55  0.60  0.65  0.70  0.75  Accuracy  o1 - Stateful-AIME 2024  2500   5000   7500   10000   12500   15000   17500   20000  Avg. Test Time Tokens / Question  0.300  0.325  0.350  0.375  0.400  0.425  0.450  0.475  Accuracy  Claude 3.7 Sonnet - Stateful-AIME 2024  1000   2000   3000   4000   5000   6000  Avg. Test Time Tokens / Question  0.1  0.2  0.3  0.4  0.5  0.6  0.7  Accuracy  DeepSeek R1 - Stateful-AIME 2024  sleep-time compute   test-time compute only Figure 23: AIME 2024 main result 29\n\n0   1000   2000   3000   4000   5000   6000   7000   8000  Avg. Test Time Tokens / Question  0.3  0.4  0.5  0.6  0.7  Accuracy  o3-mini - Stateful-AIME 2025  2000   4000   6000   8000   10000  Avg. Test Time Tokens / Question  0.40  0.45  0.50  0.55  0.60  0.65  0.70  0.75  0.80  Accuracy  o1 - Stateful-AIME 2025  5000   10000   15000   20000  Avg. Test Time Tokens / Question  0.20  0.25  0.30  0.35  0.40  Accuracy  Claude 3.7 Sonnet - Stateful-AIME 2025  1000   2000   3000   4000   5000   6000  Avg. Test Time Tokens / Question  0.1  0.2  0.3  0.4  0.5  0.6  Accuracy  DeepSeek R1 - Stateful-AIME 2025  sleep-time compute   test-time compute only Figure 24: AIME 2025 main result 30\n\n2000   3000   4000   5000   6000  Avg. Test Time Tokens / Question  0.40  0.45  0.50  0.55  0.60  Accuracy  o1 Sleep-Time Compute Stateful-AIME 2024  1000   2000   3000   4000   5000   6000   7000  Avg. Test Time Tokens / Question  0.45  0.50  0.55  0.60  0.65  0.70  0.75  Accuracy  o3-mini Sleep-Time Compute Stateful-AIME 2024  low reasoning effort sleep-time   medium reasoning effort sleep-time   high reasoning effort sleep-time Figure 25: Scaling sleep-time compute for Stateful AIME2024. 1000   1500   2000   2500   3000   3500   4000   4500   5000  Avg. Test Time Tokens / Question  0.275  0.300  0.325  0.350  0.375  0.400  0.425  0.450  0.475  Accuracy  o1 Sleep-Time Compute Stateful-AIME 2025  1000   2000   3000   4000   5000  Avg. Test Time Tokens / Question  0.3  0.4  0.5  0.6  0.7  Accuracy  o3-mini Sleep-Time Compute Stateful-AIME 2025  low reasoning effort sleep-time   medium reasoning effort sleep-time   high reasoning effort sleep-time  Figure 26: Scaling sleep-time compute on Stateful AIME2025 31",
    "1  Dynamic gNodeB Sleep Control for Energy-Conserving 5G Radio Access Network  Pengfei Shen, Yulin Shao,   Member, IEEE , Qi Cao, Lu Lu,   Member, IEEE  Abstract ‚Äî5G radio access network (RAN) is consuming much more energy than legacy RAN due to the denser deployments of gNodeBs (gNBs) and higher single-gNB power consumption. In   an   effort   to   achieve   an   energy-conserving   RAN,   this   pa- per develops a dynamic on-off switching paradigm, where the ON/OFF states of gNBs can be dynamically configured according to the evolvements of the associated users. We formulate the dynamic   sleep   control   for   a   cluster   of   gNBs   as   a   Markov decision process (MDP) and analyze various switching policies to reduce the energy expenditure. The optimal policy of the MDP that minimizes the energy expenditure can be derived from dynamic programming, but the computation is expensive. To circumvent this issue, this paper puts forth a greedy policy and an index policy for gNB sleep control. When there is no constraint on the number of gNBs that can be turned off, we prove   the   dual-threshold   structure   of   the   greedy   policy   and analyze   its   connections   with   the   optimal   policy.   Inspired   by the dual-threshold structure and Whittle index, we develop an index policy by decoupling the original MDP into multiple one- dimensional MDPs ‚Äì the indexability of the decoupled MDP is proven and an algorithm to compute the index is proposed. Extensive simulation results verify that the index policy exhibits close-to-optimal performance in terms of the energy expenditure of   the   gNB   cluster.   As   far   as   the   computational   complexity is   concerned,   on   the   other   hand,   the   index   policy   is   much more efficient than the optimal policy, which is computationally prohibitive when the number of gNBs is large.  Index   Terms ‚ÄîBase   station   sleep   control,   5G,   radio   access network, Markov decision process, greedy policy, index policy.  I. I NTRODUCTION  A. Background  With the rolling out of 5G new radio (NR), the energy expenditure of commercial broadband cellular networks be- comes a growing concern [1]‚Äì[4]. To support enhanced mobile broadband communications at   10   Gbps and provide seamless coverage, 5G base stations (BSs), i.e., gNodeB (gNB), are deployed more densely than 4G eNodeB (eNB). It is antici- pated that the number of gNB will reach 65 million by 2025, and the average density of gNB will be three times higher than that of eNB [5]. On the other hand, gNB incorporates a number of new and power-hungry components [6], such as in- tegrated massive MIMO antennas, faster data converters, high- power/low-noise amplifiers, and millimeter wave (mmWave)  P. Shen and L. Lu are with the University of Chinese Academy of Sciences, and the Key Laboratory of Space Utilization, Chinese Academy of Sciences, Beijing 100094, China (emails:   { shenpengfei19, lulu } @csu.ac.cn). Y.   Shao   is   with   the   Department   of   Electrical   and   Electronic   En- gineering,   Imperial   College   London,   London   SW7   2AZ,   U.K.   (e-mail: y.shao@imperial.ac.uk). C. Qi is with Xidian-Guangzhou Research Institute, Xidian University, Guangzhou, China (e-mail: caoqi@xidian.edu.cn).  transceivers. As a consequence, the power expenditure of a single gNB is estimated to be two to four times higher than that of an eNB [7]. The increasing energy expenditure of mobile radio access networks (RANs) leads to higher costs and larger amounts of greenhouse gas emissions ‚Äì as it stands now, the mobile communication industry contributes 15% to 20% of CO 2   emissions among the information and communication technology (ICT) industries [8]. To reduce the overall cost and achieve green mobile net- works, various energy-conserving schemes have been pro- posed in the literature [9]‚Äì[12], such as BS sleep control, energy harvesting, hardware optimization, energy-efficiency- oriented resource allocation, and network coverage planning, among which BS sleep control receives the most attention. The power consumption of a BS mainly comes from three aspects: 1) the static consumption [13]‚Äì[15], i.e., the power consumed by operating the BS, such as the power consumption of the electrical parts, circuits, cooling systems, etc.; 2) the dynamic consumption [13]‚Äì[17], i.e., the power consumed by serving users; and 3) the switching consumption [18]‚Äì[20], i.e., the power consumed by switching the BSs between ON and OFF states. The traffic load of a BS can vary dramatically at different times of day [2], [14]. The deployment and operation of BSs, however, are often designed to meet the peak traffic load ‚Äì hence a large amount of energy for operating the BSs is wasted during off-peak hours. In this light, BS sleep control is proposed to turn off the BSs with no or light traffic and wake them up again when there is moderate or heavy traffic, thereby saving the static power of light-traffic BSs. A practice of BS sleep control is implemented by China Mobile [21], in which a fraction of BSs are manually turned off overnight. It is reported that the energy expenditure is reduced by 36 million kilowatt hour (kWh) per year with the manual configuration of BS states.  B. Prior arts  Many research efforts have been devoted to BS sleep control in heterogeneous mobile networks [9], [22]. In general, the problem of BS switching control is combinatorial optimization and is often NP-hard. The research focus of prior arts is on designing efficient BS switching policies. Early studies on BS sleep control utilize state-independent policies [23], [24], such as random policy, to control the sleep mode of either macro or micro BSs in heterogeneous networks. In their formulations, the locations of mobile users, macro and micro BSs are often modeled as independent homogeneous Poisson point processes (PPPs). Each BS is associated with  arXiv:2207.06309v1 [cs.IT] 13 Jul 2022\n\n2  a turn-off probability. The optimization problems are then formulated to find the optimal set of turn-off probabilities to minimize the BS energy expenditure. Beyond state-independent policies, a more prevailing ap- proach to model the problem of BS sleep control is taking user distribution, BS traffic load, or transmission power budget, etc., as ‚Äústates‚Äù and designing switching policies that are governed by these states. Under this formulation, [25]‚Äì[27] in- vestigated threshold-based switching policies; [13], [28], [29] investigated the greedy policy; [30], [31], and [32] developed a switching-on/off based energy saving (SWES) algorithm, a local search algorithm, and a genetic algorithm (GA)-based al- gorithm, respectively, to solve the combinatorial optimization problems. These works, however, aim to minimize the myopic energy expenditure of mobile networks, hence is suboptimal in terms of the long-term energy expenditure when the network dynamics are correlated over time. To develop switching policies that minimize the long-term network energy expenditure, [18], [33]‚Äì[38] formulate the BS sleep control problem as Markov decision processes (MDPs). Specifically, the optimal policy for the MDP is investigated in [33] and [34]. The optimal policy, however, is known for its high complexity. To circumvent this issue, [35] proposed a policy rollout algorithm to be used in conjunction with the greedy policy to approximate the value function of each state. Along this direction, another line of work leverages deep rein- forcement learning (DRL) techniques to solve the MDP [18], [36]‚Äì[38]. The salient feature of DRL is model-free. That is, given unknown network dynamics, DRL algorithms are able to adapt to the traffic load variations and produce good switching policies that reduce the network power consumption [39], [40]. DRL algorithms, however, only produce achievability under an unknown environment, but fail to characterize the optimal policy of MDP.  C. Contributions  In this paper, we put forth a dynamic on-off switching approach to achieve efficient BS sleep control tailored for the new generation RAN (NG-RAN) architecture standardized in the latest third generation partnership project (3GPP) releases. As shown in Fig. 1, 3GPP NG-RAN defines two classes of RAN architectures for the deployment of 5G NR [41], i.e., the standalone (SA) and non-standalone (NSA) architectures. In both architectures, a user can connect to either gNB or eNB/ng-eNB (ng-eNB is an updated version of 4G eNB), indicating that light-traffic gNB can be turned off and the traffic demands of users in a turned-off gNB can be fulfilled by eNB or ng-eNB. To   achieve   judicious   gNB   sleep   control   and   energy- conserving 5G networks, we take the dynamic evolvement of users into account and formulate the on-off configuration of a cluster of 5G cells as an MDP. Given this formulation, we design and analyze various switching policies to mini- mize the long-term average   cost   of the 5G cells, where the cost of a 5G cell is a non-decreasing function of the cell‚Äôs power consumption. The optimal policy to the formulated MDP exhibits the best performance, i.e., the minimum long- term average cost, but its computational complexity increases NGC  gNB  Option 2  gNB  NGC  eNB/ng - eNB  Option 4/4a  NG - RAN SA  Option 3/3a/3x   Option 7/7a/7x  NG - RAN NSA  EPC  eNB/ng - eNB  gNB  NGC  eNB/ng - eNB gNB  EPC  eNB/ng - eNB  Figure 1: The standalone (SA) and non-standalone (NSA) architectures of NG-RAN. The difference between SA and NSA lies in whether the control plane of gNB is connected to the core networks directly or via eNB/ng-eNB. The core network can be 4G evolved packet core (EPC) or 5G new generation core (NGC). exponentially in the number of 5G cells. State-independent policies, in contrast, are computationally simple, but their performances are suboptimal. In this context, we propose and analyze two policies, one is a greedy policy and the other is an index policy to solve the MDP. For the greedy policy, we prove its dual-threshold structure when there is no constraint on the number of gNBs that can be turned off, and analyze its connections with the optimal policy. Furthermore, inspired by the dual-threshold structure and Whittle index, we decouple the original MDP to multiple one-dimensional MDPs and prove the indexability of the decoupled MDP, whereby an index policy is proposed. As far as the long-term average cost is concerned, the index policy achieves close-to-optimal performance in various simulation setups and is better than the greedy policy and state-independent policies. As far as the computational complexity is concerned, the index policy is much more efficient to compute than the optimal policy and the greedy policy. The remainder of this paper is organized as follows. Sec- tion II presents the system model and formulates the MDP. Section III analyzes the optimal policy and the greedy policy. Section IV studies the index policy. Two state-independent policies are analyzed in Section V. In addition, a lower bound is derived to measure the performance of various policies when the optimal policy is computationally prohibitive. Numerical and simulation results are presented in Section VI. Section VII concludes this paper.  Notations   ‚Äì We use boldface lowercase letters to denote column vectors and boldface uppercase letters to denote ma- trices. For a vector or matrix,   ( ¬∑ ) >   denotes the transpose.  R   and   N   stand for the sets of real and non-negative integer values, respectively. The imaginary unit is represented by   j . The cardinality of a set   V   is denoted by   |V| . II. S YSTEM   M ODEL  A. Problem formulation  We consider a cluster of   M   5G cells indexed by   { m   :   m   = 1 ,   2 ,   ¬∑ ¬∑ ¬∑   , M   } . Each cell is equipped with a gNB located in the center and the gNBs are managed by a central controller. The power consumption of a gNB consists of three main\n\n3 ng - eNB   gNB  5GC   UE  Figure 2: A cluster of 5G cells with   M   gNBs and one ng-eNB, where NGC stands for the 5G core network and UE stands for user. parts [2], [14]: static, dynamic, and switching, denoted by  P static ,   P dynamic , and   P switch , respectively.   P static   is the power consumption incurred by the operations of the gNB, such as the electrical parts, circuits, cooling systems, etc. It is constant when the gNB is on and zero when the gNB is off.  P dynamic   is the power consumed by serving users, and hence, is proportional to the number of users in the cell.   P switch   is the power consumed by state switching when the gNB is turned from the OFF state to the ON state (the power consumption of switching state from ON to OFF is often omitted [18]). Time   is   divided   into   segments   of   duration   T s .   At   the beginning of a time segment, the central controller configures the ON/OFF states of the gNBs based on the number of existing users in the cells as well as the anticipated users in the future. Intuitively, when the number of users in a cell is large, the gNB has to be turned on to provide good quality of services to users at the expense of high power expenditure. On the other hand, when the number of users is small, the gNB can be turned off to save   P static   and   P dynamic . In this case, the users in the 5G cells will be served by the ng- eNB, which is capable of satisfying most requirements of the small number of users. Note that ng-eNB is always on, thus, there is no switching power consumption and its static power consumption is irrelevant. The dynamic power consumption of the ng-eNB is denoted by   P extra , which is proportional to the number of users to be served (as   P dynamic ). Typically, the per- user dynamic power consumption of a gNB is smaller than that of the ng-eNB thanks to the closer deployments to the users. In this paper, we assume that the ng-eNB can serve at most   K   5G cells and   0   ‚â§   K   ‚â§   M   . Note that when   K   =   M   , all   M   gNBs are allowed to be turned off. To discover the optimal configuration policy for the central controller, this paper models the state configuration problem of the cell cluster as a discrete MDP, wherein the central controller makes successive switching actions based on the states of the BS cells to minimize the long-term average power consumption. More rigorously, we define the ingredients of the MDP as follows.  Definition   1   (Action) .   At the beginning of the   t -th time segment, the action of the central controller is defined as  a t   ,   ( a t  1 , a t  2 ,   ¬∑ ¬∑ ¬∑   , a t M   ) > , where   a t m   ‚àà { 0 ,   1 }   denotes the state of the   m -th gNB in the   t -th time segment (0 and 1 stand for OFF and ON, respectively). A constraint on   a t   is ‚àë M m =1   a t m   ‚â•   M   ‚àí   K ,   ‚àÄ t , as the ng-eNB can serve at most   K  cells, where   K   ‚àà { 0 ,   1 ,   2 ,   ¬∑ ¬∑ ¬∑   , M   } .  Definition   2   (State) .   At   the   beginning   of   the   t -th   time segment, the state of the cell cluster is defined as   s t   ,  ( s t  1 , s t  2 ,   ¬∑ ¬∑ ¬∑   , s t M   ) > , where   s t m   denotes the state of the   m -th cell. In particular,   s t m   ,   ( a t ‚àí 1  m   ,   Àú n t m )   consists of two parts:  a t ‚àí 1  m   is the ON/OFF state of the   m -th gNB in the   ( t   ‚àí   1) -th time segment and   Àú n t m   denotes the number of users in the   m -th cell.  It is worth noting that   Àú n t m   is the residual users from the  ( t ‚àí 1) -th time segment. On the other hand, the dynamic power consumption   P dynamic   is proportional to the total number of users   N   t m   in the cell. In the   t -th time segment,   N   t m   consists of two parts: the residual users from the   ( t ‚àí 1) -th time segment and the newly arrived users. Thus, we can write   N   t m   =   Àú n t m   +  n t m , where   n t m   denotes the number of newly arrived users in the   t -th time segment. The user arrival and departure models are explained in more detail later in Section II-B.  Definition 3   (Immediate cost) .   Suppose the power consumed by the   m -th cell is   P ( s t m , a t m )   in the   t -th time segment. The immediate cost of the action   a t m   when in state   s t m   is defined as   c ( s t m , a t m )   ,   f   [ P ( s t m , a t m )] , where   f   is a non-decreasing function. Accordingly, the immediate cost of the cell cluster is  C ( s t ,   a t )   ,   ‚àë M m =1   c ( s t m , a t m ) .  A configuration/switching policy   œÄ   is a mapping from the state space to the action space, i.e.,   a t   =   œÄ ( s t ) . Given the above definitions, the average cost incurred by a given policy  œÄ   over the infinite-time horizon is  C œÄ   =   lim  T   ‚Üí‚àû   E  [  1  T  T   ‚àí 1 ‚àë  t =0  C ( s t ,   a t )  ]  ,   (1) where the expectation is taken over the dynamics of user arrival and departure in each cell. The objective of the central controller is to discover the optimal policy   œÄ ‚àó   such that the long-term average cost   C œÄ   is minimized, giving  ( P1 ) :   œÄ ‚àó   = arg min  œÄ   C œÄ   ,   (2)  s.t. ,  M ‚àë  m =1  a t m   ‚â•   M   ‚àí   K,   ‚àÄ t.  B. Users‚Äô arrival, departure, and power consumption  This   paper   models   the   users‚Äô   arrival   and   departure   as follows.  Definition 4   (User arrival and departure processes) .   We as- sume that users arrive at and depart from a cell in an indepen- dent and identically distributed (i.i.d.) fashion. In particular, 1) Users‚Äô arrival to a cell follows a mixed Poisson process with a set of parameters   Œõ = ( Œª 1 , Œª 2 ,   ¬∑ ¬∑ ¬∑   , Œª J   ) . That is,\n\n4  the number of newly arrived users in the t-th time segment follows  Pr( n t m   =   ` ) =  J ‚àë  j =1  p m,j  ( Œª j   T s ) `  ` !   e ‚àí Œª j   T s   ,   (3)  where   Œª j   is sampled from   Œõ   with probability   Pr( Œª j   ) =  p m,j   in the   m -th cell. It is worth noting that the mixed Poisson process can be used to fit arbitrary distributions [42]. 2) The staying time of a user in the   m -cell follows the exponential distribution with parameter   Œº m , where   Œº m  is the mean service time of a user.  Given the user arrival and departure processes, we first analyze the number of users in a cell at the beginning of a time segment   Àú n t m .  Proposition 1   (The distribution of residual users) .   At the beginning   of   the   t -th   time   segment,   the   probability   mass function (PMF) of the number of users in the   m -th cell   Àú n t m   is given by  Pr( Àú n t m   =   ` ) =  J ‚àë  j =1  p m,j  ( Àú Œª m,j  ) `  ` !   e ‚àí Àú Œª m,j   ,   (4)  for   `   = 0 ,   1 ,   2 ,   ¬∑ ¬∑ ¬∑   , where   Àú Œª m,j   =   Œª j  Œº m   (1   ‚àí   e ‚àí Œº m T s   ) . The average   Àú n t m   is   E [ Àú n t m ] =   ‚àë J j =1   p m,j   Àú Œª m,j   . Proof.   See Appendix A.   \u0004  The dynamic power consumption of a cell is proportional to the number of users to be served   N   t m   =   Àú n t m   +   n t m . At the beginning of the   t -th time segment, the number of existing users in the cells   { Àú n t m   :   m   = 1 ,   2 ,   ¬∑ ¬∑ ¬∑   , M   }   is known to the central controller, while the number of users to arrive in the  t -th time segment is a random variable, the exact number of which is unknown. Thus, the central controller can only make decisions based on the expected number of users to arrive in the   t -th time segment.  Proposition 2   (Anticipated power consumption of a cell) .  Denote by   P d   and   P e   the average power consumption of the gNB and ng-eNB to serve a single user, respectively. At the beginning of the   t -th time segment, the anticipated power consumption of the   m -th cell is given by  P   ( s t m   = ( a t ‚àí 1  m   ,   Àú n t m ) , a t m  )   =   (5)  Ô£± Ô£¥ Ô£≤ Ô£¥ Ô£≥  P static   +   ( Àú n t m   +   Œª m T s  )   P d ,   if   a t m   =   a t ‚àí 1  m   = 1;  P static   +   P switch   +   ( Àú n t m   +   Œª m T s  )   P d ,   if   a t m   = 1 , a t ‚àí 1  m   = 0;  ( Àú n t m   +   Œª m T s  )   P e ,   if   a t m   = 0 ,  where   Œª m   ,   ‚àë J j =1   p m,j   Œª j   and   Œª m T s   is the expected number of newly arrived users in the   t -th time segment in the   m -th cell.  III. T HE   O PTIMAL   P OLICY AND THE   G REEDY   P OLICY  A. The optimal switching policy  Given the definitions in Section II, the discrete MDP asso- ciated with the on-off switching of gNBs can be described as follows. At the beginning of the   t -th time segment, the central controller observes a system state   s t   = ( s t  1 , s t  2 ,   ¬∑ ¬∑ ¬∑   , s t M   ) >   and determines a set of configurations   a t   = ( a t  1 , a t  2 ,   ¬∑ ¬∑ ¬∑   , a t M   ) >  for the gNBs following its policy   œÄ . The action produces two results: an immediate cost   C ( s t ,   a t )   is incurred, and the system evolves to a new state   s t +1   in the next time segment. The optimal switching policy   œÄ ‚àó   that minimizes the long- term average cost in (2) satisfies the Bellman equation:  g ‚àó   + h œÄ ‚àó   [ s ] = min  a  {  C ( s ,   a ) +   ‚àë  s ‚Ä≤  Pr( s ‚Ä≤   | s ,   a   ) h œÄ ‚àó   [ s ‚Ä≤ ]  }  (6) where   h œÄ ‚àó   [ s ]   is the relative value function of a state   s   under the optimal policy   œÄ ‚àó ;   g ‚àó   is the average cost incurred per time step under the optimal policy   œÄ ‚àó ;   Pr( s ‚Ä≤   | s ,   a   )   is the probability that the system moves to a new state   s ‚Ä≤   when the action   a   is executed in the state   s . Specifically, we have  Pr( s ‚Ä≤   | s ,   a   )   ( a )  =  M ‚àè  m =1  Pr( s ‚Ä≤  m   | s m , a m   )   (7)  ( b )  =  M ‚àè  m =1  Pr( Àú n ‚Ä≤  m   | Àú n m , a m   )  ( c )  =  M ‚àè  m =1  Ô£´ Ô£¨ Ô£≠  J ‚àë  j =1  p m,j  ( Àú Œª m,j  ) Àú n ‚Ä≤  m  Àú n ‚Ä≤  m !   e ‚àí Àú Œª m,j  Ô£∂ Ô£∑ Ô£∏   ,  where (a) follows from the independent assumption of the cells; (b) follows because the actions are determined once a policy is given ‚Äì the only random variable in the state   s ‚Ä≤  m   is  Àú n ‚Ä≤  m ; (c) follows from Proposition 1. The solution   ( g ‚àó , h œÄ ‚àó   )   to (6) can be solved by the relative value iteration algorithm (RVIA) since the MDP is unichain [39]. Once (6) is solved, the optimal policy   œÄ ‚àó   can be extracted by acting greedy, i.e., choosing the action that gives the minimal cost:  œÄ ‚àó ( s ) = arg min  a  {  C ( s ,   a ) +   ‚àë  s ‚Ä≤  Pr( s ‚Ä≤   | s ,   a   ) h œÄ ‚àó   [ s ‚Ä≤ ]  }  .   (8) This solution of RVIA is optimal, but it exhibits several problems. First, the number of states needs to be finite to solve (6). In our problem, the state size is infinite as the number of users in a cell can be any non-negative integers. Therefore, an upper limit   N th   has to be set such that the number of users in a cell is reset to   N th   if it is larger than   N th . In order not to affect the optimality of the RVIA,   N th   should be large enough to make   Pr( Àú n t m   > N th )   negligible for a set of policies in the neighborhood of the optimal switching policy. Given   the   upper   limit   N th ,   the   state   size   is   | s |   = [ ( M  0  )   +   ( M  1  )   +   ¬∑ ¬∑ ¬∑   +   ( M K  ) ]  ( N th   + 1) M   and the action size is  | a |   =   ( M  0  )   +   ( M  1  )   +   ¬∑ ¬∑ ¬∑   +   ( M K  ) . The decision space is thus  | s |√ó| a |√ó| s |   =  [( M  0  )  +  ( M  1  )  + ¬∑ ¬∑ ¬∑ +  ( M K  )] 3  ( N th +1) 2 M   .   (9) This   implies   a   formidable computational   complexity   of RVIA as the complexity will grow exponentially with the increase of   M   ‚Äì often, the optimal policy is incomputable when   M   is larger than 4.\n\n5  B. The greedy switching policy  Considering the high computational complexity of the op- timal policy, a widely-used alternative to solve the discrete MDP is the greedy policy [43]. As the name suggests, the greedy policy minimizes the immediate cost of the current time segment, as opposed to the long-term average cost   C . Denote by   œÄ g   the greedy policy. At the beginning of the   t -th time segment, the action   a t g   chosen by the greedy policy can be written as  a t g   =   œÄ g   ( s t ) = arg min  a t   C ( s t ,   a t ) ,   ‚àÄ t.   (10) Compared with the optimal policy, the decision criterion of the greedy policy is relatively simpler as it considers only the immediate cost. In our problem, the decision space of the greedy policy is  | s | √ó | a |   =  [ ( M  0  )   +   ( M  1  )   +   ¬∑ ¬∑ ¬∑   +   ( M K  ) ] 2  ( N th   + 1) M   , which also scales with   M   . However, when   K   =   M   (i.e., all the gNBs are allowed to be turned off), the greedy policy exhibits a nice threshold structure, as demonstrated in Theorem 3, and can be computed efficiently. For simplicity, the anticipated cost of a time segment for the   m -th cell is defined as follows  C (01)  m   ,   E Àú n t m  { f   [ P   ( s t m   = ( a t ‚àí 1  m   = 0 ,   Àú n t m ) , a t m   = 1 )]}  =   E Àú n t m  { f   [ P static   +   P switch   + ( Àú n t m   +   Œª m T s ) P d  ]}   , C (11)  m   ,   E Àú n t m  { f   [ P   ( s t m   = ( a t ‚àí 1  m   = 1 ,   Àú n t m ) , a t m   = 1 )]}  =   E Àú n t m  { f   [ P static   + ( Àú n t m   +   Œª m T s ) P d  ]}   , C (0)  m   ,   E Àú n t m  { f   [ P   ( s t m   = ( a t ‚àí 1  m   ,   Àú n t m ) , a t m   = 0 )]}  =   E Àú n t m  { f   [ ( Àú n t m   +   Œª m T s ) P e  ]}   ,   (11) where   C (01)  m   is the anticipated cost of a time segment when  a t ‚àí 1  m   = 0   and   a t m   = 1 ;   C (11)  m   is the anticipated cost of a time segment when   a t ‚àí 1  m   =   a t m   = 1 ; and   C (0)  m   is the anticipated cost of a time segment when   a t m   = 0 .  Theorem 3   (Structure of the greedy policy) .   The greedy policy is a dual-threshold policy when   K   =   M   . Specifically, for the  m -th cell,   m   = 1 ,   2 ,   ¬∑ ¬∑ ¬∑   , M   , there exists two thresholds  Œ≥ L m   ,   P static  P e   ‚àí P d  ‚àí Œª m T s , Œ≥ U m   ,   P static   +   P switch  P e   ‚àí P d  ‚àí Œª m T s ,   (12)  such that the action   a t m   under the greedy policy is given by  a t m   =  Ô£± Ô£¥ Ô£¥ Ô£¥ Ô£≤ Ô£¥ Ô£¥ Ô£¥ Ô£≥  1 ,   if   a t ‚àí 1  m   = 0   and   Àú n t m   > Œ≥ U m ; 0 ,   if   a t ‚àí 1  m   = 0   and   Àú n t m   ‚â§   Œ≥ U m ; 1 ,   if   a t ‚àí 1  m   = 1   and   Àú n t m   > Œ≥ L m ; 0 ,   if   a t ‚àí 1  m   = 1   and   Àú n t m   ‚â§   Œ≥ L m .  (13)  The long-term average cost of the greedy policy is  C g   =  M ‚àë  m =1  (   p L m  p L m   +   p U m  p U m C (01)  m   (14)  +   p U m  p L m   +   p U m  (1   ‚àí   p L m ) C (11)  m   +   p L m  p L m   +   p U m  C (0)  m  )  ,  where   p L m   ,   Pr( Àú n t m   < Œ≥ L m ) ;   p U m   ,   Pr( Àú n t m   > Œ≥ U m ) . Proof.   When   K   =   M   , the actions between each cell can be made independently. Therefore, we can focus on the greedy policy in one cell ‚Äì the immediate cost of the cell cluster is minimized as long as that of each cell is minimized. Consider the   m -th cell. Under the greedy policy, the   m -th gNB will be turned on in the   t -th time segment if   c ( s t m , a t m   = 1)   < c ( s t m , a t m   = 0) , where   c ( s t m , a t m ) =   f   [ P ( s t m , a t m )]   as in Definition 3. The tie breaks arbitrarily. Thus, when   a t ‚àí 1  m   = 0 , we have  f   [ ( Àú n t m   + Œª m T s ) P e  ]   > f   [ P static   + P switch   +( Àú n t m   + Œª m T s ) P d  ]   ,  i.e.,  Àú n t m   >   P static   +   P switch  P e   ‚àí P d  ‚àí   Œª m T s   ,   Œ≥ U m .  When   a t ‚àí 1  m   = 1 , we have  f   [ ( Àú n t m   +   Œª m T s ) P e  ]   > f   [ P static   + ( Àú n t m   +   Œª m T s ) P d  ]   ,  i.e.,  Àú n t m   >   P static  P e   ‚àí P d  ‚àí   Œª m T s   ,   Œ≥ L m .  In other words, depending on whether the gNB is ON or OFF in the   ( t ‚àí 1) -th time segment, we have two thresholds   Œ≥ L m  and   Œ≥ U m   for   Àú n t m : the gNB will be turned on if   Àú n t m   is larger than the two thresholds. On the other hand, the gNB will be turned off if   Àú n t m   is smaller than the two thresholds when the gNB is ON and OFF in the   ( t   ‚àí   1) -th time segment, respectively. This gives us the dual-threshold structure of the greedy policy. In the above context, the state transitions of a single cell under the greedy policy can be viewed as a Markov chain, and the state transition matrix is given by  [ 1   ‚àí   p L m   p L m  p U m   1   ‚àí   p U m  ]  ,   (15) where   p L m   ,   Pr( Àú n t m   < Œ≥ L m ) ;   p U m   ,   Pr( Àú n t m   > Œ≥ U m ) . The sta- tionary distribution of the Markov chain is  (   p U m  p L m + p U m  ,   p L m  p L m + p U m  )  , where   the   two   probabilities   correspond   to   ON   and   OFF, respectively. As a result, for a single cell, the long-term average cost of the greedy policy can be computed by  C g,m   = Pr( a t ‚àí 1  m   = 0 , a t m   = 1) C (01)  m   + Pr( a t ‚àí 1  m   = 1 , a t m   = 1) C (11)  m   + Pr( a t m   = 0) C (0)  m  =   p L m  p L m   +   p U m  p U m C (01)  m   +   p U m  p L m   +   p U m  (1   ‚àí   p L m ) C (11)  m   +  p L m  p L m   +   p U m  C (0)  m   ,  where   C (01)  m   ,   C (11)  m   , and   C (0)  m   are as defined in (11). The long- term average cost of the cell cluster is   C g   =   ‚àë M m =1   C g,m   as (14).   \u0004  Next, we analyze the connections between the greedy policy and the optimal policy.  Proposition 4   (Connections between the greedy policy and the optimal policy) .   Let   K   =   M   . For any cell in the cluster, 1) If the optimal policy instructs the gNB to turn off, the action of the greedy policy is also off. 2) If the greedy policy instructs the gNB to turn on, the optimal action is also on.\n\n6  Proof.   We prove Proposition 4 by contradiction. With the optimal policy   œÄ ‚àó , the long-term cost of the   m -th cell is given by   ‚àû ‚àë  t =1  c œÄ ‚àó   ( s t m , a t m ) .  At a time segment   t 0 , suppose the optimal action is OFF and the greedy action is ON. First, we have   c ( s t 0  m , a t 0  m   = 1)   < c ( s t 0  m , a t 0  m   = 0)   since the greedy action is ON. We can then construct a new policy as follows: i) in the   t 0 -th time segment, the new policy instructs the gNB to turn on, and ii) in any other time segments, it has the same action as the optimal policy. As can be seen, the cost incurred by the new policy differs from that of the optimal policy only in the   t 0 -th and   ( t 0   +1) -th time segments. In particular, the new policy incurs lower costs than the optimal policy since  c œÄ ‚àó   ( s t 0  m , a t 0  m   = 0) +   c œÄ ‚àó   ( s t 0 +1  m   , a t 0 +1  m   ) =   c œÄ ‚àó   ( s t 0  m , a t 0  m   = 0) +  {  f   [( Àú n t 0 +1  m   +   Œª m T s ) P e ] ,   if   a t 0 +1  m   = 0;  f   [ P static   + P switch   +( Àú n t 0 +1  m   + Œª m T s ) P d ] ,   if   a t 0 +1  m   = 1;  > c œÄ ‚àó   ( s t 0  m , a t 0  m   = 1) +  {  f   [( Àú n t 0 +1  m   +   Œª m T s ) P e ] ,   if   a t 0 +1  m   = 0;  f   [ P static   +( Àú n t 0 +1  m   + Œª m T s ) P d ] ,   if   a t 0 +1  m   = 1 ,  yielding a contradiction. As a result, for any time segments, if the optimal action is OFF, the greedy action must also be OFF. Likewise, it can be proven that when the greedy action is ON, the optimal action must also be ON; otherwise, a contradiction occurs.   \u0004  When   K   =   M   , Proposition 4 indicates that the number of ‚ÄúON‚Äù time segments under the greedy policy is no greater than that under the optimal policy. IV. T HE   I NDEX   P OLICY  The optimal policy and the greedy policy are computa- tionally expensive because the configurations of the   M   cells are coupled together, yielding decision spaces growing expo- nentially with   M   . One exception is the greedy policy with  K   =   M   , in which case the central controller can configure each cell independently and the greedy policy exhibits a dual-threshold structure. This implies that decoupling the cell configurations is a key to devising computationally efficient policies. Decoupling   the   MDP   dates   back   to   the   Whittle   index approach to solve the RMAB problem [44]. The general idea is to decouple the   M   -dimensional MDP to   M   one-dimensional MDPs, each decoupled MDP can then be solved efficiently thanks to the largely reduced state and action spaces. Inspired by Whittle‚Äôs approach [44], this paper puts forth an index policy for the on-off switching problem of gNBs.  A. The decoupled problem  To start with, we formulate the decoupled problem of (P1), i.e., the on-off switching of a single cell as opposed to the cell cluster. Specifically, we omit the constraint   ‚àë M m =1   a t m   ‚â§  M   ‚àí   K   in (2) so that the on-off configurations of gNBs are independent. For the decoupled problem, the subscript   m   is omitted in this subsection to ease exposition. The on-off switching of a single cell is a controlled Markov process defined as follows.  Definition 5   (The decoupled problem) .   Consider a single cell. The state of the cell at the beginning of the   t -th time segment is   s t   = ( a t ‚àí 1 ,   Àú n t ) , where   a t ‚àí 1   is the ON/OFF state of the cell in the   ( t   ‚àí   1) -th time segment and   Àú n t   ‚àà   N   stands for the number of users in the cell at the beginning of the   t -th time segment. The immediate cost incurred by a state-action pair ( s t   = ( a t ‚àí 1 ,   Àú n t ) , a t )   is  c ( s t , a t ) =   (16)  Ô£± Ô£¥ Ô£≤ Ô£¥ Ô£≥  f   [ P static   + ( Àú n t   +   ŒªT s ) P d  ]   ,   if   a t   =   a t ‚àí 1   = 1;  f   [ P static   +   P switch   + ( Àú n t   +   ŒªT s ) P d  ]   ,   if   a t   = 1 , a t ‚àí 1   = 0;  f   [ ( Àú n t   +   ŒªT s ) P e  ]   +   \u000f,   if   a t   = 0 ,  where   \u000f   is a cost of being OFF (which will be explained later). The optimal policy   Àú œÄ ‚àó   for the decoupled problem is defined as  ( P2 ) :   Àú œÄ ‚àó   = arg min  Àú œÄ   lim  T   ‚Üí‚àû   E  [  1  T  T   ‚àí 1 ‚àë  t =0  c ( s t , a t )  ]  .   (17) Compared with the original   M   -dimensional MDP, the de- coupled problem introduces a cost   \u000f   in (16) to penalize the OFF action. In particular, we aim to find the critical cost   \u000f ‚àó  for each state such that the expected costs incurred by turning on and off at the state are the same. In doing so, the index  \u000f ‚àó   acts as a measurement of how the controller is willing to pay to turn off the gNB. Said in another way,   \u000f ‚àó   >   0   means that the average cost for the action   a   = 0   (without the cost  \u000f ‚àó ) is smaller than that when   a   = 1 : the controller prefers to turn off this station, the larger   \u000f ‚àó   is, the more likely it is to be turned off. On the other hand,   \u000f ‚àó   <   0   means that the average cost for the action   a   = 1   is smaller, so the gNB is likely to be turned on. Given the above analysis, in the original problem with  M   cells, we can compute the corresponding indexes   \u000f ‚àó   for individual cells in each time segment according to their states. If more than   K   gNBs have positive   \u000f ‚àó , then we turn off the gNBs with   K   largest indexes. If less than   K   gNBs have positive   \u000f ‚àó , then we only turn off those with positive indexes. Next, we study how to solve the decoupled problem. As explained in Section III-A, the optimal policy of an MDP follows the Bellman equation. For the decoupled problem, the optimal policy   Àú œÄ ‚àó   follows  g ‚àó   +   h Àú œÄ ‚àó   [ s ] = min   { Q ( s, a   = 1) , Q ( s, a   = 0) }   ,   (18) where  Q ( s, a   = 1) =   c ( s, a   = 1) + Œ£ 1 , Q ( s, a   = 0) =   c ( s, a   = 0) + Œ£ 0   +   \u000f,  Œ£ 1   ,  ‚àû ‚àë  k =0  Pr( Àú n   =   k )   ¬∑   h Àú œÄ ‚àó   [ s   = (1 , k )] ,  Œ£ 0   ,  ‚àû ‚àë  k =0  Pr( Àú n   =   k )   ¬∑   h Àú œÄ ‚àó   [ s   = (0 , k )] ,\n\n7  and   Pr( Àú n   =   k )   represents the distribution of the residual users, as per (4);   h Àú œÄ ‚àó   [ s ]   is the relative value function of a state   s  under the optimal policy   Àú œÄ ‚àó ;   c ( s, a )   is the immediate cost given in (16);   g ‚àó   is gain of the decoupled MDP. To be more specific, we write one iteration of (18) in the equilibrium as follows:  Q [ s   = (1 ,   Àú n ) , a   = 1] =   f   [ P static   + ( Àú n   +   ŒªT s ) P d  ]   + Œ£ 1 , Q [ s   = (1 ,   Àú n ) , a   = 0] =   f   [ ( Àú n   +   ŒªT s ) P e  ]   + Œ£ 0   +   \u000f, h Àú œÄ ‚àó   [ s   = (1 ,   Àú n )] = min   { Q [ s   = (1 ,   Àú n ) , a   = 1] , Q [ s   = (1 ,   Àú n ) , a   = 0] }‚àí g ‚àó , Q [ s   = (0 ,   Àú n ) , a   = 1] =   f   [ P static   + P switch   +( Àú n + ŒªT s ) P d  ] +Œ£ 1 , Q [ s   = (0 ,   Àú n ) , a   = 0] =   f   [ ( Àú n   +   ŒªT s ) P e  ]   + Œ£ 0   +   \u000f, h Àú œÄ ‚àó   [ s   = (0 ,   Àú n )] = min   { Q [ s   = (0 ,   Àú n ) , a   = 1] , Q [ s   = (0 ,   Àú n ) , a   = 0] }‚àí g ‚àó .   (19) Without loss of generality, we choose state   s   = (1 ,   0)   as the reference state and set   h Àú œÄ ‚àó   [ s   = (1 ,   0)] = 0 . Eq. (19) defines the relative value function of each state under the optimal policy for a given cost   \u000f . Intuitively, the gNB of a cell has to be turned on when the number of users in the cell is large, and turned off otherwise. Inspired by the dual-threshold structure of the greedy policy when   K   =   M   , a natural question is that, does the decoupled MDP exhibits a threshold structure? In the following, we answer this question affirmatively by proving that the dual- threshold structure of the optimal policy   Àú œÄ ‚àó   to the problem (P2).  Proposition   5   (Structure   of   the   optimal   policy   Àú œÄ ‚àó ) .   The optimal policy   Àú œÄ ‚àó   for the decoupled problem (P2) is a dual- threshold policy. For a given cost   \u000f , there exists two thresholds  Œì L ,   Œì U   , and   Œì L   <   Œì U   , such that the optimal action   a t   is given by  a t   =  Ô£± Ô£¥ Ô£¥ Ô£¥ Ô£≤ Ô£¥ Ô£¥ Ô£¥ Ô£≥  1 ,   if   a t ‚àí 1   = 0   and   Àú n t   >   Œì U   ; 0 ,   if   a t ‚àí 1   = 0   and   Àú n t   ‚â§   Œì U   ; 1 ,   if   a t ‚àí 1   = 1   and   Àú n t   >   Œì L ; 0 ,   if   a t ‚àí 1   = 1   and   Àú n t   ‚â§   Œì L .  (20)  Proof.   Given a fixed   \u000f ,   h Àú œÄ ‚àó   [ s   = (1 ,   Àú n )] ,   h Àú œÄ ‚àó   [ s   = (0 ,   Àú n )] ,   Œ£ 1 , and   Œ£ 0   in (19) are constant when RVIA converges. Un- der the optimal policy, the gNB will be turned on deter- ministically in state   s   =   (1 ,   Àú n )   if   Q   [ s   = (1 ,   Àú n ) , a   = 1]   < Q   [ s   = (1 ,   Àú n ) , a   = 0] . As per (19), we have  f   [ P static   + ( Àú n   +   ŒªT s ) P d  ]   + Œ£ 1   < f   [ ( Àú n   +   ŒªT s ) P e  ]   + Œ£ 0   +   \u000f.  After some manipulation, we have  g L ( Àú n )   >   ‚àí \u000f   + Œ£ 1   ‚àí   Œ£ 0 ,  where  g L ( Àú n )   ,   f   [ ( Àú n + ŒªT s ) P e  ] ‚àí f   [ P static   +( Àú n + ŒªT s ) P d  ]  is a monotonically increasing function with   Àú n . As a result, there exists a threshold   Œì L , for a given state   s   = (1 ,   Àú n ) , if  Àú n >   Œì L , the optimal action is to turn on the gNB, otherwise, it should be turned off, and the threshold   Œì L   is the solution of the following equation:  g L (Œì L ) =   ‚àí \u000f   + Œ£ 1   ‚àí   Œ£ 0 .   (21) Likewise, for a given state   s   = (0 ,   Àú n ) , the gNB will be turned on if   Q   [ s   = (0 ,   Àú n ) , a   = 1]   < Q   [ s   = (0 ,   Àú n ) , a   = 0] . As per (19), it can be written as  g U   ( Àú n )   >   ‚àí \u000f   + Œ£ 1   ‚àí   Œ£ 0 ,  where  g U   ( Àú n )   ,   f   [ ( Àú n + ŒªT s ) P e  ] ‚àí f   [ P static   + P switch   +( Àú n + ŒªT s ) P d  ]  is also a monotonically increasing function with   Àú n , thus the threshold   Œì U   exists. For the state   s   = (0 ,   Àú n ) , if   Àú n >   Œì U   , the optimal action is to turn on the gNB, otherwise, it should be turned off, and the threshold   Œì U   is the solution of the following equation:  g U   (Œì U   ) =   ‚àí \u000f   + Œ£ 1   ‚àí   Œ£ 0 .   (22) In particular, for a given   \u000f , we have  g L (Œì L ) =   g U   (Œì U   )   (23) from (21) and (22). According to the definitions of   g L ( ¬∑ )   and  g U   ( ¬∑ ) ,   g L ( Àú n )   > g U   ( Àú n ) . Therefore,  g U   (Œì U   ) =   g L (Œì L )   > g U   (Œì L ) ,  and hence,   Œì L   <   Œì U   .   \u0004  B. The index switching policy  Given Proposition 5, we can define a ‚Äúpassive set‚Äù that con- tains all states in which the optimal action is OFF. Specifically, we define  D ( \u000f )   ,   { s   = (0 ,   Àú n ) : 0   ‚â§   Àú n   ‚â§   Œì U   ( \u000f ) ,   (24) and   s   = (1 ,   Àú n ) : 0   ‚â§   Àú n   ‚â§   Œì L ( \u000f ) }   .  Note that   Œì U   and   Œì L   are functions of   \u000f , because they are determined under a given   \u000f . According to [44] the decoupled problem is indexable if the passive set   D ( \u000f )   defined in (24) is monotonically non- increasing as   \u000f   increases. That is, for any   \u000f 1   < \u000f 2 ,   ( \u000f 1 , \u000f 2   ‚àà  R ) , the passive set   D ( \u000f 1 )   ‚äÜ D ( \u000f 2 ) . The original problem is indexable if all its decoupled problems are indexable. In the following, we shall prove that the decoupled problem (P2) is indexable, and propose an algorithm to compute the index   \u000f  for each state. Given (24), the passive set   D ( \u000f )   is monotonically non- increasing if and only if both   Œì U   ( \u000f )   and   Œì L ( \u000f )   decrease monotonically as   \u000f   increases. To prove this, we first establish the monotonicity of   H (Œì L ,   Œì U   )   ,   Œ£ 1   ‚àí   Œ£ 0   in the following.  Lemma 6.   H (Œì L ,   Œì U   ) = Œ£ 1   ‚àí   Œ£ 0   is a monotonically non- decreasing function with the increase of   Œì L   and   Œì U   . Proof.   To start with, let us define   h ( Àú n )   ,   h Àú œÄ ‚àó   [ s   = (1 ,   Àú n )]   ‚àí  h Àú œÄ ‚àó   [ s   = (0 ,   Àú n )] . It can further be written as  h ( Àú n ) =  Ô£± Ô£¥ Ô£≤ Ô£¥ Ô£≥  0 ,   Àú n   ‚â§   Œì L ( \u000f ); ‚àÜ 1 ( Àú n ) ,   Àú n >   Œì U   ( \u000f ); ‚àÜ 2 ( Àú n ) + Œ£ 1   ‚àí   Œ£ 0   ‚àí   \u000f,   Œì L ( \u000f )   <   Àú n   ‚â§   Œì U   ( \u000f ) ,  (25)\n\n8 0  ùëÑ   ùë†   =   1 ,   ‡∑§ ùëõ   ,   ùëé   =   0   =   ùëÑ   ùë†   =   0 ,   ‡∑§ ùëõ   ,   ùëé   =   0  ùëÑ   ùë†   =   1 ,   ‡∑§ ùëõ   ,   ùëé   =   1  ùëÑ   ùë†   =   0 ,   ‡∑§ ùëõ   ,   ùëé   =   1  ‚Ñé ‡∑• ùúã ‚àó   ùë†   =   1 ,   ‡∑§ ùëõ  ‚Ñé ‡∑• ùúã ‚àó   ùë†   =   0 ,   ‡∑§ ùëõ  ‚Ñé   ‡∑§ ùëõ   =   ‚Ñé ‡∑• ùúã ‚àó   ùë†   =   1 ,   ‡∑§ ùëõ   ‚àí   ‚Ñé ‡∑• ùúã ‚àó   ùë†   =   0 ,   ‡∑§ ùëõ  ‡∑§ ùëõ Œì ùêø1  Œì ùëà1  ùí´ switch  Œì ùêø2  Œì ùëà2  ùí´ switch  (a)   f   ( x ) =   x . 0  ùëÑ   ùë†   =   1 ,   ‡∑§ ùëõ   ,   ùëé   =   0   =   ùëÑ   ùë†   =   0 ,   ‡∑§ ùëõ   ,   ùëé   =   0  ùëÑ   ùë†   =   1 ,   ‡∑§ ùëõ   ,   ùëé   =   1  ùëÑ   ùë†   =   0 ,   ‡∑§ ùëõ   ,   ùëé   =   1  ‚Ñé ‡∑• ùúã ‚àó   ùë†   =   1 ,   ‡∑§ ùëõ  ‚Ñé ‡∑• ùúã ‚àó   ùë†   =   0 ,   ‡∑§ ùëõ  ‚Ñé   ‡∑§ ùëõ   =   ‚Ñé ‡∑• ùúã ‚àó   ùë†   =   1 ,   ‡∑§ ùëõ   ‚àí   ‚Ñé ‡∑• ùúã ‚àó   ùë†   =   0 ,   ‡∑§ ùëõ  ‡∑§ ùëõ Œì ùêø1  Œì ùëà1  Œì ùêø2  Œì ùëà2   (b)   f   ( x ) =   x 2 .  Figure 3: Two examples to illustrate the monotonicity of   h ( Àú n ) , where we set   f   =   x   and   f   =   x 2   in (a) and (b), respectively. where  ‚àÜ 1 ( Àú n )   ,   f   [ P static   + ( Àú n   +   ŒªT s ) P d  ]   ‚àí  f   [ P static   +   P switch   + ( Àú n   +   ŒªT s ) P d  ]   ,  ‚àÜ 2 ( Àú n )   ,   f   [ P static   + ( Àú n   +   ŒªT s ) P d  ]   ‚àí   f   [ ( Àú n   +   ŒªT s ) P e  ]   .  Note that both   ‚àÜ 1 ( Àú n )   and   ‚àÜ 2 ( Àú n )   are monotonically non- increasing functions, and   ‚àÜ 1 ( Àú n )   ‚â§   0 . Thus,   h ( Àú n )   is mono- tonically non-increasing with   Àú n , and   h ( Àú n )   ‚â§   0 .  H (Œì L ,   Œì U   )   can be written as  H   = Œ£ 1   ‚àí   Œ£ 0  =  ‚àû ‚àë  k =0  Pr( Àú n   =   k )   ¬∑ { h Àú œÄ ‚àó   [ s   = (1 , k )]   ‚àí   h Àú œÄ ‚àó   [ s   = (0 , k )] }  =  ‚àû ‚àë  k =0  Pr( Àú n   =   k )   ¬∑   h ( k ) .   (26) Appendix   B   proves   that   h ( Àú n )   is   monotonically   non- decreasing in   Œì L   and   Œì U   . Thus,  H (Œì L 1 ,   Œì U   )   ‚àí   H (Œì L 2 ,   Œì U   ) =  ‚àû ‚àë  k =0  Pr( Àú n   =   k )   ¬∑   [ h ( k,   Œì L 1 ,   Œì U   )   ‚àí   h ( k,   Œì L 2 ,   Œì U   ) ]   ‚â§   0 ,  when   Œì L 1   <   Œì L 2 , i.e.,   H (Œì L ,   Œì U   )   is a monotonically non- increasing function in   Œì L . And  H (Œì L ,   Œì U   1 )   ‚àí   H (Œì L ,   Œì U   2 ) =  ‚àû ‚àë  k =0  Pr( Àú n   =   k )   ¬∑   [ h ( k,   Œì L ,   Œì U   1 )   ‚àí   h ( k,   Œì L ,   Œì U   2 ) ]   ‚â§   0 ,  when   Œì U   1   <   Œì U   2 , i.e.,   H (Œì L ,   Œì U   )   is a monotonically non- increasing function in   Œì U   .   \u0004  To illustrate the monotonicity of   H (Œì L ,   Œì U   )   established in Lemma 6, two examples are given in Fig. 3 with   f   =   x  and   f   =   x 2 , respectively. For the linear function in Fig. 3(a),  Q [ s, a   = 0]   and   Q [ s, a   = 1]   are linear in   Àú n , as per (19), and   Q [ s   = (1 ,   Àú n ) , a   = 0]   ‚àí   Q [ s   = (1 ,   Àú n ) , a   = 1] =   P switch . Therefore,   both   the   state   value   h Àú œÄ ‚àó   [ s ]   and   h ( Àú n )   defined in   (25)   are   piecewise   linear.   When   we   increase   the   two thresholds from   (Œì L 1 ,   Œì U   1 )   to   (Œì L 2 ,   Œì U   2 ) ,   h ( Àú n )   is monotoni- cally non-decreasing, hence   H (Œì L ,   Œì U   )   is monotonically non- decreasing. The same results can be observed from Fig. 3(b). Next, we derive upper and lower bounds for   H (Œì L ,   Œì U   )  based on its monotonicity.  Lemma 7.   H (Œì L ,   Œì U   )   is bounded by  E   ‚â§   H (Œì L ,   Œì U   )   ‚â§   0 ,   (27)  where   E   ,   ‚àë ‚àû  k =0   Pr( Àú n   =   k )‚àÜ 1 ( k )   is a constant and   ‚àÜ 1 ( k )  is defined in   (25) . Proof.   From the definition of   h ( Àú n )   in (25), we have   h ( Àú n )   ‚â§   0 ,  ‚àÄ Àú n   ‚â•   0 . Thus,   H (Œì L ,   Œì U   )   ‚â§   0 , as per (26). Since   H (Œì L ,   Œì U   )  is monotonically non-decreasing with the increase of   Œì L   and  Œì U   , we have  H (Œì L ,   Œì U   )   ‚â•   H (Œì L ,   0) =  ‚àû ‚àë  k =0  Pr( Àú n   =   k )   ¬∑   h ( k )  ( a )  =  ‚àû ‚àë  k =0  Pr( Àú n   =   k )   ¬∑   ‚àÜ 1 ( k )   ,   E,   (28) where   E   is a constant;   ( a )   holds because the gNB is ON in all states when   Œì U   ‚â§   0 , and hence,   h ( Àú n ) = ‚àÜ 1 ( Àú n ) ,   ‚àÄ Àú n , according to (25).   \u0004  Given the above analysis, we are ready to prove the index- ability of the decoupled problem.  Theorem 8.   The decoupled problem (P2) is indexable. Proof.   (sketch) The decoupled problem (P2) is indexable if and only if the passive set   D ( \u000f )   in (24) is monotonically non- increasing in   \u000f . Based on (23), consider any two costs   \u000f 1   6   =  \u000f 2 . If   Œì L ( \u000f 1 )   >   Œì L ( \u000f 2 ) , then   g L   [ Œì L ( \u000f 1 ) ]   > g L   [ Œì L ( \u000f 2 ) ]  and   g U   [ Œì U   ( \u000f 1 ) ]   > g U   [ Œì U   ( \u000f 2 ) ] , hence   Œì U   ( \u000f 1 )   >   Œì U   ( \u000f 2 ) . In contrast, if   Œì L ( \u000f 1 )   <   Œì L ( \u000f 2 ) , we have   Œì U   ( \u000f 1 )   <   Œì U   ( \u000f 2 ) . This means that   Œì L ( \u000f )   and   Œì U   ( \u000f )   have the same monotonicity in   \u000f . Therefore, we only need to prove that   Œì U   ( \u000f )   is monotonically non-increasing. Detailed proof is given in Appendix C.   \u0004  So far, we have established the indexability of the decoupled problem. The only issue left is how to compute the index for each state. For a given state   s t   = ( a t ‚àí 1 ,   Àú n t ) , the index   \u000f ‚àó ( s t )   corre- sponds to the cost of turning off the gNB, and can be computed by setting   Q ( s, a   = 1) =   Q ( s, a   = 0) , i.e.,  c ( s, a   = 1) + Œ£ 1   =   c ( s, a   = 0) + Œ£ 0   +   \u000f ‚àó ( s ) .  More specifically, for the class of states   s   = (1 ,   Àú n ) , the index  \u000f ‚àó [ s   = (1 ,   Àú n )]   corresponds to the case   Œì L ( \u000f ‚àó ) =   Àú n ; for the\n\n9  Algorithm 1   Index computation via gradient descent.  Input:   s t   = ( a t ‚àí 1 ,   Àú n t )  Pick an initial value   \u000f 0 . Set an error   Œæ >   0   and a step size   Œ≤ >   0 .  k   ‚Üê   0 Œì( \u000f k )   ‚Üê   Àú n t  F   ( \u000f k ) =   Œæ   + 1  while   F   ( \u000f k )   > Œæ   do  \u000f k +1   =   \u000f k   ‚àí   Œ≤   ¬∑   ( Àú n   ‚àí   Œì( \u000f k ))  Calculate   h Àú œÄ ‚àó   by RVIA for the decoupled problem using  \u000f k +1 . Calculate   Œì( \u000f k +1 )   by (21) or (22).  F   ( \u000f k +1 )   ‚Üê   1 2   [Œì( \u000f k +1 )   ‚àí   Àú n ] 2  k   ‚Üê   k   + 1  \u000f ‚àó ( s t ) =   \u000f k  Output:   \u000f ‚àó ( s t )  class of states   s   = (0 ,   Àú n ) , on the other hand, the index   \u000f ‚àó [ s   = (0 ,   Àú n )]   corresponds to the case   Œì U   ( \u000f ‚àó ) =   Àú n . Therefore, the index of a state can be obtained by solving   Œì L ( \u000f ‚àó ) =   Àú n   or  Œì U   ( \u000f ‚àó ) =   Àú n . Deriving the closed-form   \u000f   for each state is challenging as the two thresholds   Œì L   and   Œì U   do not have explicit expressions. Thus, we resort to a numerical approach to compute   \u000f   in the following. Define  Œì( \u000f )   ,  {  Œì L ( \u000f ) ,   if   s   = (1 ,   Àú n ) ,  Œì U   ( \u000f ) ,   if   s   = (0 ,   Àú n ) ,   (29)  F   ( \u000f )   ,   1 2  [Œì( \u000f )   ‚àí   Àú n ] 2   .   (30) Then, the index   \u000f   of a state   s   is the optimal   \u000f   that mini- mizes   F   ( \u000f ) . According to Theorem 8,   Œì L ( \u000f )   and   Œì U   ( \u000f )   are monotonically decreasing in   \u000f , hence the local minimum of  F   ( \u000f )   is also the global minimum. The optimal   \u000f   can then be found by gradient descent, where the gradient of   F   ( \u000f )   can be approximated by  dF   ( \u000f )  d\u000f   = (Œì( \u000f )   ‚àí   Àú n )   d Œì( \u000f )  d\u000f   ‚âà   Àú n   ‚àí   Œì( \u000f ) ,   (31) where the approximation follows because   Œì( \u000f )   is monoton- ically decreasing according to Theorem 8. Given (31), The gradient descent approach to compute the index is summarized in Algorithm 1. The index policy for the original   M   -dimensional problem (P1) can be summarized as follows.  Definition 6   (The index policy) .   At the beginning of the   t -th time segment, the state of the cell cluster   s t   =   { s t  1 , s t  2 ,   ¬∑ ¬∑ ¬∑   , s t M   } . With the index policy   œÄ ind , an index is first computed for each cell:   \u000f ‚àó ( s t m ) ,   m   = 1 ,   2 , ..., M   . The actions are given by  a t  ind   =   œÄ ind ( s t ) = ( a t  ind , 1 , a t  ind , 2 ,   ¬∑ ¬∑ ¬∑   , a t  ind ,M   ) > ,   (32)  where  a t  ind ,m   =  {  0 ,   if   \u000f ‚àó ( s t m )   ‚â•   0   and   \u000f ‚àó ( s t m )   ‚àà I nd t ; 1 ,   others , Cell to be turned off   Cell to be turned on  Cell 1   Cell 2   Cell 3   Cell 4   Cell 5  Cell 1   Cell 2   Cell 3   Cell 4   Cell 5 Cell 1   Cell 2   Cell 3   Cell 4   Cell 5  Cell 1   Cell 2   Cell 3   Cell 4   Cell 5  Cell 1   Cell 2   Cell 3   Cell 4   Cell 5 Cell 1   Cell 2   Cell 3   Cell 4   Cell 5  1  2  3  4  5  6  Time   segment   ON/OFF state of each cell  Figure 4: An illustration of the round-robin policy.  and   I nd t   consists of   K   largest elements of   { \u000f ‚àó ( s t  1 ) , \u000f ‚àó ( s t  2 ) ,  ¬∑ ¬∑ ¬∑   , \u000f ‚àó ( s t M   ) } .  V. L OWER   B OUND AND   S TATE -I NDEPENDENT   P OLICIES  As discussed in Section III-A, the optimal policy for the dynamic on-off switching problem is computationally pro- hibitive, especially when   M   is large. To evaluate the perfor- mance of the index policy, this section constructs lower and upper bounds as benchmarks.  Theorem 9   (Lower bound of the average cost) .   A lower bound of the average cost in   (1)   is given by  L B   =  M ‚àë  m =1  C (0)  m   +  M ‚àë  m =1  ‚àë  `>Œ≥ L m  ‚àÜ 2 ,m ( ` )   ¬∑   Pr( Àú n m   =   ` ) ,   (33)  where  ‚àÜ 2 ,m ( ` )   ,   f   [ P static   + ( `   +   Œª m T s ) P d  ]   ‚àí   f   [ ( `   +   Œª m T s ) P e  ]   , `   ‚àà   N ,   C (0)  m   is the anticipated cost of a time segment when  a t m   = 0   and it is defined in   (11) ,   Œ≥ L m   =   P static  P e ‚àíP d   ‚àí   Œª m T s   is a threshold defined in Theorem 3, and   Pr( Àú n m   =   ` )   can be calculated by   (4) . Proof.   See Appendix D.   \u0004  Next, we analyze the performance of two state-independent policies, i.e., the uniform policy and the round-robin policy, as upper bounds of the optimal policy. With the uniform policy, we turn off   K   gNBs uniformly at random in each time segment. Its performance is characterized in Proposition 10.  Proposition 10   (Performance of the uniform policy) .   The long-term average cost of the uniform policy is given by  C uniform   =  M ‚àë  m =1  [  C (01)  m   ¬∑   (1   ‚àí   K/M   )   ¬∑   K/M   (34)  + C (11)  m   ¬∑   (1   ‚àí   K/M   ) 2   +   C (0)  m   ¬∑   K/M  ]  ,  where   C (01)  m   ,   C (11)  m   and   C (0)  m   are defined in   (11) . Proof.   See Appendix E.   \u0004  The round-robin policy, on the other hand, turns off the gNBs in a deterministic order, an example of which is shown in Fig. 4. As can be seen, there are five 5G cells in the cluster and three gNBs will be turned off in each time segment. With\n\n10  the round-robin policy, each gNB will be turned off in   K  consecutive time segments and turned on in the following   M   ‚àí  K   consecutive time segments. Its performance is characterized in Proposition 11.  Proposition 11   (Performance of the round-robin policy) .   The long-term average cost of the round-robin policy is given by  C round   =  Ô£± Ô£¥ Ô£¥ Ô£¥ Ô£¥ Ô£¥ Ô£≤ Ô£¥ Ô£¥ Ô£¥ Ô£¥ Ô£¥ Ô£≥ ‚àë M m =1   C (11)  m   ,   K   = 0;  ‚àë M m =1   C (0)  m   ,   K   =   M   ;  1  M  ‚àë M m =1  [  C (0)  m   K   +   C (01)  m  + C (11)  m   ( M   ‚àí   K   ‚àí   1)  ]  ,   0   < K < M,  (35)  where   C (01)  m   ,   C (11)  m   and   C (0)  m   are as defined in   (11) . Proof.   See Appendix F.   \u0004  As can be seen, the long-term average cost of the round- robin policy is linear with   K   when   0   < K < M   , and is discontinuous when   K   = 0   and   K   =   M   . In the following, we compare the performance of these two state-independent policies. When   K   = 0   (or   K   =   M   ), their performances are the same. When   0   < K < M   , their difference is  C diff   ,   C round   ‚àí   C uniform   (36)  =   K 2   ‚àí   M K   +   M M   2  M ‚àë  m =1  C (01)  m   ‚àí   C (11)  m  =   K 2   ‚àí   M K   +   M M   2   C diff ,  where   C diff   ,   ‚àë M m =1   C (01)  m   ‚àí   C (11)  m   is a constant and we have  C diff   >   0   when   P switch   >   0 . As shown in (36), the difference   C diff   is quadratic in   K , the maximum   C diff-max   is achieved when   K   = 1   and   K   =   M   ‚àí   1 , and the minimum or   C diff-min   is achieved when   K   =   M/ 2   (for even   M   ) or   K   = ( M   ¬±   1) / 2   (for odd   M   ). Specifically,  C diff-max   =   1  M   2   C diff ,   K   = 1   or   M   ‚àí   1;  C diff-min   =  {   4 ‚àí M  4 M   C diff ,   K   =   M/ 2;  ‚àí M   2 +4 M   +1 4   C diff ,   K   = ( M   ¬±   1) / 2 .  As a result, the uniform policy is strictly better than the round-robin policy when 1)   K   = 1   or   M   ‚àí   1 , in which case   C diff-max   >   0 ; 2)   M <   4 , in which case   C diff-min   >   0 . VI. N UMERICAL AND   S IMULATION   R ESULTS  This section presents numerical and simulation results to evaluate   various   policies   analyzed   in   this   paper,   i.e.,   the optimal policy, the greedy policy, the index policy, and the state-independent policies. In particular, we measure the per- formance of a policy by the gap between the long-term average cost of this policy and the lower bound given in Theorem 9. That is:  ‚àÜ policy   ,   C policy   ‚àí   L B  L B  √ó   100%   (37) Table I: Parameter settings.  Physical Quantities   Symbols   Values   Units  Average power/gNB/user   P d   1   W Average power of macro BS/user   P e   5   W Static power/gNB   P static   85   W Switching power/gNB   P switch   40   W Time segment duration   T s   1800   s Mean service time/user   1 /Œº   500   s User arrival rate   Œõ   {   0 . 005 0 . 01 0 . 015 0 . 02  }   /s Sampling probabilities   Pr(Œõ)  Set1:   { 0 ,   1 ,   0 ,   0 }  Set2:   { 0 . 5 ,   0 ,   0 . 5 ,   0 }  Set3:   { 2 / 3 ,   0 ,   0 ,   1 / 3 }  Set4:   { 0 . 3 ,   0 . 4 ,   0 . 3 ,   0 }  Set5:   { 0 . 6 ,   0 ,   0 . 2 ,   0 . 2 } ùêæ  Figure 5: Performance of different switching policies versus  K , where   M   = 4 ,   Pr(Œõ) =   { 2 / 3 ,   0 ,   0 ,   1 / 3 } , and   f   ( x ) =   x 2 . where the lower bound   L B   is defined in (33) and   C policy  denotes the long-term average cost of an evaluated policy over the infinite-time horizon. The parameter settings are presented in Table I unless specified otherwise. Specifically, as [14], [25], [45], we set the average power consumption of a gNB for serving a single user to   P d   = 1 W; the static power consumption of a gNB  P static   = 85 W; the switching power consumption of a gNB  P switch   = 50 W. The average power consumption of the ng- eNB for serving a single user   P e   is set to 5W. The duration of a time segment   T s   is set to 1800s. Users‚Äô arrival to a cell follows a mixed Poisson process with a set of parameters  Œõ   =   { 0 . 005 ,   0 . 01 ,   0 . 015 ,   0 . 02 } .   We   consider   five   sets   of sampling probabilities   Pr(Œõ) , as listed in Table I. The mean service time of a user is set to   1 /Œº   = 500 s [27]. We consider three kinds of cost functions   f   in this paper: the quadratic function   f   ( x ) =   x 2 ; the piecewise linear function  f   ( x ) =  Ô£± Ô£¥ Ô£≤ Ô£¥ Ô£≥  0 . 5 x,   if   x   ‚â§   100;  x   ‚àí   50 ,   if   100   < x   ‚â§   150; 1 . 5 x   ‚àí   125 ,   if   x >   150;  and the linear function   f   ( x ) =   x . According to (9), the optimal policy is computationally prohibited for large   M   . Thus, in the first simulation, we consider a small cluster with   M   = 4   5G cells and evaluate the performance of various policies benchmarked against the\n\n11 Time segments Number of users  Time segments Number of users  Time segments Number of users  Time segments Number of users  Figure 6: The dual-threshold structure of the greedy policy, where   M   =   K   = 4 ,   Pr(Œõ) =   { 2 / 3 ,   0 ,   0 ,   1 / 3 } , and   f   ( x ) =  x 2 . optimal policy. The simulation results are presented in Fig. 5, where we plot   ‚àÜ policy   as a function of   K . As can be seen, the index policy achieves the same performance as the optimal policy and outperforms the other policies. The greedy policy is better than state-independent policies. The cost of the uniform policy   ‚àÜ uniform   increases quadratically in   K , as predicted in (34). The cost of the round-robin policy   ‚àÜ round-robin , on the other hand, increases linearly when   1   ‚â§   K   ‚â§   M   ‚àí   1 , as predicted in (35). Recall from Theorem 3 that the greedy policy exhibits a dual-threshold structure when   K   =   M   . This is verified in Fig. 6, where we set   K   =   M   = 4 . For each 5G cell, we plot the number of residual users at the beginning of a time segment and the corresponding ON/OFF actions of the greedy policy. As shown, for each cell, the greedy policy presents a dual-threshold structure: when the number of residual users   Àú n  at the beginning of a time segment is smaller than   Œ≥ L m , the gNB will be turned off; when   Àú n   is larger than   Œ≥ U m , the gNB will be turned on; when   Œ≥ L m   ‚â§   Àú n   ‚â§   Œ≥ U m , the ON/OFF state of a gNB remains unchanged. In the second simulation, we evaluate the impact of user arrival distributions on the performance of various switching policies. Specifically, we extend the simulation in Fig. 5 to different user arrival distributions considering the five sets of   Pr(Œõ)   listed in Table   I (note that the mean user arrival rates are the same under the five sets of distributions). The simulation results are presented in Fig. 7. As shown, the index policy always achieves close-to-optimal performance under different sets of   Pr(Œõ) . In the third simulation, we consider a larger cluster with  M   = 12   cells, in which case the performance of the optimal policy is no longer available, and we shall consider different cost functions   f   ( x ) . Fig. 8 and 9 present the performance of various policies versus   K   with the piecewise linear and linear cost functions, respectively. We have similar observations as that from Fig. 5, the index policy achieves the best perfor- Set 1   Set   2   Set   3   Set   4   Set   5  Figure 7: Impact of user arrival distributions   Pr(Œõ)   on the performance of various switching policies, where   M   =   K   = 4  and   f   ( x ) =   x 2 . ùêæ  Figure 8: Performance of different switching policies versus  K , where   M   = 12 ,   Pr(Œõ) =   { 2 / 3 ,   0 ,   0 ,   1 / 3 } , and   f   ( x )   is a piecewise linear function. mance among all switching policies and the properties of other policies match our predictions. Next, we compare the performance of the uniform and round-robin policies in more detail to verify our analysis in Section V. As can be seen from Fig. 10, the uniform policy is strictly better than the round-robin policy when   M <   4   and  K   = 1   or   K   =   M   ‚àí   1 . In other cases, the round-robin policy can be better than the uniform policy. It is worth noting that the optimality of the greedy policy is determined by the switching cost   P switch . In the extreme case where the switching cost is zero and frequent switching is allowed, the greedy policy is optimal. In Fig. 11, we evaluate the impact of the switching cost by reducing the power consumption of switching from   P switch   =   40 W to  P switch   = 10 W. In the simulation, we consider a linear cost function   f   ( x ) =   x   and   M   = 4 . As shown, with the decrease in the switching cost, the gap between the greedy policy and the optimal policy reduces. For the case of   K   = 2   and   P switch   = 20 W in Fig. 11, we further analyze the compositions of power consumption when operated with different policies. As can be seen from Fig. 12, the index policy has almost the same composition\n\n12 ùêæ  Figure 9: Performance of different switching policies versus  K , where   M   = 12 ,   Pr(Œõ) =   { 2 / 3 ,   0 ,   0 ,   1 / 3 } , and   f   ( x ) =   x . ùëÄ   =   3   ùëÄ   =   4   ùëÄ   =   5   ùëÄ   =   6  ùêæ  Figure 10: Comparison of the two state-independent policies, where   Pr(Œõ) =   { 2 / 3 ,   0 ,   0 ,   1 / 3 } , and   f   ( x ) =   x 2 . of power consumption as the optimal policy, verifying that the index policy is close-to-optimal. The compositions of the greedy policy, on the other hand, are much more different. In general, the greedy policy is more inclined to turn off the gNBs compared with the optimal policy, and hence, incurs more   power   consumption   of   the   ng-eNB   and   less   power consumption of the gNBs. A piece of theoretical evidence is given in Proposition 4, where we have proven that the number of ‚ÄúON‚Äù time segments with the greedy policy is no greater than that with the optimal policy when   K   =   M   . In addition, the greedy policy incurs more switching cost compared with the optimal policy. VII. C ONCLUSION  To achieve energy-conserving 5G RAN, this paper put forth a dynamic on-off switching paradigm for gNB sleep control by taking the evolvements of users and their traffic demands into account. Formulating the dynamic sleep control for a cluster of gNBs as an MDP, we characterized the optimal policy for the MDP that minimizes the long-term average cost, where cost is a non-decreasing function of system energy expenditure. The optimal policy, however, is computationally demanding and is available only when the number of gNBs is small. ùêæ  ùí´ ùë†ùë§ùëñùë°ùëê‚Ñé   =   10 W ùí´ ùë†ùë§ùëñùë°ùëê‚Ñé   =   20 W  ùí´ ùë†ùë§ùëñùë°ùëê‚Ñé   =   30 W  ùí´ ùë†ùë§ùëñùë°ùëê‚Ñé   =   40 W  new  Figure 11: Impact of the switching power consumption on the greedy policy and the optimal policy, where   M   = 4 ,   P switch   = 20 W,   Pr(Œõ) =   { 2 / 3 ,   0 ,   0 ,   1 / 3 } , and   f   ( x ) =   x . Optimal  Consumption (W)  Greedy   Uniform   Round - robin Index  new  Figure 12: The compositions of the power consumption for different policies, where   M   = 4 ,   P switch   = 20 W,   K   = 2 ,  Pr(Œõ) =   { 2 / 3 ,   0 ,   0 ,   1 / 3 } , and   f   ( x ) =   x . To meet this challenge, we proposed a greedy policy and an index policy and analyzed their performances benchmarked against   the   optimal   policy   and   state-independent   policies. When making on-off switching decisions, the greedy policy focuses only on the immediate effect of the decisions while omitting their long-term impacts. We proved the dual-threshold structure of the greedy policy when there is no constraint on the number of gNBs that can be turned off, and analyzed its connections with the optimal policy. On the other hand, the index policy assigns an index to each gNB as a measurement of how one is willing to pay to turn off the gNB. The gNBs with relatively larger indexes are then turned off when making switching decisions. To develop the index policy, we decoupled the original MDP, proved the indexibility of the decoupled MDP, and proposed an algorithm to compute the index. Although heuristic, the index policy exhibits close- to-optimal performance and outperforms the greedy policy and state-independent policies. Furthermore, it is much more computationally efficient than the optimal policy. To summarize, our study validated the effectiveness of gNB sleep control in achieving an energy-efficient 5G RAN. Under the established dynamic on-off switching paradigm, we\n\n13  demonstrated that the proposed switching policies can reduce the system energy expenditure by a large margin, providing useful operational insights for practical 5G RAN. A PPENDIX   A P ROOF OF   P ROPOSITION   1 Considering the   ( t ‚àí 1) -th time segment, the   m -th cell serves two sets of users: the newly arrived users as well as the residual users from the   ( t ‚àí 2) -th time segment. For simplicity, we refer to the two sets as   G n   and   G r   , respectively. At the end of the  ( t   ‚àí   1) -th time segment, the number of residual users in the cell can be written as  Àú n t m   =   ` t ‚àí 1  m   +   Àú ` t ‚àí 1  m   ,  where   ` t ‚àí 1  m   and   Àú ` t ‚àí 1  m   are the number of residual users from  G n   and   G r   , respectively. First,   ` t ‚àí 1  m   can be written as  ` t ‚àí 1  m   =  n t ‚àí 1  m ‚àë  n =1  I ( T s , Œæ n , œÑ n ) ,  where   œÑ n   and   Œæ n   denote the arrival epoch and staying time of the   n -th user in   G n , respectively;   n t ‚àí 1  m   follows the mixed Poisson distribution and   Œæ n   follows the exponential distribution as   described   in   Definition   4;   The   function   I ( ¬∑ )   indicates whether the   n -th user is still in the cell at the end of the  ( t   ‚àí   1) -th time segment. That is,  I ( T s , Œæ n , œÑ n ) =  {  1 ,   if   T s   ‚àí   œÑ n   ‚â§   Œæ n ; 0 ,   otherwise .  For a specific parameter   Œª j   ‚àà   Œõ   of the mixed Poisson pro- cess,   ` t ‚àí 1  m   is a filtered Poisson process [46]. The characteristic function of   ` t ‚àí 1  m   can be written as  œÜ ` t ‚àí 1  m   ,   E [ e jœâ` t ‚àí 1  m   ] =   E  Ô£Æ Ô£∞ exp  Ô£´ Ô£≠ jœâ  n t ‚àí 1  m ‚àë  n =1  I ( T s , Œæ n , œÑ n )  Ô£∂ Ô£∏ Ô£π Ô£ª  =   E n t ‚àí 1  m   , { œÑ n }  {  E { Œæ n }  [  exp  (  jœâ  n ‚àó  ‚àë  n =1  I ( T s , Œæ n , œÑ n )  )]  | n t ‚àí 1  m   =   n ‚àó ,   { œÑ n } }   .   (38) Let   B n ( T s , œÑ n )   ,   E Œæ n   [exp ( jœâI ( T s , Œæ n , œÑ n ))] , (38) can be refined as  œÜ ` t ‚àí 1  m   =   E n t ‚àí 1  m   , { œÑ n }  [   n ‚àó  ‚àè  n =1  B n ( T s , œÑ n )   ‚à£ ‚à£ n t ‚àí 1  m   =   n ‚àó ,   { œÑ n }  ]  =   E n t ‚àí 1  m  [  E { œÑ n }  (   n ‚àó  ‚àè  n =1  B n ( T s , œÑ n )  )  ‚à£ ‚à£ n t ‚àí 1  m   =   n ‚àó  ]  ( a )  =   E n t ‚àí 1  m  [ ‚à´   T s  0  ‚à´   œÑ n ‚àó  0  ¬∑ ¬∑ ¬∑  ‚à´   œÑ 2  0  n ‚àó  ‚àè  n =1  B n ( T s , œÑ n )   n !  T   n ‚àó  s  dœÑ 1   ¬∑ ¬∑ ¬∑   dœÑ n ‚àó ‚àí 1 dœÑ n ‚àó  ‚à£ ‚à£ n t ‚àí 1  m   =   n ‚àó   ]  =   E n t ‚àí 1  m  [  1  T   n ‚àó  s  ‚à´   T s  0  ‚à´   T s  0  ¬∑ ¬∑ ¬∑  ‚à´   T s  0  n ‚àó  ‚àè  n =1  B n ( T s , œÑ n )  dœÑ 1   ¬∑ ¬∑ ¬∑   dœÑ n ‚àó ‚àí 1 dœÑ n ‚àó  ‚à£ ‚à£ n t ‚àí 1  m   =   n ‚àó   ]  ( b )  =   E n t ‚àí 1  m  Ô£Æ Ô£∞ (  1  T s  ‚à´   T s  0  B ( T s , œÑ   ) dœÑ  ) n t ‚àí 1  m  Ô£π Ô£ª  ( c )  =   G n t ‚àí 1  m  (  1  T s  ‚à´   T s  0  B ( T s , œÑ   ) dœÑ  )  ,   (39) where   ( a )   follows because the arrival epochs   œÑ n   ( n   = 1 ,   2 ,  ¬∑ ¬∑ ¬∑   , n t ‚àí 1  m   )   given   n t ‚àí 1  m   have a distribution as the order statistics sampled from a uniform distribution [46];   ( b )   follows because all   œÑ n   has the same distribution such that the subscript   n   can be omitted;   ( c )   follows from the definition of the moment generating function   G X   ( z )   ,   E ( z X   ) . Note that the random variable   n t ‚àí 1  m   follows the Poisson distribution, (39) can be further written as  œÜ ` t ‚àí 1  m   = exp  [  Œª j   T s  (  1  T s  ‚à´   T s  0  B ( T s , œÑ   ) dœÑ   ‚àí   1  )]  .   (40) In particular,   B ( T s , œÑ   )   is given by  B ( T s , œÑ   ) =   E Œæ   [exp( jœâI ( T s , Œæ, œÑ   ))] = Pr[ I ( T s , Œæ, œÑ   ) = 0] +   e jœâ   ¬∑   Pr[ I ( T s , Œæ, œÑ   ) = 1] = Pr[ I ( T s , Œæ, œÑ   ) = 1]   ¬∑   ( e jœâ   ‚àí   1) + 1 =  (‚à´   ‚àû  T s ‚àí œÑ  f Œæ   ( Œæ ) dŒæ  )  ¬∑   ( e jœâ   ‚àí   1) + 1  ( a )  =   e ‚àí Œº m ( T s ‚àí œÑ   )   ¬∑   ( e jœâ   ‚àí   1) + 1 ,   (41) where   ( a )   holds   because   the   staying   time   Œæ   follows   the exponential distribution with parameter   Œº m . By substituting (41) into (40), we have  œÜ ` t ‚àí 1  m   = exp  (   Œª j  Œº m  (1   ‚àí   e ‚àí Œº m T s   )( e jœâ   ‚àí   1)  )  = exp[ Àú Œª m,j   ( e jœâ   ‚àí   1)] ,  where   Àú Œª m,j   =   Œª j  Œº m   (1 ‚àí e ‚àí Œº m T s   )   is a constant. By Taylor series expansion, we have  œÜ ` t ‚àí 1  m   =   e ‚àí Àú Œª m,j   e Àú Œª m,j   ¬∑ e jœâ  =   e ‚àí Àú Œª m,j  ‚àû ‚àë  ` =0  ( Àú Œª m,j  ) `  ¬∑   e jœâ`  ` !   .   (42) Note that the characteristic function   œÜ ` t ‚àí 1  m   in (38) can also be written as  œÜ ` t ‚àí 1  m   =   E [ e jœâ` t ‚àí 1  m   ] =  ‚àû ‚àë  ` =0  Pr( ` t ‚àí 1  m   =   ` )   ¬∑   e jœâ` .   (43) Comparing the coefficients of each items in (42) and (43) yields  Pr( ` t ‚àí 1  m   =   ` ) =  ( Àú Œª m,j  ) `  ` !   e ‚àí Àú Œª m,j   .  For the mixed Poisson process,   Œª j   is sampled from   Œõ   with probability   p m,j   . Thus, the probability distribution of   ` t ‚àí 1  m   is given by  Pr( ` t ‚àí 1  m   =   ` ) =  J ‚àë  j =1  p m,j   Pr( ` t ‚àí 1  m   =   ` | Œª j   )\n\n14  =  J ‚àë  j =1  p m,j  ( Àú Œª m,j  ) `  ` !   e ‚àí Àú Œª m,j   .  On the other hand, for a user in the set   G r   , the probability that it departs from the cell during the   t -th segment is  p re   =  ‚à´   T s  0  Œº m e ‚àí Œº m t dt   = 1   ‚àí   e ‚àí Œº m T s   .  Thus,   Àú ` t ‚àí 1  m   follows  Pr( Àú ` t ‚àí 1  m   =   ` ) =  ( Àú n t ‚àí 1  m  `  )  ( p re ) Àú n t ‚àí 1  m   ‚àí ` (1   ‚àí   p re ) ` ,  for   `   = 0 ,   1 ,   2 ,   ¬∑ ¬∑ ¬∑   ,   Àú n t ‚àí 1  m   . Notice that the gNB switching cannot be too frequent. For a relatively large   T s , we have   p re   ‚Üí   1   and   Pr( Àú ` t ‚àí 1  m   >   0)   ‚Üí   0 . This implies that the residual users from the set   G r   can be omitted. As a result, we arrive at (4). And the average   Àú n t m   is  E [ Àú n t m ] =   ‚àë J j =1   p m,j   E ( Àú n t m | Œª j   ) =   ‚àë J j =1   p m,j   Àú Œª m,j   . A PPENDIX   B P ROOF OF THE NON - DECREASING MONOTONICITY OF   h ( Àú n )  IN   Œì L   AND   Œì U  Let us write   h ( Àú n )   as a function of   Œì L   and   Œì U   :  h ( Àú n,   Œì L ,   Œì U   ) =  Ô£± Ô£¥ Ô£≤ Ô£¥ Ô£≥  0 ,   Àú n   ‚â§   Œì L ; ‚àÜ 1 ( Àú n ) ,   Àú n >   Œì U   ; ‚àÜ 2 ( Àú n ) +   H ‚Ä≤ (Œì L ,   Œì U   ) ,   Œì L   <   Àú n   ‚â§   Œì U   ,  where   H ‚Ä≤ (Œì L ,   Œì U   )   ,   Œ£ 1   ‚àí   Œ£ 0   ‚àí   \u000f   is independent of   Àú n . By treating   Àú n   as a positive real value, we have  {  ‚àÜ 2 ( Àú n ) +   H ‚Ä≤ (Œì L ,   Œì U   ) = 0 ,   Àú n   = Œì L ,  ‚àÜ 2 ( Àú n ) +   H ‚Ä≤ (Œì L ,   Œì U   ) = ‚àÜ 1 ( Àú n ) ,   Àú n   = Œì U   ,  i.e.,   {  ‚àÜ 2 (Œì L ) +   H ‚Ä≤ (Œì L ,   Œì U   ) = 0 ,  ‚àÜ 2 (Œì U   ) +   H ‚Ä≤ (Œì L ,   Œì U   ) = ‚àÜ 1 (Œì U   ) .   (44) For   any   two   real   values   Œì L 1   <   Œì L 2 ,   we   analyze  h ( Àú n,   Œì L 1 ,   Œì U   )   ‚àí   h ( Àú n,   Œì L 2 ,   Œì U   )   as follows: 1) When   Àú n   ‚â§   Œì L 1 , we have  h ( Àú n,   Œì L 1 ,   Œì U   ) = 0 , h ( Àú n,   Œì L 2 ,   Œì U   ) = 0 ,  hence   h ( Àú n,   Œì L 1 ,   Œì U   )   ‚àí   h ( Àú n,   Œì L 2 ,   Œì U   ) = 0 . 2) When   Œì L 1   <   Àú n   ‚â§   Œì L 2 , we have  h ( Àú n,   Œì L 1 ,   Œì U   ) = ‚àÜ 2 ( Àú n ) +   H ‚Ä≤ (Œì L 1 ,   Œì U   )   ‚â§   0 , h ( Àú n,   Œì L 2 ,   Œì U   ) = 0 ,  then   h ( Àú n,   Œì L 1 ,   Œì U   )   ‚àí   h ( Àú n,   Œì L 2 ,   Œì U   )   =   ‚àÜ 2 ( Àú n ) +  H ‚Ä≤ (Œì L 1 ,   Œì U   )   ‚â§   0 . 3) When   Œì L 2   <   Àú n   ‚â§   Œì U   , we have  h ( Àú n,   Œì L 1 ,   Œì U   ) = ‚àÜ 2 ( Àú n ) +   H ‚Ä≤ (Œì L 1 ,   Œì U   ) , h ( Àú n,   Œì L 2 ,   Œì U   ) = ‚àÜ 2 ( Àú n ) +   H ‚Ä≤ (Œì L 2 ,   Œì U   ) ,  then  h ( Àú n,   Œì L 1 ,   Œì U   )   ‚àí   h ( Àú n,   Œì L 2 ,   Œì U   ) =   H ‚Ä≤ (Œì L 1 ,   Œì U   )   ‚àí   H ‚Ä≤ (Œì L 2 ,   Œì U   )  ( a )  =   ‚àí ‚àÜ 2 (Œì L 1 ) + ‚àÜ 2 (Œì L 2 )   ( b )  ‚â§   0 ,  where   ( a )   follows from (44);   ( b )   follows because   ‚àÜ 2   is a monotonically non-increasing function and   Œì L 1   <   Œì L 2 . 4) When   Àú n >   Œì U   , we have  h ( Àú n,   Œì L 1 ,   Œì U   ) = ‚àÜ 1 ( Àú n ) , h ( Àú n,   Œì L 2 ,   Œì U   ) = ‚àÜ 1 ( Àú n ) ,  hence   h ( Àú n,   Œì L 1 ,   Œì U   )   ‚àí   h ( Àú n,   Œì L 2 ,   Œì U   ) = 0 . To summarize, we have   h ( Àú n,   Œì L 1 ,   Œì U   )   ‚àí   h ( Àú n,   Œì L 2 ,   Œì U   )   ‚â§   0  when   Œì L 1   <   Œì L 2 . Likewise, for   Œì U   1   <   Œì U   2 , we compute   h ( Àú n,   Œì L ,   Œì U   1 )   ‚àí  h ( Àú n,   Œì L ,   Œì U   2 )   as follows. 1) When   Àú n   ‚â§   Œì L , we have  h ( Àú n,   Œì L ,   Œì U   1 ) = 0 , h ( Àú n,   Œì L ,   Œì U   2 ) = 0 ,  hence   h ( Àú n,   Œì L ,   Œì U   1 )   ‚àí   h ( Àú n,   Œì L ,   Œì U   2 ) = 0 . 2) When   Œì L   <   Àú n   ‚â§   Œì U   1 , we have  h ( Àú n,   Œì L ,   Œì U   1 ) = ‚àÜ 2 ( Àú n ) +   H ‚Ä≤ (Œì L ,   Œì U   1 ) , h ( Àú n,   Œì L ,   Œì U   2 ) = ‚àÜ 2 ( Àú n ) +   H ‚Ä≤ (Œì L ,   Œì U   2 ) ,  then  h ( Àú n,   Œì L ,   Œì U   1 )   ‚àí   h ( Àú n,   Œì L ,   Œì U   2 ) =   H ‚Ä≤ (Œì L ,   Œì U   1 )   ‚àí   H ‚Ä≤ (Œì L ,   Œì U   2 )  ( a )  =   [ ‚àÜ 1 (Œì U   1 )   ‚àí   ‚àÜ 2 (Œì U   1 ) ]   ‚àí   [ ‚àÜ 1 (Œì U   2 )   ‚àí   ‚àÜ 2 (Œì U   2 ) ]  ( b )  =   g U   (Œì U   1 )   ‚àí   g U   (Œì U   2 )   ( c )  ‚â§   0 ,  where   ( a )   follows from (44);   ( b )   follows because  ‚àÜ 1 (Œì U   ) ‚àí ‚àÜ 2 (Œì U   ) =   f   [ (Œì U   + ŒªT s ) P e  ]   ‚àí  f   [ P static   + P switch   +(Œì U   + ŒªT s ) P d  ]  =   g U   (Œì U   );  and   ( c )   follows   because   g U   (Œì U   )   is   a   monotonically increasing function and   Œì U   1   <   Œì U   2 . 3) When   Œì U   1   <   Àú n   ‚â§   Œì U   2 , we have  h ( Àú n,   Œì L ,   Œì U   1 ) = ‚àÜ 1 ( Àú n ) , h ( Àú n,   Œì L ,   Œì U   2 ) = ‚àÜ 2 ( Àú n ) +   H ‚Ä≤ (Œì L ,   Œì U   2 ) ,  then,   h ( Àú n,   Œì L ,   Œì U   1 ) ‚àí h ( Àú n,   Œì L ,   Œì U   2 ) = ‚àÜ 1 ( Àú n ) ‚àí ‚àÜ 2 ( Àú n ) ‚àí  H ‚Ä≤ (Œì L ,   Œì U   2 )   =   g U   ( Àú n )   ‚àí   H ‚Ä≤ (Œì L ,   Œì U   2 ) . As   g U   ( Àú n )   is a monotonically increasing function and   g U   (Œì U   2 )   =  H ‚Ä≤ (Œì L ,   Œì U   2 ) , we have   g U   ( Àú n )   ‚àí   H ‚Ä≤ (Œì L ,   Œì U   2 )   ‚â§   0   when  Àú n   ‚â§   Œì U   2 . 4) When   Àú n >   Œì U   2 , we have  h ( Àú n,   Œì L ,   Œì U   1 ) = ‚àÜ 1 ( Àú n ) , h ( Àú n,   Œì L ,   Œì U   2 ) = ‚àÜ 1 ( Àú n ) ,  hence   h ( Àú n,   Œì L ,   Œì U   1 )   ‚àí   h ( Àú n,   Œì L ,   Œì U   2 ) = 0 . To summarize, we have   h ( Àú n,   Œì L ,   Œì U   1 )   ‚àí   h ( Àú n,   Œì L ,   Œì U   2 )   ‚â§   0  when   Œì U   1   <   Œì U   2 . As a result,   h ( Àú n )   is monotonically non-decreasing in   Œì L  and   Œì U   .\n\n15  A PPENDIX   C P ROOF OF THE DECREASING MONOTONICITY OF   Œì U   ( \u000f )  1) When   \u000f   ‚â• ‚àí g U   (0) , we have  g U   [ Œì U   ( \u000f ) ]   =   ‚àí \u000f   +   H   [ Œì L ( \u000f ) ,   Œì U   ( \u000f ) ]  ‚â§   g U   (0) + 0 =   g U   (0) .  As   g U   ( ¬∑ )   is a monotonically increasing function, we have  Œì U   ( \u000f )   ‚â§   0 , hence   Àú n   ‚â•   Œì U   ( \u000f ) ,   ‚àÄ Àú n   ‚â•   0 . Therefore,   H   =   E  and is a constant, where   E   is defined in (27). In this case,  g U   [ Œì U   ( \u000f ) ]   =   ‚àí \u000f   +   E   is monotonically decreasing in   \u000f , hence   Œì U   ( \u000f )   is also monotonically decreasing in   \u000f . 2) When   \u000f <   ‚àí g U   (0) , for any two costs   \u000f 1   < \u000f 2   <   ‚àí g U   (0) , we have  g U   [ Œì U   ( \u000f 1 ) ]   =   ‚àí \u000f 1   +   H   [ Œì L ( \u000f 1 ) ,   Œì U   ( \u000f 1 ) ]  >   ‚àí \u000f 2   +   H   [ Œì L ( \u000f 1 ) ,   Œì U   ( \u000f 1 ) ]  ,   g U   [ Œì U   ( \u000f (1) ) ]   .   (45) In particular, we have   Œì L ( \u000f (1) )   <   Œì L ( \u000f 1 )   since   g U   ( ¬∑ )   is a monotonically increasing function. Further, we have  g U   [ Œì U   ( \u000f (1) ) ]   =   ‚àí \u000f 2   +   H   [ Œì L ( \u000f 1 ) ,   Œì U   ( \u000f 1 ) ]  ( a )  >   ‚àí \u000f 2   +   H   [ Œì L ( \u000f (1) ) ,   Œì U   ( \u000f (1) ) ]  ,   g U   [ Œì U   ( \u000f (2) ) ]   ,  where   ( a )   follows because   H   is a monotonically non- decreasing function in   Œì L   and   Œì U   , according to Lemma 6. In   the   above   manner,   we   can   construct   a   sequence { Œì U   ( \u000f ( i ) ) , i   = 1 ,   2 ,   ¬∑ ¬∑ ¬∑ } , where   Œì U   ( \u000f (1) )   is defined in (45), and the others follow  g U   [ Œì U   ( \u000f ( i ) ) ]   =   ‚àí \u000f 2   +   H   [ Œì L ( \u000f ( i ‚àí 1) ) ,   Œì U   ( \u000f ( i ‚àí 1) ) ]  ( a )  >   ‚àí \u000f 2   +   H   [ Œì L ( \u000f ( i ) ) ,   Œì U   ( \u000f ( i ) ) ]  =   g U   [ Œì U   ( \u000f ( i +1) ) ]   , i   = 2 ,   3 ,   ¬∑ ¬∑ ¬∑   ,   (46) where   ( a )   can be proven by mathematical induction. As can be seen,   { Œì U   ( \u000f ( i ) ) , i   = 1 ,   2 ,   ¬∑ ¬∑ ¬∑ }   is a monotonically decreasing sequence. In particular,   ‚àÄ i   ‚â•   2 ,  g U   [ Œì U   ( \u000f ( i ) ) ]   =   ‚àí \u000f 2   +   H   [ Œì L ( \u000f ( i ‚àí 1) ) ,   Œì U   ( \u000f ( i ‚àí 1) ) ]  > g U   (0) +   E.  To summarize,   g U   is monotonically non-decreasing and lower bounded by a constant   g U   (0) +   E . This sug- gests that there exists a lower bound for the sequence { Œì U   ( \u000f ( i ) ) } . Since   { Œì U   ( \u000f ( i ) ) }   monotonically decreases, we can denote its lower bound by   Œì U   ( \u000f ( ‚àû ) ) . In particular, according to (46), we can write  g U   [ Œì U   ( \u000f ( ‚àû ) ) ]   =   ‚àí \u000f 2   +   H   [ Œì L ( \u000f ( ‚àû ) ) ,   Œì U   ( \u000f ( ‚àû ) ) ]   .  Note that   g U   [ Œì U   ( \u000f 2 ) ]   =   ‚àí \u000f 2   +   H   [ Œì L ( \u000f 2 ) ,   Œì U   ( \u000f 2 ) ] , we have   \u000f ( ‚àû )   =   \u000f 2 , and  Œì U   ( \u000f 2 ) = Œì U   ( \u000f ( ‚àû ) )   ( a )  <   Œì U   ( \u000f (1) )   ( b )  <   Œì U   ( \u000f 1 ) ,   (47) where   ( a )   follows because   { Œì U   ( \u000f ( i ) ) }   is a monotonically decreasing sequence;   ( b )   follows from (45). As a result, we have   Œì U   ( \u000f 2 )   <   Œì U   ( \u000f 1 )   for   ‚àÄ \u000f 1   < \u000f 2   <   ‚àí Œì U   (0) , i.e.,  Œì U   ( \u000f )   is monotonically decreasing with   \u000f . Finally, we conclude that   Œì U   ( \u000f )   is monotonically decreasing in   \u000f . A PPENDIX   D P ROOF OF   T HEOREM   9 When the states are in equilibrium, we can rewrite (1) as  C œÄ   =   lim  T   ‚Üí‚àû   E  [  1  T  T   ‚àí 1 ‚àë  t =0  M ‚àë  m =1  c ( s t m , a t m )  ]  ( a )  =  M ‚àë  m =1  E [ c ( s m , a m )] ,   (48) where   ( a )   holds because the mean values of the cost will not change with time when in equilibrium, and the superscript   t  can be omitted. As   P switch   ‚â•   0 , the immediate cost of the   m -th cell   c ( s m , a m )   satisfies the following inequality  c ( s m , a m ) =   f   [ P ( s m , a m )]  ‚â•  {  f   [ P static   + ( Àú n m   +   Œª m T s ) P d  ]   ,   if   a m   = 1;  f   [ ( Àú n m   +   Œª m T s ) P e  ]   ,   if   a m   = 0 .  As shown,   c ( s m , a m )   is only dependent on the ON/OFF state and the number of users. We define a variable   œÅ m ( Àú n m )   to express the probability of turning on the   m -th gNB given the user number   Àú n m , and   0   ‚â§   œÅ m ( Àú n m )   ‚â§   1 . Then   E [ c ( s m , a m )]  in (48) can be written as  E [ c ( s m , a m )] =  ‚àû ‚àë  ` =0  E [ c ( s m , a m ) | Àú n m   =   ` ]   ¬∑   Pr( Àú n m   =   ` )  ‚â•  ‚àû ‚àë  ` =0  { œÅ m ( ` )   ¬∑   f   [ P static   + ( `   +   Œª m T s ) P d  ]  + [1   ‚àí   œÅ m ( ` )]   ¬∑   f   [ ( `   +   Œª m T s ) P e  ]}   ¬∑   Pr( Àú n m   =   ` ) =   C (0)  m   +  ‚àû ‚àë  ` =0  œÅ m ( ` )   ¬∑   ‚àÜ 2 ,m ( ` )   ¬∑   Pr( Àú n m   =   ` ) .  The lower bound of the average cost for the   m -th cell is given by  L B   ( E [ c ( s m , a m )])   ,   (49)  min  { œÅ m }   C (0)  m   +  ‚àû ‚àë  ` =0  œÅ m ( ` )   ¬∑   ‚àÜ 2 ,m ( ` )   ¬∑   Pr( Àú n m   =   ` ) .  By setting each   œÅ m ( Àú n m ) , the minimum value in (49) can be achieved. A valid solution is given by  œÅ m ( Àú n m ) =  {  0 ,   if   ‚àÜ 2 ,m ( Àú n m )   ‚â•   0; 1 ,   if   ‚àÜ 2 ,m ( Àú n m )   <   0 .   (50) As   f   is a non-decreasing function, (50) can be also written as  œÅ m ( Àú n m ) =  {  0 ,   if   Àú n m   ‚â§   P static  P e ‚àíP d   ‚àí   Œª m T s   =   Œ≥ L m ; 1 ,   if   Àú n m   >   P static  P e ‚àíP d   ‚àí   Œª m T s   =   Œ≥ L m ,\n\n16  where   Œ≥ L m   is defined in Theorem 3. Then the lower bound of the average cost for the   m -th cell can be calculated as  L B   ( E [ c ( s m , a m )]) =   C (0)  m   +   ‚àë  `>Œ≥ L m  ‚àÜ 2 ,m ( ` )   ¬∑   Pr( Àú n m   =   ` ) .   (51) If we ignore the constraint   ‚àë M m =1   a t m   ‚â§   M   ‚àí   K   in (2) so that the ON/OFF configurations of gNBs are independent, then the average cost in (48) follows  C œÄ   =  M ‚àë  m =1  E [ c ( s m , a m )]  ‚â•  M ‚àë  m =1  ‚àû ‚àë  ` =0  œÅ m ( ` )   ¬∑   ‚àÜ 2 ,m ( ` )   ¬∑   Pr( Àú n m   =   ` ) +  M ‚àë  m =1  C (0)  m   ,  and the lower bound of the average cost is given by  L B   ( C œÄ   )   ,   (52)  min  M ‚àë  m =1  ‚àû ‚àë  ` =0  œÅ m ( ` )   ¬∑   ‚àÜ 2 ,m ( ` )   ¬∑   Pr( Àú n m   =   ` ) +  M ‚àë  m =1  C (0)  m   .  As the ON/OFF configurations of gNBs are independent,  L B   ( C œÄ   )   in (52) can be calculated by  L B   ( C œÄ   ) =  M ‚àë  m =1  L B   ( E [ c ( s m , a m )]) .   (53) Substituting (51) into (53), we arrive at (33). A PPENDIX   E P ROOF OF   P ROPOSITION   10 Under the uniform policy, we can rewrite (48) as  C uniform   =  M ‚àë  m =1  E [ c ( s m , a m )]   (54)  =  M ‚àë  m =1  [  C (01)  m   ¬∑   Pr( a t ‚àí 1  m   = 0 , a t m   = 1) + C (11)  m   ¬∑   Pr( a t ‚àí 1  m   = 1 , a t m   = 1) + C (0)  m   ¬∑   Pr( a t m   = 0)  ]  .  In each time segment,   K   gNBs are turned off uniformly at random, we have  Pr( a t m   = 0) =   K/M ,   Pr( a t m   = 1) = 1   ‚àí   K/M,  Pr( a t ‚àí 1  m   = 0 , a t m   = 1) = Pr( a t ‚àí 1  m   = 0)   ¬∑   Pr( a t m   = 1) = (1   ‚àí   K/M   )   ¬∑   K/M,  Pr( a t ‚àí 1  m   = 1 , a t m   = 1) = Pr( a t ‚àí 1  m   = 1)   ¬∑   Pr( a t m   = 1) = (1   ‚àí   K/M   ) 2 .  Substituting the above equations into (54), we arrive at (34). A PPENDIX   F P ROOF OF   P ROPOSITION   11 First, when   K   = 0 , all the gNBs will be always turned on, hence the long-term average cost is  C round   =  M ‚àë  m =1  E   { f   [ P static   +( Àú n t m   + Œª m T s ) P d  ]}   =  M ‚àë  m =1  C (11)  m   .  When   K   =   M   , all the gNBs will be always turned off, so the long-term average cost is  C round   =  M ‚àë  m =1  E { f   [ ( Àú n t m   + Œª m T s ) P e  ]}   =  M ‚àë  m =1  C (0)  m   .  When   0   < K < M   , every   M   time segments can be viewed as a cycle, and the long-term average cost is equal to the cost in one cycle. Thus, the cost can be calculated as  C round   =   E  [  1  M  M   ‚àí 1 ‚àë  t =0  M ‚àë  m =1  c ( s t m , a t m )  ]  =  1  M  M ‚àë  m =1  M   ‚àí 1 ‚àë  t =0  E [ c ( s t m , a t m )] =  1  M  M ‚àë  m =1  [  C (0)  m   K   + C (11)  m   ( M   ‚àí K   ‚àí 1)+ C (01)  m  ]  .  To summarize, we arrive at (35). R EFERENCES [1]   I. P. Chochliouros, M.-A. Kourtis, A. S. Spiliopoulou, P. Lazaridis, Z. Zaharis, C. Zarakovitis, and A. Kourtis, ‚ÄúEnergy efficiency concerns and trends in future 5G network infrastructures,‚Äù   Energies , vol. 14, no. 17, 2021. [2]   D. L¬¥ opez-P¬¥ erez, A. De Domenico, N. Piovesan, G. Xinli, H. Bao, S. Qitao, and M. Debbah, ‚ÄúA survey on 5G radio access network energy efficiency: Massive MIMO, lean carrier design, sleep modes, and machine learning,‚Äù   IEEE Communications Surveys & Tutorials , vol. 24, no. 1, pp. 653‚Äì697, 2022. [3]   A. Israr, Q. Yang, W. Li, and A. Y. Zomaya, ‚ÄúRenewable energy powered sustainable 5G network infrastructure: Opportunities, challenges and perspectives,‚Äù   Journal of Network and Computer Applications , vol. 175, p. 102910, 2021. [4]   Y. Shao, D. G¬® und¬® uz, and S. C. Liew, ‚ÄúFederated learning with mis- aligned over-the-air computation,‚Äù   IEEE Transactions on Wireless Com- munications , vol. 21, no. 6, pp. 3951 ‚Äì 3964, 2021. [5]   C.-L. I, S. Han, and S. Bian, ‚ÄúEnergy-efficient 5G for a greener future,‚Äù  Nature Electronics , vol. 3, no. 4, pp. 182‚Äì184, 2020. [6]   3GPP, ‚ÄúRelease 15: Technical specification group services and system aspects,‚Äù Technical Specification (TS) 21.915, 2019. [7]   C.   Dongxu,   ‚Äú5G   power:   Creating   a   green   grid   that   slashes   costs, emissions & energy use,‚Äù   Technical report, Huawei , 2021. [8]   J. B. Rao and A. O. Fapojuwo, ‚ÄúA survey of energy efficient resource management techniques for multicell cellular networks,‚Äù   IEEE Commu- nications Surveys & Tutorials , vol. 16, no. 1, pp. 154‚Äì180, 2014. [9]   S. Buzzi, C.-L. I, T. E. Klein, H. V. Poor, C. Yang, and A. Zappone, ‚ÄúA survey of energy-efficient techniques for 5G networks and challenges ahead,‚Äù   IEEE Journal on Selected Areas in Communications , vol. 34, no. 4, pp. 697‚Äì709, 2016. [10]   F. Salahdine, J. Opadere, Q. Liu, T. Han, N. Zhang, and S. Wu, ‚ÄúA survey on sleep mode techniques for ultra-dense networks in 5G and beyond,‚Äù   Computer Networks , vol. 201, p. 108567, 2021. [11]   Y. Shao, S. C. Liew, and L. Lu, ‚ÄúAsynchronous physical-layer network coding: symbol misalignment estimation and its effect on decoding,‚Äù  IEEE Transactions on Wireless Communications , vol. 16, no. 10, pp. 6881‚Äì6894, 2017. [12]   Y. Shao and S. C. Liew, ‚ÄúFlexible subcarrier allocation for interleaved frequency division multiple access,‚Äù   IEEE Transactions on Wireless Communications , vol. 19, no. 11, pp. 7139‚Äì7152, 2020.\n\n17  [13]   K. Son, H. Kim, Y. Yi, and B. Krishnamachari, ‚ÄúBase station operation and user association mechanisms for energy-delay tradeoffs in green cellular networks,‚Äù   IEEE Journal on Selected Areas in Communications , vol. 29, no. 8, pp. 1525‚Äì1536, 2011. [14]   N. Saxena, A. Roy, and H. Kim, ‚ÄúTraffic-aware cloud RAN: A key for green 5G networks,‚Äù   IEEE Journal on Selected Areas in Communica- tions , vol. 34, no. 4, pp. 1010‚Äì1021, 2016. [15]   M. Deruyck, W. Joseph, and L. Martens, ‚ÄúPower consumption model for macrocell and microcell base stations,‚Äù   Transactions on Emerging Telecommunications Technologies , vol. 25, no. 3, pp. 320‚Äì333, 2014. [16]   S. K. G. Peesapati, M. Olsson, M. Masoudi, S. Andersson, and C. Cav- dar, ‚ÄúAn analytical energy performance evaluation methodology for 5G base stations,‚Äù in   International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob) , 2021. [17]   L. J. Woon, G. Ramasamy, and S. P. Thiagarajah, ‚ÄúPeak power shaving in   hybrid   power   supplied   5G   base   station,‚Äù   Bulletin   of   Electrical Engineering and Informatics , vol. 10, no. 1, pp. 62‚Äì69, 2021. [18]   Q. Wu, X. Chen, Z. Zhou, L. Chen, and J. Zhang, ‚ÄúDeep reinforcement learning with spatio-temporal traffic forecasting for data-driven base station sleep control,‚Äù   IEEE/ACM Transactions on Networking , vol. 29, no. 2, pp. 935‚Äì948, 2021. [19]   S.   Krishnasamy,   P.   T.   Akhil,   A.   Arapostathis,   R.   Sundaresan,   and S.   Shakkottai,   ‚ÄúAugmenting   max-weight   with   explicit   learning   for wireless scheduling with switching costs,‚Äù   IEEE/ACM Transactions on Networking , vol. 26, no. 6, pp. 2501‚Äì2514, 2018. [20]   J. GONG, S. ZHOU, and Z. NIU, ‚ÄúA dynamic programming approach for base station sleeping in cellular networks,‚Äù   IEICE Transactions on Communications , vol. E95.B, no. 2, pp. 551‚Äì562, 2012. [21]   M. Feng, S. Mao, and T. Jiang, ‚ÄúBase station on-off switching in 5G   wireless networks: Approaches and challenges,‚Äù   IEEE Wireless Communications , vol. 24, no. 4, pp. 46‚Äì54, 2017. [22]   F. Han, S. Zhao, L. Zhang, and J. Wu, ‚ÄúSurvey of strategies for switching off base stations in heterogeneous networks for greener 5G systems,‚Äù  IEEE Access , vol. 4, pp. 4959‚Äì4973, 2016. [23]   J. Peng, P. Hong, and K. Xue, ‚ÄúStochastic analysis of optimal base station energy saving in cellular networks with sleep mode,‚Äù   IEEE Communications Letters , vol. 18, no. 4, pp. 612‚Äì615, 2014. [24]   C. Liu, B. Natarajan, and H. Xia, ‚ÄúSmall cell base station sleep strategies for energy efficiency,‚Äù   IEEE Transactions on Vehicular Technology , vol. 65, no. 3, pp. 1652‚Äì1661, 2016. [25]   N. Lassoued, N. Boujnah, and R. Bouallegue, ‚ÄúReducing power con- sumption in C-RAN using switch on/off of MC-RRH sectors and small cells,‚Äù   IEEE Access , vol. 9, pp. 75 668‚Äì75 682, 2021. [26]   G. Yu, Q. Chen, and R. Yin, ‚ÄúDual-threshold sleep mode control scheme for small cells,‚Äù   IET Communications , vol. 8, no. 11, pp. 2008 ‚Äì 2016, 2014. [27]   J. W. Park, D.-S. Yoo, and S.-J. Oh, ‚ÄúUser-number threshold-based small-cell on/off control scheme: Performance evaluation and optimiza- tion,‚Äù   IEEE Transactions on Wireless Communications , vol. 19, no. 1, pp. 367‚Äì379, 2020. [28]   Y. Shi, J. Zhang, and K. B. Letaief, ‚ÄúGroup sparse beamforming for green cloud-RAN,‚Äù   IEEE Transactions on Wireless Communications , vol. 13, no. 5, pp. 2809‚Äì2823, 2014. [29]   Y.   Yang,   L.   Chen,   W.   Dong,   and   W.   Wang,   ‚ÄúActive   base   station set optimization for minimal energy consumption in green cellular networks,‚Äù   IEEE Transactions on Vehicular Technology , vol. 64, no. 11, pp. 5340‚Äì5349, 2015. [30]   E. Oh, K. Son, and B. Krishnamachari, ‚ÄúDynamic base station switching- on/off strategies for green cellular networks,‚Äù   IEEE Transactions on Wireless Communications , vol. 12, no. 5, pp. 2126‚Äì2136, 2013. [31]   W. Zhao and S. Wang, ‚ÄúTraffic density-based RRH selection for power saving in C-RAN,‚Äù   IEEE Journal on Selected Areas in Communications , vol. 34, no. 12, pp. 3157‚Äì3167, 2016. [32]   H. Fourati, R. Maaloul, L. Fourati, and M. Jmaiel, ‚ÄúAn efficient energy- saving scheme using genetic algorithm for 5G heterogeneous networks,‚Äù  IEEE Systems Journal , pp. 1‚Äì10, 2022. [33]   F. E. Salem, T. Chahed, E. Altman, A. Gati, and Z. Altman, ‚ÄúOptimal policies of advanced sleep modes for energy-efficient 5G networks,‚Äù in  IEEE International Symposium on Network Computing and Applications (NCA) , 2019, pp. 1‚Äì7. [34]   J. Gong, J. S. Thompson, S. Zhou, and Z. Niu, ‚ÄúBase station sleeping and resource allocation in renewable energy powered cellular networks,‚Äù  IEEE Transactions on Communications , vol. 62, no. 11, pp. 3801‚Äì3813, 2014. [35]   F. Elsherif, E. K. P. Chong, and J.-H. Kim, ‚ÄúEnergy-efficient base station control framework for 5G cellular networks based on markov decision process,‚Äù   IEEE Transactions on Vehicular Technology , vol. 68, no. 9, pp. 9267‚Äì9279, 2019. [36]   J. Ye and Y.-J. A. Zhang, ‚ÄúDRAG: Deep reinforcement learning based base station activation in heterogeneous networks,‚Äù   IEEE Transactions on Mobile Computing , vol. 19, no. 9, pp. 2076‚Äì2087, 2020. [37]   R. Li, Z. Zhao, X. Chen, J. Palicot, and H. Zhang, ‚ÄúTACT: A transfer actor-critic learning framework for energy saving in cellular radio access networks,‚Äù   IEEE Transactions on Wireless Communications , vol. 13, no. 4, pp. 2000‚Äì2011, 2014. [38]   K. Zhang, X. Wen, Y. Chen, and Z. Lu, ‚ÄúDeep reinforcement learning for energy saving in radio access network,‚Äù in   IEEE/CIC International Conference on Communications in China , 2020. [39]   M. L. Puterman,   Markov decision processes: discrete stochastic dynamic programming .   John Wiley & Sons, 2014. [40]   Y. Shao, A. Rezaee, S. C. Liew, and V. W. S. Chan, ‚ÄúSignificant sampling for shortest path routing: a deep reinforcement learning solution,‚Äù   IEEE Journal on Selected Areas in Communications , vol. 38, no. 10, pp. 2234‚Äì 2248, 2020. [41]   3GPP, ‚ÄúStudy on new radio access technology: Radio access architecture and interfaces,‚Äù Release 14, Technical Specification (TS) 38.801, 2017. [42]   B. Ghojogh, A. Ghojogh, M. Crowley, and F. Karray, ‚ÄúFitting a mixture distribution to data: Tutorial,‚Äù   arXiv:1901.06708 , 2019. [43]   Y. Shao, Q. Cao, S. C. Liew, and H. Chen, ‚ÄúPartially observable minimum-age scheduling: the greedy policy,‚Äù   IEEE Transactions on Communications , vol. 70, no. 1, pp. 404 ‚Äì 418, 2021. [44]   P. Whittle, ‚ÄúRestless bandits: activity allocation in a changing world,‚Äù  Journal of Applied Probability , vol. 25, no. A, p. 287‚Äì298, 1988. [45]   W. Roh, J.-Y. Seol, J. Park, B. Lee, J. Lee, Y. Kim, J. Cho, K. Cheun, and F. Aryanfar, ‚ÄúMillimeter-wave beamforming as an enabling technology for 5G cellular communications: theoretical feasibility and prototype results,‚Äù   IEEE Communications Magazine , vol. 52, no. 2, pp. 106‚Äì113, 2014. [46]   D. L. Snyder and M. I. Miller,   Random point processes in time and space .   Springer Science & Business Media, 2012.",
    "arXiv:cond-mat/0305660v1 28 May 2003  Quantification of Sleep Fragmentation Through the Analysis of Sleep-Stage Transitions  Chung-Chuan Lo 1 , Plamen Ch. Ivanov 1 , 2 , Lu¬¥ ƒ±s A. Nunes Amaral 1 , 2 , Thomas Penzel 3 , Claus F. Vogelmeier 3   and H. Eugene Stanley 1  1 Center for Polymer Studies and Department of Physics Boston University, Boston, MA 02215, USA  2 Cardiovascular Division, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA 02215, USA  3 Klinik f¬® ur Innere Medizin - Pneumologie, Philipps-Universit¬® at Baldingerstrasse 1, Marburg D-35033, Germany  ABSTRACT Study Objectives:   We introduce new quantitative approaches to study sleep-stage transitions with the goal of addressing the two following questions: (i) Can the new approaches provide more information on the structure of sleep-stage transitions? (ii) How does sleep fragmentation in patients with sleep apnea affect the structure of sleep- stage transitions?  Design:   We analyze hypnograms and compare normal subjects and sleep apnea patients using numerous measures, including the percentage of sleep time for each stage, probability distributions of the duration of each stage, the sleep-stage transition matrix, and a measure of the asymmetry of this matrix.  Setting:   N/A  Subjects:   197 normal subjects and 50 obstructive sleep apnea patients recruited in the SIESTA project.  Results:   We find that the time percentage for wake stage is identical for sleep apnea subjects and for normal subjects, but that the sleep apnea group have a faster decaying distribution of wake duration. Both normal subjects and sleep apnea patients have exponential distributions of duration for all sleep stages and a power law for the wake stage. We also find that there is a loss of preference of transition paths of sleep stages in sleep apnea.  Conclusions:   The new approaches proposed here enable us to show that the distribution of sleep and wake duration have different functional forms, indicating fundamental differences in the dynamics between sleep and wake control. The difference remains even in the fragmented sleep of sleep apnea. The fragmentation of sleep in sleep apnea results in a shorter wake duration and interrupts the structure of sleep-stage transitions of sleep apnea subjects, causing the loss of certain particular transition paths.  INTRODUCTION  Analyses of sleep-stage transitions have long been used as diagnostic tools in clinical applications. Such analyses mostly concentrated on the changes in the time percentage for each sleep stage and in other simple statistics such as the total number of arousals during nocturnal sleep [1,2]. There have also been several studies focusing on statistical measures such as transition probabilities [3‚Äì7], but many other statistical properties of sleep-stage transitions have not been considered in a systematic way. Sleep-stage transitions are sometimes described as having quasi-cyclic behavior (the sleep cycle) [2], but on top of the periodic patterns, there are many transitions without apparent periodicity (Fig. 1). Indeed, even if one disregards all sleep-stage transitions and considers only the wake stage during sleep, one still finds intriguing statistical properties and no apparent periodicity [8]. Furthermore, it has been reported that sleep stages correlate with the dynamics of the autonomic nervous system. For example, the correlations and scaling behavior in heart-rate variability depends on sleep stages [9,10].   Because sleep-stage transitions are such complex processes, simple statistical measures may not be sufficient to describe their dynamics and uncover any information contained in the fluctuations. Therefore, we study sleep-stage transitions with methods from modern statistical physics and nonlinear dynamics. Many advanced statistical analyses have been applied to the study of the electroencephalogram (EEG) during sleep [11‚Äì14], but an important limitation of these methods is that the EEG records only the activity close to the cortex surface, while it is believed that sleep is regulated by neurons in the hypothalamus [15]. Hence, we hypothesize that to study the dynamics of sleep regulation, one must investigate sleep-stage transitions, which contain more global information, including not only the EEG, but also eye movements and muscle tone. There are two major limitations in the analysis of sleep-stage transitions: The first is the limited number of data points ( ‚âà   900 points per night, where each point represents the sleep stage in a epoch of 30 seconds).   The second is the discretization of the data into six sleep stages. These limitations constrict the mathematical tools which can 1\n\nbe used in the analysis of sleep-stage transitions, so we focus on the distributions of duration of sleep stages, the transition probability matrices, and the degree of asymmetry of these matrices. We will also address questions regarding the statistical properties that we find: (i) how do these statistical properties change under the influence of sleep disorders, and (ii) which of these properties are fundamental and do not change under the influence of sleep disorders? To this end, we also study subjects with obstructive sleep apnea, who experience fragmented sleep with a reduced amount of slow-wave sleep and more awakenings (Fig. 1c). The sleep fragmentation is characterized by large number of arousals during nocturnal sleep. When arousal periods are longer than 15 seconds within a 30-second epoch of observation, the epoch is classified as a wake stage.   The fragmentation of sleep in obstructive sleep apnea arises from respiratory problems [16,17]. Therefore, sleep apnea is a good model for studying the effect of external disturbances on sleep-stage transitions. In the present study, we propose new quantitative approaches to studying sleep-stage transitions.   We show that these approaches enable us to find more information on the structure of sleep-stage transitions and enable us to find how sleep fragmentation of sleep apnea affects the structure of the sleep-stage transitions. Thus, the present approach gives us additional insights into the dynamics of sleep and wakefulness.  METHODS A. Subjects and Data acquisition  We analyze a database comprising 197 normal subjects and 50 patients with obstructive sleep apnea collected in eight leading European sleep laboratories under the SIESTA project [18]. For each subject, two consecutive nights were recorded with cardiorespiratory polysomnography. Sleep stages were determined according to the Rechtschaffen and Kales criteria [19]: two channels of electroencephalogram (EEG), two channels of electrooculogram (EOG), and one channel of submental electromyogram (EMG) were recorded. Signals were digitized at a minimum of 100 Hz, and a 12-bit resolution, and are scored visually in epochs of 30 seconds for six stages: wakefulness, rapid-eye-movement (REM) sleep, and non-rapid-eye-movement (NREM) sleep stages 1, 2, 3, and 4. Subjects wend to bed at midnight and were allowed to wake up in the morning at their own well. The average sleep time are xxx for healthy subjects and xxxx for sleep apnea subjects. Wake periods prior to the first sleep stage and after the last sleep stage are excluded from the analyses. We analyze hypnograms of the second night only. In order to eliminate the effect of age on sleep, we choose 48 of 197 normal subjects and 48 of 50 sleep apnea subjects. The reason for removing two sleep apnea subjects from the group is that these two sleep apnea subjects were much older (74) or younger (29) than the other sleep apnea subjects. We select the normal subjects according to the following procedure: We choose normal subjects from sleep laboratories which also provide sleep apnea subjects. The subjects are chosen to match the ages of 48 sleep apnea subjects. After all age-matched subjects have been chosen, we choose normal subjects randomly from other laboratories, also with similar age, until 48 normal subjects have been selected. We are thus able to choose normal and sleep apnea subjects with matched ages and maximum possible overlap of source laboratories. The selected normal group has an average age of 50 . 9 and a standard deviation of 9 . 4, while the selected sleep apnea group has an average age of 51 . 3 and a standard deviation of 8 . 9. We use the entire database of normal subjects in a test of the reliability of our results.  B. Coarse-graining of sleep stages  A major difficulty of studying the statistical properties of sleep-stage transitions is inter-scorer reliability, a topic of great concern in the literature [20‚Äì24]. One study reports that the agreement between sleep-stage scorers are in the range of 30%‚Äì90%, depending on the sleep stages and ages of subjects [24]. The least reliable scoring occurs for the NREM stage 1, which has only a 38% agreement on average. All other stages, such as wake, slow-wave sleep, and REM sleep, have an average agreement higher than 70%. To minimize scoring uncertainty, we reduce the six scored stages of sleep into four stages: We keep wake and REM stages unchanged, and group stages 1 and 2 into a single stage (light sleep), and stages 3 and 4 into a single stage (slow-wave sleep). The stages, wake, light sleep, slow-wave sleep, and REM sleep are abbreviated as W, L, S, and R, respectively. 2\n\nC. Percentage of sleep time  We define   F m   to the percentage of total sleep time for sleep stage   m . We measure   F m   for each sleep stage for each subject, and then calculate the mean and standard deviation of   F m   for normal and sleep apnea groups.   We apply Student‚Äôs t-test to determine the level of significance of the differences in   F m   between normal and sleep apnea groups.  D. Distributions of duration  F m   is a useful tool in diagnostic application, but it cannot capture all the information about the sleep-stage transitions. For example, identical values of   F m   could result from many short periods or from just a few long periods; two situations with different underlying dynamics.   Therefore, we study the distributions of the duration of wake and sleep stages for normal and sleep apnea groups. The distribution of duration of events is a useful measure for studying the underlying dynamics of a system. For example, a peak-like distribution indicates the periodic occurrence of events with fluctuations, such as heart beats intervals [25,26].   An exponential distribution is usually associated with a random process, such as fluorescent decay [27]. A power-law distribution, which has been observed in many systems, such as earthquakes [28], solar flares [29], and rainfall [30], is associated with self-organized criticality [31,32] or other complex mechanisms [33]. Thus, in order to quantitatively study how the brain regulates sleep, we consider the distribution of duration of sleep stages. We first calculate the duration of the separate wake and sleep stages periods for each subject, then pool the data from all subjects and calculate the group‚Äôs cumulative distributions of duration for wake, light sleep, slow-wave sleep, and REM sleep, which we denote as   P W   ( d ),   P L ( d ),   P S   ( d ), and   P R ( d ), respectively (Appendix A).  E. Transition probability matrices  The percentage   F m   and the distribution of duration   P m ( d ) of each sleep stage provide important information about the sleep stages, but they cannot provide temporal information ‚Äì i.e., time organization of transitions. For example,  P m ( d ) does not reveal any information about the preferred path of the transitions. Hence, we must study the transition probabilities between different sleep stages. Several types of transition probabilities for sleep stages have been studied [5‚Äì7]. Here, we consider a new type of transition probability matrix   T   with elements   T mn , defined as   T mn   =   N mn /N   , where   N mn   is the number of transitions from stage   n   to stage   m   during the entire night and   N   is the total number of transitions. We calculate the matrix   T  for each subject and then calculate the means and the standard errors of   T mn   for normal and sleep apnea groups. The matrix   T   is particularly useful for the analysis of the local structure of transitions because it measures the transition probability between two consecutive stages.   Since there are a large number of short transitions between different sleep stages even for normal subjects (Fig. 1), the transition matrix may be able to reveal hidden patterns in these short transitions.  F. The coefficient of asymmetry of transitions  One of the advantages of studying transition probabilities is that one may be able to extract the information about locally preferred paths in the sleep-stage transitions. One important question is: If there are locally preferred paths, are they affected by the sleep fragmentation of the sleep apnea? To answer this question, we introduce the concept of the symmetry of transitions. When the probability of having a transition from state A to state B is equal to the probability of having one from B to A, transitions between A and B are called ‚Äúsymmetric‚Äù. On the contrary, if the probability from A to B is not equal to the probability from B to A, the transition is called ‚Äúasymmetric‚Äù, a pattern indicating a preferred local transition path.   In order to quantify the asymmetry in the sleep-stage transitions, we introduce the coefficient of asymmetry   A   (Appendix B), which can be calculated from the transition matrix.   A   = 0 corresponds to a completely symmetric matrix, while   A   = 1 corresponds to a completely asymmetric matrix.   We calculate   A   for all subjects and perform Student‚Äôs t-test to evaluate the significance of the measured differences in   A  for normal and sleep-apnea groups. 3\n\nG. Test of the reliability of the results  Since sleep stages are scored visually by different experts in each laboratory, it is important to evaluate how much human bias affects the statistical analyses carried out. We compare our results with the data provided by different laboratories. For example, for the fraction   F m   of total sleep time for a given sleep stage   m , we calculated   F m   for each subject, and compare the distribution of   F m   of normal subjects from one laboratory to the normal subjects from a different laboratory. We also compare   F m   of normal subjects from one laboratory to the sleep apnea subjects from the same laboratory and from a different laboratory. We perform the same procedure on all other statistical measures calculated in this study.   We calculate the   p   value for Student‚Äôs t-test [34] and find the differences between normal and apnea subjects are much more significant ( p <   0 . 05) than the differences between normal subjects from different laboratories ( p >   0 . 05).  RESULTS  We first show results for the time percentage   F m   for each sleep stage for both normal and sleep apnea groups (Fig. 2). We find significant differences between the two groups for stage 1 ( p <   0 . 001) and also for stage 4 ( p <   0 . 05). However, there are no significant differences between normal and sleep apnea groups for the wake stage, sleep stage 2, and REM sleep. In Fig. 3 we show distributions of duration for wake,   P W   ( d ), light sleep,   P L ( d ), slow-wave sleep,   P S   ( d ), and REM sleep,   P R ( d ), for normal and sleep apnea groups.   P W   ( d ) shows a power-law decay   P W   ( d )   ‚àù   d ‚àí Œ±   for both normal and sleep apnea groups, while   P L ( d ),   P S   ( d ), and   P R ( d ) all show exponential decays,   P   ( d )   ‚àù   e ‚àí d/œÑ   . We compare   P W   ( d ),   P L ( d ),   P S   ( d ), and   P R ( d ) for normal and sleep apnea subjects and find that (i)   P W   ( d ) for sleep apnea group has a larger exponent   Œ±   = 1 . 28   ¬±   0 . 03 than the normal group,   Œ±   = 1 . 11   ¬±   0 . 05, and (ii)   P L ( d ),   P S   ( d ), and   P R ( d ) for the sleep apnea group show a steeper decay in the region   d <   5 min, but their decay time scale   œÑ   in the longer time region are similar to those of the normal group. We show the transition probability matrices   T   for the normal and sleep apnea groups in Tables 1a& b.   Not surprisingly, for both normal and sleep apnea subjects, we find some transitions are virtually prohibited: (i) there are no   R   ‚Üí   S   transitions and only few   S   ‚Üí   R   transitions, and (ii) there is no   W   ‚Üí   S   transition. For both the normal and sleep apnea groups, the matrices are asymmetric, but this asymmetry decreases for the sleep apnea group. To quantify the degree of asymmetry for normal and sleep apnea groups, we calculate the coefficient of asymmetry   A   for the data from each subject and plot distributions of   A   for normal and sleep apnea groups (Fig. 4). The normal group has a mean   A   of 0 . 058   ¬±   0 . 004, while the sleep apnea group has a mean   A   of 0 . 034   ¬±   0 . 003. We perform Student‚Äôs t-test to calculate the level of significance of the difference in   A   between normal and sleep apnea groups, resulting in a   p   value smaller than 1   √ó   10 ‚àí 5 . We also test to see if   A   changes for elder subjects, who are known to show more arousals during nocturnal sleep [1]. We choose two groups from our database of 197 normal subjects:   young (47 subjects, age:   20‚Äì35 years), and old (52 subjects age: 60‚Äì75 years). We find that the number of sleep-stage transitions in the older group has a mean of 106   ¬±   3, which is significantly larger than the mean of 84   ¬±   2 for the young group. We compare distributions of   A   between these two groups.   The young group has an average   A   of 0 . 061   ¬±   0 . 005, while the old group has an average   A   of 0 . 051   ¬±   0 . 004. Applying Student‚Äôs t-test, we find   p   = 0 . 6. A comparison of   F m ,   P m ( d ) and   A   of normal group with sleep apnea group is shown in Table 2.  DISCUSSION  We have proposed new approaches to the characterization of the dynamics of sleep-stage transitions, and found several intriguing properties: 1. We find that for normal subjects, the duration of each sleep stage is characterized by an exponential distribution with specific time scale, and the duration of wake stage is characterized by a power-low distribution suggesting a scale-free dynamics. This finding suggests a fundamental difference between the dynamics of sleep and wake- fulness control. It implies that sleep and wakefulness are not just two parts of a sleep-wake control, but that there exist entirely different mechanisms for their regulation in the brain, which supports recent studies in the neuronal level of sleep mechanisms (see, e.g., Ref. [15]). Ref. [8] reported that, for normal subjects, the duration of wake periods follows a power-law distribution,  P W   ( d )   ‚àù   d ‚àí Œ± , while the duration of sleep periods follows an exponential distribution,   P   ( d )   ‚àù   e ‚àí d/œÑ   . As shown 4\n\nin Fig. 3, when we decompose sleep into three stages: light, slow-wave and REM sleeps, all these sleep stages still follow exponential distributions. It is surprising that REM sleep, which can be regarded as somehow similar to wake from a brain activity aspect, clearly follows an exponential distribution of duration as the rest of the sleep stages, which is different from the power-law distribution of duration of the wake stage. The same forms of the distributions are observed for sleep apnea patients for all sleep stages (exponential) and for the wake stage (power law). This finding suggests robust mechanisms of sleep and wakefulness controls which do not change with sleep fragmentation in sleep apnea. 2. Our finding that the time percentage   F W   for the wake stage of the sleep apnea group is not significantly different from that of the normal group appears to contradict the ‚Äúcommon‚Äù expectation that sleep apnea subjects have more arousals. However, the difference in the wake stage between normal and sleep apnea subjects is clearly observed in the distributions of wake duration   P W   ( d ). The difference in the values of the power-law exponent   Œ±  characterizing   P W   ( d ) (Fig. 3) indicates that wake periods for sleep apnea subjects have shorter duration. Since  F W   is identical, sleep apnea subjects must have a larger number of wake periods. This is a clear indication of the sleep fragmentation one expects for sleep apnea. Although the functional form of   P L ( d ),   P S   ( d ) and   P R ( d ) is identical for normal and sleep apnea groups, the characteristic time scales are different, except for REM sleep. We find that the most significant change occurs for short duration (Fig. 3b&d). The increasing of slopes in the short duration   d <   5 min, indicates that sleep apnea subjects have many more short stages than normal subjects do, and thus a more fragmented sleep. Note that the power-law exponent   Œ±   = 1 . 1 for   P W   ( d ) for normal subjects (Fig. 3b). This value is different from what we reported ( Œ±   = 1 . 3) previously [8]. The reason is that in Ref. [8] our results was based on the database of 20 young subjects with average age of 35 . 2, which is different from the average age of 50 . 9 of the 48 normal subjects we used in this study.   With the choice of young normal subjects from the database we used in the present study, we recover   Œ±   = 1 . 3, which in agreement with the value reported in Ref. [8]. 3. From the transition matrix   T   we find that the transition probabilities between several pairs of stages change with sleep apnea. These changes can be characterized by the coefficient of asymmetry. Both normal and sleep apnea groups have asymmetric transition matrix   T   , but the sleep apnea group exhibits an increase of symmetry. The implication of an asymmetric transition matrix is that the transition process has preferred transition paths. Comparing   T RL   and   T LR , we find that there are more transitions from light sleep to REM sleep than from REM sleep to light sleep.   We also find, by comparing   T W R   and   T RW   , that there are more transitions from REM to wake then from wake to REM. These findings indicate that when a   R   ‚Üí   W   transition occurs, the sleep control system ‚Äúprefers‚Äù to make a transition to light sleep instead of back to REM (Fig. 5a). The explanation is supported by the values of   T LW   and   T W L : there are more   W   ‚Üí   L   transitions than   L   ‚Üí   W   transitions. We find that the matrices exhibit increased symmetry for the sleep apnea group (Fig. 4). This indicates that the sleep-stage transitions of sleep apnea subjects have less local structure.   From the distributions of wake duration, we learn that sleep apnea subjects have a larger number of transitions but shorter duration.   The increased wake periods, according to transition matrices, increase the symmetry of the matrix by distributing with less preference throughout the night (Fig. 5b). 4. A question one may ask is if the increase of the symmetry is a necessary result of the increase of the number of wake periods? As described in the results section, we calculate   A   for elderly subjects which have significantly larger number of wake periods during sleep. It is very interesting that although elderly subjects experience a larger number of wake periods, the coefficient of asymmetry does not change significantly ( p   = 0 . 06). This might indicate that the preferred transition path observed in normal subjects is fundamental, and is not significantly affected by age: The increased wake periods do not significantly change the preference of sleep-stage transition in elder subjects, while the increased wake periods in sleep apnea subjects do. All of our analyses are based on group distributions.   However, both normal and sleep apnea groups have broad distributions for many statistical measures. It is not known whether the changes in group distributions are represen- tative of changes in the individual behavior. It is also not known if each individual in the normal group (or in the sleep apnea group) follows the same statistics. To answer the questions, data of at least ten nights from each subject are needed. One can then compare the distribution of statistical measures from data on one subject to the data on another subject. Furthermore, all the analyses are based on whole-night records. However, sleep is not a homogeneous process. The statistical properties may vary throughout the night [35,2,8]. Hence, it is important to study the changes in   P m ( d ),  T   and   A   in the course of the night. 5\n\nOur findings of the stability of underlying dynamics of sleep-stage transitions between normal and sleep apnea subjects are intriguing.   It is important to test if the dynamics changes under pharmacological influences such as sleep-inducing drugs or caffeine, or under different psycho-physiological or pathological conditions such as stress or depression. 6\n\nAPPENDIX A. Cumulative distribution of duration  Let   p m ( d ) be the probability density function (i.e. the probability distribution) for the duration   d   of a given stage  m   for the group. We study the cumulative distribution   P m ( d ), which is defined as:  P m ( d )   ‚â°  ‚à´   ‚àû  d  p m ( r ) dr .  Therefore,   P m ( d ) is the probability of having a period of stage   m   with a duration longer than   d .   The reasons to consider   P m ( d ) instead of   p s ( d ) are: (i)   P m ( d ) gives curves smoother than   p m ( d ) does, making analyses easier. (ii)   P m ( d ) does not lose any information carried in   p m ( d ), and (iii)   P m ( d ) preserve shapes for power-law and for exponential functional forms.  B. The coefficient of asymmetry  The coefficient of symmetry of   A   is defined as  A   =  1  3  [ (   T W R   ‚àí   T RW  T W R   +   T RW  ) 2   +   (   T LW   ‚àí   T W L  T LW   +   T W L  ) 2   +   (   T LR   ‚àí   T RL  T LR   +   T RL  ) 2  ] 1 / 2  ,  where the   T mn   are elements in the transition probability matrix defined in the Methods section.   For a completely symmetric matrix in which   T mn   =   T mn ,   A   = 0, while for a completely asymmetric matrix in which one of   T mn   and  T nm   is equal to 0,   A   = 1. 7\n\nACKNOWLEDGMENTS  We thank the NIH/National Center for Research Resource (P41 RR 13622) for support. We also thank the SIESTA project (funded by the European Commission DG XII, as Biomed-2 project No. BMH4-CT97-2040 ‚ÄúSIESTA‚Äù) for providing data. We thank A. L. Goldberger and C.-K. Peng for helpful discussions and comments in the manuscript. CCL thank J. Mullington for helpful suggestions. 8\n\n[1] Chokroverty S. An overview of sleep. In: Chokroverty S ed. Sleep Disorders Medicine. Boston: Butterworth Heinemann, 1999: 7‚Äì20. [2] Carskadon MA, Dement WC. Normal Human Sleep: An Overview. In: Kryger MH, Roth T, Dement WC eds. Principles and Practice of Sleep Medicine. Philadelphia: WB Saunders Co, 2000: 15‚Äì25. [3] Williams R, Agnew H, Webb W. Sleep patterns in young adults: an EEG study. Electroen Clin Neuro 1964; 17: 376-381. [4] Brezinova V. The number and duration of the episodes of the various EEG stages of sleep in young and older people. Electroen Clin Neuro 1975; 39: 273-278. [5] Kemp B, Kamphuisen HAC. Simulation of human hypnograms using a Markov chain model. Sleep 1986; 9: 405-414. [6] Yassouridis A, Steiger A, Klinger A, Fahrmeir L. Modeling and exploring human sleep with event history analysis. J Sleep Res 1999; 8: 25-36. [7] Karlsson MO, Schoemaker RC, Kemp B, Cohen AF, van Gerven JMA, Tuk B, Peck CC, Danhof M. A pharmacodynamic Markov mixed-effects model for the effect of temazepam on sleep. Clin Pharmacol Ther 2000; 68: 175-188. [8] Lo CC, Amaral LAN, Havlin S, Ivanov PCh, Penzel T, Peter J-H, Stanley HE. Dynamics of sleep-wake transitions during sleep. Europhys Lett 2002; 57: 625-631. [9] Ivanov PCh, Bunde A, Amaral LAN, Havlin S, Fritsch-Yelle J, Baevshk RM, Stanley HE, Goldberger AL. Sleep-wake differences in scaling behavior of the human heartbeat: Analysis of terrestrial and long-term space flight data. Europhys Lett 1999; 48: 594-600. [10] Bunde A, Havlin S, Kantelhardt JW, Penzel T, Peter JH, Voigt K. Correlated and uncorrelated regions in heart-rate fluctuations during sleep Phys Rev Lett 2000; 85: 3736-3739. [11] Fell J, R¬® oschke J, Schaffner C. Surrogate data analysis of sleep electroencephalograms reveals evidence for nonlinearity. BIOLOGICAL CYBERNETICS 1996; 75: 85-92. [12] Pradhan N, Sadasivan PK. The nature of dominant Lyapunov exponent and attractor dimension curves of EEG in sleep. COMPUTERS IN BIOLOGY AND MEDICINE 1996; 26: 419-428. [13] Pereda E, Gamundi A, Rial R, Gonzalez J. Non-linear behaviour of human EEG: fractal exponent versus correlation dimension in awake and sleep stages. Neurosci Lett 1998; 250: 91-94. [14] Fell J, Kaplan A, Darkhovsky B, R¬® oschke J. EEG analysis with nonlinear deterministic and stochastic methods: a combined strategy. Acta Neurobiol Exp 2000; 60: 87-108. [15] Saper CB, Chou TC, Scammell TE. The sleep switch: hypothalamic control of sleep and wakefulness. Trends Neurosci 2002; 24: 726-731. [16] Strollo PJ, Rogers RM. Current concepts: Obstructive sleep apnea. New Engl J Med 1996; 334: 99-104. [17] Robinson A, Guilleminault C. Obstructive sleep apnea syndrome. In: Chokroverty S ed. Sleep Disorders Medicine. Boston: Butterworth Heinemann, 1999: 331‚Äì354. [18] Kl¬® osch G, Kemp B, Penzel T, Schl¬® ogl A, Rappelsberger P, Trenker E, Gruber G, Zeitlhofer J, Saletu B, Herrmann WM, Himanen SL, Kunz D, Barbanoj MJ, R¬® oschke J, V¬® arri A, Dorffner G. The SIESTA project polygraphic and clinical database. IEEE Eng Med Biol 2001; 20: 51-57. [19] Rechtschaffen A, Kales A. Manual of Standardized Terminology, Techniques, and Scoring System for Sleep Stages of Human Subjects. Los Angeles: California BIS/BRI, University of California; 1968. [20] Kelley JT, Reilly EL, Overall JE, Reed K. Reliability of rapid clinical staging of all night EEG. Clin Electroencephalogr 1985; 16: 16-20. [21] Kubicki S, Holler L, Berg I, Pastelak-Price C, Dorow R. Sleep EEG evaluation: a comparison of results obtained by visual scoring and automatic analysis with the Oxford sleep stager. Sleep 1989; 12: 140-149. [22] Whitney CW, Gottlieb DJ, Redline S, Norman RG, Dodge RR. Reliability of scoring respiratory disturbance indices and sleep staging. Sleep 1998; 21: 749-757. [23] Norman RG, Pal I, Stewart C, Walsleben JA, Rapoport DM. Interobserver agreement among sleep scorers from different centers in a large dataset. Sleep 2000; 23: 901-908. [24] Kunz D, Danker-Hopfe H, Gruber G, Kl¬® osch G, Lorenzo JL, Himanen SL, Kemp B, Penzel T, R¬® oschke J, Dorffner G. Interrater reliability between eight European sleep-labs in healthy subjects of all age groups. J Sleep Res 2000; 9: Supp 1: 106. [25] Peng CK, Mietus J, Hausdorff JM, Havlin S, Stanley HE, Goldberger AL. Long-range anti-correlations and Gon-Gaussian behavior of the heartbeat. Phys Rev Lett 1993; 70: 1343-1346. [26] Ivanov PCh, Rosenblum MG, Peng CK, Mietus J, Havlin S, Stanley HE, Goldberger AL. Scaling behaviour of heartbeat intervals obtained by wavelet-based time-series analysis. Nature 1996; 383: 323-327. [27] Campbell ID, Raymond AD. Biological spectroscopy. Menlo Park: Benjamin/Cummings Pub Co, 1984: 91‚Äì125. [28] Bak P, Christensen K, Danon L, Scanlon T. Unified scaling law for earthquakes. Phys Rev Lett 2002; 88: art. no. 178501. [29] Boffetta G, Carbone V, Giuliani P, Veltri P, Vulpiani A. Power Laws in Solar Flares: Self-Organized Criticality or Turbu-  9\n\nlence? Phys Rev Lett 1999; 82: 4662-4665. [30] Peters O, Hertlein C, Christensen K. A Complexity View of Rainfall. Phys Rev Lett 2002; 88: art. no. 18701. [31] Bak P. How nature works : the science of self-organized criticality. New York: Copernicus, 1996. [32] S¬¥ anchez A, Newman DE, Carreras BA. Waiting-Time Statistics of Self-Organized-Criticality Systems. Phys Rev Lett 2002; 88: 68320. [33] Sornette D. Critical phenomena in natural sciences: chaos, fractals, selforganization, and disorder : concepts and tools. Berlin: Springer, 2000: 285-320 [34] Press WH, Teukolsky SA, Vetterling WT, Flannery BP. Numerical recipes in C. Cambridge: Cambridge University Press; 1994. 616-617 [35] Born J, Hansen K, Marshall L, Molle M, Fehm HL. Timing the end of nocturnal sleep. Nature 1999; 397: 39-30.  10\n\nFIGURE 1  0   60   120   180   240   300   360   420   480  Time (min)  BA02602 C001002 H000602  a. b. c.  Wake REM 1 2 3 4 Wake Wake REM REM 1 1 2 2 3 3 4 4  Sleep stage  FIG. 1.   Three typical hypnograms for normal subjects (a) and (b), and for a sleep apnea subject (c).   There are large number of short sleep-stage transitions as shown in ovals throughout the nights for both normal and sleep apnea subjects. The overall patterns of hypnograms between different normal subjects are also very different. The sleep apnea subject experience fragmented sleep, and shows a much larger number of short transitions than normal subjects do.  11\n\nFIGURE 2  0 10 20 30 40 50 60  Time percentage   F m  0 20 40 60 80  Wake   1   2   3   4   REM  ** **  Normal Sleep apnea  W   L   S   R  * ** NREM  FIG. 2.   Fraction   F m   of total sleep time for a given stage   m .   Here we show the average values based on a database of 48 normal subjects and 48 sleep apnea subjects with matched ages.   The error bars give uncertainties of the average values. Student‚Äôs t-test is performed to measure the significance of the difference between normal and the sleep apnea groups.   One asterisk indicates   p <   0 . 05, and two asterisks indicate   p <   0 . 01.   Sleep stages 1 and 4 display significant differences between normal and sleep apnea subjects, while wake, stage 2, 3 and REM do not display significant differences. Further on we consider only four stages: wake (W), light sleep (L), slow-wave sleep (S), and REM sleep (REM), therefore we show the percentage of total sleep time for these four stages in the inset.  12\n\nFIGURE 3  Normal  0   10   20   30   40   50   60   70  Duration   d   (min)  10 ‚àí3  10 ‚àí2  10 ‚àí1  10 0  Cumulative probability   P m (d)   Wake  Light  Slow‚àíwave  REM  ( œÑ =9.9¬±0.1) ( œÑ =10.4¬±0.3)  ( œÑ =9.3¬±0.2)  a.  1   10  Duration   d   (min)  Œ± =0.48¬±0.01  Œ± =0.76¬±0.05  Œ± =1.11¬±0.05  b.  Sleep apnea  0   10   20   30   40   50   60   70  Duration   d   (min)  10 ‚àí3  10 ‚àí2  10 ‚àí1  10 0  Cumulative probability   P m (d)   Wake  Light  Slow‚àíwave  REM  ( œÑ =10.9¬±0.1)  ( œÑ =10.9¬±0.2) ( œÑ =9.2¬±0.2)  c.  1   10  Duration   d   (min)  Œ± =0.55¬±0.01  Œ± =0.84¬±0.05  Œ± =1.28¬±0.03  d.  FIG. 3. Cumulative distribution of duration for each sleep stage showing different features for wake stage and sleep stages but similar features for normal and sleep apnea subjects. (a) Semi-logarithmic plot and (b) double-logarithmic plot show curves for the normal group. (c) Semi-logarithmic plot and (d) double-logarithmic plot show curves for the sleep apnea group. For both normal and sleep apnea groups, the distributions for wake follow power-law decays, while the distributions for all sleep stages follow exponential decays.   Comparing to the normal group, the sleep apnea group shows larger power-law exponent  Œ±   for the distribution of wake duration, larger characteristic time scale   œÑ   for the distribution of duration of light sleep, but similar characteristic time scale for the distributions of duration of slow-wave and REM sleep. In order to compare curves of light, slow-wave and REM sleep in the small time region ( d <   5 min) between normal and sleep apnea subjects, power-law functions are fit to the curves of light and slow-wave sleep for   d <   5 min (c & d). Note that the fitting is only for the purpose of comparison.   The lack of data points in the region of   d <   5 min makes it difficult to determine the functional form of the distribution for sleep stages in this small-time region.   Note that for distributions of all sleep stages, the sleep apnea group shows a steeper decay in the small time region ( d <   5 min).  13\n\nFIGURE 4  0.00   0.10  Coefficient of asymmetry  0.00 0.10 0.20 0.30 0.40 0.50  Probability  Normal Sleep apnea  Normal mean: 0.058¬±0.004 Sleep apnea mean: 0.034¬±0.003  Student‚Äôs t‚àítest: p=7x10 ‚àí6  FIG. 4. Distribution of the coefficient of symmetry (defined in the text) for normal and sleep apnea groups. Arrows indicate means of distributions of normal and sleep apnea groups. The result of Student‚Äôs t-test indicates that the observed averages of these two groups are significantly different, suggesting that the sleep apnea group has a significant decrease of the asymmetry as the result of the sleep fragmentation.  14\n\nFIGURE 5  Normal  Deep Wake  a.  REM Light  Time  Sleep Apnea  Wake  b.  Deep  REM Light  Time  FIG. 5. Illustration of asymmetric sleep-stage transitions.   Since wake periods are much shorter than the light, slow-wave and REM sleep periods on average, we assume that the basic structure of sleep-stage transitions are dominated by light sleep, slow-wave sleep and REM sleep. (a) Wake periods can be viewed as spikes distributed throughout the night in light and REM sleep. Because   T W R   > T RW   for normal subjects (cf. Table 2, where   T W R /T RW   ‚âà   5 . 6), there is a preference for transitions from REM to wake and then to light sleep, instead of back to REM. (b) For sleep apnea subjects, there is increasing symmetry in transitions (cf.   T W R /T RW   ‚âà   2 . 6). Because sleep apnea subjects have more transitions on average, the increased wake periods may distribute in light and REM sleep with less preference throughout the night.  15\n\nTable 1  a) Transition probability matrix   T mn   (defined in the text) for normal subjects, where   m   corresponds to row and  n   corresponds to column.   The numbers in the matrix are means of the group distributions and standard errors of means. The average number of transitions per night = 96 . 0   ¬±   3 . 2.  W   R   L   S W   ‚àí   0 . 050   ¬±   0 . 005   0 . 182   ¬±   0 . 009   0 . 016   ¬±   0 . 002  R   0 . 009   ¬±   0 . 002   ‚àí   0 . 116   ¬±   0 . 007   0 . 004   ¬±   0 . 001  L   0 . 237   ¬±   0 . 010   0 . 073   ¬±   0 . 006   ‚àí   0 . 139   ¬±   0 . 010  S   0 . 001   ¬±   0 . 001   0 . 000   ¬±   0 . 000   0 . 155   ¬±   0 . 010   ‚àí  b) Same as above for sleep apnea. The average number of transitions per night = 123 . 0   ¬±   6 . 2.  W   R   L   S W   ‚àí   0 . 042   ¬±   0 . 004   0 . 217   ¬±   0 . 014   0 . 008   ¬±   0 . 002  R   0 . 016   ¬±   0 . 004   ‚àí   0 . 126   ¬±   0 . 012   0 . 001   ¬±   0 . 001  L   0 . 250   ¬±   0 . 014   0 . 099   ¬±   0 . 011   ‚àí   0 . 105   ¬±   0 . 010  S   0 . 001   ¬±   0 . 001   0 . 000   ¬±   0 . 000   0 . 114   ¬±   0 . 010   ‚àí  16\n\nTable 2  Table 2. Summary of results of our analysis for (i) the mean time percentage, (ii) the distribution of duration of sleep stages and (iii) the mean degree of asymmetry of the transition probability matrix.  ¬Ø F m   (%)   P m ( d ) Subjects   W   L*   S*   R   W*   L*   S   R   ¬Ø A *  Normal   10.6   57.3   12.2   17.8   d ‚àí 1 . 1   e ‚àí d/ 9 . 9   e ‚àí d/ 10 . 4   e ‚àí d/ 9 . 3   0.58 Sleep Apnea   10.1   61.8   8.9   17.0   d ‚àí 1 . 3   e ‚àí d/ 10 . 9   e ‚àí d/ 10 . 9   e ‚àí d/ 9 . 2   0.34  Symbols:   ¬Ø F m , mean time percentage for stage   m .   P m ( d ), distribution of duration   d   of stage   m .   ¬Ø A , mean degree of asymmetry. Stage   m   can be wake ( W   ), light sleep ( L ), slow-wave sleep ( S ) or REM ( R ). An asterisk denotes significant difference between normal and sleep apnea groups. 17",
    "1  Night sleep   duration   trajectories and associated factors among preschool children  from   the EDEN cohort  Authors:  Sabine Plancoulaine , MD, PhD a,b ,   Eve Reynaud a,b,c , MPH,   Anne Forhan a,b ,   Sandrine Lioret,  PhD a,b ,   Barbara Heude, PhD a,b   and   Marie - Aline Charles   MD, PhD a,b   ; o n behalf of t he EDEN  mother - child cohort study group.  Affiliations:  a   INSERM,   UMR1153, Epidemiology and Statistics Sorbonne Paris Cit√© Research Center  (CRESS), early ORigins   of Child Health And Development Team (ORCHAD), Villejuif, F -  94807 France ;  b   Univ Paris - Descartes , UMRS 1 153 ,   Paris , France ;  c   Ecole des Hautes Etudes en Sant√© Publique (EHESP), Rennes, F - 35043, France  Address correspondence to :  Sabine Plancoulaine ,   INSERM,   UMR1153, Epidemiology and Statistics Sorbonne Paris Cit√©  Research   Center   (CRESS),   early   ORigins   of   Child   Health   And   Development   Team  (ORCHAD),   16 Av Paul Vaillant Couturier,   94 807 Villejuif Cedex, FRANCE,  Email   :   sabine.plancoulaine@inserm.fr  P hone:   +   33 1 45 59 51 09 .  Ethical approval and consent to participate:  The study was approved by the ethics research committee of Bic√™tre Hospital   (Comit√©  Consultatif de Protection des Personnes dans la Recherche Biom√©dicale) and by the Data  Protection Authority (Commission Nationale de l‚ÄôInformatique et des Libert√©s).  Funding :  This research did not receive any specific grant from funding agencies   in the public,  commercial, or   not - for - profit sectors .\n\n2  A BSTRACT  O bjective .   S leep duration   may   vary inter - individually   and intra - individually   over time .   We   aimed at  both   identifying   night - sleep   duration   (NSD)   trajectories   among   preschoolers   and   studying  associated factors .  Methods.   NSD were collected   within the French birth - cohort study EDEN   at age s   2, 3 and 5 - 6  years   through parental questionnaires, and were used to model   NSD   trajectories   among 1205  children .   F amilial   socioeconomic   factors,   maternal   sociodemographic,   health   and   lifestyle  characteristics as well as child health, lifestyle,   and   sleep characteristics at birth and/or at   age   2  years   were   investigated in association with NSD   using m ultinomial logistic regression s .  Results.   Five   distinct   NSD   trajector ies   were identified : short (SS, <10h,   4.9 %), medium - low (MLS,  <11h,   47.8 %), medium - high (MHS,   ‚âà 11h30,   37.2 %), long (LS,   ‚â• 11h30,   4.5 %) and   changing   ( CS ,  i.e.   ‚â• 11h30   then   <11h ,   5.6 %)   NSD   trajectories . Multivaria ble   analys e s showed   in particular   that ,  compared to   the   MHS trajectory,   factors associated with increased risk for   belonging to   SS  trajectory were   male gender ,   first child , maternal age and   working   status , night - waking, parental  presence when falling asleep,   television - viewing   duration   and   both the ‚ÄúProcessed and fast foods‚Äô‚Äô  and   the ‚ÄúB aby food ‚Äù   dietary   patterns at   age   2 years.   Factors positively associated with   the   C S  trajectory were maternal smoking,   bottle - feeding at night and   the ‚Äú P rocessed   and fast   food s‚Äù  dietary   pattern at   age   2 years   wh ereas   child ‚Äôs   activity and emotionality   scores   at   age   1   y e a r w ere  negatively assoc iated .  Conclusion.   W e   identified   distinct   NSD   trajectories among   preschoolers   and   associated   early life  factors.   Some   of them   may reflect less healthy lifestyle, providing cues for early multi - behavioral  prevention intervention s .  Keywords :   Preschoolers ;   G roup - based   trajectory   modeling ;   S leep   duration ;   C ohort;   Epidemiology;  Public health;  HIGHLIGHTS  ‚Ä¢   Longitudinal data were analyzed using a data - driven developmental approach  ‚Ä¢   F ive different night sleep duration trajectories   were identified   in preschoolers  ‚Ä¢   Specific   early life factors   were   associated with each trajectory  ‚Ä¢   Most of them were   living habits   and may reflect global less healthy lifestyle  ‚Ä¢   E arly multi - behavioral prevention interventions   may be beneficial\n\n3  Abbreviations:  NSD: night - sleep duration  BMI: body - mass index  SS: short - sleep  MLS: medium - low sleep  MHS: medium - high sleep  CS: changing sleep  LS: long sleep\n\n4  1.   INTRODUCTION  Sleep is of vital importance for   children‚Äôs health and wellbeing.   There is now accumulating  evidence that insufficient quantity and/or quality of sleep have a negative impact on children‚Äôs  physical and mental health development, cognitive function,   behavior   and academic success   [1 ‚Äì 4] .  Sleep disorders and short sleep duration in childhood have also been suggested as predictors of  sleep disorders and short sleep duration in adolescence and adulthood   [5,6] .   Investigating   early  determinants of sleep durations may help   to   better   understand physiopathology and   develop  prevention   interventions of   unhealthy   sleep   pattern s .  A   British   longitudinal   cohort   study   interested   in   factors   associated   with   normal   sleep  duration variation among   over 11,000   children aged 6 months to 11 years, showed   that   girls  consistently   slept longer than boys ,   and   that older mother age (>35 years) was associated with  shorter sleep   duration   [7] .   Studies   focusing   on short sleep, with   age - specific   cut - offs, also showed  that   girls   were   less   likely to be short sleepers   [8 ‚Äì 10] .   Other factors associated with   short sleep  were identified as lower socio - economic status, non Caucasian ethnic group, maternal stress  and/or   depression,   prematurity,   low   birth   weight,   care   outside   the   home,   TV/screen   viewing  especially before going to sleep   and late bedtime   [7,8,10,11] .   Parental   behavior   a t bedtime (e.g.  parental presence until sleep onset, feeding), especially among toddlers ,   is an additional important  risk factor for fragmented sleep and consequently shorter sleep duration   [12 ‚Äì 15] .  A decrease in children‚Äôs total sleep duration has been reported in the last decades   [16,7] ,  suggesting that   a growing number of   children   may   now   get   short er   sleep duration   than needed .  The American Academy of Sleep Medicine recently recommended a total   mean   sleep duration of  10 to 13 hours per 24 hours   among preschoolers   [17] .   As   reported   by   Galland et al and B lair et al,  standard deviation of the means   var ies between 1 to 2 hours among pre schoolers   [7,16]   and   sleep  duration   mean   may   not   correctly   reflect   the   variety   of   sleep   durations   during   childhood.  Longitudinal sleep patterns or trajectory may   also   be of interest.   Previous research concerning  Canadian   preschoolers   identified   four   sleep trajectories between 2.5 and 5 years : short persistent  (<9h rs /night) , short increasing   ( <9h up to 3. 5 years old and then around 10 .5 h rs ) , 10 - h rs   persistent  and 11 - h rs   persistent patterns   [18,19] .   The   authors   showed   a n   increased risk of   externaliz ing  problems   [18]   and   high hyperactivity scores   [19]   in   6 year - old   children with short sleep duration  trajector y   ( i.e.   short - persistent   vs.   11h rs - persistent sleepers ) . They also   reported   that risk   factors  as soci a ted with   both   short   sleep trajectory   and high hyperactivity scores   were   male gender, low  household income, low maternal education and parental presence during night awakening   [19] .  However,   t hey did not   search for factors   associated with   the   short   sleep trajector y   by itself   or with  other   sleep trajectories .   In addition,   European   preschoolers   tend to sleep   longer   on average   than  the   North American   preschoolers   [14,20]   and may not display the same   sleep patterns over time   or  associated factors .\n\n5  This   first longitudinal study on   children‚Äô   sleep   duration in   a   French   birth - cohort   aimed at i)  identifying   sleep   duration   trajectories   between   2   and   5 - 6   years ;   and   ii)   identif y ing   factors  associated with   each   sleep duration   trajector y .  2.   MATERIALS/SUBJECTS AND METHODS  2.1.   STUDY DESIGN  The EDEN study aims   at   investigat ing   the pre -   and post - natal determinants of child health  and   development. Details of the EDEN study protocol have been previously published   [21] .   Briefly,  pregnant women under 24 weeks of amenorrhea were recruited   between 2003 and 2006, in the  university hospitals of Poitiers and Nancy. Those under 18 years, unable to give informed consent,  functionally illiterate in French, with a history of diabetes, planning on changing address or without  social security coverage   were excluded from the cohort.   Multiple pregnancies were   also   excluded.  Among the 3758 women invited to participate, 2002 (53%) agreed to   enroll   in to   the study. Due to  miscarriages, stillbirths and attrition, 1899 children were enlisted at birth. Written   informed consent  was obtained twice from parents: at enrolment and after the child‚Äôs birth. The study was approved  by   the   ethics   research   committee   of   Bic√™tre   Hospital   (Comit√©   Consultatif   de   Protection   des  Personnes dans la Recherche Biom√©dicale) and by th e Data Protection Authority (Commission  Nationale de l‚ÄôInformatique et des Libert√©s).  2.2.   DATA COLLECTION  Data were collected   using   parental self - administered questionnaires and   during   clinical  examinations ,   including anthropometric measurements of each child.   Sleep items were study -  designed ones.  2.2.1.   Main measure: Night sleep duration  Night s leep   durations   w ere   collected at ages 2, 3 and 5 - 6 years old   and were   calculated  based on the answers to the following   questions: ‚ÄúUsually, at what time does your child go to  bed?‚Äù, ‚ÄúUsually, at what time does your child wake up?‚Äù .   Responses were recorded in hours and  minutes.  2.2.2.   Predictors  The   household   socio - economic   and   demographic   factors,   as   well   as   maternal  characteristics were collected at inclusion. Household income was divided into three categories:  below   ‚Ç¨ 1500 per month   ( ‚âà   French   threshold of poverty for a family) , between   ‚Ç¨ 1500 and   ‚Ç¨ 3000 per  month,   and   above   ‚Ç¨ 3000   per   month   ( ‚âà 10 th   upper   percentile   of   Fre nch   income   distribution).  Education level was also defined in three categories, using the highest level reached by one of the  parents: below high - school diploma, high - school diploma, and above. Single parenting was defined  as a mother living without the child‚Äôs father, another comp anion, or another adult family member.  Mothers   reported   information   on   age   at   delivery   and   tobacco   consumption   during   and   after\n\n6  pregnancy   (coded as   never , only after pregnancy and   always (during ¬± after pregnancy ) ) .   The  mother‚Äôs   depressive symptoms   during   pregnancy were assessed by the Fr ench version of the  Center of Epi demiolog i c S tudies Depression Scale ( CES - D ) .   Mothers with a CES - D score of   ‚â• 23  were considered to present depressive symptoms   [22] .   B ody mass index (B MI )   before pregnancy  was   calculated   using   reported   height   and   weight.   T he   maternity   ward   of   recruitment  (Nancy/Poitiers)   and the mother‚Äôs working status at age 2   ( coded as yes/no )   were also taken into  account .  The child‚Äôs characteristics and anthropometrics w ere collected at birth from self - reported  questionnaires and medical records, including gender,   first child   ( yes/no ), ponderal index (defined  by birth weight in kg divided by the cube of birth   length   in meters), and preterm birth (<   37 weeks of  amenorrhea).   Breastfeeding duration was collected in months   from   prospective   self - administered  questionnaires .   Temperamental traits, namely activity, shyness, emotionality and sociality were  assessed at age 1 using the Emotionality Activity an d Sociability scale (EAS)   [23] .  A t   age 2, data were   collected   for several sleep characteristics. Nap   duration   was   assessed  through   two questions :   ‚ÄúDoes your child regularly take a nap?‚Äù ‚ÄúIf yes, what is the mean duration of  a nap?‚Äù.   Responses were recorded in hours and minutes.   Children who did not nap were coded as  0 hours 0 minutes.   Frequent night awakenings at the age of 2 years were defined as waking every  other night or more (ye s/no) over the week preceding the self - questionnaire completion, in the  absence   of   acute   illness. Parental presence   when   falling   asleep   was also   collected   through  questions on sleeping habits (place (e.g. living room), parental interaction (e.g.   holding hands) and  bed sharing). A child was considered to sleep without parental presence when parents reported  that he/she felt asleep in his/her own bed without any adult interaction.  At age 2,   we collected   the number of hours per day spent in physical   activity (walking,  playing outside) and watching television or other screens during a usual week separately for  weekdays,   Wednesdays   (weekday   without   preschool   in   France)   and   for   weekend   days.   As  expected, the mean number of hours per day spent in physical   activity was statistically different  according to the season when the self - questionnaire was completed. We therefore split this  variable into quartiles according to each season   at which the questionnaire was completed . As this  was not the case for the num ber of hours spent watching TV, the latter was analysed continuously.  W e   also   assessed   care arrangement (in large collective settings like preschool or day care cent r es  vs. home care) .   F eeding at night   (bottle -   or breast - feeding,   yes/no)   was collected at 2 and 3 years  old .   T he c hild‚Äôs   BMI - z - score   was   c alculated using the WHO age and   gender   standards , and  obesity   was   defined   as   a   BMI - z - score   ‚â• 2   SD   [24] .   W e   also   accounted   for   dietary   patterns  previously identified in the EDEN cohort   [25] .   Briefly,   children‚Äôs dietary intake was collected using a  short food frequency questionnaire and   three dietary patterns   -   accounting for 26.8% of the  explained variance   -   were identified at 2 years of age using principal component analysis   (PCA) .  The first pattern ,   labeled   ‚Äò‚ÄòProcessed and fast foods‚Äô‚Äô ,   was   positively correlated with intake of\n\n7  French fries, processed meat, carbonated soft drinks, chocolate, chips, cookies, pizza, fruit juice,  meat, dairy desserts, and ice cream (by descending order of PCA   loadings). The second pattern,  labeled   ‚Äò‚ÄòGuidelines,‚Äô‚Äô   was   characterized   mainly   by   high   consumption   frequency   of   cooked  vegetables,   rice, fresh fruit, raw vegetables, low - fat fish, potatoes, ham, stewed fruit, and meat.  The third pattern ,   labeled   ‚Äò‚ÄòBaby foods‚Äô‚Äô,   had high positive loadings for baby foods, brea kfast  cereals, and stewed fruit and negative loadings for raw vegetables and fresh fruit.  2.3.   STATISTICAL METHODS  2.3.1.   Group - based trajectory modeling  The group - based trajectory modeling method   (PROC TRAJ procedure)   developed by Nagin  et al.   [26]   was used to   identify meaningful and distinct   patterns   of sleep duration   from the age 2 to  5 - 6 years .   The method is based on the underlying hypothesis that within a population there are  inherent groups that evolve according to different   sleep   patterns. The groups are not directly  identifiable or pre - established by sets of characteristics but statistically determined through each  series of responses using maximum likelihood. The   relationship between age and night sleep  duration was modeled by po lynomial equations defining trajectories. The most adequate model,  regarding the number of groups and the shape of the trajectories ,   was determined by iterations:  different models with two to five groups were computed and then compared   using the Bayesian  I nformation   Criteria   (BIC)   and   favoring   parsimony.   The   chosen   model   quality   was   verified  according to the recommended criteria : the average posterior probabilities for each subgroup  ( ‚â• 0.7) ,   the   odds of correct classification   ( ‚â• 5) , and   the similarity between   the model‚Äôs estimation of  the trajectory   prev alence and the actual prevalence   [26] .  Children were included in the trajectory‚Äôs elaboration if their parents had answered the  questions regarding   night - sleep durations at least   at   two time points out of three. To verify the  robustness of the model, sensitivity analys is   w as   performed   in   childr en who had complete sleep  duration data at all three time points .  2.3.2.   S tudy of associated factors  Children were assigned to   the trajectory for which he/she has the highest probability   of  belong ing. Multinomial logistic regressions were then computed to study   factors associated with  modeled night - sleep duration trajectories.   We chose as reference trajectory, the one that was the  nearest of the recommended sleep duration between 2 and 5 years old, i.e. between 11 and 11.30  hours/night.   An unadjusted analysis was   first performed   on collected data described in the previous  section , then a multivariable analysis that included factors   with   a p - value <0.20 in the unadjusted  analyses   and   socioeconomic   factors   (i.e.   parental   education   status,   household   income   and  recruitment   center ) . Missing values for   explanatory   factors represented 4.0% of the total data set.  Simple imputation s   (modal   value for categorical variables and   median   value   for continuous ones)  were implemented.\n\n8  All analyses were performed using SAS (SAS 9.3 SAS Institute Inc, Cary, NC, USA).  3.   RESULTS  3.1.   Night - sleep duration trajectories  Out of the   1899   children enrolled at birth,   self - administered questionnaires were available  for   1349   children   at   age   2, 1377 at   age 3 and 1 255 at   age   3.   A total of   12 05   presented two out of  three completed time points for   night - sleep duration   and were included in the trajectory conception .  Compared   to included children,   non - included   children   (N = 694 ) were   more   likely to   be born to a  mother   from   Nancy   recruitment cent e r   ( 41.4 % versus   31.5 %, p <10 - 4 ) ,   with low incomes   ( 19.0 %  ‚â§ 1500   ‚Ç¨ /months versus   10.4 %, p =0.01 ) ,   low educational level ( 31.0 % versus   15.2 %   with a level  below high - school diploma, p<10 - 4 ),   who smoked   during   and after   pregnancy   ( 66.7 %   versus  22.3 %,   p<10 - 4 ), and   who was   unemployed   2 years   post - partum   (4 3 .8% versus 26. 0 %, p<10 - 4 ) .  The re was no difference between the two population   group s regarding   maternal   age at delivery  (p=0.09) ,   parity   (p=0.92) ,   child gender   (p=0.46) , prematurity status   (p=0.82) ,   or breastfeeding  duration   (p=0.45) .   Mean night - sleep duration   of selected children   was   11 h rs 06   ( SD 0h49   -   range  8 h rs 00 - 14 h rs 00 )   at age 2   (N=1082) ,   10h rs 52 (SD 0h rs 40   -   range 9h rs 00 - 13h rs 45)   at age 3  (N=1170)   and   10 h rs 52   ( SD 0h rs 28   -   range   9 h rs 17 - 12 h rs 17 )   at   age   5 - 6   (N=1020) .  The optimal and parsimonious trajectory model to describe night - sleep duration patterns  was a five - group model   as illustrated in   Figure 1 :   a   S hort - S leep duration   trajectory   (SS,   always  <10h rs3 0/night) best explained by a   quadratic   relationship with time and representing   4.9 % of the  children ;   a M edium - L ow - S leep duration trajectory   (MLS, 10h rs 30 - 11h rs 00/night) best explained by  a   posi tive linear relationship with time and representing   47.8 % of the children ;   a M edium - H igh -  S leep   duration   trajectory   (MHS,   around   11h rs 30/night)   best   explained   by   a   negative   linear  relationship with time and representing   37.2 % of the children ;   a L ong - S leep duration trajectory   (LS,  ‚â• 11h rs 30/night) best explained by a negative linear relationship with time and representing   4.5 % of  the children ;   and   a   Changing - S leep duration trajectory   ( C S, i.e.   up to age 3   similar to   LS   and   then  to   MLS) estimated to be quadratic over time and representing   5.6 % of the children.   Nagin‚Äôs  recommended   criteria   for goodness of fit   were met for all groups   [26] .   To test robustness of the  model,   t he same procedure   was   performed   including   children with three completed time points  (N= 862 )   that   showed no notable difference regarding   i)   the number of groups,   ii)   the shape of the  trajectories or   iii)   compliance with   recommended criteria for goodness of fit   (data not shown) .  Hence, we chose to include the largest sample size for further analysis.\n\n9  Figure   1.   Night   sleep   duration   trajectories   obtained   among   the   EDEN   preschool   children  (N=1205). Full lines represent mean sleep duration trajectories. Black circles = Short sleepers (SS,  4.9% of the children): triangles = Medium Low sleepers (MLS, 47.8% of the chi ldren); diamonds =  Medium High sleepers (MHS, 37.2% of the children), squares = Changing (CS, 5.6% of the  children) and white circles = Long sleepers (LS, 4.5% of the children). Dashed lines represent the  95% confidence intervals of the trajectory estimati ons.  3.2.   Factors   associated with night - sleep   duration   trajectories  Population characteristics are presented in Table 1 and multivariable analysis is reported in  Table 2.   As compared to the MHS trajectory, membership to the SS trajectory between 2 to 5 - 6  years was more likely in boys, first - borns, born to older mothers, with   at age 2 years   higher  occurrence of frequent night waking, more frequent parental presence when fall ing asleep, longer  time spent in front of TV, higher scores on both the ‚ÄúProcessed and fast food‚Äù and ‚ÄúBaby foods‚Äù  dietary patterns, and when mothers worked 2 years post - partum . Of note, most of these factors  were also associated with the MLS trajectory me mbership, as compared to the MHS.   There   was   no  association between membership to SS or   to   M L S trajectories and   the maternal smoking status,  the child‚Äôs temperament scores   at   age 1   feeding at night at age 2 .  9  9,5  10  10,5  11  11,5  12  12,5  13  2   2,5   3   3,5   4   4,5   5   5,5  Night sleep duration (hours)  Age (years)\n\n10  Table 1 .   Characteristics of the 1205 children in the full sample and according to each night - sleep duration trajectory. Data are %(n) or  mean¬±sd.  Full sample   SS a   MLS a   MHS a   CS a   LS a   Global p - value  (n=1205)   n=59   n=576   n=448   n=68   n=54  Socieconomic factors  Center (Nancy)   46.8 (564)   47.5 (28)   46.9 (270)   45.1 (202)   60.3 (41)   42.6 (23)  Parental education level  < High school   15.2 (183)   17.0 (10)   14.6 (84)   15.2 (68)   17.7 (12)   16.7 (9)  High school   18.2 (219)   25.4 (15)   17.5 (101)   17.4 (78)   22.0   (15)   18.5 (10)  > high school   66.6 (803)   57.6 (34)   67.9 (391)   67.4 (302)   60.3 (41)   64.8 (35)  Household income  <1500   ‚Ç¨ /month   10.4 (125)   8.5 (5)   9.0 (52)   10.5 (47)   19.1 (13)   14.8 (8)  1501 - 3000   ‚Ç¨ /month   58.9 (710)   64.4 (38)   61.3 (353)   56.7 (254)   54.4 (37)   51.9 (28)  >3000   ‚Ç¨ /month   30.7 (370)   27.1 (16)   29.7 (171)   32.8 (147)   26.5 (18)   33.3 (18)  Maternal characteristics  Age at delivery (years)   30.0 ¬± 4.6   30.5 ¬± 4.59   30.5 ¬± 4.5   29.7 ¬± 4.7   28.6 ¬± 5.0   29.4 ¬± 4.4   **  Smoking habits   *  Never   64.3 (775)   57.6 (34)   66.8 (385)   64.7 (290)   50.0 (34)   59.3 (32)  Only after pregnancy   13.4 (161)   11.9 (7)   12.9 (74)   14.7 (66)   11.8 (8)   11.1 (6)  Always   22.3 (269)   30.5 (18)   20.3 (117)   20.5 (92)   38.2 (26)   29.6 (16)  Pre - pregnancy BMI   23.1 ¬± 4.3   23.   6 ¬± 4.4   23.3 ¬± 4.4   22.9 ¬± 4.1   23.1 ¬± 4.8   23.0 ¬± 4.5  Depressive symptoms b   5.2 (62)   3.4 (2)   4.3 (25)   5.1 (23)   11.8 (8)   7.4 (4)  Single parenting   3.5 (40)   1.8 (1)   4.1 (22)   3.3 (14)   3.0 (2)   1.9 (1)  Child characteristics  First child   46.6 (561)   61.0 (36)   43.6 (251)   46.2 (207)   58.9 (40)   50.0 (27)   *  Gender (Boy)   53.2 (641)   71.2 (42)   56.3 (324)   50.5 (226)   36.8 (25)   44.4 (24)   ***  Pre - term birth c   5.3 (64)   6.8 (4)   4.9 (28)   6.0 (27)   0.0 (0)   9.3 (5)  Child ponderal index (kg/m 3 )   27.0 ¬± 2.7   27.0 ¬± 2.3   26.9 ¬± 2.8   26.9 ¬± 2.54   27.4 ¬± 3.1   27.2 ¬± 3.2  Breastfeeding duration (months)   3.4 ¬± 3.7   2.9 ¬± 3.9   3.5 ¬± 3.8   3.1 ¬± 3.6   3.3 ¬± 3.9   3.   7 ¬± 4.0  Temperament at age 1 d  Activity   3.53 ¬± 0.48   3.63 ¬± 0.44   3.53 ¬± 0.47   3.54 ¬± 0.49   3.41 ¬± 0.53   3.51 ¬± 0.50  Shyness   2.08 ¬± 0.56)   1.97 ¬± 0.42   2.08 ¬± 0.58   2.10 ¬± 0.56   2.11 ¬± 0.62   2.12 ¬± 0.55  Emotionality   2.76 ¬± 0.70)   2.8 ¬± 0.86   2.76 ¬± 0.67   2.77 ¬± 0.69   2.63 ¬± 0.72   2.80 ¬± 0.80  Sociability   3.69 ¬± 0.59   3.83   ¬±   0.69   3.72 ¬± 0.58   3.65 ¬± 0.58   3.62 ¬± 0.61   3.74 ¬± 0.59  Characteristics at 2 years of age  Working mother   ** *  No   26.0 (313)   20.3 (12)   22.7 (131)   29.2 (131)   29.4 (20)   35.2 (19)  Part - time   34.1 (411)   33.9 (20)   35.6 (205)   34.2 (153)   32.4 (22)   20.4 (11)  Full - time   39.9 (481)   45.8 (27)   41.7 (240)   36.6 (164)   38.2 (164)   44.4 (24)\n\n11  Collective care arrangement   21.1 (254)   18.6 (11)   22.6 (130)   20.8 (93)   16.2 (11)   16.7 (9)  Nap duration (hrs/day)   2hrs04 ¬± 0hrs30   2hrs07 ¬± 0hrs34   2hrs04 ¬± 0hrs30   2hrs05 ¬± 0hrs29   2hrs02 ¬± 0hrs32   2hrs02 ¬± 0hrs30  Frequent night - wakings   20.3 (245)   40.7 (24)   24.1 (139)   14.1 (63)   19.1 (13)   11.1 (6)   ***  Falling asleep with p arental presence   11.5 (139)   25.4 (15)   13.7 (79)   8.7 (39)   5.9 (4)   3.7 (2)   ***  F eeding at night   26.4 (318)   25.4 (15)   26.9 (155)   24.8 (111)   45.6 (31)   11.1 (6)   ***  Body mass index (z - score)   0.25 ¬± 0.98   0.28 ¬± 0.78   0.25 ¬± 0.89   0.26 ¬± 0.85   0.27 ¬± 0.80   0.03 ¬± 0.74  Television watching (hrs/day)   0hrs40 ¬± 0hrs43   1hrs10 ¬± 1hrs10   0hrs41 (0hrs40)   0hrs37 (0hrs39)   0hrs31 (0hrs40)   0hrs40 (0hrs49)   ***  Physical activity (quartiles) e  Q1   23.4 (282)   28.8 (17)   24.5 (141)   21.4 (96)   27.9 (19)   16.7 (9)  Q2   27.2 (328)   17.0 (10)   25.4 (146)   31.2 (140)   20.6 (14)   33.3 (18)  Q3   24.2 (292)   27.1 (16)   24.1 (139)   23.7 (106)   23.6 (16)   27.8 (15)  Q4   25.2 (303)   27.1 (16)   26.0 (150)   23.7 (106)   27.9 (19)   22.2 (12)  Dietary pattern score  Processed and fast foods   - 0.05 ¬± 0.94   0.12 ¬± 1.08   - 0.01 ¬± 0.96   - 0.12 ¬± 0.87   0.11 ¬± 1.07   - 0.22 ¬± 0.80  Guidelines   0.03 ¬± 0.93   0.01 ¬± 1.05   0.01 ¬± 0.91   0.07 ¬± 0.94   - 0.05 ¬± 0.9   0.11 ¬± 0.94  Baby foods   - 0.02 ¬± 0.97   0.34 ¬± 0.94   - 0.03 ¬± 0.98   - 0.07 ¬± 0.94   0.11 ¬± 0.93   0.03 ¬± 1.08   *  * ‚â§ 0.05, ** ‚â§ 0.01, *** ‚â§ 0.001  a   Night sleep duration trajectories: SS for Short sleep duration, MLS for Medium Low sleep duration, MHS for Medium High sleep   duration, CS  for Changing sleep duration and LS for Long sleep duration trajectory.  b   Center of Epidemiologic Studies Depression   scale score   ‚â• 23  c   Birth before 37 weeks of amenorrhea  d   Emotionality Activity and Sociability scale (EAS); score range 0 ‚Äì 5, a higher score indicates more activity, shyness, emotionality or sociability  e   Quartiles of physical activity according to each   season\n\n12  Table 2. Multiple multinomial logistic regression for sleep trajectories, N=1205. The MHS a   trajectory served as reference  SS a   MLS a   CS a   LS a  Global p - value b  OR c   (95% CI)   OR c   (95% CI)   OR c   (95% CI)   OR c   (95% CI)  Socieconomic factors  Cente r   (Nancy)   1 . 44 (0 . 77   ‚Äì   2 . 70)   1.1 9   (0. 91   -   1.5 6 )   2.55 (1.4 1   -   4.5 8 ) **   0.9 6   (0.5 2   -   1. 79 )   *  Parental education level  < High school   0 . 80 (0 . 3 0   ‚Äì   2 . 14)   0.9 1   (0.5 7   -   1.4 4 )   0.72 (0.29   -   1.79)   1. 12   (0.4 1   ‚Äì   3.06 )  High school   (reference)   (reference)   ( reference)   (reference)  > high school   0 . 58 (0 . 27   ‚Äì   1 . 26)   1.00   (0.69   -   1.4 4 )   0.78 (0.37   -   1.6 6 )   0.9 4   (0.4 1   -   2.1 8 )  Household income (euros/months)  <1500   0.67 (0.18   -   2.4 5 )   1.2 1   (0.69   -   2.0 9 )   1.7 5   (0.6 3   -   4.8 9 )   1. 20   (0.39   -   3. 65 )  1501 - 3000   1.30   (0.62   -   2.74)   1.38 (1.01   -   1.88)   1.2 3   (0.62   -   2.43)   0.8 4   (0.4 1   -   1.7 1 )  >3000   (reference)   (reference)   (reference)   (reference)  Maternal characteristics  Age at delivery (years)   1.14 (1.06   -   1.22) ***   1.06 (1.03   -   1.10) ***   0.98 (0.91   -   1.05)   1.00   (0.9 3   -   1.07)   ***  Smoking habits  Never   (reference)   (reference)   (reference)   (reference)  Only after pregnancy   1.10 (0.44   -   2.76)   0.89 (0.61   -   1.30)   0.91 (0.39   -   2.13)   0.84 (0.33   -   2.13)  Always   1. 92   (0.9 5   -   3.8 7 )   1.0 3   (0.7 3   -   1.4 4 )   2.40 (1.27   -   4.5 5 ) **   1. 6 0 (0.7 9   -   3. 23 )  Depressive symptoms d   0.7 5   (0.16   -   3. 44 )   0.8 5   (0.47   -   1.5 5 )   2. 63   (1.0 3   -   6. 7 3) *   1.3 3   (0.43   -   4.1 4 )  Child characteristics  First child   3. 19   (1. 57   -   6. 50 ) ***   1. 08   (0.8 0   -   1. 45 )   1.83 (0.9 6   -   3.4 9 )   1. 00   (0.5 1   ‚Äì   1.96 )   **  Gender (Boy)   2.4 6   (1.3 0   -   4. 68 ) **   1.28 (0.99   -   1.6 6 )   0.60 (0.34   -   1.0 6 )   0.8 4   (0.4 5   -   1. 50 )   **  Temperament at age 1 e  Activity   1.0 3   (0.5 2   -   2.0 1 )   0.9 1   (0. 69   -   1.21)   0.52 (0.3 0   -   0.91) *   0.8 3   (0.4 5   -   1. 55 )  Shyness   0.91 (0.49   -   1. 70 )   1.02 (0.79   -   1.33)   1.1 2   (0.66   -   1.9 1 )   1.1 4   (0.6 3   -   2. 06 )  Emotionality   0.8 5   (0.54   -   1.3 4 )   0.93 (0.76   -   1.1 3 )   0.62 (0.41   -   0.9 5 ) *   1.00   (0.63   -   1.5 8 )  Sociability   1. 64   (0.9 3   -   2. 87)   1.1 9   (0.9 3   -   1.5 2 )   1.0 5   (0.6 3   -   1.7 5 )   1.4 6   (0.8 4   -   2. 52 )  Characteristics at 2 years   of age  Working mother   **  No   (reference)   (reference)   (reference)   (reference)  Part - time   2 . 39 (0 . 99   ‚Äì   5 . 74)   1 . 42 (1.00   ‚Äì   2 . 01)   1 . 18 (0 . 57   ‚Äì   2 . 42)   0 . 48 (0 . 21   ‚Äì   1 . 08)  Full time   2 . 93 (1 . 26   ‚Äì   6 . 80) *   1 . 78 (1 . 26   ‚Äì   2 . 52) **   1 . 22 (0 . 59   ‚Äì   2 . 50)   0 . 98   (0 . 49   ‚Äì   1 . 96)  Frequent night - wakings   3. 71   (1. 90   -   7. 21 ) ***   1.9 1   (1.3 5   -   2. 70 ) **   1.47 (0.7 2   ‚Äì   2.99 )   0.7 7   (0.31   -   1.9 3 )   ***  Falling asleep with parental presence   3. 44   (1. 59   ‚Äì   7.41 ) **   1.62 (1.05   -   2.50) *   0.5 4   (0.17   -   1.72)   0. 50   (0. 11   ‚Äì   2.22 )   **  F eeding at night   0.55 (0.27   -   1.1 4 )   1.00   (0.73   -   1.3 5 )   2.4 6   (1.3 8   -   4.4 7 ) **   0.3 7   (0.15   -   0. 92 ) *   ***  Television watching (hrs/day)   2.1 1   (1. 50   -   2.9 7 ) **   1.13 (0.93   -   1.38)   0.57 (0.35   -   0.93) *   1.1 3   (0.73   -   1.7 3 )   ***  Dietary pattern score  Processed and   fast foods   1.45 (1.06   ‚Äì   2.01 ) *   1.21 (1.04   -   1.41) *   1.38 (1.04   -   1.81) *   0.83 (0.57   -   1.2 2 )   *  Guidelines   1.00 (0.73   -   1.3 8 )   0.94 (0.82   -   1.0 9 )   0.91 (0.68   -   1.22)   1.07 (0.78   -   1.4 7 )  Baby foods   1.48 (1.08   -   2.03) **   1.0 6   (0.93   -   1.22)   1.18 (0.89   -   1.57)   1.12   (0.83   -   1.51)\n\n13  * ‚â§ 0.05, ** ‚â§ 0.01, *** ‚â§ 0.001  a   Night sleep duration trajectories: SS for Short sleep duration, MLS for Medium Low sleep duration, CS for Changing sleep dura tion and LS for  Long sleep duration trajectory.  b   p - value for the global effect of the corresponding factor analy z ed  C   odds ratio (OR) and 95% confidence interval (95%CI)  d   Center of Epidemiologic Studies Depression scale score   ‚â• 23  e   Emotionality Activity and Sociability scale (EAS); score range 0 ‚Äì 5, a higher score indicates more activity, shyness, emotionality or sociability\n\n1 4  As compared to the MHS trajectory, membership to the   C S trajectory was more likely   in  children   from Nancy ,   fed at night ,   with higher scores on the ‚ÄúProcessed and fast foods‚Äù dietary  pattern at 2 years ,   as well as   and   in children   whose mother presented depressive symptoms during  pregnancy and smoked during and after pregnancy .   The activity and emotionality temperament  score at 1 year old   decreased the likelihood of   membership to th e CS   trajectory as   did   time spent  in front of TV .   Moreover, additional adjustment for night feeding at 3 years did not change the  results. In   particular the OR for night feeding stayed very stable at 2 years (OR=2.28 (95%CI 1.19 -  4.40)), the one for night feeding at 3 years was borderline significant (OR=1.93 (0.95 - 3.88))  F eeding at night at 2 years old was the only factor associated with   membership to the LS  trajectory   showing that   night   fed   children   were less likely   to belong to   this trajectory   than to the  MHS one .  No   association   was   observed   between   sleep   duration   trajectories   and   socioeconomic  factors (education level, household incomes).  4.   DISCUSSION  This study ,   using trajectory   modeling ,   gives new insight into developmental patterns of  night - sleep duration and associated factors among   preschoolers .   In this context, t hree   trajectories  and their associated factors   are of particular interest: the SS trajectory that   was   under the sleep  duration recommendations, the LS   trajectory that slowly decreased   between   12.5hrs/night to  11hrs/night bet ween 2 and 5 - 6 years old and the   C S trajectory that showed a 2h rapid decrease  between 2 and 3 years.  4.1.   Sleep duration trajectories  We identified five   night   sleep   duration   trajectories   among   preschoolers .   We showed ,   as  others ,   that   each night sleep duration   trajectory (except the CS one)   was   quite stable during early  childhood   [18,27] .   This may reflect one child‚Äôs inherent sleep needs, howev er we identified several  factors associated with the belonging to each trajectory (discussed below)   stressing   the importance  for   good sleep habits   setting in early infancy .   In contrast,   the   thresholds   allowing to distinguish  different trajectories were overall higher   than those   described in Canadian pre - school population  (short   was defined as   < 9h rs /night , medium   low   as   10 - h rs   persistent , medium high   as   11 - h rs  persistent ,   changing   as   short then   between   10 - h rs   and 11 - h rs   persistent , and long   were   not  observed )   [18,19] .   These differences   may   partly   be explained by the   overall   higher night -   and total -  sleep durations in French   [14]   an d   in   North - European   [20]   preschool children, as   compared to  North Americans   [18,19,27] .   I n the present study, mean sleep durations at age 2, 3   and 5 - 6   were in  the higher limits of the American Academy of Sleep Medicine recommendations to promote optimal  health   [17] .   However, w e reported similar proportion of   members of   the   ‚Äú short ‚Äù   sleep trajectory  group   (5 to 6%)   to   that published among children o f   the same ages using   the   same trajectory  method   [18,19] .\n\n15  4.2.   Factors associated with short sleep   duration trajectory  The present study confirm ed   some of   the   risk factors for short sleep duration   suggested   in  both cross - sectional and longitudinal studies   among preschool or school aged children , i.e.   male  gender   [7 ‚Äì 10,14,19]   and maternal older age   [7,14] .   First - born children ha ve   been shown to present  shorter sleep duration in infancy   [28] ,   which could suggest   higher   parental   stress   or   higher   parental  intervention on child ‚Äôs sleep   or both .   However, the relation   wa s observed in the present analysis  independently of maternal age, maternal depressive status and sleep habits.   A couple of   sleep  habits ,   already shown to be associated with short sleep durations   [27] ,   w ere   positively   associated  with SS trajectory, namely parental presence when falling asl eep and   frequent night waking .   A s  often discussed, the association between   child‚Äôs sleep   and sleep strategies may be bidirectional  [29] ,   and   the child‚Äôs temperament   may influence sleep and sleep behaviors   [30,31] .   However,   the  observed   relation   persisted   after   adjustment   for   child‚Äôs   temperament   scores   suggesting  involvement of other factors such as parental beliefs and practices   [32] .   Altogether, these elements  indicate   that   children   belonging   to   the   short   sleep   trajectory   could   benefi t   from   behavioral  interventions promoting healthier sleep hygiene ,   shown to   be   associated with longer sleep duration  and less night - waking in childhood   [33,34] .  T ime spent in front of TV   at age 2   was positively associated with this SS trajectory   between  2 and 5 - 6 years old , as observed by others   [35] .   Beside children wit h low physiological sleep needs  who   may   be   entertained   by   longer   TV   watching,   t his   m ight   be   explained   either   by   direct  replacement of sleep   by TV   watching   or   by   the program viewed and its   aggressive ness   associated  with more sleep troubles   [36] .   Unfortunately,   these hypotheses could not be addressed in the  current study, given   that   the appropriate information was not collected . Another   explanation could  be   the   blue light exposure   from the   mobile   screens   alter ing   circadian rhythms .   T he low access to  these devices when data were collected   make s   this hypothesis unlikely .   Children belonging to the  SS trajectory   more   often   had   working mother s   at age 2.   Th e latter   m ay be   more likely to   come  back   home   later   than their non - working counterparts, making it more challenging   to get their  child ren   to   sleep   early ; they also   may   need to wake them up earlier   for   care arrangement ,  altogether resulting in   shorter night sleep duration   [37,38] .   However, i n the current study, there was  no difference in prevalence of   care arrangement according to the   five   trajectories.   Finally,   shorter  and lower quality of sleep   have been associated with higher energy intake mainly through   high fat  food   in adult s   [39]   and   chil d ren   [40] .   A recent review also noted that diet , especially diet rich   in  fresh fruits, vegetables, whole grains, and low - fat protein sources,   promotes sleep quantity in  adults   [41] .   In children,   Kocevska   et al .   showed that   a higher contribution of fat to total energy  intake   at 13 months of age was negatively associated with sleep duration at 2 years of age   [42] .  Th ese   findings   are   in li ne with the   positive association between   ‚ÄúProcessed and fast foods‚Äù dietary  pattern   scores   supposedly   positively   associated   with   total   energy   intake   and   SS   trajectory  observed in the current study .   A   positive   association   is also   noted with the   ‚ÄúB aby   foods ‚Äù   score .   One\n\n16  may say that working mothers with less   available   time to cook may   favor   prepared food s   for their  child either processed and fast food s   or   more specific al ly   baby food   [43 ‚Äì 45] .   In this context, these  latter associations may reflect a   less healthy   lifestyle .   R isk factors associated with the MLS  trajectory   ( between   10hrs30   and   11hrs/night)   were   similar   to   those   associated   with   the   SS  trajectory except for   gender ,   first child ,   television - viewing duration and baby - food dietary patterns  when compared to MLH trajectory.   MLS trajectory is ,   however, within the   Ame rican   Academy of  Sleep   Medicine   recommendation   of   sleep   duration   range   to   promote   optimal   health   among  preschoolers .   Furth er studies will be needed   to investigate   the   relations hips   between t h ese sleep  trajector ies   and   subsequent health outcomes.  4.3.   Factors associated with   changing   night - sleep duration trajectory  Factors associated with   C S   trajectory   (as compared with the MHS)   were   quite   specific   and  may reflect factors associated with the   sharp   decline   in sleep duration between 2 and 3 years old .  Of note,   care - arrangement ,   nap duration, working status,   incomes and parental education level s  were not associated with this trajectory.   Consistent with other studies   [11] ,   we   found that m aternal  depressi on   was   associated with short er   sleep duration in children .   Several studies conjecture that  at least part of this link is mediated by   inappropriate   sleep strateg ies   [46] ,   e.g.   feeding at night   ( as  also   observed   here) .   A nother inappropriate strategy could be   the use of   processed and fast foods  for the child,   that may   bring too much fat shown to be deleterious for good sleep   in childhood   [42] .  Processed   and   fast   foods   dietary   pattern   scores   have   been   shown   to   track   (spearma n  correlation=0.40, p<0.001) between 2 and 3 years old in the EDEN study   [25] .   We found   that easy  child   temperament   at   1   year   old   (lower   score   for   activity   and   emotionality)   was   positively  associated   with   the   C S   trajectory   between   2   and   5 - 6   years   old,   independently   of   maternal  depressive status.   Maternal smoking , especially during pregnancy,   h as been associated with sleep  disturbances   [47,48] ,   through   prenatal   physiological   modification   involving   hypoxia   (as   those  involved in   sudden i nfant   death syndrome   [49]   or by a direct increas e of   health problems such as  asthma, lower respiratory function, infections (reviewed in   Treyster et al   [50] )   or both .   Overall ,  factors associated with   membership   to the   C S   trajectory   we re   behavioral   ones reflecting a global  life style less stringent with familial health and health recommendations.   T he   positive   association  between   Nancy   recruitment   center   and th e   C S   trajectory   is unexpected   and still unexplained.   It  may reflect incomplete   accounting   f or some   risk factors (e.g. socioeconomic   or environmental  factors)   or existence of some yet unidentified ones within this specific group of children .   Future  studies w ill   be needed to explore   in particular   lifestyle   changes   that occurred   between 2 and 3  years old that might explain ,   at least partially ,   the rapid decrease of sleep duration within this sleep  trajectory .  4.4.   Factors associated with long   night sleep duration trajectory  After adjustment, t he only factor   remaining   significantly associated to the LS trajectory was  a   negative   one. Children within this trajectory were less   bottle - fed at night   at two years old   than the\n\n17  children of the MHS trajectory. This confirms the reduced occurrence of night waking and   thus   of  strat egies involved to get the child go back to sleep such as feeding.   Of note, there was no  association with   the parental education level, familial incomes, temperament scores   of the child   at  1 year,   maternal working status   or   dietary pattern scores.   This suggests that ,   despite night sleep  duration   evolution between 2 and 5 - 6 years , which may reflect   children   physiological needs   in  general population ;   children of both   MHS and LS   trajectories   were quite   similar.  4.5.   Strengths and limitations  S trength s   of this study   are   the   general   population sample and   the   longitudinal data   for  children   sleep   duration , along   with   the   method   used   that   allowed   a   powerful   developmental  analysis of night - sleep duration in preschool age.   However, the results of the present   study should  be   interpreted   in   light   of   some   limitations.   Sleep   duration   was   calculated   based   on   self -  administered questionnaires asking for usual bedtimes and wake up times with no information on  sleep onset. They may be different from bedtimes and diffic ult for parents to estimate. While sleep  duration here reflects time in bed, this is a measure still widely used in epidemiology   [7,16,20] .   To  better estimate sleep onset and time spent awake, an independent and objective measure of sleep  by actigraphy would have been more accurate but had not been considered   for   cost and   logistical  reasons . Simple parental reports on their child‚Äôs sleep duration have however been shown to be  reliable   when   compared   to   actigraphy   [51,52] .   Parental - r eported   sleep   durations   are   usually  overestimated   and   night   awakenings   underestimated   compared   to   actigraphy .   However,   the  questionnaires and methods used allow comparison with the international literature and   especially  studies performed in Canad a   with similar sleep questions and trajectory modeling   [18,19] .   We  selected children with availabl e sleep data at least for 2 out of 3 time points leading to sleep  duration trajectories estimation on 66% of the original cohort. Bias cannot be ruled out if for  example, those who were lost to follow up were more likely to have certain sleep duration  char acteristics. Comparison of included and excluded children showed   no   differences   for   night  sleep duration   when   available   and we hypothesize a low impact on the modeled   night sleep  duration   trajectories. However,   recruitment rate and   attrition in the cohort   follow up,   lead to a  studied population   with   higher socioeconomic status   and   higher education level   than the targeted  population   [21] ,   generalization of the   findings is not possible especially   regarding associated  factors to low social classes .   T his population selection may   also   explain certain observed   non -  significant associations .   In addition, w e   analyzed   simultaneously 5 trajectories and a   large   number  of variables   that   may   have   lead   to   lack of power especially when considering trajectories with small  sample size .   Lastly,   w e   did not perform correction for multiple testing and may have falsely  identified association between studied factors and sleep duration trajectories. Our results, issued  from this first longitudinal study on sleep duration trajectories and associated factor s among  preschoolers, will need to be confirmed\n\n18  5.   CONCLUSION  Trajectory analyses give new insight into developmental patterns of night - sleep duration  and   associated   factors   among   preschoolers .   The   study   confirmed   know n   early   life   factors  associated with   short er   sleep duration in   preschoolers   but also highlight ed   new ones such as   less  healthy   dietary patterns .   Interestingly ,   some of these   risk factors   including dietary patterns   were  associated with   medium - low sleep duration trajectory   that   however   meets   the   American Academy  of Sleep Medicine   sleep duration recommendations   in   preschoolers .   This study also identified a  particular sleep duration trajectory, the   ‚Äú changing ‚Äù   one,   that   presented specific early risk factors,  including   depressive symptoms during   pregnancy,   tobacco smoking during and after pregnancy,  feeding at night   and processed dietary pattern   at 2 years old.   Altogether, identified risk factors  associated with   shorter or   changing   sleep duration trajectories   between 2 to 5 - 6 years old   were  mainly   living   habits   and   may   reflect   global   less healthy   lifestyle. T hus   early   multi - behavioral  prevention interventions   may   be   beneficial in the s e   population s .   F urther studies   are needed to  investigate whether those sleep trajectories are differently related to   subsequent health outcomes  and to replicate the results   in larger mother - child cohorts.\n\n19  ACKNOWLEDGMENTS  Collaborators: We thank the EDEN mother - child cohort study group (I. Annesi - Maesano , J.Y  Bernard, J. Botton, M.A. Charles, P. Dargent - Molina, B. de Lauzon - Guillain, P. Ducimeti√®re, M. de  Agostini, B. Foliguet, A. Forhan, X. Fritel, A. Germa, V. Goua, R. Hankard, B. Heude, M. Kaminski,  B. Larroque‚Ä†, N. Lelong, J. Lepeule, G. Magnin, L. Ma rchand, C. Nabet, F. Pierre, R. Slama, M.J.  Saurel - Cubizolles, M. Schweitzer, O. Thiebaugeorges).  We thank all funding sources for the EDEN study: Foundation for medical research (FRM),  National Agency for Research (ANR), National Institute for Research i n Public health (IRESP:  TGIR cohorte sant√© 2008 program), French Ministry of Health (DGS), French Ministry of Research,  INSERM Bone and Joint Diseases National Research (PRO - A) and Human Nutrition National  Research Programs, Paris ‚Äì Sud University, Nestl√©, F rench National Institute for Population Health  Surveillance (InVS), French National Institute for Health Education (INPES), the European Union  FP7 programs (FP7/2007 - 2013, HELIX, ESCAPE, ENRIECO,Medall projects), Diabetes National  Research Program (in coll aboration with the French Association of Diabetic Patients (AFD), French  Agency   for   Environmental   Health   Safety   (now   ANSES),   Mutuelle   G√©n√©rale   de   l‚ÄôEducation  Nationale complementary health insurance (MGEN), French national agency for food security,  French   speaking association for the study of diabetes and metabolism (ALFEDIAM).\n\n20  REFERENCES  [1]   Gruber R. Short sleep duration is associated with teacher - reported inattention and cognitive  problems   in   healthy   school - aged   children.   Nat   Sci   Sleep   2012;4:33 ‚Äì 40.  doi:10.2147/NSS.S24607.  [2]   O‚ÄôCallaghan FV, Al Mamun A, O‚ÄôCallaghan M, Clavarino A, Williams GM, Bor W, et al. The  link between sleep problems in infancy and early childhood and att entio n problems at 5 and 14  years: Evidence from a birth cohort study. Early Hum Dev 2010;86:419 ‚Äì 424.  [3]   Reynaud E, Vecchierini M - F, Heude B, Charles MA, Plancoulaine S. Sleep and its relation to  cognition and behavior in typically developing preschool ag ed   children: a systematic review. J  Sleep Res 2018;In press. doi:10.1111/jsr.12636.  [4]   Miller M, Kruisbrink M, Wallace J, Ji C, Cappuccio FP. Sleep Duration and Incidence of  Obesity in Infants, Children and Adolescents: A Systematic Review and Meta - Analys is   of  Prospective Studies. SLEEP 2018;In Press.  [5]   Al Mamun A, O‚ÄôCallaghan F, Scott J, Heussler H, O‚ÄôCallaghan M, Najman J, et al. Continuity  and discontinuity of trouble sleeping behaviors from early childhood to young adulthood in a  large Australian com mun ity - based - birth cohort study. Sleep Med 2012;13:1301 ‚Äì 6.  [6]   Quach J, Hiscock H, Canterford L, Wake M. Outcomes of Child Sleep Problems Over the  School - Transition   Period:   Australian   Population   Longitudinal   Study.   Pediatrics  2009;123:1287 ‚Äì 92. d oi:10.1542/ped s.2008 - 1860.  [7]   Blair PS, Humphreys JS, Gringras P, Taheri S, Scott N, Emond A, et al. Childhood sleep  duration and associated demographic characteristics in an English cohort. Sleep 2012;35:353 ‚Äì  60.  [8]   Sadeh A, Raviv A, Gruber R. Sleep patt erns and sleep   disruptions in school - age children. Dev  Psychol 2000;36:291 ‚Äì 301. doi:10.1037/0012 - 1649.36.3.291.  [9]   Biggs SN, Lushington K, James Martin A, van den Heuvel C, Declan Kennedy J. Gender,  socioeconomic, and eth nic differences in sleep patterns in school - aged   children. Sleep Med  2013;14:1304 ‚Äì 9. doi:10.1016/j.sleep.2013.06.014.  [10]   McDonald L, Wardle J, Llewellyn CH, van Jaarsveld CHM, Fisher A. Pred ictors of shorter  sleep in early childhood. Sleep Med 2014;15:536 ‚Äì 40. doi:10.1016/j.sleep.2014.01.005.  [11]   Neva rez MD, Rifas - Shiman SL, Kleinman KP, Gillman MW, Taveras EM. Associations of  early life risk factors with infant sleep duration. Acad Pedia tr 2010;10:187 ‚Äì 93.  [12]   Mindell JA, Sadeh A, Kohyama J, How TH. Parental behaviors and sleep outcomes in infants  and   toddlers:   A   cross - cultural   comparison.   Sleep   Med   2010;11:393 ‚Äì 9.  doi:10.1016/j.sleep.2009.11.011.  [13]   Reynaud E, Forhan A, Heude B, de Lauzon - Guillain B, Charles M - A, Plancoulaine S. Night -  waking trajectories and associated factors in French preschoolers   from the EDEN birth - cohort.  Sleep Med 2016;27 ‚Äì 28:59 ‚Äì 65. doi:10.1016/j.sleep.2016.09.008.  [14]   Plancoulaine S, Lioret S, Regnault N, Heude B, Charles M - A, the Eden Mother - Child Cohort  Study Group. Gender - specific factors associated with shorter sleep durati on at age 3 years. J  Sleep Res 2015;24:610 ‚Äì 20. doi:10.1111/jsr.12308.  [15]   Touchette E, Petit D, Paquet J, Boivin M, Japel C, Tremblay RE, et al. Factors associated with  fragmented sleep at night across early childhood. Arch Pediatr Adolesc Med 2005;159:24 2 ‚Äì 9.  [16]   Galland BC, Taylor BJ, Elder DE, Herbison P. Normal sleep patterns in infants and children: a  systematic review of observational studies. Sleep Med Rev 2012;16:213 ‚Äì 222.  [17]   Paruthi S, Brooks LJ, D‚ÄôAmbrosio C, Hall WA, Kotagal S, Lloyd RM, et al.   Recommended  Amount of Sleep for Pediatric Populations: A Consensus Statement of the American Academy  of Sleep Medicine. J Clin Sleep Med 2016;12:785 ‚Äì 6. doi:10.5664/jcsm.5866.  [18]   Touchette E, Petit D, Seguin JR, Boivin M, Tremblay RE, Montplaisir JY. Ass ociations  between sleep duration patterns and behavioral/cognitive functioning at school entry. Sleep  2007;30:1213 ‚Äì 9.\n\n21  [19]   Touchette E, Cote SM, Petit D, Liu X, Boivin M, Falissard B, et al. Short nighttime sleep -  duration and hyperactivity trajectories in   early childhood. Pediatrics 2009;124:e985 - 93.  [20]   Hense S, Barba G, Pohlabeln H, De Henauw S, Marild S, Molnar D, et al. Factors that  influence weekday sleep duration in European children. Sleep 2011;34:633 ‚Äì 9.  [21]   Heude B, Forhan A, Slama R, Douhaud L, B edel S, Saurel - Cubizolles M - J, et al. Cohort  Profile: The EDEN mother - child cohort on the prenatal and early postnatal determinants of  child health and development. Int J Epidemiol 2015;45:353 ‚Äì 63. doi:10.1093/ije/dyv151.  [22]   F√ºhrer R, Rouillon F. La versi on fran√ßaise de l‚Äô√©chelle CES - D. Description et traduction de  l‚Äô√©chelle d‚Äôauto√©valuation [The French version of CES - D: Description and translation of the  self - report scale]. Psychiatr Psychobiol 1989;4:163 ‚Äì 6.  [23]   Buss A h., Plomin R. Temperament: early de veloping personality traits. Numerized. Michigan  Univsersity: Erlbaum; 2008.  [24]   de   Onis   M.   Development   of   a   WHO   growth   reference   for   school - aged   children   and  adolescents. Bull World Health Organ 2007;85:660 ‚Äì 7. doi:10.2471/BLT.07.043497.  [25]   Lioret S,   Betoko A, Forhan A, Charles M - A, Heude B, de Lauzon - Guillain B, et al. Dietary  Patterns Track from Infancy to Preschool Age: Cross - Sectional and Longitudinal Perspectives.  J Nutr 2015;145:775 ‚Äì 82. doi:10.3945/jn.114.201988.  [26]   Nagin DS. Group - based modell ing of development. Harvard University Press. Cambridge,  Massachusetts: 2005.  [27]   Sadeh A, Mindell JA, Luedtke K, Wiegand B. Sleep and sleep ecology in the first 3 years: a  web - based study. J Sleep Res 2009;18:60 ‚Äì 73. doi:10.1111/j.1365 - 2869.2008.00699.x.  [28]   Kaley F, Reid V, Flynn E. Investigating the biographic, social and temperamental correlates of  young infants‚Äô sleeping, crying and feeding routines. Infant Behav Dev 2012;35:596 ‚Äì 605.  doi:10.1016/j.infbeh.2012.03.004.  [29]   Sadeh A, Tikotzky L, Scher A.   Parenting and infant sleep. Sleep Med Rev 2010;14:89 ‚Äì 96.  doi:10.1016/j.smrv.2009.05.003.  [30]   Molfese VJ, Rudasill KM, Prokasky A, Champagne C, Holmes M, Molfese DL, et al. Relations  Between Toddler Sleep Characteristics, Sleep Problems, and Temperament.   Dev Neuropsychol  2015;40:138 ‚Äì 54. doi:10.1080/87565641.2015.1028627.  [31]   Sorondo BM, Reeb - Sutherland BC. Associations between infant temperament, maternal stress,  and   infants‚Äô   sleep   across   the   first   year   of   life.   Infant   Behav   Dev   2015;39:131 ‚Äì 5.  doi:10.1016 /j.infbeh.2015.02.010.  [32]   Tikotzky L, Shaashua L. Infant sleep and early parental sleep - related cognitions predict sleep in  pre - school children. Sleep Med 2012;13:185 ‚Äì 92. doi:10.1016/j.sleep.2011.07.013.  [33]   Mindell JA, Meltzer LJ, Carskadon MA, Chervin   RD. Developmental aspects of sleep hygiene:  Findings from the 2004 National Sleep Foundation Sleep in America Poll. Sleep Med  2009;10:771 ‚Äì 9. doi:10.1016/j.sleep.2008.07.016.  [34]   Mindell JA, Kuhn B, Lewin DS, Meltzer LJ, Sadeh A, American Academy of Sleep   Medicine.  Behavioral treatment of bedtime problems and night wakings in infants and young children.  Sleep 2006;29:1263 ‚Äì 76.  [35]   Cespedes   EM,   Gillman   MW,   Kleinman   K,   Rifas - Shiman   SL,   Redline   S,   Taveras   EM.  Television Viewing, Bedroom Television, and Sleep   Duration From Infancy to Mid - Childhood.  PEDIATRICS 2014;133:e1163 ‚Äì 71. doi:10.1542/peds.2013 - 3998.  [36]   Garrison MM, Liekweg K, Christakis DA. Media Use and Child Sleep: The Impact of Content,  Timing, and Environment. PEDIATRICS 2011;128:29 ‚Äì 35. doi:10.1542/ peds.2010 - 3304.  [37]   Speirs KE, Liechty JM, Wu C - F. Sleep, but not other daily routines, mediates the association  between maternal employment and BMI for preschool children. Sleep Med 2014;15:1590 ‚Äì 3.  doi:10.1016/j.sleep.2014.08.006.  [38]   Magee CA, Caputi P , Iverson DC. Are parents‚Äô working patterns associated with their child‚Äôs  sleep? An analysis of dual - parent families in Australia: Parent work and child sleep. Sleep Biol\n\n22  Rhythms 2012;10:100 ‚Äì 8. doi:10.1111/j.1479 - 8425.2011.00530.x.  [39]   Dashti HS, Scheer F A, Jacques PF, Lamon - Fava S, Ordovas JM. Short Sleep Duration and  Dietary Intake: Epidemiologic Evidence, Mechanisms, and Health Implications. Adv Nutr Int  Rev J 2015;6:648 ‚Äì 59. doi:10.3945/an.115.008623.  [40]   Fisher A, McDonald L, van Jaarsveld CHM, Llewel lyn C, Fildes A, Schrempft S, et al. Sleep  and energy intake in early childhood. Int J Obes 2014;38:926 ‚Äì 9. doi:10.1038/ijo.2014.50.  [41]   Peuhkuri K, Sihvola N, Korpela R. Diet promotes sleep duration and quality. Nutr Res  2012;32:309 ‚Äì 19. doi:10.1016/j.nutr es.2012.03.009.  [42]   Kocevska D, Voortman T, Dashti HS, van den Hooven EH, Ghassabian A, Rijlaarsdam J, et al.  Macronutrient Intakes in Infancy Are Associated with Sleep Duration in Toddlerhood. J Nutr  2016;146:1250 ‚Äì 6. doi:10.3945/jn.115.225847.  [43]   Slate r J, Sevenhuysen G, Edginton B, O‚Äôneil J. ‚ÄòTrying to make it all come together‚Äô:  structuration and employed mothers‚Äô experience of family food provisioning in Canada. Health  Promot Int 2011;27:405 ‚Äì 415.  [44]   Blake CE, Wethington E, Farrell TJ, Bisogni CA, D evine CM. Behavioral Contexts, Food -  Choice Coping Strategies, and Dietary Quality of a Multiethnic Sample of Employed Parents. J  Am Diet Assoc 2011;111:401 ‚Äì 7. doi:10.1016/j.jada.2010.11.012.  [45]   Datar A, Nicosia N, Shier V. Maternal work and children‚Äôs di et, activity, and obesity. Soc Sci  Med 2014;107:196 ‚Äì 204. doi:10.1016/j.socscimed.2013.12.022.  [46]   Jian N, Teti DM. Emotional availability at bedtime, infant temperament, and infant sleep  development   from   one   to   six   months.   Sleep   Med   2016;23:49 ‚Äì 58.  doi:10. 1016/j.sleep.2016.07.001.  [47]   Johansson A, Ludvigsson J, Hermansson G. Adverse health effects related to tobacco smoke  exposure in a cohort of three - year olds: Tobacco smoke exposure related to health. Acta  Paediatr 2008;97:354 ‚Äì 7. doi:10.1111/j.1651 - 2227. 2007.00619.x.  [48]   Yolton K, Xu Y, Khoury J, Succop P, Lanphear B, Beebe DW, et al. Associations Between  Secondhand Smoke Exposure and Sleep Patterns in Children. PEDIATRICS 2010;125:e261 ‚Äì 8.  doi:10.1542/peds.2009 - 0690.  [49]   Fleming   PJ,   Blair   PS,   Pease   A.   S udden   unexpected   death   in   infancy:   aetiology,  pathophysiology, epidemiology and prevention in 2015. Arch Dis Child 2015;100:984 ‚Äì 8.  doi:10.1136/archdischild - 2014 - 306424.  [50]   Treyster Z, Gitterman B. Second hand smoke exposure in children: environmental fac tors,  physiological effects, and interventions within pediatrics. Rev Environ Health 2011;26:187 ‚Äì 95.  [51]   Iwasaki M, Iwata S, Iemura A, Yamashita N, Tomino Y, Anme T, et al. Utility of Subjective  Sleep Assessment Tools for Healthy Preschool Children: A Com parative Study Between Sleep  Logs,   Questionnaires,   and   Actigraphy.   J   Epidemiol   2010;20:143 ‚Äì 9.  doi:10.2188/jea.JE20090054.  [52]   Sadeh A, Hauri PJ, Kripke DF, Lavie P. The role of actigraphy in the evaluation of sleep  disorders. Sleep 1995;18:288 ‚Äì 302.",
    "SWS- promoting MHb-IPN-MRN circuit opposes  the theta- promoting circuit, active wake and REM sleep.  A circuit-based model of functional properties.  Karin Vadovi ƒç ov√°  ABSTRACT Hippocampus was connected to medial habenula (MHb) by multisynaptic axonal tracts in my previous DTI study. These probabilistic tracts linked hippocampus to septum, and amygdala to bed nucleus of stria terminalis (BNST). The axons from septum and BNST passed by anteromedial thalamic nucleus (AM) to MHb, then from MHb to pineal gland, known for control of circadian cycles and sleep. Question is what is the MHb doing and why it receives information from hippocampus via septum? So this study explores the connectivity of MHb, predicts its functional role and how it is linked to memory replay. My combination of known findings about septum and MHb connectivity and function led to this circuit-based idea/hypothesis that posterior septum activates MHb, MHb activates interpeduncular nucleus (IPN), and then IPN stimulates MRN and its serotonin release. Proposed idea is that this MHb-IPN-MRN circuit promotes slow wave sleep (SWS), high serotonin and low acetylcholine state. My prediction is that this SWS-promoting circuit reciprocally suppresses the theta oscillations promoting circuit, linked to high acetylcholine levels in brain, and formed by supramamillary area (SUM) projections to the medial septum (MS) that induces theta rhythm in hippocampus and other theta-coupled regions. The MHb- IPN-MRN pathway likely inhibits, possibly reciprocally, also some regions that have stimulating input to the theta-generating SUM and MS, such as the wakefulness promoting nucleus incertus (NI), posterior hypothalamus (PH), lateral hypothalamus (LH) and laterodorsal tegmentum (LDT), as well as the REM sleep inducing neurons in LDT and reticular nucleus pontis oralis (PnO). Thus, proposed SWS- promoting circuit attenuates the output of the theta-promoting regions, both the active wake-on and REM-on regions. The theta rhythm in wake state is linked to recording and binding information with their spatio- temporal and relational context by hippocampus, while the SWS supports rest, replay and transfer of hippocampally stored inter-connected information/memory traces and their cortical reactivations, e. g. in retrosplenial cortex linked to autobiographic memory or in prefrontal cortex that can combine information from any sources.  Introduction. Known role of serotonin in inducing SWS.  Serotonin signal in the brain induces behavioural and emotional relaxation, slow-down and rest while dopamine promotes action, locomotion, motivation, speeding up. Serotonin is present early during embryogenesis, probably to slow down/lower heart rate and blood pressure (by activating parasympathetic system). Later on the same serotonin slows down skeletal muscles movement (running, locomotion) and breathing, attenuates sympathetic system by inhibiting amygdala and dorsal anterior cingulated cortex (dACC), plus might enable the relaxation phase in ON-OFF rhythmic motor activity of axial muscles in fish where contraction alternates with extension. Brain serotonin slows down locomotion, calms down the active avoidance, negative emotions and drive, makes us rest and relax, promotes\n\nwell-being (Vadovi ƒç ov√° and Gasparotti, 2014), satisfaction and reconstructive (deep) stage of sleep called slow wave sleep or non-REM (SWS or NREM) sleep. SWS shows high amplitude, low frequency EEG, while the rapid eye movement (REM) sleep shows low amplitude, high frequency EEG oscillations in cortex (Jouvet, 1962). The SWS is known for its recovery-restorative function, calcium cascade of nocturnal proteosyntesis and also for the replay and transfer of the contextually/relationally bound information from the hippocampus to cortex, by replaying the waking neuronal firing patterns in hippocampus and cortex during temporally coupled hippocampal sharp-wave/ripples (SWRs) and cortical spindles (Buzs√°ki, 1989). The 5-10 Hz oscillations in the hippocampal local field potential called theta rhythm occur during voluntary exploration, locomotion and REM sleep (O'Keefe and Recce, 1993; Bland and Oddie, 2001; Buzsaki, 2002). REM sleep is proportionally more abundant in young mammals (Roffwarg et al. 1966). The EEG patterns of sleep and wakefulness become adult-like only after full development of the cortex (Blumberg et al., 2003). The fast EEG synchrony typical of wakefulness develops through adolescence in humans, similar to prolonged cortical maturation in higher primates (Uhlhaas et al., 2009).  Serotonin from the dorsal raphe nucleus (DRN) has been functionally grouped with the arousal-promoting neuromodulators important for wake state: noradrenaline, histamine, orexin (hypocretin) and acetylcholine. Orexin stabilizes wakefulness, as its deficiency causes narcolepsy disorder with inability to maintain long waking periods, with abrupt transitions into SWS sleep, and intrusions of REM sleep into waking (Sakurai, 2007). In addition, the mice deficient in norepinephrine or histamin sleep more and have no trouble to fall asleep after mild stress. In contrary, mice lacking serotonin receptor 5-HT1A (inhibitory receptor, also MRN autoreceptor) have 400% more REM sleep. The orexin, histamine and noradrenaline neurons have highest firing rate in wakefulness (Aston-Jones and Bloom, 1981). Extracellular electrophysiological recordings in freely moving cats have shown that DRN serotonergic neurons fire tonically during wakefulness, decrease their activity during slow wave sleep (SWS), and are nearly quiescent during REM (McGinty and Harper, 1976; Trulson and Jacobs, 1979). In contrary, the acetylcholine levels in the rat thalamus (innervated by mesopontine cholinergic neurons) are intermediate in SWS but high in both REM and wake-state (Williams et al., 1994). In addition the acetylcholine release during active waking is increased by approximately 75% compared to quiet waking (Marrosu et al., 1995). Interestingly the tonic dopamine firing seems to be present in all sleep-wake cycles, and burst firing was found in both wake and REM sleep (Dahan et al., 2007).  Raphe system lesion in cats caused permanent insomnia and diminution of cerebral serotonin (Jouvet et al., 1967) and MRN lesions produced uninterrupted theta (Maru et al., 1979; Yamamoto et al., 1979). Serotonergic firing is inversely correlated with the occurrence of ponto-geniculo-occipital PGO-waves (Lydic et al., 1983) that are typical for REM sleep. Inhibition of serotonin synthesis in cats induced PGO- waves also in waking state (Jacobs et al., 1972). Injection of serotonin precursor induced SWS and suppressed REM sleep for 5-6 hours (Bogdanski et al., 1958; Monnier and Tissor, 1958; Costa et al, 1960; Delorme, 1966). So these SWS-promoting effects of serotonin are not caused by the wakefulness linked DRN and its cortical, striatal and amygdalar projections involved in choice behavior and well- being, but by the MRN that has the needed subcortical afferents and efferents to interact with the other SWS-promoting regions, and to suppress the theta, wakefulness and REM sleep promoting regions. Main MRN efferents target midline forebrain including supramamillary nucleus (SUM), medial mamillary body (MMB), medial septum and vertical diagonal band of Broca (MS/vDBB), posterior hypothalamus (PH), lateral habenula (LHb), perifornical hypothalamus (PeF), midline and intralaminar thalamus, zona incerta (ZI) and hippocampus\n\n(Vertes and Linley, 2008). Main MRN and DRN afferents are from lateral and medial preoptic area (LPO, MPO), LHb, lateral hypothalamus (LH) and PeF (both produce orexin), dorsomedial nuclei of hypothalamus (DMN), midbrain nuclei, locus coeruleus (LC), caudal raphe nuclei, laterodorsal thalamus (LDT) and periacqueductal grey (PAG). Additional MRN afferents are from IPN and MB, while the DRN afferents are from amygdala, bed nucleus of stria terminalis (BNST), lateral septum (LS), substantia nigra, DBB and tuberomamillary nucleus (TMN). Serotonin hyperpolarizes cholinergic burst neurons in the rat LDT in vitro (Luebke et al., 1992), so opposes/suppresses the theta circuit, wake and REM sleep states that require this acetylcholine signal. Serotonergic MRN projections inhibit also theta bursting of MS/vDBB, the source of hippocampal theta rhythm (Kinney et al., 1996). This was found by recordings in mice MS/DBB and hippocampus after inhibition of MRN by 5-HT1A agonist on its autoreceptors. This is a functional evidence for known antagonism between the SWS- provoking MRN and the theta-generating MS/vDBB region.  Cholinergic agonists promote theta rhythm and PGO waves in rats and cats, but serotonergic neurons inhibit theta rhythm and PGO waves. The reciprocal interaction model of sleep control (Hobson and McCarley 1975; McCarley and Hobson 1975) proposed that REM-on neurons increase their firing just prior and during REM, while REM-off neurons show reverse pattern. The cholinergic REM-on neurons were located in LDT and PPT. The norepinephrine and serotonin REM-off neurons (from locus coeruleus and raphe nucleus) were found to be inhibited during REM sleep, and to inhibit REM-on (cholinergic) neurons in LDT/PPT during waking and SWS. Many studies support this mutual inhibition between the REM sleep and SWS circuits. For example reversible inactivation of LC and DRN by cooling decreased REM sleep (Cespuglio et al, 1982). In cats were REM-on LDT/PPT neurons inhibited by serotonin agonist, while WAKE-on/REM-on neurons were unaffected (Thakkar et al., 1998). Role of acetylcholine in promoting REM sleep in animals was found in early studies (George et al., 1964; Hernandez-peon et al., 1964). Multiple studies in humans showed that enhancement of cholinergic tone decreases REM sleep latency and increases its amount (Berkowitz et al. 1990; Hohagen et al., 1993; Lauriello et al, 1993; Riemann et al., 1994; Sitaram and Gillin, 1980; Sitaram et al., 1976).  Based on combination of functional findings and anatomical connectivity of the medial habenula (MHb), interpeduncular nucleus (IPN) and serotonergic MRN in the literature, this new hypothesis shows how the MHb   ÔÉ†   IPN   ÔÉ†   MRN circuit (linked to the low acetylcholine and high serotonin state) promotes slow wave sleep. This idea proposes antagonism (reciprocal inhibition) between this SWS-promoting circuit and the theta- promoting circuit formed by SUM and MS/vDBB. The strength of theta oscillations increases during both active wake and REM sleep. Theta rhythm is linked to high acetylcholine release in brainstem and thalamus. This model predicts also a functional opposition between the MHb  ÔÉ†   IPN   ÔÉ†   MRN circuit and some regions that stimulate the theta-promoting circuit: nucleus incertus (NI), PH, LH, LDT and ventral tegmental nucleus of Gudden (VTg). Both MRN and LPO are known to promote SWS. As the IPN projects to LPO, it might also potentiate the LPO effects.  After first describing the function and connectivity of proposed MHb-IPN-MRN circuit, the following sections will try to show its interesting known and predicted interactions with several regions involved in control of wakefulness, sleep, in theta oscillations, or contextual memory formation and recall.  The medial habenula pathway.\n\nThis study extends the prevailing models of sleep and wakefulness control in the brain, by adding the MHb and IPN regions to the known systems and circuits. It will provide wider context, circuit based and functional evidence for the idea that posterior septum (PS) activates MHb, which activates IPN, which stimulates serotonergic MRN to promote SWS and to inhibit the theta-, wakefulness and REM sleep promoting regions (Vadovi ƒç ova, 2014). This idea came from my DTI probabilistic tractography study in humans, which showed disynaptic axonal tracts that connected hippocampus and amygdala (via dorsal thalamus and via fornix) to septum and anterior BNST, which both projected to MHb. The observed axonal tracts from hippocampus and amygdala passed tightly by both septum and aBNST, then turned posteriorly by anteromedial thalamus (AM), and reached to MHb via stria medialis, then projected from MHb to the pineal gland. This pathway resembled the MHb afferents known from tracing studies in rat. The observed tract branched around septum and BNST to reach also hypothalamus, and via the amygdalofugal pathway passing by/through substantia innominata (SI) it was linked also with dorsal central amygdala (CeA) and hippocampus. Also the vACC showed axonal links to (or from) septum and BNST, so the well-being signal from vACC might control strength of septal and BNST output. Now we need to look into anatomy and physiology data to see what these diverse septo-habenular projections could do, to guess their possible functions and roles. Anatomical studies show input to MHb from posterior septum and BNST, and main output from MHb to IPN, which then projects to MRN. So it is possible that these projections have stimulating effects that lead to serotonin release from MRN.  Medial habenula, MHb. Its connectivity and proposed role.  The main MHb input comes from supracommissural septum (Herkenham and Nauta, 1977). Triangular septum (TS) with input from hippocampal dentate gyrus; and septofimbrial nucleus (SF) with input from fimbria of hippocampus form posterior septum (PS) and project to MHb (Raisman, 1966). The MHb receives input from the glutamatergic and ATPergic triangular septum, from cholinergic septofimbral nuclei, from GABAergic medial septum and vertical DBB (MS/vDBB), from serotonergic raphe, noradrenergic locus coeruleus neurons and sympathetic superior cervical ganglion, from substance P-ergic anterior medial part of BNST (amBNST or BAC, bed nucleus of anterior commissure), and from dopaminergic ventral tegmental area,VTA (Herkenham and Nauta, 1977; Gottesfeld, 1983; Qin and Luo, 2009; Yamaguchi et al., 2013). MHb has also afferents from LDT, and reciprocal connections with MS/vDBB (Woolf, 1991), which my model suggest to have all inhibitory effects. Model further proposes that triangular and septofimbrial septal nuclei stimulate MHb, while the MS/vDBB, and noradrenergic LC and sympathetic system neurons attenuate the output of MHb. The theta-generating MS/DBB likely inhibits MHb because MHb via IPN stimulates serotonergic MRN that promotes SWS and suppresses few regions of theta- promoting circuit: SUM, MS/vDBB and LDT. Similarly the stress (and light) evoked noradrenaline (NA) input suppresses MHb pathway to interrupt or postpone induction of SWS in the unsafe circumstances. In addition the substance P likely activates MHb when the circumstances are safe enough to afford sleep (without imminent threat to survival). This might be supported by the TS and aBNST/BAC connectivity that forms two parallel pathways: dentate gyrus   ÔÉ†   TS  ÔÉ†   ventral MHb   ÔÉ†   IPN core, and the medial amygdala (MeA)   ÔÉ†   BAC   ÔÉ†   dorsal MHb   ÔÉ†  lateral IPN (Yamaguchi et al., 2013) and by the increased fear and arousal after BAC lesions. In addition the BAC input comes from the anxiety decreasing medial amygdala (MeA). In my opinion the amBNST/BAC projections might also attenuate SUM, LC, VTA, SI, paraventricular thalamus (PVT), periacqueductal grey (PAG), CeA, and stimulate besides the MHb also the LPO.\n\nMedial habenula projects to and activates pineal population of silent cells (Axelrod, 1970; Ronnekleiv and Moller, 1979, Ronnekleiv et al., 1980) known to produce melatonin in the dark period. Light stimulation on retina inhibits melatonin synthesis by activating suprachiasmatic nucleus (SCN), which then activates paraventricular hypothalamic nucleus (PVN, known for hormonal reaction to stress) that stimulates sympathetic system in superior cervical ganglia that inhibits pineal gland and MHb by norepinephrine release (Teclemariam- Mesbah et al. 1999). Some PVN fibres innervate pineal gland directly (Reuss and Moller, 1986). Norepinephrine (NE) released from sympathetic terminals at pineal gland attenuates nicotinic cholinergic input from parasympathetic system and MHb (Yoon et al., 2014). Parasympathetic autonomic system is linked to slowing down heart beat and respiration, to rest and digestion.  The superior MHb is glutamatergic and also expresses Interleukin-18 (IL-18); the dorsal MHb is both glutamatergic and substance P-ergic. Both the superior and dorsal MHb have hight density of mu-opioid receptor; while the inferior parts of MHb are both cholinergic and glutamatergic (Sugama et al, 2002; Aizawa et al., 2012). MHb sends topographically organized glutamate, substance P and acetylcholine output to IPN (Qin and Luo, 2009; Ren et al., 2011; Herkenham and Nauta, 1979). So it is interesting that MHb that belongs to the SWS- and serotonin- promoting system produces also acetylcholine (the main neuromodulator of the opposing theta- promoting circuit). Substance P from the MHb was found released in lateral habenula (Kim and Chang, 2005; Antolin-Fontes et al., 2015) and VTA (Claudio Cuello et al., 1978). My prediction is that MHb attenuates both LHb and VTA output to enable SWS. The MHb projects to IPN via the internal part of fasciculus retroflexus and via IPN it controls MRN, LPO and LDT (Herkenham and Nauta, 1979; Groenewegen et al., 1986). So the IPN likely stimulates MRN and LPO, and inhibits LDT.  Based on its anatomical connectivity and interactions with neuromodulators, this model proposes that MHb stimulates SWS via the MHb   ÔÉ†   IPN   ÔÉ†   MRN pathway that also suppresses the theta, wakefulness, alertness and REM driving regions. This is supported by dense mu opioid receptors (that bind morphine, the sleep inducing substance) in MHb, and by circadian rhythmicity of MHb neurons (McCormick and Prince, 1987; Quick et al., 1999; Guilding and Piggins, 2007). By the markedly increased MHb and IPN metabolic activity during anesthesia (pentobarbital, ether and chloral hydrate) in rats (Herkenham, 1981), and also by the fact that the MHb neurons produce sleep promoting interleukin IL-18 (Sugama et al., 2002) and might control via IPN the MRN serotonin. Further evidence comes from high firing rates of MRN cells during SWS and during non-exploratory waking states in rats (when not recording new information by hippocampus), and their low firing rates during the theta linked exploration and REM sleep (Jacobs and Azmitia, 1992; Marrosu et al., 1996). Firing of serotonergic DRN neurons is high in wakefulness, lower in SWS and minimal in REM sleep (Saper et al., 2001). The cholinergic activity in LDT/PPT as well as the acetylcholine levels in cortex and hippocampus are high in wakefulness and REM sleep (Sakai, 1980; Marrosu et al., 1995). Discharge rate of noradrenergic LC neurons is highest during active waking, significantly lower during quiet waking, and ceased during SWS and REM sleep (Takahashi et al., 2010). Another studies found lower LC firing during SWS in rats than during wakefulness (Aston-Jones and Bloom, 1981). The lack or low NE in SWS fits its alarm/alert inducing function. Histamine neurons of tuberomamillary nucleus (TMN) in posterior hypothalamus (PH) are active only in wakefulness, highest at high vigilance, low at quiet waking and silent during SWS and REM (Takahashi et al., 2006).  Wake, SWS and REM circuits (ON and OFF regions).\n\nThe LPO or ventrolateral preoptic area (VLPO) induces SWS by inhibiting cholinergic LDT/PPT and nucleus basalis of Meynert NBM (source of cortical stimulation and gamma coupling, inhibited by adenosine), noradrenergic LC, histaminergic TMN (and PH), orexinergic LH and serotonergic DRN, so by inhibiting the wake-promoting monoaminergic arousal system (Strecker et al., 2000). Reciprocally the TMN, LC, orexinergic LH and GABAergic NBM inhibit VLPO, either directly or via interneurons (Steininger et al., 2001). LDT/PPT and orexinergic LH stimulate cholinergic and parvalbumin containing NBM neurons that induce fast gamma coupling in cortex (Kim et al., 2015). Orexin stabilizes wakefulness by exciting cortex, TMN, LC, DRN, VTA and LDT/PPT (Kilduff and Peyron, 2000; Saper et al., 2001, Bernard et al., 2002).  In addition the serotonergic and noradrenergic (REM-off) regions are suppressed by REM- promoting PnO, SubCoeruleaus (SubC) or medullar dorsal paragigantocerullar nuclei (DPGi), directly or via nearby GABAergic REM-on neurons (Gervasoni et al, 1998; Gervasoni, 2000). Reciprocally, the LC and DRN inactivation increased REM sleep (Cespuglio et al., 1982). Norepinephrine inhibited mesopontine cholinergic (probably REM- on) neurons (Williams and Reiner, 1993), while serotonin injection into SubCoeruleus in rats suppressed PGO waves in pons without affecting thalamic or cortical PGO (Datta et al., 2003). REM-on LDT/PPT neurons were inhibited by 5-HT 1A agonist in cats while the wake-on/REM-on neurons of LDT/PPT were not (Thakkar et al., 1998). Also the LPO that induces SWS is inhibited by REM-on nuclei that stimulate GABA (REM-on) neurons nearby LPO. Both the SWS-on, deep mesencephalic reticular nucleus (also named LPT) and the wake-on, vlPAG nucleus (that stimulates locomotion and motor neurons) do inhibit REM-on regions SubC and PnO/RPO. The PnO is known to be stimulated by REM-on neurons of PPT/LDT.  So my model predicts reciprocally inhibitory interactions between the SWS- promoting MHb  ÔÉ†   IPN   ÔÉ†   MRN circuit and the theta-promoting circuit SUM   ÔÉ†   MS/vDBB   ÔÉ†   hippocampus. It also proposes the opposition (reciprocal inhibition) between this MHb pathway activation and the activity of regions that stimulate the theta-generating circuit: NI, VTg, LDT and PH; as well as those regions that stimulate wakefulness: histaminergic TMN, orexinergic LH, gamma coupling inducing NBM, value-signaling/action-urging VTA, and alert/alarm linked LC. So there is also functional opposition (mutual inhibition) between the SWS- promoting circuit (MHb-IPN-MRN and LPO) versus the wakefulness promoting orexin, histamine, norepinephrine and the locomotion triggering and value-signaling dopamine system. SWS- promoting circuit might show similar opposition with regions of the REM-promoting circuits, REM-on LDT/PPT, PnO, PnC or SubC.  Brain regions with theta rhythm. The theta oscillations in hippocampus occur during awake exploration and during REM sleep (Vanderwolf, 1969). They are generated by supramamillary nuclei (SUM) that determine theta frequency and activate medial septum and vertical limb of diagonal band of Broca (MS/vDBB) that determine theta amplitude and induce theta oscillations in hippocampus and other target regions that show theta-rhythm (Pan and McNaughton, 2004). The SUM is activated by nucleus pontis oralis PnO/RPO in anesthetized rats during REM (Vertes and Martin, 1988; Vertes and Kocsis, 1997; Oddie et al., 1994), possibly also by LDT. During waking state is SUM activated for example by posterior hypothalamus (PH), orexinergic LH, dopaminergic (VTA) and nucleus incertus (NI) input, while the NI induces theta rhythm in\n\nMS by release of insulin-like peptide relaxin-3 (Ma et al., 2009). Another way to induce theta coupling in the brain might be via reciprocal connections between prefrontal cortex and SUM. Both SUM and MS project to hippocampus and medial mamillary body (MMB). The MMB and SUM have reciprocal connections with the ventral tegmental nucleus of Gudden (VTg) that (similar to SUM, MMB and MS) shows theta oscillations and similar to NBM and hDBB contains neurons with parvalbumin. Parvalbumine GABAergic cells from hDBB and NBM generate fast gamma synchronization in cortex (so possibly also in VTg). Medial part of MMB projects to the anteromedial nuclei (AM), while its lateral part projects to the anteroventral (AV) nuclei of ATN. Both AV and AM show theta rhythm. Prefrontal cortex projects to AV (top down control) but is reciprocally connected with AM, so AM might contextually bias the source of information in prefrontal cortex working memory depending on event-based context and memories and associations linked to it. Prefrontal cortex involved in goal-directed control of behavior, evaluation, predictions, decision making and planning projects also to MMB. Hippocampal efferents from subiculum project via fornix to septum (via fornix but my DTI results showed also dorsomedial thalamic tract), anterior thalamic nuclei and mamillary bodies (Aggleton et al., 2005). Further regions that demonstrate theta rhythm are subicular, retrosplenial, entorhinal, perirhinal, posterior cingulate cortex (PCC), ACC and medial prefrontal cortices that receive afferents from MS/DBB, anteromedial and anteroventral nuclei of ATN. Based on its connectivity, my prediction is that AM has role in automatic context- based selection of information from episodic and relational memories that will reach prefrontal cortex and working memory based on their associations with ongoing events. Prefrontal cortex input to AM and AV might on the other hand help to select recall of those episodic memories, events, scenarios, cognitive schemes and task rules that are relevant to current context, goals, task set, situation, and thoughts in working memory.  Interestingly both the theta inducing MS/vDBB and the gamma inducing hDBB have reciprocal connections (Woolf, 1991) with the IPN, MHb, LHb, hippocampus, amygdala, subiculum, entorhinal cortex, piriform cortex, retrosplenial cortex, cingulate cortex (perhaps both PCC and ACC), insula (codes aversive properties of things and subjects, pain and taste), and temporal pole (codes identities of objects and subjects). Thus, this model predicts reciprocal inhibition of the MS/vDBB and hDBB by MHb and IPN, as well as the inhibition of MS/vDBB and hDBB by LHb (to decrease theta and gamma rhythm linked to recording of new information and arousal). These cortical regions and amygdala might reciprocally induce the MS/vDBB and hDBB firing and be driven by them into theta and gamma coupling. The theta coupling in cortex might also be induced by SUM. Other afferents of MS/DBB are from PPT/LDT, LC, VTA, orexinergic LH, DRN and MRN (Woolf, 1991).  Supramamillary nucleus, SUM and some of its interactions.  SUM controls the frequency of hippocampal theta activity via MS/DBB, while MS/vDBB controls its amplitude (Pan and McNaughton, 2004). SUM is known to stimulate theta rhythm during exploration in rats (Vertes and Kocsis, 1997) that gets disrupted by serotonergic MRN. SUM in rats has reciprocal connection with MMB, VTg, PH, LH, AH, LDT, MS/DBB, lateral septum (LS), PAG, LPO, medial preoptic hypothalamic nucleus (MPO, involved in regulation of body temperature), MRN, DRN, VTA (VTA encodes expected reward value signal and novelty), cognitive anterior cingulate cortex (homologue of human cognitive PFC), medial and ventrolateral orbital cortex (processing of rewards and punishments). SUM afferents come also from IPN, lateral habenula (LHb), (Kiss et al., 2002), VMH, BNST, subiculum and nucleus prepositus. SUM efferents project also to\n\nanteromedial and anteroventral thalamic nuclei (AM, AV), reuniens nuclei, intralaminar thalamic nuclei, centromedian thalamic nuclei (CM), mediodorsal thalamus (MDT, involved in value-based selection of choices that are further encoded in prefrontal working memory), substantia innominata (SI, which includes primate NBM homologue), hippocampus, dentate gyrus (receives strong input), entorhinal cortex (EC), frontal cortex, subthalamic nucleus (STN), amygdala, LC and cerebellar nuclei (CN), (Vertes, 1988, 1992; Hayakawa et al., 1993; Shibata, 1987; Risold and Swanson, 1997; Swanson, 1982; Thinschmidt, 1993; Kiss et al., 2002, Contestabile and Flumerfelt, 1981). So this model predicts stimulating input to SUM from wakefulness promoting regions of PH, LH, LDT (from wake-on/REM-on LDT cells), from VTA (with dopamine that signals value), from PAG, and prefrontal cortex (that informs SUM about meanings of things and events around us). Model proposes inhibitory input from LHb, and from SWS- promoting IPN, MRN and LPO to SUM. Similarly, this model suggests stimulatory effects of SUM on VTg, AM, AV, CM, MDT, SI, amygdala, entorhinal and prefrontal cortex function, and predicts inhibitory effect of SUM efferents on MRN output.  Ventral tegmental nucleus of Gudden, VTg and its connectivity.  VTg has reciprocal projections with MMB. VTg has input from prefrontal, cingulate, insular and retrosplenial cortex, MRN, IPN and LHb, maybe even from NBM, PH, LH and LPO as VTg receives input from basal forebrain and hypothalamus (Irle et al., 1984). Both VTg and SUM receive LHb, IPN and MRN projections, so this model predicts that they have inhibitory effect on both these regions that demonstrate theta oscillations. Because the VTg is needed for alternate choice working memory and during mental navigation tasks, but not during SWS sleep. In addition the VTg has possibly stimulating input from dorsal tegmental nucleus of Gudden (DTg), vestibular nucleus (head movement signals), substantia nigra pars compacta (SNc, that signals informational value to brain, what is meaningful, relevant, what way of doing things is right), VTA (signals expected reward value), LC (alarm signal), PAG (fear response) and from dopaminergic cells in zona incerta (ZI, linked to locomotion). VTg has input also from fields of Forel, nucleus of Darkschewitsch (reflex gaze), interstitial nucleus of Cajal (integration of head and eye movements) and nucleus prepositus hypoglossi. Many VTg neurons projecting to MMB are parvalbumin positive, so capable to transfer fast gamma oscillations important for WM and focused attention.  Nucleus incertus, NI and its interaction with SWS-circuit.  The NI is known to induce theta rhythm and to increase spatial working memory performance (and theta-power in hippocampus), by releasing peptide relaxin-3 into MS/DBB (Ma et al, 2009). Even in the anaesthetised rats did the relaxin-3 antagonist in medial septum decreased the PnO-induced hippocampal theta power (Ma et al, 2009). The NI in rats has reciprocal connections with cortical affective evaluation regions: prelimbic cortex (homologue of dorsal anterior cingulated cortex, dACC in primates), medial and ventrolateral orbital cortex; with cognitive anterior cingulate cortex (cognitive PFC homologue); with retrosplenial cortex important for autobiographic memory; with subcortical MRN, IPN (Goto et al., 2001; Aizawa et al., 2012), LPO, ZI, medial LHb, SUM, PH, LH, ventrolateral PAG, MS/vDBB (GABAergic negative feedback) and pontine reticular nucleus. Medial LHb inhibits MRN and projects to intermediate part of the IPN (Wang and Aghajanian, 1977; 2015; Kim, 2009). This model predicts that the cortical input likely stimulates via NI the theta coupling to enhance the recording of episodes with affective and informative meanings to us. Based on the properties of SWS- promoting circuit MHb-IPN-MRN, this model predicts that LHb and the theta- opposing regions IPN and MRN do reciprocally inhibit the\n\noutput of the theta- and arousal inducing NI, and that LHb also inhibits the IPN output to MRN.  The NI in rats and mice has receptors for CRH (corticotropin releasing hormone), orexin, MCH (melanin concentrating hormone, linked to sleep), oxytocin, serotonin 5-HT1A and ghrelin (Bittencourt and Sawchenko, 2000; Greco and Shiromani, 2001; Marcus et al., 2001; Saito et al., 2001; Vaccari et al., 1998; Mani et al, 2014; Miyamoto et al., 2008). So the serotonergic MRN likely inhibits NI during SWS, while the wakefulness linked agents activate NI to enforce arousal, theta coupling and the recording of new events in hippocampus. This model suggests that histaminergic and orexinergic neurons of PH/LH stimulate NI, as both also promote wakefulness, and that LPO inhibits NI, as LPO promotes SWS that opposes theta state and arousal. NI in rats projects also to all hippocampus especially to dorsal fimbria and ventral dentate gyrus, CA3 and subiculum, to entorhinal cortex, claustrum, SI, PPT, LS, triangular and septofimbrial septal nuclei, MHb, MMB, lateral mamillary body (LMB), AV, AM, AD, nucleus reuniens, CM, MDT , DRN, PVT, PVN, dorsomedial thalamic nucleus (DMN), VMN, MPO, supraoptic hypothalamic nucleus (SON), anterior hypothalamus (AH), arcuate nucleus, amygdala, BNST, contralateral NI, nucleus accumbens (NAc, involved in motivation/drive and inhibitory avoidance), ZI, VTA, SNc, and superior colliculus (SC), (Goto et al., 2001; Olucha-Bordonau et al., 2003 and 2012; Teruel-Marti et al., 2008). This model predicts that NI (besides its known effect on medial septum theta rhythm) activates its targets in PFC, RSC, hippocampus, BNST, LS, PAG, PVN, PVT, MDT and CM; but inhibits MHb, IPN, MRN and LPO leading to suppression of SWS.  Triangular and septofimbrial septal nuclei. Some of their interactions.  Triangular septum (TS) projects to MHb, IPN and LHb (Raisman, 1966). Posterior septum (PS) that includes TS and septofimbrial septal nuclei (SF) has GABAergic projections to NI (and NI projects to PS), SUM and MRN. Also medial septum and horizontal DBB (hDBB) have GABAergic projections to nucleus incertus (Sanchez-Perez et al., 2015). By proposing SWS- promoting role of PS, this model suggests that TS inhibits LHb to disinhibit the serootnergic MRN, and that TS and SF inhibit NI and SUM, but activate MRN (by inhibiting MRN interneurons). The NI is known to induce theta by its relaxin-3 release in MS (Ma et al., 2009). Horizontal DBB together with NBM is the main source of the cortical cholinergic innervation and the parvalbumin containing GABAergic projection neurons that induce fast gamma rhythm linked to thinking, attention, working memory and feature binding. So the hDBB might induce cholinergic activation or even gamma oscillations in NI towards informative and salient stimuli to increase temporal coupling (and temporal summation) towards important information.  Median raphe nucleus, MRN and its interactions.  Major MRN input is from IPN, LHb, MS, MB, LPO, MPO, LH, perifornical hypothalamus, DMN, PAG, LDT, LC and infralimbic cortex in rats (homologue of ventral ACC in humans). Medial LHb reciprocally inhibits serotonergic MRN (Wang and Aghajanian, 1977). MRN projects to medial mammillary body (MMB), SUM, PH, perifornical hypothalamus (PF/LH), cholinergic MS/vDBB, hDBB, NBM, septum, VTA, dopaminergic A13 region of ZI, LC, LDT/PPT, subcoeruleus, LHb, IPN, MPO, nucleus reuniens, mediodorsal thalamus (MDT),\n\ncentral medial, paracentral and central lateral nuclei of midline intralaminar thalamus, suprachiasmatic nucleus (SCN), hippocampus and NAc (Vertes and Martin, 1998, Vertes and Linley, 2008). Cortical projections from MRN are light and restricted to perirhinal, entorhinal and some prefrontal cortex. MRN stimulation enhances the secretion of gonadotropins (James et al., 1987). Glutamate input to MRN was increased during non-theta phase of anesthesia in rats but not after tail pinch (Varga et al., 1998). This evidence supports the proposed activation of MRN by MHb during SWS, as MHb is also stimulated by anesthetics, possibly disinhibited by morphine, and has indirect input to MRN via IPN. So this model predicted that MHb stimulates IPN, which stimulates MRN to release serotonin during SWS. Both LPO and MRN promote SWS and suppress some regions of cholinergic theta- promoting circuit. So this model proposes that LPO and possibly vACC activate MRN, while the MS/vDBB, MMB, LDT, orexinergic LH, noradrenergic LC, and fear response related PAG inhibit MRN. Similarly to the known MRN inhibition of SUM, this model suggests that MRN attenuates also the following theta- , working memory or arousal linked regions: MMB, MS/vDBB, histaminergic PH, orexinergic LH, VTA, A13 of ZI, intralaminar and midline thalamic nuclei. Hippocampal theta induced by SUM and MS activation was produced after MRN inhibition by glutamatergic antagonists, GABA agonist and serotonin 1A agonist (acting via MRN autoreceptor) in urethane anesthetized rats (Kinney et al., 1994; Kinney et al., 1995; Vertes et al, 1994, Kinney et al., 1996).  Interpeduncular nucleus, IPN  Main IPN input comes from MHb, less from medial LHb, MPO, ventral hypothalamus, MRN, DRN, dorsal and ventral tegmental nuclei of Gudden (DTg, VTg), LDT, PAG, SUM, premamillary nuclei, LC, sparse input comes from hDBB (Contestabile and Flumerfelt, 1981; Vertes and Fass, 1988), and some from VTA neurons that contain dopamine and corticotropin releasing factor (CRF), (Zhao-Shea et al., 2013). The IPN neurons are mostly GABAergic and project to MRN, DRN, LPO, MPO, LDT, DTg and VTg (strongly), medial mamillary body (MMB, weakly), NI, nucleus basalis of Meynert (BNM), LC, PAG, MS/DBB, LH, hypothalamus, entorhinal cortex (EC), hippocampus, MDT, nucleus gelatinosus, and midline thalamic nuclei (Groenewegen et al., 1986; Goto et al., 200; Vertes and Fass, 1988). LDT has reciprocal connections with IPN, but also with MRN and LPO. So it is possible that IPN, MRN and LPO attenuate LDT output, to promote SWS, and vice versa that LDT suppresses IPN, MRN and LPO.  As gabaergic parvalbumine containing NBM projection neurons induce cortical gamma (40- 100 Hz) oscillations and wakefulness (Brown and McKenna, 2015) and project to VTg, while the VTg shows theta oscillations, also contains fast firing parvalbumin GABA neurons (projecting to MMb), and is needed in alternation task working memory (Dillingham et al., 2015), this model suggests an inhibitory effect of IPN on NBM and VTg. It proposes that IPN stimulates the SWS-promoting LPO and MRN serotonin release; but attenuates the output of theta and arousal promoting regions: VTg, DTg, MMB, NI, LDT, NBM, LC and fight-or- flight response of PAG. In addition the model predicts that medial LHb that inhibits MRN possibly inhibits also IPN (by targeting IPN interneurons) and itself is inhibited by MHb. The IPN interneurons might be targeted also by dopamine and CRH release from VTA to interrupt sleep. Similarly, the IPN is probably inhibited by DTg, VTg, LDT, PAG, hDBB, SUM, premamillary nuclei and LC.\n\nLateral preoptic area, LPO and some interactions predicted by model.  GABAergic neurons in the VLPO promote sleep by inhibiting arousal-promoting circuits, such as TMN, NBM, LC and DRN (Saper et al., 1997; Saper et al., 2001; Luppi et al., 1999; Lydic and Baghdoyan, 2005). LPO was found to promote SWS. LPO projects also to SUM, LDT and PPT, and based on their properties this model proposes that LPO inhibits them. This inhibition might be reciprocal. It was found that MRN serotonin inhibits LTD, PPT and SUM. Both LPO and LH project to LHb, RMTg and VTA.  So this model predicts stimulatory effect of LPO on rostromedial tegmental nucleus (RMTg), and inhibitory effect of LPO on LHb and VTA, to disinhibit the MRN serotonin release during SWS (suppressed by medial LHb, i.e. in deppression) but to inhibit the dopamine groups (SNc/A9, VTA/A10 and A11) that do facilitate locomotion, value-based learning, drive (go-for-it) and activate spinal motor neurons (A11). This claim is supported by robust locomotor activation after infusion of the GABAA agonist muscimol into the RMTg (Lavezzi et al., 2024). The orexinergic LH projections on the other hand likely stimulate VTA and inhibit LHb and RMTg. Another supporting fact is that the LDT is essential for burst firing of VTA dopamine neurons (Lodge DJ, Grace AA, 2006). Stimulation of (wake-on ?) PPT or LDT excites dopaminergic neurons of VTA and SNc (Lacey et al. 1990) and is needed for maintenance of burst firing of dopamine neurons (Lodge and Grace, 2006). The RMTg is known for reciprocal connections with LDT, PPT, pontine and medullary reticular formation, and for strongly suppressing effect on VTA, SNc and DRN (Perroti et al., 2005; Jhou et al., 2009 a, b; Kaufling et al., 2009; Balcita-Pedicino et al., 2011). This model proposes that RMTg mutually supresses LDT and PPT to decrease arousal and locomotion (e.g. after injuries, in sickness, in depression). So the LPO uses the LHb and RMTg as ''switch off- switch on'' buttons to enable SWS, by boosting the serotonergic MRN system and by suppressing the dopaminergic SNc and VTA system. Actually the LPO might activate just that part of RMTg (lateral ?) that suppresses SNc and VTA, because the serotonergic DRN firing is reduced during SWS but ceased only during REM sleep. Interestingly respiratory rate is higher in REM sleep compared with both non-REM sleep and wakefulness, in line with the inhibition/cessation of serotonergic firing at MRN and DRN, and with calming serotonergic effect on respiration.  Similarly to the LPO, also the SWS-on deep mesencephalic nuclei might suppress dopamine system. That population of BNST neurons, which promotes reactivity to threat, activates VTA and inhibits LPO, most probably inhibits also the LHb and RMTg to disinhibit motor reactivity. Also the MS/DBB has input to LHb, RMTg and VTA, possibly to induce there the theta coupling. This model predicts inhibitory effect of LPO projections to SUM, to suppress theta oscillations during SWS. The main inhibitory input to LPO comes from GABAergic neurons of NBM, lateral septum and BNST (Zahm et al., 1999, 2013; Zahm, 2006). Their role in fast gamma coupling, panic and anxiety response supports the LPO role in SWS. Threat suppresses SWS by inhibiting LPO, what leads to lower RMTg activity: causing rise in dopamine firing, agitation and impulsive response. Interestingly cholinergic projections from the mesopontine tegmentum inhibit the RMTg at muscarinic M4 receptors, while exciting VTA dopamine neurons at M5 receptors (Wasserman et al. 2013, 2014). So this acetylcholine might come from wake promoting LDT to disinhibit dopamine system, to fuel motion, motivated behaviour, drive, reward and value/meaning based learning in wakefulness and awareness. The LPO projects also to reticular thalamic nucleus involved in up and down states during SWS, and to hippocampus, cortex and parabrachial nucleus (PB, part of pain pathway), possibly to promote SWS sleep.\n\nLateral habenula, LHb and its proposed role in theta control and REM sleep  LHb directly and via RMTG activation strongly suppresses (for few milliseconds) dopamine and serotonin release (Christoph et al., 1986; Wang and Aghajanian, 1977; Park, 1987; Ji and Shepard, 2007; Matsumoto and Hikosaka, 2007). Looking at the lateral habenula connectivity and function my conclusion is that LHb might be used as a ''switch-off'' button to suppress serotonin (MRN and DRN) and to lower dopamine (SNc, VTA) firing during REM. Although serotonin, noreinephrine and histamine neurons cease firing during REM sleep, dopamine neurons show bursting activity in both wakefulness and REM sleep.  Main LHb input is from GPi, LH, VTA, DRN, MRN, LPO (reciprocal), MS/vDBB, SI, NBM, PH, PAG and BNST (Herkenham and Nauta, 1977; Sutherland, 1982). LHb projects to SUM (Kiss et al., 2002), and medial LHb innervates intermediate IPN (Kim, 2009). LHb inhibits dopaminergic VTA/SNc and serotonergic DRN/MRN, and stimulates GABAergic RMTg that directly inhibits DRN, VTA and SNc (Perroti et al., 2005; Jhou et al., 2009 a, b; Kaufling et al., 2009). LHb projects also to LC, TMN, PH, LH, LDT, PPT, NBM, SI, MS/DBB, SUM, LPO, ZI, PVT, MDT (involved in value-based choice selection), raphe pontis nucleus, contralateral LHb and to REM-promoting PnO (Herkenham and Nauta, 1979; Araki et al., 1988). So my prediction is that LHb suppresses the SWS-promoting LPO and IPN. Lateral habenula inhibition of MRN is already well-known. This model proposes that LHb attenuates wake-on cholinergic, GABAergic or glutamatergic neurons in LDT, PPT, NBM, SI, MS/DBB, then noradrenergic LC, histaminergic PH/TMN, and orexinergic LH neurons, glutamatergic SUM. Further prediction is that LHb attenuates also VTg, DTg, ZI, SC, PAG, CM (centromedian thalamic nucleus) and MDT (deselecting choices) to decrease movement and arousal after defeat, after repeatedly bad feedback/outcomes, in chronically hostile environment and during REM sleep. Chronic pain and negative feedback overstimulate LHb, causing learned helplessness, to stop us moving and exerting/losing energy for things that repeatedly hurt and harm us and decrease our well-being or survival.  PPT stimulates STN during REM sleep (Fern√°ndez-Mendoza et al., 2009) enhancing the fast (15 ‚Äì 35 Hz) subthalamic oscillatory activity. STN then activates LHb by stimulating internal globus pallidus (GPi), as GPi has strong glutamatergic input to LHb. So probably the firing of subthalamic neurons activates GPi, which then causes activation of LHb during REM sleep. This REM (and preREM, shortly before REM) sleep stimulation of LHb helps to suppress dopamine and serotonin release during REM, so prevents switching into waking and into SWS state, respectively. Prolonged LHb activation might lead to suppression of SUM and weakened theta oscillations in the brain, as the LHb projects to SUM, and this model predicts that SUM is suppressed by LHb. In addition the SNr inhibits PPT. It is not clear if the LHb inhibits the wake -on PPT/LDT neurons (which stimulate VTA/SNc) or also the REM-on LDT/PPT neurons. LHb might not suppress REM-on LDT/PPT groups (as they are used to trigger the theta-frequency in SUM during REM sleep), but might attenuate wake/REM-on LDT and PPT neurons leading to decrease in arousal and awareness. If would LHb inhibit REM-on LDT/PPT, it might cause gradual suppression of REM state and support the switching/alternations between the REM sleep and SWS.  The PPT/LDT is known to activate SubC and medullary reticular nuclei that inhibit motor neurons during REM sleep, causing muscle atonia. Overstimulation of LHb, by chronic pain, loss, worries, bad outcomes, or by low basal dopamine or serotonin signal in brain (leading to LHb disinhibition) actually prolongs REM sleep and shortens SWS. The reason for this might be that the shortage of brain serotonin signal when feeling down disinhibits LHb what leads to further suppression of serotonin release. The lack of serotonin then disinhibits the REM-on\n\ncircuit and shortens SWS stage. Increased REM sleep duration was found in depression (Steriade and McCarley, 1990). This finding supports my prediction that LHb is one of the effectors activated by REM-on neurons in LDT/PPT, possibly via STN.  Interestingly LHb projects to PnO, so might promote (or control) REM sleep not only by suppression of dopamine and serotonin. Model predicts that wake-on orexinergic LH neurons inhibit LHb and RMTg, thus causing rise in VTA/SNc dopamine and reactivity (i.e. when hungry). The REM-on, melanin concentrating hormone (MCH) neurons of LH might inhibit dopaminergic A11 stimulation of motor neurons, or activate SubC or PnO. Further prediction of this model is that LHb suppresses NBM activity, e.g. in depression and after repeated defeat and loss, what leads to weakened attention, working memory strength via weakened fast gamma based cortical coupling. As tonic, fast oscillatory (20-40 Hz) cortical activity is elicited by NBM stimulation (Metherate et al., 1992).  Reticular nucleus pontis oralis and caudalis. Some of their interactions.  Subcoeruleus, nucleus pontis caudalis (PnC) and oralis (PnO/RPO) receive REM-on LDT/PPT input and promote REM sleep. Both PnC and PnO project to oculomotor/visual system. The PnC projections to STN might enhance the REM linked motor response suppression. Movement suppression in REM is caused by SubC that inhibits spinal motor neurons via reticular medullar nuclei. Wake-on norepinephrine is known to inhibit SubC while the wake-on PPT group inhibits PnC. The theta rhythm inducing PnO projects to SUM, LDT, IPN, lateral mamillary body (LMB), mesencephalic reticular formation (that projects to reticular thalamic, reuniens and subthalamic nucleus), retrorubral nucleus, VTA, SNc, zona incerta (ZI), specific PAG regions and CM (Vertes and Martin, 1998). So question is why the PnO interacts with the LMB during REM sleep? The LMB with its head-direction cells receives DTg and postsubicular hippocampal input, and projects to DTg and anterodorsal thalamic nucleus AD. The AD is reciprocally connected with postsubicular hippocampus and with retrosplenial cortex. The LMB might (besides spatial navigation) support navigation on temporal axes (distant past, less distant past, things ahead..) of memory, what is not a strong feature of dreams. Content of dreams is often evolving in incongruous temporal context, with jumps between scenes. Perhaps a random activation of LMB and reuniens during REM serves to mix up and link distant and fresher events and memories into wider cognitive map.  Conclusions  Theta oscillations are evoked either during active waking state by what is going on around us, so by contextual and stimulus based novelty, salient sensory input, interesting or meaningful stimuli, good/valuable or bad/harmful things. Theta rhythm is induced also by REM-on PnO projections to SUM, or via LDT projections to SUM and MS/DBB. In quiet waking without novelty and during consumatory (repetitive) behaviour there is low need to record new information, so it was linked to replay of previously encoded information, after the theta rhythm enabled recording events, contexts and interrelations between things. Possibly, when the hippocampal dentate gyrus gets full and new information lead to interference, the hippocampus stimulates posterior septum to induce SWS via MHb-pathway, to clean up short term memory storage for new input. The MHb   ÔÉ†   IPN   ÔÉ†   MRN circuit then promotes SWS and antagonizes the theta promoting circuit, wake and REM sleep. Besides the main idea, this\n\nstudy brought new predictions about interactions of some SWS- versus theta- promoting regions with LHb, RMTg, LPO, VTg and NI. And their effects on sleep/wake control.  This model predicted that lateral habenula projections to SUM have inhibiting effects and attenuate theta rhythm. It also proposed that LHb suppresses the wake-promoting substantia innominata/nucleus basalis (SI/NBM), as well as the SWS-promoting LPO. LHb is known to suppress (for miliseconds) dopamine and serotonin release. Consequent decrease in dopamine input then lowers the NBM output (as dopamine stimulates NBM). One of the purposes of dopamine suppression by LHb might be to decrease arousal after chronic defeat and chronic negative feedback, to stop us moving and losing energy for bad choices, to unlearn wrong (no more valid) ideas, and to deselect the suboptimal choices, decisions and prediction from working memory. Because the LHb attenuates NBM via suppressing dopamine in system, and LHb projects to NBM, the LHb might act in similar way on NBM and directly inhibit it.  Further my circuit-based findings suggest that LHb reciprocally inhibits LPO and orexinergic lateral hypothalamus. While LPO possibly activates RMTg. This study also suggested how can LHb promote REM sleep. Via the REM-on PPT neurons stimulation of STN that activates SNr and GPi, which then activate LHb to suppress dopamine and serotonin release during REM. The IPN   ÔÉ†   LPO and LPO   ÔÉ†   MRN connections link together two SWS- promoting systems: proposed MHb   ÔÉ†   IPN   ÔÉ† MRN and LPO. My prediction is that IPN stimulates LPO and LPO stimulates MRN but it has to be tested.  This work seems to be the first circuit based model of the MHb-IPN-MRN circuit function. It extended the known system for control of wakefulness and sleep, by adding the role of MHb and IPN to the known serotonergic MRN system. The MHb increases its activity during anesthesia, and anesthesia is similar to SWS stage. This model combined connectivity references (on regions involved in sleep-wake control and on MHb) and the available (partial) functional findings from the literature. It predicted how do MHb and IPN promote slow wave sleep: by stimulating serotonergic MRN, as well as by inhibiting the opposing theta-promoting circuit, wakefulness and REM sleep regions. It showed few new interactions of theta-promoting regions, known to enable recording of new information in hippocampus in active wake linked to theta state. SWS is known for replay of relationally and spatio- temporally bound informattion in hippocampus. So because the SWS and REM states are involved in different functions, it has sense that there is opposition/inhibitory effect between MHb-IPN-MRN and the theta- promoting circuit. Different neural regions, neuromodulators and states are needed in recording than in replay. Because of proposed circuit based opposition between SWS - promoting and theta- promoting regions, some new relations and interactions between the less known regions of sleep-wake system could be predicted. For example that LHb inhibits IPN and SUM, or that LPO (SWS promoting region) inhibits LHb and VTA but stimulates RMTg to oppose/suppress REM state.  Abbreviations  DRN dorsal raphe nukleus  DTg dorsal tegmental nucleus of Gudden  GPi globus pallidus pars interna  IPN interpeduncular nukleus  LC locus coeruleaus\n\nLDT lateral dorsal tegmental nukleus  LH lateral hypothalamus  LHb lateral habenula  LPO lateral preoptic nucleus  LS lateral septum  MDT mediodorsal thalamus  MHb medial habenula  MRN median raphe nucleus  MS/DBB medial septum/diagon√°l band of Broca  NBM nukleus basalis of Meynert  NI nucleus incertus  PH posterior hypotalamus  PPT pedunculopontine nucleus  REM rapid eye movement  RMTg rotromedial tegmental nukleus  SI substantia innominata  SNc Substantia nigra compacta  SNr Substantia nigra reticulata  STN subthalamic nukleus  SUM supramamillary nukleus  SWS slow wave sleep  TMN tuberomamillary nucleus  VTA vetral tegmental nucleus  VTg ventral tegmental nucleus of Gudden  REFERENCES  Aizawa H, Kobayashi M, Tanaka S, Fukai T, Okamoto H. Molecular characterization of the subnuclei in rat habenula. J Comp Neurol 2012; 520: 4051066.\n\nAntolin-Fontes B, Ables JL, Gorlich A, Ibanez-Tallon I (2014). The habenulo- interpeduncular pathway in nicotine aversion and withdrawal.   Neuropharmacology   96 (Pt B): 2132.  Araki M, McGeer PL, Kimura H (1988) The efferent projections of the rat lateral habenular nucleus revealed by the PHA-L anterograde tracing method. Brain Res, 44, 31930.  Aston-Jones G, Bloom FE (1981) Activity of norepinephrine-containing locus coeruleus neurons in behaving rats anticipates fluctuations in the sleep-waking cycle. J Neurosci-1:876- 886.  Axelrod J (1970) \"The pineal gland\". Endeavour 29 (108): 144.  Balcita-Pedicino J. J., Omelchenko N., Bell R., Sesack S. R. (2011). The inhibitory influence of the lateral habenula on midbrain dopamine cells: ultrastructural evidence for indirect mediation via the rostromedial mesopontine tegmental nucleus. J. Comp. Neurol. 519, 1143164 10.1002/cne.22561  Berkowitz A, Sutton L, Janowsky DS (1990) Gillin JC. Pilocarpine, an orally active muscarinic cholinergic agonist, induces REM sleep and reduces delta sleep in normal volunteers. Psychiatry Res.33:113 ‚Äì 119.  Bernard R, Lydic R, Baghdoyan HA(2002) Hypocretin-1 activates G proteins in arousal- related brainstem nuclei of rat. Neuroreport 13, 44750  Bittencourt JC, Sawchenko PE (2000) Do centrally administered neuropeptides access cognate receptors? An analysis in the central corticotropin-releasing factor system. J Neurosci, 20 (3),1142156.  Bland BH, Oddie SD (2001) Theta band oscillation and synchrony in the hippocampal formation and associated structures: the case for its role in sensorimotor integration. Behav. Brain Res. 127, 11936.  Blumberg MS, Karlsson KA, Seelke AM, Mohns EJ. The ontogeny of mammalian sleep: a response to Frank and Heller (2003) J Sleep Res. 2005;14:918.  Bogdanski DF, Weissbach H, Udenfriend S (1958)   J. Pharmacol. Exp. Therap. 122, 182.  Brown RE, McKenna JT (2015) Turning a negative into a positive: ascending GABAergic control of cortical activation and arousal. Front. Neurol. 6:135.  Buzsaki G (1989) Two-stage model of memory trace formation: a role for noisy brain states. Neuroscience. 31:55170.  Buzsaki G (2002) Theta oscillations in the hippocampus. Neuron. 33:32540.  Cespuglio R, Gomez ME, Faradji H, Jouvet M (1982) Alterations in the sleep-waking cycle induced by cooling of the locus coeruleus area. Electroencephalogr Clin Neurophysiol. 54:57078.\n\nChristoph GR, Leonzio RJ, Wilcox KS (1986) Stimulation of the lateral habenula inhibits dopamine-containing neurons in the substantia nigra and ventral tegmental area of the rat. J Neurosci 6:613-619.  Claudio Cuello A, Emson PC, Paxinos G, Jessell T (1978). Substance P containing and cholinergic projections from the habenula. Brain Res. 149, 41329 10.1016/0006- 8993(78)90484-5  Contestabile A, Flumerfelt BA (1981) Afferent connections of the interpeduncular nucleus and the topographic organization of the habenulo-interpeduncular pathway: an HRP study in the rat. Comp Neurol, 196:25370.  Costa R, Pscheidt GR, van Meter WG, Himwich HE, J. Pharmacol. Exp. Therap. 130,81 (1960).  Dahan L, Astier B, Vautrelle N, Urbain N, Kocsis B, Chouvet G.Prominent burst firing of dopaminergic neurons in the ventral tegmental area during paradoxical sleep. Neuropsychopharmacology. 2007 Jun;32(6):1232-41.  Datta S, Mavanji V, Patterson EH, Ulloor J. Regulation of rapid eye movement sleep in the freely moving rat: local microinjection of serotonin, norepinephrine, and adenosine into the brain stem. Sleep. 2003;26:51320.  Delorme   F (1966)   thesis, University of Lyons.  Dillingham CM, Holmes JD, Wright NF, Erichsen JT, Aggleton JP, Vann SD. Calcium- binding protein immunoreactivity in Gudden? tegmental nuclei and the hippocampal formation: differential co-localization in neurons projecting to the mammillary bodies.  Frontiers in Neuroanatomy . 2015;9:103.  George R, Haslett WL, Jenden DJ (1964) A cholinergic mechanism in the brainstem reticular formation: induction of paradoxical sleep. Int J Neuropharmacol. 3:541 ‚Äì 552.  Gervasoni D, Darracq L, Fort P, Souliere F, Chouvet G, Luppi PH (1998) Electrophysiological evidence that noradrenergic neurons of the rat locus coeruleus are tonically inhibited by GABA during sleep. Eur J Neurosci 10:96470.  Gervasoni D, Peyron C, Rampon C, Barbagli B, Chouvet G, Urbain N, Fort P, Luppi PH (2000) Role and origin of the GABAergic innervation of dorsal raphe serotonergic neurons. J Neurosci 20:4217225.  Goto M, Swanson LW, Canteras NS (2001) Connections of the nucleus incertus. J Comp Neurol438: 8622.  Gottesfeld Z (1983). Origin and distribution of noradrenergic innervation in the habenula: a neurochemical study. Brain Res. 275, 29904 10.1016/0006-8993(83)90990-3  Greco MA, Shiromani PJ. Hypocretin receptor protein and mRNA expression in the dorsolateral pons of rats. Brain Res Mol Brain Res 2001; 88: 17682.\n\nGroenewegen HJ, Ahlenius S, Haber SN, Kowall NV, Nauta WJ (1986) Cytoarchitecture, fiber connections, and some histochemical aspects of the interpeduncular nucleus in the rat. J. Comp Neurol, 249: 6502.  Guilding C, Piggins HD (2007) Challenging the omnipotence of the suprachiasmatic timekeeper: are circadian oscillators present throughout the mammalian brain? Eur J Neurosci 25:3195216.  Hayakawa T, Ito H, Zyo K (1993) Neuroanatomical study of afferent projections to the supramammillary nucleus of the rat. Anat. Embryol. 188, 13948.  Herkenham M (1981) Anesthetics and the habenulo-interpeduncular system: selective sparing of metabolic activity. Brain Res 210:46166.  Herkenham M, Nauta WJ (1977) Afferent connections of the habenular nuclei in the rat. A horseradish peroxidase study, with a note on the fiber-of-passage problem. J Comp Neurol 173:12345.  Herkenham M, Nauta WJ (1979) Efferent connections of the habenular nuclei in the rat. J Comp Neurol 187:19-47.  Hernandez-peon R, Chavez-Ibarra G, Morgane PJ, Timo-Iaria C (1963). Limbic cholinergic pathways involved in sleep and emotional behaviour. Exp Neurol. 8:93 ‚Äì 111.  Hobson JA, McCarley RW, Wyzinski PW (1975) Sleep cycle oscillation: reciprocal discharge by two brainstem neuronal groups. Science.189:55 ‚Äì 58.  Hohagen F, Riemann D, Spiegel R, Holzhauer M, Berger M (1993) Influence of the cholinergic agonist SDZ 210-086 on sleep in healthy subjects. Neuropsychopharmacology. 9:225 ‚Äì 232.  Irle E, Sarter M, Guldin WO, Markowitsch HJ. Afferents to the ventral tegmental nucleus of Gudden in the mouse, rat, and cat. J Comp Neurol. 1984;228:50941.  Jacobs BL, Azmitia EC (1992) Structure and function of the brain serotonin system Physiol Rev 2:16529.  Jacobs BL, Henriksen SJ, Dement WC. Neurochemical bases of the PGO wave. Brain Res. 1972;48:40611.  James MD, MacKenzie EJ, Tuohy-Jones PA, Wilson CA (1987) Dopaminergic neurones in the zona incerta exert a stimulatory control on gonadotrophin release via D1 dopamine receptors. Neuroendocrinology, 45: 348 355.  Jhou, TC, Geisler, S, Marinelli, M, Degarmo, BA & Zahm, DS (2009) The mesopontine rostromedial tegmental nucleus: A structure targeted by the lateral habenula that projects to the ventral tegmental area of Tsai and substantia nigra compacta. J. Comp. Neurol. 513, 56696.\n\nJhou T, Fields HL, Baxter MG, Saper CB, Holland PC (2009) The Rostromedial Tegmental Nucleus (RMTg), a GABAergic Afferent to Midbrain Dopamine Neurons, Encodes Aversive Stimuli and Inhibits Motor Responses. Neuron, 61:5, 78600.  Ji H, Shepard PD (2007) Lateral Habenula Stimulation Inhibits Rat Midbrain Dopamine Neurons through a GABAA Receptor-Mediated Mechanism. J Neurosci, 27, 6923930.  Jouvet M (1962) Recherches sur les structures nerveuses et les mecanismes responsables des differentes phases du sommeil physiologique. Arch Ital Biol. 100:12506.  Jouvet M, Bobillier P, Pujol JF, Renault J (1967) Permanent insomnia and diminution of cerebral serotonin due to lesion of the raphe system in cats. J Physiol, 59:248.  Kaufling J, Veinante P, Pawlowski SA, Freund-Mercier MJ, Barrot M.(2009) Afferents to the GABAergic tail of the ventral tegmental area in the rat. J Comp Neurol. 513, 597-621.  Kilduff TS, Peyron C (2000) The hypocretin/orexin ligand receptor system: implications for sleep and sleep disorders. Trends Neurosci. 23, 35965 .  Kim U (2009) Topographic commissural and descending projections of the habenula in the rat. J Comp Neurol; 513: 17387.  Kim T, Thankachan S, McKenna JT, McNally JM, Yang C, Choi JH, et al. (2015) Cortically projecting basal forebrain parvalbumin neurons regulate cortical gamma band oscillations. Proc Natl Acad Sci U S A, 112(11):3535-3540.  Kim U, Chang S (2005) Dendritic morphology, local circuitry, and intrinsic electrophysiology of neurons in the rat medial and lateral habenular nuclei of the epithalamus. J Comp Neurol 483: 23650.  Kinney GG, Kocsis B, Vertes RP. Injections of excitatory amino acid antagonists into the median raphe nucleus produce hippocampal theta rhythm in the urethane anesthetized rat. Brain Res. 1994;654:9604.  Kinney GG, Kocsis B, Vertes RP. Injections of muscimol into the median raphe nucleus produce hippocampal theta rhythm in the urethane anesthetized rat. Psychopharmacology. 1995;120:24448.  Kinney GG, Kocsis B, Vertes RP. Medial septal unit firing characteristics following injections of 8-OH-DPAT into the median raphe nucleus. Brain Res. 1996;708:11622.  Kiss J, Csaki A, Bokor H, Kocsis K, Kocsis B (2002) Possible   glutamatergic/aspartatergic projections to the supramammillary nucleus and their origins in the rat studied by selective [(3)H]D-aspartate labelling and immunocytochemistry. Neuroscience 111:67191.  Lauriello J, Kenny WM, Sutton L, Golshan S, Ruiz C, Kelsoe J, Rapaport M, Gillin JC (1993) The cholinergic REM sleep induction test with pilocarpine in mildly depressed patients and normal controls. Biol Psychiatry.33:33 ‚Äì 39.\n\nLavezzi HN, Parsley KP, Zahm DS. 2014. Modulation of locomotor activation by the rostromedial tegmental nucleus. Neuropsychopharmacology 40:67687.  Lodge DJ, Grace AA (2006) The laterodorsal tegmentum is essential for burst firing of ventral tegmental area dopamine neurons. Proc Natl Acad Sci U S A. 2006 Mar 28; 103(13):5167-72.  Luebke JI, Greene RW, Semba K, Kamondi A, McCarley RW, Reiner PB. Serotonin hyperpolarizes cholinergic low-threshold burst neurons in the rat laterodorsal tegmental nucleus in vitro. Proc Natl Acad Sci USA. 1992;89:74347.  Luppi PH, Peyron C, Rampon C, et al. (1999) Inhibitory mechanisms in the dorsal raphe nucleus and locus coeruleus during sleep. In: Lydic R, Baghdoyan HA, eds.   Handbook of behavioral state control: molecular and cellular mechanisms.   Boca Raton, FL: CRC, 195 ‚Äì  211.  Lydic R, Baghdoyan HA (2005) Sleep, anesthesiology, and the neurobiology of arousal state control. Anesthesiology. 2005 Dec; 103(6):1268-95.  Lydic R, McCarley RW, Hobson JA (1983). The time-course of dorsal raphe discharge, PGO waves, and muscle tone averaged across multiple sleep cycles. Brain Res. 1983;274:36570.  Ma S, Olucha-Bordonau FE, Hossain MA, Lin F, Kuei C, Liu C, Wade JD, Sutton SW, Nunez A, Gundlach AL. Modulation of hippocampal theta oscillations and spatial memory by relaxin-3 neurons of the nucleus incertus. Learn Mem 2009; 16: 73042.  Mani BK, Walker AK, Lopez Soto EJ, Raingo J, Lee CE, Perello M, Andrews ZB, Zigman JM. Neuroanatomical characterization of a growth hormone secretagogue receptor-green fluorescent protein reporter mouse. J Comp Neurol 2014; 522: 3644666.  Maru E, Takahashi LK, Iwahara S (1979) Effects of median raphe nucleus lesions on hippocampal EEG in the freely moving rat. Brain Res,163 : 22334.  Marcus JN, Aschkenasi CJ, Lee CE, Chemelli RM, Saper CB, Yanagisawa M, Elmquist JK. Differential expression of orexin receptors 1 and 2 in the rat brain. J Comp Neurol 2001; 435: 65.  Marrosu F, Portas C, Mascia MS, Casu MA, Fa M, Giagheddu M et al. (1995) Microdialysis measurement of cortical and hippocampal acetylcholine release during sleep-wake cycle in freely moving cats.   Brain Res . 671, 32932.  Marrosu F, Fornal CA, Metzler CW, Jacobs BL (1996) 5-HT 1A agonists induce hippocampal theta activity in freely moving cats: role of presynaptic 5-HT 1A receptors. Brain Res 739:19200.  Matsumoto M, Hikosaka O (2007). Lateral habenula as a source of negative reward signals in dopamine neurons.   Nature   447 (7148): 1111115.  McCarley RW, Hobson JA (1975) Neuronal excitability modulation over the sleep cycle: a structural and mathematical model. Science. 189:58 ‚Äì 60.\n\nMcCormick DA., Prince DA (1987) Actions of acetylcholine in the guinea-pig and cat medial and lateral geniculate nuclei, in vitro. J Physiol 392:14765.  McGinty DJ, Harper RM (1976) Dorsal raphe neurons: depression of firing during sleep in cats. Brain Res 101:56975.  Metherate R, Cox CL, Ashe JH (1992) Cellular bases of neocortical activation: modulation of neural oscillations by the nucleus basalis and endogenous acetylcholine. 12:4701 ‚Äì 4711.  Miyamoto Y, Watanabe Y, Tanaka M (2008) Developmental expression and serotonergic regulation of relaxin 3/INSL7 in the nucleus incertus of rat brain. Regul Pept, 145: 549.  Monnier M and Tissot R (1958) Helv. Physiol Pharmacol Acta 16, 255.  Oddie SD, Bland BH, Colom LV, Vertes RP (1994) The midline posterior hypothalamic region comprises a critical part of the ascending brainstem hippocampal synchronizing pathway. Hippocampus, 4, 45473.  O'Keefe J., Recce M. L. (1993). Phase relationship between hippocampal place units and the EEG theta rhythm. Hippocampus 3, 31730.  Olucha-Bordonau FE, Teruel V, Barcia-Gonzalez J, Ruiz-Torner A, Valverde-Navarro AA, Martinez-Soriano F. Cytoarchitecture and efferent projections of the nucleus incertus of the rat. J Comp Neurol 2003; 464: 627.  Olucha-Bordonau FE, Otero-Garcia M, Sanchez-Perez AM, Nunez A, Ma S, Gundlach AL. Distribution and targets of the relaxin-3 innervation of the septal area in the rat. J Comp Neurol 2012; 520: 1903939.  Pan WX, McNaughton N (2004) The supramammillary area: its organization, functions and  relationship to the hippocampus. Prog. Neurobiol. 74, 127 ‚Äì 166.  Park MR (1987) Monosynaptic inhibitory postsynaptic potentials from lateral habenula recorded in dorsal raphe neurons. Brain Res Bull 19:581-586.  Perrotti LI, Bolanos CA, Choi KH, Russo SJ, Edwards S, Ulery PG, Wallace DL, Self DW, Nestler EJ, Barrot M (2005) DeltaFosB accumulates in a GABAergic cell population in the posterior tail of the ventral tegmental area after psychostimulant treatment. Eur J Neurosci 21:2817824.  Phillipson OT, Pycock CJ. 1982. Dopamine neurons of the ventral tegmentum project to both medial and lateral habenula. Exp Brain Res 45: 894.  Qin C and Luo M. (2009). Neurochemical phenotypes of the afferent and efferent projections of the mouse medial habenula. Neuroscience 161:82737.  Quick MW, Ceballo RM, Kasten M, McIntosh JM, Lester RA (1999)   Œ± 3 Œ≤   4 subunit- containing nicotinic receptors dominate function in rat medial habenula neurons. Neuropharmacology 38:76983.\n\nRaisman G (1966) The connections of the septum. Brain 89: 317-348.  Ren J, Qin C, Hu F, Tan J, Qiu L, Zhao S, Feng G, Luo M (2011). Habenula cholinergic neurons co-release glutamate and acetylcholine and activate postsynaptic neurons via distinct transmission modes. 69:44552.  Reuss S, Moller M 1986. Direct projections to the rat pineal gland via the stria medullaris thalami. Cell Tissue Res 244: 69194.  Riemann D, Hohagen F, Bahro M, Lis S, Stadmuller G, Gann H, Berger M (1994) Cholinergic neurotransmission, REM sleep and depression. J Psychosom Res.38(Suppl 1):15 ‚Äì 25.  Ronnekleiv OK, Kelly MJ, Wuttke W. Single unit recordings in the rat pineal gland: evidence for habenulo-pineal neural connections. Exp Brain Res 39: 18792, 1980  Ronnekleiv OK, Moller M. Brain-pineal nervous connections in the rat: an ultrastructure study following habenular lesion. Exp. Brain Res. 1979;37:55162.  Roffwarg HP, Muzio JN, Dement WC (1966) Ontogenetic development of the human sleep- dream cycle Science 29; 152(3722):604-19.  Saito Y, Cheng M, Leslie FM, Civelli O. Expression of the melanin-concentrating hormone (MCH) receptor mRNA in the rat brain. J Comp Neurol 2001; 435: 260.  Sakai K (1980)   ‚ÄúSome anatomical and physiological properties of ponto -mesencephalic tegmental neurons with special reference to PGO waves and postural atonia during  paradoxical sleep,‚Äù in The Reticular Formation Revisited, eds Hobson J. A., Brazier M. A. B.,  editors. (New York: Raven Press; ), 427 ‚Äì 447.  Sakurai T (2007) The neural circuit of orexin (hypocretin): maintaining sleep and wakefulness. Nat. Rev. Neurosci. 8, 17181 10.1038/nrn2092  Sanchez-Perez, AM, Arnal-Vicente I, Santos FN, Pereira CW, ElMlil N, Sanjuan J, et al. (2015). Septal projections to nucleus incertus in the rat: bidirectional pathways for modulation of hippocampal function.   J. Comp. Neurol.   523, 56588.  Saper, CB, Chou TC & Scammell TE (2001) The sleep switch: hypothalamic control of sleep and wakefulness. Trends Neurosci. 24, 72631.  Saper CB, Sherin JE, Elmquist JK (1997) Role of the ventrolateral preoptic area in sleep induction. In: Hayaishi O, Inoue S, eds.   Sleep and sleep disorders: from molecule to behavior.   Tokyo: Academic,281 ‚Äì 294.  Sitaram N, Gillin JC (1980) Development and use of pharmacological probes of the CNS in man: evidence of cholinergic abnormality in primary affective illness. Biol Psychiatry. 15:925 ‚Äì 955.\n\nSitaram N, Wyatt RJ, Dawson S, Gillin JC (1976) REM sleep induction by physostigmine infusion during sleep. Science. 191:1281 ‚Äì 1283.  Steininger TL, Gong H, McGinty D & Szmusiak R (2001). Subregional organization of preoptic area/anterior hypothalamic projections to arousal-related monoaminergic cell groups. J. Comp. Neurol. 429, 63853.  Strecker, R. E.   et al . Adenosinergic modulation of basal forebrain and preoptic/anterior hypothalamic neuronal activity in the control of behavioral state. Behav. Brain Res. 115, 18304 (2000).  Sutherland RJ (1982) The dorsal diencephalic conduction system: a review of the anatomy and functions of the habenular complex. Neurosci Biobehav Rev 6:13.  Sugama S, Cho BP, Baker H, Joh TH, Lucero J, Conti B (2002). Neurons of the superior nucleus of the medial habenula and ependymal cells express IL-18 in rat CNS. Brain Res. 958, 1 10.1016/S0006-8993(02)03363-2  Takahashi K, Kayama Y, Lin JS, and Sakai K (2010). Locus coeruleus neuronal activity during the sleep-waking cycle in mice. Neuroscience 169, 1115126.  Takahashi K, Lin JS, Sakai K Neuronal activity of histaminergic tuberomammillary neurons during wake-sleep states in the mouse. J.Neurosci. 2006;26:102920298.  Teclemariam-Mesbah, R., Ter Horst, G. J., Fostema, F., Wotel, J. & Buijs, R. M. Anatomical demonstration of the suprachiasmatic nucleus-pineal gland. J. Comp. Neurol. 406, 17182 (1999).  Teruel-Marti V, Cervera-Ferri A, Nunez A, Valverde-Navarro AA, Olucha-Bordonau FE, Ruiz-Torner A. Anatomical evidence for a ponto-septal pathway via the nucleus incertus in the rat. Brain Res 2008; 1218: 876.  Thakkar MM, Strecker RE, McCarley RW (1998) Behavioral state control through differential serotonergic inhibition in the mesopontine cholinergic nuclei: a simultaneous unit recording and microdialysis study. J Neurosci. 18:5490497.  Thinschmidt, JS, 1993. The supramammillary nucleus: does it play a role in the mediation of hippocampal theta rhythm? MA Thesis. Florida Atlantic University.  Trulson ME, Jacobs BL (1979) Raphe unit activity in freely moving cats: correlation with level of behavioral arousal. Brain Res 163:13550.  Uhlhaas PJ, Roux F, Singer W, Haenschel C, Sireteanu R, Rodriguez E (2009) The development of neural synchrony reflects late maturation and restructuring of functional networks in humans. Proc Natl Acad Sci USA;106:9866871.  Vaccari C, Lolait SJ, Ostrowski NL (1998). Comparative distribution of vasopressin V1b and oxytocin receptor messenger ribonucleic acids in brain. Endocrinology; 139: 5015033.\n\nVadovi ƒç ov√° K (2014) Affective and cognitive prefrontal cortex projections to the lateral habenula in humans. in Front Hum Neurosci. 2014; 8:819. Published also in arXiv:1402.2196 [q-bio.NC]  Vadovi ƒç ov√° K, Gasparotti R (2014) Reward and adversity processing circuits: their competition and interactions with dopamine and serotonin signaling.   ScienceOpen Research , 15 Sept 2014. DOI: 10.14293/S2199-1006.1.SOR-LIFE.AEKZPZ.v1   Published also in 2013 in arXiv:1304.4201 [q-bio.NC]  Vanderwolf, CH (1969) Hippocampal electrical activity and voluntary movement in the rat. Electroencephalogr. Clin. Neurophysiol., 26, 40718.  Varga V, Kekesi A, Juhasz G, Kocsis B (1998) Reduction of the extracellular level of glutamate in the median raphe nucleus associated with hippocampal theta activity in the anaesthetized rat. Neuroscience. 1998 May; 84(1):49-57  Vertes RP and Fass B (1988) Projections between the interpeduncular nucleus and basal forebrain in the rat as demonstrated by the anterograde and retrograde transport of WGA- HRP. Exp. Brain Res., 73: 231.  Vertes RP, Kinney GG, Kocsis B, Fortin WJ (1994) Pharmacological suppression of the median raphe nucleus with serotonin1A agonists, 8-OH-DPAT and buspirone, produces hippocampal theta rhythm in the rat. Neuroscience, 60:44151.  Vertes, RP and Kocsis B (1997) Brainstem-diencephalo-septohippocampal systems controlling the theta rhythm of the hippocampus. Neuroscience, 81, 89326.  Vertes RP, Linley SB (2008) in Serotonin and sleep: molecular, functional and clinical aspects, Efferent and afferent connections of the dorsal and median raphe nuclei in the rat, eds Monti JM, Pandi-Perumal SR, Jacobs BL, Nutt DJ (Birkhnser Verlag, Basel), pp 6902.  Vertes, RP and Martin GF (1988) Autoradiographic analysis of ascending projections from the pontine and mesencephalic reticular formation and the median raphe nucleus in the rat. J. Comp. Neurol., 275: 51141. doi:10.1002/cne.902750404  Wang RY, Aghajanian GK (1977) Physiological evidence for habenula as major link between forebrain and midbrain raphe. Science 197:89-91.  Wasserman DI, Wang HG, Rashid AJ, Josselyn SA, Yeomans JS. 2013. Cholinergic control of morphine-induced locomotion in rostromedial tegmental nucleus versus ventral tegmental area sites. Eur J Neurosci 38:2774785.  Wasserman DI, Tan JMJ, Kim J, Yeomans JS. 2014. Muscarinic control of rostromedial tegmental nucleus (RMTg) GABA neurons and morphine-induced locomotion. Soc Neurosci Abstr 364.02.  Williams JA, Comisarow J, Day J, Fibiger HC, Reiner PB (1994) State-dependent release of acetylcholine in rat thalamus measured by in vivo microdialysis. 14:5236242.\n\nWilliams JA, Reiner PB. Noradrenaline hyperpolarizes identified rat mesopontine cholinergic neurons in vitro. J Neurosci. 1993;13:3878883.  Woolf NJ (1991) Cholinergic systems in mammalian brain and spinal cord. Progress in Neurobiology, 37, 475-524.  Yamaguchi T, Danjo T, Pastan I, Hikida T, Nakanishi S (2013) Distinct roles of segregated transmission of the septo-habenular pathway in anxiety and fear. Neuron. 78, 53744 10.1016/j.neuron  Yamamoto T, WatanabeS, Oishi R, Ueki S (1979) Effects of midbrain raphe stimulation and lesion on EEG activity in rats. Brain Res Bull, 4:49195.  Yoon JY, Jung SR, Hille B, Koh DS (2014) Modulation of nicotinic receptor channels by adrenergic stimulation in rat pinealocytes. Am J Physiol Cell Physiol; 306:C726n735.  Zahm DS (2006) The evolving theory of basal forebrain functional-anatomical acrosystems.Neurosci Biobehav Rev 30:14872.  Zahm DS, Jensen SL, Williams ES, Martin JR 3rd. 1999. Direct comparison of projections from the central amygdaloid region and nucleus accumbens shell. Eur J Neurosci 11:1119126.  Zahm DS, Parsley KP, Schwartz ZM, Cheng AY. 2013. On lateral septum-like characteristics of outputs from the accumbal hedonic hotspot of Pecina and Berridge with commentary on the transitional nature of basal forebrain boundaries.J Comp Neurol 521:508.",
    "Data-Efficient Sleep Staging with Synthetic Time Series Pretraining  Niklas Grieger 1 , 2 , 3 , ‚àó   Siamak Mehrkanoon 2   Stephan Bialonski 1 , 3 , ‚àó  1 Department of Medical Engineering and Technomathematics, FH Aachen University of Applied Sciences, 52428 J¬® ulich, Germany  2 Department of Information and Computing Sciences, Utrecht University, Utrecht, The Netherlands  3 Institute for Data-Driven Technologies, FH Aachen University of Applied Sciences, 52428 J¬® ulich, Germany  ‚àó grieger@fh-aachen.de, bialonski@fh-aachen.de  Abstract  Analyzing electroencephalographic (EEG) time series can be challenging, especially with deep neural networks, due to the large variability among human subjects and often small datasets. To address these challenges, various strategies, such as self-supervised learning, have been suggested, but they typically rely on extensive empirical datasets. Inspired by recent advances in computer vision, we propose a pretraining task termed ‚Äúfrequency pretraining‚Äù to pretrain a neural network for sleep staging by predicting the frequency content of randomly generated synthetic time series. Our experiments demonstrate that our method surpasses fully supervised learning in scenarios with limited data and few subjects, and matches its performance in regimes with many subjects. Furthermore, our results underline the relevance of frequency information for sleep stage scoring, while also demonstrating that deep neural networks utilize information beyond frequencies to enhance sleep staging performance, which is consistent with previous research. We anticipate that our approach will be advantageous across a broad spectrum of applications where EEG data is limited or derived from a small number of subjects, including the domain of brain-computer interfaces.  1   Introduction  Deep neural networks have achieved significant advances in analyzing electroencephalographic (EEG) time series [39], ranging from brain-computer interfaces [30] to the intricacies of sleep stage scoring [36, 15].   Such successes are attributed to the ability of deep neural networks, as universal function approximators, to learn properties (features) from patient data that are difficult for humans to conceptualize and define. However, training neural networks requires large and diverse datasets that capture the considerable variety between individual subjects and their medical conditions (subject heterogeneity). Creating such datasets is challenging due to the typically limited amount of data per subject (data scarcity) and diverse measurement protocols used in different clinics, which can introduce additional variability in the data.   Furthermore, acquiring large datasets is often expensive, complicated, or even intractable due to strict privacy policies and ethical guidelines. This hinders the advancement of deep neural networks for widespread application in real-world medical settings. Efforts to mitigate the scarcity of large datasets have primarily followed two paths:   (1) the development of network architectures that incorporate constraints mirroring the data‚Äôs intrinsic characteristics, such as symmetries [7], and (2) enhancing model performance with additional or cross-domain data to learn effective priors.   Pertaining to the first path, a common feature in time series processing networks is the use of convolutional layers.   These layers are designed to be translation-equivariant [18], which ensures that a temporal shift in the input only affects the output by the same shift. This characteristic enables consistent network responses to temporal patterns, regardless of their temporal location, while reducing the number of model parameters compared to architectures lacking such constraints. For the second path, a variety of strategies have been proposed to learn useful priors from data. One approach is data augmentation, in which time series are transformed while preserving their annotations (labels) to artificially expand the dataset [31, 23]. Deep neural networks trained on such augmented datasets implicitly learn to become invariant under these transformations, which can lead to better out-of-sample prediction performance. Another strategy is transfer learning [12], a two-step process in which neural networks are trained on one task using a large dataset (pretraining step [37]) and then adapted to learn the actual task of interest using another (usually much smaller) dataset (fine-tuning step).   A variant of this idea is self-supervised learning [32, 2], which allows neural networks to be pretrained on large and heterogeneous datasets without explicitly labeled examples.   Finally, generative models such as VAEs, GANs, and diffusion models can be used to sample new time series to extend existing datasets [22, 8, 46].   Such generative models approximate a data distribution and require large heterogeneous datasets for training. While all of these approaches have been demonstrated to be able to improve the performance of neural networks, they still rely on large empirical datasets for training. Recent advances in computer vision have demonstrated that it is possible to learn effective priors exclusively from synthetic images, which has the potential to significantly reduce the need for large empirical datasets [3, 26]. Synthetic images for image 1  arXiv:2403.08592v2 [cs.LG] 17 Sep 2025\n\nclassification tasks were generated by simple random processes, such as iterated function systems to produce fractals [26] or random placement of geometric objects to cover an image canvas [3].   Deep neural networks pretrained on such data were demonstrated to learn useful priors for image classification tasks, yielding competitive performance comparable to pretraining on natural images on various benchmarks [26].   This remarkable finding highlights the potential of synthetic datasets that can be generated without much computational resources and, theoretically, in unlimited amounts. Inspired by these advances, we hypothesize that pretraining exclusively on synthetic time series data generated from simple random processes can also yield effective priors for sleep staging.   Given the importance of frequencies for sleep stage scoring and other EEG-based applications [5, 33], we introduce a pretraining method called ‚Äúfrequency pretraining‚Äù (FPT) that centers on generating synthetic time series data with specific frequency content. During pretraining, deep neural networks learn to accurately predict the frequencies present in these synthetic time series. Despite the deliberate simplicity of our synthetic data generation process and the inherent domain shift between synthetic and EEG data, we observe that FPT allows a deep neural network to detect sleep stages more accurately than fully supervised training when few samples (few-sample regime) or data from few subjects (few-subject regime) are available for fine-tuning. The success of our method underscores the essential role of frequency content in enabling neural networks to accurately and reliably discern sleep stages. We consider pretraining techniques leveraging synthetic data, like the one we propose, as a promising area of research, offering the potential to develop models in sleep medicine and neuroscience that are particularly suited for scenarios involving small datasets. To facilitate testing and further advancements, we make the source code of our method publicly available [19].  Contributions  ‚Ä¢   Novel synthetic pretraining approach:   We introduce ‚Äúfrequency pretraining‚Äù (FPT), a pretraining approach using synthetic time series with random frequency content, eliminating the need for empirical EEG data during pretraining.  ‚Ä¢   Demonstrated data efficiency:   We demonstrate superior sleep staging performance of FPT in few-sample and few- subject regimes across three datasets, with comparable results to fully supervised methods when data is abundant.  ‚Ä¢   Analysis of frequency-based priors:   We evaluate the role of frequency information in our pretraining task and how synthetic sample diversity affects fine-tuning.  ‚Ä¢   Comparison with self-supervised methods:   We benchmark our approach against established self-supervised learning methods, demonstrating that synthetic data pretraining can achieve comparable results without requiring EEG data for pretraining.  2   Results  Our approach, illustrated in Figure 1 and detailed in Section 4, is based on a two-phase training process that combines pretraining on synthetic time series with fine-tuning on clinical sleep data.   During the pretraining phase, we generate synthetic time series composed of sine waves with random frequencies drawn from predefined frequency ranges (frequency bins). These synthetic signals are then used to train a deep neural network whose feature extractor,   f   , learns to extract useful features, while the classifier,   c p , learns to predict the frequency bins from which the frequencies were drawn to generate the synthetic time series. After pretraining, the feature extractor is transferred to the fine-tuning phase, where it is applied to real EEG and electrooculography (EOG) data to classify sleep stages. In this phase, the model processes sequences of eleven consecutive sleep epochs, indexed   i   ‚àí   5 to   i   + 5, with the feature extractor producing features   h i   from each epoch. Another classifier   c f   then aggregates these features to predict the sleep stage (Wake, N1, N2, N3, REM) for the central sleep epoch   i . We evaluated our approach on three publicly available datasets,   DODO/H ,   Sleep-EDFx , and   ISRUC , which provided data from 276 subjects, including both healthy individuals and those with various medical conditions (see Section 4.2.1). For sleep staging performance, we tracked the Macro-F1 score, with higher values indicating better classification accuracy across sleep stages. During the pretraining phase, we assessed the model‚Äôs ability to predict frequency bins using the Hamming metric and the accuracy (see Section 4).  2.1   Training Configurations  We compared the performance of pretrained models against the performance of non-pretrained models in scenarios with varying amounts of training data. In particular, we studied the performance of our approach in few-sample and few-subject regimes, where the greatest benefit was expected.   Furthermore, we analyzed the priors that the model learned during pretraining and the role of frequency information in the learned features.   Finally, we investigated whether these features could be further improved by fine-tuning the feature extractor.   To enable these investigations, we created four training configurations.  Fully Supervised.   The Fully Supervised training configuration is similar to many existing deep learning approaches for sleep staging [36] and served as a baseline to compare our pretrained models against. In this configuration, we skipped the pretraining step and trained (fine-tuned) the feature extractor   f   and classifier   c f   from scratch using sleep staging data. 2\n\nFigure 1:   The training process consists of a   pretraining   and a   fine-tuning   phase.   In the pretraining phase (‚Äúfrequency pretraining‚Äù), we generated synthetic time series signals by summing sine waves with random frequencies. These synthetic signals were used to train a deep neural network consisting of a feature extractor   f   and a classifier   c p   to predict the frequencies present in the signals (multi-label classification problem). In the fine-tuning phase, the pretrained feature extractor   f   produced features   h i   from individual EEG and EOG epochs. The features of a sequence of these epochs were then used by a classifier  c f   that was trained to predict the sleep stage of the middle epoch in the sequence (multi-class classification problem).  Fixed Feature Extractor.   We employed the Fixed Feature Extractor configuration to investigate the relevance of the features generated by the pretrained feature extractor for sleep staging. After pretraining the feature extractor   f   on synthetic data, we kept its model weights and BatchNorm statistics fixed and only fine-tuned the sleep staging classifier   c f   on sleep data.  Fine-Tuned Feature Extractor.   With this training configuration, we studied (i) how model performance changes when the pretrained feature extractor is allowed to change during fine-tuning and (ii) whether the priors learned during pretraining can prevent overfitting in few-sample or few-subject regimes. As in the previous configuration, we first pretrained the feature extractor   f   on synthetic data, but then fine-tuned both the feature extractor and the classifier   c f   on sleep data without keeping any model weights fixed. Consequently, this configuration is similar to the Fully Supervised configuration with the key distinction that the feature extractor is initialized with pretrained weights.  Untrained Feature Extractor.   The Untrained Feature Extractor configuration served as a baseline to study whether our pretraining scheme produces priors that are superior to random weights for sleep staging. We randomly initialized the feature extractor   f   using Kaiming normal initialization [24] and then kept its weights fixed while fine-tuning the classifier   c f   . This approach mirrors the Fixed Feature Extractor configuration, but with a random feature extractor instead of a pretrained one.  2.2   Data Efficiency  To assess the data efficiency of our pretraining method, we compare the performance of the different training configurations when fine-tuned with a reduced amount of training data (low-data regime) or the full training data (high-data regime). We investigated the low-data regime by first pretraining models with the full synthetic dataset. Depending on the training configuration, we then fine-tuned the pretrained or randomly initialized models with the data of 50 randomly sampled sleep staging samples from one subject. The sampling procedure selected sleep staging data without class stratification, and each sleep stage was represented at least once in the reduced datasets. In the high-data regime, we followed the same procedure 3\n\n]   * ]   * ]   * ]   * ]   * ]   * ]   * ]   * ]   * Figure 2:   Average macro F1 scores achieved by the different training configurations when fine-tuned with a small set of training data (left side) or a large set (full set) of training data (right side) from one of the three datasets DODO/H, Sleep-EDFx, and ISRUC. The bars indicate the mean of the macro F1 scores measured on the test sets and averaged over 15 trainings (3 repetitions of a 5-fold cross-validation). Error bars show the standard deviation of the macro F1 scores, and * symbols indicate significant differences between Untrained and Fixed Feature Extractor or between Fine-Tuned Feature Extractor and Fully-Supervised training configuration ( p <   0 . 01) according to a one-sided Wilcoxon signed-rank test. but fine-tuned models with the full training data instead of a reduced amount of data. We repeated all experiments three times in a 5-fold cross-validation scheme, resulting in 15 training runs for each configuration and dataset.   This approach allowed us to estimate the spread of the macro F1 scores when using different model initializations, sleep staging samples, and data folds for training and testing (see Section 4). In the low-data regime, we observed that models pretrained with synthetic data outperformed models trained from scratch in sleep stage classification (see Figure 2). The performance gap between pretrained and non-pretrained models was most pronounced when comparing the fine-tuned feature extractor to the fully supervised configuration, with the former achieving average macro F1 scores that were 0.06‚Äì0.07 higher than those of the latter across datasets. When removing the fine-tuning of the pretrained features (fixed feature extractor configuration), our method still yielded macro F1 scores that were 0.01‚Äì 0.05 higher than those of the fully supervised configuration. Comparing the fixed feature extractor to the untrained feature extractor configuration further highlights the importance of the learned features.   Pretraining the feature extractor with synthetic data improved the macro F1 scores by 0.10‚Äì0.17 compared to a random initialization. While the macro F1 scores of the training configurations varied between datasets, the general trends observed in the low-data regime were consistent across all three datasets. In the high-data regime, our pretrained models were on par with fully supervised trained models ( p   ¬° 0.05 for a paired TOST test with a margin of   ¬± 0 . 01 on the DODO/H and ISRUC datasets) and achieved competitive performance in sleep stage classification (see Figure 2). The fine-tuned feature extractor configuration achieved average macro F1 scores of 0.76‚Äì 0.81 across datasets, comparable to the macro F1 scores of 0.76‚Äì0.80 achieved by the fully supervised configuration. As in the low-data regime, we observed that fine-tuning the pretrained features was beneficial, as the macro F1 scores achieved by the fine-tuned feature extractor configuration were 0.02‚Äì0.05 higher than those of the fixed feature extractor configuration. The performance gap between the untrained feature extractor and the fixed feature extractor remained substantial even in the high-data regime, with the former achieving average macro F1 scores that were 0.08‚Äì0.12 lower than those of the latter.  2.3   Impact of Subject Diversity and Number of Training Samples  We further explored the data efficiency of our pretraining method by investigating how model performance is affected by subject diversity and sample volume (i.e., number of samples) in the training data used for fine-tuning. To study the effect of subject diversity independent of sample volume, we separately varied the number of subjects and the number of samples in the training data.   The number of subjects was randomly sampled as   n subj   ‚àà { 1 ,   2 ,   3 ,   4 ,   5 } , and the number of samples was randomly sampled from those subjects as   n samples   ‚àà { 50 ,   130 ,   340 ,   900 ,   all }   (‚Äúall‚Äù indicates that all available training samples were used). Our sampling strategy selected sleep staging data without class stratification, and each sleep stage was 4\n\nrepresented at least once in the reduced datasets.   For each parameter combination, we trained the fully supervised and fine-tuned feature extractor configurations on all three datasets with three repetitions of 5-fold cross-validation. In our results, we observed that both the fully supervised and the fine-tuned feature extractor configurations benefited from increased subject diversity, even when the total number of training samples was held constant (see rows in Figure 3a‚Äìf). Similarly, both configurations benefited from an increased number of training samples when the number of subjects was held constant (see columns in Figure 3a‚Äìf).   For the considered parameter ranges, the impact of reduced subject diversity and reduced sample volume on model performance appeared to be comparable. Similar to the observations made in Section 2.2, the fine-tuned feature extractor configuration achieved better macro F1 scores than the fully supervised configuration in the few-sample regime. The performance gap between the two configurations was most evident when the number of samples was limited to 50, with bootstrap estimates of the mean differences in macro F1 scores ranging from 0.05 to 0.09 across datasets and subject numbers (see Figure 3g‚Äìi).   These differences in macro F1 scores decreased as the number of samples increased.   When training on all available training samples, the fine-tuned feature extractor configuration achieving comparable or slightly better performance than the fully supervised configuration. Interestingly, the performance gap between the two configurations with all available training samples was most pronounced for the DODO/H dataset. The fine-tuned feature extractor configuration achieved average macro F1 scores that were 0.02‚Äì0.06 higher than those of the fully supervised configuration. For the Sleep-EDFx and ISRUC datasets, the performance differences between the two configurations with all available training samples were minimal at 0.00‚Äì0.01. Depending on the dataset, the fine-tuned feature extractor configuration showed varying degrees of improvement over the fully supervised configuration in the few-subject regime.   When training with data of a single subject, the fine-tuned feature extractor configuration achieved average macro F1 scores that were 0.06‚Äì0.11 higher across sample numbers than those of the fully supervised configuration for the DODO/H dataset (see rows in Figure 3g). This performance gap decreased as the number of subjects increased, with mean bootstrapped differences in macro F1 scores between 0.02 and 0.09 for five subjects. In contrast, varying the number of subjects had less impact on the performance gap between the fine-tuned feature extractor and the fully supervised configurations for the Sleep-EDFx and ISRUC datasets (see rows in Figure 3h‚Äìi).   The improvements achieved by the fine-tuned feature extractor configuration when trained with one subject (0.01‚Äì0.05 for the Sleep-EDFx dataset and 0.00‚Äì0.07 for the ISRUC dataset) were comparable to those achieved when trained with five subjects (0.00‚Äì0.06 for the Sleep-EDFx dataset and 0.01‚Äì0.06 for the ISRUC dataset).  2.4   Priors Towards Frequency Information  To get a better understanding of the pretraining process and the priors learned by the model, we recorded several metrics during pretraining.   The recorded loss function converged to a low value, indicating that the model has learned effectively (see Figure 4a). At the same time, the Hamming metric reached a high value of 0.9 on the validation data (see Figure 4b). This value can be interpreted as the model predicting the frequency bins that were used to create the synthetic signals with an accuracy of 90%.   The model was particularly proficient in predicting higher frequencies starting from 2.5 Hz (accuracies   >   90%; see Figure 4c).   Lower frequencies, especially those below 1 Hz, were predicted with lower accuracy (75‚Äì85%). We hypothesize that the differences in prediction accuracy across frequency bins are not due to the pretrained model being unable to predict lower frequencies. Instead, we believe this discrepancy arises from the varying width of the frequency bins (see x-axis of Figure 4c) as the bins for lower frequencies were narrower than those for higher frequencies due to their logarithmic scaling. While we applied a logarithmic binning scheme to increase our model‚Äôs focus on the lower frequencies important for identifying slow wave sleep (N2 and N3 sleep), the narrow low frequency bands increase the difficulty of the pretraining task leading to decreased accuracies.   Preliminary exploration of this trade-off between model focus and task difficulty showed that the current binning scheme slightly outperforms a linear binning scheme in the fixed feature extractor setup. Interestingly, the ability of the pretrained feature extractor to extract useful features for sleep staging was strongly influenced by the diversity of the synthetic pretraining data (see Figure 4d).   We investigated this influence of sample diversity by pretraining models with varying amounts of different synthetic samples   n synthetic   ‚àà { 1 ,   10 ,   100 ,   10 3 ,   10 4 ,   10 5 ,   10 6 } . To isolate the effect of sample diversity from the effect that the number of training steps has on model performance, we kept the number of gradient updates per training epoch constant by under- or oversampling the synthetic data to 100,000 samples. The pretrained models were then trained for sleep staging using data from one random subject from the DODO/H dataset and evaluated on the validation data of each cross-validation fold.   As in the previous experiments, we performed three repetitions of a 5-fold cross-validation scheme for each number of synthetic samples. Both the fixed feature extractor and the fine-tuned feature extractor configurations required a high level of diversity in the synthetic pretraining data to achieve good sleep staging performance (see Figure 4d). When pretrained with only one synthetic sample, the performance of the two training configurations with pretraining differed only slightly from the performance of the configurations without pretraining (untrained feature extractor and fully supervised configurations). As the number of synthetic samples was increased to more than 100, the performance of the pretrained models improved substantially until reaching a plateau at around 10,000 samples. We hypothesize that this plateau was reached because the model had learned all the relevant features from the pretraining task, and additional samples did not provide any further benefit. The simplicity 5\n\nFigure 3:   Detailed comparison of the fully supervised and fine-tuned feature extractor configurations in few-sample and few-subject regimes for each of the three datasets DODO/H (panels   a , d , g ), Sleep-EDFx (matrices   b , e , h ), and IS- RUC (panels   c , f , i ).   Panels ( a ‚Äì c ) and Panels ( d ‚Äì f   ) show the macro F1 scores achieved by the fully supervised and the fine-tuned feature extractor configurations, respectively.   The displayed scores are the mean and the standard de- viation of the macro F1 scores measured on the test set over 15 trainings (3 repetitions of a 5-fold cross-validation). Panels ( g‚Äìi ) show the average macro F1 scores achieved by the fine-tuned feature extractor configuration minus the average macro F1 scores achieved by the fully supervised configuration.   These differences were calculated using a bootstrapping approach with 10,000 bootstrap samples. In this bootstrapping approach, we first paired the 15 macro F1 scores available for both configurations for each matrix entry based on the used seed and fold.   We then calculated the difference between each pair of macro F1 scores. For each bootstrap sample, we sampled 15 of these differences with replacement and calculated their average. Finally, we display the mean and the standard deviation of these bootstrap samples. 6\n\nFigure 4:   Analysis of the ‚Äúfrequency pretraining‚Äù task. Panel ( a ) shows the development of the loss function during a single pretraining run for both the training and validation data. The following two panels quantify the accuracy of a pretrained model to predict the frequencies of the synthetic signals. The hamming metric in panel ( b ) measures the overall accuracy summarized across all frequency bins, while panel ( c ) shows the accuracy for each frequency bin separately.   Panel ( d ) illustrates how the diversity of the synthetic pretraining data affects the performance of the pretrained feature extractor (FE) after fine-tuning for sleep staging on a single subject from the DODO/H dataset. Each bar indicates the mean of the macro F1 scores on the validation data averaged over 3 repetitions of a 5-fold cross-validation, while the error bars show the standard deviation of the macro F1 scores. of the pretraining task could also explain the negligible performance differences between the pretrained configurations with less than 100 synthetic samples and the training configurations without pretraining.   For such few synthetic samples, the model may have memorized the synthetic data rather than learn general features useful for sleep staging.  2.5   Comparison to Self-Supervised Methods  We compared our frequency pretraining approach (FPT) with two popular self-supervised learning (SSL) methods, Sim- CLR [9] and VICReg [4], using the same model architecture as in FPT. The projection head (SimCLR) and expander (VICReg) followed their original designs [9, 4]. Different from the conceptually simple multi-label classification task in FPT, both SSL methods follow the objective of contracting representations of data-augmented ‚Äúpositive‚Äù samples while keeping representations of dissimilar ‚Äúnegative‚Äù samples far apart (see original works for details [9, 4]). Positive samples were gen- erated using standard data augmentations: amplitude scaling (random factor 0.5‚Äì2), Gaussian noise injection ( œÉ   = 0.05), random temporal masking (10 segments of 1.5‚Äì3 s), time shifting (up to   ¬± 1.5 s), and time warping (random factor 0.67‚Äì1.5). We evaluated two pretraining configurations: pretraining on (i) synthetic data (as in FPT) and (ii) EEG recordings from the ISRUC and Sleep-EDFx datasets. Fine-tuning was performed on DODO/H datasets under low-data (50 random epochs from one random subject) and high-data (all available training data) regimes, respectively. When pretrained on synthetic data, both SimCLR and VICReg achieved performance comparable to the FPT method, with FPT slightly outperforming the SSL methods in the high-data regime when the feature extractor was fine-tuned (average MF1 scores of 0.80 versus 0.81, see Table 1). Pretraining on EEG data yielded only modest improvements, with both SSL methods showing slightly better performance in the low-data regime when the feature extractor was fixed (difference in average MF1 scores of 0.02) and in the high-data regime when fine-tuning the feature extractor (difference in average MF1 7\n\nscores of 0.01).   Compared to the EEG-pretrained SimCLR and VICReg models in the high-data regime, FPT showed similar performance (average MF1 scores of 0.76 and 0.81) but, unlike the two SSL methods, did not require EEG data for pretraining. In the low-data regime, the SSL methods performed comparable to the FPT method when fine-tuning the feature extractor and achieved slightly higher scores than FPT when keeping the feature extractor fixed (average MF1 scores of 0.44 and 0.45 versus 0.42).   None of the differences in MF1 scores between the SSL methods and FPT were significant according to a two-sided Wilcoxon signed-rank test ( p -values   >   0.05). Table 1:   Comparison of different pretraining methods when fine-tuned with 50 random sleep epochs of one subject (low-data regime) or the full training set (high-data regime) of the DODO/H dataset. During fine-tuning, the feature extractor was either kept fixed (FE fixed) or updated together with the classifier (FE fine-tuned).   We pretrained SimCLR and VICReg on the same synthetic data used for the frequency pretraining task, in addition to the traditional approach of pretraining on EEG data (i.e., ISRUC and Sleep-EDFx datasets). MF1 scores were calculated as the average of three repetitions of a five-fold cross validation (standard deviation in parentheses).  Pretraining Method   Avg. MF1 Low-Data Regime   Avg. MF1 High-Data Regime FE Fixed   FE Fine-Tuned   FE Fixed   FE Fine-Tuned  SimCLR, pretrained with synth. data   0.42 (0.08)   0.44 (0.09)   0.76 (0.02)   0.80 (0.02) SimCLR, pretrained with EEG data   0.44 (0.08)   0.43 (0.09)   0.76 (0.02)   0.81 (0.02) VICReg, pretrained with synth. data   0.43 (0.07)   0.44 (0.08)   0.76 (0.02)   0.80 (0.02) VICReg, pretrained with EEG data   0.45 (0.08)   0.45 (0.09)   0.76 (0.02)   0.81 (0.01) Frequency pretraining   0.42 (0.06)   0.44 (0.09)   0.76 (0.01)   0.81 (0.02)  3   Discussion  In this work, we propose a novel pretraining scheme for EEG time series data that leverages synthetic data generated by a simple random process.   We specialized the hyperparameters of the pretraining task to the typical frequency range and distribution of sleep EEG signals and demonstrated the effectiveness of this task for sleep stage classification.   Due to the availability of several open sleep staging datasets [35, 47], we were able to fully control the amount and diversity of the training data, which allowed us to study the impact of our method in different data regimes. We hypothesize that our pretraining scheme could be particularly beneficial in few-sample and few-subject regimes, which we argue could benefit greatly from the priors towards frequency information that a model learns during pretraining. Our results confirm the effectiveness of our pretraining scheme, particularly in few-sample and few-subject regimes. Pretrained models outperformed non-pretrained models when fine-tuned with a reduced number of subjects or training samples (see rows and columns in Figure 3g‚Äìi, respectively). The performance gap between pretrained and non-pretrained models was most pronounced in the few-sample regime, where pretrained models consistently achieved improvements over non-pretrained models across multiple datasets.   In the few-subject regime, this performance gap was not as consistent across datasets, with our pretraining method showing the most substantial improvements in the DODO/H dataset.   Our findings support observations made in the field of Self-Supervised Learning (SSL) that pretrained models generally have better data efficiency than fully supervised ones [2, 13].   In contrast to SSL methods, however, our pretraining scheme improves data efficiency without requiring empirical data, while achieving comparable or only slightly reduced performance (see Table 1). Interestingly, we observed that two data-augmentation-based SSL methods performed well even when pretrained with synthetic data instead of EEG data (see Table 1), suggesting that SSL approaches are promising, yet computationally intensive, alternatives to the FPT method. Further exploration of the use of SSL methods for pretraining on synthetic data is warranted and seems promising. Generating synthetic data can be much cheaper and more cost-effective than collecting EEG data, as generating 10,000 samples of the synthetic data used in this study required only 8 . 17   ¬±   0 . 37 s of a single consumer-grade CPU core (Lenovo Legion S7 16IAH7 Laptop with an Intel ¬Æ   Core ‚Ñ¢   i7-12700H CPU). We hypothesize that the potential of synthetic data stems from the priors that the model learns during pretraining. These priors could prevent overfitting to a small number of training samples, particularly those from minority classes (e.g., N1 sleep), or subject-specific features, which is especially problematic in situations with very little training data. As expected, we observed that all of our training configurations improved with a larger training dataset (see Figure 2). This aligns with the prevalent view in the literature that deep learning models for sleep staging need substantial amounts of diverse data to perform well [36, 1, 15, 14]. When trained with the full training data, pretrained models performed comparably to fully supervised models (see Figure 2), achieving macro F1 scores similar to those of other deep learning approaches for sleep staging [36, 16]. In conclusion, our pretraining method was most beneficial in situations with limited training data, where it outperformed models trained from scratch, but had less impact in situations with large amounts of training data. We further observed that, while the frequency content of a signal is crucial for sleep staging, deep neural networks extract additional information from the data that exceeds the frequency domain.   The importance of the frequency content of a signal for sleep staging is demonstrated by the high macro F1 scores achieved by the fixed feature extractor configuration 8\n\nand the substantial performance improvements it achieved over untrained feature extractors (see Figure 2).   We attribute the performance gap between the two training configurations to the priors learned during pretraining the feature extractor. These priors biased the model to extract frequency information from the data, which it achieved with high accuracy after pretraining (see Figure 4b,c). Our finding is consistent with previous studies that reported frequency-based features to be important for sleep staging [33].   When the feature extractor of our model was allowed to be fine-tuned after pretraining, model performance increased (see Figure 2). We hypothesize that this increase in the macro F1 score is due to the feature extractor learning to extract information beyond the frequency content of the signal during fine-tuning.   This hypothesis is in line with the AASM annotation guidelines [5], which consider several frequency-unrelated features essential for sleep staging. These features include time-domain information, which is important for spindles as well as amplitudes and specific patterns, such as k-Complexes [15].   Recent studies that applied feature engineering approaches to sleep staging further support our hypothesis by including additional features from the time-domain in the models used [43, 10].   In their work, Vallat and Walker analyzed the most important features for their model and found that time-related features, such as the time elapsed from the beginning of a recording, were among the top 20 most important features [43]. Although it remains unclear what additional information our pretrained models learn during fine-tuning, our method offers a promising avenue for future research into the interpretability of deep neural networks for sleep staging. There are several opportunities for future work that could build upon our findings. One promising direction is to explore the pretraining task in more detail, for example, by investigating the synthetic data generation process and the impact of changing the used frequency range.   Similar to previous work in the vision domain [3], it could also be promising to investigate which structural properties of synthetic time series are important for sleep staging.   This could be achieved by defining new pretraining tasks that are based on different data generation processes that incorporate more complex structures like desynchronized phases across channels, noise, or polymorphic amplitude variations.   Exploring such data generation processes may lead to a better understanding of what constitutes ‚Äúnatural‚Äù EEG time series and what information, besides the frequency content, is essential for sleep staging. In addition, we suggest exploring models with greater capacity and less inductive bias than the CNN-based architecture used in this work, such as transformer models [45, 6], which we expect to benefit even more from our pretraining method. Pretraining such models with synthetic data may alleviate their need for large amounts of training data [11]. Another avenue for future research is to investigate whether our pretraining method is beneficial for specific cohorts of subjects, such as patients with a specific disorder or specific age groups. Although we did investigate datasets with different demographics in this work, we did not perform detailed analyses of the impact of these demographics on model performance. Finally, it could be insightful to compare our approach with a broader range of SSL methods [32] and data augmentation strategies that employ synthetic EEG generators [31, 22]. To enable such comparisons and to facilitate future research in this direction, we make our code available online [19]. Our method presents a novel solution to address important issues that affect current deep learning models in the EEG time series domain, without requiring large amounts of patient data. We expect our approach to be advantageous in various applications where EEG data is scarce or derived from a limited number of subjects, such as brain‚Äìcomputer interfaces [30] or neurological disorder detection [44].  4   Materials and Methods  We trained deep neural networks in two phases: a pretraining phase based on synthetic data and a fine-tuning phase based on clinical sleep staging data. The training process is illustrated in Figure 1.  4.1   Phase 1: Pretraining with Synthetic Data  In the pretraining phase, we trained a deep neural network to predict the frequencies of randomly-generated synthetic time series (‚Äúfrequency pretraining‚Äù) [20].   The deep neural network consisted of a feature extractor to produce features and a classifier to predict which frequencies are present in the synthetic time series. Instead of training the model to predict the exact frequencies, we defined frequency ranges (frequency bins) and let the model identify the bins containing frequencies present in the signal (therefore turning the problem into a multi-label classification task).  4.1.1   Synthetic Data Generation  The   synthetic   samples   used   for   pretraining   consisted   of   a   time   series   signal  s ( t )   ‚àà   R 3 √ó 3000 , featuring 3 channels of 30 s sampled at 100 Hz, and an associated label vector   l .   The synthetic time series were created by summing sine waves with randomly sampled frequencies, while the label vector encoded from which frequency ranges (frequency bins) the frequencies were sampled. Since we wanted to test our method in the context of sleep staging, we followed the American Academy of Sleep Medicine (AASM) guidelines and focused on the spectral band between 0.3‚Äì35 Hz. This range was divided into 20 frequency bins on a base-2 logarithmic scale, resulting in a label vector   l   ‚àà { 0 ,   1 } 20  with binary entries for each bin that indicated whether frequencies in a given bin were present (1) or absent (0) in the time series.   To generate a synthetic time series, we first randomly selected a subset of the 20 frequency bins, setting the corresponding entries in the label vector   l   to 1 (each bin was selected with a probability of 50%). Next, we independently 9\n\nsampled frequencies from the selected bins for each channel and generated sine waves with these frequencies. The sine waves were then shifted by a random phase sampled from a uniform distribution between 0 and 2 œÄ , summed, and normalized to create the synthetic signal. Therefore, one channel   s c ( t ) of a synthetic signal   s ( t ) = ( s 1 ( t ) , s 2 ( t ) , s 3 ( t )) is defined as  s c ( t ) =  Àú s c ( t )   ‚àí   Œº c  œÉ c  ,   Àú s c ( t ) =  n f  X  i  I i   sin(2 œÄ tf c,i   +   œï i ) ,   I i   ‚àà U{ 0 ,   1 } ,   (1) where   t   denotes time (in seconds),   n f   denotes the number of frequency bins,   I i   denotes the indicator function encoding whether a frequency within a bin   i   is present (1) or not (0),   f c,i   denotes the frequencies of the sine waves (in Hertz),   œï i  denotes their phase (in radians), and   Œº c   and   œÉ c   denote mean and standard deviation of Àú s c .   Note that the phases   œï i   were sampled for each frequency bin independently but remained the same across channels to keep the data generation process simple, while the frequencies   f c,i   were sampled independently for each bin and channel. For each training run, we generated 101,000 synthetic samples, using 100,000 samples for training and the remaining 1000 samples as a validation set to track various metrics. The number of synthetic samples, frequency bins, and the logarithmic scale that defines the boundaries between the bins were determined through preliminary experiments where we explored a wide range of hyperparameters.  4.1.2   Model  We based our model on the TinySleepNet architecture, a conceptually simple deep neural network for sleep staging that has previously demonstrated competitive results [41]. This architecture consists of a convolutional feature extractor that extracts features from individual sleep epochs and a classifier that aggregates these feature across multiple epochs to perform sleep staging.   The feature extractor consisted of four convolutional layers with 128 filters each, a kernel size of 50, 8, 8, and 8, respectively, and a stride of 25, 1, 1, and 1, respectively. Following each convolutional layer was a batch normalization layer and a ReLU activation function. The outputs of the first and last convolutional layer were passed through max pooling layers that reduced the temporal dimension of the feature maps by a factor of 8 and 4, respectively. After both max pooling layers, we applied dropout with a dropout rate of 0.5. The feature extractor was followed by a classifier, which consisted of a dense layer with 80 neurons and ReLU activation function as well as a dense layer with 20 neurons and sigmoid activation function (i.e., one output for each frequency bin). We defined a threshold of 0.5 to determine whether a frequency from a frequency bin was present in the signal (output greater than 0.5) or not (output less than or equal to 0.5).  4.1.3   Pretraining for Frequency Prediction  We pretrained models for 20 training epochs using the Adam optimizer [29], a fixed learning rate of 10 ‚àí 4 , a batch size of 64, and a binary cross-entropy loss. This loss function is commonly employed for multi-label classification problems with one-hot encoded labels. It is defined as  L bce   =   ‚àí   1  N  1  n f N X  i =1  n f  X  j =1  y i,j   ¬∑   log(ÀÜ y i,j   ) + (1   ‚àí   y i,j   )   ¬∑   log(1   ‚àí   ÀÜ y i,j   ) ,   (2) where   N   is the number of samples,   n f   is the number of frequency bins,   y i,j   is the true one-hot encoded label of sample   i   and frequency bin   j , and ÀÜ y i,j   is the predicted one-hot encoded label of sample   i   and frequency bin   j . In addition to the loss function, we recorded the hamming metric on the training and validation data after each training epoch. This metric is derived from the hamming loss, a common metric for multi-label classification problems [40]. Specifically, the hamming metric tracks the fraction of correctly predicted frequency bins and is defined as  H   =   1  N  1  n f N X  i =1  n f  X  j =1  I { y i,j   =ÀÜ y i,j   } ,   (3) where   I   is the indicator function, which assumes the value 1 if the true one-hot encoded label   y i,j   of sample   i   and frequency bin   j   is equal to the predicted one-hot encoded label ÀÜ y i,j   of sample   i   and frequency bin   j .  4.2   Phase 2: Fine-Tuning with Sleep Staging Data  In the fine-tuning phase, we used the pretrained feature extractor of the pretraining phase for sleep stage classification on EEG and EOG data. Sleep stage classification is a multi-class classification problem where a short segment of EEG and EOG data (sleep epoch) is assigned to one of five sleep stages (Wake, N1, N2, N3, REM) based on the underlying brain activity. In our approach, the feature extractor of our model produced features from individual sleep epochs of EEG and EOG data. The extracted features were then concatenated over a sequence of multiple epochs and aggregated by a classifier to predict the sleep stage of the middle epoch in the input sequence (see Figure 1). By incorporating the surrounding sleep epochs into the classifier‚Äôs input, we provided additional temporal context, potentially enhancing the accuracy of sleep stage prediction. 10\n\n4.2.1   Sleep Staging Data  To test our approach, we used four publicly available datasets encompassing a diverse range of subjects, including both healthy individuals and those with various medical conditions such as sleep apnea, REM sleep behavior disorder, and affective disorders:   DODO [21], DODH [21], Sleep-EDFx [27, 34], and ISRUC [28].   The DODO and DODH datasets contain 55 recordings from subjects diagnosed with obstructive sleep apnea (OSA) and 25 recordings from healthy subjects, respectively. We combined the two datasets into a single dataset with 80 recordings, which we refer to as DODO/H. Each recording stems from a different subject and was split into 30-s non-overlapping windows (sleep epochs), which were annotated with sleep stages (Wake, N1, N2, N3, REM) by five sleep experts following the AASM guidelines [5]. We aggregated these five expert annotations into a consensus label for each sleep epoch using majority voting, with ties resolved by selecting the sleep stage determined by the most reliable scorer (defined as the scorer with the highest average agreement with all other scorers) [21]. Epochs that the consensus of the sleep experts annotated as artifacts were removed from the datasets. In our experiments, we focused on three EEG and EOG derivations available in both datasets and recommended by the AASM guidelines [5]: C3-M2, F3-M2, EOG1. All channels were sampled at 250 Hz. The   Sleep-EDFx   dataset   is   provided   on   the   PhysioNet   platform   [17]   and   contains 197 recordings from two studies [27, 34], of which we used the 153 recordings of the ‚ÄúSleep Cassette‚Äù study [34].   The recordings stem from 78 healthy subjects with two recordings per subject, except for subjects 13, 36, and 52, who have only one recording each due to technical issues. The recordings were split into 30-s sleep epochs and annotated with sleep stages (Wake, N1, N2, N3, N4, REM) according to the 1968 Rechtschaffen and Kales manual [38] by a single expert per recording. To be consistent with the annotations of the other datasets, we combined the N3 and N4 stages into a single N3 stage and removed data annotated as artifacts or movement.   Furthermore, we removed excess daytime data from the recordings by cropping them to begin 30 min before the first annotated non-Wake stage and end 30 min after the last annotated non-Wake stage. All available EEG and EOG channels (Fpz-Cz, Pz-Oz, EOG horizontal) were sampled at 100 Hz. The ISRUC dataset [28] contains 126 recordings and is divided into three subgroups. Subgroup one contains 100 recordings from 100 subjects suffering from various disorders affecting sleep (including OSA, REM disorder, affective disorder, snoring), subgroup two contains 16 recordings from 8 subjects diagnosed with OSA and snoring (2 recordings per subject), and subgroup three contains 10 recordings from 10 healthy subjects.   Due to technical issues, we excluded two recordings (recordings 8 and 100) from the first subgroup. All recordings were split into 30-s sleep epochs and annotated with sleep stages by two experts following the AASM guidelines [5]. We only used the annotations of the first expert and focused on the EEG and EOG channels C3-A2, F3-A2, and LOC-A2 sampled at 200 Hz. To prepare the data for training, we filtered the signals between 0.3 and 35 Hz with an 8th-order zero-phase Butterworth filter and downsampled the filtered signals to 100 Hz using polyphase filtering if necessary. We then normalized the amplitudes of each individual sleep epoch by subtracting the median and dividing the result by the interquartile range of its amplitude distribution. Finally, we clipped all signal amplitudes above 20 or below   ‚àí 20 to minimize outliers. After preprocessing, the three datasets (DODO/H, Sleep-EDFx, ISRUC) were split subject-wise into five folds for cross- validation. Note that we created a separate cross-validation split for each dataset, resulting in three different 5-fold cross- validation configurations. When splitting the DODO/H and the ISRUC datasets, we ensured that the recordings within each split were balanced in regard to the sub-datasets or subgroups. In addition to splitting the data into training and test folds, we reserved approximately 10% of the data from each fold as validation data for hyperparameter tuning and early stopping (i.e., one recording of DODO and DODH each, two subjects of Sleep-EDFx, and two recordings from the first subgroup of ISRUC for each fold). We validated our models on the validation data of the four training folds. The validation data of the test fold was kept separate and not involved in validation or testing to prevent data leakage.  4.2.2   Model  Since the sleep epochs used for fine-tuning had the same format as the synthetic data generated for pretraining (i.e., 3 channels with 30 s of data sampled at 100 Hz), we kept the architecture of the feature extractor unchanged. However, we replaced the classifier with a different architecture to predict sleep stages instead of frequency bins. The classifier was inspired by the TinySleepNet architecture [41] and consisted of a bidirectional Long-Short Term Memory (LSTM) [25] layer with a hidden size of 128, a dropout layer with a dropout rate of 0.5, and a dense layer with 5 neurons and softmax activation function.  4.2.3   Fine-Tuning for Sleep Stage Classification  We fine-tuned the models with training samples consisting of 11 sleep epochs that provided the classifier with context information from 5 epochs before and after the epoch to be classified.   To ensure that the model could use the same aggregation process for all sleep epochs of a recording, we padded the first and last five sequences of each recording with zeros to the full sequence length. Fine-tuning was performed using the Adam optimizer [29], a fixed learning rate of 10 ‚àí 4 , weight decay of 10 ‚àí 3 , a batch size of 32, and the categorical cross-entropy loss. To prevent overfitting, we limited each training run to a maximum of 50 training epochs and stopped training early if the macro F1 score on the validation data did not improve for 10 training epochs (early stopping).   Additionally, we clipped all gradients with a maximum norm greater than 5.0 to prevent exploding gradients. 11\n\nWe tracked model performance by recording the macro F1 score on the training and validation data after each training epoch. The macro F1 score is calculated as the average F1 score [42] across all sleep stages and is defined as  F 1   =  1  k  k X  i =1  2   ¬∑   p i   ¬∑   r i  p i   +   r i  ,   (4) where   k   is the number of sleep stages,   p i   is the precision of sleep stage   i , and   r i   is the recall of sleep stage   i . In all four training configurations (Fully Supervised, Fixed Feature Extractor, Fine-Tuned Feature Extractor, and Un- trained Feature Extractor), we performed training using the cross-validation scheme described in Section 4.2.1.   A single training run in this cross-validation scheme included both pretraining and fine-tuning where applicable. If not specified oth- erwise, all reported results were obtained on the test folds of the cross-validation splits, while the small part of the training data reserved for validation was used as early stopping set during fine-tuning. To ensure comparability between different training and data configurations, we seeded the model initialization, the synthetic data generation during pretraining, and the data subsampling when fine-tuning with a limited amount of training data.   This strategy reduced the influence of random initialization and data sampling on comparisons between training configurations. In particular, seeding ensured that models were fine-tuned with the same data across all training configurations in the few-sample and few-subject regimes.   Furthermore, when training with a reduced amount of data, we maintained a constant number of gradient updates per training epoch by duplicating each training sample   ‚åä   N N red   ‚åã   times, where   N   is the number of samples in the full training data and   N red   is the number of samples after reduction. Experiments were performed on an NVIDIA DGX A100 workstation with eight NVIDIA A100 GPUs and a Dell work- station with a single NVIDIA RTX A6000 GPU.  Author Contributions  Conceptualization, N.G. and S.B.; methodology, N.G.; software, N.G.; validation, N.G.; formal analysis, N.G.; investigation, N.G., S.M. and S.B.; resources, S.B.; data curation, N.G.; writing‚Äîoriginal draft preparation, N.G. and S.B.; writing‚Äîreview and editing, N.G., S.M. and S.B.; visualization, N.G. and S.B.; supervision, S.M. and S.B.; project administration, N.G. and S.B. All authors have read and agreed to the published version of the manuscript.  Funding  This research received no external funding.  Data Availability  The DODO and DODH datasets analyzed in the current study are described in Guillot et al. [21] and are publicly available (see   https://github.com/Dreem-Organization/dreem-learning-open   (accessed on 30 March 2023) for how to access the datasets). The Sleep-EDFx dataset is described in Kemp et al. [27] and Mourtazaev et al. [34] and is publicly available at  https://physionet.org/content/sleep-edfx/1.0.0/   (accessed on 30 March 2023). The ISRUC dataset is described in Khalighi et al. [28] and is publicly available at   https://sleeptight.isr.uc.pt/ (accessed on 13 April 2023). The source code necessary to reproduce our results is available on GitHub at   https://github.com/dslaborg/frequency-pretraining/ tree/full-paper-version   (accessed on 29 August 2025).  Acknowledgments  We are grateful to M. Rei√üel and V. Sander for providing us with computing resources.  Conflicts of Interest  The authors declare no conflicts of interest.  References  [1] D. Alvarez-Estevez. Challenges of applying automated polysomnography scoring at scale.   Sleep Med. Clin. , 18(3):277‚Äì 292, Sept. 2023. 12\n\n[2] H. Banville, O. Chehab, A. Hyv¬® arinen, D.-A. Engemann, and A. Gramfort. Uncovering the structure of clinical EEG signals with self-supervised learning.   J. Neural Eng. , 18:046020, Mar. 2021. [3] M. Baradad, J. Wulff, T. Wang, P. Isola, and A. Torralba.   Learning to see by looking at noise.   In M. Ranzato, A. Beygelzimer, Y. N. Dauphin, P. Liang, and J. W. Vaughan, editors,   Annu. Conf. on Neural Information Processing Systems, NeurIPS, Virtual, 6‚Äì14 December , pages 2556‚Äì2569, Red Hook, NY, USA, Dec. 2021. Curran Associates Inc. [4] A. Bardes, J. Ponce, and Y. LeCun. VICReg: Variance-invariance-covariance regularization for self-supervised learning. In   The Tenth Int. Conf. on Learning Representations, ICLR, Virtual, 25‚Äì29 April . OpenReview.net, 2022. [5] R. B. Berry, R. Brooks, C. E. Gamaldo, S. M. Harding, R. M. Lloyd, C. L. Marcus, and B. V. Vaughn.   The AASM manual for the scoring of sleep and associated events:   Rules, terminology and technical specifications, Version 2.6 . American Academy of Sleep Medicine, Darien, Illinois, 2020. [6] G. Brandmayr, M. M. Hartmann, F. F¬® urbass, G. Matz, M. Samwald, T. Kluge, and G. Dorffner.   Relational local electroencephalography representations for sleep scoring.   Neural Networks , 154:310‚Äì322, 2022. [7] M. M. Bronstein, J. Bruna, T. Cohen, and P. Velickovic.   Geometric deep learning: Grids, groups, graphs, geodesics, and gauges.   CoRR , abs/2104.13478, 2021. [8] F. P. Carrle, Y. Hollenbenders, and A. Reichenbach. Generation of synthetic EEG data for training algorithms supporting the diagnosis of major depressive disorder.   Front. Neurosci. , 17:1219133, 2023. [9] T. Chen, S. Kornblith, M. Norouzi, and G. E. Hinton. A simple framework for contrastive learning of visual represen- tations. In   Proc. 37th Int. Conf. on Machine Learning, ICML 2020, Virtual, 13‚Äì18 July , volume 119 of   Proceedings of Machine Learning Research , pages 1597‚Äì1607. PMLR, 2020. [10] M. J. V. D. Donckt, J. V. D. Donckt, E. Deprost, N. Vandenbussche, M. Rademaker, G. Vandewiele, and S. V. Hoecke. Do not sleep on traditional machine learning: Simple and interpretable techniques are competitive to deep learning for sleep scoring.   Biomed. Signal Process. Control. , 81:104429, 2023. [11] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly, J. Uszkoreit, and N. Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. In  Int. Conf. on Learning Representations, ICLR, Vienna, Austria, 3‚Äì7 May , 2021. [12] A. Ebbehoj, M. √ò. Thunbo, O. E. Andersen, M. V. Glindtvad, and A. Hulman. Transfer learning for non-image data in clinical research: A scoping review.   PLOS Digital Health , 1(2):e0000014, Feb. 2022. [13] E. Eldele, M. Ragab, Z. Chen, M. Wu, C.-K. Kwoh, and X. Li. Self-supervised learning for label-efficient sleep stage classification: A comprehensive evaluation.   IEEE T. Neur. Sys. Reh. , 31:1333‚Äì1342, 2023. [14] L. Fiorillo, G. Monachino, J. van der Meer, M. Pesce, J. D. Warncke, M. H. Schmidt, C. L. A. Bassetti, A. Tzovara, P. Favaro, and F. D. Faraci. U-Sleep‚Äôs resilience to AASM guidelines.   npj Digit. Medicine , 6:33, 2023. [15] L. Fiorillo, A. Puiatti, M. Papandrea, P.-L. Ratti, P. Favaro, C. Roth, P. Bargiotas, C. L. Bassetti, and F. D. Faraci. Automated sleep scoring: A review of the latest approaches.   Sleep Med. Rev. , 48:101204, 2019. [16] M. Gaiduk, A. Serrano Alarc¬¥ on, R. Seepold, and N. Mart¬¥ ƒ±nez Madrid. Current status and prospects of automatic sleep stages scoring: Review.   Biomed. Eng. Lett. , 13(3):247‚Äì272, July 2023. [17] A. L. Goldberger, L. A. N. Amaral, L. Glass, J. M. Hausdorff, P. C. Ivanov, R. G. Mark, J. E. Mietus, G. B. Moody, C.-K. Peng, and H. E. Stanley. PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals.   Circulation , 101(23), June 2000. [18] I. J. Goodfellow, Y. Bengio, and A. C. Courville.   Deep Learning . Adaptive computation and machine learning. MIT Press, Cambridge, Massachusetts, 2016. [19] N. Grieger. Source code of the model presented in Grieger et al., ‚ÄúData-efficient sleep staging with synthetic time series pretraining‚Äù.   https://github.com/dslaborg/frequency-pretraining , 2024. [20] N. Grieger, S. Mehrkanoon, and S. Bialonski. Pretraining sleep staging models without patient data. In   Int. Conf. on Learning Representations (ICLR), Workshop on Learning from Time Series For Health, Vienna, Austria, 7‚Äì11 May , Vienna, Austria, 2024. [21] A. Guillot, F. Sauvet, E. H. During, and V. Thorey.   Dreem open datasets:   Multi-scored sleep datasets to compare human and automated sleep staging.   IEEE T. Neur. Sys. Reh. , 28(9):1955‚Äì1965, Sept. 2020. 13\n\n[22] A. G. Habashi, A. M. Azab, S. Eldawlatly, and G. M. Aly.   Generative adversarial networks in EEG analysis:   An overview.   J. NeuroEng. Rehabil. , 20(1):40, Apr. 2023. [23] C. He, J. Liu, Y. Zhu, and W. Du. Data augmentation for deep neural networks model in EEG classification task: A review.   Front. Hum. Neurosci. , 15:765525, Dec. 2021. [24] K. He, X. Zhang, S. Ren, and J. Sun. Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification. In   2015 IEEE Int. Conf. on Computer Vision, ICCV 2015, 7‚Äì13 December , pages 1026‚Äì1034, Santiago, Chile, Dec. 2015. IEEE Computer Society. [25] S. Hochreiter and J. Schmidhuber. Long short-term memory.   Neural Comput. , 9:1735‚Äì1780, Nov. 1997. [26] H. Kataoka, K. Okayasu, A. Matsumoto, E. Yamagata, R. Yamada, N. Inoue, A. Nakamura, and Y. Satoh. Pre-training without natural images.   Int. J. Comput. Vis. , 130(4):990‚Äì1007, 2022. [27] B. Kemp, A. H. Zwinderman, B. Tuk, H. A. C. Kamphuisen, and J. J. L. Oberye. Analysis of a sleep-dependent neuronal feedback loop: The slow-wave microcontinuity of the EEG.   IEEE Trans. Biomed. Eng. , 47(9):1185‚Äì1194, 2000. [28] S. Khalighi, T. Sousa, J. M. dos Santos, and U. Nunes.   ISRUC-Sleep:   A comprehensive public dataset for sleep researchers.   Comput. Methods Programs Biomed. , 124:180‚Äì192, 2016. [29] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. In Y. Bengio and Y. LeCun, editors,   3rd Int. Conf. Learning Representations, ICLR , San Diego, CA, USA, May 2015. [30] W. Ko, E. Jeon, S. Jeong, J. Phyo, and H.-I. Suk. A survey on deep learning-based short/zero-calibration approaches for EEG-based brain-computer interfaces.   Front. Hum. Neurosci. , 15:643386, May 2021. [31] E. Lashgari, D. Liang, and U. Maoz. Data augmentation for deep-learning-based electroencephalography.   J. Neurosci. Meth. , 346:108885, Dec. 2020. [32] Z. Liu, A. Alavi, M. Li, and X. Zhang. Self-supervised contrastive learning for medical time series: A systematic review.  Sensors , 23(9):4221, 2023. [33] S. Motamedi-Fakhr, M. Moshrefi-Torbati, M. Hill, C. M. Hill, and P. R. White. Signal processing techniques applied to human sleep EEG signals ‚Äî A review.   Biomed. Signal Process. Control. , 10:21‚Äì33, 2014. [34] M. S. Mourtazaev, B. Kemp, A. H. Zwinderman, and H. A. C. Kamphuisen. Age and gender affect different characteristics of slow waves in the sleep EEG.   Sleep , 18(7):557‚Äì564, Sept. 1995. [35] I. Obeid and J. Picone. The Temple University hospital EEG data corpus.   Front. Neurosci. , 10:196, May 2016. [36] H. Phan and K. Mikkelsen.   Automatic sleep staging of EEG signals:   Recent development, challenges, and future directions.   Physiol. Meas. , 43(4):04TR01, Apr. 2022. [37] Y. Qiu, F. Lin, W. Chen, and M. Xu. Pre-training in medical data: A survey.   Mach. Intell. Res. , 20(2):147‚Äì179, Feb. 2023. [38] A. Rechtschaffen, A. Kales, R. Berger, W. Dement, A. Jacobson, L. Johnson, M. Jouvet, L. Monroe, I. Oswald, H. Rof- fwarg, B. Roth, and R. Walter.   A Manual of Standardized Terminology, Techniques and Scoring System for Sleep Stages of Human Subjects . Public Health Service, U.S. Government Printing Office, Washington, D.C., 1968. [39] Y. Roy, H. Banville, I. Albuquerque, A. Gramfort, T. H. Falk, and J. Faubert. Deep learning-based electroencephalog- raphy analysis: A systematic review.   J. Neural Eng. , 16:051001, 2019. [40] M. Sokolova and G. Lapalme.   A systematic analysis of performance measures for classification tasks.   Inf. Process. Manag. , 45(4):427‚Äì437, 2009. [41] A. Supratak and Y. Guo. TinySleepNet: An efficient deep learning model for sleep stage scoring based on raw single- channel EEG. In   42nd Annual Int. Conf. of the IEEE Engineering in Medicine & Biology Society, EMBC 2020 , pages 641‚Äì644, Montreal, QC, Canada, July 2020. IEEE. [42] A. Tharwat. Classification assessment methods.   Appl. Comput. Inform. , 17(1):168‚Äì192, 2021. [43] R. Vallat and M. P. Walker. An open-source, high-performance tool for automated sleep staging.   eLife , 10:e70092, Oct. 2021. [44] H. van Dijk, G. van Wingen, D. Denys, S. Olbrich, R. van Ruth, and M. Arns. The two decades brainclinics research archive for insights in neurophysiology (TDBRAIN) database.   Sci. Data , 9(1):333, June 2022. 14\n\n[45] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin. Attention is all you need. In I. Guyon, U. von Luxburg, S. Bengio, H. M. Wallach, R. Fergus, S. V. N. Vishwanathan, and R. Garnett, editors,   Annu. Conf. Neural Information Processing Systems, NeurIPS, 4‚Äì9 December , pages 5998‚Äì6008, Red Hook, NY, USA, 2017. Curran Associates Inc. [46] Z. You, Y. Guo, X. Zhang, and Y. Zhao. Virtual electroencephalogram acquisition: A review on electroencephalogram generative methods.   Sensors , 25(10):3178, May 2025. [47] G.-Q. Zhang, L. Cui, R. Mueller, S. Tao, M. Kim, M. Rueschman, S. Mariani, D. Mobley, and S. Redline. The national sleep research resource: Towards a sleep data commons.   J. Am. Med. Inform. Assn. , 25(10):1351‚Äì1358, May 2018. 15",
    "Sleep Staging from Electrocardiography and Respiration with Deep Learning  Haoqi Sun, PhD 1 , Wolfgang Ganglberger, MSc 1 , Ezhil Panneerselvam, MD 1 , Michael J. Leone, MSc 1 , Syed A. Quadri, MD 1 , Balaji Goparaju, MSc 1 , Ryan A. Tesh, BS 1 , Oluwaseun Akeju, MD 2 , Robert J. Thomas, MD 3 , M. Brandon Westover, MD, PhD 1  1   Department of Neurology, Massachusetts General Hospital, Boston, MA, USA  2   Department of Anesthesia, Critical Care and Pain Medicine, Massachusetts General Hospital, Boston, MA, USA  3   Division of Pulmonary, Critical Care & Sleep, Department of Medicine, Beth Israel Deaconess Medical Center, Boston, MA, USA  Abstract  Study Objective : Sleep is reflected not only in the electroencephalogram but also in heart rhythms and breathing patterns. Therefore, we hypothesize that it is possible to accurately stage sleep based on the electrocardiogram (ECG) and respiratory signals.  Methods : Using a dataset including 8,682 polysomnographs, we develop deep neural networks to stage sleep from ECG and respiratory signals. Five deep neural networks consisting of convolutional networks and long short-term memory networks are trained to stage sleep using heart and breathing, including the timing of R peaks from ECG, abdominal and chest respiratory effort, and the combinations of these signals.  Results : ECG in combination with the abdominal respiratory effort achieve the best performance for  staging all five sleep stages with a Cohen‚Äôs kappa of 0.600   (95% confidence interval 0.599   ‚Äì   0.602); and 0.762 (0.760   ‚Äì   0.763) for discriminating awake vs. rapid eye movement vs. non-rapid eye movement sleep. The performance is better for young participants and for those with a low apnea-hypopnea index, while it is robust for commonly used outpatient medications.  Conclusions : Our results validate that ECG and respiratory effort provide substantial information about sleep stages in a large population. It opens new possibilities in sleep research and applications where electroencephalography is not readily available or may be infeasible, such as in critically ill patients.  Keywords  Deep Learning; Electrocardiography; Respiration; Sleep Stages\n\n1  Introduction  Characterizing   sleep   has   primarily   relied   on   the   analysis   of   the   electroencephalogram   (EEG), supplemented by the electrooculogram and chin electromyogram   1 . Three distinct states are readily discernable through such analysis: wake, rapid eye movement sleep (REM) and non-REM sleep (NREM)  1 . Three stages of progressive depth (N1, N2, and N3) can be differentiated in NREM   1 . EEG slow-wave oscillations (about 1   ‚Äì   4Hz) dominate deeper NREM sleep, while sleep spindles (about 10   ‚Äì   13 Hz) and theta wave oscillations (about 4   ‚Äì   8Hz) dominate lighter NREM sleep   1 .  Cortical, subcortical, and brainstem systems are highly interactive throughout sleep   2-6 , and their activity couples autonomic activity with the cortical activity measurable by EEG. Examples include strong sinus arrhythmia   3 , blood pressure dipping   7 , and stable breathing or stable flow-limitation   8 . REM sleep is characterized by highly recognizable respiratory rate and tidal volume fluctuations, and by surges in heart rate and blood pressure   9 . Wake demonstrates dominance of low-frequency heart rate variability and large amplitude movements. These observations suggest that accurate sleep staging might be possible from non-EEG signals influenced by the autonomic nervous system, such as the ECG or respiratory signals.  An accurate non-EEG method for staging state characterization would have several advantages. For example,   the   ECG   is   recorded   continuously   in   numerous   medical   and   situations,   especially   in hospitalized patients. Wearable devices increasingly measure ECG and respiration   10-12 . Cardiorespiratory signals may be obtainable in a number of ways, including contact recordings such as Withings, ballistocardiogram   13 , or non-contact radar-type applications such as EarlySense   14 , and SleepScore   15 , etc. On the other hand, EEG can be highly abnormal in medically ill populations, making standard analysis difficult   16 .  Deep learning approaches can be used to accurately estimate sleep states. We previously showed that deep neural networks can learn to score conventional sleep stages based on EEG signals obtained during overnight PSG with an accuracy of 87.5 % and a Cohen‚Äôs kappa of 0.805 , comparable to the performance of human sleep scoring experts   17 . Here we develop deep neural networks using ECG and/or respiratory signals to classify sleep stages. Our approach is based on convolutional neural network (CNN) in combination with long-short term memory (LSTM) recurrent neural network. It is trained on a large clinical dataset, which also accounts for patient heterogeneity, spanning a wide range of ages, medications and sleep disorders.  Methods  Dataset  The Partners Institutional Review Board approved retrospective analysis of polysomnograms (PSG), acquired in the Sleep Laboratory at Massachusetts General Hospital from 2009 to 2016, without requiring additional consent for use in this study. PSGs were recorded adhering to American Academy of Sleep Medicine (AASM) standards. Each PSG includes one ECG channel and two respiratory effort channels recorded from chest and abdomen belts. The sampling frequency is 200 Hz for all signals. The dataset contains three major types of sleep tests: diagnostic, full-night continuous positive airway\n\n2  pressure (CPAP), and split-night CPAP. PSGs were annotated in 30-second non-overlapping epochs according to AASM standards as one of the five stages: wake (W), non-REM stage 1 (N1), non-REM stage 2 (N2), non-REM stage 3 (N3), and rapid eye movement (REM). Seven sleep technicians in total annotated the dataset, with one technician per PSG.  The entire dataset includes 10,121 PSGs; 9,644 were exported successfully without time mismatch or missing sleep stage annotations. We included atrial fibrillation cases because the deep learning network is supposed to work with heterogeneous data. We excluded PSGs with fewer than 100 artifact-free 30- second epochs, resulting in 8,682 PSGs. The dataset is summarized in   Table 1 .  Table 1 . Dataset Summary.  Characteristics   Value  Number of PSGs   8,682  Number of patients   7,208  Age: year, median (IQR)   53 (41   ‚Äì   63)  Sex: number (percentage of all patients)  Female   2,997 (41.6%)  Male   4,189 (58.1%)  Unknown due to human error   22 (0.3%)  BMI: kg/m 2 , median (IQR)   31 (27   ‚Äì   36)  Type of Test: number (percentage of all patients)  Diagnostic   3,571 (49.5%)  All night CPAP   1,751 (24.3%)  PSG split night   1,798 (24.9%)  Extended EEG-sleep montage   76 (1.1%)  Bedside   9 (0.1%)  Research   3 (0.04%)  Apnea-Hypopnea Index (AHI, events / hour) : number (percentage of all patients)  Normal (AHI < 5)   2,879 (39.9%)  Mild (5 ‚â§ AHI < 15)   1,995 (27.7%)  Moderate (15 ‚â§ AHI < 30)   1,468 (20.4%)  Severe (AHI ‚â• 30)   866 (12.0%)  Respiratory Disturbance Index (RDI, events / hour)   15.0 (5.8   ‚Äì   28.4)  Periodic Limb Movement Index (PLMI, events / hour)   10.4 (3.1   ‚Äì   28.3)  Outpatient Medication Listing, by Category  Systemic   4523 (62.7%)  Hypertension   2755 (38.2%)  Sleeping   2187 (30.3%)  Antidepressant   1874 (26.0%)  Neuroactive   1365 (18.9%)  Benzodiazepine   1297 (18.0%)  Diabetic   802 (11.1%)  RLS/PLMS   688 (9.5%)  Opiate   548 (7.6%)  Z-drug   348 (4.8%)  Stimulant   310 (4.3%)\n\n3  Preprocessing  Sleep staging was done in 30-second epochs following AASM standards. However, changes in heart rhythms and respiration often occur over longer time scales. For this reason, and to provide contextual information, our deep neural networks used information extending 120 seconds on both sides of each 30-second epoch, creating a 270-second epoch (4.5min, nine 30-second epochs) centered on each 30- second epoch to be scored. The goal of the deep neural networks presented herein is to classify the sleep stage of the middle 30-second epoch using information from the 270-second epoch. This is illustrated in Figure S1 in the supplementary material.  When using ECG as the input, we identified 270-second epochs with amplitude larger than 6mV or standard deviation smaller than 5 Œº V, as they are not physiologically possible. In each 270-second epoch we extracted timings of R peaks   18   and converted the ECG to a binary sequence, where R peaks are  indicated by a ‚Äú 1 ‚Äù   and all other points   indicated by ‚Äú 0 ‚Äù . The 270-second epochs with spurious R peaks were identified using the ADARRI   19   method. 270-second epochs with less than 20 R peaks per minute were also identified, as they are not physiologically possible. About 25% of the 270-second epochs were identified as artifact. In total, there were 5,964,359 270-second epochs.  When using chest and abdominal respiratory effort as the input, 270-second epochs with amplitude larger than   6mV or standard deviation smaller than 10ŒºV were identified. Respiratory signals were  down-sampled to 10Hz. About 10% of the 270-second epochs were identified as artifact. In total, there were 6,847,246 270-second epochs for the chest signal; and 6,749,286 270-second epochs for the abdominal signal.  When using pairs of signals as the input, the 270-second epochs where any signal modality that meet the above criteria are identified as artifact. In any of above cases, the artifactual 270-second epochs were removed when training CNN, and remained when training LSTM to preserve the temporal context.  Deep Network Architecture  We trained five deep neural networks based on the following input signals and their combinations: 1) ECG; 2) CHEST (chest respiratory effort); 3) ABD (abdominal respiratory effort); 4) ECG+CHEST; and 5) ECG+ABD. Each deep neural network contained a feed-forward convolutional neural network (CNN) which learned features pertaining to each epoch, and a recurrent neural network (RNN), in this case long-short term memory (LSTM), to learn temporal patterns among consecutive epochs.  The CNN of the network is similar to that in Hannun et al.   20 . As shown in   Figure 1 A and   Figure 1 B, the network for a single type of input signal, i.e. ECG, CHEST or ABD, consists of a convolutional layer, several residual blocks and a final output block. For a network with both ECG and CHEST/ABD as input signals ( Figure 1 C), we first fixed the weights of the layers up to the 9 th   residual block (gray) for the ECG network and similarly fixed up to the 5 th   residual block (gray) for the CHEST/ABD network, concatenated the outputs, and then fed this concatenation into a subnetwork containing five residual blocks and a final output block. The numbers of fixed layers were chosen so that the outputs of layers from different modalities have the same shape (after padding zeros), and were then concatenated.  The LSTM of the network has the same structure for different input signals. It is a bi-directional LSTM, where the context cells from the forward and backward directions are concatenated. For the network\n\n4  with ECG as input, the LSTM has two layers with 20 hidden nodes in each layer. For CHEST and ECG+CHEST, the LSTM has three layers with 100 hidden nodes in each layer. For ABD and ECG+ABD, the LSTM has two layers with 100 hidden nodes in each layer. The number of LSTM layers, number of hidden nodes, and dropout rate were determined by the method described in the next subsection.  Figure 1 . Deep neural network architecture.   (A and B)   CNN architecture using ECG, or CHEST or ABD as input. The numbers between blocks are the shapes of the output for each input 270-second epoch. For  example, ‚Äú320√ó4‚Äù means 320 channels and four time points. ‚Äú17@64‚Äù in the convolution layers means  kernel size 17 points and 64 kernels. The repetition number of the residual blocks (Res Block) is marked above each block. Arrows indicate the flow of network activations.   (C)   The CNN architecture when using multiple signals as input. Gray blocks mean their weights are obtained from network trained in (A) and (B), then fixed during training the network.   (D)   RNN architecture, which uses the output from the CNN from every 270-second epoch (corresponding to a 30-second epoch). The output is fed into a bidirectional LSTM, followed by concatenation of the activations from both directions, and finally into a dense layer. The legends on the right show the detailed structure of the residual block and final output block. Inside each residual block, the first convolution layer subsamples the input by 4 (stride = 4) and the max pooling skip-layer connection also subsamples the input by 4.  Training and Evaluating the Network  We randomly split the PSGs into a training set of 6,682 PSGs, a validation set of 1,000 PSGs and a testing set of 1,000 PSGs. Due to the large amount of data, we expect the random split should give similar distribution of the variables across these sets. We first trained the CNN, then the LSTM using the outputs from the CNN. The objective function of both CNN and LSTM is cross-entropy, a measure of the distance between two categorical distributions for classification. The networks were trained with a mini- batch size of 32, maximum epochs of 10, and learning rate 0.001 (as commonly used in deep learning). The LSTM was trained using sequences of 20 epochs (10min). We set the number of LSTM layers, number of hidden nodes, and the dropout rate as the combination that minimizes the objective function on the validation set.\n\n5  Some sleep stages occur more frequently than others. For example, people spend about 50% of sleep in N2 and 20% in N3. To prevent the network from simply learning to report the dominant stage, we weighed each 270-second input signal in the objective function by the inverse of the number of epochs in each sleep stage within the training set.  For the   performance metrics on the testing set, we used confusion matrices and Cohen‚Äôs kappa. We  show performance for staging five sleep stages according to the AASM standards (W, N1, N2, N3, R), and we additionally collapse these stages into 3 sleep super-stages, in two different ways. The first set of super- stages is ‚Äúawake or drowsy‚Äù (W+N1) vs. ‚Äúsleep‚Äù (N2+N3) vs. ‚ÄúREM sleep‚Äù (R), and The second set  of super- stages is ‚Äúawake‚Äù (W) vs. ‚ÄúNREM sleep‚Äù (N1+N2+N3) vs. ‚ÄúREM sleep‚Äù (R). We obtained 95%  confidence intervals for kappa values by bootstrapping (sample with replacement) 1,000 times.  Results  Overall Staging Performance  In   Figure 2 , we show the confusion matrices for predicting all five sleep stages with different input signals. Using both ECG and ABD as input signals yields the best prediction results on the testing set. This network is correct in 81.8% of wake, 55.8% of N1, 66.3% of N2, 66.6% of N3 and 92.2% of REM epochs. Most misclassifications are found between W vs. N1, N1 vs. N2, and N2 vs. N3. For example, 31% of N3 epochs are misclassified as N2, and 34% of N1 epochs are misclassified as either W or N2. This limitation is reduced when grouping the sleep stages as in   Figure 3   and   Figure 4 , so that both epochs of REM and NREM can be classified correctly with greater than 80% accuracy.\n\n6  Figure 2 . Five-stage classification confusion matrices, comparing staging by sleep technicians vs. network predictions on the 1000-PSG testing set for different input signals. Each row in the confusion matrix is the sleep stage annotated by the technician, while each column is the network prediction. The numbers are percentages.  Figure 3 . Three-stage classification confusion matrices, comparing staging by sleep technicians vs. network predictions on the 1000-PSG testing set for different input signals. The 3   ‚Äúsuper -stages ‚Äù here  are:   ‚Äúawake or drowsy‚Äù (W+N1) vs. ‚Äúsleep‚Äù (N2+N3) vs. ‚ÄúREM sleep‚Äù (R ).  Figure 4 . Three-stage classification confusion matrices, comparing staging by sleep technicians vs. network predictions on the 1000-PSG testing set for different input signals. The 3   ‚Äúsuper -stages ‚Äù here  are:   ‚Äúawake‚Äù (W) vs. ‚ÄúNREM sleep‚Äù (N1+N2+N3) vs. ‚ÄúREM sleep‚Äù (R).\n\n7  For every choice of input signal, we calculated   Cohen‚Äôs kappa , a statistic for assessing inter-reader agreement, and the corresponding 95% confidence intervals. These are shown in   Table 2 . ECG+ABD has the highest kappa, with values of 0.6 (all five stages), 0.74 (W+N1 vs. N2+N3 vs. REM) and 0.762 (Wake vs. NR vs. REM). Since the testing set has 1,000 PSGs (6.6√ó10 5   30-second epochs), the confidence interval is narrow. Therefore the differences between kappa values are all significant at 0.05 level.  Table 2 . Cohen‚Äôs kappa on the 1000 -PSG testing set using different input signals.  Input   S ignal   5 Stages   3 Stages  W+N1 vs. N2 +N3 vs. R   W vs. NR vs. R  ECG   0.494 (0.492   ‚Äì   0.495)   0.649 (0.647   ‚Äì   0.65)   0.649 (0.647   ‚Äì   0.651)  CHEST   0.565 (0.563   ‚Äì   0.566)   0.708 (0.707   ‚Äì   0.709)   0.707 (0.706   ‚Äì   0.709)  ABD   0.579 (0.578   ‚Äì   0.581)   0.725 (0.723   ‚Äì   0.726)   0.738 (0.736   ‚Äì   0.739)  ECG + CHEST   0.506 (0.504   ‚Äì   0.507)   0.648 (0.646   ‚Äì   0.65)   0.661 (0.659   ‚Äì   0.663)  ECG + ABD   0.600 (0.599   ‚Äì   0.602)   0.740 (0.738   ‚Äì   0.741)   0.762 (0.76   ‚Äì   0.763)  Staging Performance on Different Groups of Participants  In   Table 3 , we   show Cohen‚Äôs kappa   for different population groups in the testing set using ECG+ABD as the input signals. Kappa is lower in the elderly ( ‚â• 60 years) and   in people with higher Apnea-Hypopnea Index (AHI), compared to the respective control groups. Split-night studies have lower kappa values than diagnostic or CPAP nights due to different patterns before and after applying CPAP. Note again that due to the large number of epochs in the testing set, confidence intervals are narrow, and all comparisons are statistically significant at 0.05 level.   The Cohen‚Äôs kappa for different population   groups in the testing set using other input signals are shown in Table E1-E4 in the supplementary material.  While performance is reduced with increasing AHI, the network still achieves Cohen‚Äôs kappa of   0.574 for five stages; and more than 0.7 for three super-stages for severe apnea. We interpret this to mean that either autonomic features characteristic of stages are independent of sleep apnea, or more likely, that the network has learned normal, apneic, and other pathological patterns of the respiration signals change according to sleep stage.   For example, REM and NREM interruptions in breathing may have distinct distributions of features such as event duration.  Table 3 . Cohen‚Äôs kappa in different groups in the 1000 -PSG testing set using ECG + ABD as input.  Category   Group   5 stages  3 stages  W+N1 vs.  N2+ N3 vs. R   W vs. NR vs. R  Age  Young: 18 ‚â§ Age < 40   0.622   0.760   0.773  Middle: 40 ‚â§ Age < 60   0.598   0.736   0.761  Old: Age ‚â• 60   0.576   0.713   0.742  Sex   Male   0.594   0.728   0.755  Female   0.602   0.746   0.763  BMI (kg/m 2 )   Normal: 18.5 ‚â§ BMI < 25   0.613   0.737   0.752  Overweight: BMI ‚â• 25   0.596   0.736   0.760  Type of Test   Diagnostic   0.600   0.738   0.756  All Night CPAP   0.608   0.758   0.770\n\n8  Split Night   0.584   0.707   0.752  AHI (per hour)  Normal: AHI < 5   0.608   0.760   0.773  Mild: 5 ‚â§ AHI < 15   0.604   0.746   0.750  Moderate: 15 ‚â§ AHI < 30   0.600   0.733   0.752  Severe: AHI ‚â• 30   0.574   0.717   0.742  Periodic limb movement (per hour)  Normal: PLM < 5   0.606   0.736   0.765  Mild: 5 ‚â§ PLM < 15   0.600   0.746   0.767  Moderate: 15 ‚â§ PLM < 30   0.600   0.733   0.752  Severe: PLM ‚â• 30   0.574   0.717   0.742  Medication  Antidepressant   0.588   0.736   0.756  Benzodiazepine   0.602   0.750   0.761  Diabetic   0.589   0.757   0.770  Herbal   0.596   0.745   0.743  Hypertension   0.595   0.732   0.758  Neuroleptic   0.588   0.716   0.749  Opiate   0.600   0.721   0.766  Neuroactive   0.598   0.736   0.762  Systemic   0.599   0.740   0.766  RLS/PLMS   0.608   0.755   0.773  Sleeping   0.610   0.750   0.763  Stimulant   0.603   0.740   0.774  Z-drug   0.627   0.765   0.774  Staging Performance on Individual PSGs  In   Figure 5 , we   show the histogram of Cohen‚Äôs kappa   of each individual PSG using both ECG and ABD as input. The results indicate a fair amount of heterogeneity between PSGs, where the lowest extreme has negative kappa values around -0.1 and the highest extreme has kappa values around 0.9. In Figure S2 in the supplementary material, we show the   Cohen‚Äôs kappa of each individual PSG using all signal types.  Figure 5 . Histogram of   Cohen‚Äôs kappa values for individual PSGs using both ECG and ABD as input. The  distributions are right-skewed.\n\n9  Dependence on temporal precision of R-peak timing in the ECG  In face of signal noise, the deep learning network should learn robust patterns of the ECG R peak time series. To validate its robustness to signal noise, we simulated noise that preserves the mean but corrupts higher order pattern of the ECG R peaks. In Figure S3 of the supplementary material, we can see that adding zero-mean Gaussian jitter to the R peaks causes performance to drop progressively as the standard deviation of the jitter increases.  Signal Examples  To gain some insight into the differences in breathing and heart rhythms that the deep neural network is using to distinguish sleep stages, we show some example whole night recordings from the 1000-PSG testing set in   Figure 6 ,   Figure 7 , and   Figure 8 . These examples are selected as ‚Äútypical‚Äù, meaning that  the y have the closest Cohen‚Äôs kappa   compared to the overall kappa across the testing set. The 60- second signal examples in Panel C are the signals where the deep neural network assigns the highest probability to the correct sleep stage within the recording. We can see a visible correspondence between the spectrogram and the sleep stages, as well as the mismatch between the spectrogram and EEG-based sleep stage. For example, in   Figure 8 , around 2 hours and 4.5 hours, the spectrogram of heart rate variability shows loss of very low frequency power, which is classified by the network as N3, but the EEG-based sleep stages contain both N2 and N3. More illustrations of the trained deep neural networks are shown in Figure S4-S12 of the supplementary material.  Figure 6 . An example 47-year male.   (A)   The sleep stages over the whole night annotated by the technician (hypnogram).   (B)   The predicted sleep stages from the deep neural network using ABD respiration as input.   (C)   Example 60-second ABD segment from each sleep stage which is correctly classified and has the highest predicted probability of that stage. Different colors correspond to the triangle markers on other panels, which indicate the location of the example in the whole night recording. The number above each example signal indicates the probability of being that stage as\n\n10  predicted by the deep learning network.   (D)   The spectrogram of the ABD respiratory signal. The y-axis indicates the frequency.  Figure 7 . Similar to   Figure 6 , showing an example 42-year female using CHEST respiration as input. The scaling of the signals in Panel C is the same as in   Figure 6 , but amplitude of these example signal itself happens to be smaller. It is possible that other epochs have larger or similar amplitude compared to  Figure 6 .  Figure 8 . Similar to   Figure 6 , showing an example 39-year female using the R peaks from ECG as input. Panel C shows the R peaks represented as a binary sequence (see Methods). Panel D shows the spectrogram of the R peak intervals   21 .\n\n11  Discussion  We hypothesize that it is possible to accurately stage sleep based on the electrocardiogram (ECG) and respiratory signals using deep learning. Our key findings are: 1) ECG and respiratory signals contain substantial information about sleep stages; 2) reduced staging accuracy is associated with older age and/or more severe sleep apnea, although the networks still perform well on signals from patients with advanced age and high AHI; 3) using deep learning, the staging performance is robust for a wide range of typical sleep disorders like OSA and PLMS, and commonly used medications; 4) collapsing certain stages of sleep/wake (e.g., N1 with wake and N2 with N3) results in greater staging agreement.  Previous studies comparable to ours are summarized in   Table 4 . Some prior studies have also sought to stage sleep from ECG and respiration using deep neural networks. However, these studies suffered from small sample sizes and limiting generalizability. Only one prior study used more than 100 participants for training and evaluation. The large sample size of training and testing sets in the present study provides more robust results compared to prior literature, and is expected to increase generalizability when applied to heterogeneous / external populations.  Table 4 .   Related work in the literature.  Author  (year)   Dataset size   Performance  ( Œ∫ is Cohen‚Äôs kappa )   Type of Signal   Features  Sady et al.  2013   12  13  participants  3 stages (W, NREM, REM):  accuracy=78%  5 stages (W, N1, N2, N3, REM):  accuracy=62%  Photo -  Plethysmogram,  hemoglobin oxygen  saturation,  pneumotachograph  Heartbeat  interval, time  domain  respiratory  signals.  Long et al.  2014   22  48  participants  3 stages (W, NREM, REM):  Œ∫ =0.48  4 stages (W, light sleep, deep  sleep, REM):   Œ∫   =0.41  Respiratory effort  Time domain,  dissimilarity  measure  Fonseca et  al.  2015   23  48  participants  4 stages (W, light sleep, deep  sleep, REM):   Œ∫ =0.49,  accuracy=69%  3 stages (W, NREM, REM):  Œ∫ =0.56  Accura cy=80%  ECG + Respiratory  inductance  plethysmography  Time and  frequency  domain,  nonlinear  Zhao et al.  2017   24  25  participants,  100 nights  4 stages (W, N1+N2, N3, REM):  Œ∫ =0.70,  accuracy=79.8%  Radio frequency  signal reflected off  body (heartbeat,  respiration)  Radio  frequency  spectrogram  Zhang et al.  2017   25  37,000  epochs  5 stages (W, N1, N2, N3, REM):  Precision = 53.9%  Re call = 56.0%  F1 score = 53.2%  Heart rate derived  from a wearable  device  Frequency  domain  (DCT)\n\n12  Radha et al.  2018   26  ECG: 352 participants, PPG: 60 participants  ECG: 6 stages (W, S1, S2, S3, S4, REM),   Œ∫ =0.61 and accuracy=76.30%  PPG: 5 stages (W, N1, N2, N3, REM),   Œ∫ =0.63 and accuracy=74.65%  ECG and PPG  Selected features from time and frequency domain  Sleep staging based on ECG and respiration has lower performance compared to using EEG. We previously performed EEG-based sleep staging with a deep neural network trained on data from the same set of patients used in the present work. This achieves performance similar to human inter-rater agreement   17 . This is not surprising since sleep technicians stage sleep mainly using EEG based on the AASM guideline.  The improvement in staging performance when collapsing certain stages of sleep into super-stages may reflect information regarding the true biology of sleep states. N1 is an unstable transitional state with low probability and non-distinct EEG features. About half of sleep is N2, and can show both stable and unstable characteristics, such as cyclic alternating pattern, apneic, or stable breathing in patients with sleep apnea. Different methods to characterize sleep depth and quality are available, and it will be important in future work to investigate whether further parsing of NREM sleep is meaningful using machine learning combined with methods such as the Odds Ratio Product of NREM sleep depth   27   or ECG-cardiopulmonary coupling   8 .  The mild degradation of performance with age is not surprising when using conventional sleep stages as the ground truth. The reduction of N3 with age (mainly in males) is not accompanied by equal and simultaneous reductions in stable N2   ‚Äì   thus, older individuals with equally reduced N3 may have very different N2 quality. By contrast, stable N2 and N3 may have very similar or identical cardiorespiratory signatures, making it difficult or impossible for deep learning models to reliably distinguish them. Thus  ‚Äúerror s ‚Äù   in discriminating these stages may reflect that EEG-based annotation in the reference standard is somewhat orthogonal to autonomic fluctuations.  Estimation of sleep states from cardiac and respiratory signals can simplify sleep tracking in health and disease, especially in environments like an intensive care unit (ICU) or hospitalized patients in general, when the model is trained with enough ICU patients who receive various heart rate or blood pressure medications.  Limitations of our analysis are as follows. 1) Our dataset includes only adults, and generalizability to the pediatric group will require additional study. 2) The 30-second epoch-based scoring of sleep limits the fine-grained analysis of sleep stages. This is especially true when sleep fragmenting conditions are present, where a given 30-second epoch may have features of multiple states. Moreover, boundary zones may be amplified, such as transitions between wake-REM and NREM in the presence of sleep  apnea in REM sleep. Such periods will introduce ‚Äúerror‚Äù in machine learning analys es, though these are biological features of sleep fragmentation rather than measurement or characterization error, such as arousal, apnea, or limb movement. 3)   Due to the ‚Äúblack - box‚Äù   nature of deep neural networks, there is limited insight into what the networks use as key features. Future work to interpret what the networks have learned (beyond   Figure 6 ,   Figure 7 ,   Figure 8 , and Figure S4-S12 in the supplementary material) is needed. (4) 1-fold validation (single training-validation-testing split) is used. Although this is the\n\n13  common practice in large datasets, it is nevertheless less biased to use cross-validation on multiple folds.  In conclusion, utilizing a large-scale dataset consisting of 8,682 PSGs, we have developed a set of deep neural networks to classify sleep stages from ECG and/or respiration. ECG and respiratory effort provide substantial information about sleep stages. The best staging performance is obtained using both ECG and abdominal respiration. Staging performance depends to some extent on age, apnea-hypopnea index, and sleep study type.  Acknowledgments  We gratefully acknowledge expert technical support from the Clinical Data Animation Center (CDAC) at Massachusetts General Hospital.  Disclosure Statement  RJT reports 1) Patent, license and royalties from MyCardio, LLC, for an ECG-based method to phenotype sleep quality and sleep apnea; 2) GLG consulting for general sleep medicine; 3) Intellectual Property (patent) for a device using CO2 for central / complex sleep apnea. BG declares that the work was done while at Massachusetts General Hospital. He is currently a full time employee at Novartis Institutes of Biomedical Research with a role of Data Scientist.  References  1.   Silber MH, Ancoli-Israel S, Bonnet MH, et al. The visual scoring of sleep in adults. J Clin Sleep Med.   2007; 3 (2): 121-131.  2.   Chervin RD, Shelgikar AV, Burns JW. Respiratory cycle-related EEG changes: response to CPAP. Sleep.   2012; 35 (2): 203-209.  3.   Niizeki K, Saitoh T. Association Between Phase Coupling of Respiratory Sinus Arrhythmia and Slow Wave Brain Activity During Sleep. Front Physiol.   2018; 9: 1338.  4.   Penzel T, Kantelhardt JW, Bartsch RP, et al. Modulations of Heart Rate, ECG, and Cardio- Respiratory Coupling Observed in Polysomnography. Front Physiol.   2016; 7: 460.  5.   Thomas RJ, Mietus JE, Peng CK, et al. Relationship between delta power and the electrocardiogram-derived cardiopulmonary spectrogram: possible implications for assessing the effectiveness of sleep. Sleep Med.   2014; 15 (1): 125-131.  6.   Lockmann AL, Laplagne DA, Leao RN, Tort AB. A Respiration-Coupled Rhythm in the Rat Hippocampus Independent of Theta and Slow Oscillations. J Neurosci.   2016; 36 (19): 5338-5352.  7.   Iellamo F, Placidi F, Marciani MG, et al. Baroreflex buffering of sympathetic activation during sleep: evidence from autonomic assessment of sleep macroarchitecture and microarchitecture. Hypertension.   2004; 43 (4): 814-819.\n\n14  8.   Thomas RJ, Mietus JE, Peng CK, Goldberger AL. An electrocardiogram-based technique to assess cardiopulmonary coupling during sleep. Sleep.   2005; 28 (9): 1151-1161.  9.   Sei H. Blood pressure surges in REM sleep: A mini review. Pathophysiology.   2012; 19 (4): 233- 241.  10.   Thomas RJ, Wood C, Bianchi MT. Cardiopulmonary coupling spectrogram as an ambulatory clinical biomarker of sleep stability and quality in health, sleep apnea and insomnia. Sleep.   2017.  11.   Bianchi MT. Sleep devices: wearables and nearables, informational and interventional, consumer and clinical. Metabolism.   2018; 84: 99-108.  12.   Sady CC, Freitas US, Portmann A, Muir JF, Letellier C, Aguirre LA. Automatic sleep staging from ventilator signals in non-invasive ventilation. Comput Biol Med.   2013; 43 (7): 833-839.  13.   Migliorini M, Bianchi AM, Nistico D, et al. Automatic sleep staging based on ballistocardiographic signals recorded through bed sensors. Conf Proc IEEE Eng Med Biol Soc.   2010; 2010: 3273-3276.  14.   Tal A, Shinar Z, Shaki D, Codish S, Goldbart A. Validation of Contact-Free Sleep Monitoring Device with Comparison to Polysomnography. J Clin Sleep Med.   2017; 13 (3): 517-522.  15.   Zaffaroni A, Doheny EP, Gahan L, et al. Non-Contact Estimation of Sleep Staging. 2018; Singapore.  16.   Watson PL, Pandharipande P, Gehlbach BK, et al. Atypical sleep in ventilated patients: empirical electroencephalography findings and the path toward revised ICU sleep scoring criteria. Crit Care Med.  2013; 41 (8): 1958-1967.  17.   Biswal S, Sun H, Goparaju B, Westover MB, Sun J, Bianchi MT. Expert-level sleep scoring with deep neural networks. Journal of the American Medical Informatics Association.   2018; 25 (12): 1643- 1650.  18.   Pan J, Tompkins WJ. A real-time QRS detection algorithm. IEEE Trans Biomed Eng.   1985; 32 (3): 230-236.  19.   Rebergen DJ, Nagaraj SB, Rosenthal ES, Bianchi MT, van Putten MJ, Westover MB. ADARRI: a novel method to detect spurious R-peaks in the electrocardiogram for heart rate variability analysis in the intensive care unit. Journal of clinical monitoring and computing.   2018; 32 (1): 53-61.  20.   Hannun AY, Rajpurkar P, Haghpanahi M, et al. Cardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms using a deep neural network. Nature medicine.   2019; 25 (1): 65.  21.   van Gent PaF, Haneen and Nes, Nicole and Arem, B. Heart Rate Analysis for Human Factors: Development and Validation of an Open Source Toolkit for Noisy Naturalistic Heart Rate Data. In: proceedings from the the 6th HUMANIST Conference; 2018; the Netherlands.  22.   Long X, Yang J, Weysen T, et al. Measuring dissimilarity between respiratory effort signals based on uniform scaling for sleep staging. Physiological measurement.   2014; 35 (12): 2529.  23.   Fonseca P, Long X, Radha M, Haakma R, Aarts RM, Rolink J. Sleep stage classification with ECG and respiratory effort. Physiological measurement.   2015; 36 (10): 2027.  24.   Zhao M, Yue S, Katabi D, Jaakkola TS, Bianchi MT. Learning sleep stages from radio signals: A conditional adversarial architecture. In: proceedings from the Proceedings of the 34th International Conference on Machine Learning-Volume 70; 2017.  25.   Zhang X, Kou W, Eric I, et al. Sleep stage classification based on multi-level feature learning and recurrent neural networks via wearable device. Computers in biology and medicine.   2018; 103: 71-81.  26.   Radha M, Fonseca P, Ross M, Cerny A, Anderer P, Aarts RM. LSTM knowledge transfer for HRV- based sleep staging. arXiv preprint arXiv:180906221.   2018.  27.   Younes M, Ostrowski M, Soiferman M, et al. Odds ratio product of sleep EEG as a continuous measure of sleep state. Sleep.   2015; 38 (4): 641-654.\n\n15\n\n16  Supplementary Figures  Figure S1 . Illustration of signal segmentation.  Figure S2.   The histogram of C ohen‚Äôs kappa of individual PSGs for different input signals and different  combinations of sleep stages.\n\n17  Figure S3 . Cohen‚Äôs kappa when applying zero -mean Gaussian jitter to the ECG R peaks.  Figure S4 . tSNE visualization of the last layer activation of the deep network that takes ECG as the input. Each point in the figure is a 270-second epoch.\n\n18  Figure S5 . tSNE visualization of the last layer activation of the deep network that takes chest repiration signal as the input. Each point in the figure is a 270-second epoch.  Figure S6 . tSNE visualization of the last layer activation of the deep network that takes abdominal repiration as the input. Each point in the figure is a 270-second epoch.\n\n19  Figure S7 . The kernels of the first convolution layer in the deep network that takes ECG as the input.  Figure S8 . The kernels of the first convolution layer in the deep network that takes chest respiration as the input.\n\n20  Figure S9 . The kernels of the first convolution layer in the deep network that takes abdominal respiration as the input.  Figure S10 . Examples of ABD signals for different sleep stages. These examples are selected based on having high probability according to the deep neural network in each of the 5 sleep stages. The signals are not necessarily from the same recording.\n\n21  Figure S11 . Examples of CHEST signals in different sleep stages, selected based on having high probability by the deep neural network. The signals are not necessarily from the same recording.  Figure S12 . Example ECG R peaks in different sleep stages, selected based on having high probability by the deep neural network. The signals are not necessarily from the same recording.\n\n22  Supplementary Tables  Table S1 . Cohen‚Äôs kappa in different group   in the 1000-PSG testing set using ECG as input.  Category   Group   5 stages  3 stages  W+N1 vs.  N2+ N3 vs. R  W vs. NR vs.  R  Age  Young: 18 ‚â§ Age < 40   0.54   0.715   0.717  Middle: 40 ‚â§ Age < 60   0.514   0.672   0.685  Elderly: Age ‚â• 60   0.426   0.57   0.564  Sex   Male   0.483   0.636   0.644  Female   0.51   0.673   0.67  BMI (kg/m 2 )   Normal: 18.5 ‚â§ BMI < 25   0.536   0.678   0.672  Overweight: BMI ‚â• 25   0.49   0.65   0.654  Type of Test  Diagnostic   0.508   0.667   0.667  All Night CPAP   0.501   0.67   0.663  Split Night   0.462   0.601   0.622  AHI (per hour)  Normal: AHI < 5   0.519   0.699   0.701  Mild: 5 ‚â§ AHI < 15   0.499   0.655   0.639  Moderate: 15 ‚â§ AHI < 30   0.471   0.615   0.621  Severe: AHI ‚â• 30   0.427   0.532   0.603  Periodic   limb movement (per hour)  Normal: PLMI < 5   0.497   0.656   0.676  Mild: 5 ‚â§ PLMI < 15   0.512   0.667   0.669  Moderate: 15 ‚â§ PLMI < 30   0.502   0.664   0.649  Severe: PLMI ‚â• 30   0.459   0.609   0.611  Medication  Antidepressant   0.489   0.651   0.652  Benzodiazepine   0.501   0.674   0.662  Diabetic   0.501   0.673   0.668  Herbal   0.484   0.65   0.639  Hypertension   0.495   0.649   0.655  Neuroleptic   0.483   0.664   0.674  Opiate   0.476   0.624   0.626  Neuroactive   0.5   0.648   0.661  Systemic   0.496   0.656   0.663  RLS/PLMS   0.515   0.647   0.657  Sleeping   0.499   0.669   0.66  Stimulant   0.507   0.671   0.646  Z-drug   0.526   0.692   0.682\n\n23  Table S2 . Cohen‚Äôs kappa in different group in the 1000 -PSG testing set using CHEST as input.  Category   Group   5 stages  3 stages  W+N1 vs.  N2+ N3 vs. R  W vs. NR vs.  R  Age  Young: 18 ‚â§ Age < 40   0.581   0.728   0.728  Middle: 40 ‚â§ Age < 60   0.569   0.709   0.713  Old: Age   ‚â• 60   0.546   0.691   0.689  Sex   Male   0.558   0.701   0.704  Female   0.573   0.719   0.716  BMI (kg/m 2 )   Normal: 18.5 ‚â§ BMI < 25   0.554   0.697   0.692  Overweight: BMI ‚â• 25   0.567   0.71   0.711  Type of Test  Diagnostic   0.57   0.714   0.713  All Night CPAP   0.564   0.719   0.702  Split Night   0.553   0.685   0.707  AHI (per hour)  Normal: AHI < 5   0.576   0.734   0.725  Mild: 5 ‚â§ AHI < 15   0.572   0.714   0.708  Moderate: 15 ‚â§ AHI < 30   0.555   0.688   0.696  Severe: AHI ‚â• 30   0.517   0.628   0.68  Periodic   limb movement (per hour)  Normal: PLMI < 5   0.556   0.698   0.71  Mild: 5 ‚â§ PLMI < 15   0.576   0.715   0.709  Moderate: 15 ‚â§ PLMI < 30   0.576   0.72   0.716  Severe: PLMI ‚â• 30   0.551   0.698   0.699  Medication  Antidepressant   0.573   0.72   0.718  Benzodiazepine   0.572   0.714   0.706  Diabetic   0.561   0.708   0.707  Herbal   0.586   0.728   0.713  Hypertension   0.565   0.704   0.709  Neuroleptic   0.532   0.691   0.689  Opiate   0.576   0.709   0.704  Neuroactive   0.573   0.713   0.72  Systemic   0.564   0.706   0.71  RLS/PLMS   0.58   0.725   0.726  Sleeping   0.572   0.719   0.713  Stimulant   0.581   0.722   0.7  Z-drug   0.581   0.72   0.709\n\n24  Table S3 . Cohen‚Äôs kappa in different group in the 1000 -PSG testing set using ABD as input.  Category   Group   5 stages  3 stages  W+N1 vs.  N2+ N3 vs. R  W vs. NR vs.  R  Age  Young: 18 ‚â§ Age < 40   0.584   0.737   0.753  Middle: 40 ‚â§ Age   < 60   0.586   0.728   0.746  Old: Age ‚â• 60   0.551   0.698   0.705  Sex   Male   0.574   0.719   0.737  Female   0.577   0.725   0.732  BMI (kg/m 2 )   Normal: 18.5 ‚â§ BMI < 25   0.552   0.684   0.679  Overweight: BMI ‚â• 25   0.579   0.727   0.743  Type of Test  Diagnostic   0.584   0.724   0.733  All Night CPAP   0.578   0.738   0.734  Split Night   0.555   0.698   0.737  AHI (per hour)  Normal: AHI < 5   0.584   0.742   0.741  Mild: 5 ‚â§ AHI < 15   0.585   0.734   0.739  Moderate: 15 ‚â§ AHI < 30   0.563   0.696   0.723  Severe: AHI ‚â• 30   0.533   0.651   0.725  Periodic   limb movement (per hour)  Normal: PLMI < 5   0.574   0.726   0.748  Mild: 5 ‚â§ PLMI < 15   0.583   0.73   0.738  Moderate: 15 ‚â§ PLMI < 30   0.579   0.714   0.728  Severe: PLMI ‚â• 30   0.559   0.7   0.714  Medication  Antidepressant   0.574   0.731   0.743  Benzodiazepine   0.595   0.738   0.749  Diabetic   0.574   0.736   0.74  Herbal   0.605   0.741   0.75  Hypertension   0.576   0.719   0.738  Neuroleptic   0.527   0.695   0.715  Opiate   0.585   0.722   0.74  Neuroactive   0.581   0.729   0.743  Systemic   0.578   0.726   0.744  RLS/PLMS   0.58   0.739   0.74  Sleeping   0.589   0.737   0.745  Stimulant   0.604   0.745   0.769  Z-drug   0.602   0.75   0.756\n\n25  Table S4 . Cohen‚Äôs kappa in different group in the 1000 -PSG testing set using ECG + CHEST as input.  Category   Group   5 stages  3 stages  W+N1 vs.  N2+ N3 vs. R  W vs. NR vs.  R  Age  Young: 18   ‚â§ Age < 40   0.539   0.691   0.708  Middle: 40 ‚â§ Age < 60   0.506   0.645   0.657  Old: Age ‚â• 60   0.468   0.603   0.621  Sex   Male   0.492   0.633   0.647  Female   0.518   0.659   0.673  BMI (kg/m 2 )   Normal: 18.5 ‚â§ BMI < 25   0.54   0.672   0.682  Overweight: BMI ‚â• 25   0.499   0.642   0.656  Type of Test  Diagnostic   0.518   0.661   0.674  All Night CPAP   0.504   0.652   0.644  Split Night   0.472   0.602   0.642  AHI (per hour)  Normal: AHI < 5   0.521   0.677   0.683  Mild: 5 ‚â§ AHI < 15   0.518   0.657   0.651  Moderate: 15 ‚â§ AHI < 30   0.472   0.604   0.637  Severe: AHI   ‚â• 30   0.451   0.554   0.627  Periodic   limb movement (per hour)  Normal: PLMI < 5   0.5   0.643   0.668  Mild: 5 ‚â§ PLMI < 15   0.52   0.655   0.661  Moderate: 15 ‚â§ PLMI < 30   0.511   0.657   0.661  Severe: PLMI ‚â• 30   0.475   0.611   0.632  Medication  Antidepressant   0.508   0.66   0.664  Benzodiazepine   0.519   0.663   0.673  Diabetic   0.488   0.658   0.658  Herbal   0.547   0.687   0.719  Hypertension   0.49   0.631   0.641  Neuroleptic   0.462   0.633   0.679  Opiate   0.499   0.613   0.644  Neuroactive   0.504   0.648   0.667  Systemic   0.499   0.643   0.656  RLS/PLMS   0.516   0.671   0.681  Sleeping   0.517   0.667   0.679  Stimulant   0.539   0.677   0.683  Z-drug   0.547   0.684   0.703",
    "arXiv:2506.21828v1 [q-bio.NC] 27 Jun 2025  1  Fetal Sleep: A Cross-Species Review of Physiology, Measurement, and Classification  Weitao Tang, Johann Vargas-Calixto, Nasim Katebi, Robert Galinsky, Gari D. Clifford, Faezeh Marzbanrad  Abstract ‚ÄîFetal sleep is a relatively underexplored yet vital aspect of prenatal neurodevelopment. Understanding fetal sleep patterns could provide insights into early brain maturation and help clinicians detect signs of neurological compromise that   arise   due   to   fetal   hypoxia   or   fetal   growth   restriction. This   review   synthesizes   over   eight   decades   of   research   on the physiological characteristics, ontogeny, and regulation of fetal sleep. We compare sleep-state patterns in humans and large animal models, highlighting species-specific differences and the presence of sleep-state analogs. We review both invasive techniques in animals and non-invasive modalities in humans. Computational methods for sleep-state classification are also examined, including rule-based approaches (with and without clustering-based preprocessing) and state-of-the-art deep learn- ing techniques. Finally, we discuss how intrauterine conditions such as hypoxia and fetal growth restriction can disrupt fetal sleep. This review provides a comprehensive foundation for the development of objective, multimodal, and non-invasive fetal sleep monitoring technologies to support early diagnosis and intervention in prenatal care.  Index   Terms ‚ÄîFetal   Sleep,   Fetal   Behavioral   States,   Fetal Monitoring, Sleep Classification, Neurodevelopment  I. I NTRODUCTION  Sleep plays a crucial role in brain development, synap- tic   plasticity,   and   metabolic   regulation   [1],   [2],   [3].   In neonates and infants, consolidated sleep‚Äìwake cycles have been shown to support neurodevelopmental milestones and long-term cognitive outcomes [4], [5], [6], [7]. However, the nature and function of sleep before birth‚Äîduring fetal life‚Äîremain poorly understood. This lack of understanding poses a significant gap in prenatal care, as fetal sleep may reflect underlying brain maturation and help identify early signs of neurological compromise or neurodevelopmental disorders. Developing objective and non-invasive fetal sleep monitoring tools could empower clinicians to assess neu- rodevelopmental trajectories, detect early signs of complica- tions such as antepartum hypoxia or fetal growth restriction,  W. Tang is with the Department of Electrical and Computer Systems Engineering, Monash University, Melbourne, Australia. J. Vargas-Calixto is with the Department of Biomedical Informat- ics, Emory University, Atlanta, USA. N. Katebi is with the Department of Biomedical Informatics, Emory University, Atlanta, USA. R. Galinsky is with the Ritchie Centre, Hudson Institute of Med- ical Research, and the Department of Obstetrics and Gynaecology, Monash University, Melbourne, Australia. G. D. Clifford is with the Department of Biomedical Informatics, Emory University, Atlanta, USA, and also with the Department of Biomedical Engineering, Georgia Institute of Technology, Atlanta, USA. F. Marzbanrad is with the Department of Electrical and Computer Systems Engineering, Monash University, Melbourne, Australia. Research reported in this publication was supported in part by the National Institutes of Health through the Fogarty International Center and the Eunice Kennedy Shriver National Institute of Child Health and Human Development (Grant R01HD110480), by the Google.org AI for the Global Goals Impact Challenge Award, and by the National Health and Medical Research Council (NHMRC) of Australia (Grants 1124493 & 1164954). N.K. is partially supported by a PREHS-SEED award (Grant K12ES033593).  and implement timely interventions to improve perinatal outcomes. Although adult human sleep has been well studied over the past decades, the origins of sleep and circadian rhythm research date back to 1729. Jean-Jacques d‚ÄôOrtous de Mairan observed that the leaves of Mimosa pudica continued their daily opening and closing cycles even in constant dark- ness [8], providing the first scientific evidence of an endoge- nous biological clock. Building upon this, early physiological studies in humans were initiated by John Davy, who in 1845 systematically measured body temperature fluctuations across the sleep-wake cycle and suggested a relationship between temperature rhythms and rest [9]. Research on brain activity during sleep dates back nearly a century. In 1924, German psychiatrist Hans Berger success- fully recorded the first human electroencephalogram (EEG), he published his landmark findings in 1929, providing the first objective evidence of brain wave activity during sleep and wakefulness [10]. Loomis et al. recorded electrical ac- tivity from the human cerebral cortex and reported rhythmic variations in brain potentials influenced by mental activity, external stimuli, emotional states, and sleep in their 1936 study,   ‚ÄúElectrical   Potentials   of   the   Human   Brain‚Äù   [11]. However, systematic sleep studies can be considered to have begun in the 1950s, when Kleitman and Aserinsky discovered rapid eye movement (REM) sleep in humans [12]. Their 1953 landmark study demonstrated that REM episodes were associated with vivid dreams, marking the first clear differentiation between REM and non-rapid eye movement (NREM) sleep. By 1957, further studies estab- lished cyclic variations in EEG during sleep, confirming that REM sleep recurs in predictable cycles throughout the night [13]. Stemming from the seminal work of Rechtschaffen and Kales [14] and others in the 1960s, sleep staging criteria became standardized in adults. However, the earlier we look into human development, the less we understand about sleep. In particular, fetal sleep remains one of the least understood stages due to significant technical and ethical challenges associated with studying the developing brain in human fetuses. As a result, there have been disagreements regarding how to classify fetal neurobehavioral states. Nevertheless, as we discuss in this article, these states phenotypically display characteristics of REM and NREM sleep, and are therefore best referred to as fetal sleep states, which can provide valuable insights into neurodevelopment. In parallel, fetal sleep studies emerged during the 1950s and 1960s. Early research primarily focused on fetal heart rate patterns and behavioral states, laying the groundwork for later investigations. In 1967, studies focusing on the relationship of intrauterine fetal activity to maternal sleep [15] and evidence of fetal-sleep cycles [16] examined fetal movements in relation to maternal sleep, suggesting that distinct sleep cycles may exist in utero. The 1970s marked a significant shift, as technological advancements allowed\n\n2  for more precise monitoring of fetal brain activity in large animal models such as sheep and calves. A pivotal advance came in 1971, when Ruckebusch systematically recorded alternating high-voltage slow activity and low-voltage fast activity in fetal lambs and calves, associating high-voltage slow activity with NREM sleep and low-voltage fast activity with REM sleep or alert wakefulness [17]. His work laid the foundation for interpreting fetal EEG activity in relation to behavioral states. Building upon this, a 1974 study confirmed the presence of EEG-based fetal sleep stages and linked them to cardiovascular regulation in fetal sheep [18]. Further validation came in 1977, as alternating high-voltage slow activity and low-voltage fast activity states were again ob- served in fetal lambs, reinforcing their similarity to neonatal and adult sleep patterns [19]. Finally, a 1979 study on human fetuses identified short-term cyclic patterns of fetal activity [20], supporting the hypothesis that early sleep-wake cycles emerge before birth. A major conceptual breakthrough occurred in 1982, when Nijhuis et al. introduced the fetal behavioral states (FBS) framework [21]. This classification system defined distinct fetal states based on physiological and behavioral markers, drawing parallels between fetal and neonatal behavioral state patterns [21]. Nijhuis further expanded the framework in a 1986 study [22], providing a more detailed characterization of these states and their relevance to neurodevelopment and clinical assessments [22]. These findings confirmed that human fetuses exhibit four behavioral states (1F to 4F), analogous to neonatal states [21], [22]. States 1F and 2F correspond to quiet (NREM-like) and active (REM-like) sleep, respectively, while 3F is characterized by continuous eye movements without body movement, and 4F by vigorous body activity with unstable heart rate [22]. Fetal breathing, heart rate, and movement patterns were shown to serve as key indicators of neurodevelopment [22]. These insights reinforced the potential of FBS as a clinical tool for assessing fetal brain function and detecting potential developmental abnormalities [22]. Despite extensive behavioral classifications such as the FBS framework [21], the presence of true wakefulness in the   fetus   remains   controversial.   In   sheep,   baboons,   and humans alike, episodes of increased activity or arousal- like features often lack the sustained neural and behavioral markers associated with postnatal wakefulness [23], [24], [25]. Some have suggested that the apparent wakefulness state reflects a transitional phase between sleep states, similar to indeterminate sleep in the newborn [1], rather than true wakefulness [23]. This will be discussed in more detail later in the paper. These foundational studies laid the groundwork for mod- ern research, which continues to refine our understanding of fetal sleep across different species. However, despite eight decades of progress, there remains no comprehensive literature review that systematically integrates findings on fetal sleep physiology, measurement, classification, and dis- ruption under pathological conditions. To address this gap, we synthesize and structure the state of the art in fetal sleep research. Specifically, we:  ‚Ä¢   synthesize fetal sleep research across humans, sheep, and baboons, highlighting species-specific similarities and differences in sleep ontogeny and physiology;  ‚Ä¢   compare measurement modalities, ranging from inva- sive techniques in animal models to non-invasive ap- proaches in human studies;  ‚Ä¢   review classification methods used to identify sleep states, spanning rule-based approaches‚Äîsome of which incorporate multimodal signal integration‚Äîand recent advances in state-of-the-art deep learning; and  ‚Ä¢   examine how abnormal intrauterine conditions such as hypoxia and fetal growth restriction disrupt fetal sleep development and expression. By bridging physiology, engineering, and clinical rele- vance, this review provides a foundation for future work in fetal neurodevelopment and the advancement of objective, fetal sleep-state monitoring tools. II. B ACKGROUND ON   S LEEP  A. The Nature of Sleep  Sleep is a fundamental biological process characterized by altered consciousness, reduced responsiveness to external stimuli, and decreased physical activity [26]. It is broadly classified into two main phases: NREM and REM [27]. These phases alternate cyclically and are regulated by both circadian rhythms and homeostatic sleep pressure [27]. In adults, NREM sleep is subdivided into three stages: N1 (Stage 1) light sleep, N2 (Stage 2) intermediate sleep, and N3 (Stage 3) deep sleep or Slow-Wave Sleep (SWS). A typical adult sleep cycle progresses through N1   ‚Üí   N2   ‚Üí  N3   ‚Üí   N2   ‚Üí   REM [28], repeating every 90 minutes for 4‚Äì6 cycles per night [29]. REM sleep is characterized by rapid eye movements, skeletal muscle atonia, and dreaming. It is a paradoxical state due to its wake-like EEG (low amplitude, mixed frequency) combined with high arousal threshold and lack of muscle tone [30], [31], [32]. Ontogenetically, REM is the dominant state in neonates and gradually declines with age [33], [34], [35]. This high proportion suggests a crucial role in brain maturation. REM- related muscle twitches are now believed to serve as sensory feedback signals that help the developing brain refine motor maps and connectivity [36]. This ontogenetic role highlights the fundamental contribution of REM sleep to early-life brain development [37]. As reviewed by Peever and Fuller (2017), REM sleep exhibits substantial interspecies diversity [37]. While ter- restrial mammals and birds generally display well-defined REM features, marine mammals such as dolphins appear to lack many classical characteristics, including rapid eye movements, cortical EEG desynchronization, skeletal muscle atonia [38], [39]. REM sleep may serve species-specific adaptive functions. Two main hypotheses have been pro- posed to explain interspecies variation in REM sleep. The energy allocation hypothesis posits that REM sleep con- serves energy by suspending thermoregulation during this state, while the ontogenetic hypothesis suggests that REM sleep supports neural development and plasticity, particularly in altricial species [36].  B. The Significance of Fetal Sleep  Fetal sleep is essential for neurodevelopment, supporting the maturation of both the central (CNS) and autonomic nervous systems (ANS) [33], [40], [41], [6], [42], [43], [44]. Cycling through distinct FBS promotes synaptogenesis, brain plasticity, and neuronal differentiation, contributing to postnatal cognitive and behavioral development [45], [6]. Unlike postnatal sleep, fetal sleep is defined by physiological\n\n3  markers such as heart rate variability (HRV), body move- ments, and EEG (in animal models), rather than behavioral reports [6], [46], [47]. The emergence of distinct FBS such as quiet and active sleep during the third trimester has been interpreted as a sign of increasing functional brain complexity, driven by coordinated neural activity across developing circuits [48], [6], [49]. This maturation is paralleled by the progressive development of the ANS, which plays a key role in sup- porting physiological regulation during fetal life [42], [43], [40]. In particular, the vagus nerve‚Äîa central component of the parasympathetic system‚Äîhas been implicated in vital processes such as anti-inflammatory signaling and metabolic regulation across fetal, perinatal, and postnatal periods [50], [51]. From around 25 weeks of gestation, increasing vagal tone and myelination have been reported [43], [52], [53], potentially contributing to the regulation of heart rate and state-dependent behaviors. As such, the emergence of dis- tinguishable sleep states in the third trimester‚Äîdetectable via patterns of fetal heart rate, eye movements, and body activity [21]‚Äîmay reflect both neural and autonomic matu- ration. REM-like   sleep   is   characterized   by   spontaneous   fetal movements, including fetal breathing movements (FBM), which are thought to play a critical role in preparing vital systems for postnatal life [54]. When fetal movements are pharmacologically suppressed‚Äîsuch as through anesthesia or neuromuscular blockade‚Äîthere is a marked reduction in oxygen consumption [55], suggesting that fetal activity itself significantly contributes to metabolic demand. While this observation does not directly implicate REM sleep in energy conservation, it highlights the physiological cost of fetal activity and the potential adaptive role of sleep states in regulating energy expenditure. Moreover,   FBM‚Äîoften   observed   during   REM-like states‚Äîare   believed   to   contribute   to   lung   growth   and maturation.   Disruption   of   these   movements,   whether experimentally   or   in   pathological   conditions   such   as prolonged   oligohydramnios,   can   result   in   pulmonary hypoplasia   [56],   [57],   [58],   [59],   [60],   [61].   Although these   disruptions   are   not   exclusive   to   REM   sleep,   the strong   association   between   FBM   and   REM-like   states suggests that fetal sleep behavior may indirectly support pulmonary development. Altogether, these findings imply that FBS contribute not only to neurodevelopment, but also play a broader role in maintaining metabolic balance and promoting organ system maturation [49].  C. Current Research Status and Gaps  Advances in fetal monitoring techniques have enabled detailed characterization of sleep states using EEG, integrat- ing electrocardiogram (ECG), and HRV analysis [62], [63]. Non-invasive methods such as fetal magnetoencephalogra- phy (FMEG) complement traditional measures by providing insights into fetal cortical activity [64]. Current research has primarily focused on automated classification of fetal sleep states based on heart rate and movement patterns [65], [66]. Studies have also explored EEG-based analysis of REM and NREM sleep across species [47], [67]. Additionally, researchers have investigated neural and autonomic markers of fetal brain maturation through spectral EEG and HRV analysis [68], [62], and recent studies have also evaluated EEG spectral power and sleep state cycling to assess matu- ration after hypoxia‚Äìischaemia in fetal sheep [69]. Despite   these   advancements,   significant   research   gaps remain. The mechanisms linking fetal sleep disruptions to neurodevelopmental disorders are still poorly understood. Current   measurement   techniques   are   limited,   relying   on indirect and intermittent measurements fetal movement, heart rate variability and breathing to infer fetal sleep and be- havioral states. Furthermore, cross-species comparisons lack standardization, making it difficult to generalize findings from animal models to human fetal development. III. P HYSIOLOGICAL   C HARACTERISTICS OF   F ETAL  S LEEP  A. Historical Background: Discovery of Fetal Sleep States  The scientific understanding of fetal sleep has evolved since the late 20th century. Nijhuis et al. first proposed a systematic classification of fetal behavioral states in the early 1980s based on physiological rhythms and movement patterns [21], followed by studies linking these states to fetal heart rate variability and motor activity [70], [22]. These findings suggested that sleep-wake regulation begins before birth. More recent advances in non-invasive fetal monitoring, including transabdominal fetal electrocardiography (FECG) and fetal magnetocardiography (FMCG), have confirmed the presence of sleep-like cycles in third-trimester human fetuses through heart rate variability analyses [71], [66]. Cross-species   investigations   have   further   strengthened the   concept   of   prenatal   sleep   organization.   In   fetal sheep,   intrauterine   polygraphic   recordings‚Äîincluding EEG,   electrooculography,   and   nuchal   electromyogra- phy‚Äîdemonstrated   a   developmental   transition   from disorganized to structured behavioral states around 115‚Äì120 days of gestation (approximately 80% of term) [45]. These recordings revealed alternating episodes of quiet sleep, REM sleep, and arousal, resembling adult-like sleep architecture and implying an early onset of sleep-wake regulation in utero. Similarly, studies in fetal baboons during the early 1990s   identified   EEG   patterns   indicative   of   both   REM and NREM sleep, which closely resembled those seen in preterm human infants [72], [73]. Together, these findings suggest that core aspects of fetal sleep-state differentiation are conserved across species with relatively mature central nervous systems at birth. Together, human and animal studies show that fetal sleep states   emerge   prenatally   and   follow   species-specific   yet evolutionarily conserved patterns. The next section examines sleep-state classification across species.  B. Fetal Sleep Cycle in Different Species  Since direct recordings of fetal EEG and other neural activity are not feasible in humans, many fetal sleep stud- ies rely on animal models [54], [74]. Understanding the similarities   and   differences   between   species   is   therefore crucial for interpreting these findings and assessing their relevance to human development. Comparative studies across species provide insights into how fetal sleep develops and its evolutionary significance. Fetal sheep and baboons are widely used models for study- ing sleep state maturation due to their well-characterized sleep architecture and physiological similarities to humans [75], [74], [76], [77], [67], [78], [79]. For example, fetal\n\n4  TABLE I C OMPARISON OF   G ESTATIONAL   L ENGTH AND   B IRTH   W EIGHT  A CROSS   S PECIES  Species (Fetus)   Gestation Length   Birth Weight (kg)  Human   37‚Äì41 weeks (259‚Äì294 days) [80] 3.02‚Äì3.80 [64] Sheep   20‚Äì22 weeks (145‚Äì150 days) [81],   [18],   [82],   [45],   [77], [75] 3.50‚Äì5 [81], [83] Baboon   25‚Äì26 weeks (175‚Äì180 days) [73], [72] 0.46‚Äì0.90 [84], [72]  Note: Reported ranges are for illustrative reference and may vary across studies.  sheep exhibits a transition from disorganized to structured sleep patterns around 80% gestation, mirroring human fetal sleep development at approximately 32-36 weeks gestation [21]. To better compare the sleep states of different species, we first take a deeper look at gestational length and birth weight, as shown in Table I. From Table I, we observe that sheep fetuses have a higher birth weight than human fetuses, while baboon fetuses are the lightest. Interestingly, this pattern does not follow the order of gestational length: human fetuses have the longest gestation (37‚Äì41 weeks), baboons fall in between (25‚Äì26 weeks), and sheep have the shortest (20‚Äì22 weeks). This dis- sociation between gestation length and birth weight suggests that longer gestation may not be solely for somatic growth. Instead, it may reflect species-specific neurodevelopmental priorities. In humans, for instance, the prolonged gestation supports a brain growth spurt that begins in mid-gestation and extends well into early postnatal life, enabling greater cortical and synaptic development [85]. This implies that cerebral complexity, rather than body weight, may better explain interspecies differences in gestation length‚Äîat least among medium-sized mammals. Moreover, human fetal birth weight   is   influenced   by   factors   such   as   fetal   sex   [86], maternal weight [2], and gestational diabetes [80], while such influences have not been extensively studied in sheep or baboon models. Comparison of sleep state development across species is summarized in Table II. This table outlines key develop- mental milestones‚Äîranging from the onset of physiological rhythmicity to the emergence and maturation of distinguish- able sleep states‚Äîin humans, sheep, and baboons. Among the three species, fetal sheep appear to exhibit organized sleep states earliest, with REM/NREM-like dif- ferentiation observable as early as 79% of gestation. Fetal baboons also show distinct REM- and NREM-like cycling by 82‚Äì87% of gestation, although data are limited to a narrow gestational window and lack a comprehensive developmental trajectory. In contrast, humans typically show consistent REM/NREM differentiation only after 90% of gestation, suggesting a relatively delayed maturation process. These cross-species comparisons provide insight into sleep state ontogeny; however, differences in methodology, avail- able data, and sampling windows, particularly in the fetal baboon limit direct comparisons. The table should therefore be interpreted as an approximate alignment across species rather than a definitive staging framework.  C. Comparison of Sleep-like States Across Species  FBS are broadly classified into sleep-like states (REM and NREM), transitional or indeterminate states, and potential wakefulness. However, the nature and classification of fetal wakefulness remain a subject of debate. This section com- pares sleep patterns in fetal sheep, baboons, and humans based on available research.  1) Sleep-like States:   All three species exhibit two primary sleep-like states: Quiet sleep and Active sleep. In fetal sheep, Quiet sleep is characterized by high-voltage low-frequency EEG, the absence of REMs, and variable nuchal muscle tone [45], [89]. Active sleep in fetal sheep is distinguished by a low-voltage high-frequency EEG pattern, the presence of REM, and a background of absent sustained nuchal muscle tone, often interspersed with phasic muscle contractions and breathing movements [45], [90].  TABLE II C OMPARISON OF   S LEEP   S TATE   D IFFERENTIATION   A CROSS   S PECIES  Sleep State Differentiation   Human Fetus   Sheep Fetus   Baboon Fetus  Initial Physiological Rhythmicity   80‚Äì90% of gestation: FHR, eye, and body movements cycle inde- pendently; chance overlaps lack the synchrony   and   stability   required for true behavioral states [21]. 79‚Äì83%   of   gestation:   35.1   ¬± 2.5% NREM, 52.7 ¬± 2.4% REM, 11.2   ¬±   1.7%   Wake   like   activ- ity were observed, marking the transition   from   disorganized   to organized behavioral states. [45] 78‚Äì86% of gestation: EEG power and coherence cycles (1h) observed in fetal baboons, even in the absence of full behavioral state measures, may reflect early sleep-like rhythmicity [78] REM/NREM Differentiation   90‚Äì95% of gestation: In most fe- tuses, heart rate, movement, and eye activity are only partially syn- chronized, preventing reliable state classification. [21] 83‚Äì90%   of   gestation:   38.4   ¬± 1.6% NREM, 49.9 ¬± 1.7% REM, 11.8 ¬± 1.6% Wake like state [45] 82‚Äì87%   of   gestation:   20.9%   NREM, 58.3% REM, 20.9% Transition [87] Emergence of Stable Behavioral States   95%   of   gestation:   NREM:   32% (range:   9‚Äì53.5%)   REM:   42.5% (range:   23‚Äì64%)   Wake-like   state (combined   3F   and   4F):   14.75% (range: 6.5‚Äì33%) No state identi- fied: 11.5% (range: 3‚Äì53.5%) [21] 90‚Äì97%   of   gestation:   38.2   ¬± 1.8% NREM, 46.1 ¬± 2.0% REM, 15.1 ¬± 1.9% Wake like state [45] 82‚Äì87%   of   gestation:   36.8%   NREM, 63.2% REM [88] Full Maturation of Sleep Cycles   99%   of   gestation:   NREM:   38% (range: 24.5‚Äì52.5%) REM: 42.5% (range: 22‚Äì73.5%) Wake-like state (combined   3F   and   4F):   13.5% (range: 2.5‚Äì38%) No state identi- fied: 5% (range: 0‚Äì26.5%) [21] 97‚Äì99%   of   gestation:   43.8   ¬± 2.5% NREM, 37.7 ¬± 2.8% REM, 18.3 ¬± 2.9% Wake like state [45] 73‚Äì90% of gestation: 48% NREM, 32% REM, 20% transition [84]\n\n5  Fig. 1.   Representative physiological signals illustrating sleep states in fetal sheep [91]. NREM sleep is marked by high-voltage (HV), low-frequency EEG patterns recorded from both hemispheres (L EEG and R EEG), whereas REM sleep is characterized by low-voltage (LV), high-frequency EEG activity. TR represents an intermediate state between REM and NREM, capturing the dynamic shift from one state to the other. This state typically exhibits mixed EEG features that do not fully conform to either REM or NREM characteristics. Additional signals include nuchal EMG, obtained from electrodes implanted in the fetal neck muscles, which reflects muscle tone and fetal movements. BA 1 denotes the raw intra-balloon pressure signal, capturing both the balloon inflation pressure and the ambient amniotic pressure. All signals were collected from fetal sheep using chronic invasive instrumentation, including surgically implanted EEG and EMG electrodes and an intra-amniotic balloon catheter, enabling continuous in utero monitoring of physiological and neural activity.  To better elucidate the physiological distinctions between NREM and REM sleep, we provide representative traces from our own fetal sheep recordings. These examples high- light characteristic differences in EEG, EMG, and intra- balloon pressure across behavioral states. As illustrated in Figure 1, these features are clearly distinguishable: green waveform segments correspond to quiet sleep (HV/NREM), red segments indicate active sleep (LV/REM), and black segments denote brief transition periods (TR). Similarly, fetal baboons display quiet and active sleep states. Quiet sleep is associated with trace alternant, a pattern of   intermittent   bursts   of   high-voltage   EEG   activity   also reported in other species such as fetal sheep, whereas active sleep exhibits an increased presence of high-frequency EEG components [72]. Fetal breathing is present in both sleep states but occurs more frequently in active sleep [73], a pattern consistent across species. The organization of these states resembles that of fetal sheep and humans. In humans, these two states are referred to as Quiet sleep (1F) and Active sleep (2F). Quiet sleep is characterized by infrequent fetal movement, stable fetal heart rate with low variability, and an absence of eye movements (EOG), akin to NREM sleep; whereas Active sleep, corresponding to REM sleep, involves frequent fetal body movements, continuous EOG, and a variable heart rate [22], [92].  2) Sleep Transitions and Indeterminate Sleep:   All three species‚Äîsheep, baboons, and humans‚Äîexhibit transitional or indeterminate fetal sleep states, reflecting the develop- mental complexity of sleep organization. In fetal sheep, these ambiguous states‚Äîoften termed inter- mediate sleep‚Äîare neither clearly REM nor NREM. Mellor (2005) linked them to immature brain regulation [23]. Quan- titative EEG studies identified two spectral intermediates, falling between high-voltage slow activity and low-voltage fast activity, as exemplified by the TR highlighted in black in Figure 1, accounting for   23% of recording time [93]. Rao et al. (2009) defined indeterminate sleep as transitional or mismatched EEG/EOG periods, excluded if under 3 minutes [94]. Such states may reflect neural transitions key to sleep maturation [95]. Fetal baboons also show EEG evidence of graded tran- sitions between quiet and active sleep. EEG-ratio analyses reveal sleep as a continuum, with up to 60% of time spent in indeterminate states [72], [84]. In humans, fetal sleep cycles last 70‚Äì90 minutes, with state transitions typically within 3 minutes [96], [97]. Inde-\n\n6  terminate states, defined by mismatched behavioral markers, occur in approximately 5‚Äì10% of recordings near term [21], suggesting lower prevalence compared to baboons.  3) Fetal   Arousal   and   Wakefulness:   The   definition   of arousal and wakefulness in the fetus remains contentious. In fetal sheep, brief periods of activity characterized by low- voltage electrocorticography (ECoG), EOG, and increased EMG activity have been interpreted as an aroused state [98], [99], [100], [101]. Nevertheless, accumulating evidence suggests that such episodes may merely reflect transitional phases between sleep states, rather than true wakefulness [23].   Direct   observations   of   unanaesthetized   fetal   sheep provide further evidence against the existence of true wake- fulness in utero. Rigatto et al. [24] observed a fetal sheep through a Plexiglas window for 5,000 hours and found no signs of wakefulness, such as eye opening or coordinated head movements. This suggests that fetal sheep remain in sleep-like states throughout gestation without experiencing a state that would be comparable to postnatal wakefulness. In fetal baboons, studies indicate that hiccups and gross fetal movements do not necessarily induce sleep-state tran- sitions, implying that fetal activity does not always equate to wakefulness [25]. Some researchers have suggested that fetal wakefulness, if present, is rare and might be a misclas- sification of state transitions [72]. In human fetuses, state 3F (quiet awake) is rarely ob- served,   and   state   4F   (active   awake),   though   defined,   is difficult to identify reliably due to obscured eye move- ments [21]. Some researchers suggest that fetal wakefulness may not exist in the same form as in neonates; episodes commonly interpreted as wakefulness could instead reflect transitions between sleep states [23]. As inferred from elec- trophysiological evidence, EEG activity during such periods may resemble spontaneous sleep-state transitions rather than sustained wakefulness [23]. The ability to intentionally wake the fetus is not well established. In fetal sheep, external stimuli such as ma- ternal hormone fluctuations influence fetal sleep patterns, but there is little evidence that these lead to wakefulness [77], [23]. In fetal baboons, experimental challenges such as hypoxia and auditory stimuli have been proposed to investigate   fetal   state   changes,   but   the   extent   to   which these lead to true wakefulness is unclear [25]. For human fetuses, vibroacoustic stimulation (VAS) has been studied as a method to elicit state transitions, but behavioral state organization remains largely resistant to external influences [102]. Nevertheless, early acoustic studies by Walker (1971) identified consistent intrauterine sound patterns originating from maternal cardiovascular activity, suggesting the fetal environment is shaped by rhythmic auditory input [103]. Moreover, term fetuses have been shown to display differen- tial heart rate responses to their mother‚Äôs voice compared to a stranger‚Äôs, indicating a capacity for auditory learning and in utero voice recognition [104]. Although factors such as maternal emotions, Braxton Hicks contractions, and uterine contractions during labor do not significantly alter fetal behavioral state patterns [102], these findings imply that specific types of auditory stimulation may modulate fetal physiology without necessarily inducing full wakefulness. All three species spend the majority of their time in sleep- like states, suggesting that fetal wakefulness, if it exists, is actively suppressed. In fetal sheep, mechanisms such as prostaglandin-mediated regulation and hypoxia-induced depression of breathing contribute to the maintenance of prolonged sleep-like states [77], [23]. Baboons exhibit a similar predominance of sleep-like states, with only brief transitions into undefined states [73]. In humans, the fetal nervous system appears to be adapted for continuous sleep- like states, with developing neuronal circuits reinforcing these patterns [105], [49]. Fetal sheep, baboons, and humans exhibit similar sleep- like states, though true wakefulness remains unclear. Tran- sitional states are frequent, and sleep organization matures with gestation. Across species, sleep state dominates with little evidence of sustained wakefulness before birth.  D. Maternal and External Factors  Maternal physiology and environmental conditions have been shown to influence fetal sleep states [64], [106]. Fetal sleep rhythms begin to develop in utero and are thought to be entrained by maternal melatonin and circadian cues [107]. Various factors, including maternal sleep position, circadian rhythms, sleep disorders, and external stressors, contribute to the regulation of fetal brain activity and be- havioral states. External stressors can also influence fetal sleep states. For example, hypoxia suppresses FBM and modifies EEG activity, a process likely mediated by elevated adenosine levels, which act as an inhibitory neuromodulator, and by increased neurosteroids such as allopregnanolone, which suppress neuronal excitation and protect the fetal brain [108], [109]. The position a mother adopts during sleep may affect FBS. Supine sleep is known to be associated with reduced uteroplacental perfusion, leading to fetal quiescence [64]. This reduction may be due to altered maternal cardiac output and uteroplacental perfusion, which transiently affect oxygen and nutrient delivery to the fetus, potentially influencing fetal sleep patterns and activity levels [110], [111], [112]. Late stillbirth is independently related to the position women adopt during sleep [64]. Vulnerable fetuses, who may already experience chronic hypoxia, have a reduced ability to adapt to maternal sleep position stressors [64]. Another study found that passive maternal movements, such as rocking or swaying, can alter fetal heart rate and potentially the behavioral states, likely through activation of the vestibular system [113]. Fetal sleep patterns are also closely linked to maternal circadian rhythms. Studies have shown that fetal sleep states align with maternal melatonin secretion and activity-rest cycles, indicating that maternal circadian rhythms play a role in regulating fetal brain activity [114]. Furthermore, maternal sleep-disordered breathing (SDB), such as sleep apnea, becomes more common in the third trimester and can disrupt the intrauterine environment by inducing noc- turnal hypoxia and heightened maternal autonomic activity. These changes have been associated with alterations in fetal physiological behaviors, including heart rate decelerations and reduced fetal breathing movements‚Äîboth of which are key indicators of fetal sleep states. While the precise impact on long-term neurodevelopment remains uncertain, these findings suggest that maternal SDB may acutely influence fetal sleep regulation [115], [116]. In summary, maternal physiological and environmental factors have significant effects on fetal sleep states through mechanisms involving hemodynamics, hormonal regulation,\n\n7  TABLE III C OMPARISON OF   F ETAL   S LEEP   M EASUREMENT   T ECHNIQUES  Measurement   Fetal Human (Non-invasive)   Fetal Sheep (Invasive)   Fetal Baboon (Invasive)  EEG/ECoG   Infeasible   Implanted electrodes [117], [93], [118]   Dural electrodes [67], [73], [72] EOG   Ultrasound imaging [119], [102]   Canthus electrodes [118], [45], [95]   Canthus electrodes [87], [84] EMG   Infeasible   Nuchal EMG [120], [121] Diaphragmatic EMG [122] Not Commonly used FHR   CTG [71], [65], [123] Abdominal ECG [124] Scalp ECG (Invasive) [125] FMCG [126], [127], [128], [129] Arterial pressure [120], [130] ECG [131] ECG electrodes [84] FBM   Ultrasound imaging [119], [102]   Tracheal catheter [132] Diaphragm EMG [133] Laryngeal EMG (PCA) [133] Tracheal catheter + amniotic subtraction [73], [25], [84] Body Movements   Actocardiogram [86], [129]   Limb EMG [45], [134] Ultrasound [135] Not Commonly used  and neural modulation. These factors collectively contribute to shaping fetal brain activity and behavioral states. IV. A CQUISITION OF   P HYSIOLOGICAL   S IGNALS IN THE  F ETUS  To understand fetal behavioral and sleep states, researchers have relied on both non-invasive technologies suitable for human fetuses and invasive modalities enabled by animal models such as fetal sheep and baboons. Table III summa- rizes the key measurement techniques across species. In the remainder of this section, we describe each modality in more detail, with a focus on signal types, acquisition methods, and the physiological information derived.  A. Non-Invasive Technologies for Human Fetus  In human fetal research, ethical and technical limitations necessitate the use of non-invasive techniques. These tech- nologies prioritize safety, cost-effectiveness, and practicality, while attempting to capture physiological signals linked to fetal behavioral states.  ‚Ä¢   Cardiotocography   (CTG) :   A   widely   used   method employing   1D   Doppler   ultrasound   to   monitor   fetal heart rate (FHR) and uterine contractions through the maternal abdomen [71], [65], [123]. CTG is low-cost and non-invasive [136], but it provides only a smoothed heart rate estimate rather than beat-to-beat intervals, limiting detailed HRV analysis [137], [138].  ‚Ä¢   FECG : Electrodes on the maternal abdomen record fetal cardiac signals, though maternal ECG interference often degrades signal quality [124]. A scalp electrode applied intrapartum offers improved fidelity but is in- vasive and limited to labor [125], [138].  ‚Ä¢   FMCG : A high-resolution modality that uses super- conducting   quantum   interference   devices   sensors   to detect fetal cardiac magnetic fields through the ma- ternal abdomen [126], [127], [128], [129]. It offers millisecond temporal resolution and is reported to be less susceptible to artifacts than FECG [139], but it is expensive and technically demanding.  ‚Ä¢   Ultrasound Imaging : Ultrasound is used to monitor fetal body and eye movements, amniotic fluid volume, breathing, and muscle tone [119], [102].  ‚Ä¢   Actocardiography :   Actocardiography   combines Doppler-derived FHR and movement data [86], [129], enabling richer behavioral state characterization [66].  B. Invasive Technologies in Animal Models  Several fetal monitoring techniques used in humans, in- cluding FECG and FMCG, are also employed in animal models. In particular, fetal sheep and baboons enable the use of invasive methods that offer high-resolution, direct physiological measurements. These modalities facilitate a more granular analysis of fetal sleep and behavior, including electrocortical activity, eye movements, respiration, muscle tone, and cardiovascular dynamics.  ‚Ä¢   EEG/ECoG : Electrodes implanted on or beneath the fetal   skull   record   electrocortical   activity.   In   sheep, stainless-steel   screws   and   solder-ball   electrodes   are used [117], [93], [118], [147]; in baboons, electrodes are placed on the dura mater [67], [73]. Signals are filtered (0.1‚Äì40 Hz or up to 100 Hz) and digitized at 50‚Äì200 Hz [130], [78]. Sleep states are differentiated by power spectral analysis: quiet sleep shows 1‚Äì4 Hz bursts (Trace Alternans), while active sleep exhibits elevated 12‚Äì24 Hz power [72]. Common measures include spectral edge frequency (SEF) and EEG-ratio (0.03‚Äì0.2 Hz vs. 12‚Äì24 Hz) [78], [82], [148].  ‚Ä¢   EMG : captures muscle activity via implanted electrodes and is used in fetal sheep to assess neuromuscular and respiratory activity. Limb EMG detects gross body movements through electrodes in muscles such as the quadriceps and triceps [45], [134], while nuchal EMG assesses muscle tone and sleep state transitions via electrodes in neck muscles [120], [121]. Diaphragmatic EMG reflects respiratory-related muscle activity and is used to detect FBM [122].  ‚Ä¢   EOG : detects eye movements through electrodes im- planted near the orbits (sheep) [118] or subcutaneously around the eye (baboons) [87].  ‚Ä¢   Respiratory Activity Monitoring : FBM are monitored invasively using pressure catheters or EMG electrodes. In sheep, a pressure catheter is placed in the fetal trachea to detect intrathoracic fluid shifts [132], while EMG electrodes can be sewn into respiratory muscles such as the diaphragm or posterior cricoarytenoid [133]. In baboons, tracheal and amniotic fluid pressures are measured with separate catheters to isolate breathing activity‚Äîa method also commonly used in fetal sheep studies [73], [25], [84]. Breathing is typically intermittent and linked to REM- like sleep, characterized by low-voltage ECoG [132]. These fetal breathing movements are essential not only\n\n8  TABLE IV C OMPARISON OF   EEG   AND   FHR F REQUENCY   B AND   D EFINITIONS   A CROSS   S PECIES  Signal Type   Fetal Human   Fetal Sheep   Fetal Baboon  EEG   Not available in fetal human stud- ies Delta   (0‚Äì3.9   Hz),   Theta   (4‚Äì7.9 Hz), Alpha (8‚Äì12.9 Hz), Beta (13‚Äì 22 Hz) [140], [91] Delta (1‚Äì4 Hz), Theta (4‚Äì7 Hz), Alpha   (8‚Äì12   Hz),   Beta1   (14‚Äì18 Hz), Beta2 (22‚Äì29 Hz) [78] FHR   VLF (0.02‚Äì0.08 Hz), LF (0.08‚Äì0.2 Hz), Intermediate (0.2‚Äì0.4 Hz), HF (0.4‚Äì1.7 Hz) [141], [142], [143] VLF (0‚Äì0.04 Hz), LF (0.04‚Äì0.15 Hz),   HF   (0.15‚Äì0.4   Hz)   [144], [145], [146] LF   (0.05‚Äì0.2   Hz),   HF   (0.5‚Äì2.0 Hz) [84]  for lung development but also for training the neural circuits that control respiration and for strengthening respiratory muscles in preparation for breathing after birth. Data are digitized at rates such as 25 Hz for waveform analysis [73].  ‚Ä¢   Cardiovascular Signal Acquisition : Fetal heart rate is derived from ECG, arterial pressure signals, or Doppler flow   probes   secured   onto   major   arteries.   In   sheep, ECG electrodes are implanted on the chest [131] or pressure waveforms are recorded via catheters in fetal arteries   [120], [130]. In baboons, ECG leads with silver solder balls are fixed beneath the skin over the precordium [84], [67].  C. Comparison of EEG and FHR Frequency Bands  Table IV compares EEG and FHR frequency band defi- nitions across fetal human, sheep, and baboon studies. This table highlights a key challenge in cross-species compar- isons: the frequency band boundaries, especially for EEG rhythms, vary considerably due to both biological differences and species-specific research conventions. For instance, delta and theta bands in fetal sheep span wider frequency ranges than in baboons. Similarly, the definition of FHR bands such as very low frequency (VLF) and high frequency (HF) also differs between species, which complicates the translation of findings from animal models to human contexts. Recogniz- ing these inconsistencies is essential for interpreting spectral analyses and designing cross-species comparative studies. V. A UTOMATIC   C LASSIFICATION OF   F ETAL   S LEEP  Fetal sleep classification has been explored using rule- based and deep learning approaches. Rule-based methods rely on expert-defined thresholds and logic rules, sometimes supported   by   clustering-based   preprocessing   such   as   K- means. In contrast, deep learning enables end-to-end, data- driven modeling from raw physiological signals. Table V summarizes key distinctions across these approaches. The following subsections detail each category, including recent developments in multimodal signal integration.  A. Fetal Heart Rate Variability Analysis 1) Physiological Basis of FHRV in Sleep:   Sleep states in fetuses are associated with distinct changes in physiological parameters, prominently fetal heart rate variability (FHRV) [84], [68]. In humans, transitions between sleep states are reflected in changes in heart rate patterns, strongly corre- lating with behavioral states defined by heart rate, body movements, and eye movements [21]. Similar correlations have been observed in fetal baboons, where FHRV measures, combined with EOG and EEG data, have been successfully used to define behavioral state cycles [87]. High EEG-Ratio periods, indicative of quiet sleep, correspond to lower heart rates and reduced FHRV in fetal baboons [72], suggesting that ANS modulation of FHRV is influenced by sleep states [87]. In fetal sheep, physiological studies show distinct differ- ences in FHRV between sleep states. Quiet sleep is typically associated with lower beat-to-beat variability compared to active sleep, indicating varying ANS modulation [68].  2) Feature Extraction for Sleep Classification:   Feature extraction from FHRV typically relies on time-domain and frequency-domain measures derived from RR intervals. In fetal baboons, features such as the standard deviation of RR intervals (SD-RR) and the root mean square of successive differences (RMSSD) are computed on a minute-by-minute basis, provided that at least 90% of RR intervals are artifact- free [84]. In human fetal studies, SDNN, RMSSD, and per- mutation entropy have similarly been employed to classify sleep states [129]. In fetal sheep, frequency-domain spectral measures‚Äîsuch as low-frequency (LF), HF, and the LF/HF ratio‚Äîhave been used to differentiate FBS [68]. However, the interpretation of LF/HF as a marker of sympatho-vagal balance is controversial, as LF power reflects a combination of sympathetic and parasympathetic influences, and the ratio can be affected by non-neural factors such as respiration and heart rate [151].  B. Rule-based Approaches 1) Threshold-Based Classification Using FMCG and Ac- togram Signals:   Rule-based approaches for FBS classifica- tion typically rely on deterministic thresholds derived from physiological signals, such as HRV and actogram-based fetal movement data. These systems apply expert-defined rules to classify states by comparing extracted features with fixed thresholds. While these methods provide interpretable and practical solutions for assessing fetal sleep and wakefulness, they lack the flexibility to adapt to individual variability and gestational changes, limiting their robustness in real-world scenarios. In 2016, Vairavan et al. [65] developed an early automated pipeline for FBS classification using FMCG recordings from 39 fetuses between 30 and 38 weeks of gestation. They trans- lated Nijhuis criteria [21] into fixed-threshold rules based on fetal heart rate patterns and actogram-derived movements. The system demonstrated strong agreement with expert an- notations, particularly for quiet sleep (intraclass correlation coefficient (ICC) = 0.88), though performance declined for active sleep in later gestation (ICC dropped to 0.41). These findings suggest that while rule-based classification is feasi- ble with FMCG and CTG, behavioral complexity increases with maturation, potentially limiting such approaches. Building on Vairavan et al.‚Äôs work, Semeia et al. [63] refined rule-based FBS classification by introducing ges- tational   age-specific   distinctions.   Using   a   large   FMCG dataset,   they   separated   younger   ( < 32   weeks)   and   older\n\n9  TABLE V C OMPARISON OF   FBS C LASSIFICATION   S TUDIES  Study   Species   Sample Size Gestational Age Signals Used   Method   States Identified   Performance  Vairavan et al. (2016) [65] Human fetuses   39   30‚Äì38 weeks   FMCG   (HR   + Actogram) Rule-based thresholds + ROC optimization  < 36 wks: 1F vs. 2F  ‚â• 36 wks: 1F vs. 2F  < 36 wks: ICC = 0.88 (1F), 0.65 (2F)  ‚â• 36 wks: ICC = 0.88 (1F), 0.41 (2F) AUC = 0.99 (both) Semeia   et   al. (2022) [63] Human fetuses   52   27‚Äì39 weeks   FMCG   (HRV   + Actogram) Rule-based thresholds + ROC optimization  < 32 wks: Active vs. Passive  ‚â• 32 wks: 1F vs. 2F  < 32 wks: AUC   ‚âà   1.0 (HRV), 0.80‚Äì0.83 (Actogram)  ‚â• 32 wks: AUC   ‚âà   1.0 (HRV), 0.86‚Äì0.87 (Actogram) Myers   et   al. (1993) [72] Fetal baboons   3   143‚Äì153 days EEG   (frontal   + parietal) Rule-Based (K-means preprocessing) 1F vs. 2F   Expert agreement: 87.1% (Overall) 79.7% (1F), 91.3% (2F) Grieve   et   al. (1994) [87] Fetal baboons   3   80%‚Äì90% of term EEG, EOG, ECG   Rule-Based (K-means preprocessing) 1F vs. 2F   Expert agreement: 81.5% (Overall) 83.7% (1F), 79.4% (2F) Samjeed (2022) [149] Human fetuses   105   20‚Äì40 weeks   Non-invasive fetal   ECG   (NI- fECG) 1D CNN   1F vs. 2F   F1: 80.2% (1F), 69.5% (2F) Accuracy: 76% Sensitivity: 72.7% (1F), 82.6% (2F) Subitoni (2022) [150] Human fetuses   115   27‚Äì39 weeks (grouped: early/mid/late) FHR   HMM   +   CNN   (Hy- brid) 1F vs. 2F   HMM+CNN:  F1: 87.87%, Balanced Acc: 88.37%  HMM only:  F1: 77.73%, Balanced Acc: 83.30%  ( ‚â• 32 weeks) fetuses and adapted the classification accord- ingly‚Äîdistinguishing active/passive states in early gestation and 1F/2F states later. Their results showed that HRV-derived parameters, especially RMSSD and standard deviation (STD) of HR, achieved near-perfect classification accuracy (AUC  ‚âà   1.0), while actogram-based features were less reliable. These findings reinforce the utility of HRV metrics for FBS classification and highlight the need for developmental stage- specific models. Both studies demonstrated that rule-based approaches can achieve high classification accuracy for prototypical FBS, but their reliance on fixed thresholds restricts their adaptability across different gestational ages and individual variations. The absence of a temporal component in these models makes it difficult to capture transitional states that naturally occur as fetal development progresses. Moreover, rule-based meth- ods do not account for probabilistic uncertainty, potentially leading to overconfidence in misclassified instances. Semeia et al. [63] identified a key limitation of rule- based methods: substantial overlap in parameters between quiet and active sleep, which hampers accurate classifi- cation‚Äîespecially during transitional phases with gradual physiological changes. This suggests such methods may oversimplify the complex dynamics of FBS. As shown in Table V, Vairavan et al. [65] and Semeia et al. [63] achieved good results using FMCG, but did not assess generalizability to more accessible modalities like CTG. Their methods also struggle with fetal state transitions and individual variability, highlighting the need for more advanced probabilistic and machine learning approaches.  2) Rule-Based   Classification   Using   K-means   and EEG/Multimodal Signals:   Unsupervised clustering methods have been explored for FBS classification, particularly using K-means applied to spectral EEG features. Myers et al. [72] proposed an early rule-based method using fetal baboon EEG data.   They   developed the   ‚ÄúEEG-Ratio‚Äù   defined as the power in the 0.03‚Äì0.2 Hz band (associated with trace alternant) divided by power in the 12‚Äì24 Hz band. This feature   correlated   with   visually   scored   sleep   states,   and K-means clustering was applied to classify data into two binary states: trace alternant (TA, representing quiet sleep) and   non-TA   (active   sleep).   The   resulting   classification achieved an 87.1% agreement with expert scoring. However, the study had limitations. It included only three fetal baboons, each contributing four EEG recordings, to- taling 3,694 minutes of usable data. The authors did not use any form of cross-validation or independent testing, as thresholds were optimized and validated on the same dataset, potentially inflating accuracy estimates. Moreover, the EEG-Ratio‚Äîbeing a scalar feature‚Äîmay not generalize well across subjects or conditions. To improve robustness, Grieve et al. [87] extended this approach by integrating multimodal signals‚ÄîEEG, EOG, and ECG‚Äîfrom the same three fetal baboons, each recorded for 16 continuous hours. They applied K-means clustering to extract binary thresholds for three features: EEG ratio, EOG spectral power, and RR interval variability (CVRR). These features were then combined using rule-based cri- teria to define two sleep states: 1F (quiet sleep) and 2F (active sleep). Transitions and indeterminate states were also identified using temporal continuity rules. Agreement with expert annotations reached 81.5% overall (83.7% for 1F and 79.4% for 2F), demonstrating the feasibility of long-term, automated multimodal classification. While the use of multimodal features provided a more physiologically grounded framework, limitations remained, including small sample size, absence of gestational stratifi- cation, and no direct comparison with unimodal or machine learning-based models. Nonetheless, these early efforts laid the groundwork for automated fetal sleep state detection using interpretable, unsupervised approaches.\n\n10  C. Machine Learning Approaches  Deep learning has emerged as a powerful tool for classify- ing FBS from physiological signals. Two recent studies‚Äîby Samjeed et al. [149] and Subitoni et al. [150]‚Äîhave pro- posed deep neural network-based methods leveraging fetal ECG and FHR signals, respectively. Samjeed et al. [149] proposed a 1D convolutional neural network (1D-CNN) to classify fetal behavioral states from non-invasive   abdominal   ECG   recordings   of   105   fetuses (20‚Äì40 weeks gestation, 3‚Äì10 min duration). The CNN consisted of three convolutional layers and was trained using stochastic gradient descent with momentum (SGDM) with 5-fold cross-validation. It achieved 76% accuracy, with F1- scores of 80.2% for the quiet state and 69.5% for the active state, suggesting challenges in distinguishing between states. Limitations included dataset imbalance, lack of temporal modeling, and use of a single modality. Future directions included exploring recurrent neural networks (RNNs), mul- timodal inputs, and transfer learning. Subitoni et al. [150] proposed a hybrid model combining hidden markov models (HMMs) and a U-Net style 1D-CNN (U-Sleep variant) to classify fetal behavioral states from 115 manually annotated FHR recordings. The dataset was stratified into three gestational age groups (27‚Äì32, 33‚Äì36, 37‚Äì39 weeks) to account for developmental differences. The approach used HMMs for unsupervised segmentation to generate pseudo-labels, which were then used to pre-train a CNN. The model was subsequently fine-tuned using expert annotations. This two-stage training allowed the system to leverage both unlabeled and labeled data. The hybrid model achieved a Macro F1-score of 87.87%, outperforming   the   HMM   alone   (77.73%).   However,   the study did not clarify whether evaluation was subject-wise or sample-wise, and relied on annotations from a single expert, limiting generalizability. Still, the method demonstrates a promising strategy to reduce dependence on annotated data via hybrid learning. VI. E FFECTS OF   A BNORMAL   C ONDITIONS ON   F ETAL  S LEEP  A. Hypoxia  Hypoxia is a major disruptor of fetal sleep and neu- rodevelopment. Graded hypoxia experiments in fetal sheep have demonstrated significant disruptions in sleep states, including altered ECoG and behavioral activity [152], [68]. Koos et al. [152] reported that mild hypoxia did not alter the incidence of low-voltage ECoG activity, FBM, or REMs, whereas moderate and severe hypoxia markedly suppressed both FBM and REMs. A critical threshold was identified, with a reduction in arterial oxygen content of   2 . 00   ¬±   0 . 23  ml/dl associated with inhibition of both eye and breathing activity. Recent studies have further characterized hypoxia-induced brain dysfunction through temporal assessments of EEG power   and   frequency   recovery.   In   a   fetal   sheep   model of asphyxia, prophylactic creatine supplementation signifi- cantly improved EEG recovery after umbilical cord occlusion (UCO), with higher power and faster restoration of physio- logically organized frequencies, and reduced electrographic seizure burden. These effects were accompanied by reduced cortical cell death and white matter gliosis [153]. Moreover, integration   of   low-   and   high-voltage   EEG   activity   with nuchal EMG recordings provided detailed insights into sleep state reorganization under hypoxic stress. In contrast, while magnesium sulfate attenuated gliosis and modestly improved myelin density in white matter tracts, it failed to improve EEG power, frequency, or sleep-state cycling in preterm fetal sheep exposed to hypoxia‚Äìischemia. Neuronal and oligodendrocyte survival were similarly unaf- fected, suggesting limited functional neuroprotection despite some histological benefit [69]. Prolonged hypoxia in late gestation can cause persistent suppression of EEG activity and dysmaturation of sleep states. In preterm fetal sheep, UCO led to a shift towards lower frequency EEG activity for the first five days, with a lasting reduction in EEG power in the delta and theta bands [140]. Chronic hypoxia impairs gestational age-related increases in overall fetal HRV, with evidence of suppressed sympathetic nervous system control of HRV after 72 hours of hypoxia exposure [68]. Hypoxia alters fetal brain activity by promoting inhibitory neuromodulatory pathways, notably via elevated adenosine and increased neurosteroids such as allopregnanolone, re- sulting in predominant sleep-like EEG states [108], [109]. In parallel with these central nervous system effects, hy- poxia markedly reduces fetal forelimb movements and abol- ishes rapid eye movements, reflecting oxygen-conserving behavioral adaptations in fetal lambs [134]. These EEG changes   under   hypoxic   conditions   are   thought   to   result from adenosine-mediated inhibition and may suggest com- pensatory autonomic regulation [108]. Acute fetal hypoxia, induced by reduced uterine blood flow or UCO, suppresses FBM, a response associated with elevated adenosine levels in the brain under hypoxic conditions [154], [155], [156]. Severe hypoxia further leads to muscle atonia, as reported by Breen et al. [157]. Neurophysiological studies indicate that the fetal midbrain regulates episodic breathing and mediates hypoxic inhibition of respiratory activity [158]. Koos et al. [159] identified the parafascicular nuclear complex in the caudal thalamus as a critical structure mediating the suppres- sion of fetal breathing during acute hypoxemia. While this inhibition is an acute response, it is important to recognize that severe or prolonged hypoxemia may lead to cerebral ischemia and encephalopathy, potentially altering fetal EEG patterns even after the hypoxic insult has passed [160]. Hypercapnia during REM sleep enhances fetal breathing by increasing tracheal pressure and reducing apneic pauses, with CO 2   stimulation of breathing observed only during REM sleep in fetal lambs [161]. Neurophysiological studies indicate that the fetal midbrain regulates episodic breathing and mediates hypoxic inhibition of respiratory activity [158]. Koos et al. [159] identified the parafascicular nuclear com- plex in the caudal thalamus as a critical structure mediating the suppression of fetal breathing during acute hypoxemia. While this inhibition is an acute response, it is important to recognize that severe or prolonged hypoxemia may lead to cerebral ischemia and encephalopathy, potentially alter- ing fetal EEG patterns even after the hypoxic insult has passed [160].  B. Fetal Growth Restriction (FGR)  FGR disrupts the normal organization of fetal sleep states, particularly in late gestation. Growth-restricted fetuses ex- hibit greater sleep-state instability, often spending more time in quiet sleep than in active sleep [162], [163]. In addition,\n\n11  FGR is commonly associated with impaired oxygenation, reduced breathing and general movements, and an increased number of heart rate decelerations, reflecting ANS dysfunc- tion [164], [165]. FGR fetuses also show diminished motor activity, charac- terized by slower, monotonous, and lower-amplitude move- ments,   which   reflect   central   nervous   system   impairment [105], [166], [167]. These disturbances are considered late- stage indicators of fetal compromise, often preceded by abnormalities in HRV and blood flow parameters [105], [168]. Collectively, these findings highlight FBS as important indicators of neurodevelopment and fetal well-being.  C. Fetal Congenital Malformations  Structural or chromosomal abnormalities often correlate with altered fetal sleep states and reduced fetal movements (hypokinesia), linked to prolonged periods of low heart rate variability [169], [105], [168].  D. Other Maternal Conditions  Several maternal and fetal abnormalities influence fetal sleep patterns, directly or indirectly:  1) Maternal Diabetes:   Fetuses of diabetic mothers may show delayed sleep-state development between 32 and 40 weeks, often lacking the typical increase in quiet and active sleep seen in normal pregnancies [170].  2) Maternal Sleep Position:   In the third trimester, the maternal supine sleep position significantly impacts FBS, increasing the likelihood of a transition towards quiet sleep due to reduced uterine perfusion and oxygen availability [171]. Such adaptation might reflect a fetal compensatory mechanism for reduced oxygen supply [171], [64].  3) Maternal Anxiety and Stress:   Although explicit data on fetal sleep states remain limited, growing evidence highlights the significant impact of maternal psychological stress and anxiety on fetal development. Maternal self-reported anxiety has been associated with reduced expression of placental 11 Œ≤ -hydroxysteroid dehydrogenase type 2 (11 Œ≤ -HSD2), an enzyme critical for inactivating cortisol, thereby increasing fetal exposure to maternal glucocorticoids and potentially disrupting fetal neuroendocrine development [172]. Such endocrine   alterations   represent   one   of   the   physiological pathways suspected to contribute to the later emergence of psychological disorders [173]. Longitudinal   studies   have   elucidated   the   role   of   the pregnancy period in the intergenerational transmission of stress [174]. Prenatal stress exposure has also been asso- ciated with impaired fetal growth [175], and these growth alterations are further linked to subsequent behavioral traits, including   temperament   in   childhood   [176]   and   adoles- cence [177]. In addition to growth-related outcomes, maternal stress has been shown to directly alter the development of the fetal ANS. Specifically, maternal stress can entrain FHR patterns with maternal heart rate (HR) decelerations during respiratory efforts [178], and stressed mothers exhibit altered maternal-fetal HR coupling, characterized by significant de- creases in FHR, suggesting the presence of a fetal stress memory that may serve as a novel non-invasive biomarker of prenatal stress exposure [178]. Furthermore, recent evidence suggests that placental calcifications may reflect cumulative prenatal exposure to maternal stress and disease, potentially acting as a biological memory of the intrauterine environ- ment. These placental adaptations may influence offspring cardiovascular and metabolic health through modulation of fetal ANS development [179]. Collectively,   these   findings   imply   that   maternal   stress during pregnancy may have broad implications for fetal neu- robehavioral development, including pathways potentially relevant to the regulation of sleep states, autonomic function, and long-term health outcomes.  4) Alcohol   Consumption:   Alcohol   exposure,   even episodic, disrupts fetal REM sleep and drastically reduces fetal   breathing   activity,   potentially   leading   to   long-term neurobehavioral consequences characteristic of fetal alcohol syndrome (FAS) [97]. Such effects were demonstrated in a   controlled   study   where   maternal   consumption   of   two glasses of wine suppressed fetal REM activity and breathing movements [97]. These disruptions may underlie some of the neurobehavioral and ophthalmic deficits observed in FAS [105].  5) Smoking:   Smoking during pregnancy has been as- sociated with significant alterations in PE, reflecting dis- rupted autonomic regulation before birth [180], [181], [52]. Such autonomic disruptions may also suggest potential dis- turbances in fetal sleep-state organization, though specific sleep-related effects require further investigation.  6) Caffeine Intake:   Maternal caffeine consumption affects FBS organization, increasing general body movements and altering sleep-wake patterns, with a trend toward reduced breathing activity [182].  7) Magnesium Sulfate Administration:   Magnesium sul- fate reduces FBM [119] and has been reported to cause fetal bradycardia and diminished HRV, possibly through maternal hypothermia or direct fetal cardiac effects [183]. Recent studies in preterm fetal sheep further demonstrate that magnesium sulfate suppresses FHR, EEG activity, and increases cardiac afterload, all of which may influence fetal behavioural   states   [184],   [185],   [186].   In   addition,   sex- specific differences have been observed in EEG suppression and cardiovascular responses to hypoxia, suggesting that fetal sex may modulate the effects of pharmacological inter- ventions on fetal behaviour [186]. Additionally, concurrent use   of   magnesium   sulfate   and   nifedipine   may   result   in severe hypotension and cardiac depression in the fetus [187]. These effects may potentially impact FBS, although specific disruptions in sleep-related behaviors remain to be clarified.  8) Antidepressants:   Selective   serotonin   reuptake   in- hibitors are commonly prescribed to manage maternal anxi- ety and depression during pregnancy [188]. According to findings reported by Mulder et al. [189] and summarized in this chapter [105], fetal exposure to standard or high Selective serotonin reuptake inhibitors dosages was associated with increased general movements and disrupted NREM sleep near term, characterized by persistent bodily activity and impaired inhibitory motor control during quiet states. However, the significance of poor fetal sleep reg- ulation for postnatal neurobehavioral development remains unclear and warrants further investigation [105].  E. Intra-amniotic Infection (Chorioamnionitis)  Intra-amniotic infections, including clinical and subclini- cal chorioamnionitis, have been associated with loss of fetal heart rate cycling and adverse perinatal outcomes, supporting the role of inflammation in fetal behavioral dysregulation\n\n12  [190]. More recently, absence of fetal heart rate cycling has also been linked to maternal intrapartum pyrexia, with af- fected fetuses showing lower neonatal Apgar scores, further suggesting disruption in FBS organization [191]. As fetal heart rate cycling reflects the alternation between active and quiet sleep, these findings imply that intra-amniotic infection may disturb fetal sleep-wake cycling. Consistent with this, progressive   systemic   inflammation   in   late-gestation   fetal sheep leads to suppression of high-frequency EEG activity, particularly in the beta and gamma bands, which are believed to reflect cortical activation and sleep state transitions. These EEG alterations were sustained even after the resolution of inflammation, suggesting persistent disruption of fetal behavioral state cycling [147]. In conclusion, although specific evidence on the direct impact of these abnormalities on fetal sleep is limited, the observed disruptions in fetal movements, HRV and breathing patterns highlight potential implications for fetal sleep states. Understanding these links further emphasizes the importance of monitoring fetal sleep as a critical parameter in fetal surveillance. VII. F UTURE   D IRECTIONS AND   C HALLENGES  A. Limitations of Current Studies 1) Technological Limitations:   While current tools have advanced FBS research, technologies like ultrasound, CTG, and FMCG face limitations such   as low signal quality, motion artifacts, and limited applicability in early gestation. Fetal MRI provides better CNS insights but is costly and inaccessible. Overall, existing methods lack the resolution and scope to fully capture early fetal neurodevelopment and sleep transitions.  2) Analytical Challenges:   FBS detection often depends on visual inspection or algorithms trained on prototypical segments, overlooking transitional or ambiguous states that may offer important developmental insights. Inconsistent terminology across studies further hinders reproducibility and comparison. Most methods also fail to capture complex dynamics like diurnal rhythms or maternal-fetal interactions.  3) Sample   Size   and   Interindividual   Variability:   Small sample sizes limit the statistical power and generalizabil- ity   of   fetal   sleep   studies,   especially   in   linking   FHR   to biochemical markers. Variability across fetuses‚Äîdriven by gestational   age,   maternal   health,   and   environmental   fac- tors‚Äîcomplicates standardizing FBS classification. Broad gestational groupings (e.g., mid and late gestation) may mask critical developmental transitions.  4) Longitudinal and Genetic Considerations:   Links be- tween prenatal sleep and postnatal outcomes are limited by long assessment gaps and unaccounted genetic influences shared by mother and fetus. This highlights the need for integrated, genetically-informed longitudinal studies to better explain outcome variability.  B. Future Research Directions  To overcome current limitations, future research should explore advanced analytical tools‚Äîsuch as point process models and detailed HRV metrics‚Äîto uncover biomarkers of fetal brain and ANS development. Although fetal EEG is infeasible in humans, invasive recordings in animal mod- els (e.g., sheep, baboons) can inform the interpretation of non-invasive human data (e.g., FMEG, FMCG, coherence). Cross-modal integration of spatio-temporal and synchrony features may further elucidate fetal CNS maturation and sleep-state transitions. Improving automated FBS detection remains critical. Ma- chine   learning   models,   validated   against   tools   like   fetal MRI and synchronized physiological signals, can increase reproducibility and standardization. Establishing consistent terminology and definitions will also enhance model gener- alizability and cross-study comparability. To address small sample sizes and individual variability, transfer learning is a promising solution. Pretrained models on adult sleep data can be fine-tuned on fetal recordings, leveraging shared low-level features while adapting high- level patterns to fetal physiology. This reduces data demands and improves model robustness across gestational ages and maternal-fetal conditions. In addition, adult sleep data can be transformed to better match the spectral characteristics of fetal sleep data using signal processing or generative adver- sarial networks (GANs). Aligning spectral distributions in this way provides a more compatible source for fine-tuning, further enhancing transfer learning performance. Inspired by reinforcement learning, reward-guided fine-tuning based on physiological plausibility or expert preference can further improve adaptation across gestational stages. A multidisciplinary approach‚Äîlinking neuroscience, ob- stetrics, and neuroimaging‚Äîis essential. Longitudinal stud- ies from early gestation to infancy with continuous maternal- fetal monitoring can clarify developmental trajectories, espe- cially sleep-state transitions and maternal influences. Further exploration of vagal tone and ANS maturation may identify critical periods of vulnerability. Refining mea- surement tools through multimodal integration will be key to developing clinical guidelines for identifying fetuses at risk of autonomic or neurodevelopmental disorders. Ultimately,   a   comprehensive   perinatal   perspec- tive‚Äîrecognizing   bidirectional   maternal-fetal   interactions and   the   continuity   of   sleep-state   development‚Äîis   vital. Monitoring   fetal   sleep   may   enable   early   detection   of FGR,   chronic   hypoxia,   or   emerging   neurological   issues. Early intervention (e.g., optimized delivery, neuroprotective agents, maternal care) is crucial for improving long-term outcomes during this sensitive developmental window. R EFERENCES  [1] M. Mirmiran, Y. G. Maas, and R. L. Ariagno, ‚ÄúDevelopment of fetal and neonatal sleep and circadian rhythms,‚Äù   Sleep Medicine Reviews , vol. 7, pp. 321‚Äì334, Aug. 2003. [2] F. Cerritelli, M. G. Frasch, M. C. Antonelli, C. Viglione, S. Vecchi, M. Chiera, and A. Manzotti, ‚ÄúA review on the vagus   nerve   and   autonomic   nervous   system   during   fetal development: Searching for critical windows,‚Äù   Frontiers in Neuroscience , vol. 15, p. 721605, Sept. 2021. [3] P. Luu and D. M. Tucker, ‚ÄúContinuity and change in neural plasticity through embryonic morphogenesis, fetal activity- dependent synaptogenesis, and infant memory consolidation,‚Äù  Developmental Psychobiology , vol. 65, p. e22439, Dec. 2023. [4] M. Mirmiran, ‚ÄúThe function of fetal/neonatal rapid eye move- ment sleep,‚Äù   Behavioural Brain Research , vol. 69, pp. 13‚Äì22, July 1995. [5] M. Mirmiran, Y. G. Maas, and R. L. Ariagno, ‚ÄúDevelopment of fetal and neonatal sleep and circadian rhythms,‚Äù   Sleep Medicine Reviews , vol. 7, no. 4, pp. 321‚Äì334, 2003. [6] S. N. Graven and J. V. Browne, ‚ÄúSleep and brain develop- ment,‚Äù   Newborn and Infant Nursing Reviews , vol. 8, pp. 173‚Äì 179, Dec. 2008. [7] T. V. De Beritto, ‚ÄúNewborn sleep: Patterns, interventions, and outcomes,‚Äù   Pediatric Annals , vol. 49, Feb. 2020.\n\n13  [8] J.-J. d‚ÄôOrtous de Mairan, ‚ÄúObservation botanique,‚Äù in   Histoire de l‚ÄôAcad¬¥ emie royale des sciences, avec les m¬¥ emoires de math¬¥ ematique et de physique tir¬¥ es des registres de cette Acad¬¥ emie , pp. 35‚Äì36, Acad¬¥ emie Royale des Sciences, 1729. [9] J. Davy, ‚ÄúOn the temperature of man,‚Äù   Philosophical Transac- tions of the Royal Society of London , vol. 135, pp. 319‚Äì326, 1845. Read June 19, 1845. [10] H. Berger, ‚Äú ¬® Uber das elektroenkephalogramm des menschen,‚Äù  Archiv f¬® ur psychiatrie und nervenkrankheiten , vol. 87, no. 1, pp. 527‚Äì570, 1929. [11] A. L. Loomis, E. N. Harvey, and G. Hobart, ‚ÄúElectrical potentials   of   the   human   brain,‚Äù   Journal   of   experimental Psychology , vol. 19, no. 3, p. 249, 1936. [12] E. Aserinsky and N. Kleitman, ‚ÄúRegularly occurring periods of eye motility, and concomitant phenomena, during sleep,‚Äù  Science , vol. 118, no. 3062, pp. 273‚Äì274, 1953. [13] W. Dement and N. Kleitman, ‚ÄúCyclic variations in EEG during   sleep   and   their   relation   to   eye   movements,   body motility, and dreaming,‚Äù   Electroencephalography and Clin- ical Neurophysiology , vol. 9, no. 4, pp. 673‚Äì690, 1957. [14] A. Rechtschaffen and A. Kales, eds.,   A Manual of stan- dardized terminology, techniques and scoring system of sleep stages in human subjects .   Los Angeles: Brain Information Service/Brain Research Institute, University of California, 1968. [15] M. Sterman, ‚ÄúRelationship of intrauterine fetal activity to ma- ternal sleep stage,‚Äù   Experimental Neurology , vol. 19, pp. 98‚Äì 106, Dec. 1967. [16] O. Petre-Quadens, A. De Barsy, J. Devos, and Z. Sfaello, ‚ÄúSleep in pregnancy: Evidence of foetal-sleep characteristics,‚Äù  Journal of the Neurological Sciences , vol. 4, pp. 600‚Äì605, May 1967. [17] Y. Ruckebusch, ‚ÄúActivit¬¥ e ¬¥ electro-corticale chez le f≈ìtus de la brebis (Ovis aries) et de la vache (Bos taurus),‚Äù   Revue de M¬¥ edecine V¬¥ et¬¥ erinaire , vol. 122, pp. 483‚Äì510, 1971. [18] L. I. Mann, S. Duchin, and R. R. Weiss, ‚ÄúFetal EEG sleep stages and physiologic variability,‚Äù   American Journal of Ob- stetrics and Gynecology , vol. 119, pp. 533‚Äì538, June 1974. [19] Y. Ruckebusch, M. Gaujoux, and B. Eghbali, ‚ÄúSleep cycles and kinesis in the foetal lamb,‚Äù   Electroencephalography and Clinical Neurophysiology , vol. 42, pp. 226‚Äì237, Feb. 1977. [20] M. Granat, P. Lavie, D. Adar, and M. Sharf, ‚ÄúShort-term cy- cles in human fetal activity,‚Äù   American Journal of Obstetrics and Gynecology , vol. 134, pp. 696‚Äì701, July 1979. [21] J. Nijhuis, H. Prechtl, C. Martin, and R. Bots, ‚ÄúAre there behavioural states in the human fetus?,‚Äù   Early Human Devel- opment , vol. 6, pp. 177‚Äì195, Apr. 1982. [22] J. G. Nijhuis, ‚ÄúBehavioural states: Concomitants, clinical im- plications and the assessment of the condition of the nervous system,‚Äù   European Journal of Obstetrics & Gynecology and Reproductive Biology , vol. 21, pp. 301‚Äì308, May 1986. [23] D. J. Mellor, T. J. Diesch, A. J. Gunn, and L. Bennet, ‚ÄúThe importance of ‚Äòawareness‚Äô for understanding fetal pain,‚Äù  Brain Research Reviews , vol. 49, pp. 455‚Äì471, Nov. 2005. [24] H. Rigatto, M. Moore, and D. Cates, ‚ÄúFetal breathing and behavior measured through a double-wall plexiglas window in sheep,‚Äù   Journal of Applied Physiology , vol. 61, no. 1, pp. 160‚Äì164, 1986. [25] R. I. Stark and M. M. Myers, ‚ÄúBreathing and hiccups in the fetal baboon,‚Äù in   Fetal Development , pp. 51‚Äì65, Psychology Press, 2013. [26] N. Baranwal, K. Y. Phoebe, and N. S. Siegel, ‚ÄúSleep phys- iology,   pathophysiology,   and   sleep   hygiene,‚Äù   Progress   in Cardiovascular Diseases , vol. 77, pp. 59‚Äì69, 2023. [27] A. K. Patel, V. Reddy, K. R. Shumway, and J. F. Araujo, ‚ÄúPhysiology, sleep stages,‚Äù in   StatPearls [Internet] , StatPearls Publishing, 2024. [28] I. Feinberg and T. Floyd, ‚ÄúSystematic trends across the night in human sleep cycles,‚Äù   Psychophysiology , vol. 16, no. 3, pp. 283‚Äì291, 1979. [29] P. Memar and F. Faradji, ‚ÄúA novel multi-class EEG-based sleep stage classification system,‚Äù   IEEE Transactions on Neu- ral Systems and Rehabilitation Engineering , vol. 26, no. 1, pp. 84‚Äì95, 2017. [30] B. Jones, ‚ÄúParadoxical rem sleep promoting and permitting neuronal networks,‚Äù   Archives Italiennes De biologie , vol. 142, no. 4, pp. 379‚Äì396, 2004. [31] R. Boissard, D. Gervasoni, M. H. Schmidt, B. Barbagli, P. Fort, and P.-H. Luppi, ‚ÄúThe rat ponto-medullary network responsible for paradoxical sleep onset and maintenance: A combined microinjection and functional neuroanatomical study,‚Äù   European Journal of Neuroscience , vol. 16, no. 10, pp. 1959‚Äì1973, 2002. [32] M.-C. Xi, F. R. Morales, and M. H. Chase, ‚ÄúThe motor inhibitory system operating during active sleep is tonically suppressed by gabaergic mechanisms during other states,‚Äù  Journal of Neurophysiology , vol. 86, no. 4, pp. 1908‚Äì1915, 2001. [33] H. P. Roffwarg, J. N. Muzio, and W. C. Dement, ‚ÄúOntogenetic development of the human sleep-dream cycle: The prime role of ‚Äùdreaming sleep‚Äù in early life may be in the development of the central nervous system,‚Äù   Science , vol. 152, no. 3722, pp. 604‚Äì619, 1966. [34] M. S. Blumberg, A. M. Seelke, S. B. Lowen, and K. A. Karlsson, ‚ÄúDynamics of sleep-wake cyclicity in developing rats,‚Äù   Proceedings of the National Academy of Sciences , vol. 102, no. 41, pp. 14860‚Äì14864, 2005. [35] M.   S.   Blumberg   and   A.   M.   H.   Seelke,   ‚ÄúThe   form   and function of infant sleep: From muscle to neocortex,‚Äù in   Oxford handbook of developmental behavioral neuroscience   (M. S. Blumberg, J. H. Freeman, and S. R. Robinson, eds.), pp. 391‚Äì 423, New York: Oxford University Press, 2010. [36] M. S. Blumberg, J. A. Lesku, P.-A. Libourel, M. H. Schmidt, and N. C. Rattenborg, ‚ÄúWhat is rem sleep?,‚Äù   Current Biology , vol. 30, no. 1, pp. R38‚ÄìR49, 2020. [37] J. Peever and P. M. Fuller, ‚ÄúThe biology of rem sleep,‚Äù  Current Biology , vol. 27, no. 22, pp. R1237‚ÄìR1248, 2017. [38] O. I. Lyamin, P. R. Manger, S. H. Ridgway, L. M. Mukhame- tov, and J. M. Siegel, ‚ÄúCetacean sleep: An unusual form of mammalian sleep,‚Äù   Neuroscience & Biobehavioral Reviews , vol. 32, no. 8, pp. 1451‚Äì1484, 2008. [39] L. M. Mukhametov, ‚ÄúUnihemispheric slow-wave sleep in the amazonian dolphin, inia geoffrensis,‚Äù   Neuroscience Letters , vol. 79, no. 1-2, pp. 128‚Äì132, 1987. [40] A. R. Zizzo, I. Kirkegaard, J. Hansen, N. Uldbjerg, and H. M√∏lgaard, ‚ÄúFetal heart rate variability is affected by fetal movements: A systematic review,‚Äù   Frontiers in Physiology , vol. 11, p. 578898, 2020. [41] U. Schneider, B. Frank, A. Fiedler, C. Kaehler, D. Hoyer, M. Liehr, J. Haueisen, and E. Schleussner, ‚ÄúHuman fetal heart rate variability-characteristics of autonomic regulation in the third trimester of gestation,‚Äù   Journal of Perinatal Medicine , vol. 36, no. 5, pp. 433‚Äì441, 2008. [42] D. Hoyer, J. Àô Zebrowski, D. Cysarz, H. Gonc ¬∏alves, A. Pyt- lik, C. Amorim-Costa, J. Bernardes, D. Ayres-de Campos, O. W. Witte, E. Schleussner,   et al. , ‚ÄúMonitoring fetal mat- uration‚Äîobjectives,   techniques   and   indices   of   autonomic function,‚Äù   Physiological Measurement , vol. 38, no. 5, p. R61, 2017. [43] S. B. Mulkey and A. D¬¥ u Plessis, ‚ÄúThe critical role of the cen- tral autonomic nervous system in fetal-neonatal transition,‚Äù  Seminars in Pediatric Neurology , vol. 28, pp. 29‚Äì37, 2018. [44] A.   Samjeed,   M.   Wahbah,   L.   Hadjileontiadis,   and   A.   H. Khandoker, ‚ÄúFetal ECG-based analysis reveals the impact of fetal movements and maternal respiration on maternal- fetal heart rate synchronization,‚Äù   PloS One , vol. 19, no. 12, p. e0312310, 2024. [45] H. H. Szeto and D. J. Hinman, ‚ÄúPrenatal development of sleep-wake patterns in sheep,‚Äù   Sleep , vol. 8, no. 4, pp. 347‚Äì 355, 1985. [46] J. A. DiPietro, R. S. Raghunathan, H. Wu, J. Bai, H. Watson, F. P. Sgambati, J. L. Henderson, and G. W. Pien, ‚ÄúFetal heart rate during maternal sleep,‚Äù   Developmental Psychobiology , vol. 63, pp. 945‚Äì959, July 2021. [47] M. E. Koome, L. Bennet, L. C. Booth, J. O. Davidson, G. Wassink, and A. J. Gunn, ‚ÄúOntogeny and control of the heart rate power spectrum in the last third of gestation in fetal sheep,‚Äù   Experimental Physiology , vol. 99, pp. 80‚Äì88, Jan. 2014. [48] M. S. Scher, ‚ÄúOntogeny of EEG-sleep from neonatal through infancy periods,‚Äù   Sleep Medicine , vol. 9, no. 6, pp. 615‚Äì636, 2008. [49] B. R. Van Den Bergh and E. J. Mulder, ‚ÄúFetal sleep organi- zation: A biological precursor of self-regulation in childhood\n\n14  and adolescence?,‚Äù   Biological Psychology , vol. 89, pp. 584‚Äì 590, Mar. 2012. [50] C. L. Herry, P. Burns, A. Desrochers, G. Fecteau, L. D. Durosier, M. Cao, A. J. Seely, and M. G. Frasch, ‚ÄúVagal con- tributions to fetal heart rate variability: An omics approach,‚Äù  Physiological Measurement , vol. 40, no. 6, p. 065004, 2019. [51] K.   Bystrova,   ‚ÄúNovel   mechanism   of   human   fetal   growth regulation: A potential role of lanugo, vernix caseosa and a second tactile system of unmyelinated low-threshold c- afferents,‚Äù   Medical Hypotheses , vol. 72, no. 2, pp. 143‚Äì146, 2009. [52] S. B. Mulkey and A. J. du Plessis, ‚ÄúAutonomic nervous system development and its impact on neuropsychiatric out- come,‚Äù   Pediatric Research , vol. 85, no. 2, pp. 120‚Äì126, 2019. [53] S.   D.   Schlatterer,   R.   B.   Govindan,   S.   D.   Barnett, T.   Al-Shargabi,   D.   A.   Reich,   S.   Iyer,   L.   Hitchings, G. Larry Maxwell, R. Baker, A. J. du Plessis,   et al. , ‚ÄúAu- tonomic development in preterm infants is associated with morbidity of prematurity,‚Äù   Pediatric Research , vol. 91, no. 1, pp. 171‚Äì177, 2022. [54] D. Rurak, ‚ÄúFetal sleep and spontaneous behavior in utero: Animal and clinical studies,‚Äù in   Prenatal and Postnatal De- terminants of Development , pp. 89‚Äì146, Springer, 2016. [55] D. Rurak and N. Gruber, ‚ÄúIncreased oxygen consumption associated with breathing activity in fetal lambs,‚Äù   Journal of Applied Physiology , vol. 54, no. 3, pp. 701‚Äì707, 1983. [56] H. E. Fox and A. C. Moessinger, ‚ÄúFetal breathing movements and lung hypoplasia: Preliminary human observations,‚Äù   Amer- ican Journal of Obstetrics and Gynecology , vol. 151, no. 4, pp. 531‚Äì533, 1985. [57] P. Gruenwald, ‚ÄúHypoplasia of the lungs,‚Äù   Journal of the Mount Sinai Hospital, New York , vol. 24, no. 6, pp. 913‚Äì919, 1957. [58] J.   Wigglesworth   and   R.   Desai,   ‚ÄúEffects   on   lung   growth of cervical cord section in the rabbit fetus,‚Äù   Early Human Development , vol. 3, no. 1, pp. 51‚Äì65, 1979. [59] J.   E.   Fewell,   C.   C.   Lee,   and   J.   A.   Kitterman,   ‚ÄúEffects of phrenic nerve section on the respiratory system of fe- tal lambs,‚Äù   Journal of Applied Physiology , vol. 51, no. 2, pp. 293‚Äì297, 1981. [60] A. C. Moessinger, ‚ÄúFetal akinesia deformation sequence: An animal model,‚Äù   Pediatrics , vol. 72, no. 6, pp. 857‚Äì863, 1983. [61] J. Wigglesworth, ‚ÄúThe effects of placental insufficiency on the fetal lung,‚Äù   Journal of Clinical Pathology. Supplement (Royal College of Pathologists). , vol. 10, p. 27, 1976. [62] D. Hoyer, S. Nowack, S. Bauer, F. Tetschke, A. Rudolph, U. Wallwitz, F. Jaenicke, E. Heinicke, T. G¬® otz, R. Huonker,  et al. , ‚ÄúFetal development of complex autonomic control evaluated from multiscale heart rate patterns,‚Äù   American Jour- nal of Physiology-Regulatory, Integrative and Comparative Physiology , vol. 304, no. 5, pp. R383‚ÄìR392, 2013. [63] L. Semeia, K. Sippel, J. Moser, and H. Preissl, ‚ÄúEvaluation of parameters for fetal behavioural state classification,‚Äù   Scientific Reports , vol. 12, p. 3410, Mar. 2022. [64] P. R. Stone, W. Burgess, J. McIntyre, A. J. Gunn, C. A. Lear,   L.   Bennet,   E.   A.   Mitchell,   J.   M.   Thompson,   and M. S. I. P. R. G. T. U. of Auckland, ‚ÄúAn investigation of fetal behavioural states during maternal sleep in healthy late gestation pregnancy: An observational study,‚Äù   The Journal of Physiology , vol. 595, no. 24, pp. 7441‚Äì7450, 2017. [65] S. Vairavan, U. Ulusar, H. Eswaran, H. Preissl, J. Wilson, S. Mckelvey, C. Lowery, and R. Govindan, ‚ÄúA computer- aided approach to detect the fetal behavioral states using multi-sensor magnetocardiographic recordings,‚Äù   Computers in Biology and Medicine , vol. 69, pp. 44‚Äì51, Feb. 2016. [66] L. Mercado, S. Rose, D. Escalona-Vargas, E. R. Siegel, J. R. Whittington, H. Preissl, M. Helmich, and H. Eswaran, ‚ÄúCorrelation of fetal heart rate dynamics to inflammatory markers and brain-derived neurotrophic factor during preg- nancy,‚Äù   Journal of Perinatal Medicine , vol. 52, pp. 399‚Äì405, May 2024. [67] M. M. Myers, K. F. Schulze, W. P. Fifer, and R. I. Stark, ‚ÄúMethods for quantifying state-specific patterns of EEG ac- tivity in fetal baboons and immature human infants,‚Äù in   Fetal Development , pp. 35‚Äì49, Psychology Press, 2013. [68] C. Shaw, B. Allison, N. Itani, K. Botting, Y. Niu, C. Lees, and D. Giussani, ‚ÄúAltered autonomic control of heart rate variability in the chronically hypoxic fetus,‚Äù   The Journal of Physiology , vol. 596, no. 23, pp. 6105‚Äì6119, 2018. [69] R. Galinsky, S. K. Dhillon, S. B. Kelly, G. Wassink, J. O. Davidson, C. A. Lear, L. G. van den Heuij, L. Bennet, and A. J. Gunn, ‚ÄúMagnesium sulphate reduces tertiary gliosis but does not improve EEG recovery or white or grey matter cell survival after asphyxia in preterm fetal sheep,‚Äù   The Journal of Physiology , vol. 601, no. 10, pp. 1999‚Äì2016, 2023. [70] M. Van Vliet, C. Martin, J. Nijhuis, and H. Prechtl, ‚ÄúThe relationship between fetal activity and behavioral states and fetal breathing movements in normal and growth-retarded fetuses,‚Äù   American Journal of Obstetrics and Gynecology , vol. 153, pp. 582‚Äì588, Nov. 1985. [71] N. Pini, M. Lucchini, W. P. Fifer, and R. Barbieri, ‚ÄúA point process framework for the characterization of fetal sleep states,‚Äù in   2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC) , pp. 612‚Äì615, IEEE, 2020. [72] M. M. Myers, R. I. Stark, W. P. Fifer, P. G. Grieve, J. Haiken, K. Leung, and K. F. Schulze, ‚ÄúA quantitative method for classification of EEG in the fetal baboon,‚Äù   American Jour- nal of Physiology-Regulatory, Integrative and Comparative Physiology , vol. 265, pp. R706‚ÄìR714, Sept. 1993. [73] R. I. Stark, S. S. Daniel, Y.-I. Kim, K. Leung, M. M. Myers, and P. J. Tropper, ‚ÄúPatterns of fetal breathing in the baboon vary with EEG sleep state,‚Äù   Early Human Development , vol. 38, pp. 11‚Äì26, July 1994. [74] M. Schwab, K. Schmidt, H. Witte, and R. M. Abrams, ‚ÄúInves- tigation of nonlinear ECoG changes during spontaneous sleep state changes and cortical arousal in fetal sheep,‚Äù   Cerebral Cortex , vol. 10, no. 2, pp. 142‚Äì148, 2000. [75] K. Schwab, T. Groh, M. Schwab, and H. Witte, ‚ÄúTime-variant analysis of nonlinear stability and bispectral measures to quantify the development of fetal sleep states,‚Äù in   2006 In- ternational Conference of the IEEE Engineering in Medicine and Biology Society , pp. 1454‚Äì1457, IEEE, 2006. [76] A.   Tournier,   M.   Beacom,   J.   A.   Westgate,   L.   Bennet, C. Garabedian, A. Ugwumadu, A. J. Gunn, and C. A. Lear, ‚ÄúPhysiological control of fetal heart rate variability during labour: Implications and controversies,‚Äù   The Journal of Phys- iology , vol. 600, no. 3, pp. 431‚Äì450, 2022. [77] B. Lee, J. J. Hirst, and D. W. Walker, ‚ÄúProstaglandin d syn- thase in the prenatal ovine brain and effects of its inhibition with selenium chloride on fetal sleep/wake activityin utero,‚Äù  Journal of Neuroscience , vol. 22, no. 13, pp. 5679‚Äì5686, 2002. [78] J. R. Isler, M. Garland, R. I. Stark, and P. G. Grieve, ‚ÄúLocal coherence oscillations in the EEG during development in the fetal baboon,‚Äù   Clinical Neurophysiology , vol. 116, pp. 2121‚Äì 2128, Sept. 2005. [79] J. O. Davidson, J. S. Quaedackers, S. A. George, A. J. Gunn, and L. Bennet, ‚ÄúMaternal dexamethasone and EEG hyper- activity in preterm fetal sheep,‚Äù   The Journal of Physiology , vol. 589, no. 15, pp. 3823‚Äì3835, 2011. [80] C. M. Pettker and K. H. Campbell, ‚ÄúAntepartum fetal assess- ment,‚Äù   Avery‚Äôs Diseases of the Newborn , pp. 145‚Äì157, 2018. [81] P.   L.   Toubas,   A.   L.   Pryor,   and   R.   E.   Sheldon,   ‚ÄúEffect of morphine on fetal electrocortical activity and breathing movements in fetal sheep,‚Äù   Developmental Pharmacology and Therapeutics , vol. 8, no. 2, pp. 115‚Äì128, 1985. [82] M. J. Nijland and M. G. Ross, ‚ÄúOvine hourly fetal urine production: Relation to fetal electrocortical activity,‚Äù   The Journal of Maternal-Fetal Medicine , vol. 9, pp. 267‚Äì272, Sept. 2000. [83] S. B. Kelly, V. Stojanovska, V. A. Zahra, A. Moxham, S. L. Miller, T. J. Moss, S. B. Hooper, M. F. Nold, C. A. Nold- Petry, J. M. Dean,   et al. , ‚ÄúInterleukin-1 blockade attenuates white matter inflammation and oligodendrocyte loss after progressive systemic lipopolysaccharide exposure in near- term fetal sheep,‚Äù   Journal of Neuroinflammation , vol. 18, pp. 1‚Äì18, 2021. [84] R. I. Stark, M. Garland, S. S. Daniel, K. Leung, M. M. Myers, and P. J. Tropper, ‚ÄúFetal cardiorespiratory and neu- robehavioral response to zidovudine (AZT) in the baboon,‚Äù  The Journal of the Society for Gynecologic Investigation: JSGI , vol. 4, pp. 183‚Äì190, 1997.\n\n15  [85] J. Dobbing and J. Sands, ‚ÄúQuantitative growth and devel- opment of human brain,‚Äù   Archives of Disease in Childhood , vol. 48, no. 10, pp. 757‚Äì767, 1973. [86] J. A. DiPietro, K. A. Costigan, and K. M. Voegtline, ‚ÄúStudies in fetal behavior: Revisited, renewed, and reimagined,‚Äù   Mono- graphs of the Society for Research in Child Development , vol. 80, no. 3, p. vii, 2015. [87] P. G. Grieve, M. M. Myers, and R. I. Stark, ‚ÄúBehavioral states in the fetal baboon,‚Äù   Early Human Development , vol. 39, no. 3, pp. 159‚Äì175, 1994. [88] R. I. Stark, J. Haiken, D. Nordli, and M. M. Myers, ‚ÄúCharac- terization of electroencephalographic state in fetal baboons,‚Äù  American Journal of Physiology-Regulatory, Integrative and Comparative Physiology , vol. 261, no. 2, pp. R496‚ÄìR500, 1991. [89] B. Frank, M. G. Frasch, U. Schneider, M. Roedel, M. Schwab, and D. Hoyer, ‚ÄúComplexity of heart rate fluctuations in near- term sheep and human fetuses during sleep,‚Äù   Biomedizinische Technik/Biomedical Engineering , vol. 51, pp. 233‚Äì236, Oct. 2006. [90] F. Clewlow, G. Dawes, B. M. Johnston, and D. Walker, ‚ÄúChanges in breathing, electrocortical and muscle activity in unanaesthetized fetal lambs with age,‚Äù   The Journal of Physiology , vol. 341, no. 1, pp. 463‚Äì476, 1983. [91] W. Tang, N. Tran, N. Katebi, R. Sameni, G. D. Clifford, D. Walker, V. Horlali, C. Taylor, R. Galinsky, and F. Marzban- rad, ‚ÄúAdvancing fetal surveillance with physiological sensing: Detecting hypoxia in fetal sheep,‚Äù in   2024 IEEE SENSORS , pp. 1‚Äì4, 2024. [92] N. K. Lowe and R. Reiss, ‚ÄúParturition and fetal adapta- tion,‚Äù   Journal of Obstetric, Gynecologic & Neonatal Nursing , vol. 25, pp. 339‚Äì349, May 1996. [93] M. E. McNERNEY and H. H. Szeto, ‚ÄúAutomated identifica- tion and quantitation of four patterns of electrocortical activity in the near-term fetal lamb,‚Äù   Pediatric Research , vol. 28, no. 2, pp. 106‚Äì110, 1990. [94] N. Rao, A. Keen, M. Czikk, M. Frasch, and B. S. Richardson, ‚ÄúBehavioural state linkage in the ovine fetus near term,‚Äù   Brain Research , vol. 1250, pp. 149‚Äì156, 2009. [95] S. Ioffe, A. H. Jansen, B. J. Russell, and V. Chernick, ‚ÄúSleep, wakefulness and the monosynaptic reflex in fetal and newborn lambs,‚Äù   Pfl¬® ugers Archiv European Journal of Physiology , vol. 388, pp. 149‚Äì157, Nov. 1980. [96] G. Visser, E. Mulder, and H. Prechtl, ‚ÄúStudies on devel- opmental   neurology   in   the   human   fetus,‚Äù   Developmental Pharmacology and Therapeutics , vol. 18, no. 3-4, pp. 175‚Äì 183, 1992. [97] E. J. Mulder, L. P. Morssink, T. Van Der Schee, and G. H. Visser, ‚ÄúAcute maternal alcohol consumption disrupts be- havioral state organization in the near-term fetus,‚Äù   Pediatric Research , vol. 44, no. 5, pp. 774‚Äì779, 1998. [98] H. H. Szeto, ‚ÄúBehavioral states and their ontogeny: Animal studies,‚Äù   Seminars in Perinatology , vol. 16, no. 4, pp. 211‚Äì 216, 1992. [99] K. J. Crossley, M. B. Nicol, J. J. Hirst, D. W. Walker, and G. D. Thorburn‚Ä†, ‚ÄúSuppression of arousal by progesterone in fetal sheep,‚Äù   Reproduction, Fertility and Development , vol. 9, no. 8, p. 767, 1997. [100] M. Nicol, J. J. Hirst, and D. Walker, ‚ÄúEffect of pregnane steroids on electrocortical activity and somatosensory evoked potentials in fetal sheep,‚Äù   Neuroscience Letters , vol. 253, no. 2, pp. 111‚Äì114, 1998. [101] M. B. Nicol, J. J. Hirst, and D. W. Walker, ‚ÄúEffect of finasteride on behavioural arousal and somatosensory evoked potentials in fetal sheep,‚Äù   Neuroscience letters , vol. 306, no. 1-2, pp. 13‚Äì16, 2001. [102] G. H. A. Visser and E. J. H. Mulder, ‚ÄúThe effect of vibro- acoustic stimulation on fetal behavioral state organization,‚Äù  American Journal of Industrial Medicine , vol. 23, pp. 531‚Äì 539, Apr. 1993. [103] D. Walker, J. Grimwade, and C. Wood, ‚ÄúIntrauterine noise: A component of the fetal environment,‚Äù   American Journal of Obstetrics and Gynecology , vol. 109, no. 1, pp. 91‚Äì95, 1971. [104] B. S. Kisilevsky, S. M. Hains, K. Lee, X. Xie, H. Huang, H. H. Ye, K. Zhang, and Z. Wang, ‚ÄúEffects of experience on fetal voice recognition,‚Äù   Psychological Science , vol. 14, no. 3, pp. 220‚Äì224, 2003. [105] E. J. H. Mulder and G. H. A. Visser, ‚ÄúFetal behavior: Clinical and experimental research in the human,‚Äù in   Fetal Develop- ment   (N. Reissland and B. S. Kisilevsky, eds.), pp. 87‚Äì105, Cham: Springer International Publishing, 2016. [106] D. L. Wilson, A. M. Fung, H. Skrzypek, G. Pell, M. Barnes, M. E. Howard, and S. P. Walker, ‚ÄúMaternal sleep behaviours preceding fetal heart rate events on cardiotocography,‚Äù   The Journal of Physiology , vol. 600, pp. 1791‚Äì1806, Apr. 2022. [107] S. R. Yiallourou, ‚ÄúChildhood sleep after fetal growth restric- tion,‚Äù   Diet, Nutrition, and Fetal Programming , pp. 487‚Äì499, 2017. [108] E. P. on Animal Health, W. (AHAW), S. More, D. Bicout, A. Botner, A. Butterworth, P. Calistri, K. Depner, S. Edwards, B. Garin-Bastuji, M. Good,   et al. , ‚ÄúAnimal welfare aspects in respect of the slaughter or killing of pregnant livestock animals (cattle, pigs, sheep, goats, horses),‚Äù   Efsa Journal , vol. 15, no. 5, p. e04782, 2017. [109] T. Yawno, E. B. Yan, J. J. Hirst, and D. W. Walker, ‚ÄúNeuroac- tive steroids induce changes in fetal sheep behavior during normoxic and asphyxic states,‚Äù   Stress , vol. 14, pp. 13‚Äì22, Jan. 2011. [110] M. S. Kinsella and G. Lohmann, ‚ÄúSupine hypotensive syn- drome,‚Äù   Obstetrics & Gynecology , vol. 83, no. 5, pp. 774‚Äì 788, 1994. [111] J. P. PIRHONEN and R. U. ERKKOLA, ‚ÄúUterine and um- bilical flow velocity waveforms in the supine hypotensive syndrome,‚Äù   Obstetrics & Gynecology , vol. 76, no. 2, pp. 176‚Äì 179, 1990. [112] R.   Jeffreys,   W.   Stepanchak,   B.   Lopez,   J.   Hardis,   and J. Clapp III, ‚ÄúUterine blood flow during supine rest and exercise after 28 weeks of gestation,‚Äù   BJOG: An International Journal   of   Obstetrics   &   Gynaecology ,   vol.   113,   no.   11, pp. 1239‚Äì1247, 2006. [113] J.-P. Lecanuet and A.-Y. Jacquet, ‚ÄúFetal responsiveness to maternal passive swinging in low heart rate variability state: effects of stimulation direction and duration,‚Äù   Developmental Psychobiology: The Journal of the International Society for Developmental Psychobiology , vol. 40, no. 1, pp. 57‚Äì67, 2002. [114] M. Mirmiran and S. Lunshof, ‚ÄúPerinatal development of human   circadian   rhythms,‚Äù   Progress   in   Brain   Research , vol. 111, pp. 217‚Äì226, 1996. [115] G.   W.   Pien   and   R.   J.   Schwab,   ‚ÄúSleep   disorders   during pregnancy,‚Äù   Sleep , vol. 27, no. 7, pp. 1405‚Äì1417, 2004. [116] F. K. Sahin, G. Koken, E. Cosar, F. Saylan, F. Fidan, M. Yil- mazer, and M. Unlu, ‚ÄúObstructive sleep apnea in pregnancy and fetal outcome,‚Äù   International Journal of Gynecology & Obstetrics , vol. 100, no. 2, pp. 141‚Äì146, 2008. [117] B. J. Koos, T. Maeda, and C. Jan, ‚ÄúAdenosine A 1   and A 2a  receptors modulate sleep state and breathing in fetal sheep,‚Äù  Journal of Applied Physiology , vol. 91, pp. 343‚Äì350, July 2001. [118] D. J. Hinman and H. H. Szeto, ‚ÄúCholinergic influences on sleep-wake patterns and breathing movements in the fetus,‚Äù  The Journal of Pharmacology and Experimental Therapeu- tics , vol. 247, pp. 372‚Äì378, Oct. 1988. [119] C. S. Han and L. D. Platt, ‚ÄúFetal biophysical profile,‚Äù in  Obstetric   Imaging:   Fetal   Diagnosis   and   Care ,   pp.   537‚Äì 540.e1, Elsevier, 2018. [120] D. Burchfield, E. Graham, R. Abrams, and K. Gerhardt, ‚ÄúCo- caine alters behavioral states in fetal sheep,‚Äù   Developmental Brain Research , vol. 56, pp. 41‚Äì45, Oct. 1990. [121] M. B. Nicol, J. J. Hirst, and D. Walker, ‚ÄúEffects of preg- nanolone on behavioural parameters and the responses to GABAA   receptor   antagonists   in   the   late   gestation   fetal sheep,‚Äù   Neuropharmacology , vol. 38, pp. 49‚Äì63, Jan. 1999. [122] S. Ioffe, A. H. Jansen, and V. Chernick, ‚ÄúFetal respiratory neuronal activity during REM and NREM sleep,‚Äù   Journal of Applied Physiology , vol. 75, pp. 191‚Äì197, July 1993. [123] Z.   Alfirevic,   G.   M.   Gyte,   A.   Cuthbert,   and   D.   Devane, ‚ÄúContinuous cardiotocography (CTG) as a form of electronic fetal monitoring (EFM) for fetal assessment during labour,‚Äù  Cochrane Database of Systematic Reviews , no. 2, 2017. [124] J.   Karin,   M.   Hirsch,   and   S.   Akselrod,   ‚ÄúAn   estimate   of fetal autonomic state by spectral analysis of fetal heart rate fluctuations,‚Äù   Pediatric Research , vol. 34, pp. 134‚Äì138, Aug. 1993.\n\n16  [125] J. Van Laar, C. Peters, R. Vullings, S. Houterman, and S. Oei, ‚ÄúPower spectrum analysis of fetal heart rate variability at near term and post term gestation during active sleep and quiet sleep,‚Äù   Early Human Development , vol. 85, pp. 795‚Äì798, Dec. 2009. [126] M. Chiera, F. Cerritelli, A. Casini, N. Barsotti, D. Boschiero, F.   Cavigioli,   C.   G.   Corti,   and   A.   Manzotti,   ‚ÄúHeart   rate variability in the perinatal period: A critical and conceptual review,‚Äù   Frontiers in Neuroscience , vol. 14, p. 561186, 2020. [127] P. Van Leeuwen, L. Werner, Z. Hilal, S. Schiermeier, W. Hatz- mann, and D. Groenemeyer, ‚ÄúFetal electrocardiographic mea- surements in the assessment of fetal heart rate variability in the antepartum period,‚Äù   Physiological Measurement , vol. 35, no. 3, p. 441, 2014. [128] C. L. Lowery, R. Govindan, P. Murphy, and H. Eswaran, ‚ÄúAssessing cardiac and neurological maturation during the intrauterine period,‚Äù   Seminars in Perinatology , vol. 32, no. 4, pp. 263‚Äì268, 2008. [129] J. Br¬® andle, H. Preissl, R. Draganova, E. Ortiz, K. O. Kagan, H. Abele, S. Y. Brucker, and I. Kiefer-Schmidt, ‚ÄúHeart rate variability parameters and fetal movement complement fetal behavioral states detection via magnetography to monitor neurovegetative development,‚Äù   Frontiers in Human Neuro- science , vol. 9, p. 147, 2015. [130] S. U. Hasan and A. Rigaux, ‚ÄúArterial oxygen tension thresh- old range for the onset of arousal and breathing in fetal sheep,‚Äù   Pediatric Research , vol. 32, pp. 342‚Äì349, Sept. 1992. [131] E. C. Jensen, L. Bennet, S.-J. Guild, L. C. Booth, J. Stewart, and A. J. Gunn, ‚ÄúThe role of the neural sympathetic and parasympathetic systems in diurnal and sleep state-related cardiovascular   rhythms   in   the   late-gestation   ovine   fetus,‚Äù  American Journal of Physiology-Regulatory, Integrative and Comparative Physiology , vol. 297, no. 4, pp. R998‚ÄìR1008, 2009. [132] G. Dawes, H. . E. Fox, B. Leduc, G. Liggins, and R. Richards, ‚ÄúRespiratory movements and rapid eye movement sleep in the foetal lamb,‚Äù   The Journal of Physiology , vol. 220, no. 1, pp. 119‚Äì143, 1972. [133] R. Harding, J. N. Sigger, E. R. Poore, and P. Johnson, ‚ÄúIngestion in fetal sheep and its relation to sleep states and breathing movements,‚Äù   Quarterly Journal of Experimental Physiology , vol. 69, pp. 477‚Äì486, July 1984. [134] R. Natale, F. Clewlow, and G. Dawes, ‚ÄúMeasurement of fetal forelimb movements in the lamb in utero,‚Äù   American Journal of Obstetrics and Gynecology , vol. 140, pp. 545‚Äì551, July 1981. [135] E. Poore and D. Walker, ‚ÄúChest wall movements during fetal breathing in the sheep,‚Äù   The Journal of Physiology , vol. 301, no. 1, pp. 307‚Äì315, 1980. [136] W. Sha and X. Guo, ‚ÄúPrenatal and intrapartum EFM,‚Äù in   Elec- tronic Fetal Monitoring   (X. Guo, ed.), pp. 65‚Äì118, Singapore: Springer Singapore, 2021. [137] M. Hirsch, J. Karin, and S. Akselrod, ‚ÄúHeart rate variability in the fetus,‚Äù   Heart Rate Variability , pp. 517‚Äì531, 1995. [138] S. Lange, P. Van Leeuwen, U. Schneider, B. Frank, D. Hoyer, D. Geue, and D. Gr¬® onemeyer, ‚ÄúHeart rate features in fetal behavioural   states,‚Äù   Early   Human   Development ,   vol.   85, pp. 131‚Äì135, Feb. 2009. [139] M. Peters, J. Crowe, J.-F. Pi¬¥ eri, H. Quartero, B. Hayes-Gill, D. James, J. Stinstra, and S. Shakespeare, ‚ÄúMonitoring the fetal heart non-invasively: A review of methods,‚Äù   Journal of Perinatal Medicine , vol. 29, no. 5, pp. 408‚Äì416, 2001. [140] C. A. Lear, B. A. Lear, J. O. Davidson, V. J. King, Y. Maeda, A. McDouall, S. K. Dhillon, A. J. Gunn, and L. Bennet, ‚ÄúDys- maturation of sleep state and electroencephalographic activity after hypoxia-ischaemia in preterm fetal sheep,‚Äù   Journal of Cerebral Blood Flow & Metabolism , vol. 44, pp. 1376‚Äì1392, Aug. 2024. [141] M. David, M. Hirsch, J. Karin, E. Toledo, and S. Akselrod, ‚ÄúAn estimate of fetal autonomic state by time-frequency analysis of fetal heart rate variability,‚Äù   Journal of Applied Physiology , vol. 102, no. 3, pp. 1057‚Äì1064, 2007. [142] K. M. Gustafson, J. J. Allen, H.-w. Yeh, and L. E. May, ‚ÄúCharacterization of the fetal diaphragmatic magnetomyo- gram and the effect of breathing movements on cardiac metrics of rate and variability,‚Äù   Early Human Development , vol. 87, no. 7, pp. 467‚Äì475, 2011. [143] K. M. Gustafson, L. E. May, H.-w. Yeh, S. K. Million, and J. J. Allen, ‚ÄúFetal cardiac autonomic control during breathing and non-breathing epochs: The effect of maternal exercise,‚Äù  Early Human Development , vol. 88, no. 7, pp. 539‚Äì546, 2012. [144] S.-W. Min, H. Ko, and C.-S. Kim, ‚ÄúPower spectral analysis of heart rate variability during acute hypoxia in fetal lambs,‚Äù  Acta   Obstetricia   et   Gynecologica   Scandinavica ,   vol.   81, no. 11, pp. 1001‚Äì1005, 2002. [145] J. Van Laar, C. Peters, R. Vullings, S. Houterman, and S. Oei, ‚ÄúPower spectrum analysis of fetal heart rate variability at near term and post term gestation during active sleep and quiet sleep,‚Äù   Early Human Development , vol. 85, no. 12, pp. 795‚Äì 798, 2009. [146] M. E. Koome, L. Bennet, L. C. Booth, G. Wassink, J. O. Davidson, M. Gunning, and A. J. Gunn, ‚ÄúQuantifying the power spectrum of fetal heart rate variability.,‚Äù   Experimental Physiology , vol. 99, no. 2, 2014. [147] S. B. Kelly, J. M. Dean, V. A. Zahra, I. Dudink, A. Thiel, G.   R.   Polglase,   S.   L.   Miller,   S.   B.   Hooper,   L.   Bennet, A. J. Gunn,   et al. , ‚ÄúProgressive inflammation reduces high- frequency EEG activity and cortical dendritic arborisation in late gestation fetal sheep,‚Äù   Journal of Neuroinflammation , vol. 20, no. 1, p. 124, 2023. [148] S. Ioffe, A. H. Jansen, and V. Chernick, ‚ÄúECoG and breathing activity in fetal lambs after undercut of cerebral cortex,‚Äù  Journal of Applied Physiology , vol. 57, pp. 1195‚Äì1201, Oct. 1984. [149] A. Samjeed, M. Wahbah, L. Hadjileontiadis, and A. H. Khan- doker, ‚ÄúClassification of fetal behavioral states by using 1D- CNN based on fetal electrocardiography,‚Äù in   2022 Computing in Cardiology (CinC) , vol. 498, pp. 1‚Äì4, IEEE, 2022. [150] L. Subitoni, ‚ÄúHidden markov models and deep neural net- works: Segmentation of the fetal heart rate signal into behav- ioral patterns,‚Äù master‚Äôs thesis, Politecnico di Milano, Milan, Italy, 2023. [151] G. E. Billman, ‚ÄúThe LF/HF ratio does not accurately measure cardiac sympatho-vagal balance,‚Äù 2013. [152] B. J. Koos, H. Sameshima, and G. G. Power, ‚ÄúFetal breathing, sleep state, and cardiovascular responses to graded anemia in sheep,‚Äù   Journal of Applied Physiology , vol. 63, pp. 1463‚Äì 1468, Oct. 1987. [153] N. T. Tran, S. J. Ellery, S. B. Kelly, J. S¬¥ evigny, M. Chatton, H. Lu, G. R. Polglase, R. J. Snow, D. W. Walker, and R. Galinsky, ‚ÄúProphylactic fetal creatine supplementation im- proves post-asphyxial EEG recovery and reduces seizures in fetal sheep: Implications for hypoxic‚Äìischemic encephalopa- thy,‚Äù   Annals of Neurology , vol. 97, no. 4, pp. 673‚Äì687, 2025. [154] B. J. Koos, B. A. Mason, O. Punla, and A. M. Adinolfi, ‚ÄúHypoxic inhibition of breathing in fetal sheep: Relationship to brain adenosine concentrations,‚Äù   Journal of Applied Phys- iology , vol. 77, no. 6, pp. 2734‚Äì2739, 1994. [155] B. J. Koos, L. Kruger, and T. F. Murray, ‚ÄúSource of extracel- lular brain adenosine during hypoxia in fetal sheep,‚Äù   Brain Research , vol. 778, no. 2, pp. 439‚Äì442, 1997. [156] C. S. Watson, R. Schaefer, S. E. White, J. H. Homan, L. Fra- her, R. Harding, and A. D. Bocking, ‚ÄúEffect of intermittent umbilical cord occlusion on fetal respiratory activity and brain adenosine in late-gestation sheep,‚Äù   Reproduction, Fertility and Development , vol. 14, no. 1, pp. 35‚Äì42, 2002. [157] S. Breen, S. Rees, and D. Walker, ‚ÄúIdentification of brainstem neurons responding to hypoxia in fetal and newborn sheep,‚Äù  Brain Research , vol. 748, no. 1-2, pp. 107‚Äì121, 1997. [158] G. Dawes, W. Gardner, B. M. Johnston, and D. Walker, ‚ÄúBreathing in fetal lambs: The effect of brain stem section.,‚Äù  The Journal of Physiology , vol. 335, no. 1, pp. 535‚Äì553, 1983. [159] B. J. Koos, A. Chau, M. Matsuura, O. Punla, and L. Kruger, ‚ÄúThalamic locus mediates hypoxic inhibition of breathing in fetal sheep,‚Äù   Journal of Neurophysiology , vol. 79, no. 5, pp. 2383‚Äì2393, 1998. [160] A.   A.   Baburamani,   N.   T.   Tran,   M.   Castillo-Melendez, T. Yawno, and D. W. Walker, ‚ÄúBrief hypoxia in late gestation sheep causes prolonged disruption of fetal electrographic, breathing behaviours and can result in early labour,‚Äù   The Journal of Physiology , vol. 599, no. 12, pp. 3221‚Äì3236, 2021. [161] A. H. Jansen, S. Ioffe, B. Russell, and V. Chernick, ‚ÄúInfluence\n\n17  of sleep state on the response to hypercapnia in fetal lambs,‚Äù  Respiration Physiology , vol. 48, pp. 125‚Äì142, Apr. 1982. [162] D. Arduini, G. Rizzo, L. Caforio, M. R. Boccolini, C. Ro- manini, and S. Mancuso, ‚ÄúBehavioural state transitions in healthy and growth retarded fetuses,‚Äù   Early Human Devel- opment , vol. 19, no. 3, pp. 155‚Äì165, 1989. [163] M. Van Vliet, C. Martin Jr, J. Nijhuis, and H. Prechtl, ‚ÄúBehavioural states in growth-retarded human fetuses,‚Äù   Early Human Development , vol. 12, no. 2, pp. 183‚Äì197, 1985. [164] F. Cerritelli, M. G. Frasch, M. C. Antonelli, C. Viglione, S. Vecchi, M. Chiera, and A. Manzotti, ‚ÄúThe role of the vagus nerve during fetal development and its relationship with the environment,‚Äù   arXiv preprint arXiv:2106.01756 , 2021. [165] D. Bekedam, E. Mulder, R. Snijders, and G. Visser, ‚ÄúThe effects of maternal hyperoxia on fetal breathing movements, body movements and heart rate variation in growth retarded fetuses,‚Äù   Early Human Development , vol. 27, no. 3, pp. 223‚Äì 232, 1991. [166] D. Bekedam, G. Visser, J. De Vries, and H. Prechtl, ‚ÄúMotor behaviour in the growth retarded fetus,‚Äù   Early Human Devel- opment , vol. 12, no. 2, pp. 155‚Äì165, 1985. [167] D. Sival, G. Visser, and H. Prechtl, ‚ÄúThe effect of intrauterine growth retardation on the quality of general movements in the human fetus,‚Äù   Early Human Development , vol. 28, no. 2, pp. 119‚Äì132, 1992. [168] G. H. A. Visser, E. J. H. Mulder, and F. F. Tessa Ververs, ‚ÄúFetal behavioral teratology,‚Äù   The Journal of Maternal-Fetal & Neonatal Medicine , vol. 23, pp. 14‚Äì16, Oct. 2010. [169] J. De Vries and B. Fong, ‚ÄúChanges in fetal motility as a result of congenital disorders: An overview,‚Äù   Ultrasound in Obstetrics and Gynecology: The Official Journal of the Inter- national Society of Ultrasound in Obstetrics and Gynecology , vol. 29, no. 5, pp. 590‚Äì599, 2007. [170] L. Dierker Jr, S. Pillay, Y. Sorokin, and M. G. Rosen, ‚ÄúThe change in fetal activity periods in diabetic and nondiabetic pregnancies,‚Äù   American Journal of Obstetrics and Gynecol- ogy , vol. 143, no. 2, pp. 181‚Äì185, 1982. [171] P. R. Stone, W. Burgess, J. P. R. McIntyre, A. J. Gunn, C. A. Lear, L. Bennet, E. A. Mitchell, J. M. D. Thompson, and the Maternal Sleep In Pregnancy Research Group, The University of Auckland, ‚ÄúEffect of maternal position on fetal behavioural state and heart rate variability in healthy late gestation pregnancy,‚Äù   The Journal of Physiology , vol. 595, pp. 1213‚Äì1221, Feb. 2017. [172] K. J. O‚ÄôDonnell, A. B. Jensen, L. Freeman, N. Khalife, T. G. O‚ÄôConnor, and V. Glover, ‚ÄúMaternal prenatal anxiety and downregulation of placental 11 Œ≤ -hsd2,‚Äù   Psychoneuroen- docrinology , vol. 37, no. 6, pp. 818‚Äì826, 2012. [173] M.   G.   Opler   and   E.   S.   Susser,   ‚ÄúFetal   environment   and schizophrenia,‚Äù   Environmental Health Perspectives , vol. 113, no. 9, pp. 1239‚Äì1242, 2005. [174] A. Lehrner, L. M. Bierer, V. Passarelli, L. C. Pratchett, J. D. Flory, H. N. Bader, I. R. Harris, A. Bedi, N. P. Daskalakis, I. Makotkine,   et al. , ‚ÄúMaternal ptsd associates with greater glucocorticoid sensitivity in offspring of holocaust survivors,‚Äù  Psychoneuroendocrinology , vol. 40, pp. 213‚Äì220, 2014. [175] M. N. Spann, D. Scheinost, T. Feng, K. Barbato, S. Lee, C.   Monk,   and   B.   S.   Peterson,   ‚ÄúAssociation   of   maternal prepregnancy body mass index with fetal growth and neonatal thalamic brain connectivity among adolescent and young women,‚Äù   JAMA Network Open , vol. 3, no. 11, pp. e2024661‚Äì e2024661, 2020. [176] J. A. Dipietro, K. M. Voegtline, H. A. Pater, and K. A. Costigan, ‚ÄúPredicting child temperament and behavior from the fetus,‚Äù   Development and Psychopathology , vol. 30, no. 3, pp. 855‚Äì870, 2018. [177] W. Schlotz, K. M. Godfrey, and D. I. Phillips, ‚ÄúPrenatal origins of temperament: Fetal growth, brain structure, and inhibitory control in adolescence,‚Äù   PLoS One , vol. 9, no. 5, p. e96715, 2014. [178] S. M. Lobmaier, A. M¬® uller, C. Zelgert, C. Shen, P. Su, G. Schmidt, B. Haller, G. Berg, B. Fabre, J. Weyrich,   et al. , ‚ÄúFetal heart rate variability responsiveness to maternal stress, non-invasively detected from maternal transabdominal ECG,‚Äù  Archives of Gynecology and Obstetrics , vol. 301, pp. 405‚Äì 414, 2020. [179] M. C. Wallingford, C. Benson, N. W. Chavkin, M. T. Chin, and M. G. Frasch, ‚ÄúPlacental vascular calcification and car- diovascular health: It is time to determine how much of maternal and offspring health is written in stone,‚Äù   Frontiers in Physiology , vol. 9, p. 1044, 2018. [180] P. S. Zeskind and J. L. Gingras, ‚ÄúMaternal cigarette-smoking during pregnancy disrupts rhythms in fetal heart rate,‚Äù   Journal of Pediatric Psychology , vol. 31, no. 1, pp. 5‚Äì14, 2006. [181] H. Kapaya, F. Broughton-Pipkin, B. Hayes-Gill, and P. V. Loughna, ‚ÄúSmoking in pregnancy affects the fetal heart: Possible links to future cardiovascular disease,‚Äù   The Journal of Maternal-Fetal & Neonatal Medicine , vol. 28, no. 14, pp. 1664‚Äì1668, 2015. [182] E. Mulder, L. Tegaldo, P. Bruschettini, and G. Visser, ‚ÄúFoetal response to maternal coffee intake: Role of habitual versus non-habitual caffeine consumption,‚Äù   Journal of Psychophar- macology , vol. 24, pp. 1641‚Äì1648, Nov. 2010. [183] R. J. Cardosi and R. A. Chez, ‚ÄúMagnesium sulfate, maternal hypothermia, and fetal bradycardia with loss of heart rate variability,‚Äù   Obstetrics & Gynecology , vol. 92, no. 4 Part 2, pp. 691‚Äì693, 1998. [184] R. Galinsky, J. O. Davidson, P. P. Drury, G. Wassink, C. A. Lear, L. G. van den Heuij, A. J. Gunn, and L. Bennet, ‚ÄúMagnesium sulphate and cardiovascular and cerebrovascular adaptations to asphyxia in preterm fetal sheep,‚Äù   The Journal of Physiology , vol. 594, no. 5, pp. 1281‚Äì1293, 2016. [185] R. Galinsky, V. Draghi, G. Wassink, J. O. Davidson, P. P. Drury, C. A. Lear, A. J. Gunn, and L. Bennet, ‚ÄúMagnesium sulfate reduces EEG activity but is not neuroprotective after asphyxia in preterm fetal sheep,‚Äù   Journal of Cerebral Blood Flow & Metabolism , vol. 37, no. 4, pp. 1362‚Äì1373, 2017. [186] R. Galinsky, S. K. Dhillon, C. A. Lear, K. Yamaguchi, G. Wassink, A. J. Gunn, and L. Bennet, ‚ÄúMagnesium sulfate and   sex differences   in   cardiovascular   and neural   adapta- tions during normoxia and asphyxia in preterm fetal sheep,‚Äù  American Journal of Physiology-Regulatory, Integrative and Comparative Physiology , vol. 315, no. 2, pp. R205‚ÄìR217, 2018. [187] S. M. Khedun, B. Maharaj, and J. Moodley, ‚ÄúEffects of anti- hypertensive drugs on the unborn child: What is known, and how should this influence prescribing?,‚Äù   Paediatric Drugs , vol. 2, pp. 419‚Äì436, 2000. [188] G. Hanley, K. Hookenson, D. Rurak, and T. F. Oberlander, ‚ÄúFetal effects of in utero serotonin reuptake inhibitor (SRI) antidepressant exposure,‚Äù   Fetal Development: Research on Brain and Behavior, Environmental Influences, and Emerging Technologies , pp. 365‚Äì381, 2016. [189] E. J. H. Mulder, F. F. Ververs, R. De Heus, and G. H. A. Visser, ‚ÄúSelective serotonin reuptake inhibitors affect neu- robehavioral development in the human fetus,‚Äù   Neuropsy- chopharmacology , vol. 36, pp. 1961‚Äì1971, Sept. 2011. [190] L. Galli, A. Dall‚ÄôAsta, V. Whelehan, A. Archer, and E. Chan- draharan, ‚ÄúIntrapartum cardiotocography patterns observed in suspected clinical and subclinical chorioamnionitis in term fetuses,‚Äù   Journal of Obstetrics and Gynaecology Research , vol. 45, no. 12, pp. 2343‚Äì2350, 2019. [191] S. Pereira, K. Lau, C. Modestini, D. Wertheim, and E. Chan- draharan, ‚ÄúAbsence of fetal heart rate cycling on the intra- partum cardiotocograph (CTG) is associated with intrapartum pyrexia and lower Apgar scores,‚Äù   The Journal of Maternal- Fetal & Neonatal Medicine , vol. 35, pp. 7980‚Äì7985, Feb. 2025.",
    "Sleep Model ‚Äì A Sequence Model for Predicting the Next Sleep Stage  Iksoo Choi and Wonyong Sung  Department of Electrical and Computer Engineering Seoul National University   Seoul, Korea  { akacis, wysung } @snu.ac.kr  Abstract ‚ÄîAs sleep disorders are becoming more prevalent there   is   an   urgent   need   to   classify   sleep   stages   in   a   less disturbing   way.   In   particular,   sleep-stage   classification   using simple sensors, such as single-channel electroencephalography (EEG), electrooculography (EOG), electromyography (EMG), or electrocardiography (ECG) has gained substantial interest. In this study, we proposed a sleep model that predicts the next sleep stage and used it to improve sleep classification accuracy. The sleep models were built using sleep-sequence data and employed either statistical   n -gram or deep neural network-based models. We developed beam-search decoding to combine the information from the sensor and the sleep models. Furthermore, we evaluated the performance of the   n -gram and long short-term memory (LSTM) recurrent neural network (RNN)-based sleep models and demonstrated the improvement of sleep-stage classification using an EOG sensor. The developed sleep models significantly improved the accuracy of sleep-stage classification, particularly in the absence of an EEG sensor.  Index Terms ‚Äîpolysomnography, sleep stage classification, deep neural networks, beam search decoding  I. I NTRODUCTION  Currently, sleep disorders are prevalent and lead many peo- ple to seek help from a psychiatrist or specialist. The sleep test divides a sleep period into epochs, typically 30-second long, and assigns a sleep class label to each epoch. The classification guidelines of the American Association of Sleep Medicine (AASM) distinguish five sleep classes: rapid eye movement ( REM   ) sleep, three non- REM   sleep classes ( N   1 ,   N   2 , and  N   3 ), and wake ( W   ) [1]. Sleep staging is generally performed through manual visual scoring of polysomnography (PSG) that includes several signal sources, such as electroencephalog- raphy (EEG), electrooculography (EOG), electromyography (EMG), electrocardiography (ECG), and respiratory sensors! [2]. While   PSG   remains   the   gold   standard   for   the   clinical evaluation of sleep, it is impractical for long-term monitoring of sleep problems at home. In recent years, several surrogate measures have been studied to reduce the costs and discomfort associated with PSG testing. Many sleep classification studies have employed a subset of PSG sensors, including single- channel EEG, EMG, EOG, ECG, or PPG [3]‚Äì[8]. However, when compared to full PSG, these surrogate tests inevitably result in an accuracy drop. Deep neural networks (DNN) offer new opportunities to dramatically improve the accuracy of simple sleep tests [9]‚Äì[11]. While it is challenging to accurately predict the next sleep stage,   sleep   generally   follows   typical   patterns   [12].   It   is unlikely that the sleep stage changes at every epoch. When observing sleep patterns, short-term inertia or predictability appears. Additionally, the sleep pattern typically includes four to six long-term cycles overnight, each of which comprises both   REM   and non- REM   stages [13], [14]. Our study proposes a sleep model that assesses and exploits the sequential nature of sleep. The use of sleep models can help to improve sleep classification accuracy, especially when relying on only simple surrogate sensors. The sleep model concept originated from the language model that predicts the probability of the next word or character in speech or text. In particular, language models are important for improving the accuracy of speech recognition [15], [16]. In Section II we cover the background and related works, including the sleep data and signal processing models used in the study, as well as an introduction to language models. Sec- tion III presents the proposed sleep models and beam search decoding, while Section IV provides experimental results and analyses. Finally, Section V concludes the study. II. SLEEP DATA   AND   BACKGROUND INFORMATION  A. Sleep Dataset  There are many sleep datasets publically available due to a considerable number of PSG tests. These sleep datasets serve two purposes: firstly, to extract sleep sequences from simplified input signals using signal processing   and   deep neural networks; secondly, to develop sleep models based on sleep patterns observed in PSG tests. To this end, we use the Haagleanden Medisch Centrum Sleep Database (HMC) dataset for the first purpose, and both HMC and NCH Sleep DataBank (NCHSDB) datasets for the second purpose [17], [18]. The HMC dataset was divided into 98 training, 24 validation, and 29 test splits, while the NCHSDB dataset used   3036 ,   379 , and  380   records for training, validation, and testing, respectively. The signal data were pre-filtered and resampled at 100 Hz using the method described in [17]. Each epoch of the time- series data was classified into one of the five sleep stages ( W   ,  REM   ,   N   1 ,   N   2 , and   N   3 ) based on the annotations provided for a sleep recording typically eight hours long.  arXiv:2302.12709v1 [eess.SP] 17 Feb 2023\n\nB. Signal Model  Our   study   involved   the   development   of   sleep   signal- processing models capable of classifying sleep stages using either the entire PSG data or a subset of it. The aim was to evaluate the performance of these models in both beam search decoding and greedy decoding. In conventional automatic sleep-stage classification methods, the sleep class with the highest probability at each epoch is selected, a process referred to as greedy decoding in this context. To build our sleep signal model, we followed the DNN model proposed in [8], which consisted of feature extraction and classification blocks as depicted in Fig. 1. The input sensor data which included two EEG channels (C4-M1 and C3-M2), one EMG (chin), and one EOG (E2-E1) channel were applied to the feature extraction block. The feature extraction block consisted of 3 convolutional neural networks (CNN) and 1 fully-connected DNN (FC-DNN) [19], [20]. In this block, the   e th   epoch that corresponded to 30-second of PSG data,   d e , was transformed to a   64 -dimensional feature vector,   f e . The classification block employed in this study was formed using FC-DNN with a layer size of 320 and a depth of 2. To classify one sleep stage,   s e , the classification block processed five epochs of input feature vectors:   f e ‚àí 2 ,   f e ‚àí 1 ,   f e ,   f e +1 , and   f e +2 . The HMC sleep dataset was used to develop two sleep signal models. The first model utilized four channels, which included EEG, EOG, and EMG as inputs. The second model only employed EOG and had a single channel.  C. Language Model  A language model predicts the probability distribution of the next word in a corpus. The inspiration for the proposed sleep model came from language models that are frequently used in computational linguistics and probabilistic fields [21], [22]. An excellent example of such a large language model is ChatGPT, which is capable of generating human-like responses [23]. They are traditionally trained on large corpus of text data, such as Wikipedia or speech transcriptions [24], [25]. Traditionally,  n -gram based language models have been used, but in recent  Fig. 1: Signal model employing deep neural networks.  Fig. 2: The sleep model that predicts the probabilities of sleep classes in the next epoch based on the previous ones. years, DNNs such as LSTM-RNNs or Transformers have gained popularity due to their superior performance [26]‚Äì[30]. However,   n -gram-based models are easier to build and require less time for inference [31]‚Äì[33]. III. S LEEP   M ODEL AND   B EAM   S EARCH   D ECODING  A. Sleep Model  The   SL eep   M odel (SLM) proposed in this study predicts the likelihood of each sleep class for the next epoch. These classes correspond to one of the five sleep stages, as shown in Fig. 2. The SLM was constructed using training data that contains sleep sequences. Sleep stages exhibit fairly consistent patterns, and the following sleep class is heavily influenced by the preceding stages, much like language models [12], [13]. We built   n -gram SLMs in manner of an   n -gram language model. An   n -gram SLM was built in this study by approximat- ing the probability with the number of occurrences of certain patterns in the training dataset. The number of occurrences was counted while traversing the entire sleep-stage sequences in dataset. For example, a   3 -gram   ( trigram )   SLM shows the probability of the next sleep class based on the previous two sleep classes, which can have   25   ( = 5 2 ) cases. The   trigram  probability of   P  (   N   3  N   1 ,N   2  )  , which is the probability of next stage being   N   3   following previous   N   1   and   N   2   stages, can be approximated as follows:  P  (   N   3  N   1 , N   2  )  ‚âà   C   ( N   1 , N   2 , N   3)  C   ( N   1 , N   2)   ,   (1) where   C   ( N   1 , N   2)   denotes the number of occurrences or counts of sleep stages   N   1   followed by   N   2   in the data. Thus, the process of building an   n -gram model is straightforward and the accuracy of prediction generally improves with the increas- ing value of   n . However, the above approximation cannot be accurate when the number of counts in the denominator, for example   C   ( N   1 , N   2)   in Equation (1), is not sufficiently large, which is called the data scarcity problem. To avoid the problem of data scarcity, a large training data is required. Increasing   n  also results in an exponential growth in the number of possible cases ( = 5 n ‚àí 1 ). Generally, when the number of counts is very small, the modeling fallbacks to a lower   n   [34]. In addition, there should not be a zero-probability prediction for the next class. Thus, when the numerator count is zero, we need smoothing that adds small numbers to the numerator and denominator terms to ensure a computational safety. A length of 8 hours sleep consists of   960   epochs or sleep stages,\n\nthus the total number of epochs for the HMC training set was approximately   100 ,   000 . To obtain a fairly accurate probability estimation, the number of the denominator count in Equation (1) needs to be around   100 . If the sleep sequences are equally distributed, which is unrealistically optimistic, the number of different sequences that can be formed with   100 ,   000   epochs is about   1 ,   000 , which can be approximated to   625   ( = 5 4 ) . Thus, we consider that the meaningful   n -gram size for HMC dataset would be around   n   = 5 . We also developed SLMs based on the LSTM-RNN archi- tecture by varying the number of LSTM layers or the hidden dimension of each LSTM layer [26]. The LSTM is a type of RNN architecture that has internal states to retain latent information from previous sequences. This property makes LSTM based SLMs unrestricted by previous sequence length, in contrast to   n -gram models, which are limited to a length of   n   ‚àí   1 . The network architecture of the LSTM based SLM consists of a sleep stage embedding layer, LSTM layers, and a softmax output layer.  B. Beam Search Decoding  Typical automatic sleep-stage classification only employs a sleep signal model. In the signal model, we can simply select the sleep class with the highest probability from each position in the sequence, which is often called greedy decoding. When surrogate sensors are used for sleep tests, the accuracy of the signal model with greedy decoding is not sufficiently high. The recognition accuracy of greedy decoding can be im- proved using a SLM. The output of the SLM provides the prior information for sleep classification. The posterior probability was determined by multiplying, addition in the   log   domain, the probability of the signal model ( P sig   ) by that of the SLM ( P SLM   ) using Equation (2).  log   P   ( s e ) = log   P sig   ( s e | d e ‚àí 2 , . . . , d e +2 ) +   Œ±   log   P SLM   ( s e | s 1 , . . . , s e ‚àí 1 )   ,   (2) where   d   is input signal,   s   denotes the sleep stages,   e   in subscript means the   e th   epoch, and   Œ±   is a parameter that as- signs a balanced weight between the signal and sleep models. Here, the signal model generates the likelihood of the sleep class using the input signal, whereas the SLM provides the prior probability. Sleep-stage classification can be considered a sequence recognition problem, that is, we need to consider the results over a long time span. The beam-search-decoding algorithm can select multiple sleep classes for each epoch in a given sequence [35]‚Äì[37]. This means that even sleep classes that do not show the highest probability can be saved for fur- ther evaluations in the future. Because the number of sequence candidates grows exponentially as decoding progresses, it is not possible to retain all of them. The algorithm chooses the  W   -best alternatives via a hyperparameter known as the beam width. The posterior probability for each epoch was obtained by multiplying the probabilities obtained from the signal and sleep models. To determine the most likely beam, the posterior probabilities of each beam sequence are multiplied, and the TABLE I:   2 -gram ( bigram ) sleep model probability table for HMC train split.  Previous Sleep Stage Next Sleep stage  W   REM   N   1   N   2   N   3  W   0.854   0.001   0.138   0.003   0.000  REM   0.016   0.907   0.066   0.010   0.000  N   1   0.109   0.080   0.498   0.311   0.000  N   2   0.019   0.014   0.062   0.864   0.040  N   3   0.007   0.001   0.007   0.063   0.921  resulting probability values are compared to select the highest one.  C. Model Details and Metric  We built the   n -gram model using KenLM, which imple- ments fall-back, smoothing, and data compression [38]. We evaluated   n -gram models on HMC and NCHSDB dataset, varying   n   from   2   to   9 , and applied the fall-back option. We also developed four kinds of LSTM-RNN based SLMs, 2 or 4 LSTM layers with 256 or 1,024 hidden dimensions on training split of each dataset. The performance of language models is commonly mea- sured by the perplexity [39]. The perplexity is defined as the inverse probability of the sequence of words,   w , normalized by the number of words,   N   , as shown in Equation 3,  P erplexity   ( w 1 , w 2 , . . . , w N   ) =   N  ‚àö  1  P   ( w 1 , w 2 , . . . , w N   )   . (3) We also used the perplexity to measure the performance of SLMs. A lower perplexity value indicates better performance of the SLM in predicting the next sleep stage. IV. E XPERIMENTAL   R ESULTS  A.   n -gram and LSTM-RNN based Sleep Models  Table I shows the   2 -gram ( bigram ) probabilities on the HMC dataset. This table shows that the probability of   REM  stage at the next epoch is 8% when the current sleep stage  Fig. 3: The test set perplexity of   n -gram sleep models with HMC or NCHSDB dataset.\n\nTABLE II: The validation and test set perplexities of LSTM- RNN based SLMs trained with training split of HMC or NCHSDB dataset. The numbers in the first column represent (the number of layers)   √ó   (the size of the hidden dimension) for each SLM.  LSTM-RNN Sleep Model HMC   NCHSDB Valid. set   Test set   Valid. set   Test set 2 √ó   256   1.546   1.609   1.293   1.287 2 √ó 1024   1.547   1.608   1.291   1.286  4 √ó   256   1.547   1.613   1.293   1.287 4 √ó 1024   1.548   1.610   1.291   1.286  is   N   1 . As expected, the diagonal terms show high values, indicating the inertia of repeating the same sleep classes. The transition probability from   N   1   to   N   2   is quite high and exhibits a low inertia of the   N   1   stage. As a result, classification between   N   1   and   N   2   introduces many errors. The perplexity of   n -gram SLMs, when assessed with the test dataset, is shown in Fig. 3. For HMC dataset, it shows that the perplexity decreased as   n   increased until   n   = 5 , but then increased thereafter. As described in Section III, the back- off and smoothing algorithms implemented in KenLM have an impact on performance distortion when   n   is greater than 5. The size of NCHSDB dataset was approximately 20 times larger than HMC dataset, we can expect improved SLM performance and less sensitive to   n . Next we trained LSTM-RNN based SLMs using HMC or NCHSDB training set. Table II shows the perplexity accord- ing to different LSTM-RNN based SLM configurations. The results confirm that LSTM-RNN based SLMs are better than the   n -gram based ones. The experimental resutls indicated that the size of training set had a significant impact on the SLM performance. The SLMs trained on the NCHSDB dataset performed relatively better than those with HMC. This implies that building a good SLM requires at least   1 ,   000   records. The performance of the SLM was affected by the characteristics of the sleep sequence, as evidenced by the difference in performance between the LSTM-RNN based SLM trained on the NCHSDB and tested on the HMC test set. The SLM was configured with 2 LSTM layers and a hidden dimension of   1 ,   024 , and achieved a perplexity of   1 . 286   on the NCHSDB test set, but only   1 . 654  on the HMC data. This difference is likely due to the fact that the sleep records in the HMC dataset are from adults, while those in the NCHSDB are from pediatrics, resulting in different sleep patterns that affect the inter-dataset performance of the SLMs.  B. Beam Search Decoding for Combining Signal and Sleep Models  We combined the 4-channel and 1-channel sleep signal models, explained in Section II-B, with the LSTM-RNN based SLM through beam-search decoding. The 4-channel signal model was combined with the LSTM-RNN based SLM used in IV-A with the optimum   Œ± , as described in Equation (2), TABLE III: The performance of the LSTM-RNN SLMs with 4 or 1 -channel signal models. The SLMs had 2 layers of LSTM with 1,024 hidden dimensions.  (a) 4-Channel Signal Model  Sleep Stage Classification Model   Œ±   Valid. set   Test set Kappa   Acc.   Kappa   Acc. Signal Model   N/A   0.741   0.804   0.680   0.759 + SLM Decording   0.12   0.680   0.759   0.680   0.759  (b) 1-Channel Signal Model  Sleep Stage Classification Model   Œ±   Valid. set   Test set Kappa   Acc.   Kappa   Acc. Signal Model   N/A   0.505   0.629   0.464   0.602 + SLM Decording   0.42   0.596   0.698   0.519   0.644  TABLE IV: The effect of probability weighting factor. The beam width was 128 and 1-channel signal model with 2 √ó 1024 LSTM-RNN SLM was evaluated.  Œ±   Valid. set   Test set Kappa   Acc.   Kappa   Acc. 0.34   0.587   0.692   0.517   0.642 0.38   0.592   0.696   0.516   0.642 0.42   0.596   0.698   0.519   0.644  0.46   0.588   0.693   0.515   0.640 0.50   0.594   0.697   0.511   0.638  of   0 . 12   and a beam width of   128 . The evaluation results are shown in Table III (a). The classification results based on greedy decoding for the signal models that do not utilize SLMs are labeled as ‚ÄòSignal Model‚Äô. Despite our attempts to improve decoding performance by incorporating the SLM, the results were not notably affected by varying   Œ±   values ranging from  0 . 2   to   1 . 5 . This is likely due to the highly informative nature of the 4-channel signal model, which employed two channels of EEG and one channel each of EMG and EOG as input. The results in Table III (b) demonstrate the 1-channel signal model when combined with the same SLM. The combination resulted in a   6 . 5%   improvement in Kappa score and a   4 . 3%  improvement in accuracy, despite the lower accuracy of sleep- stage classification using EOG alone compared to the 4- channel PSG signal. We used a beam width of 128 and searched for the best   Œ±   on the validation set, and the results of the   Œ±   search are listed in Table IV. The findings indicate that utilizing SLMs in sleep-stage classification can be beneficial, particularly when working with limited signal information, such as a single input channel or surrogate signals. This approach has the potential to be applied to other input modalities or different contexts to improve sleep- stage classification. V. C ONCLUSION  Our study proposed sleep models for predicting the next sleep stage, which can significantly enhance sleep classifica- tion accuracy by utilizing information from numerous sleep-\n\nstage sequences and extending the context length. Our models were applied to sleep-stage classification using simple EOG sensors. Sleep-stage sequences, rather than the signal sources, are the only data required to train sleep models, making them compatible with various sleep archives. Furthermore, once sleep models have been built, they can be employed in sleep- stage classification using different sensors, such as PPG, EOG, or ECG. R EFERENCES [1]   Richard B Berry, Rita Brooks, Charlene E Gamaldo, Susan M Harding, Robin M Lloyd, Carole L Marcus, and B Vaughn, ‚ÄúThe aasm manual for the scoring of sleep and associated events, version 2.4,‚Äù   Chicago: American Academy of Sleep Medicine , 2017. [2]   Clete A Kushida, Michael R Littner, Timothy Morgenthaler, Cathy A Alessi, Dennis Bailey, Jack Coleman Jr, Leah Friedman, Max Hir- shkowitz, Sheldon Kapen, Milton Kramer, et al., ‚ÄúPractice parameters for the indications for polysomnography and related procedures: an update for 2005,‚Äù   Sleep , vol. 28, no. 4, pp. 499‚Äì523, 2005. [3]   Mathias Perslev, Michael Jensen, Sune Darkner, Poul J√∏rgen Jennum, and Christian Igel,   ‚ÄúU-time: A fully convolutional network for time series segmentation applied to sleep staging,‚Äù   Advances in Neural Information Processing Systems , vol. 32, 2019. [4]   Md   Mosheyur   Rahman,   Mohammed   Imamul   Hassan   Bhuiyan,   and Ahnaf Rashik Hassan, ‚ÄúSleep stage classification using single-channel eog,‚Äù   Computers in biology and medicine , vol. 102, pp. 211‚Äì220, 2018. [5]   Mustafa Radha, Pedro Fonseca, Arnaud Moreau, Marco Ross, Andreas Cerny,   Peter   Anderer,   Xi   Long,   and   Ronald   M   Aarts,   ‚ÄúA   deep transfer learning approach for wearable sleep stage classification with photoplethysmography,‚Äù   NPJ digital medicine , vol. 4, no. 1, pp. 1‚Äì11, 2021. [6]   Qiao Li, Qichen Li, Chengyu Liu, Supreeth P Shashikumar, Shamim Nemati, and Gari D Clifford,   ‚ÄúDeep learning in the cross-time fre- quency domain for sleep staging from a single-lead electrocardiogram,‚Äù  Physiological measurement , vol. 39, no. 12, pp. 124005, 2018. [7]   Pedro Fonseca, Xi Long, Mustafa Radha, Reinder Haakma, Ronald M Aarts, and J¬¥ erÀÜ ome Rolink,   ‚ÄúSleep stage classification with ecg and respiratory effort,‚Äù   Physiological measurement , vol. 36, no. 10, pp. 2027, 2015. [8]   Iksoo Choi and Wonyong Sung, ‚ÄúPerformance assessment of automatic sleep stage classification using only partial psg sensors,‚Äù in   2022 IEEE Biomedical Circuits and Systems Conference (BioCAS) . IEEE, 2022, pp. 670‚Äì674. [9]   Mustafa Radha, Pedro Fonseca, Arnaud Moreau, Marco Ross, Andreas Cerny, Peter Anderer, Xi Long, and Ronald M Aarts,   ‚ÄúSleep stage classification from heart-rate variability using long short-term memory neural networks,‚Äù   Scientific reports , vol. 9, no. 1, pp. 14149, 2019. [10]   Huy Phan, Fernando Andreotti, Navin Cooray, Oliver Y Ch¬¥ en, and Maarten De Vos, ‚ÄúSeqsleepnet: end-to-end hierarchical recurrent neural network   for   sequence-to-sequence   automatic   sleep   staging,‚Äù   IEEE Transactions on Neural Systems and Rehabilitation Engineering , vol. 27, no. 3, pp. 400‚Äì410, 2019. [11]   Dani Kiyasseh, Tingting Zhu, and David A Clifton, ‚ÄúClocs: Contrastive learning   of   cardiac   signals   across   space,   time,   and   patients,‚Äù   in  International Conference on Machine Learning . PMLR, 2021, pp. 5606‚Äì 5615. [12]   Irwin Feinberg, ‚ÄúChanges in sleep cycle patterns with age,‚Äù   Journal of psychiatric research , vol. 10, no. 3-4, pp. 283‚Äì306, 1974. [13]   Agnessa Babloyantz, JM Salazar, and C Nicolis, ‚ÄúEvidence of chaotic dynamics of brain activity during the sleep cycle,‚Äù   Physics letters A , vol. 111, no. 3, pp. 152‚Äì156, 1985. [14]   Antonino Crivello, Paolo Barsocchi, Michele Girolami, and Filippo Palumbo,   ‚ÄúThe meaning of sleep quality: a survey of available tech- nologies,‚Äù   IEEE access , vol. 7, pp. 167374‚Äì167390, 2019. [15]   Kyuyeon Hwang and Wonyong Sung,   ‚ÄúCharacter-level incremental speech recognition with recurrent neural networks,‚Äù   in   2016 IEEE international conference on acoustics, speech and signal processing (ICASSP) . IEEE, 2016, pp. 5335‚Äì5339. [16]   Tomohiro Nakatani,   ‚ÄúImproving transformer-based end-to-end speech recognition   with   connectionist   temporal   classification   and   language model integration,‚Äù in   Proc. Interspeech , 2019. [17]   Diego Alvarez-Estevez and Roselyne Rijsman,   ‚ÄúHaaglanden medisch centrum   sleep   staging   database   (version   1.0.1),‚Äù   PhysioNet. https://doi.org/10.13026/7egw-0p30 , 2021. [18]   Guo-Qiang Zhang, Licong Cui, Remo Mueller, Shiqiang Tao, Matthew Kim, Michael Rueschman, Sara Mariani, Daniel Mobley, and Susan Redline,   ‚ÄúThe national sleep research resource: towards a sleep data commons,‚Äù   Journal of the American Medical Informatics Association , vol. 25, no. 10, pp. 1351‚Äì1358, 2018. [19]   Yann LeCun, Yoshua Bengio, and Geoffrey Hinton,   ‚ÄúDeep learning,‚Äù  nature , vol. 521, no. 7553, pp. 436‚Äì444, 2015. [20]   Yann LeCun, Yoshua Bengio, et al., ‚ÄúConvolutional networks for images, speech, and time series,‚Äù   The handbook of brain theory and neural networks , vol. 3361, no. 10, pp. 1995, 1995. [21]   Yoshua Bengio, R¬¥ ejean Ducharme, and Pascal Vincent, ‚ÄúA neural prob- abilistic language model,‚Äù   Advances in neural information processing systems , vol. 13, 2000. [22]   Peter F Brown, Vincent J Della Pietra, Peter V Desouza, Jennifer C Lai, and Robert L Mercer, ‚ÄúClass-based n-gram models of natural language,‚Äù  Computational linguistics , vol. 18, no. 4, pp. 467‚Äì480, 1992. [23]   Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al., ‚ÄúLanguage models are few-shot learners,‚Äù  Advances in neural information processing systems , vol. 33, pp. 1877‚Äì 1901, 2020. [24]   Jey Han Lau, Alexander Clark, and Shalom Lappin, ‚ÄúGrammaticality, acceptability, and probability: A probabilistic view of linguistic knowl- edge,‚Äù   Cognitive science , vol. 41, no. 5, pp. 1202‚Äì1241, 2017. [25]   Jerome R Bellegarda,   ‚ÄúStatistical language model adaptation: review and perspectives,‚Äù   Speech communication , vol. 42, no. 1, pp. 93‚Äì108, 2004. [26]   Sepp Hochreiter and J¬® urgen Schmidhuber, ‚ÄúLong short-term memory,‚Äù  Neural computation , vol. 9, no. 8, pp. 1735‚Äì1780, 1997. [27]   Iksoo Choi, Jinhwan Park, and Wonyong Sung,   ‚ÄúCharacter-level lan- guage modeling with gated hierarchical recurrent neural networks.,‚Äù in  INTERSPEECH , 2018, pp. 411‚Äì415. [28]   Stephen Merity, Nitish Shirish Keskar, and Richard Socher,   ‚ÄúReg- ularizing   and   optimizing   lstm   language   models,‚Äù   arXiv   preprint arXiv:1708.02182 , 2017. [29]   Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, ≈Åukasz Kaiser, and Illia Polosukhin, ‚ÄúAttention is all you need,‚Äù   Advances in neural information processing systems , vol. 30, 2017. [30]   Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova, ‚ÄúBert:   Pre-training   of   deep   bidirectional   transformers   for   language understanding,‚Äù   arXiv preprint arXiv:1810.04805 , 2018. [31]   Martin Sundermeyer, Ralf Schl¬® uter, and Hermann Ney,   ‚ÄúLstm neural networks for language modeling,‚Äù   in   Thirteenth annual conference of the international speech communication association , 2012. [32]   Aytug Onan and Mansur Alp Toc ¬∏oÀò glu, ‚ÄúA term weighted neural language model and stacked bidirectional lstm based framework for sarcasm identification,‚Äù   IEEE Access , vol. 9, pp. 7701‚Äì7722, 2021. [33]   Ehsan Shareghi, Daniela Gerz, Ivan Vuli¬¥ c, and Anna Korhonen, ‚ÄúShow some love to your n-grams: A bit of progress and stronger n-gram language modeling baselines,‚Äù in   Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) , 2019, pp. 4113‚Äì4118. [34]   Stanley F Chen and Joshua Goodman, ‚ÄúAn empirical study of smoothing techniques for language modeling,‚Äù   Computer Speech & Language , vol. 13, no. 4, pp. 359‚Äì394, 1999. [35]   Volker Steinbiss, Bach-Hiep Tran, and Hermann Ney,   ‚ÄúImprovements in beam search,‚Äù in   Third international conference on spoken language processing , 1994. [36]   Peng Si Ow and Thomas E Morton, ‚ÄúFiltered beam search in schedul- ing,‚Äù   The International Journal Of Production Research , vol. 26, no. 1, pp. 35‚Äì62, 1988. [37]   Christoph Tillmann and Hermann Ney, ‚ÄúWord reordering and a dynamic programming beam search algorithm for statistical machine translation,‚Äù  Computational linguistics , vol. 29, no. 1, pp. 97‚Äì133, 2003. [38]   Kenneth Heafield, ‚ÄúKenlm: Faster and smaller language model queries,‚Äù in   Proceedings of the sixth workshop on statistical machine translation , 2011, pp. 187‚Äì197. [39]   Fred Jelinek, Robert L Mercer, Lalit R Bahl, and James K Baker, ‚ÄúPerplexity‚Äîa measure of the difficulty of speech recognition tasks,‚Äù\n\nThe Journal of the Acoustical Society of America , vol. 62, no. S1, pp. S63‚ÄìS63, 1977.",
    "A large collection of real-world pediatric sleep studies  Harlin Lee, 1   Boyue Li, 1   Shelly DeForte, 2   Mark L. Splaingard, 2  Yungui Huang, 2   Yuejie Chi, 1*   Simon L. Linwood 3*  Abstract  Despite being crucial to health and quality of life, sleep‚Äîespecially pediatric sleep‚Äîis not yet well understood.   This is exacerbated by lack of access to sufficient pediatric sleep data with clinical annotation. In order to accelerate research on pediatric sleep and its connection to health, we create the Nationwide Children‚Äôs Hospital (NCH) Sleep DataBank and publish it at Physionet and the National Sleep Research Resource (NSRR), which is a large sleep data common with physiological data, clinical data, and tools for analyses. The NCH Sleep Data- Bank consists of 3,984 polysomnography studies and over 5.6 million clinical observations on 3,673 unique patients between 2017 and 2019 at NCH. The novelties of this dataset include: 1) large-scale sleep dataset suitable for discovering new insights via data mining, 2) explicit focus on pediatric patients, 3) gathered in a real-world clinical setting, and 4) the accompanying rich set of clinical data. The NCH Sleep DataBank is a valuable resource for advancing automatic sleep scoring and real-time sleep disorder prediction, among many other potential scientific discoveries.  Background & Summary  Sleep is an active process associated with physiological changes that involve multiple organ systems, and is vital for the maturation and daily functioning of infants, children and adolescents. Conse- quently, disruption of the complex interplay between sleep and other physiological processes can lead to significant medical consequences [1].   Sleep disorders, like obstructive sleep apnea (OSA) [2, 3], can lead to derangements in function that contribute to significant morbidity and even mor- tality. Sleep can also be disrupted by many organ-specific diseases like asthma, sickle cell disease, renal failure, or depression that alter the course of a particular medical condition and result in a poorer quality of life. Sleep disturbances in children are classified as behavioral insomnias of children, sleep-related breathing disorders, parasomnias, sleep-related movement disorders, circadian rhythm disorders or hypersomnias [4].   These sleep disorders may be associated with excessive daytime sleepiness (rare in young children), hyperactivity‚Äìimpaired attention, poor school performance from impaired concentration and vigilance, and behavior problems including irritability. Sleep problems suffer from under-reporting by parents and under-diagnosis by primary care physicians, but are conservatively estimated to occur in approximately 25% of healthy children  1. Department of Electrical and Computer Engineering, Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh PA 15213, USA. 2. Nationwide Children‚Äôs Hospital, 700 Children‚Äôs Drive, Columbus OH 43205, USA. 3. School of Medicine, University of California, Riverside, 92521 Botanic Gardens Drive, Riverside CA 92507, USA. *Corresponding authors: Yuejie Chi (yuejiechi@cmu.edu), Simon Lin Linwood (simon.linwood@ucr.edu)  1  arXiv:2102.13284v4 [eess.SP] 22 Jun 2022\n\nyounger than 5 years and in up to 80% of children with special health care needs.   Estimates of prevalence of sleep disorders in children vary more widely for behavioral sleep problems like insomnia than organic sleep problems like OSA. While some childhood sleep disorders need only medical history to be properly diagnosed and managed, some infants and children require an analysis of the child actually sleeping, called an overnight sleep study or polysomnography (PSG), to accurately diagnose their sleep-related con- dition. During an overnight PSG, the sleeping child‚Äôs physiological signals are recorded under the direct supervision of specially trained sleep technicians, who attach monitoring sensors to special computer software and adjust them during the night.   The technician also provides observations about the child‚Äôs sleep that are invaluable in making an accurate diagnosis. Video monitoring is also incorporated into the PSG, allowing review of movements necessary to diagnose nocturnal seizures, which occur in about 20% of children with epilepsy. The physiological data collected during a PSG provide a picture of clinically useful information about different sleep stages, sleep disruption, respiratory status during different sleep stages, leg movements, and changes in cardiac rate and rhythm during sleep. For instance, episodes of OSA may consist of decreased airflow in spite of normal respiratory effort in thoracic and abdominal belts, changes in electroencephalogram (EEG) pattern called arousals, cardiac deceleration, and oxygen desaturation.   These findings may be mild during non-random eye movement (non-REM) sleep but profound during REM sleep. Computational algorithms that learn from large amounts of data have seen remarkable success in healthcare, particularly with the proliferation of electronic health records (EHR) and improved sensors. Regrettably, without a curated and comprehensive dataset of substantial size and acces- sibility, pediatric sleep has not been able to fully benefit from such opportunities yet.   As a first step, this data descriptor introduces the Nationwide Children‚Äôs Hospital (NCH) Sleep DataBank, which has 3,984 pediatric sleep studies on 3,673 unique patients conducted at NCH between 2017 and 2019, along with the patients‚Äô longitudinal clinical data. They were gathered in the real-world clinical setting at NCH as opposed to, for example, a controlled clinical trial. The published PSG contain the patient‚Äôs physiological signals as well as the technician‚Äôs assessment of the sleep stages and descriptions of additional irregularities [5].   The accompanying 5.6 million records of clinical data are extracted from the EHR, and are separated into encounters, medications, measurements (e.g.   body mass index), diagnoses, and procedures.   The dataset is deposited in the National Sleep Research Resource (NSRR) [6] and Physionet [7, 8], and can be requested from   https: //sleepdata.org/datasets/nchsdb   or   https://physionet.org/content/nch-sleep .   Accom- panying code in Python to assist users in interacting with the dataset is published at   https: //github.com/liboyue/sleep_study . We expect the NCH Sleep DataBank to be used to study many problems related to pediatric sleep, including but not limited to:  ‚Ä¢   Automatic sleep stage classification, especially algorithms that combine modalities beyond EEG or ECG [9, 10, 11, 12, 13].  ‚Ä¢   Automatic real-time sleep disorder (e.g. OSA) detection [14, 15].  ‚Ä¢   Diagnosis prediction.  ‚Ä¢   Patient subtyping.   There is increasing evidence that many sleep disorders (e.g.   insomnia [16]) are heterogeneous and have different subtypes. Identifying them can help us understand 2\n\nthe disorder better and develop a more tailored course of treatment for different groups of patients.  ‚Ä¢   Treatment (e.g. medications and procedures) efficacy analysis.  Methods  Sleep study data acquisition  The NCH Sleep DataBank contains sleep studies acquired under standard care at NCH between Dec. 16, 2017 and Dec. 31, 2019 using Natus Sleepworks versions 8 and 9 [17, 18]. Physiological data collected during an overnight sleep study contain:  ‚Ä¢   Electroencephalogram (EEG) to identify sleep stages,  ‚Ä¢   Electromyelogram (EMG) of chin activity to help identify the decreased tone seen during REM sleep,  ‚Ä¢   Leg EMG to measure leg movements,  ‚Ä¢   Electrooculogram (EOG) to identify characteristic eye movements seen during REM sleep,  ‚Ä¢   Electrocardiogram (ECG) to monitor cardiac rate and rhythm,  ‚Ä¢   Nasal and oral sensors to measure airflow,  ‚Ä¢   Thoracic and abdominal belts to measure chest and abdominal movements during breathing, which is helpful in demonstrating increased or decreased respiratory effort,  ‚Ä¢   Pulse oximetry to measure blood oxygen saturation,  ‚Ä¢   End-tidal carbon dioxide (CO 2 ) measurement of exhaled air to indirectly measure blood CO 2  to assess for hypoventilation. Sleep studies were annotated in real time by technicians at the time of the study, and then were staged and scored by a second technician after the study was completed.   Technicians annotated studies using a combination of free-form text entries and selections within Natus Sleepworks. Tech- nicians tried to identify all events of interest, however each technician may have their own style of text annotation.   Due to the variability in sleep stages in children, NCH does not use automatic scoring of sleep stages. All sleep stages were manually scored by a technician and then verified or changed by a physician board certified in sleep medicine. Sleep studies were manually downloaded and converted to EDF+ format between May 2019 and Feb. 2020 using Natus Sleepworks version 9. Any gaps in the time-series data were padded with zeros as part of the conversion. The specific acquisition equipment, setup, and montage all followed standard care protocol at NCH. While changes may have been made to some studies, the NCH protocol for PSG is in accordance with the rules and technical specifications recommended by the American Academy of Sleep Medicine [10, 11]. Standard channel names are used and documented in the header of the EDF files, allowing inference of the montage. 3\n\nPatient cohort  The NCH Sleep DataBank consists of 3,984 sleep studies performed on 3,673 unique patients. Of them, 3,400 patients have one sleep study in the dataset, 238 have two studies, and 35 patients have more than two studies, with a maximum of 5 sleep studies for one patient. In terms of gender distribution, 2,068 patients were male, and 1,604 were female, with one unknown. Table 1 shows the distribution of the unique patients‚Äô races, where the majority of the patients were White, and about a fifth were Black or African American. In regards to ethnicity, 186 patients were Hispanic or Latino, 3,446 patients were Not Hispanic or Latino, and 41 had ethnicity of Other, Unknown, or No Information. Race description   Count   Percentage White   2,433   66.24% Black or African American   738   20.09% Multiple races   277   7.54% Asian   93   2.53% Others and unknown   132   3.59% Total   3,673   100% Table 1: The distribution of 3,673 unique patients‚Äô races. The majority of patients (2,412) in the dataset were less than 10 years old at the time of the sleep study, as seen in Figure 1. Figure 2 summarizes the length of care at NCH before and after the first sleep study. The length of care prior to first sleep study was calculated as the time between the patient‚Äôs earliest EHR entry (i.e. diagnosis, encounter, medication, measurement, procedure) and their first sleep study. If the patient‚Äôs earliest EHR entry was after the first sleep study, length of care is defined as 0.   The length of follow up was calculated as the time between the patient‚Äôs first sleep study and their last recorded EHR entry. Patients had a median of 289 days of follow-up after their first sleep study, and 74% (2,718) had follow-up between 90 days and 2 years.  Patient data linkage  Sleep study recordings and associated reports at NCH are stored in a database that is independent from the EHR, using Natus Sleepworks as a front end. It was therefore necessary to link patient information in two places. The first link was between the header information in the EDF+ files and the patient data entered in Natus Sleepworks. The second link was between the patient information in Natus and the EHR. A spreadsheet listing all sleep studies was exported from Natus Sleepworks. This listing included the date and time of each sleep study and patient information such as first and last name, date of birth and medical record number (MRN) for most sleep studies. Sleep studies were then downloaded from Natus in mini-batches, and exported to EDF+. Sleep study specific header information in the EDF+ files were used to match these files to the Natus spreadsheet export. When ambiguity was present, or when MRNs were not present in Natus, we removed the EDF+ file from our dataset. We then used each patient‚Äôs last name, date of birth, and MRNs extracted from Natus to retrieve patient records from the EHR. When matches could not be confidently made to the EHR, the sleep studies were removed from the dataset. 4\n\n0   5   10   15   20   25   30 Age at time of sleep study (years) 0 50 100 150 200 250 300 Number of sleep studies Figure 1: Age at the time of sleep study, where   20   patients that are more than   30   years old are not shown.  Data de-identification and IRB exemption  Each unique patient was given a random identifier (STUDY_PAT_ID), and each sleep study was given a separate random identifier (SLEEP_STUDY_ID). A single patient may have multiple sleep studies in the dataset, and therefore have multiple associated SLEEP_STUDY_IDs, but only one STUDY_PAT_ID. Sleep studies were then renamed (STUDY_PAT_ID)_(SLEEP_STUDY_ID).edf. All EDF+ headers were de-identified by replacing the first 256 bytes of the EDF+ file with a standard de-identified header.   As such, users are advised to ignore all header information in the EDF files (such as patientID, recordID, startdate, duration), but instead rely on the metadata in the accompanying .csv files to interpret the PSG results. Annotation channels were read from EDF+ using Python MNE [19] and written to text.   All EDF+ files were converted to EDF by removing the annotation channel using Luna ( https://zzz.bwh.harvard.edu/luna ). Annotation text files were then de-identified by replacing any word that was not in a whitelist with ‚ÄúXXX‚Äù. This process affected 10,888 annotations, which is about 0.22% of the total number of annotations (5,046,370).   The whitelist was a combination of 162 common phrases found in the annotations obtained by manual inspection, and a larger whitelist used by the de-identification program Philter [20]. The Philter whitelist contains approximately 195,000 tokens of medical terms and codes and common medical abbreviations, in addition to 20,000 most common English words, and excludes the most common Social Security and Census names. The tab delimited, de-identified annotations were then renamed to match the EDF filenames. To protect every patient‚Äôs privacy, random date shifts were applied to all data: for each patient (i.e. patients with the same STUDY_PAT_ID), one random date shift of +/- 180 days was chosen and applied to all data that are linked to the patient. Finally, we considered the risk of re-identification through rare diagnoses. Say a malicious user of this dataset is interested in re-identifying a specific patient, and the attacker has some information 5\n\n‚àí 25   ‚àí 20   ‚àí 15   ‚àí 10   ‚àí 5   0  Length of care before first sleep study (YEARS)  0 100 200 300 400 500 600  Number of patients  0   200   400   600   800   1000   1200  Follow up after first sleep study (DAYS)  0 100 200 300 400 500 600  Number of patients Figure 2:   Length of care at NCH before and after first sleep study, where each patient has two entries: one negative for length of care prior to first sleep study (in years), and one positive for follow up after first sleep study (in days). One entry above 1200 days and 5 entries below -25 years are not shown. about the patient such as their sex and race, as well as the fact that the patient has been diagnosed for a very rare genetic disease at NCH. If this diagnostic information is visible within the NCH Sleep DataBank, then the malicious user can likely figure out who this patient is, e.g. by searching for a female Asian child born between 2012 and 2016 with this very rare disease.   Therefore, we redacted rare diagnosis codes from DIAGNOSIS.CSV through the following procedure as an extra precaution. The EHR in NCH and the diagnoses table in NCH Sleep DataBank (DIAGNOSIS.CSV) contain several variables. One is DX_CODE (diagnosis code), which holds the International Classification of Diseases (ICD) code for each diagnosis. On Oct. 1, 2015, hospitals in the United States, including NCH, have switched from using ICD 9 (the 9th revision of ICD) codes to ICD 10 (the 10th revision of ICD) codes in EHR. Another relevant variable is DX_SOURCE_TYPE (diagnosis source type), which indicates whether the diagnosis was given at admission, presented as a part of the patient‚Äôs previous medical history, etc.   We were interested in the ones labeled ‚ÄúFinal Dx‚Äù, i.e.   the final diagnoses the clinicians gave after relevant examinations and tests. Using these variables, we defined rare diagnosis codes as ICD 10 or ICD 9 codes that were given as Final Dx to less than 10 unique patients in the entire NCH patient population (not limited to the NCH Sleep DataBank patients) during a given time period. Specifically, we queried 1) for every ICD 9 code, the number of unique NCH patients given the diagnosis as Final Dx between Jan. 1, 2000 and Sep. 30, 2015, and 2) for every ICD 10 code, the number of unique NCH patients given the diagnosis as Final Dx between Oct.   1, 2015 and Dec.   31, 2020.   If a code had less than 10 unique patients in either ICD 9 or ICD 10 lists, it was deemed a rare diagnosis code for our purpose. 6\n\nWe did not consider diagnoses before 2000 since the earliest diagnosis in NCH Sleep DataBank was from 2001. Then, in every row of DIAGNOSIS.CSV where a rare diagnosis code appeared, we changed the entries in DX_CODE, DX_NAME (diagnosis name), DX_ALT_CODE (corresponding ICD 10 codes for records before Oct 2015, and ICD 9 codes for those after Oct 2015), CLASS_OF_PROBLEM (‚ÄúStage 1‚Äù, ‚ÄúChronic‚Äù, ‚ÄúAcute‚Äù, ‚ÄúPresent upon Admission‚Äù), CHRONIC_YN (Indication of chronic disease) to the phrase ‚Äúredacted‚Äù. This process affected a total of 6,460 rows and 834 unique patients in DIAGNOSIS.CSV. As this project concerns analysis on de-identified data, the project did not fit the definition of Human Subjects Research as defined by the United States Department of Health and Human Ser- vices and Food and Drug Administration. Therefore, this study received NCH Institutional Review Board (IRB) exemption with HIPAA waiver. The protocol that concerns the de-identification and processing of the data, which requires handling identified data, and the collection and publication of data and summary statistics, was approved under ‚ÄúSTUDY00000505: Preparation of sleep study data‚Äù on September 22, 2019.  Data Records  The raw data for NCH Sleep DataBank [8] is available at Physionet   https://physionet.org/ content/nch-sleep , or at National Sleep Research Resource (NSRR)   https://sleepdata.org/ datasets/nchsdb . The NCH Sleep DataBank consists of two folders: Sleep_Data and Health_Data. Sleep_Data contains annotated PSG recordings, while Health_Data contains patient demographic and clinical data extracted from the EHR. Inside Sleep_Data, PSG sleep studies are provided in the EDF format, and annotations are provided in a separate tab-delimited file.   Sleep studies and their matched annotations share the same file name (STUDY_PAT_ID)_(SLEEP_STUDY_ID) but different extensions (.edf, .tsv). Clinical data in Health_Data are in .csv files, and they are linked to the files in Sleep_Data through the same STUDY_PAT_ID. Variables follow EHR conventions, and descriptions can be found in the file Sleep_Study_Data_File_Format.pdf in Health_Data.  Sleep studies  The 3,984 sleep study files (.edf) contain PSG recordings taken in clinical setting at NCH. An example plot of the signals can be seen in Figure 3.   Almost half (1,972) of the files have 26 channels, a quarter (1,012) have 29, a fifth (820) have 25, and the rest have 28, 24, 40, 27, 9, or 56 channels, in decreasing order of frequency. The most commonly appearing channel names are summarized in Table 2. The channel PATIENT EVENT was not used and can be excluded from analyses. We note again that all EDF headers were replaced with a standard de-identified version as part of the de-identification process. The total length of recording in the NCH Sleep DataBank amounts to 40,884 hours, where the minimum length of study is 3 minutes, the maximum is 16.5 hours, and the mean is 10.3 hours. 94.85% of the files contain between 8 and 12 hours of recordings, and the patients slept for a subset of those times. Users of the dataset should take into account that the majority of the recordings (3,204) are collected with a sampling frequency of 256 Hz, but 581 studies were sampled in 400 Hz, and the rest (199) in 512 Hz. 7\n\nChannel name   Description   Count   Percentage EEG C3-M2   3,971   99.67% EEG O1-M2   3,971   99.67% EEG O2-M1   3,971   99.67% EEG CZ-O1   3,971   99.67% RATE   Pulse oximeter signal integrity   3,970   99.65% ETCO2   End tidal CO2   3,970   99.65% CAPNO   End tidal CO2 waveform   3,970   99.65% RESP RATE   Respiratory rate   3,970   99.65% SPO2 (2,819) or OSAT (1,152)   Oxygen saturation   3,970   99.65% EEG F3-M2   3,969   99.62% RESP THORACIC (2,821) or RESP CHEST (1,148)   Thoracic inductance   3,969   99.62% RESP ABDOMINAL (2,821) or RESP ABDOMEN (1,148)   Abdominal inductance   3,969   99.62% SNORE   Measure of snore or air vibrations   3,968   99.60% EEG C4-M1   3,962   99.45% EEG F4-M1   3,960   99.40% C-FLOW   Continuous positive airflow waveform (PAP only)   3,943   98.97% EOG LOC-M2   3,933   98.72% EOG ROC-M1   3,931   98.67% EMG CHIN1-CHIN2   3,782   94.93% PRESSURE   CPAP pressure (PAP only)   2,824   70.88% EMG LLEG-RLEG   2,820   70.78% ECG EKG2-EKG   2,820   70.78% RESP AIRFLOW   Airway pressure with a thermistor   2,820   70.78% TIDAL VOL   Exhaled tidal volume (PAP only)   2,818   70.73% RESP PTAF   Airway pressure with nasal cannula   2,817   70.71% PATIENT EVENT   2,722   68.32% TCCO2   Transcutaneous CO2   1,417   35.57% SNORE_DR   Derived snore from PTAF   1,148   28.82% XFLOW   Derived airflow from Resp chest and abdominal   1,148   28.82% EMG LLEG+-LLEG-   1,146   28.77% EMG RLEG+-RLEG-   1,146   28.77% ECG LA-RA   1,146   28.77% FLOW_DR   Derived flow from Resp airflow   1,146   28.77% RESP FLOW   Airflow channel   1,146   28.77% C-PRESSURE   Positive pressure delivered via a PAP device   1,146   28.77% EEG CHIN1-CHIN2   136   3.41% Table 2:   List of 33 most common channels and their frequencies in 3,984 EDF files.   Other 101 channels appear in less than 1% of the files. Brief descriptions are included for channels that are not measuring EEG, EOG, or EMG. CO2 is carbon dioxide, PAP is positive airway pressure, CPAP is continuous PAP, and PTAF is pressure transducer. 8\n\nonset   duration   description 15985.234375   0.0   Chewing motion 15990.93359375   30.0   Sleep stage W 16002.09375   0.0   Movement 16002.34375   1.21875   Limb Movement Table 3: Example annotations from a .tsv file.   ‚ÄúChewing motion‚Äù and ‚ÄúMovement‚Äù are free text entries by the NCH technicion, while ‚ÄúLimb Movement‚Äù is a standard sleep event labeled by Natus Sleepworks.  Sleep study annotations  The 3,984 annotation files (.tsv) contain a total of 5,046,370 annotations. The minimum number of annotations contained in a sleep study is 5, while the maximum is 6,047, and the mean value is 1,267. Each annotation has the following information, where an example is given in Table 3.  ‚Ä¢   onset: The start time of the event since the beginning of the study in seconds.  ‚Ä¢   duration: The length of the event in seconds.  ‚Ä¢   description: The description of the event, which may be sleep stage label or free-form text entry by the NCH technician, or standard sleep event label by Natus Sleepworks. 35,821 unique descriptions appear in NCH Sleep DataBank. In particular, sleep stages are found in annotations with a duration of 30 seconds, where the descriptions include ‚ÄúSleep stage W‚Äù, ‚ÄúSleep stage N1‚Äù, ‚ÄúSleep stage N2‚Äù, ‚ÄúSleep stage N3‚Äù, ‚ÄúSleep stage R‚Äù, or ‚ÄúSleep stage ?‚Äù.   In sleep stage classification, W indicates awake, R stands for REM sleep, and N1, N2, N3 are non-REM stages 1, 2, 3, respectively. The annotation ‚ÄúSleep stage ?‚Äù typically occurs after ‚ÄúLights On‚Äù, and physiological data acquired during that time can usually be ignored, as it indicates that the study has ended. Of the total number of annotations, 79.48% were related to sleep staging:   6.88% (347,294) are ‚ÄúSleep stage ?‚Äù, 13.19% (665,676) are ‚ÄúSleep stage W‚Äù, 2.54% (128,410) are ‚ÄúSleep stage N1‚Äù, 27.41% (1,383,765) are ‚ÄúSleep stage N2‚Äù, 17.35% (875,486) are ‚ÄúSleep stage N3‚Äù, and 12.11% (611,320) are ‚ÄúSleep stage R‚Äù. This is equivalent to 30,539 hours of data with sleep stage labels. The mean length of such data per study is 7.7 hours, and 96.63% (3,850) of the studies contain between 6 and 10 hours of sleep data with stage labels. Besides sleep stage labels, the most common events include: Oxygen Desaturation, Oximeter Event, EEG Arousal, Obstructive Hypopnea, Limb Movement, Gain/Filter Change, Move, Body Position:   (Left, Right, Supine, Prone, Upright), Obstructive Apnea, Hypopnea, Central Apnea, and Mixed Apnea. Free text annotations by the NCH technician typically describe events in the room, movements, and other patient activities, and will often have a duration of 0 seconds. Additionally, hypopneas, apneas, seizures, and other patient events may be mentioned in the free text annotations. On the other hand, standard sleep event annotations are selected in, or automatically applied by Natus Sleepworks [17, 18], and are likely to have varying durations other than 0 or 30 seconds. While there may be some variation, the general format for sleep studies is as follows:   Sleep staging begins at the annotation ‚ÄúLights Off‚Äù and ends at ‚ÄúLights On‚Äù.   Descriptive annotations 9\n\nwill typically precede sleep stage scoring at irregular intervals prior to ‚ÄúLights Off‚Äù.   Sleep stages are annotated in 30 second epochs, beginning at ‚ÄúLights Off‚Äù; however not all studies include this annotation.  Clinical data  The NCH Sleep DataBank includes patient demographics and longitudinal clinical data such as encounters, medication, measurements, diagnoses, and procedures.   The number of observations and variables for each file are listed in Table 4. More details about the variables can be found in Sleep_Study_Data_File_Format.pdf in the same folder. Note that the age of the patient at the time of sleep study is calculated in SLEEP_STUDY.csv. Measurements include body mass index, body mass index percentile, or blood pressure. Table 5 lists 20 diagnoses that are given to the highest number of unique patients in the NCH Sleep DataBank according to DIAGNOSIS.csv.   Only diagnoses indicated as Final Dx in DX_SOURCE_TYPE were considered for this analysis. Any DX_CODEs recorded in ICD 9 code were converted to the corresponding ICD 10 codes, according to the ICD 10 codes provided under the variable DX_ALT_CODE in DIAGNOSIS.csv.   17 unique ICD 9 diagnoses (across 75 rows) that did not have corresponding ICD 10 codes were disregarded from further consideration.   We leveraged the hierarchical structure of ICD 10 codes to get a broad overview of the patient popu- lation. For example, ICD 10 code ‚ÄúG47.33 Obstructive sleep apnea (adult) (pediatric)‚Äù fall under the more general ICD 10 code ‚ÄúG47.3 Sleep apnea‚Äù which in turn is under the even more general ICD 10 code ‚ÄúG47 Sleep disorders.‚Äù Therefore, two patients with ‚ÄúG47.33 Obstructive sleep apnea (adult) (pediatric)‚Äù and ‚ÄúG47.61 Periodic limb movement disorder‚Äù, respectively, counted as two patients diagnosed with ‚ÄúG47 Sleep disorders‚Äù in Table 5. Note that we started by considering all diagnoses in the EHR data, not just the diagnoses resulting from the specific sleep studies included the NCH Sleep DataBank.  Technical Validation  Validation of de-identification procedure  After EDF files were de-identified, we performed several validation steps to confirm that the data matched the original EDF+ export. We loaded all channels from both the de-identified EDF file and the original EDF+ export and confirmed that all signal channels matched.   Finally, all files included in the data set have been read by Python MNE through this validation procedure and any files with read errors were not included in the data set.  Validation of data maps  We identified and tested three separate points in our data pipeline:   1) mapping of sleep study from Natus Sleepworks to the de-identified EDF file, 2) mapping of clinical data from EHR to the de-identified CSV files, and 3) the linkage between the sleep study and the clinical data. The first was the mapping between the de-identified EDF file and the original sleep data file accessible via Natus Sleepworks.   We first chose four random sleep studies (about 0.1% of the dataset), and a random 30-second segment from each study. Then we confirmed that the sleep data 10\n\nFile name   Variable names   Rows DEMOGRAPHIC.csv   study pat ID, birth date,   pcori gender cd,   pcori race cd, pcori hispanic cd, gender descr, race descr, ethnicity descr, language descr, peds gest age num weeks, peds gest age num days 3,673 SLEEP_STUDY.csv   study pat ID, sleep study ID, sleep study start date- time, sleep study duration datetime, age at sleep study days 3,984 SLEEP_ENC_ID.csv   study pat ID, sleep study ID, study enc ID   3,964 ENCOUNTER.csv   study enc ID, study pat ID, encounter date, visit start datetime, visit end datetime, adt arrival date- time, ed departure datetime, encounter type, visit type cd, visit type descr, ICU visit Y/N, prov ID, prov type, dept ID, dept specialty, admit source, hosp admit source, discharge disposition, discharge destination, drg code, drg name, visit reason 495,138 MEDICATION.csv   study med ID, study enc ID, study pat ID, med start datetime, med end datetime, med order datetime, med   taken   datetime,   med   source   type,   quantity, days supply, frequency, effective drug dose, eff drug dose source value, drug dose unit, refills, RxNorm code, RxNorm term type, medication descr, generic drug descr, drug order status, drug action, route, route source value, prescribing prov ID, pharm class, pharm subclass, thera class, thera subclass 3,035,986 MEASUREMENT.csv   study meas ID, study pat ID, study enc ID, meas recorded datetime, meas type, meas value number, meas value text, meas source, study prov ID 332,569 DIAGNOSIS.csv   study dx ID, study enc ID, study pat ID, dx start datetime, dx end datetime, dx source type, dx enc type, dx code type, dx code, dx name, dx alt code, class of problem, chronic Y/N, prov ID 1,513,853 PROCEDURE.csv   study proc ID, study pat ID, study enc ID, procedure datetime, study prov ID, proc ID NCH, proc code, proc code type, proc descr 283,599 PROCEDURE_SURG_HX.csv   study surghx ID, study pat ID, proc noted date, proc start time, proc end time, proc code, cpt code, proc descr 10,190 Table 4: The variable names and number of observations for each patient data file in Health_Data. More details about the variables can be found in Sleep_Study_Data_File_Format.pdf in the same folder. 11\n\nDiagnosis   ICD 10 code   Patients,   N  Sleep disorders   G47   3,379 Sleep apnea   G47.3   2,558 Sleep disorder, unspecified   G47.9   1,163 Other sleep disorders   G47.8   914 Circadian rhythm sleep disorders   G47.2   566 Insomnia   G47.0   388 Hypersomnia   G47.1   257 Sleep related movement disorders   G47.6   180 Parasomnia   G47.5   165 Narcolepsy and cataplexy   G47.4   47 Abnormalities of breathing   R06   2,776 Encounter for immunization   Z23   1,720 Chronic diseases of tonsils and adenoids   J35   1,686 Encounter   for   general   examination   without   com- plaint, suspected or reported diagnosis Z00   1,587 Acute upper respiratory infections of multiple and unspecified sites J06   1,537 Body mass index (BMI)   Z68   1,417 Suppurative and unspecified otitis media   H66   1,378 Symptoms and signs concerning food and fluid intake   R63   1,369 Acute pharyngitis   J02   1,260 Other symptoms and signs involving the circulatory and respiratory system R09   1,256 Other functional intestinal disorders   K59   1,185 Cough   R05   1,176 Lack of expected normal physiological development in childhood and adults R62   1,097 Encounter for follow-up examination after completed treatment for conditions other than malignant neo- plasm Z09   1,068 Nausea and vomiting   R11   1,051 Fever of other and unknown origin   R50   1,043 Specific developmental disorders of speech and lan- guage F80   1,002 Asthma   J45   991 Gastro-esophageal reflux disease   K21   982 Table 5: 20 diagnoses that are given to the highest number of unique patients in the NCH Sleep DataBank according to DIAGNOSIS.csv. Note that the diagnoses were abstracted to a higher level before being counted. For example, patients with diagnosis ‚ÄúG47.33 Obstructive sleep apnea (adult) (pediatric)‚Äù were counted under G47 and G47.3. 12\n\nviewed on Natus Sleepworks (Figure 3 top) matched data visualized from the corresponding EDF file in the published dataset (Figure 3 bottom). The second mapping was between the de-identified clinical data and the EHR. We extracted from the dataset all clinical data associated with the four random patients chosen in the first verification step, and confirmed that they are identical to the medical records viewed from the physician interface of the EPIC electronic medical record. The last mapping we verified was SLEEP_STUDY_ID, the random identifier linking the sleep studies to the patient data. We verified this by matching the sleep study, which is represented by SLEEP_STUDY_ID, with its corresponding encounter in the patient data, which is represented by STUDY_ENC_ID. If an encounter had procedure codes and departmental codes associated with sleep study, had the same randomly assigned STUDY_PAT_ID as the sleep study, and the same starting date and time (within a window of +/- one hour) as the sleep study start time obtained from Natus Sleepworks, we considered it a match.   We were able to match 3,964 sleep studies to encounter codes in the patient data using this method, therefore providing validation of a mapping between the sleep studies and patient data and consistency of date shifting.   This information is provided in the file SLEEP_ENC_ID.csv.  Sleep stage classification for PSG data validation  We developed a baseline sleep stage classifier and included it in the codebase to demonstrate the technical quality as well as a potential utility of the dataset, especially the PSG data. This simple algorithm predicts the sleep stages (W, N1, N2, N3, R) based on 30 seconds of 7 EEG channels (F4-M1, O2-M1, C4-M1, O1-M2, F3-M2, C3-M2, CZ-O1) after they are down sampled to 128Hz. Wavelet transform is a powerful method that can flexibly represent the time-frequency content of a signal. As such, it is particularly useful in analyzing non-stationary signals, and have previously been used for EEG-based sleep stage classification [21, 22, 23, 24]. After applying multi-resolution Daubechies wavelet transform [25] to each EEG channel, we computed summary statistics such as min, max, mean, and standard deviation of the coefficients, resulting in 84 features.   A random forest classifier with 100 decision trees was then trained on these features using 67% of the dataset, and tested on the rest. Table 6 reports the 3-fold stratified cross validation results on 3,928 sleep studies that had the 7 EEG channels, in addition to the results on some subgroups (0 to 1 year old, 1 to 2 years old, and 18+ patients). Fitting the classifier with default parameters from Scikit-learn [26] took 1 hour on Intel Xeon Gold 3.60GHz CPU in parallel; subgroups took less than 2 minutes each. This quick and straightforward algorithm, without any denoising or parameter tuning, achieves a classification accuracy of over 80% on the 222 adult sleep studies, suggesting high quality of the PSG recordings. Moreover, the difference in classification results between age groups supports the importance of having a dataset dedicated to pediatric sleep.  Prader-Willi syndrome (PWS) patient analysis for EHR data validation  The availability of EHR allows the study of clinically meaningful patient subpopulations in the NCH Sleep DataBank. As a use case, we examine the sleep patterns of PWS patients within this dataset.   To provide context, PWS is a rare genetic disorder that is estimated to affect 1 out of 10,000 to 30,000 people, and many researchers and clinicians are interested in sleep abnormalities and sleep-disordered breathing of PWS patients [27, 28, 29, 30, 31]. We construct two PSG cohorts, 13\n\nFigure 3:   Visual verification that a randomly chosen 30-second segment of sleep data on Natus Sleepworks (top) matches the sleep data in the corresponding EDF file (bottom), especially at the region of interest marked by red box. Natus Sleepworks may denoise or auto-scale some signals for the viewer. 14\n\nAutomated score sleep stage W   N1   N2   N3   R Manual score sleep stage,   N   W (661,645)   63.1   0.   34.0   1.5   1.4 N1 (127,602)   23.9   0.9   68.1   2.1   5.0 N2 (1,375,678)   4.4   0.   88.6   5.8   1.1 N3 (871,200)   1.7   0.   27.2   70.7   0. R (608,180)   6.7   0.   76.6   1.5   15.1  (a) All age groups.   3,928 sleep studies and 3,644,305 samples.   Overall accuracy is 64.4%.  Automated score sleep stage W   N1   N2   N3   R Manual score sleep stage,   N   W (52,979)   89.5   0.1   8.2   0.5   1.7 N1 (8,263)   37.5   2.5   47.4   0.6   12.1 N2 (80,275)   5.6   0.1   89.1   2.9   2.3 N3 (30,612)   2.6   0.   18.3   79.1   0. R (24,006)   9.2   0.   24.7   0.6   65.5  (b) 18 years and older. 222 sleep studies and 196,135 samples. Overall accuracy is 81.1%.  Automated score sleep stage W   N1   N2   N3   R Manual score sleep stage,   N   W (63,041)   83.3   0.   2.4   2.8   11.4 N1 (4,579)   28.7   1.1   24.7   6.2   39.2 N2 (38,525)   9.4   0.   62.9   10.2   17.4 N3 (64,512)   4.5   0.   3.7   83.3   8.5 R (60,167)   11.1   0.   5.0   7.1   76.8  (c) 0-1 year olds.   242 sleep studies and 230,824 samples.   Overall accuracy is 76.6%.  Table 6: Sleep stage classification results of our baseline algorithm applied to different age groups. One sample is a 30-second epoch of sleep. Cell (row   i , column   j ) of the normalized confusion matrix indicates the percentage (%) of samples in stage   i   (manually scored by NCH technician) that were predicted to be in stage   j   (by our automated algorithm). Each row adds to 100%. Bolded diagonal entries are the percentages of samples in each stage that were correctly classified. Overall accuracy is the total number of correctly classified samples divided by the total number of samples in %. All numbers reported are averaged over 3-fold stratified cross validation trials and rounded to one decimal point. Standard deviation was <1% for all entries except one and not shown here. 15\n\nCohort 1   Cohort 2 PSG,   N   16   370 Unique patients,   N   12   311 Age, mean   ¬±   s.d. (years)   10.5   ¬±   5.6   13.2   ¬±   4.7 Sleep time, mean   ¬±   s.d. (hours)   8.0   ¬±   0.7   7.5   ¬±   0.9 W, mean   ¬±   s.d. (%)   14.4   ¬±   7.1   20.5   ¬±   16.1 N1, mean   ¬±   s.d. (%)   4.1   ¬±   2.7   3.5   ¬±   3.4 N2, mean   ¬±   s.d. (%)   45.2   ¬±   7.3   39.9   ¬±   11.5 N3, mean   ¬±   s.d. (%)   20.5   ¬±   6.7   21.1   ¬±   8.5 R, mean   ¬±   s.d. (%)   15.8   ¬±   6.0   15.0   ¬±   7.3 N1 N2, mean   ¬±   s.d. (%)   49.3   ¬±   6.7   43.4   ¬±   11.8 N1 N2 N3, mean   ¬±   s.d. (%)   69.8   ¬±   6.3   64.5   ¬±   13.4 Table 7:   Summary statistics of sleep time and distribution of sleep stages for two PSG cohorts. Cohort 1: PSGs with OSA diagnoses on PWS patients, Cohort 2: PSGs with OSA diagnoses on obese but not PWS patients; sleep time: total amount of time spent in sleep stages W, N1, N2, N3, and R; s.d.: standard deviation. Percentage of each sleep stage is calculated by dividing time spent in each sleep stage by sleep time. All numbers are rounded to one decimal point. where Cohort 1 includes the PSGs of PWS patients, and Cohort 2 consists of PSGs of obese but non-PWS patients. To control for the effect of OSA, both cohorts only consider PSGs during which patients were diagnosed OSA. To construct the PSG cohorts, we first searched for all STUDY_ENC_IDs in DIAGNOSIS.csv during which a patient was given a final diagnosis of OSA. Then, we only kept the encounter IDs that were also present in SLEEP_ENC_ID.csv, as we have matched them with SLEEP_STUDY_IDs in an earlier validation step.   This process identified 860 PSGs (763 unique patients) with OSA diagnoses. Among these, 16 PSGs (12 unique patients) were designated Cohort 1, since they were associated with STUDY_PAT_IDs that had a final diagnosis of PWS in the EHR. For reference, the NCH Sleep DataBank has a total of 34 unique patients who had final diagnosis of PWS in the EHR. On the other hand, 370 PSGs (311 unique patients) were associated with STUDY_PAT_IDs with obesity diagnoses but not PWS, and selected Cohort 2. For every PSG in Cohort 1 and Cohort 2, we tallied the number of each sleep stage (W, N1, N2, N3, R) annotation, and extracted the following sleep characteristics: total length of sleep (sleep time) by counting 30 seconds of sleep for each sleep stage annotation, and distribution of sleep stages, e.g., W constitutes 20% of the sleep time.   Table 7 describes summary statistics of the two cohorts‚Äô sleep characteristics.   In summary, the ease-of-navigation of the EHR data makes it possible to conduct disease-specific data mining using NCH Sleep DataBank, e.g. extraction of sleep characteristics such as apnea-hypopnea index (AHI), and refined statistical analysis that accounts for potential confounding variables such as BMI and age. 16\n\nUsage Notes  The NCH Sleep DataBank can potentially be used to study many problems related to pediatric sleep, including but not limited to:  ‚Ä¢   Automatic sleep scoring (sleep stage classification): Sleep scoring divides sleep into two stages, rapid eye movement (REM), and non-REM, then further divides the latter into shallow sleep (stages N1 and N2) and deep sleep (stage N3) [9, 10, 11], in addition to wake (Stage W). In typical pediatric clinical settings, this is a time-consuming and tedious process done by a technician. Many computational algorithms have shown promise for automatic sleep scoring in adults [12], which encourage exploration on automatic sleep scoring for infants and children. Algorithms that combine PSG modalities beyond EEG or ECG [13] especially warrant more investigation.  ‚Ä¢   Automatic sleep disorder (e.g. obstructive apnea) detection: Large sets of PSG signals pub- lished with expert annotations can be leveraged to develop computational algorithms in sleep disorder detection, unleashing the potential of eventual real-time systems that read these signals and detect sleep disorders at their onsets [14, 15]. OSA detection is particularly im- portant, as OSA is associated with various cardiovascular, respiratory, and neurocognitive deficits and morbidity among infants and children [2, 3].  ‚Ä¢   Diagnosis prediction: Statistical models that predict or measure the risk of diagnoses using other variables (e.g. other diagnoses, demographic, features from PSG, encounters, measure- ment values) can be constructed and validated to create hypotheses for further experiment.  ‚Ä¢   Identifying patient subgroups:   Given the demographics and medical history, patients can be divided into clinically meaningful subgroups before further analysis, as demonstrated in this paper for PWS. Additionally, data-driven approaches may be developed to reveal clusters within the patient population, which could affect their symptoms or best courses of treatment, e.g. as suggested for insomnia [16].  ‚Ä¢   Treatment efficacy analysis: Retrospective studies using the accompanying longitudinal clin- ical data (e.g. medications and procedures) can be used to analyze efficacy of different treat- ments options.  Competing interests  The authors declare no competing interests.  Acknowledgements  Research reported in this publication was supported by the National Institute Of Biomedical Imag- ing And Bioengineering of the National Institutes of Health under Award Number R01EB025018. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.   The authors thank Tim Held for data identification, Melody Kitzmiller for data query, Dan Digby for data pipelines, Rajesh Ganta for data validation, Iris Karhoff for the interpretation of PSG channel names, Rahul Ragesh, Ramachandra Mannava, 17\n\nand Jacob Hoffman for help with sleep stage classifier development, Daniel Mobley and Michael Rueschman for publishing the data to NSRR, and Lucas McCullum and Tom Polland for publishing the data to Physionet.  Author contributions  Y.C. and S.L.L. designed and supervised the study. S.D., Y.H., B.L., and H.L. prepared the dataset. M.L.S. provided clinical interpretations. H.L., B.L., and S.D. conducted data analysis and technical validation. H.L., Y.C., S.D., M.S., Y.H., B.L., and S.L.L. drafted the manuscript.  Code availability  The code that was used to analyze patient data, read EDF files, run baseline sleep stage classifier, and generate figures and tables in this paper is published at   https://github.com/liboyue/sleep_ study .  References  [1] Splaingard, M. L. & May, A. Sleep disturbances (nonspecific). In McInerny, T. K.   et al.   (eds.)  American Academy of Pediatrics Textbook of Pediatric Care , chap. 194 (American Academy of Pediatrics, 2016). [2] Lumeng, J. C. & Chervin, R. D. Epidemiology of pediatric obstructive sleep apnea.   Proc. Am. Thorac. Soc.   5 , 242‚Äì252 (2008). [3] Beebe, D. W.   et al.   Neuropsychological effects of pediatric obstructive sleep apnea.   J. Int. Neuropsychol. Soc.   10 , 962 (2004). [4] American Academy of Sleep Medicine.   International classification of sleep disorders   (American Academy of Sleep Medicine, 2014), 3rd edn. [5] Kushida, C. A.   et al.   Practice parameters for the indications for polysomnography and related procedures: an update for 2005.   Sleep   28 , 499‚Äì523 (2005). [6] Zhang, G.-Q.   et al.   The national sleep research resource:   towards a sleep data commons.  Journal of the American Medical Informatics Association   25 , 1351‚Äì1358 (2018). [7] Goldberger, A. L.   et al.   Physiobank, physiotoolkit, and physionet:   components of a new research resource for complex physiologic signals.   circulation   101 , e215‚Äìe220 (2000). [8] Lee, H., Li, B., Huang, Y., Chi, Y. & Lin, S.   NCH sleep databank:   a large collection of real-world pediatric sleep studies with longitudinal clinical data (version 3.1.0).   PhysioNet  https://doi.org/10.13026/p2rp-sg37 (2021). [9] Grigg-Damberger, M.   et al.   The visual scoring of sleep and arousal in infants and children.   J. Clin. Sleep Med.   3 , 201‚Äì240 (2007). 18\n\n[10] Berry, R. B.   et al.   The AASM manual for the scoring of sleep and associated events: rules, terminology and technical specifications. Version 2.4.   (American Academy of Sleep Medicine, 2017). [11] Berry, R. B.   et al.   The AASM manual for the scoring of sleep and associated events: rules, terminology and technical specifications. Version 2.5.   (American Academy of Sleep Medicine, 2018). [12] Fiorillo, L.   et al.   Automated sleep scoring: A review of the latest approaches.   Sleep Med. Rev.  48 , 101204 (2019). [13] Yan, R.   et al.   Multi-modality of polysomnography signals‚Äô fusion for automatic sleep scoring.  Biomed. Signal Process. Control   49 , 14‚Äì23 (2019). [14] Mendonca, F., Mostafa, S. S., Ravelo-Garc√≠a, A. G., Morgado-Dias, F. & Penzel, T. A review of obstructive sleep apnea detection approaches.   IEEE J. Biomed. Health Inform.   23 , 825‚Äì837 (2018). [15] Xie, B. & Minn, H. Real-time sleep apnea detection by classifier combination.   IEEE Trans. Inf. Technol. Biomed.   16 , 469‚Äì477 (2012). [16] Benjamins, J. S.   et al.   Insomnia heterogeneity:   characteristics to consider for data-driven multivariate subtyping.   Sleep Med. Rev.   36 , 71‚Äì81 (2017). [17]   SleepWorks 8 reference manual   (Natus Medical Incorporated, 2017). [18]   SleepWorks 9 reference manual   (Natus Medical Incorporated, 2017). [19] Gramfort, A.   et al.   MEG and EEG data analysis with MNE-Python.   Front. Neurosci.   7 , 267. [20] Norgeot, B.   et al.   Protected Health Information filter (Philter): accurately and securely de- identifying free-text clinical notes.   NPJ Digit. Med.   3 , 1‚Äì8 (2020). [21] Ebrahimi, F., Mikaeili, M., Estrada, E. & Nazeran, H.   Automatic sleep stage classification based on EEG signals by using neural networks and wavelet packet coefficients. In   2008 30th Annual International Conference of the IEEE Engineering in Medicine and Biology Society , 1151‚Äì1154 (IEEE, 2008). [22] Fraiwan, L., Lweesy, K., Khasawneh, N., Wenz, H. & Dickhaus, H.   Automated sleep stage identification system based on time‚Äìfrequency analysis of a single EEG channel and random forest classifier.   Comput. Methods Programs Biomed.   108 , 10‚Äì19 (2012). [23] Hassan, A. R. & Bhuiyan, M. I. H.   A decision support system for automatic sleep staging from EEG signals using tunable Q-factor wavelet transform and spectral features.   J. Neurosci. Methods   271 , 107‚Äì118 (2016). [24] ≈ûen, B., Peker, M., √áavu≈üoƒülu, A. & √áelebi, F. V.   A comparative study on classification of sleep stage based on EEG signals using feature selection and classification algorithms.   J. Med. Syst.   38 , 18 (2014). [25] Daubechies, I. Orthonormal bases of compactly supported wavelets.   Comm. Pure Appl. Math.  41 , 909‚Äì996 (1988). 19\n\n[26] Pedregosa, F.   et al.   Scikit-learn:   machine learning in Python.   J. Mach. Learn. Res.   12 , 2825‚Äì2830 (2011). [27] Vela-Bueno, A.   et al.   Sleep in the prader-willi syndrome: clinical and polygraphic findings.  Arch. Neurol.   41 , 294‚Äì296 (1984). [28] Hertz, G., Cataletto, M., Feinsilver, S. H. & Angulo, M.   Sleep and breathing patterns in patients with prader willi syndrome (pws):   effects of age and gender.   Sleep   16 , 366‚Äì371 (1993). [29] Nixon, G. M. & Brouillette, R. T.   Sleep and breathing in prader-willi syndrome.   Pediatr. Pulmonol.   34 , 209‚Äì217 (2002). [30] Meyer, S. L.   et al.   Outcomes of adenotonsillectomy in patients with prader-willi syndrome.  Arch. Otolaryngol. Head Neck Surg.   138 , 1047‚Äì1051 (2012). [31] Pavone, M.   et al.   Sleep disordered breathing in patients with prader‚Äìwilli syndrome: A mul- ticenter study.   Pediatr. Pulmonol.   50 , 1354‚Äì1359 (2015). 20",
    "Title Page  Title: Microbes in the Moonlight: How the Gut Microbiota Influences Sleep  Author: Enso O. Torres Alegre  Affiliation: Pontifical Catholic University of Chile, Santiago, Chile  Email: onill@uc.cl  ORCID: https://orcid.org/0000 - 0002 - 6798 - 8776  Co - authors: None  Conflict of Interest Statement  The author declares no conflicts of interest related to this work.  Funding Statement  No external funding was received to support the preparation of this manuscript.  Data Availability Statement  No new datasets were generated or analyzed for this review. All data discussed in the  manuscript are derived from previously published studies cited in the References  section.  Ethics Approval Statement  Ethics approval was not required for this review article, as it does not involve new  human or animal research.  Patient Consent Statement  Not applicable. This article does not contain any studies involving human  participants.  Permission to Reproduce Material  Figures created using BioRender.com are original to the author. No previously  published material was reproduced.  Clinical Trial Registration  Not applicable. This manuscript does not report results of a clinical trial.\n\nAbstract  The gut microbiota has emerged as a fundamental regulator of sleep physiology, acting  through interconnected neural, immune, and endocrine pathways. This bidirectional  relationship influences neurotransmitter production, circadian rhythms, inflammatory  act ivity, and metabolic balance. Changes in microbial composition, particularly those  affecting serotonin, GABA, and short - chain fatty acid (SCFA) metabolism, have been  associated with insomnia, neuroinflammation, metabolic dysfunction, and mood  disturbances.   The gut microbiota also shapes immune responses and endocrine  signaling. Dysbiosis promotes IL - 1 Œ≤   and TNF - Œ±   mediated inflammation, alters intestinal  permeability, activates the HPA axis, and disrupts cortisol and melatonin rhythms,  which together impair sleep quality. This review synthesizes current evidence on the  integrated interactions among gut microbiota,   sleep regulation, immune activity, and  endocrine function. It also examines emerging therapeutic strategies, including  probiotics,   fecal   microbiota   transplantation   (FMT   and   WMT),   chrononutrition,  nutraceuticals,   and   neuropeptide - based   approaches   aimed   at   r estoring   sleep  homeostasis and improving systemic health.  Abreviations:  BBB   ‚Äì   Blood - Brain Barrier  CNS   ‚Äì   Central Nervous System  ENS   ‚Äì   Enteric Nervous System  GM   ‚Äì   Gut Microbiota  GMBA   ‚Äì   Gut - Microbiota - Brain Axis  HPA   ‚Äì   Hypothalamic - Pituitary - Adrenal Axis  NREMS   ‚Äì   Non - Rapid Eye Movement Sleep  REMS   ‚Äì   Rapid Eye Movement Sleep  SCN   ‚Äì   Suprachiasmatic Nucleus  GABA   ‚Äì   Gamma - Aminobutyric Acid  SCFAs   ‚Äì   Short - Chain Fatty Acids  NE   ‚Äì   Norepinephrine  ACh   ‚Äì   Acetylcholine\n\nDA   ‚Äì   Dopamine  5 - HT   ‚Äì   Serotonin  OX - A/B   ‚Äì   Orexin A/B  IL - 1 Œ≤   ‚Äì   Interleukin 1 Beta  TNF - Œ±   ‚Äì   Tumor Necrosis Factor Alpha  LPS   ‚Äì   Lipopolysaccharides  TLR4   ‚Äì   Toll - Like Receptor 4  GH   ‚Äì   Growth Hormone  GHRH   ‚Äì   Growth Hormone - Releasing Hormone  IGF - 1   ‚Äì   Insulin - Like Growth Factor 1  PGD2   ‚Äì   Prostaglandin D2  FMT   ‚Äì   Fecal Microbiota Transplantation  WMT   ‚Äì   Washed Microbiota Transplantation  SII   ‚Äì   Systemic Immune - Inflammation Index  1.   Introduction:  Sleep is a cyclical and transient state regulated by neurobiological processes, playing a  fundamental role in growth, development, immune function, and overall homeostasis.  However, sleep disorders, such as insomnia, are increasingly prevalent across all a ge  groups   and   represent   significant   risk   factors   for   metabolic,   cardiovascular,   and  neuropsychiatric diseases, including depression, diabetes mellitus, hypertension, and  coronary heart disease. Factors such as stress, anxiety, stimulant consumption, and  ex cessive use of electronic devices before bedtime further exacerbate these disorders,  intensifying their negative impact on health   [1,2] .  In recent years, the prevalence of sleep disorders has risen dramatically due to lifestyle  changes such as remote work, excessive social media exposure, and the effects of the  COVID - 19 pandemic. Chronic sleep deprivation not only impairs cognitive function   but  is also associated with an increased risk of inflammatory, metabolic, and neurological  diseases   [3,4] .   Older adults are particularly vulnerable to sleep disturbances due to age -  related physiological changes, such as prolonged sleep latency, reduced efficiency, and\n\nshorter total sleep duration, predisposing them to circadian rhythm disorders and sleep -  disordered breathing   [5] .  The circadian rhythm, regulated by a hierarchical system of cellular clocks with the  suprachiasmatic   nucleus   as   the   central   pacemaker,   synchronizes   physiological  processes with the 24 - hour cycle. Disruptions to this system can lead to metabolic and  neurops ychiatric imbalances, increasing susceptibility to chronic diseases   [6] .   Modern  societal habits, such as irregular schedules and nighttime light exposure, often cause  circadian misalignment, which has been linked to conditions like metabolic syndrome  and certain cancers   [7] .   Understanding the mechanisms underlying this synchronization  is crucial for developing effective therapeutic strategies.  Recent evidence suggests a bidirectional relationship between the gut microbiota and  circadian   rhythms.   Both   central   and   peripheral   clocks   influence   gut   microbiota  composition and metabolites, while the microbiota, in turn, affects circadian regulation,  cl ock gene expression, and sleep quality. Disruptions in this interplay   induced by factors  such as shift work or obesogenic diets   can compromise metabolic homeostasis and  contribute to sleep disorders   [8] [9] .   Restoring circadian rhythmicity through strategies  like time - restricted feeding and probiotic supplementation has shown promising effects  on sleep improvement and metabolic health   [9] .  The gut - microbiota - brain axis has emerged as a key player in sleep regulation and  cognitive function. It has been proposed that gut dysbiosis contributes to sleep disorders  through   systemic   inflammation   and   neurotransmitter   modulation,   opening   new  therapeu tic possibilities. In this context, non - pharmacological therapies such as  Traditional Chinese Medicine (TCM), light therapy, melatonin, and gut microbiota  modulation have gained relevance in the treatment of insomnia and other sleep  disturbances   [10 ‚Äì 13] .  Given the growing recognition of the gut microbiota‚Äôs role in sleep and circadian  regulation, it is crucial to further explore the underlying mechanisms linking these  systems. This review examines the interconnection between the gut - microbiota - brain  axis a nd its impact on sleep physiology, highlighting its implications for sleep disorder  treatment and potential therapeutic interventions.  Despite the rapid expansion of research linking the gut microbiota with sleep physiology,  existing reviews often address these interactions in isolation ,   focusing either on  circadian rhythms, immune activation, or metabolic pathways. However, no current  synthesis integrates the combined roles of the gut microbiota, immune function,  endocrine signaling, and microbial metabolites in shaping sleep health. This   gap limits a  comprehensive understanding of how these systems converge to influence sleep  architecture and the pathophysiology of sleep disorders. To address this, the present\n\nreview provides an integrated multi - system perspective on the sleep - microbiota axis,  connecting mechanistic evidence with emerging therapeutic strategies.  The following section explores the gut - microbiota - brain axis in greater depth, analyzing  how gut microbiota influences brain function and sleep regulation, as well as its  potential implications for the treatment of sleep disorders .  2.   Literature Search Strategy and Study Selection  A comprehensive literature search was conducted to identify peer - reviewed studies  examining the relationships among gut microbiota, sleep physiology, immune  function, and endocrine regulation. Searches were performed in PubMed, covering  literature publishe d between January 2015 and October 2024. Recent preprints  were considered only when supported by peer - reviewed evidence.  The search strategy combined controlled vocabulary and free - text terms,  including:  ‚Äúgut microbiota AND sleep‚Äù ,   ‚Äúmicrobiome AND circadian rhythm‚Äù ,   ‚Äúsleep  deprivation AND inflammation‚Äù ,   ‚ÄúSCFAs AND sleep‚Äù ,   ‚Äúgut ‚Äì brain axis AND  insomnia‚Äù ,   ‚Äúsleep AND immune system‚Äù ,   ‚Äúmicrobiota AND neurotransmitters‚Äù ,  and   ‚Äúchrononutrition AND sleep.‚Äù  Inclusion criteria  Studies were included if they:  1.   Reported original data in humans or animals on gut microbiota, sleep, immune  signaling, or endocrine outcomes.  2.   Explored   mechanistic   pathways   involving   microbial   metabolites   (SCFAs,  tryptophan derivatives), neuroimmune interactions, or circadian processes.  3.   Evaluated interventions targeting the microbiota ‚Äì sleep axis (e.g., probiotics,  WMT/FMT, dietary approaches, neuropeptides).  4.   Were published in English between 2015 and 2024.  Exclusion criteria  Excluded were:  ‚Äì   Studies without sleep - related outcomes.  ‚Äì   Work focused solely on gastrointestinal disorders without neuroimmune or  endocrine relevance.  ‚Äì   Narrative reviews lacking mechanistic synthesis.  ‚Äì   Studies with insufficient methodological detail.  Study selection  The search yielded 1,263 records. After removing duplicates and screening titles  and abstracts, 247 studies underwent full - text review. A total of 110 articles met\n\ninclusion criteria and were incorporated into this review, covering clinical  research, controlled animal studies, microbiota transplantation models, multi -  omics analyses, and interventional trials.  3.   The Gut - Microbiota - Brain Axis and Its Relationship with Sleep  The gut microbiota (GM) plays a crucial role in regulating various biological functions,  including brain function, behavior, and sleep. Through the Gut - Microbiota - Brain Axis  (GMBA), bidirectional communication occurs via neural, endocrine, and immune  pathw ays. Key components such as the enteric nervous system (ENS) and vagus nerve  mediate this interaction, allowing microbiota alterations to influence cognition,  behavior, and sleep patterns. Conversely, abnormal sleep patterns reciprocally impact  GM   composit ion   and   function.   Evidence   suggests   that   microbiota - targeting  interventions,   including   probiotics   and   fecal   microbiota   transplantation,   hold  therapeutic potential for enhancing brain function and improving sleep quality   [14,15] .  Dysbiosis of gut microbiota disrupts these processes by altering intestinal metabolism,  leading to significant changes in neurotransmission - related metabolites, such as  serotonin and vitamin B6. For instance, studies in antibiotic - induced microbiota -  deplet ed (AIMD) mice revealed disrupted sleep architecture, including reduced time  spent in non - rapid eye movement sleep (NREMS) during the light phase, increased time  in NREMS and rapid eye movement sleep (REMS) during the dark phase, frequent  transitions from   NREMS to REMS, and reduced theta power density during REMS   [16] .  Intestinal dysbiosis disrupts the bidirectional relationship between GM and the central  nervous   system   (CNS),   impacting   host   physiology   through   abnormal   microbial  metabolites and altered signaling pathways. This disruption is increasingly recognized  as a s usceptibility factor for neurodevelopmental and neurological disorders, including  Alzheimer's disease, Parkinson's disease, multiple sclerosis, and autism spectrum  disorder   [17] .   Additionally, the gut microbiota influences neurotransmitter activity,  shaping both gastrointestinal and neurological processes through its metabolic  interactions   [18] .  3.1   Metabolites and neurotransmitter s  GM - diet interactions influence nutrient sensing and signaling along the GMBA,  mediated by metabolites such as short - chain fatty acids (SCFAs), secondary bile  acids, and amino acid - derived compounds. These metabolites activate gut -  endocrine or neural pathwa ys or enter systemic circulation to reach the brain,  shaping communication between the gut and brain. Feeding time and dietary  composition are key factors driving gut microbiota structure and function, with\n\nunhealthy   diets   or   irregular   feeding   patterns   potentially   altering   microbial  metabolite production and nutrient availability   [19] .   Alterations in amino acid  metabolism, such as changes in glutamate and tryptophan levels, can disrupt  neural signaling and contribute to disorders like Parkinson‚Äôs disease (PD). These  disturbances in metabolic pathways are increasingly recognized as potent ial  contributors to non - motor symptoms of PD, including sleep disorders, highlighting  the   importance   of   microbiota   metabolites   in   maintaining   normal  neurophysiological functions   [20] .  3 .1.1 Short - chain fatty acids (SCFA s )  SCFAs, including acetate ,   propionate   and   butyrate   influence emotional state s   and  cognition through the gut - brain axis. Reduced levels of acetate and propionate were  negatively   correlated   with   depressive   symptoms,   as   measured   by   Beck's  Depression   Inventory,   suggesting   their   role   in   modulating   depression   and  highlighting their impor tance in the gut microbiota's impact on mental health   [21] .  Furthermore, short sleep duration in insomnia has been associated with increased  concentrations of SCFAs, in feces, likely due to decreased uptake by gut epithelial  cells, which may compromise their essential role in gut cell function and brain  signaling v ia pathways like serotonin   [22] .   Recent findings show that SCFAs  supplementation in mice undergoing psychosocial stress alleviates anhedonia,  heightened stress responsiveness, and stress - induced intestinal permeability .  These results provide novel insights into how gut microbiota influences brain  homeostasis,   behavior,   and   host   metabolism,   supporting   the   potential  development of microbiota - targeted therapies for stress - related disorders   [23] .  3 .1.2 Serotonin  The sleep ‚Äì wake cycle is a complex, multifaceted process influenced by various  neurotransmitters such as acetylcholine, norepinephrine, serotonin, histamine,  dopamine, orexin, and   Œ≥ - aminobutyric acid   ( GABA ) , all of which can be modulated  by   different   nutrients   that   participate   in   their   metabolic   pathways   [24,25] .  Tryptophan, an essential amino acid and precursor of serotonin, is crucial in the  microbiota - gut - brain axis. Serotonin regulates emotions, sleep, appetite, and gut  motility,   while   tryptophan metabolites,   including those   from the   kynurenine  pathway,   influen ce   neural   activity   and   inflammation.   Gut   microbes   affect  tryptophan metabolism both directly and indirectly, altering behavior and cognition,  making the gut microbiome a potential therapeutic target for neurological and  psychiatric disorders   [26] .   Beyond its neurological role, tryptophan also impacts  sleep through its conversion to melatonin, a key regulator of the sleep - wake cycle.\n\nDiets rich in tryptophan - containing foods, such as fruits, vegetables, and legumes,  have been associated with improved sleep quality, emphasizing the intricate link  between nutrition, microbiota, and sleep health   [27] .   A study demonstrated that  depleting the gut microbiota through antibiotic treatment disrupted sleep/wake  regulation in mice, leading to altered neurotransmitter metabolism, including  reduced serotonin and vitamin B6 levels. This imbalance was associated wi th  changes in sleep architecture, such as reduced non - REM sleep during the light  phase and increased REM sleep episodes, highlighting the influence of the gut  microbiota on sleep regulation   [16] .  3 .1.3 GABA  The main neurons involved in the regulation of arousal and sleep are glutamate and  GABA neurons, which   are in   the reticular core of the brain and, through both local  and distant projections and interactions, control cortical activity and behavior  during wakefulness and sleep states   [28] .   In this context, the gut microbiota plays a  crucial role, as highlighted by a study showing that   Bacteroides ,   Parabacteroides ,  and   Escherichia   species actively express GABA - producing pathways. Genome -  based metabolic modeling and transcriptome analysis of human stool samples  revealed that these bacteria are key contributors to GABA production in the gut,  which may influence sleep regulation throu gh their impact on the gut - brain   axis  [29] .   Another study reveals that intestinal stem cells (ISCs) are involved in sleep -  regulated intestinal homeostasis and function, with gut microbiota dysbiosis and  the GABA pathway playing key roles in this gut - brain communication. Antibiotic  treatment reduced   stem cell division and increased sleep time, suggesting the  involvement of   microbiota , while GABA activation rescued both sleep behavior and  intestinal phenotypes, highlighting potential therapeutic targets for gut disorders  linked to sleep deprivation   [30] .  3 .1.4 Acetylcholine  Acetylcholine, a neurotransmitter, plays a role in regulating REM sleep through  cholinergic neurons in the brainstem and basal forebrain, which project to wide  areas of the cerebral cortex and interact with other neuromodulatory systems to  produce the slee p - wake cycle and different sleep stages   [31] .   Choline, a precursor  of acetylcholine, plays a vital role in brain function and is linked to gut microbiota,  which influences digestion, metabolism, and overall health. Choline metabolism,  partly regulated by gut bacteria, is essential for neurotransmitter   synthesis and may  impact neurodegenerative conditions like Alzheimer's disease   [32] .  3 .1.5 Dopamine\n\nDopamine plays a crucial role in regulating the sleep - wake cycle by promoting  wakefulness, with elevated levels often disrupting sleep. It also influences the  circadian   clock,   including   the   entrainment   of   the   master   clock   in   the  suprachiasmatic nuclei (SCN ), while its own signaling is regulated by circadian  rhythms   [33] .   Moreover, dopamine levels are significantly influenced by the gut  microbiota through the microbiota - gut - brain axis. This interaction is mediated by  pathways involving the vagus nerve, immune system, and microbial metabolites.  Key   bacterial   genera,   such   as   Prevotella,   Bacteroides,   Lactobacillus,  Bifidobacterium, Clostridium, Enterococcus , and   Ruminococcus , contribute to  dopamine metabolism, underscoring the microbiota's essential role in maintaining  optimal dopamine levels   [34] .  3 .1.6 Histamine  Histamine plays a critical role in regulating the sleep - wake cycle, with the histamine  H3 receptor (H3R) being of particular interest due to its unique function as a pre -  and postsynaptic receptor that controls the synthesis and release of histamine and  ot her neurotransmitters in the brain. Preclinical studies have demonstrated that  H3R antagonists/inverse agonists hold promise in modulating sleep - wake cycle  disorders, alongside cognitive impairment and mood regulation   [35] .   Specific  bacterial species, such as   Escherichia coli   and   Morganella morganii , have been  identified for their ability to synthesize and release histamine   [36,37] .  3 .1.7   Orexin  Orexin play s   a pivotal role in regulating the sleep - wake cycle, with orexin mimetics  enhancing wakefulness during the day and orexin receptor antagonists promoting  sleep at night, offering promising therapeutic avenues for improving memory,  cognition,   and   daytime   perf ormance   [38] .   The   hypocretin/orexin   system,  comprising neuropeptides orexin - A and orexin - B, plays a critical role in sleep - wake  regulation,   with   HCRTR2/OX2R   specifically   linked   to   sleep - wake   control.  Therapeutic   compounds   targeting   these   receptors,   such   as   FDA - approved  antagonists for insomnia, highlight the potential of orexin - based therapies in  addressing sleep disorders and advancing our understanding of hypocretin/orexin  neurobiology   [39] .   Recent studies suggest that the gut microbiota, through the  production of acetate and other   SCFAs , may influence the orexinergic system by  modulating   orexin - A ( OX - A )   neuronal activity   [40]   This connection underscores the  interplay between gut health, energy homeostasis, and sleep - wake regulation,  while also pointing to the broader role of   OX - A   in the gut - brain axis, where it exerts  anti - inflammatory and gastroprotective effects. These findings offer novel insights\n\ninto the therapeutic potential of targeting the orexinergic system to address  inflammation, stress responses, and gastrointestinal disorders   [41] .  3 .1.8 Norepinephrine  The amplitude of Norepinephrine   ( NE )   oscillations is crucial for shaping sleep  micro - architecture related to memory performance: prolonged descent of NE  promotes spindle - enriched intermediate state and REM sleep but also associates  with awakenings, whereas shorter NE descents uphold NREM sle ep and micro -  arousals. Thus, the NE oscillatory amplitude may be a target for improving sleep in  sleep disorders   [42] .   Under stress, the enteric nervous system's sympathetic nerve  endings synthesize and secrete NE, which directly affects the gut microbiota and,  in turn, influences the host's physiological state. Exposure to NE increased  microbial diversity in the cecum, wi th shifts in bacterial abundance correlating with  NE levels used to maintain blood pressure   [43] .   A study suggests that   NE   can  modulate   microbial   composition and metabolite production. It was demonstrated  that exposure to NE increased the diversity of the bacterial community, increasing  the abundance of facultative pathogens such as   Hathewaya, Clostridium , and  Streptococcus , while reducing beneficial genera like   Lactobacillus . This could  increase pathogen colonization and infection   [44] .  The influence of the gut microbiota on sleep can be observed in how certain bacterial  species and the metabolites they produce affect key neurotransmitters involved in  sleep regulation, such as serotonin, GABA, and dopamine, among others. The following  T able   1 and   T able 2   emphasize some of these bacteria and their effects on sleep quality .  Table 1:   Gut Microbiota   and Their   Positive Effects on Sleep  Gut Microbiota   Effect on Sleep Disorders   References  Lactobacillus   Decreased   abundance   associated   with   ASD,   reducing   the  production of SCFAs like propionic acid.   Supplementation of  GABA - producing   Lactobacillus   increased plasma GABA levels  and   reduced   stress   hormones,   reversing   sleep   deprivation -  induced gut dysbiosis and stress responses.  [45]   [46]  Lactobacillus  plantarum JYLP - 326  Administration helped to restore disturbed gut microbiota and  reduce anxiety, depression, and insomnia symptoms in test -  anxious students.  [47]  Lactobacillus  plantarum PS128  Reduced depressive symptoms, fatigue, and brainwave activity,  improving sleep quality during deep sleep stages in insomniac  participants.  [48]  Lactobacillus   reuteri  NK33  Promotes better sleep quality and reduces stress and anxiety as  part of the NVP - 1704 formulation.  [49]  Lactobacillus   brevis  DL1 - 11  GABA - fermented milk with   Lactobacillus brevis   DL1 - 11 improved  sleep quality and reduced anxiety, associated with increased  SCFAs and altered gut microbiota .  [50]\n\nLactobacillus  fermentum PS150  Improved   NREM   sleep   length,   reduced   sleep   latency,   and  mitigated fragmented sleep during the first night effect.  [51]  Lactiplantibacillus  plantarum P72  Reduced sleep latency and enhanced sleep duration. Alleviated  insomnia - like behaviors by upregulating GABA and serotonin  systems.  [52]  Bifidobacterium   Increased abundance in participants after consuming a dairy -  based product, which possibly contributed to sleep improvement.  [12]  Bifidobacterium  longum  Negative association with   obstructive sleep apnea ( OSA ) , possibly  lowering the risk of developing OSA.  [53]  Bifidobacterium  adolescentis   NK98  Increased   abundance   linked   to   improved   sleep   quality   and  reduced   depressive   symptoms   after   probiotic   NVP - 1704  treatment.  [49]  Anaerostipes   Inverse association with OSA, suggesting reduced abundance in  individuals with OSA.  [53]  Eubacterium  (xylanophilum group)  Shown to have a protective association against OSA, lowering its  risk.  [54]  Akkermansia  muciniphila  Reduced abundance after sleep deprivation; supplementation  alleviated cognitive dysfunction, prevented hippocampal synaptic  loss, and increased serum SCFAs levels.   Abundance altered by  chronic   intermittent   hypoxia   (CIH)   and   chronic   sleep  fragmentation (CSF ).  [55]   ,   [56]  Parasutterella   Lower levels associated with ASD, which may negatively impact  the production of metabolites important for circadian rhythm  regulation and stress response.  [45]  Muribaculum   Decreased levels in ASD, potentially contributing to disruptions in  gut homeostasis and systemic inflammation that affect sleep  quality.  [45]  Monoglobus   Reduced abundance linked to gut dysbiosis in ASD, possibly  impairing gut - brain communication and contributing to circadian  rhythm misalignment.  [45]  Eubacterium  xylanophilum  Negative   association   with   Obstructive   Sleep   Apnea   (OSA),  potentially reducing the risk of OSA.  [53]  Enterococcus  faecium BS5  Produces GABA, a neurotransmitter with tranquilizing effects,  potentially improving anxiety and sleep quality.  [57]  Parabacteroides  merdae  Negative association with OSA, indicating a potential protective  effect against OSA.  [53]  Bacteroidetes   Decreased   abundance   after   PSD,   with   a   shift   in   the  Firmicutes:Bacteroidetes   ratio linked to metabolic perturbations.  [58]  Faecalibacterium  prausnitzii  Strong association with sleep quality scores, particularly due to its  involvement in metabolic pathways such as L - arginine and L -  tryptophan biosynthesis.  [59]  Lachnospiraceae_NK  4A136  Decreased in sleep - deprived mice, linked to reduced butyrate  levels and worsened memory and inflammatory responses.  [13]  Lachnospiraceae_NK  4A136  Increased   abundance   associated   with   higher   SCFA   levels,  supporting neurotransmitter function and better sleep patterns.  [60]  Table 2: Gut Microbiota and Their Potential Negative Effects on Sleep  Gut Microbiota   Effect on Sleep Disorders   References\n\nCandidatus_Arthromi  tus  Increased abundance associated with acute sleep deprivation  (ASD), potentially contributing to systemic inflammation and  circadian rhythm disruptions.  [45]  Enterobacter   Increased levels linked to ASD, possibly exacerbating gut  inflammation and barrier dysfunction, which can amplify sleep  disturbances.  [45]  Bacteroides   Played a role in altering microbiota network structure during  circadian rhythm disturbances, affecting gut   functionality .  S ignature bacteria for acute insomnia patients, differing from  healthy   controls.   Found   in   paradoxical   insomnia   (P - IN)  patients, distinguishing their microbiota profile, potentially  linked   to   sleep   disturbances.   Positively   correlated   with  Pittsburgh Sleep Quality Index (PSQI) scores, indicating poorer  sleep quality.  [61]   ,   [62]   ,  [63]   ,   [64]  Firmicutes   Increased   abundance   following   partial   sleep   deprivation  (PSD), associated with metabolic disturbances like insulin  resistance.   Increased abundance in pregnant rats subjected to  maternal   sleep   deprivation   ( MSD ) ,   leading   to   microbial  dysbiosis in offspring and neuroinflammation.  [58]   ,   [65]  Lachnospira   Signature bacteria for distinguishing acute insomnia patients   [62]  Blautia   Signature bacteria for chronic insomnia patients   [62]  Aeromonas   Increased in sleep - deprived mice, associated with elevated  LPS levels, hippocampal inflammation, and spatial memory  impairment.  [13]  Ruminococcus_1   Positively correlated with proinflammatory cytokines IL - 1 Œ≤   and  TNF - Œ±   in the offspring of MSD, linked to neuroinflammation.  [65]  Ruminococcaceae_U  CG - 005  Positively correlated with IL - 1 Œ≤   and TNF - Œ±   in MSD offspring,  contributing to neuroinflammation in the brain.  [65]  Ruminococcaceae_U  CG - 002  Mediates the positive association between chronic insomnia  and cardiometabolic diseases (CMD), possibly through the gut  microbiota - bile acid axis.  [66]  Ruminococcaceae_  UCG - 003  Associated with chronic insomnia and CMD, with bile acids like  isolithocholic   acid   and   nor   cholic   acid   mediating   this  relationship.  [66]  Coriobacteriaceae   Associated with objective insomnia (O - IN), potentially linked  to the onset of insomnia.  [63]  Erysipelotrichaceae   Found in O - IN patients, possibly contributing to the microbiota  imbalance seen in insomnia.  [63]  Clostridium   Identified in O - IN patients, related to sleep disturbances and  microbiota alterations in insomnia.   Associated with insomnia  through inflammatory pathways.  [63,67]   ,   [68]  Pediococcus   Present in O - IN patients, contributing to distinct gut microbiota  profiles in insomnia.  [63]  Staphylococcus   Present in P - IN patients, contributing to unique microbiota  profiles in this insomnia subtype.  [63]  Carnobacterium   Present in P - IN patients, potentially associated with altered  sleep - wake regulation.  [63]  Pseudomonas   Linked   to   P - IN,   contributing   to   microbiota   dysbiosis   in  insomnia.  [63]  Odoribacter   A key discriminant in P - IN patients, playing a role in gut - brain  axis dysregulation and sleep disturbance.  [63]  Streptococcus   Found in higher levels in insomniacs, linked to changes in  metabolism and immune responses.  [69]\n\nLactobacillus  crispatus  Elevated in insomnia patients; associated with disruptions in  glycerophospholipid and glutamate metabolism pathways.  [69]  Prevotella amnii,  Prevotella buccalis,  Prevotella  timonensis,  Prevotella colorans  They contribute to inflammation by correlating with elevated  levels of TNF - Œ±   and IL - 1 Œ≤  [69]  Ruminococcaceae  UCG - 009  Positively associated with an increased risk OSA.   [54]  Collinsella   Enriched in REM sleep behavior disorder (RBD) and first -  degree   relatives   of   RBD   (RBD - FDR),   associated   with  inflammation.  [70]  Flavonifractor   Changes in abundance linked to Narcolepsy   T ype 1 (NT1),  indicating potential gut dysbiosis in narcolepsy.  [71]  Sutterella   Positively correlated with daytime dysfunction and may be a  biomarker for poor sleep quality in MA users  [72]  3 .2 Bacteria with Positive Effects on Sleep:  Several bacteria have been linked to improved sleep quality or a reduction in sleep  disturbances, as summarized in   Table 1 . Bifidobacterium longum, Bifidobacterium  adolescentis NK98,   and   Lactobacillus reuteri NK33   are notable for their association  with improved sleep quality, likely through mechanisms involving neurotransmitter  regulation, such as increased GABA levels and the reduction of stress hormones  [45,48,49] . These bacteria, especially when supplemented through probiotics, seem to  restore balance in the gut microbiota, thereby alleviating symptoms of insomnia,  anxiety, and depression   [47,48] .  Furthermore,   Faecalibacterium prausnitzii , a species linked to metabolic pathways like  L - arginine and L - tryptophan biosynthesis, shows a strong positive association with  sleep quality   [59] .   Lactobacillus plantarum   strains, such as P72 and PS128, also  contribute to sleep improvement by modulating GABAergic and serotonergic systems  [50,52] .   These findings suggest that increasing the abundance of these beneficial  bacteria might be a promising therapeutic strategy for improving sleep quality in  individuals with sleep disorders.  Several bacteria have been linked to improved sleep quality or a reduction in sleep  disturbances .   Bifidobacterium   longum,   Bifidobacterium   adolescentis   NK98,   and  Lactobacillus reuteri NK33   are notable for their association with improved sleep quality,  likely through mechanisms involving neurotransmitter regulation, such as increased  GABA levels and the reduction of stress hormones   [45,48,49] . These bacteria,  especially when supplemented through probiotics, seem to restore balance in the gut  microbiota, thereby alleviating symptoms of insomnia, anxiety, and depression   [47,48] .\n\nFurthermore,   Faecalibacterium prausnitzii , a species linked to metabolic pathways like  L - arginine and L - tryptophan biosynthesis, shows a strong positive association with  sleep quality   [59] .   Lactobacillus plantarum   strains, such as P72 and PS128, also  contribute to sleep improvement by modulating GABAergic and serotonergic systems  [50,52] .   These findings suggest that increasing the abundance of these beneficial  bacteria might be a promising therapeutic strategy for improving sleep quality in  individuals with sleep disorders.  3 .3   Bacteria with Negative Effects on Sleep:  In contrast, certain bacteria appear to have a detrimental impact on sleep, particularly  in conditions like   sleep deprivation and insomnia,   as summarized in   Table   2 .  Aeromonas , for instance,   are   found in higher levels in sleep - deprived mice and   are  associated with increased inflammatory markers like LPS, contributing to hippocampal  inflammation and memory impairment   [13] . Similarly,   Collinsella   and   Staphylococcus ,  which are enriched in conditions like REM sleep behavior disorder (RBD) and insomnia,  are linked to systemic inflammation and disrupted sleep patterns   [70,71] . These  bacteria   may impair   the   gut - brain   axis,   leading to   sleep disturbances   through  neuroinflammatory pathways.  3 . 4   Bacteria Linked to Circadian Rhythm and Metabolic Disruptions:  Certain gut bacteria also play a role in the regulation of circadian rhythms and  metabolic processes, both of which are critical for maintaining healthy sleep patterns,  as summarized in   Table 2 . For instance,   Bacteroides , a signature bacterium found in  patients with paradoxical insomnia (P - IN), is positively correlated with poor sleep  quality and disrupted circadian rhythms   [61,62] . In addition,   Ruminococcaceae  species, including   Ruminococcaceae UCG - 002   and   Ruminococcaceae UCG - 003 , are  associated with chronic insomnia and cardiometabolic diseases, suggesting a link  between gut microbiota, sleep disorders, and metabolic health   [54,66] .  4.   S leep - immune - microbiota axis  4 .1 Introduction to Sleep - Immune - Microbiota Axis  Dynamic interactions between gut microbiota and a host‚Äôs innate and adaptive  immune systems are essential in maintaining intestinal homeostasis and inhibiting  inflammation. Gut microbiota metabolizes proteins and complex carbohydrates,  synthesizes vitamins , and produces numerous metabolic products that mediate cross -  talk between the gut epithelium and immune cells   [73] .   The composition of the  intestinal microbiome plays a pivotal role in maintaining the stability of the intestinal  barrier. Dysbiosis contributes to the disruption of this barrier, commonly referred to as\n\n\"leaky gut\"   a condition characterized by increased intestinal permeability .   This  condition facilitates the translocation of bacterial metabolites and endotoxins, such as  LPS into the bloodstream, triggering systemic inflammation and   facilitating   the  development of metabolic and autoimmune diseases   [74] .   Figure 1 illustrates the  integrated bidirectional interactions between sleep, the gut microbiota, the immune  system, and the endocrine system that frame the conceptual basis of this section.  Comprehending these mechanisms highlights potential therapeutic strategies, such as  the use of probiotics, prebiotics, or dietary interventions, to restore gut barrier integrity  and mitigate sleep disturbances . This section explores the intricate relationships  between sleep, immunity, and microbiota, offering insights into their combined role in  maintaining systemic health.  4 .2 Disbiosis, Inflammation, and Barrier Integrity  Restoring gut microbial balance through fecal microbiota transplantation (FMT) has  been shown to reduce LPS levels in the colon, serum, and other tissues, thereby  suppressing the TLR4/MyD88/NF - Œ∫ B signaling pathway and its downstream pro -  inflammatory produc ts   [75] .   This inflammation compromises blood - brain barrier (BBB)  integrity, facilitating the translocation of inflammatory mediators and metabolites into  the brain. These processes contribute to neuroinflammation, neurodegeneration, and  brain aging   [76] .  Several gut microbiota s , especially   Firmicutes   and   Bacteroidetes ,   have   demonstrated  significant effects on mental health. Dysbiosis involving these groups is associated  with mental disorders such as anxiety, depression, and chronic intestinal inflammation  [77,78] .   An increase in opportunistic pathogens, such as   Aeromonas , destabilizes  intestinal tight junction proteins, allowing microorganisms or microbial components  like LPS to enter systemic circulation. This process triggers systemic inflammation,  with LPS reaching the brain and binding to Toll - like receptor 4 (TLR4) o n microglia,  inducing the synthesis and secretion of pro - inflammatory cytokines   [13] .   Conversely,  beneficial bacteria such as   Lactobacillus, Muribaculum , and   Parasutterella   have been  shown to enhance the integrity of both intestinal and brain barriers   [45] .  4 .3 Impact of Maternal Sleep Deprivation (MSD) on Gut and Immune Health  Maternal sleep deprivation (MSD) alters gut microbiota and immune responses in  offspring. Studies using quantitative real - time polymerase chain reaction (qRT - PCR)  and   enzyme - linked   immunosorbent   assay   (ELISA)   revealed   significantly   higher  expression levels   of pro - inflammatory cytokines, such as interleukin 1 Œ≤ ( IL - 1 Œ≤)   and  tumor necrosis factor   Œ± ( TNF - Œ±),   in offspring of MSD - exposed mothers compared to\n\ncontrols. Notably, Ruminococcus_1 and Ruminococcaceae_UCG - 005 were positively  correlated with these cytokines, suggesting a role in MSD - related neuroinflammation  [65] .  4 .4 Sleep, Microbiota, and Immune Dysregulation  Studies on insomnia have demonstrated significant differences in gut microbiota  composition   between   patients   and   healthy   controls.   Insomniacs   exhibited   an  increased relative abundance   of   Lactobacillus ,   Streptococcus , and   Lactobacillus  crispatus . These changes were associated with elevated IL - 1 Œ≤   levels and reduced TNF -  Œ±   levels. Specific bacterial shifts, such as increases in   Prevotella   species, were linked  to altered immune markers, highlighting the role of microbial metabolites in insomnia  pathophysiology   [69] .  Further research into the interplay between sleep, immune function, and microbiota  revealed   that   immunization   with   heat - killed   Mycobacterium   vaccae   (MV),   an  environmental   bacterium   with   immunoregulatory   properties,   mitigates   systemic  inflammation and behavioral changes induced by sleep disruption. MV immunization  prevented   alterations   in   non - REM   (NREM)   and   REM   sleep,   stress - induced  hyperlocomotion, a nd memory deficits, underscoring the therapeutic potential of  microbiota - immune interactions in modulating sl eep deprivation   [79] .  4 .5 Sleep Disturbance, Immune Activation, and Disease Risk  Sleep   disturbances   contribute   to   inflammation - mediated   diseases,   including  depression, through the activation of the innate immune system and an increased risk  of infections. Sleep architecture involves dynamic shifts between T helper 1 (Th1) -  mediated infl ammation during early sleep and T helper 2 (Th2) - mediated responses in  late sleep   [80] .   A study utilizing mass cytometry and single - cell RNA sequencing  revealed that sleep deprivation increases T and plasma cell frequencies while  upregulating autoimmune - related pathways in CD4+ T and B cells. Sleep deprivation  also reduces cytotoxic cell acti vity, increasing susceptibility to infections and tumor  development, while promoting myeloid inflammation and cellular senescence   [81] .  Severe sleep deprivation in mouse models has been linked to significant inflammation  and high mortality. Specifically, increased prostaglandin D2 (PGD2) levels in the brain  were   shown   to   drive   peripheral   immune   pathologies,   including   neutrophil  accumulatio n and cytokine - storm - like syndromes. Disrupting the PGD2/DP1 axis  significantly   reduced   these   inflammatory   effects,   suggesting   it   as   a   potential  therapeutic target   [82] .\n\nObstructive   sleep apnea (OSA) disrupts   systemic immune   function.   Single - cell  transcriptomics (scRNA - seq) analysis revealed OSA - induced transcriptional changes  in peripheral blood mononuclear cells (PBMCs), with severity - dependent alterations in  several   imm une   cell   lineages.   A   molecular   signature   of   32   genes   effectively  distinguished OSA patients from controls, highlighting deregulation in systemic  immunity   [83] .   Data from the National Health and Nutrition Examination Survey  (NHANES) also revealed positive associations between sleep disorders and the  systemic immune - inflammation index   (SII),   with higher SII levels   in individuals  experiencing sleep problems   [84] .  Sleep loss induces significant changes in immune cell composition and function,  particularly in effector CD4+ T cells and myeloid cells. This is mediated by upregulation  of Granulocyte - Macrophage Colony - Stimulating Factor (GM - CSF), a cytokine that  drives t he IL - 23/Th17/GM - CSF feedback mechanism, exacerbating inflammatory  responses and autoimmune conditions such as experimental autoimmune uveitis  (EAU). Targeting GM - CSF offers a promising therapeutic avenue for managing sleep -  related inflammatory diseases   [85] .  5   The Sleep - Endocrine - Microbiota Axis: Interactions and Implications for Health  5 .1 Sleep and the Endocrine System: An Intimate Relationship  Sleep and the endocrine system share a bidirectional relationship, where hormonal  regulation influences sleep quality, and sleep, in turn, modulates endocrine function.  Key hormones such as melatonin, cortisol, leptin, ghrelin, and growth hormone (GH)  play   pivotal roles in this interplay   [86 ‚Äì 89] .  Melatonin, produced by the pineal gland, is a central regulator of the circadian rhythm.  Its secretion is stimulated by darkness and inhibited by light, making it essential for  synchronizing sleep - wake cycles   [86] . Beyond its role in sleep regulation, melatonin  exhibits antioxidant and anti - inflammatory properties, which contribute to cellular  protection and the mitigation of oxidative stress   [90] . Disruptions in melatonin  production, such as those caused by exposure to artificial light at night, have been  linked to sleep disorders and metabolic dysregulation   [91] .  Cortisol, a glucocorticoid released by the adrenal glands, follows a diurnal rhythm with  peak levels in the early morning and a gradual decline throughout the day. Sleep  disturbances, such as insomnia or sleep apnea, can dysregulate cortisol secretion,  lea ding to hyperactivation of the hypothalamic - pituitary - adrenal (HPA) axis. This  dysregulation is associated with increased stress, anxiety, and a higher risk of\n\nmetabolic and cardiovascular diseases   [92] . For instance, sleep deprivation has been  shown to elevate nighttime cortisol levels, exacerbating stress - related disorders   [93] .  Studies have shown that changes in the ghrelin/leptin ratio are significantly correlated  with alterations in subjective hunger during chronic circadian disruption and sleep  restriction   [94] .   Growth hormone (GH) is primarily secreted during slow - wave sleep  (SWS), and its release is regulated by growth hormone - releasing hormone (GHRH) and  somatostatin. GH stimulates the production of insulin - like growth factor 1 (IGF - 1),  which plays a key role i n tissue growth, neuroprotection, and metabolic regulation.  Sleep deprivation significantly reduces GH and IGF - 1 levels, affecting metabolic  homeostasis and cognitive function   [89] .  5 .2 The Role of the Endocrine System in the Microbiota - Sleep Connection  The gut microbiota, through its influence on the intestinal environment and systemic  pathways, is recognized as a functional endocrine organ. It interacts with various  hormones, including estrogen, androgens, and insulin, playing a critical role in  endocri ne regulation   [95] .   R ecent studies have shown that gut dysbiosis can activate  the hypothalamic - pituitary - adrenal (HPA) axis, leading to a hormonal imbalance that  impacts sleep patterns. This activation of the HPA axis can result in elevated cortisol  levels, a stress hormone th at, when excessive, can disrupt sleep architecture and  contribute to sleep disorders   [96] .  Additionally, gut microbiota influences the production of serotonin, a neurotransmitter  that serves as a precursor to melatonin, the primary hormone regulating the sleep -  wake cycle. An imbalance in the microbiota can alter serotonin   [97] .  The relationship between the microbiota and the endocrine system is also evident in  glucose metabolism regulation. A study observed that reduced REM sleep duration is  associated   with   an   unfavorable   glycemic   profile   and   alterations   in   microbiota  composition , suggesting an interaction between sleep, microbiota, and endocrine  regulation of energy metabolism   [98] .  Moreover, interventions that modulate the gut microbiota, such as the use of probiotics  and prebiotics, have shown promising effects in improving sleep disorders. These  interventions may influence the endocrine system by restoring microbiota balance,  norma lizing the production of hormones and neurotransmitters involved in sleep  regulation   [99] .  In summary, the endocrine system acts as a key mediator in the bidirectional  connection between gut microbiota and sleep. Alterations in the microbiota can trigger  endocrine responses that affect sleep quality, while sleep disturbances can influence\n\nmicrobial composition and endocrine function. Understanding this interaction is  essential for developing therapeutic strategies aimed at improving sleep health through  microbiota and endocrine system modulation.  Figure 1 .   Integrated bidirectional interactions between sleep, gut microbiota, the  immune system, and the endocrine system.  Sleep loss reduces microbial diversity, increases intestinal permeability, lowers T/NK  cell activity, elevates cortisol, and disrupts circadian rhythms. Gut dysbiosis alters  SCFA   and   serotonin   production,   activates   TLR4 ‚Äì NF Œ∫ B   signaling,   and   promotes  inflammation. Immune activation (IL - 1 Œ≤ , TNF - Œ± ) disrupts sleep architecture, damages  the   gut   barrier,   and   stimulates   HPA   axis   activity.   Endocrine   dysregulation   is  characterized   by increased cortisol and reduced   melatonin. This   further impairs sleep  and modifies gut microbial composition. Together, these systems form a tightly  interconnected axis in which disturbances in one component propagate through the  others.  6 .0   Emerging Therapies Targeting the Sleep - Microbiota Axis  The sleep - microbiota axis has emerged as a promising frontier in the development of  novel therapeutic strategies. The intricate bidirectional relationship between sleep, gut\n\nmicrobiota, and the immune system offers multiple intervention points to enhance  sleep quality and reduce systemic inflammation. Probiotic interventions, particularly  with strains such as   Lactobacillus   and   Bifidobacterium , have demonstrated potential  in   improving   sleep   by   modulating   the   gut - brain   axis,   altering   neurotransmitter  synthesis, and reducing inflammatory markers associated with sleep disorders   [100] .  In parallel, emerging nutraceutical approaches, such as compositions including   Œ≤ -  glucan, prebiotics, and the herbal extract silymarin, have shown promise. A 90 - day pilot  study demonstrated that these formulations improved sleep quality, mood, and life  qual ity   while   reducing   inflammatory   markers   and   enhancing   metabolic   health,  suggesting their potential as integrative therapies targeting the sleep - microbiota axis  [101] .   As   illustrated   in   Figure   2,   therapeutic   interventions   targeting   the   sleep -  microbiota   axis   encompass   probiotics,   fecal   microbiota   transplantation,  nutraceuticals, neuropeptides, chrononutrition, and acupuncture, all of which act on  microbiota composition, circadian regulation, neurochemical balance, and microbe -  host communication.  Emerging therapeutic approaches continue to explore the potential of fecal microbiota  transplantation (FMT) and its advanced variant, washed microbiota transplantation  (WMT),   as   innovative   interventions   to   restore   gut   integrity   and   mitigate  neuroinflammati on. Notably, WMT has shown promising results in improving sleep  quality among patients with inflammatory bowel disease (IBD)   [102] .   Moreover, a recent  study demonstrated that WMT significantly enhances sleep quality and life quality in  patients with sleep disorders by regulating gut microbiota, with improved outcomes  observed following multiple treatment courses. These findings highlig ht WMT's safety  and efficacy, further supporting its role as a novel therapeutic option for targeting the  sleep - microbiota axis   [103] .  Furthermore, advancements in chronobiology have revealed that gut microbiota  exhibits   a circadian rhythm closely synchronized   with host sleep - wake   cycles.  Dysbiosis disrupts this rhythm, negatively impacting sleep quality. Therapies targeting  the restorati on of microbiota circadian patterns are gaining attention as a strategy for  managing sleep disorders   [104] .   For instance, chrononutrition, or the timing of food  intake in alignment with circadian rhythms, has shown potential to enhance microbial  rhythmicity and improve sleep outcomes. Chrononutrition, which includes practices  such as diurnal fasting, meal timing , and avoiding late eating, has been linked to  improvements   in   sleep   quality,   particularly   through   its   influence   on   metabolic  regulation and circadian alignment   [105] .  Microbial metabolites such as short - chain fatty acids (SCFAs) are increasingly being  investigated for their roles in sleep regulation, particularly in the context of insomnia.\n\nSCFAs, including acetate, butyrate, and propionate, are key byproducts of fiber  fermentation in the gut and influence gut - brain communication pathways associated  with sleep continuity. Evidence from studies in older adults with insomnia symptoms  suggests t hat higher concentrations of SCFAs are linked to poorer sleep efficiency and  longer sleep onset latency, particularly in individuals with the short sleep duration  phenotype, which is considered a more biologically severe form of insomnia   [106] .  These findings highlight the potential of SCFAs not only as biomarkers of sleep  disorders but also as attractive targets for future therapeutic interventions .  Additionally, the use of neuropeptides, such as orexins ,   vasoactive intestinal peptide  (VIP)   and neuropeptide Y   represents another avenue for therapeutic intervention. These  molecules modulate both sleep cycles and gut microbiota interactions, offering a  potential dual - target strategy for improving sleep and gut health   is essential for  wakefulness   maintenance,   while   melanin - concentrating   hormone   and   galanin  promote REM sleep   [107] .   In parallel, neuropeptide S (NPS) has been shown to alleviate  anxiety - like behavior and sleep disturbances caused by paradoxical sleep deprivation  (PSD). NPS modulates wakefulness, suppresses paradoxical sleep, and alters EEG  theta activity. By activating   NPSR receptors in the amygdala, NPS counteracts the  effects of PSD without triggering rebound sleep, which further underscores its potential  as a therapeutic option for anxiety - related sleep disorders.   [108] .  Complementary therapies, such as acupuncture, have demonstrated potential as  nonpharmacological interventions for insomnia by modulating both neurotransmitter  levels and gut microbiota composition. In PCPA (p - chlorophenylalanine) - induced  insomnia models, a cupuncture was shown to reduce serum levels of dopamine, 5 -  hydroxytryptamine, and norepinephrine, while increasing melatonin levels in the pineal  gland. Furthermore, 16S rRNA sequencing revealed that both acupuncture and  hypnotic drugs produced similar imp rovements in gut microbiota composition,  suggesting shared mechanisms of action. Notably, acupuncture networks exhibited  greater   microbial   community   stability   and   fewer   side   effects   compared   to  pharmacological interventions, highlighting its potential as a   safer alternative for  targeting the sleep - microbiota axis   [109] .\n\nFigure 2. Emerging therapeutic strategies targeting the sleep ‚Äì microbiota axis.  Multiple   approaches   aim to restore   sleep quality by modulating gut   microbial  composition, neuroendocrine signaling, and circadian alignment. Probiotics, fecal and  washed microbiota transplantation (FMT/WMT), and microbial metabolites such as  SCFAs support   microbial balance and gut ‚Äì brain communication. Nutraceuticals,  including   silymarin,   prebiotics,   and   Œ≤ - glucan,   enhance   metabolic   and   anti -  inflammatory pathways relevant to sleep regulation. Neuropeptides such as orexin, VIP,  NPY, NPS, and galanin offer additional targets for modulating arousal and sleep  architecture. Chrononutrition strategies   diurnal fasting, meal timing, and circadian -  aligned eating   reinforce microbial and metabolic rhythms. Acupuncture serves as a  nonpharmacological therapy that influences neurotransmitters, increases melatonin,  and promotes a healthier microbiota. Together, these modali ties illustrate a multi -  modal therapeutic framework for improving sleep outcomes.  7 .0   Limitations of Current Literature  Despite major advances in understanding the sleep   microbiota axis, several limitations  constrain   the   current   body   of   evidence.  First, most studies rely on small sample sizes, reducing statistical power and  generalizability. For example, clinical work examining fecal metabolites and sleep\n\nquality uses modest cohorts that limit robust subgroup analyses and mechanistic  inference   [22] .  Second,   much   of   the   mechanistic   evidence   still   comes   from   animal   models,  particularly rodent studies on circadian disruption, sleep loss, and neuroinflammation.  While informative, these models cannot fully capture the complexity of human  microbiota, or the   variability in lifestyle, diet, and circadian behavior seen in real  populations   [45] .  Third, methodological heterogeneity across microbiome studies remains a major  limitation. Differences in sequencing platforms, microbial classification pipelines, and  metabolite profiling approaches create inconsistencies across reports, complicating  direc t   comparisons   between   findings.  Studies evaluating interventions such as nutraceutical compositions or acupuncture  further   illustrate   variability   in   outcome   measures,   microbial   endpoints,   and  inflammatory biomarkers, making it difficult to establish unifie d mechanistic pathways  [101,109] .  Although endocrine pathways are clearly affected by sleep loss, this component of the  axis remains understudied. Current evidence shows that sleep deprivation and  circadian disruption alter cortisol rhythms and HPA - axis activity, contributing to  metabolic   and inflammatory imbalance   [87] .   However, most studies assess cortisol or  sleep outcomes in isolation, without simultaneous measurement of immune or  microbiota variables   [92] .  As a result, very few human studies integrate endocrine, immune, and microbial  markers   within   a   unified   experimental   design.   Finally,   therapeutic   approaches  including chrononutrition, nutraceutical formulations, and microbiota transplantation  have shown promising but preliminary results with significant variability in dosage,  duration, and treatment adherence   [75,101,105]   These limitations highlight the need  for larger, standardized, multimodal studies to fully understand the bidirectional  interactions among sleep, microbiota, endocrine signaling, and immune networks.  8 .0   Future Directions for Research  Future   research   should   integrate   microbiota,   neurochemical   signaling,   immune  activity, and endocrine rhythms to define causal mechanisms of the sleep   microbiota  axis. Sleep - loss ‚Äì driven IL - 23/Th17/GM - CSF inflammation   [85]   together with dysbiosis  induced TLR4/NF - Œ∫ B activation   [75]   highlight the need for interventions targeting barrier  integrity and systemic inflammation. Mechanistic studies must clarify how sleep -  regulating neurotransmitters described in sleep - wake neurochemistry are shaped by\n\nGABA - producing bacteria   [29] , SCFAs, and disrupted serotonin   vitamin B6 metabolism  in antibiotic   depleted models   [110] .  Therapeutically,   both   WMT   improving   sleep   in   humans   [102]   and   acupuncture  modulating microbiota and monoamines in insomnia models   [109]   suggest promising  microbiota   directed interventions. Future work should also evaluate chrononutrition  [105]   and   metabolic   circadian   alignment,   particularly   in   disorders   affecting  leptin / ghrelin oscillations. Finally, deeper characterization of GMBA immune   neural  interactions   [20]   is   essential   for   developing   integrated   neuroimmune   microbial  therapies for sleep disorders.  Conclusions:  The interplay between the gut microbiota and sleep regulation represents a fascinating  and rapidly evolving area of research. While substantial progress has been made,  critical gaps in knowledge remain. For instance, the mechanisms by which specific  microb ial metabolites influence sleep architecture are still not fully understood.  Moreover, the variability in individual microbiota compositions presents challenges in  developing universally effective therapies.  Evidence suggests that targeting microbiota may offer novel therapeutic avenues for  sleep disorders, particularly those with an inflammatory or stress - related component.  Future therapies could integrate microbiota modulation with established clinical  proto cols, such as cognitive - behavioral therapy for insomnia or pharmacological  interventions.   Additionally,   emerging   diagnostic   tools,   like   microbiota - based  biomarkers, hold promise for identifying individuals at risk of sleep disorders or  monitoring treatment   efficacy.  Future   investigations   should   prioritize   integrative   approaches   that   combine  microbiota - targeted   therapies   with   lifestyle   modifications,   such   as   dietary  adjustments, sleep hygiene, and stress management. By addressing these aspects  holistically, researchers   and clinicians can maximize the potential of these therapies to  improve sleep quality and overall health outcomes.  Acknowledgements  Figures in this manuscript were created with BioRender.com.  References  [1]   Sejbuk M, Miro≈Ñczuk - Chodakowska I, Witkowska AM. Sleep Quality: A Narrative  Review on Nutrition, Stimulants, and Physical Activity as Important Factors.  Nutrients 2022;14. https://doi.org/10.3390/nu14091912.\n\n[2]   Irwin MR, Opp MR. Sleep Health: Reciprocal Regulation of Sleep and Innate  Immunity. Neuropsychopharmacology 2017;42:129 ‚Äì 55.  https://doi.org/10.1038/npp.2016.148.  [3]   Cabr√© - Riera A, Torrent M, Donaire - Gonzalez D, Vrijheid M, Cardis E, Guxens M.  Telecommunication devices use, screen time and sleep in adolescents.   Environ  Res 2019;171:341 ‚Äì 7. https://doi.org/10.1016/j.envres.2018.10.036.  [4]   Wehbe AT, Costa TE, Abbas SA, Costa JE, Costa GE, Wehbe TW.   The Effects of  the COVID - 19 Confinement on Screen Time, Headaches, Stress and Sleep  Disorders among Adolescents: A Cross Sectional Study. Chronic Stress 2022;6.  https://doi.org/10.1177/24705470221099836.  [5]   Jaqua EE, Hanna M, Labib W, Moore C, Matossian V. Common Sleep Disorders  Affecting Older Adults. 2022.  [6]   Albrecht U. Timing to Perfection: The Biology of Central and Peripheral  Circadian Clocks. Neuron 2012;74:246 ‚Äì 60.  https://doi.org/10.1016/j.neuron.2012.04.006.  [7]   Koronowski KB, Sassone - Corsi P. Communicating clocks shape circadian  homeostasis. Science (1979) 2021;371.  https://doi.org/10.1126/science.abd0951.  [8]   Mashaqi S, Gozal D. ‚ÄúCircadian misalignment and the gut microbiome. A  bidirectional relationship triggering inflammation and metabolic disorders‚Äù -   a  literature review. Sleep Med 2020;72:93 ‚Äì 108.  https://doi.org/10.1016/j.sleep.2020.03.020.  [9]   Matenchuk BA, Mandhane PJ, Kozyrskyj AL. Sleep, circadian rhythm, and gut  microbiota. Sleep Med Rev 2020;53.  https://doi.org/10.1016/j.smrv.2020.101340.  [10]   Sun S - Y, Chen G - H. Treatment of Circadian Rhythm Sleep ‚Äì Wake Disorders. Curr  Neuropharmacol 2021;20:1022 ‚Äì 34.  https://doi.org/10.2174/1570159x19666210907122933.  [11]   Feng W, Yang Z, Liu Y, Chen R, Song Z, Pan G, et al. Gut microbiota: A new target  of traditional Chinese medicine for insomnia. Biomedicine and  Pharmacotherapy 2023;160. https://doi.org/10.1016/j.biopha.2023.114344.  [12]   Schaafsma A, Mallee L, van den Belt M, Floris E, Kortman G, Veldman J, et al.  The effect of a whey - protein and galacto - oligosaccharides based product on\n\nparameters of sleep quality, stress, and gut microbiota in apparently healthy  adults with moderate sleep disturbances: A randomized controlled cross - over  study. Nutrients 2021;13. https://doi.org/10.3390/nu13072204.  [13]   Wang X, Wang Z, Cao J, Dong Y, Chen Y. Gut microbiota - derived metabolites  mediate the neuroprotective effect of melatonin in cognitive impairment  induced by sleep deprivation. Microbiome 2023;11.  https://doi.org/10.1186/s40168 - 022 - 01452 - 3.  [14]   Asadi A, Shadab Mehr N, Mohamadi MH, Shokri F, Heidary M, Sadeghifard N, et  al. Obesity and gut ‚Äì microbiota ‚Äì brain axis: A narrative review. J Clin Lab Anal  2022;36. https://doi.org/10.1002/jcla.24420.  [15]   Han M, Yuan S, Zhang J. The interplay between sleep and gut microbiota.   Brain  Res Bull 2022;180:131 ‚Äì 46. https://doi.org/10.1016/j.brainresbull.2021.12.016.  [16]   Ogawa Y, Miyoshi C, Obana N, Yajima K, Hotta - Hirashima N, Ikkyu A, et al.   Gut  microbiota depletion by chronic antibiotic treatment alters the sleep/wake  architecture and sleep EEG power spectra in mice. Sci Rep 2020;10.  https://doi.org/10.1038/s41598 - 020 - 76562 - 9.  [17]   Ullah H, Arbab S, Tian Y, Liu CQ, Chen Y, Qijie L, et al. The gut microbiota ‚Äì brain  axis in neurological disorder. Front Neurosci 2023;17.  https://doi.org/10.3389/fnins.2023.1225875.  [18]   Chen M, Ruan G, Chen L, Ying S, Li G, Xu F, et al. Neurotransmitter and Intestinal  Interactions: Focus on the Microbiota - Gut - Brain Axis in Irritable Bowel  Syndrome. Front Endocrinol (Lausanne) 2022;13.  https://doi.org/10.3389/fendo.2022.817100.  [19]   Roman√≠ - P√©rez M, Bullich - Vilarrubias C, L√≥pez - Almela I, Li√©bana - Garc√≠a R,  Olivares M, Sanz Y. The microbiota and the gut - brain axis in controlling food  intake and energy homeostasis. Int J Mol Sci 2021;22.  https://doi.org/10.3390/ijms22115830.  [20]   Le W, Reichmann H, Yang X, Zhao Y, Zhu G. Interactions between gut microbiota  and Parkinson‚Äôs disease: The role of microbiota - derived amino acid  metabolism. n.d.  [21]   Skonieczna - ≈ºydecka K, Grochans E, Maciejewska D, Szkup M, Schneider -  Matyka D, Jurczak A, et al. Faecal short chain fatty acids profile is changed in  Polish depressive women. Nutrients 2018;10.  https://doi.org/10.3390/nu10121939.\n\n[22]   Magzal F, Even C, Haimov I, Agmon M, Asraf K, Shochat T, et al. Associations  between fecal short - chain fatty acids and sleep continuity in older adults with  insomnia symptoms. Sci Rep 2021;11. https://doi.org/10.1038/s41598 - 021 -  83389 - 5.  [23]   van de Wouw M, Boehme M, Lyte JM, Wiley N, Strain C, O‚ÄôSullivan O, et al.  Short - chain fatty acids: microbial metabolites that alleviate stress - induced  brain ‚Äì gut axis alterations. Journal of Physiology 2018;596:4923 ‚Äì 44.  https://doi.org/10.1113/JP276431.  [24]   Holst SC, Landolt HP. Sleep - Wake Neurochemistry. Sleep Med Clin  2018;13:137 ‚Äì 46. https://doi.org/10.1016/j.jsmc.2018.03.002.  [25]   Innocenti A, Lentini G, Rapacchietta S, Cinnirella P, Elia M, Ferri R, et al. The  Role of Supplements and Over - the - Counter Products to Improve Sleep in  Children: A Systematic Review. Int J Mol Sci 2023;24.  https://doi.org/10.3390/ijms24097821.  [26]   Roth W, Zadeh K, Vekariya R, Ge Y, Mohamadzadeh M. Tryptophan metabolism  and gut - brain homeostasis. Int J Mol Sci 2021;22:1 ‚Äì 23.  https://doi.org/10.3390/ijms22062973.  [27]   Zuraikat FM, Wood RA, Barrag√°n R, St - Onge MP. Sleep and Diet: Mounting  Evidence of a Cyclical Relationship. Annu Rev Nutr 2021;41:309 ‚Äì 32.  https://doi.org/10.1146/annurev - nutr - 120420 - 021719.  [28]   Jones BE. Arousal and sleep circuits. Neuropsychopharmacology 2020;45:6 ‚Äì 20.  https://doi.org/10.1038/s41386 - 019 - 0444 - 2.  [29]   Strandwitz P, Kim KH, Terekhova D, Liu JK, Sharma A, Levering J, et al. GABA -  modulating bacteria of the human gut microbiota. Nat Microbiol 2019;4:396 ‚Äì  403. https://doi.org/10.1038/s41564 - 018 - 0307 - 3.  [30]   Zhou J, He L, Liu M, Guo X, Du G, Yan L, et al.   Sleep loss impairs intestinal stem  cell function and gut homeostasis through the modulation of the GABA  signalling pathway in Drosophila. Cell Prolif 2023;56.  https://doi.org/10.1111/cpr.13437.  [31]   Gott JA, St√ºcker S, Kanske P, Haaker J, Dresler M. Acetylcholine and  metacognition during sleep. Conscious Cogn 2024;117.  https://doi.org/10.1016/j.concog.2023.103608.\n\n[32]   Eslami M, Alibabaei F, Babaeizad A, Banihashemian SZ, Mazandarani M,  Hoseini A, et al.   The Importance of Gut Microbiota on Choline Metabolism in  Neurodegenerative Diseases. Biomolecules 2024;14:1345.  https://doi.org/10.3390/biom14111345.  [33]   Ashton A, Jagannath A. Disrupted Sleep and Circadian Rhythms in  Schizophrenia and Their Interaction With Dopamine Signaling. Front Neurosci  2020;14. https://doi.org/10.3389/fnins.2020.00636.  [34]   Hamamah S, Aghazarian A, Nazaryan A, Hajnal A, Covasa M. Role of  Microbiota - Gut - Brain Axis in Regulating Dopaminergic Signaling. Biomedicines  2022;10. https://doi.org/10.3390/biomedicines10020436.  [35]   Alhusaini M, Eissa N, Saad AK, Beiram R, Sadek B. Revisiting Preclinical  Observations of Several Histamine H3 Receptor Antagonists/Inverse Agonists in  Cognitive Impairment, Anxiety, Depression, and Sleep ‚Äì Wake Cycle Disorder.  Front Pharmacol 2022;13. https ://doi.org/10.3389/fphar.2022.861094.  [36]   Barcik W, Pugin B, Westermann P, Perez NR, Ferstl R, Wawrzyniak M, et al.  Histamine - secreting microbes are increased in the gut of adult asthma  patients. Journal of Allergy and Clinical Immunology 2016;138:1491 - 1494.e7.  https://doi.org/10.1016/j.jaci.2016 .05.049.  [37]   Mishima Y, Ishihara S. Molecular Mechanisms of Microbiota - Mediated  Pathology in Irritable Bowel Syndrome. Int J Mol Sci 2020;21:8664.  https://doi.org/10.3390/ijms21228664.  [38]   Toor B, Ray LB, Pozzobon A, Fogel SM. Sleep, Orexin and Cognition, 2021, p. 38 ‚Äì  51. https://doi.org/10.1159/000514960.  [39]   Sun Y, Tisdale RK, Kilduff TS. Hypocretin/Orexin Receptor Pharmacology and  Sleep Phases. Front Neurol Neurosci 2021;45:22 ‚Äì 37.  https://doi.org/10.1159/000514963.  [40]   Forte N, Marfella B, Nicois A, Palomba L, Paris D, Motta A, et al. The short - chain  fatty acid acetate modulates orexin/hypocretin neurons: A novel mechanism in  gut - brain axis regulation of energy homeostasis and feeding. Biochem  Pharmacol 2024;226:116383.   https://doi.org/10.1016/j.bcp.2024.116383.  [41]   Steiner MA, Yanagisawa M, Clozel M, editors. The Orexin System. Basic Science  and Role in Sleep Pathology. vol. 45. S. Karger AG; 2021.  https://doi.org/10.1159/isbn.978 - 3 - 318 - 06844 - 3.\n\n[42]   Kjaerby C, Andersen M, Hauglund N, Untiet V, Dall C, Sigurdsson B, et al.  Memory - enhancing properties of sleep depend on the oscillatory amplitude of  norepinephrine. Nat Neurosci 2022;25:1059 ‚Äì 70.  https://doi.org/10.1038/s41593 - 022 - 01102 - 9.  [43]   Wang J, Fang Z, Dong X, Li W, Wan X. Effect of norepinephrine on host immunity  and bacterial infection. Chin Med J (Engl) 2024;137:362 ‚Äì 4.  https://doi.org/10.1097/CM9.0000000000002931.  [44]   Menon R, Fitzsimmons B, Vanajakumari MU, Lee K, Jayaraman A. Effect of  Norepinephrine on Gut Bacterial Community Structure and Function. The  FASEB Journal 2019;33.  https://doi.org/10.1096/fasebj.2019.33.1_supplement.724.4.  [45]   Yang DF, Huang WC, Wu CW, Huang CY, Yang YCSH, Tung YT. Acute sleep  deprivation exacerbates systemic inflammation and psychiatry disorders  through gut microbiota dysbiosis and disruption of circadian rhythms. Microbiol  Res 2023;268. https://doi.org/10.1016 /j.micres.2022.127292.  [46]   Zhao N, Shu Y, Jian C, Zhou Z, Bao H, Li X, et al. Lactobacillus Ameliorates SD -  Induced Stress Responses and Gut Dysbiosis by Increasing the Absorption of  Gut - Derived GABA in Rhesus Monkeys. Front Immunol 2022;13.  https://doi.org/10.3389/fimmu.2022.915393 .  [47]   Zhu R, Fang Y, Li H, Liu Y, Wei J, Zhang S, et al. Psychobiotic Lactobacillus  plantarum JYLP - 326 relieves anxiety, depression, and insomnia symptoms in  test anxious college via modulating the gut microbiota and its metabolism.  Front Immunol 2023;14. https ://doi.org/10.3389/fimmu.2023.1158137.  [48]   Ho YT, Tsai YC, Kuo TBJ, Yang CCH. Effects of lactobacillus plantarum ps128 on  depressive symptoms and sleep quality in self - reported insomniacs: A  randomized, double - blind, placebo - controlled pilot trial. Nutrients 2021;13.  https://doi.org/10.3390/nu1308 2820.  [49]   Lee HJ, Hong JK, Kim JK, Kim DH, Jang SW, Han SW, et al. Effects of probiotic  nvp - 1704 on mental health and sleep in healthy adults: An 8 - week randomized,  double - blind, placebo - controlled trial. Nutrients 2021;13.  https://doi.org/10.3390/nu13082660.  [50]   Yu L, Han X, Cen S, Duan H, Feng S, Xue Y, et al. Beneficial effect of GABA - rich  fermented milk on insomnia involving regulation of gut microbiota. Microbiol  Res 2020;233. https://doi.org/10.1016/j.micres.2020.126409.\n\n[51]   Lin A, Shih CT, Chu HF, Chen CW, Cheng YT, Wu CC, et al. Lactobacillus  fermentum PS150 promotes non - rapid eye movement sleep in the first night  effect of mice. Sci Rep 2021;11. https://doi.org/10.1038/s41598 - 021 - 95659 - 3.  [52]   Lee DY, Baek JS, Shin YJ, Kim DH. Alleviation of Immobilization Stress or Fecal  Microbiota - Induced Insomnia and Depression - like Behaviors in Mice by  Lactobacillus plantarum and Its Supplement. Nutrients 2024;16.  https://doi.org/10.3390/nu16213711.  [53]   Liu L, He G, Yu R, Lin B, Lin L, Wei R, et al. Causal relationships between gut  microbiome and obstructive sleep apnea: a bi - directional Mendelian  randomization. Front Microbiol 2024;15.  https://doi.org/10.3389/fmicb.2024.1410624.  [54]   Yan W, Jiang M, Hu W, Zhan X, Liu Y, Zhou J, et al. Causality Investigation  between Gut Microbiota, Derived Metabolites, and Obstructive Sleep Apnea: A  Bidirectional Mendelian Randomization Study. Nutrients 2023;15.  https://doi.org/10.3390/nu15214544.  [55]   Li N, Tan S, Wang Y, Deng J, Wang N, Zhu S, et al. Akkermansia muciniphila  supplementation prevents cognitive impairment in sleep - deprived mice by  modulating microglial engulfment of synapses. Gut Microbes 2023;15.  https://doi.org/10.1080/19490976.2023.22 52764.  [56]   Wang F, Zou J, Xu H, Huang W, Zhang X, Wei Z, et al. Effects of Chronic  Intermittent Hypoxia and Chronic Sleep Fragmentation on Gut Microbiome,  Serum Metabolome, Liver and Adipose Tissue Morphology. Front Endocrinol  (Lausanne) 2022;13. https://doi.org/10. 3389/fendo.2022.820939.  [57]   Bs S, Thankappan B, Mahendran R, Muthusamy G, Femil selta DR, Angayarkanni  J. Evaluation of GABA Production and Probiotic Activities of Enterococcus  faecium BS5. Probiotics Antimicrob Proteins 2021;13:993 ‚Äì 1004.  https://doi.org/10.1007/s12602 - 021 - 09759 - 7.  [58]   Benedict C, Vogel H, Jonas W, Woting A, Blaut M, Sch√ºrmann A, et al. Gut  microbiota and glucometabolic alterations in response to recurrent partial  sleep deprivation in normal - weight young individuals. Mol Metab 2016;5:1175 ‚Äì  86. https://doi.org/10.1016/j.m olmet.2016.10.003.  [59]   Seong HJ, Baek Y, Lee S, Jin HJ. Gut microbiome and metabolic pathways linked  to sleep quality. Front Microbiol 2024;15.  https://doi.org/10.3389/fmicb.2024.1418773.\n\n[60]   Li X, Zhang Y, Zhang Q, Cao A, Feng J. Eucalyptus essential oil exerted a  sedative - hypnotic effect by influencing brain neurotransmitters and gut  microbes via the gut microbiota - brain axis. Front Pharmacol 2024;15.  https://doi.org/10.3389/fphar.2024.14646 54.  [61]   Liu Z, Wei Z - Y, Chen J, Chen K, Mao X, Liu Q, et al. Acute Sleep - Wake Cycle Shift  Results in Community Alteration of Human Gut Microbiome. MSphere 2020;5.  https://doi.org/10.1128/msphere.00914 - 19.  [62]   Li Y, Zhang B, Zhou Y, Wang D, Liu X, Li L, et al.   Gut microbiota changes and their  relationship with inflammation in patients with acute and chronic insomnia. Nat  Sci Sleep 2020;12:895 ‚Äì 905. https://doi.org/10.2147/NSS.S271927.  [63]   Barone M, Martucci M, Sciara G, Conte M, Medina LSJ, Iattoni L, et al. Towards a  personalized prediction, prevention and therapy of insomnia: gut microbiota  profile can discriminate between paradoxical and objective insomnia in post -  menopausal women. EPMA   Journal 2024;15:471 ‚Äì 89.  https://doi.org/10.1007/s13167 - 024 - 00369 - 1.  [64]   Tanaka A, Sanada K, Miyaho K, Tachibana T, Kurokawa S, Ishii C, et al. The  relationship between sleep, gut microbiota, and metabolome in patients with  depression and anxiety: A secondary analysis of the observational study. PLoS  One 2023;18. https://doi.o rg/10.1371/journal.pone.0296047.  [65]   Yao ZY, Li XH, Zuo L, Xiong Q, He WT, Li DX, et al. Maternal sleep deprivation  induces gut microbial dysbiosis and neuroinflammation in offspring rats.   Zool  Res 2022;43:380 ‚Äì 90. https://doi.org/10.24272/j.issn.2095 - 8137.2022.023.  [66]   Jiang Z, Zhuo L bao, He Y, Fu Y, Shen L, Xu F, et al.   The gut microbiota - bile acid  axis links the positive association between chronic insomnia and  cardiometabolic diseases. Nat Commun 2022;13.  https://doi.org/10.1038/s41467 - 022 - 30712 - x.  [67]   Li Y, Deng Q, Liu Z. The relationship between gut microbiota and insomnia: a bi -  directional two - sample Mendelian randomization research. Front Cell Infect  Microbiol 2023;13. https://doi.org/10.3389/fcimb.2023.1296417.  [68]   Chen HW, Zhou R, Cao BF, Liu K, Zhong Q, Huang YN, et al. The predictive,  preventive, and personalized medicine of insomnia: gut microbiota and  inflammation. EPMA Journal 2023;14:571 ‚Äì 83. https://doi.org/10.1007/s13167 -  023 - 00345 - 1.\n\n[69]   Wang Q, Chen B, Sheng D, Yang J, Fu S, Wang J, et al. Multiomics Analysis  Reveals Aberrant Metabolism and Immunity Linked Gut Microbiota with  Insomnia. Microbiol Spectr 2022;10. https://doi.org/10.1128/spectrum.00998 -  22.  [70]   Huang B, Chau SWH, Liu Y, Chan JWY, Wang J, Ma SL, et al. Gut microbiome  dysbiosis across early Parkinson‚Äôs disease, REM sleep behavior disorder and  their first - degree relatives. Nat Commun 2023;14.  https://doi.org/10.1038/s41467 - 023 - 38248 - 4.  [71]   Lecomte A, Barateau L, Pereira P, Paulin L, Auvinen P, Scheperjans F, et al. Gut  microbiota composition is associated with narcolepsy type 1. Neurology(R)  Neuroimmunology & Neuroinflammation 2020;7.  https://doi.org/10.1212/NXI.0000000000000896.  [72]   Deng Z, Liu L, Liu W, Liu R, Ma T, Xin Y, et al.   Alterations in the fecal microbiota of  methamphetamine users with bad sleep quality during abstinence. BMC  Psychiatry 2024;24. https://doi.org/10.1186/s12888 - 024 - 05773 - 5.  [73]   Yoo JY, Groer M, Dutra SVO, Sarkar A, McSkimming DI. Gut microbiota and  immune system interactions. Microorganisms 2020;8:1 ‚Äì 22.  https://doi.org/10.3390/microorganisms8101587.  [74]   Di Vincenzo F, Del Gaudio A, Petito V, Lopetuso LR, Scaldaferri F. Gut  microbiota, intestinal permeability, and systemic inflammation: a narrative  review. Intern Emerg Med 2024;19:275 ‚Äì 93. https://doi.org/10.1007/s11739 - 023 -  03374 - w.  [75]   Zhao Z, Ning J, Bao X qi, Shang M, Ma J, Li G, et al. Fecal microbiota  transplantation protects rotenone - induced Parkinson‚Äôs disease mice via  suppressing inflammation mediated by the lipopolysaccharide - TLR4 signaling  pathway through the microbiota - gut - bra in axis.   Microbiome 2021;9.  https://doi.org/10.1186/s40168 - 021 - 01107 - 9.  [76]   Mou Y, Du Y, Zhou L, Yue J, Hu X, Liu Y, et al.   Gut Microbiota Interact With the  Brain Through Systemic Chronic Inflammation: Implications on  Neuroinflammation, Neurodegeneration, and Aging. Front Immunol 2022;13.  https://doi.org/10.3389/fimmu.2022.796288.  [77]   Xiong RG, Li J, Cheng J, Zhou DD, Wu SX, Huang SY, et al. The Role of Gut  Microbiota in Anxiety, Depression, and Other Mental Disorders as Well as the\n\nProtective Effects of Dietary Components. Nutrients 2023;15.  https://doi.org/10.3390/nu15143258.  [78]   Parker BJ, Wearsch PA, Veloo ACM, Rodriguez - Palacios A. The Genus Alistipes:  Gut Bacteria With Emerging Implications to Inflammation, Cancer, and Mental  Health. Front Immunol 2020;11. https://doi.org/10.3389/fimmu.2020.00906.  [79]   Bowers SJ, Lambert S, He S, Lowry CA, Fleshner M, Wright KP, et al.  Immunization with a heat - killed bacterium, Mycobacterium vaccae NCTC  11659, prevents the development of cortical hyperarousal and a PTSD - like  sleep phenotype after sleep disruption and ac ute stress in mice. Sleep  2021;44:1 ‚Äì 16. https://doi.org/10.1093/sleep/zsaa271.  [80]   Feuth T. Interactions between sleep, inflammation, immunity and infections: A  narrative review. Immun Inflamm Dis 2024;12:e70046.  https://doi.org/10.1002/iid3.70046.  [81]   Liu X, Chen B, Huang Z, Duan R, Li H, Xie L, et al. Effects of poor sleep on the  immune cell landscape as assessed by single - cell analysis. Commun Biol  2021;4. https://doi.org/10.1038/s42003 - 021 - 02859 - 8.  [82]   Sang D, Lin K, Yang Y, Ran G, Li B, Chen C, et al. Prolonged sleep deprivation  induces a cytokine - storm - like syndrome in mammals. Cell 2023;186:5500 -  5516.e21. https://doi.org/10.1016/j.cell.2023.10.025.  [83]   Cortese R, Adams TS, Cataldo KH, Hummel J, Kaminski N, Kheirandish - Gozal L,  et al. Single - cell RNA - seq uncovers cellular heterogeneity and provides a  signature for paediatric sleep apnoea. European Respiratory Journal 2023;61.  https://doi.org/10.1183/1399 3003.01465 - 2022.  [84]   Kadier K, Dilixiati D, Ainiwaer A, Liu X, Lu J, Liu P, et al. Analysis of the  relationship between sleep - related disorder and systemic immune -  inflammation index in the US population.   BMC Psychiatry 2023;23.  https://doi.org/10.1186/s12888 - 023 - 05286 - 7.  [85]   Liu X, Su Y, Huang Z, Lv J, Gu C, Li Z, et al.   Sleep loss potentiates Th17 ‚Äê cell  pathogenicity and promotes autoimmune uveitis. Clin Transl Med 2023;13.  https://doi.org/10.1002/ctm2.1250.  [86]   Nava Zisapel C, Zisapel N. New perspectives on the role of melatonin in human  sleep, circadian rhythms and their regulation LINKED ARTICLES 2018.  https://doi.org/10.1111/bph.v175.16/issuetoc.\n\n[87]   De Nys L, Anderson K, Ofosu EF, Ryde GC, Connelly J, Whittaker AC. The effects  of physical activity on cortisol and sleep: A systematic review and meta -  analysis. Psychoneuroendocrinology 2022;143.  https://doi.org/10.1016/j.psyneuen.2022.105843.  [88]   Kurnool S, McCowen KC, Bernstein NA, Malhotra A. Sleep Apnea, Obesity, and  Diabetes   ‚Äî   an Intertwined Trio. Curr Diab Rep 2023;23:165 ‚Äì 71.  https://doi.org/10.1007/s11892 - 023 - 01510 - 6.  [89]   Chennaoui M, L√©ger D, Gomez - Merino D. Sleep and the GH/IGF - 1 axis:  Consequences and countermeasures of sleep loss/disorders. Sleep Med Rev  2020;49. https://doi.org/10.1016/j.smrv.2019.101223.  [90]   Reiter RJ, Mayo JC, Tan DX, Sainz RM, Alatorre - Jimenez M, Qin L. Melatonin as  an antioxidant: under promises but over delivers. J Pineal Res 2016:253 ‚Äì 78.  https://doi.org/10.1111/jpi.12360.  [91]   Tordjman S, Chokron S, Delorme R, Charrier A, Bellissant E, Jaafari N, et al.  Melatonin: Pharmacology, Functions and Therapeutic Benefits. Curr  Neuropharmacol 2017;15:434 ‚Äì 43.  https://doi.org/10.2174/1570159X14666161228122115.  [92]   Hirotsu C, Tufik S, Andersen ML. Interactions between sleep, stress, and  metabolism: From physiological to pathological conditions. Sleep Science  2015;8:143 ‚Äì 52. https://doi.org/10.1016/j.slsci.2015.09.002.  [93]   Kim TW, Jeong JH, Hong SC. The impact of sleep and circadian disturbance on  hormones and metabolism. Int J Endocrinol 2015;2015.  https://doi.org/10.1155/2015/591729.  [94]   McHill AW, Hull JT, Klerman EB. Chronic Circadian Disruption and Sleep  Restriction Influence Subjective Hunger, Appetite, and Food Preference.  Nutrients 2022;14. https://doi.org/10.3390/nu14091800.  [95]   Qi X, Yun C, Pang Y, Qiao J. The impact of the gut microbiota on the reproductive  and metabolic endocrine system. Gut Microbes 2021;13:1 ‚Äì 21.  https://doi.org/10.1080/19490976.2021.1894070.  [96]   Naufel MF, Truzzi G de M, Ferreira CM, Coelho FMS. The brain - gut - microbiota  axis in the treatment of neurologic and psychiatric disorders. Arq  Neuropsiquiatr 2023;81:670 ‚Äì 84. https://doi.org/10.1055/s - 0043 - 1767818.\n\n[97]   Wang Z, Wang Z, Lu T, Chen W, Yan W, Yuan K, et al. The microbiota - gut - brain  axis in sleep disorders. Sleep Med Rev 2022;65:101691.  https://doi.org/10.1016/j.smrv.2022.101691.  [98]   Arnoriaga - Rodr√≠guez M, Leal Y, Mayneris - Perxachs J, P√©rez - Brocal V, Moya A,  Ricart W, et al. Gut Microbiota Composition and Functionality Are Associated  With REM Sleep Duration and Continuous Glucose Levels. Journal of Clinical  Endocrinology and Metabolis m 2023;108:2931 ‚Äì 9.  https://doi.org/10.1210/clinem/dgad258.  [99]   Li L, Liang T, Jiang T, Li Y, Yang L, Wu L, et al. Gut microbiota: Candidates for a  novel strategy for ameliorating sleep disorders. Crit Rev Food Sci Nutr  2024;64:10772 ‚Äì 88. https://doi.org/10.1080/10408398.2023.2228409.  [100]   Smith RP, Easson C, Lyle SM, Kapoor R, Donnelly CP, Davidson EJ, et al. Gut  microbiome diversity is associated with sleep physiology in humans.   PLoS One  2019;14. https://doi.org/10.1371/journal.pone.0222394.  [101]   Santamarina AB, Nehmi Filho V, Freitas JA de, Silva BFRB da, Gusm√£o AF,  Olivieri EHR, et al.   Nutraceutical composition (yeast   Œ≤ - glucan, prebiotics,  minerals, and silymarin) predicts improvement of sleep quality and metabolic  parameters: A randomized pilot study. Clin Nutr ESPEN 2024;63:476 ‚Äì 90.  https://doi.org/10.1016/j.clnesp.2024.06.033.  [102]   Li Q, Liu Y, Zhang Z, Zhang S, Ding X, Zhang F. Washed Microbiota  Transplantation Improves the Sleep Quality in Patients with Inflammatory Bowel  Disease. Nat Sci Sleep 2024;16:1141 ‚Äì 52.  https://doi.org/10.2147/NSS.S460882.  [103]   He H, Li M, Qiu Y, Wu Z, Wu L. Washed microbiota transplantation improves  sleep quality in patients with sleep disorder by the gut - brain axis. Front  Neurosci 2024;18. https://doi.org/10.3389/fnins.2024.1415167.  [104]   Liang X, Bushman FD, FitzGerald GA. Rhythmicity of the intestinal microbiota is  regulated by gender and the host circadian clock. Proc Natl Acad Sci U S A  2015;112:10479 ‚Äì 84. https://doi.org/10.1073/pnas.1501305112.  [105]   Saidi O, Rochette E, Dambel L, St - Onge MP, Duch√© P. Chrono - nutrition and  sleep: lessons from the temporal feature of eating patterns in human studies   -   A  systematic scoping review. Sleep Med Rev 2024;76.  https://doi.org/10.1016/j.smrv.2024.101953.\n\n[106]   Magzal F, Even C, Haimov I, Agmon M, Asraf K, Shochat T, et al. Associations  between fecal short - chain fatty acids and sleep continuity in older adults with  insomnia symptoms. Sci Rep 2021;11. https://doi.org/10.1038/s41598 - 021 -  83389 - 5.  [107]   Shen YC, Sun X, Li L, Zhang HY, Huang ZL, Wang YQ. Roles of Neuropeptides in  Sleep ‚Äì Wake Regulation. Int J Mol Sci 2022;23.  https://doi.org/10.3390/ijms23094599.  [108]   Xie JF, Shao YF, Wang HL, Wang C, Cui GF, Kong XP, et al. Neuropeptide s  counteracts paradoxical sleep deprivation - induced anxiety - like behavior and  sleep disturbances. Front Cell Neurosci 2018;12.  https://doi.org/10.3389/fncel.2018.00064.  [109]   Hong J, Chen J, Kan J, Liu M, Yang D. Effects of acupuncture treatment in  reducing sleep disorder and gut microbiota alterations in PCPA - induced  insomnia mice. Evidence - Based Complementary and Alternative Medicine  2020;2020. https://doi.org/10.1155/2020/3 626120.  [110]   Zhang SL, Bai L, Goel N, Bailey A, Jang CJ, Bushman FD, et al. Human and rat  gut microbiome composition is maintained following sleep restriction.   Proc  Natl Acad Sci U S A 2017;114:E1564 ‚Äì 71.  https://doi.org/10.1073/pnas.1620673114.",
    "Quantified Sleep  Machine learning techniques for observational n-of-1 studies  Gianluca Truda Vrije Universiteit Amsterdam May 17, 2021  Abstract  This paper applies statistical learning techniques to an observational Quantified-Self (QS) study to build a descriptive model of sleep quality. A total of 472 days of my sleep data was collected with an Oura ring. This was combined with a variety of lifestyle, environmental, and psychological data, harvested from multiple sensors and manual logs. Such n-of-1 QS projects pose a number of specific challenges: heterogeneous data sources with many missing values; few observations and many features; dynamic feedback loops; and human biases. This paper directly addresses these challenges with an end-to-end QS pipeline for observational studies that combines techniques from statistics and machine learning to produce robust descriptive models. Sleep quality is one of the most difficult modelling targets in QS research, due to high noise and a large number of weakly-contributing factors. Sleep quality was selected so that approaches from this paper would generalise to most other n-of-1 QS projects. Techniques are presented for combining and engineering features for the different classes of data types, sample frequencies, and schema. This includes manually-tracked event logs and automatically-sampled weather and geo-spatial data. Relevant statistical analyses for outliers, normality, (auto)correlation, stationarity, and missing data are detailed, along with a proposed method for hierarchical clustering to identify correlated groups of features.   The missing data was overcome using a combination of knowledge-based and statistical techniques, including several multivariate imputation algorithms. ‚ÄúMarkov unfolding‚Äù is presented for collapsing the time series into a collection of independent observations, whilst incorporating historical information. The final model was interpreted in two key ways: by inspecting the internal   Œ≤ -parameters, and using the SHAP framework, which can explain any ‚Äúblack box‚Äù model. These two interpretation techniques were combined to produce a list of the 16 most-predictive features, demonstrating that an observational study can greatly narrow down the number of features that need to be considered when designing interventional QS studies.  Keywords : Quantified-self, machine learning, missing data, imputation, n-of-1, sleep, Oura ring, prediction, supervised learning, biohacking, observational, longitudinal, time series, interpretable, explainable.  Source code : github.com/gianlucatruda/quantified-sleep 1  arXiv:2105.06811v1 [q-bio.QM] 14 May 2021\n\nContents  1   Introduction   4  1.1   Specific challenges   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   4 1.1.1   Establishing causal relationships   . . . . . . . . . . . . . . . . . . . . . . . .   4 1.1.2   Many heterogeneous data sources . . . . . . . . . . . . . . . . . . . . . . . .   5 1.1.3   Human in the dynamic feedback loops . . . . . . . . . . . . . . . . . . . . .   6 1.1.4   Wide datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   6 1.1.5   Missing values   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   7 1.1.6   Complexities of sleep . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   7 1.2   Terminology and notation   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   8  2   Data sources   8  2.1   Sleep data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   8 2.2   Supporting data   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   9  3   Data wrangling   11  3.1   Data ingestion   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   11 3.2   Midnight unwrapping   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   11 3.3   Transformations   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   12 3.4   Aggregation techniques   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   13 3.4.1   Aggregating temporal data   . . . . . . . . . . . . . . . . . . . . . . . . . . .   13 3.4.2   Aggregating location data with geohashes   . . . . . . . . . . . . . . . . . . .   13 3.5   Dataset concatenation   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   14  4   Analysis of dataset properties   15  4.1   Time period . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   15 4.2   Outliers   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   15 4.3   Normality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   16 4.4   Correlation   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   16 4.4.1   Pairwise correlation with target . . . . . . . . . . . . . . . . . . . . . . . . .   17 4.4.2   Hierarchical correlational clustering   . . . . . . . . . . . . . . . . . . . . . .   18 4.4.3   Autocorrelation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   20 4.5   Stationarity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   21  5   Overcoming missing data   22  5.1   Theory of missing data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   22 5.2   Analysis of missing data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   22 5.3   Approaches to handle missing data . . . . . . . . . . . . . . . . . . . . . . . . . . .   24 5.4   Knowledge-based filling   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   24 5.5   Imputation strategies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   25 5.5.1   Univariate imputation   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   25 5.5.2   Multivariate imputation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   25 5.5.3   Multiple imputation   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   25 5.6   Baseline dataset with missing values   . . . . . . . . . . . . . . . . . . . . . . . . . .   26 5.7   Quantifying imputation distance   . . . . . . . . . . . . . . . . . . . . . . . . . . . .   26  6   Collapsing time with Markov unfolding   28  6.1   Markov assumption . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   28 6.2   Markov unfolding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   29 2\n\nQuantified Sleep : CONTENTS   Gianluca Truda  7   Model interpretation   30  7.1   Interpreting model parameters   . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   30 7.1.1   Regularised linear models   . . . . . . . . . . . . . . . . . . . . . . . . . . . .   30 7.1.2   Recursive feature elimination (RFE)   . . . . . . . . . . . . . . . . . . . . . .   30 7.2   Model-agnostic interpretation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   31 7.2.1   Shapley values   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   31 7.2.2   SHAP   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   32  8   Experiments   32 9   Results and discussion   34  9.1   Effectiveness of Markov unfolding . . . . . . . . . . . . . . . . . . . . . . . . . . . .   34 9.2   Comparison of imputation techniques   . . . . . . . . . . . . . . . . . . . . . . . . .   36 9.3   Predictive performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   38 9.4   Model interpretation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   39 9.4.1   Interpreting cross-validated RFE   . . . . . . . . . . . . . . . . . . . . . . . .   39 9.4.2   Interpreting cross-validated Lasso . . . . . . . . . . . . . . . . . . . . . . . .   40 9.4.3   Interpreting model with SHAP   . . . . . . . . . . . . . . . . . . . . . . . . .   41 9.4.4   Combined interpretation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   43 9.5   Feature explanation   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   45  10 Limitations and future work   46  10.1 Ground truth   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   46 10.2 Generalisability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   46 10.3 Markov unfolding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   46 10.4 Imputation   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   47 10.5 Interpretation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   47 10.6 Hierarchical clustering   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   47  11 Conclusions   48 12 Practicalities   49  12.1 Code and data availability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   49 12.2 Replicating this work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   49  A   Appendices   53  Page 3\n\nQuantified Sleep : 1   INTRODUCTION   Gianluca Truda  1   Introduction  Connected wearable devices are making personal data collection ubiquitous. These advances have made Quantified-Self (QS) projects an increasingly-interesting avenue of research into personalised healthcare and life extension [   1 ]. Whilst there has been considerable progress made on the challenges of collecting, storing, and summarising such data, there remains a gap between basic insights (e.g. sleep duration) and the deeper kinds of analysis that allow for effective interventions [   2   ] ‚Äî e.g. taking precisely 0.35 mg of melatonin 1-2 hours before bedtime to increase deep sleep by 22%. There are also major challenges like missing values, few observations, feedback loops, and biological complexity [3]. This QS study utilised 15 months of my personal data to find useful relationships between sleep quality and hundreds of lifestyle and environmental factors. Multiple heterogeneous data sources from both active and passive tracking systems were combined and preprocessed into a day-level timeseries (¬ß2). The study combines various techniques for feature engineering (¬ß3), dataset analysis (¬ß4), missing value imputation (¬ß5), temporal representation (¬ß6), and model interpretation (¬ß7). These methods were evaluated for various learning algorithms through a series of experiments (¬ß8). The context of sleep quality is a good case study in observational n-of-1 research, as its challenges generalise to other areas of QS research. Fig. 1 gives a graphical overview of the components of this study. Data source 1  Data source 2  Data source n  Preprocessing and Aggregation   Unified view  Analysis  Knowledge- based filling  Missing data imputation  . . .  Grid search over datasets and models  Best model and dataset combination  Beta-parameter interpretation  SHAP interpretation  Markov unfolding  Final interpretation  Dataset variants  Figure 1: An overview of the data pipeline for this study, from disparate data sources to a final interpretation of the effects on sleep quality.  1.1   Specific challenges  N-of-1 studies pose a number of unique challenges, but so do QS projects and observational studies. At the intersection of all of these (Fig. 2) is the set of attributes that make this study uniquely challenging. We begin by exploring these challenges.  1.1.1   Establishing causal relationships  The gold standard for experiments involving human subjects is the double-blind, randomised, controlled trial (RCT). Such a study is   interventional , typically having a single variable that is manipulated, such as whether a subject receives a specific drug therapy. All other variables are controlled by strict laboratory conditions, selective recruiting of participants, and rigorous protocols. All of these measures help minimise various statistical and human biases that might affect the outcome. This allows researchers to establish causal links between variables. Page 4\n\nQuantified Sleep : 1   INTRODUCTION   Gianluca Truda Observational   N-of-1 Day-level Quantified Self  This study  Figure 2: Illustrative diagram of how this study sits at the intersection of observational research, n-of-1 experiments, and day-level Quantified-Self (QS) research. In total contrast, we have the n-of-1 QS study.   This involves a single individual who designs, administers, and is the subject of the experiments [   1 ]. This makes the study very difficult to blind. Confounding factors, ordering effects, and human biases are thus exacerbated when studying single individuals. Moreover, it is often unclear at the outset what variables are relevant to study in this way. This paper addresses these challenges by using a wide-spanning   observational   study to identify interesting factors that can then be examined further in controlled studies. Techniques for effectively executing these initial observational studies are the focus of this paper. Whilst there are many challenges in observational n-of-1 research, it is also important to acknowledge the many advantages. Firstly, n-of-1 studies offer something that RCTs cannot. Namely, direct applicability to the subject in question. The cohort of an RCT is very carefully selected. The results of these studies may, therefore, not fully generalise to the genetic, environmental, and psychological attributes of other groups. For complex systems, n-of-1 studies allow data to be collected about the specific individual in question [ 4   ]. Secondly, by beginning with a wide-ranging observational study, n-of-1 research allows the subject to fit the study around their daily life. This further increases the relevance of results, because they fit within the specific context that we are seeking to optimise. The observational approach can also capture unexpected interactions between variables, which helps identify the most relevant factors for future controlled studies.  1.1.2   Many heterogeneous data sources  The QS domain often requires combining multiple bespoke systems to collect both active and passive data [   2 ]. For instance, I log my caffeine intake actively using the   Nomie   app on my phone, but my screen time is monitored passively by the   RescueTime   desktop software. For simple analytics, it is sufficient to work with these sources in isolation. For more valuable multivariate analysis, however, it is essential to unify the data sources and produce a combined dataset. This is challenging for two reasons. Firstly, each source has its own schema for storing, processing, and exporting data. These schema are usually specific to each system. Many tools often limit the level at which data can be exported or analysed. Secondly, the nature and structure of the data differs from source to source. For example, I keep track of caffeine intake by actively logging the date-time-stamp whenever I drink coffee. This follows an event-based scheme, where each date-time-stamp is a record in a relational database. Conversely, my sleep quality is passively measured and logged by my   Oura  ring and stored (primarily) as a daily summary. To analyse the interactions between my caffeine Page 5\n\nQuantified Sleep : 1   INTRODUCTION   Gianluca Truda intake and my sleep, I would need to reconcile these two schema by aggregating the caffeine logs to daily summaries and then aligning the dates with the sleep summaries. Instead of events, I now have daily features like average number of coffees, time of last coffee, etc. As more sources are included in the dataset, the complexity of the processing and alignment increases. This study addresses these challenge by parsing each data source into a dataframe [   5 ], then aligning these into a unified view.   In order to do so, a number of feature aggregation and engineering techniques were developed for this context (¬ß3).  1.1.3   Human in the dynamic feedback loops  The very aspect of n-of-1 QS that makes it interesting also imbues it with challenges. Having a human ‚Äúin the loop‚Äù of the experiment introduces a number of biases and errors [   6 ] that affect the results [   1   ]. It is typically too impractical to use any blinding methods in QS because we mostly study multiple variables at once and cannot control for all the other factors. Self-blinding is quite challenging even for a single independent variable [ 7 ]. For problems like sleep modelling, blinding the subject is outright impossible, as almost all of the interesting variables include at least some degree of subjectivity.   For instance, it may be that tracking my sleep quality makes me more anxious about my sleep, which in turn keeps me up longer and degrades my sleep efficiency. Or, I may be less effective at estimating my mood and energy levels when I am sleep deprived. Or, the act of logging caffeinated drinks or melatonin tablets may have a stronger placebo effect than the actual substance. This means that even an accurate and explainable model will only be able to describe the system it was based on ‚Äî biases, feedback loops, and placebos included. It also means that we need to take great care when interpreting our engineered features and the results we produce. Moreover, modelling   dynamic   systems with feedback loops requires time series techniques. Unfor- tunately, these place constraints on the choice of models and the interpretations we can perform. In this study, a technique called ‚ÄúMarkov unfolding‚Äù (¬ß6) is used to collapse the time series into independent observations, allowing for historical data to be captured by non-temporal models.  1.1.4   Wide datasets  A fundamental challenge for n-of-1 QS projects is having insufficient data. Whilst many sensors collect large quantities of data at high sample rates [   1 ,   3 ], much of this is aggregated down to summaries. This is because we are often interested in longer time periods, like hours or days [ 2 ]. In this study, for instance, the focus is sleep quality. Because this is quantified daily, all data sources must be aggregated to match this day-long window size of observations. A 200 Hz accelerometer ultimately becomes dozens of engineered features summarising daily motion and activity. This has the effect of collapsing low-dimensional, high-frequency data into high-dimensional, low-frequency data. In other words, our dataset becomes wider than it is long. Na√Øve modelling of such a dataset results in overparameterised models that are high in variance [8] and do not generalise [9, 10]. This challenge is addressed through the use of multiple feature selection techniques (¬ß7.1.2), which reduce dimensionality [   3 ]. This is complemented by analysing the distributions of cross-validated results to detect the ones that are robust across subsets of the data (¬ß8). Page 6\n\nQuantified Sleep : 1   INTRODUCTION   Gianluca Truda  1.1.5   Missing values  Missing data is a major problem for modelling, because most techniques assume complete data [ 11 ]. The missing values either have to be filled in (imputed or interpolated) or discarded (dropped) along with all other data for the observation.   Imputation maintains the size and shape of the dataset, but reduces the quality by introducing noise. Dropping introduces no additional noise, but reduces the number of observations ‚Äî making the dataset relatively shorter and wider ‚Äî which increases model variance. N-of-1 QS studies exacerbate the problem of missing data dramatically.   Because the study is about a single individual, there are already fewer observations at the outset. Moreover, there is a great deal of noise and complexity in the observations, as they are specific to the individual being studied [ 7 ]. Additionally, QS projects involve data from multiple heterogeneous sources, and so often require some experimentation with different pieces of software and hardware [ 2 ]. This results in a dataset that has a great deal of missing values in one of a few characteristic types (¬ß5.1). Additionally, sensors and systems can fail, resulting in missing values scattered throughout the data. Active-tracking sources are prone to poor adherence. Fortunately, the unique nature of n-of-1 QS studies also allows us to utilise a collection of tricks and tools that can overcome some of these missing data issues. This paper organises missing values into distinct types (¬ß5.1), inferring some from domain knowledge (¬ß5.4), whilst others are imputed using various sophisticated techniques (¬ß5.5).  1.1.6   Complexities of sleep  This study‚Äôs target variable (sleep quality) posed some additional challenges. Not only is sleep a complex and little-understood process [   12 ], but it is one for which the subject is necessarily not fully conscious, making measurement far more difficult. Many lifestyle factors have been shown to affect sleep quality and quantity [   13 ,   14 ,   15 ].   Poor sleep also impairs a subject‚Äôs ability to accurately assess their sleep quality and quantity [   16 ,   12 ]. Consumer-grade hardware for sleep tracking is increasingly available due to wearable technology, but must infer sleep stages from other physiological markers like heart rate, movement, heart rate variability (HRV), and body temperature [   17 ]. Unlike exercise tracking, the ground truth for sleep tracking is uncertain. This adds additional noise to the target variable. Sleep exists within a complex feedback loop with hundreds of other factors (including itself) [ 15 ,   12 ], so a simple univariate analysis is clearly insufficient. Instead, this study is framed as a modelling problem in which we wish to construct an explanatory model of sleep. To build the best possible model, we convert the task to an optimisation problem under the framework of supervised learning: models with a low prediction error on unseen (out-of-sample) data are more likely to have captured the relevant variable interactions [ 10 ]. However, our end goal is not to make a good   predictive  model. That is just an intermediate step to finding a good   descriptive   model. By interpreting the model (¬ß7), it is possible to find which variables are most influential in determining sleep quality, highlighting potential avenues for further studies. For instance, the model may reveal that melatonin consumption and timing of intense exercise are, together, two of the biggest predictors of sleep quality. This information could then be used to design interventional n-of-1 studies that specifically determine the effect size or optimal ‚Äúdose‚Äù of each variable in isolation. Page 7\n\nQuantified Sleep : 2   DATA SOURCES   Gianluca Truda  1.2   Terminology and notation  Because machine learning sits at the intersection of a number of fields ‚Äî statistics, computer science, and software engineering ‚Äî terminology is varied and overlapping. The goal of this paper is to model a dependent variable (sleep quality) in terms of the independent variables that influence it, such as caffeine consumption, exercise, weather, and previous sleep quality. In this paper, the term   feature   will be used to refer to a preprocessed independent variable, whilst  target   (feature) will be used for the dependent variable (sleep quality).   For instance, caffeine consumption is an   input variable   but, after preprocessing and aggregating, the hour at which caffeine was consumed is a   feature 1 . Input variables are often non-numeric, but all features are numeric. Individual points in time (days) will be called   observations 2 . When we dig beneath this modelling view, datasets are organised as dataframes ‚Äî   m   √ó   n   matrices with labels for each column and row. Row   i   corresponds to an   observation   on a particular day. Column   j   correspond to a timeseries for some   feature . So   columns   are how we practically store our   features   whilst   rows   are how we practically store our   observations . This means that value   x i,j   is the single value in row   i  and column   j   of our data matrix   X   ‚àà   R m √ó n . So on day   i , the   j th feature had a value of   x i,j   .  2   Data sources  An overview of the data sources is found in Table 1. A detailed explanation follows.  2.1   Sleep data  The target variable for this study was sleep quality.   This is a function of several sleep-related variables that were captured using a second-generation Oura ring. The Oura ring is a wearable device with sensors that measure movement, heartbeats, respiration, and temperature changes. Being located on the finger instead of the wrist or chest, it can measure pulse and temperature with greater sensitivity and accuracy, resulting in measurements suitable for sleep analysis [17]. Studies have found that the 250 Hz sensors of the Oura ring are extremely accurate for resting heart rate and heart rate variability (HRV) measurement when compared to medical-grade ECG devices [   18 ].   This is likely due to the use of dual-source infrared sensors instead of the more common single-source green light sensors when performing photoplethysmography [ 17 ]. Respiratory rate was found to be accurate to within 1 breath per minute of electrocardiogram-derived measures by an external study [ 19   ]. Internal studies [ 17 ] found the temperature sensor to be highly correlated with leading consumer hardware, but uncorrelated to environmental temperature. Combining the sensor data, the Oura ring has been found by a number of studies [   20   ,   21 ,   22 ] to produce reasonable estimates of sleep behaviour when compared to medical-grade polysomnography equipment. This is remarkable given the significantly lower cost and invasiveness of the Oura ring. Whilst all of the studies report that sleep detection has high sensitivity (and reasonable specificity), the classification of different sleep stages diverges considerably from the polysomnography reference. This, combined with the underlying opaqueness of sleep, made the target variable of this study noisy  1 Because this paper may be of interest to readers from varying backgrounds, it should be noted that the term  feature   is synonymous with terms like   predictor ,   regressor ,   covariate , and   risk factor   ; whilst the   target   variable might be known to others as a   response   variable,   regressand ,   outcome , or   label .  2 In machine learning,   observations   are sometimes called   examples   or   instances , but that is avoided in this paper to prevent confusion.  Page 8\n\nQuantified Sleep : 2   DATA SOURCES   Gianluca Truda and uncertain. Despite this, the low costs and simplicity of the Oura ring make it an invaluable tool for QS research in the domain of sleep. The Oura API gives access to daily summaries generated from the raw sensor data. For this study, the   oura_score   variable was of most interest, as it is intended to represent the overall sleep quality during a sleep period. It is a weighted average of sleep duration (0.35), REM duration (0.1), deep sleep duration (0.1), sleep efficiency (0.1), latency when falling asleep (0.1), alignment with ideal sleep window (0.1), and 3 kinds of sleep disturbances: waking up (0.05), getting up (0.05), and restless motion (0.05).  2.2   Supporting data  ‚Ä¢   My electronic activities and screen time were tracked with the   RescueTime   application and exported as daily summaries of how much time was spent in each class of activity (e.g. 3h42m on software development).  ‚Ä¢   My GPS coordinates, local weather conditions, and phonecall metadata were logged using the   AWARE   application for iOS and queried from the database using SQL. Local weather conditions and location information were logged automatically at 15-minute intervals (when possible). Phonecall metadata was logged whenever a call was attempted, received, or made.  ‚Ä¢   Full timestamped logs of all caffeine and alcohol consumption were collected with the   Nomie  app for iOS. Logs were made within 5 minutes of beginning to consume the beverage. Caffeine was measured in approximate units of 100mg and alcohol was measured in approximations of standard international alcohol units.  ‚Ä¢   Logs of activity levels and exercise measured on my phone were exported from Apple‚Äôs  HealthKit   using the   QS Export   app in the form of non-resting kilocalories burned at hourly intervals and activities (running, walking, etc.) logged as they began and ended.  ‚Ä¢   Heart rate was recorded approximately once per minute 3   on a   Mi Band 4   and synchronised with   AWARE   via   HealthKit .  ‚Ä¢   My daily habits ‚Äì meditation, practising guitar, reading, etc. ‚Äì were captured (as Boolean values) daily before bedtime using the   Way of Life   iOS app.  ‚Ä¢   My daily eating window (start and end times) was logged in the   Zero   app as daily summaries.  ‚Ä¢   My mood and energy levels were logged at multiple (irregular) times a day in the   Sitrus   app.  ‚Ä¢   A collection of spreadsheets were used to log the timestamps and quantities of sleep-affecting substances like melatonin and CBD oil.  3 Higher frequencies were used during workout tracking and lower frequencies were used when the device was not worn.  Page 9\n\nQuantified Sleep : 2   DATA SOURCES   Gianluca Truda  Kind   Prefix   Hardware   Software   Format   Frequency   Active/Passive   Hoogendoorn- Funk [3] categories  Sleep   oura   Oura ring, 2nd gen.   Oura API   JSON   Daily summaries   Passive   Physical Readiness   oura   Oura ring, 2nd gen.   Oura API   JSON   Daily summaries   Passive   Physical Computer activity   rescue   Personal computer   RescueTime   CSV   Daily summaries   Passive   Mental & Cognitive GPS coordinates   aw_loc   iPhone 8   AWARE v2   SQL   ~15 mins   Passive   Environmental Barometric pressure   aw_bar   iPhone 8   AWARE v2   SQL   ~15 mins   Passive   Environmental Local weather condi- tions aw_weather   iPhone 8   AWARE v2   SQL   ~15 mins   Passive   Environmental Phonecall metadata   aw_call   iPhone 8   AWARE v2   SQL   ~15 mins   Passive   Social, Environmental Activity / Exercise   hk   iPhone 8, Mi Band 3, Oura ring Apple HealthKit   CSV   Hourly summaries   Passive   Physical Heart rate   aw_hr   Mi Band 3   AWARE v2   SQL   ~1 min   Passive   Physical Caffeine and Alcohol   nomie   iPhone 8   Nomie app   CSV   Timestamped logs   Active   Diet Habits   wol   iPhone 8   Way of Life app   CSV   Daily   Active   Mental   &   Cognitive, Psychological,   Situa- tional Eating / Fasting peri- ods zero   iPhone 8   Zero app   CSV   Daily summaries   Active   Physical, Diet Mood and Energy   mood   iPhone 8   Sitrus app   CSV   Timestamped logs   Active   Psychological Melatonin use   melatonin   N/A   Spreadsheet   CSV   Timestamped logs   Active   Diet CBD use   cbd   N/A   Spreadsheet   CSV   Timestamped logs   Active   Diet Daily metrics   daily   ?   N/A   Spreadsheet   CSV   Daily logs   Active   Environmental, Situa- tional  Table 1: The data sources used to build the dataset for this study. The prefix column indicates the string that the feature names in the dataset inherit from their source. These prefixes help associate features with their sources and allow easier grouping of features.   ?   Other prefixes: location, city, country, travelling. Page 10\n\nQuantified Sleep : 3   DATA WRANGLING   Gianluca Truda  3   Data wrangling  The sampling intervals of the data sources ranged from below 1 minute to a full   24   hours. Much of the data was necessarily at irregular intervals because it was an event log (e.g. having coffee or taking melatonin). The data sources were all structured, but were a mix of temporal and numeric types that required different feature engineering and aggregation techniques. Because the target (sleep quality) was calculated at a daily interval, all the data needed to be up- or down-sampled accordingly. This section details how the heterogeneous data sources were ingested (¬ß3.1), how custom feature engineering was used to align (¬ß3.2) and aggregate (¬ß3.3) the different classes of time series, and how the sources were concatenated into a unified dataset (¬ß3.5).  3.1   Data ingestion  Each data source had its own bespoke data ingester that ultimately fed into a single unified view from which features could be engineered to produce a dataset (Fig. 1). Each ingester is a function responsible for reading a data source in its source format, transforming it into a dataframe, renaming the columns with appropriate conventions and a descriptive prefix, then returning the dataframe. This modularity allowed for iterative development during this study. It also allows the downstream code to generalise to future studies on different data sources.  3.2   Midnight unwrapping  Because the data typically showed one sleep pattern per night, the window size for observations in this study was necessarily one sleep-wake cycle (i.e. one day). Because sleep runs over midnight, it was essential to select another time as the point around which each ‚Äúday‚Äù was defined. To determine this, temporal histograms of important activities like sleep, food consumption, and exercise were plotted (e.g. Fig. 3). From this, a time of 05:00 was selected as the offset point. A window size of 24 hours was then applied from that reference. For instance, alcohol and caffeine consumed between midnight and 05:00 count towards aggregates for the   previous   day. This simple technique preserves causal relationships between input features and the target, as the order of events is preserved.  Figure 3: Temporal histograms for for alcohol and caffeine consumption, illustrating how a reference time of 05:00 was selected for midnight unwrapping. Page 11\n\nQuantified Sleep : 3   DATA WRANGLING   Gianluca Truda The summary date (based on 05:00 offset) was generated for each timestamp in each data source. For instance, if alcohol was logged at   2020-04-07 01:03:41 , the summary date was set to   2020-04-06 . All records were then grouped on that summary date attribute, with specific time-domain aggrega- tions applied over the attributes to produce numerical features. This was informed by intuition and domain knowledge and thus the aggregations varied across data sources.  3.3   Transformations  The unified dataset required all sources to be sparse daily summaries. This required aggregations and interpolations. The data sources fell into three groups: 1.   Daily summaries :   those sources that were already daily summaries (e.g.   Oura, Zero, RescueTime). These required no further adjustment, provided their datestamp format was correct. 2.   Event logs : those that were records of the date and time that events occurred (e.g. caffeine, alcohol, melatonin, calls). There sources needed to be   pivoted   into wide format. The dates were then interpolated to daily summaries. Events occurring on the same day were aggregated. 3.   Intra-day samples : higher-frequency records (e.g. weather, location, heart rate). These sources needed aggregation to produce daily summaries. Fig. 4 illustrates how such transformations would take place using highly-simplified scenarios. 2020-05-02  2020-05-03  2020-05-04  138  102  192  78  113  109  73  81  86 Date   Deep sleep REM sleep   Score  2020-05-02  2020-05-02  2020-05-04  00:01  00:02  23:59  63  65  81 Date   Time   Heart rate  2020-05-04   23:58   92  ...  2020-05-04   09:01   Coffee  2020-05-02  2020-05-02  08:12  09:45  Coffee  Coffee Date   Time   Event  2020-05-03   22:17   Alcohol  2020-05-02  2020-05-03  2020-05-04  Date  138  102  192  78  113  109  73  81  86 Deep sleep REM sleep   Score  2  0  1  0  1  0  Coffee   Alcohol  74  78  92  32  29  43  HR avg.   HR std.  2020-05-02  2020-05-03  2020-05-04  2  0  1  0  1  0 Date   Coffee   Alcohol  2020-05-02  2020-05-03  2020-05-04  74  78  92  32  29  43 Date   HR avg.   HR std.  Daily summaries Event logs Intra-day samples  Pivoting & aggregating Aggregating  Figure 4: Toy examples of how the three kinds of data source in this study were transformed prior to concatenation into the unified dataset. Page 12\n\nQuantified Sleep : 3   DATA WRANGLING   Gianluca Truda  3.4   Aggregation techniques  When collapsing event logs and intra-day samples into daily summaries, aggregation functions summarise the distribution. The choice of aggregation functions needs to consider the original data source and the downstream learning pipeline. For continuous variables (e.g.   heart rate), standard summary statistics ‚Äî minimum, mean, maximum, standard deviation ‚Äî capture the shape of the data well. This is particularly true when the variable is close to a normal distribution, which many QS sources are. For categorical variables, one-hot encoding and summation were used to aggregate data. For event logs (e.g. coffee and alcohol consumption), counts are the most intuitive aggregation. Because the times that the events took place is also important, specialised temporal aggregation techniques were needed.  3.4.1   Aggregating temporal data  For event logs, the   hour   of occurrence was encoded as a numeric feature along with the quantity, allowing aggregation with   min ,   max , and   range   functions. Hourly resolution is a reasonable level given the inherent noise in the data. Caffeine data is shown by way of an example:  Summary date   Value sum   Hour min   Hour max   Hour range  2020-06-12   2.0   12   14   2 2020-06-13   1.0   13   13   0 2020-06-15   2.0   11   13   2 Because midnight unwrapping had been applied, the   net   hour of occurrence was used. So having a last beer at 1AM on Saturday would result in the   net_hour_max   feature on   Friday   having a value of 25.  3.4.2   Aggregating location data with geohashes  High-frequency GPS data has huge potential for building information-rich features, but poses two major challenges. Firstly, not all GPS measurements have the same level of accuracy, due to signal availability and power-saving measures. Secondly, comparing or aggregating coordinates is difficult and ill-defined. One solution is to manually define regions as places of interest and calculate which GPS coordinate pairs fall within those regions. This proves to be very computationally expensive and time consuming. Instead, this study used the   geohash   system [23] (Fig. 5). Geohashing recursively divides the earth into 32-cell grids that are each codified with an alphanumeric sequence. Because geohashes are based on the mathematics of z-order curves, they offer some useful properties like arbitrary precision and fast encoding. For example, the GPS coordinates of the Vrije Universiteit can be mapped to a level-6 geohash:   (52 . 3361 ,   4 . 8633)   ‚Üí   u173wx , which corresponds to a rectangle with an area of   0 . 7   km. But by simply truncating the last 3 characters, we can ‚Äúzoom out‚Äù to   u17 , which covers the northern half of the Netherlands. Page 13\n\nQuantified Sleep : 3   DATA WRANGLING   Gianluca Truda  Figure 5:   Illustration of the geohash system and example of the level-6 geohash for the Vrije Universiteit [24]. The variable precision of geohashes helps overcome the GPS accuracy problem. Reducing pairs of GPS co-ordinates to single alphanumeric strings with well-defined neighbourhood properties solves the aggregation problems of GPS data. The geohash   encode   function was mapped over all 61 000 GPS values in the dataset to generate the level-12 geohashes in seconds. By simply truncating digits from the ends of these level-12 geohashes, features were generated for levels 5 through 9. These levels correspond to blocks ranging from  25 m 2   to   25 km 2 , capturing location information at a variety of resolutions. With this in place, daily aggregation was performed in two ways: (1) by counting the number of unique geohashes from each level (5-9) for that day, (2) by finding the 10 most common level-5 geohashes over the entire dataset and counting the proportion of logs that matched each in that day. This produced 15 features that summarised the locations and movements of the day in an efficient format.  3.5   Dataset concatenation  All the preprocessed data sources were sequentially concatenated on the summary date column using a   left join   operation. The sleep dataframe was used as the starting object. This served two purposes. Firstly, it prevented the need for interpolating dates, as the sleep data was complete. Secondly, it automatically resulted in all rows being trimmed to match the start and end of the target feature (contained in the sleep data). This produced a unified dataset with 789 observations (rows) and 309 columns, of which 271 were numeric features. Because the data from the Oura ring contained numerous linear components of the target feature, there was a risk of data leaks.   For instance,   oura_yesterday_total   alone contributes   35%   of the   oura_score   target. But these variables were relevant to predicting future nights of sleep. To remedy this, all variables with the   oura_   prefix were copied, shifted one day later, and re-prefixed with   sleep_yesterday_ . Before fitting the model, the features with the   oura_   prefix were always dropped. This way, each observation had no features leaking information about the target, yet still included useful information about prior sleep behaviour. Page 14\n\nQuantified Sleep : 4   ANALYSIS OF DATASET PROPERTIES   Gianluca Truda  4   Analysis of dataset properties  4.1   Time period  The subset of the data used in this study ran for 472 days from mid-October 2019 to mid-January 2021. Some   65%   of this time was under various restrictions due to the Covid-19 pandemic. This meant much less variety in location and much more consistent patterns of behaviour, due to the stay-at-home orders. This formed a natural experiment by keeping many factors consistent from March 2020 to December 2020. On one hand, this produced a more ‚Äúcontrolled‚Äù experiment, with fewer free variables. On the other hand, the unique circumstances mean that the results may not generalise as well. Moreover, a lack of variability in features makes them less useful to a predictive model [   10   ]. This can result in highly-relevant variables being absent in the final model because they remained consistent during the course of the lockdown. To mitigate this, data from 5 months of pre-pandemic conditions was retained.  4.2   Outliers  It is essential to differentiate   variational   outliers from   measurement-error   outliers [   3   ]. The former are a legitimate result of natural variation in a system and must be retained in order to build a fully-descriptive model. The latter are a result of failed sensor readings, corrupted data, or erroneous data entry. These measurement errors add noise to the dataset that makes it more challenging to fit a model to the underlying signal. They should therefore be removed. Unfortunately, it is often difficult to differentiate the two types of outlier. To err on the side of caution, minimal outlier removal was used in this study. The focus of the study was sleep quality, so the most relevant sleep features were assessed to detect outliers. By inspecting the distributions and linear relationships in the sleep data 4 , the presence of some outliers was apparent. Both the sleep efficiency and overall sleep score were negatively skewed ‚Äî with potential outliers in the left tail. Chauvenet‚Äôs criterion is a technique to find observations that have a probability of occurring lower than   1  cN   , where   N   is the number of observations and   c   is a strictness factor [ 3 ].   Chauvenet‚Äôs criterion ( c   = 2 ) identified a total of 6 outliers across the 4 key sleep features: score, total, efficiency, duration. All but one of these outliers pre-dated the intended timespan of the study, and that outlier was removed. For the non-target features, distribution plots and 5-number summaries were inspected to detect erroneous measurements. For instance, a heart rate of 400 would have been clearly erroneous. No values were deemed obvious errors 5 .  4 See Fig. 24 in the Appendices.  5 It is, of course, possible that some data-entry errors or measurement errors made it past this conservative filter, adding further noise to the data.  Page 15\n\nQuantified Sleep : 4   ANALYSIS OF DATASET PROPERTIES   Gianluca Truda  4.3   Normality  Many learning algorithms assume that the target feature is normally distributed [ 25   ,   26 ]. If it significantly differs from a normal distribution, we can either (1) normalise the target feature, or (2) apply a transformation to the model predictions to map them onto the same distribution as the target feature. Neither of these are ideal. Normalising the target feature makes our model predictions harder to interpret [   27 ]. Transforming the predictions can introduce a number of errors and points of confusion.  Figure 6: Histogram showing the distribution of the target feature for the time period of the study:  oura_score . The median is indicated with a green vertical line. The mean is indicated with a dashed red line. We can see that they are almost identical. Dotted black lines indicate one standard deviation ( œÉ ) in either direction of the mean. The target feature ( oura_score ) followed the general shape of a normal distribution, but with a skewness of   ‚àí 0 . 325   and an excess kurtosis of   0 . 154 , indicating thin tails and a negative skew (Fig. 6). We know that the target is bounded by   [0 ,   100]   and sleep behaviour generally regresses to the mean [   15 ], so there is little chance that the population distribution is extreme [   28 ], even if it is slightly skewed. These heuristics, along with the desire to keep the model interpretable, informed the decision not to transform the target feature.  4.4   Correlation  It is important to understand how features linearly relate with one another (correlation) and with themselves at different points in time (autocorrelation). If features that share a source are highly correlated, we may want to combine them or discard one of them, as this maintains most of the same information (and interpretability), whilst reducing the number of features our model needs to process [   25 ]. More importantly, features that are correlated with the target are strong candidate features for our final model. Page 16\n\nQuantified Sleep : 4   ANALYSIS OF DATASET PROPERTIES   Gianluca Truda  4.4.1   Pairwise correlation with target  At first, we consider only correlations of each feature to the target (Fig. 7). ‚àí\u0004\u0003\b   ‚àí\u0004\u0003\u0007   ‚àí\u0004\u0003\u0006   \u0004\u0003\u0004   \u0004\u0003\u0006   \u0004\u0003\u0007   \u0004\u0003\b   \u0004\u0003   \u0005\u0003\u0004  \u0019\u001e\u001b   \u0010\u000f\u001d\u0014\u0017\u0010 \u001c\u001d   \u001b\u001d \u000f\u0010\u0016\u001d  \u0019\u001e\u001b   \u0017\u0014\u000f\u001a\u0019\u0014\u0018\u001d   \u001d \u000f\u0010\u0016\u001d  \u0019\u001e\u001b   \u0013\u001b \u0016\u0019   \u0010\u001c\u001d  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u0017\u0014\u000f\u001a\u0019\u0014\u0018\u001d \u001d\u0014\u0017\u0010  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u000f\u001e\u001b   \u001d\u0014\u0019\u0018  \u0019\u001e\u001b   \u001a\u0010\u001b\u0014\u0019\u000f \u0014\u000f  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u000f\u0010\u0010\u001a  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001b\u0017\u001c\u001c\u000f  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   !   \u0015\u0010  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001c\u000e\u0019\u001b\u0010 \u001d\u0019\u001d   \u0016  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001d\u0019\u001d   \u0016  \u0019\u001e\u001b   \u0013\u001b   \u001f\u0010\u001b   \u0012\u0010  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   !   \u0010\u000f\u001d\u0014\u0017\u0010 \u0010\u0018\u000f \u000f\u0010\u0016\u001d  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u0016\u0014\u0012\u0013\u001d  \u0019\u001e\u001b   \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010   \u000e\u001d\u0014\u001f\u0014\u001d!   \u0016  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010 \u001a\u001b\u0010\u001f\u0014\u0019\u001e\u001c \u0018\u0014\u0012\u0013  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001c\u000e\u0019\u001b\u0010 \u000f\u0010\u0010\u001a  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001c\u000e\u0019\u001b\u0010  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u0019\u0018\u001c\u0010\u001d \u0016   \u001d\u0010\u0018\u000e!  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010   \u000e\u001d\u0014\u001f\u0014\u001d!   \u0016  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010 \u001b\u0010\u001c\u001d\u0014\u0018\u0012 \u0013\u001b  \u0019\u001e\u001b   \u0019\u0018\u001c\u0010\u001d \u0016   \u001d\u0010\u0018\u000e!  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010 \u001a\u001b\u0010\u001f\u0014\u0019\u001e\u001c \u000f   !  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001c\u000e\u0019\u001b\u0010 \u001b\u0010\u0017  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001b\u0010\u0017  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010 \u001b\u0010\u000e\u0019\u001f\u0010\u001b! \u0014\u0018\u000f\u0010  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u0017\u0014\u000f\u001a\u0019\u0014\u0018\u001d   \u001d \u000f\u0010\u0016\u001d  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010 \u001d\u0010\u0017\u001a\u0010\u001b   \u001d\u001e\u001b\u0010  \u0019\u001e\u001b   \u001d\u0010\u0017\u001a\u0010\u001b   \u001d\u001e\u001b\u0010 \u001d\u001b\u0010\u0018\u000f \u000f\u0010\u001f\u0014   \u001d\u0014  \u0019\u001e\u001b   \u001d\u0010\u0017\u001a\u0010\u001b   \u001d\u001e\u001b\u0010 \u000f\u0010\u001f\u0014   \u001d\u0014\u0019\u0018  \u0019\u001e\u001b   \u001d\u0010\u0017\u001a\u0010\u001b   \u001d\u001e\u001b\u0010 \u000f\u0010\u0016\u001d  \u0019\u001e\u001b   \u001b\u0010   \u001d\u0013   \u001f\u0010\u001b   \u0012\u0010  \u0019\u001e\u001b   \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010 \u001a\u001b\u0010\u001f\u0014\u0019\u001e\u001c \u000f   !  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001c\u000e\u0019\u001b\u0010 \u0016   \u001d\u0010\u0018\u000e!  \u0019\u001e\u001b   \u001b\u0017\u001c\u001c\u000f  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001c\u000e\u0019\u001b\u0010   \u0016\u0014\u0012\u0018\u0017\u0010\u0018\u001d  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001d\u0010\u0017\u001a\u0010\u001b   \u001d\u001e\u001b\u0010 \u001d\u001b\u0010\u0018\u000f \u000f\u0010\u001f\u0014   \u001d\u0014  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001b\u0010\u001c\u001d\u0016\u0010\u001c\u001c  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   !   \u0010\u000f\u001d\u0014\u0017\u0010 \u001c\u001d   \u001b\u001d \u000f\u0010\u0016\u001d  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u0013\u001b \u0016\u0019   \u0010\u001c\u001d  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u0013\u001b   \u001f\u0010\u001b   \u0012\u0010  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001d\u0010\u0017\u001a\u0010\u001b   \u001d\u001e\u001b\u0010 \u000f\u0010\u001f\u0014   \u001d\u0014\u0019\u0018  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001d\u0010\u0017\u001a\u0010\u001b   \u001d\u001e\u001b\u0010 \u000f\u0010\u0016\u001d  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001a\u0010\u001b\u0014\u0019\u000f \u0014\u000f  \u0019\u001e\u001b   \u001c\u000e\u0019\u001b\u0010 \u000f\u0014\u001c\u001d\u001e\u001b   \u0018\u000e\u0010\u001c  \u0019\u001e\u001b   \u0010\u000f\u001d\u0014\u0017\u0010 \u0010\u0018\u000f \u000f\u0010\u0016\u001d  \u0019\u001e\u001b   \u001b\u0010\u001c\u001d\u0016\u0010\u001c\u001c  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001c\u000e\u0019\u001b\u0010 \u0010\u0011\u0011\u0014\u000e\u0014\u0010\u0018\u000e!  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u0010\u0011\u0011\u0014\u000e\u0014\u0010\u0018\u000e!  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010 \u001c\u0016\u0010\u0010\u001a   \u0016   \u0018\u000e\u0010  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   !   \u001b\u0010   \u001d\u0013   \u001f\u0010\u001b   \u0012\u0010  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001c\u000e\u0019\u001b\u0010 \u000f\u0014\u001c\u001d\u001e\u001b   \u0018\u000e\u0010\u001c  \u0019\u001e\u001b   \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010 \u001d\u0010\u0017\u001a\u0010\u001b   \u001d\u001e\u001b\u0010  \u0019\u001e\u001b   \u0015\u0010  \u0019\u001e\u001b   \u001c\u000e\u0019\u001b\u0010 \u0016   \u001d\u0010\u0018\u000e!  \u0019\u001e\u001b   \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010 \u001b\u0010\u001c\u001d\u0014\u0018\u0012 \u0013\u001b  \u0019\u001e\u001b   \u0010\u0011\u0011\u0014\u000e\u0014\u0010\u0018\u000e!  \u0019\u001e\u001b   \u001c\u000e\u0019\u001b\u0010 \u0010\u0011\u0011\u0014\u000e\u0014\u0010\u0018\u000e!  \u0019\u001e\u001b   \u001d\u0014\u0017\u0010\"\u0019\u0018\u0010  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001d\u0014\u0017\u0010\"\u0019\u0018\u0010  \u0019\u001e\u001b   \u001c\u000e\u0019\u001b\u0010   \u0016\u0014\u0012\u0018\u0017\u0010\u0018\u001d  \u0019\u001e\u001b   \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010 \u001b\u0010\u000e\u0019\u001f\u0010\u001b! \u0014\u0018\u000f\u0010  \u0019\u001e\u001b   \u001c\u000e\u0019\u001b\u0010 \u000f\u0010\u0010\u001a  \u0019\u001e\u001b   \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010 \u001c\u0016\u0010\u0010\u001a   \u0016   \u0018\u000e\u0010  \u0019\u001e\u001b   \u000f\u0010\u0010\u001a  \u0019\u001e\u001b   \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010  \u0019\u001e\u001b   \u0016\u0014\u0012\u0013\u001d  \u0019\u001e\u001b   \u0017\u0014\u000f\u001a\u0019\u0014\u0018\u001d \u001d\u0014\u0017\u0010  \u0019\u001e\u001b   \u001b\u0010\u0017  \u0019\u001e\u001b   \u001c\u000e\u0019\u001b\u0010 \u001b\u0010\u0017  \u0019\u001e\u001b   \u000f\u001e\u001b   \u001d\u0014\u0019\u0018  \u0019\u001e\u001b   \u001c\u000e\u0019\u001b\u0010 \u001d\u0019\u001d   \u0016  \u0019\u001e\u001b   \u001d\u0019\u001d   \u0016  \u0019\u001e\u001b   \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010 \u001a\u001b\u0010\u001f\u0014\u0019\u001e\u001c \u0018\u0014\u0012\u0013  \u0019\u001e\u001b   \u001c\u000e\u0019\u001b\u0010  \u0019\u001b\u001b\u0010\u0016   \u001d\u0014\u0019\u0018   of sleep variables with target (oura_score) ‚àí\u0004\u0003\u0007   ‚àí\u0004\u0003\u0006   ‚àí\u0004\u0003\u0005   \u0004\u0003\u0004   \u0004\u0003\u0005   \u0004\u0003\u0006  '(+-!\u0019!\u001e&\",)!\u001e+\u001e  \u001c(.'-+2\u0019\u0015\u0014\u0012  \u001c\"-2\u0019\u0010&,-\u001e+\u001d\u001a&  \u001a0\u0019\u001a\u001c-\"/\u0019\u001c2\u001c%\"'  \u001a0\u00190\u001e\u001a-!\u001e+\u0019)+\u001e,,.+\u001e\u0019,-\u001d  +\u001e,\u001c.\u001e\u0019-(-\u001a%\u0019\u001d\",-+\u001a\u001c-\"'   \u0019-\"&\u001e  \u001a0\u00190\u001e\u001a-!\u001e+\u00190\"'\u001d\u0019,)\u001e\u001e\u001d\u0019&\u001e\u001d\"\u001a'  \u001a0\u00190\u001e\u001a-!\u001e+\u0019+\u001a\"'\u0019,-\u001d  +\u001e,\u001c.\u001e\u0019'\u001e0,  +\u001e,\u001c.\u001e\u0019\u001d\",-+\u001a\u001c-\"'  '(&\"\u001e\u0019\u001c\u001a\u001f\u0019/\u001a%.\u001e\u0019,.&  \u001a0\u00190\u001e\u001a-!\u001e+\u00190\"'\u001d\u0019,)\u001e\u001e\u001d\u0019,-\u001d  '(&\"\u001e\u0019\u001c\u001a\u001f\u0019'\u001e-\u0019!(.+\u0019&\u001a1  \u001a0\u0019   \u001e(!\u001a,!   \u0019'.&\u0019.'\"*.\u001e  \u001a0\u00190\u001e\u001a-!\u001e+\u0019\u001c%(.\u001d\"'\u001e,,\u0019&\u001e\u001d\"\u001a'  +\u001e,\u001c.\u001e\u0019\u001e'-\u001e+-\u001a\"'&\u001e'-  \u001a0\u0019   \u001e(!\u001a,!   \u0019'.&\u0019.'\"*.\u001e  '(&\"\u001e\u0019\u001c\u001a\u001f\u0019'\u001e-\u0019!(.+\u0019+\u001a'   \u001e  '(&\"\u001e\u0019\u001c\u001a\u001f\u0019'\u001e-\u0019!(.+\u0019,)+\u001e\u001a\u001d  0(%\u0019&(+'\"'   \u0019#(.+'\u001a%  0(%\u0019\u001f(+&\u001a%\u0019&\u001e\u001d\"-\u001a-\"('  \u001a0\u0019!+\u0019!\u001e\u001a+-\u0019+\u001a-\u001e\u0019&\u001e\u001d\"\u001a'\u0019&(+'  \u001a0\u00190\u001e\u001a-!\u001e+\u0019!.&\"\u001d\"-2\u0019&\u001e\u001d\"\u001a'  \u001a0\u0019!+\u0019!\u001e\u001a+-\u0019+\u001a-\u001e\u0019,-\u001d\u0019\u001d\u001a2  +\u001e,\u001c.\u001e\u0019\u001d\u001e,\"   '  \u001a0\u0019!+\u0019!\u001e\u001a+-\u0019+\u001a-\u001e\u0019,-\u001d\u0019\u001e/\u001e  \u001a0\u0019   \u001e(!\u001a,!   \u0019'.&\u0019.'\"*.\u001e  !$\u0019\u001a\u001c-\u0019\u0006!  +\u001e,\u001c.\u001e\u0019/\u001e+2\u0019\u001d\",-+\u001a\u001c-\"'  !$\u0019\u001a\u001c-\u0019\u0005!  3\u001e+(\u0019'\"   !-\u0019\u001e\u001a-\"'  0(%\u0019/\u001e   \u001e-\u001a+\"\u001a'\u0019\u001d\"\u001e-  \u001a0\u00190\u001e\u001a-!\u001e+\u0019+\u001a\"'\u0019&\u001e\u001d\"\u001a'  !$\u0019\u001a\u001c-\u0019'\"   !-\u0019&\u001e\u001a'  +\u001e,\u001c.\u001e\u0019-(-\u001a%\u0019-\"&\u001e  \u001a0\u0019   \u001e(!\u001a,!   \u0019'.&\u0019.'\"*.\u001e  +\u001e,\u001c.\u001e\u0019,!())\"'  !$\u0019\u001a\u001c-\u0019\u0006\u0006!  !$\u0019\u001a\u001c-\u0019\u0005 4h  rescue_social_network  hk_act_23h  hk_act_ 0h  zero_start_hour_delta  aw_hr_heart_rate_std_morn  aw_loc_speed_max  aw_geohash5_num_unique  nomie_caf_net_hour_min  aw_hr_heart_rate_median_eve  city_Paarl  wol_intensive_workout  wol_take_creatine  aw_weather_cloudiness_std  rescue_productive  rescue_utilities  zero_hours_since_prev_fast  wol_moderate_activity  wol_pescatarian_diet  aw_hr_heart_rate_std_night  rescue_coms_and_scheduling  rescue_total_productice_time  wol_no_alcohol  hk_act_9h  hk_act_ 21h  rescue_very_productice  aw_activ_running  aw_hr_heart_rate_median_night  hk_act_8h  aw_activ_walking  hk_act_16h  hk_act_19h  zero_prev_end_hour_delta  rescue_business  hk_act_1 3h  wol_read_book  is_weekend  rescue_neutral  daily_weekday  daily_year  aw_hr_heart_rate_median_day  hk_act_17h  hk_act_ 20h  zero_hours  aw_activ_automotive  hk_act_4h  wol_brush_teeth_before_bed  aw_loc_altitude_mean  hk_act_7h  rescue_software_dev  hk_act_morn_mean  hk_act_ 3h  hk_act_6h  wol_daily_metrics  hk_act_eve_mean  rescue_reference_and_learning  hk_act_1 0h  aw_weather_humidity_std  hk_act_afternoon_mean  hk_act_5h  hk_act_15h  hk_act_11h  hk_act_1 2h  aw_activ_stationary  hk_act_18h  aw_weather_temperature_min_median  aw_weather_temperature_max_median  aw_weather_temperature_median  aw_weather_pressure_median  wol_caffeinated_drinks_<=_2  wol_no_caffeine_after_3pm  aw_weather_temperature_std  aw_weather_temperature_max_std  aw_weather_temperature_min_std  daily_month  daily_week_no .  country_ZAF  city_Cape Town  Correlation of other variables with target   (oura_score)  Figure 7: Pearson correlations between features and the target ( oura_score ). The left subfigure shows features that originate from the Oura ring, i.e. sleep related. The right subfigure shows features that originate from other data sources. Recall from ¬ß3.5 that the prefix   sleep_yesterday_  is used for a 1-day lag on the   oura_   features to make it easier to remember to remove same-day sleep features that constitute a data leak. So   sleep_yesterday_total   can be interpreted as   oura_total  with a shift of 1 day. As expected, sleep-related features were more strongly correlated with the sleep score than the non-sleep features. Specifically, measures of sleep duration and efficiency had a strong positive correlation with the target ( 0 . 5   ‚â§   r   ‚â§   0 . 9 ). This is expected, knowing that sleep score is a weighted Page 17\n\nQuantified Sleep : 4   ANALYSIS OF DATASET PROPERTIES   Gianluca Truda linear sum over several of these features.   Curiously, a few sleep-related features had no direct correlation with sleep score. Notably, those related to respiration rate and temperature. The bedtime feature had a strong negative correlation with the target ( r   ‚âà ‚àí 0 . 6 ), which is likely because it is considered as part of the ideal sleep window calculation that comprises   10%   of the sleep score. It was important to remove features like this from the dataset prior to training the model, in order to prevent data leaks. The non-sleep features had much weaker correlations with sleep score ( ‚àí 0 . 3   ‚â§   r   ‚â§   0 . 3 ), highlighting that there were no obvious candidate features. The strongest correlations fell into the location, weather, and caffeine categories. Notably, time-related features like the week number and month number showed a notable correlation to sleep quality ( r   ‚âà   0 . 2 ), indicating some trend or seasonality. This would also explain why weather and location features showed strong correlations with the target. Analysis of data stationarity is an essential step (¬ß4.5).  4.4.2   Hierarchical correlational clustering  It is also important to consider how features might correlate with each other. For small numbers of features, correlation matrices are ideal for such analysis. However, these graphics become difficult to interpret when there are more than a dozen features. Instead, this study made use of   agglomerative clustering   of features by their correlations to produce a   dendrogram   (Fig. 8). The dendrogram was generated as follows: First, the features were filtered to only consider those with less than 10% of their values missing. Each of the   n   features then had its absolute Pearson correlation to each other feature calculated, producing an   n   √ó   n   correlation matrix.   Next, the pairwise Euclidean distances between each row of absolute correlations were calculated. Hierarchical clustering was performed on these pairwise distances using the Nearest-Point algorithm. These clusters were then plotted as a coloured dendrogram (Fig. 8). This hierarchical approach to correlations between features is immensely useful and offers more intuitive interpretations than a standard correlation matrix.   By summarising the correlations between all   n   √ó   n   pairs of features into distances in   n -dimensional space, the complexity of the relationships is interpreted for us. This highlights groups of features that are strongly correlated with one another but not with other clusters of features. Moreover, we can use the dendrogram representation to interpret just how correlated subsets of features are. This is immensely useful for validating (and refining) feature engineering in order to achieve the higher sample efficiency needed to model wide QS data. In Fig. 8 we can see that the hourly movement data (prefix   hk_act_ ) clustered together in chunks of time and was highly correlated with aggregation features for this data.   Specifically, we can see that movement between the hours of 1 and 7 was very highly correlated and therefore also highly correlated with their mean ( hk_act_night_mean ) (Fig. 8b). This tells us that most of the (linear) information about nighttime movement can be captured from a single feature that averages over the hourly features. We can also notice that there was low correlation between different time windows of movement features. The morning, afternoon, and evening features clustered within their time windows but not across them (Fig. 8c). This tells us that the different windows of time throughout the day ‚Äî morning, afternoon, evening, night ‚Äî capture different information that might be relevant to our model. A final observation from the dendrogram is that location data formed a number of related, but strongly-separated clusters. Geohashes gave similar information and were clustered (Fig. 8e), but were very far from the cluster of features relating to city, country, and hemisphere (Fig. 8d). This suggests that two levels of resolution are important ‚Äî frequent changes in location at a resolution of metres, and infrequent changes in location at a resolution of kilometres. Page 18\n\nQuantified Sleep : 4   ANALYSIS OF DATASET PROPERTIES   Gianluca Truda b.  c.  d.  e.  a.  Figure 8: Dendrogram of hierarchical correlational clustering for all features with low missing data. Each of the   n   features were clustered based on their distance in   n -dimensional space to other features from the   n   √ó   n   correlation matrix. The dendrogram shows features on the vertical axis and pairwise Euclidean distance on the horizontal axis. Vertices indicate where clusters join into superclusters. The distance between clusters is represented by their vertical distance on the vertical axis. Colour-coding is used to illustrate primary clusters based on a 70% similarity threshold. Note that some feature names are replaced with   location x   to protect private data. Page 19\n\nQuantified Sleep : 4   ANALYSIS OF DATASET PROPERTIES   Gianluca Truda  4.4.3   Autocorrelation  Autocorrelation can be detected by computing the correlation between a feature and a copy of the feature where values are shifted (lagged) by 1 or more points. Autocorrelation gives us an indication of how well a feature predicts its own future values [   29 ]. This was immensely useful in this study because of the inherent time series nature of most QS data. Behavioural and biological patterns often have periodic variations or trends over time. For example, it is common for people to dramatically shift their sleeping patterns on weekends compared with weekdays. This can often be detected by spikes in autocorrelation at intervals of 6-7 days ‚Äî last week somewhat predicts this week. For this study, the autocorrelation of each feature was analysed for varying shifts (lags) up to 25 days. Four interesting patterns are presented in Fig. 9.  (a) No autocorrelation.   (b) Trending autocorrelation.  (c) Periodic autocorrelation.   (d) Trending autocorrelation.  Figure 9: Notable autocorrelation patterns observed across features. Each plot shows the correlation on the vertical axis and the lag (in days) on the horizontal axis. The shaded regions represent a 95% confidence interval for the null hypothesis at each lag level, so values that fall within this region are unlikely to be significant. We can see that the target feature ( oura_score ) had a very low degree of autocorrelation (Fig. 9a). This is extremely surprising, as it implies that previous sleep quality does not have a strong linear relationship to current sleep quality. This highlights how difficult the task of predicting sleep quality is. Interestingly, a lag of 1 day had a small negative correlation with the target ( r 1   ‚âà ‚àí 0 . 2 ). This suggests that sleep oscillates in quality on adjacent nights. We can also see that some features showed a clean trend of autocorrelation with respect to lag (Fig. 9b and 9d). This is to be expected Page 20\n\nQuantified Sleep : 4   ANALYSIS OF DATASET PROPERTIES   Gianluca Truda of a number of features, such as habits and temporally-derived features like   sleep_balance . What is worth noting is the lag point at which the autocorrelation becomes statistically insignificant. This gives us a rough indication of how many days of history may be relevant for our model. Finally, we can see that some features displayed prominent periodicity (Fig. 9c). Productivity time is derived from time spent on my laptop working with specific software or websites that are marked as productive. We can see from the spikes in the plot that the periodicity had a peak-to-peak length of exactly 7 days. This makes a great deal of sense, as my productivity levels are highly influenced by the day of the week.  4.5   Stationarity  A key principle of modelling time series data is that it should be stationary. Specifically, it should exhibit no periodicity or trends, leaving only irregular variations that we attempt to predict using other features [ 3   ]. However, most real-world data is not stationary. As we have already seen, many of the relevant features in this dataset are periodic.  (a) Trend of mean for target.   (b) Trend of variance for target.  Figure 10: Scatterplots of target features ( oura_score ) over time (indexed observations). The left figure superimposes trends of the 7- and 30- day rolling mean. The right figure superimposes trends of the 7- and 30- day rolling variance. The augmented Dickey-Fuller test can be used to assess the stationarity of a sequence of data [   30 ]. This test was applied to each feature in the dataset. A total of 34 input features were found to be non-stationary ( p >   0 . 05 ). Many of these were explicitly temporal features like the year, month, or day. Many were naturally non-stationary data like weather patterns. What we are most concerned with, however, is whether the target feature is stationary. If not, techniques like statistical differencing need to be applied before building a model [ 3 ]. Unfortu- nately, such applications make interpretation much more difficult. Fortunately, the target feature ( oura_score ) was found to be stationary with reasonable confidence ( p <   0 . 01 ). This means that variations had no major periodic or trending patterns.   This is illustrated visually with rolling averages of both the mean and variance in Fig. 10. This was very fortunate for this study, as the interpretation step is easier if we do not have to transform the target feature. This stationarity of the sleep features was likely a happy result of the pandemic conditions. The data included for modelling begins from October 2019. When including data back to December 2018, the target was less likely to be stationary ( p   ‚âà   0 . 09 ). Page 21\n\nQuantified Sleep : 5   OVERCOMING MISSING DATA   Gianluca Truda  5   Overcoming missing data  5.1   Theory of missing data  There are three main types of missing data identified in the statistics literature [   31 ]. Understanding their different properties is integral to selecting robust imputation techniques for filling in the missing values [11].  Missing completely at random (MCAR) : Missing values are considered MCAR if the events that caused them are independent of the other features and occur entirely at random. This means that the nullity (missingness) of the values is unrelated to any of our study features and we can treat the data this   is   present as a representative sample of the data as a whole. Unfortunately, most missing values are not MCAR [11].  Missing at random (MAR) : Despite the name, MAR occurs when the nullity is   not   random, but can be fully accounted for by other features that have no missing values. For instance, I did not explicitly log the city where I slept every night, but the data is MAR because it is fully accounted for by the date index and geohash features, from which I can accurately infer the missing values for the city.  Missing not at random (MNAR) : Data is MNAR when the nullity of the value is related to the reason that it is missing. This makes the dataset as a whole biased. For instance, I am more likely to forget to log my mood when I am very happy or utterly miserable. The missing extreme values in the data are thus MNAR.  5.2   Analysis of missing data  The absence of data points is a major factor in Quantified-Self (QS) projects [ 3 ], especially when combining data from multiple sources. An upfront analysis of the quantity and distribution of missing values is essential before missing values can be rectified. Missing data matrices are an invaluable visualisation in this regard. They give an impression of the dataset in the same rows-as- observations and columns-as-features format that we are accustomed to, with shading to indicate where data is present. In Fig. 11, the entire dataset is rendered as on of these matrices using the superb   missingno   library [   32 ]. It is important to note that this version of the dataset included more than the 15-month timeline of the final dataset. This was for illustrative purposes. Much of the top half of the dataset was ultimately discarded before modelling. In Fig. 12, the columns are grouped by the source prefix (Table 1) in order to get a better understanding of which data sources are to blame for which missing data. When combining columns from the same source, missing values took precedence. In other words, the simplified matrix represents the worst-possible combination of the columns from that source, in terms of nullity. Anecdotally, these patterns are typical of multiple-source QS projects. New data sources are added over time, whilst others fall out of use. Some data is tracked very consistently (often automatically), whilst many of the manually-tracked sources have short sequences of missing values spread all over ‚Äî due to poor adherence to tracking protocols. We can see from the missing data matrices that the sources used changed dramatically over time. The AWARE ( aw ), Nomie, and Zero sources were only adopted later on. Fortunately for the focus of this study, the sleep data ( oura ) was complete and had no missing data, as it was automatically tracked and the ring was worn every night. By having a target feature free of missing data, this study was well-positioned to mitigate the missing data in the other features. Page 22\n\nQuantified Sleep : 5   OVERCOMING MISSING DATA   Gianluca Truda 285 123 1 789  Figure 11: Missing data matrix for the entire raw dataset. The vertical axis represents rows in the dataset (corresponding to daily observations). The horizontal axis represents columns in the dataset (corresponding to features). The dashed blue line indicates the start of the period of time considered for this study. The sparkline on the right indicates the general shape of the data completeness, with the rows of minimum and maximum nullity labelled with a count of the non-missing values in the rows.  Figure 12: Missing data matrix for groups of features in the raw dataset. The vertical axis represents rows in the dataset (corresponding to daily observations). The horizontal axis represents columns in the dataset (corresponding to features). The dashed blue line indicates the start of the period of time considered for this study. The sparkline on the right indicates the general shape of the data completeness, with the rows of minimum and maximum nullity labelled with a count of the non-missing values in the rows. The column names are the prefixes of each source (see Table 1). Page 23\n\nQuantified Sleep : 5   OVERCOMING MISSING DATA   Gianluca Truda  5.3   Approaches to handle missing data  Most modelling techniques assume complete data, meaning that missing values pose a major problem [ 25 ].   There are three common strategies for dealing with missing data: omission, full analysis, and imputation [31, 25, 33].  Omission   (dropping): The most common approach is to omit sections of the dataset that contain missing values. Typically, this involves discarding observations (rows) that contain one or more missing values. This leaves only complete observations, but discards much of the information in the original dataset. In QS datasets with many features from heterogeneous sources, it is often the case that the majority of observations contain at least one missing value. In such cases, dropping all these rows would discard almost all of the dataset. Some features (columns) have more missing values than others, so it is often desirable to discard the worst-offending features first, then discard the observations with missing values from the features that remain. This often results in retaining more overall information. In n-of-1 QS studies, we typically cannot afford to discard much data, so finding the right trade-off between retaining observations and features is a challenge.  Full analysis : Some learning algorithms are designed to use all available data and to tolerate missing values. Many of these are beyond the scope of this study, but the XGBoost implementation of gradient boosted Decision Trees is of interest. XGBoost is a well-engineered ensemble technique that learns default directions in the branches of the Decision Trees that are taken when missing values are encountered [   34 ]. This leverages the values that are present to learn reasonable estimates for missing values. XGBoost is also a high-performing algorithm [   34 ] and was thus a prime candidate from the outset of this study.  Imputation : Instead of omitting missing values, we can try to estimate them using imputation. This has the advantage of retaining the size and shape of the dataset, but the disadvantage of incorporating estimation error into the data ‚Äî resulting in additional noise for the model to overcome [   31 ,   33 ]. This study employed a variety of imputation strategies (¬ß5.5) in combination and compared the resulting model performance. When our data is an ordered time series, we can use a specific kind of imputation called interpolation [ 3 ]. This fills the gaps between available samples by assuming some regular rate of change between samples. For most features in the dataset, the sample frequency was too low for interpolation to be viable. One notable exception was the heart rate data, which was sampled over a thousand times each day. This feature was first resampled at intervals of 1 minute to make it regular, then linear interpolation was applied to smooth over discontinuities.  5.4   Knowledge-based filling  Much of the data in observational n-of-1 studies is MAR or MNAR, both of which can be predicted with an accuracy much greater than random guessing [   11 ]. Furthermore, some QS studies have a unique kind of MCAR data that can be filled accurately, albeit not with prediction. We can refer to these as   informative absences . They are the result of the feature engineering step, but can be overcome due to intimate knowledge of the study protocol and adherence ‚Äî a perk unique to QS research. The informative absences resulted from event logs that were aggregated into daily summaries and, in most cases, could simply be filled with a suitable placeholder value. For instance, alcohol consumption was only logged (with a timestamp) when it occurred. Because I was both the subject and the researcher, I can be extremely confident that I almost never failed to log events like alcohol because I was conscious of my own adherence patterns. When the event logs were aggregated, there were very many days where no alcohol was consumed that simply had no data. Because Page 24\n\nQuantified Sleep : 5   OVERCOMING MISSING DATA   Gianluca Truda I was confident that I adhered well to alcohol logging, I could simply fill this missing data with appropriate values indicating that no alcohol was consumed:   0 . 0   for the sum features, and   ‚àí 1 . 0   for the temporal features. I refer to the manual filling of these kinds of MCAR data as   knowledge-based  filling, as it relies on expert and domain knowledge to determine when and what values should be filled. We can see these informative absences in Fig. 12 for   melatonin ,   nomie , and   aw_calls .  5.5   Imputation strategies  After manually filling the informative absences with the knowledge-based approach, many MAR and MNAR values remained. These were imputed using one of several imputation strategies (see Table 2).  5.5.1   Univariate imputation  The most straightforward imputation strategy is univariate imputation. This is where missing values for the   j -th feature are imputed based on the non-missing values for that   j -th feature. In the case of continuous features, the mean or the median of the non-missing values is calculated for each feature. That value is then filled into the missing values for the respective feature. In this study, both mean and median univariate imputation were utilised (see Table 2).  5.5.2   Multivariate imputation  In the case of data that is MAR, the missing values for the   j -th feature may be more accurately imputed when considering each observation   i   individually and conditioning on information from the other features. For instance, a missing value relating to a particular day‚Äôs activity levels could likely be imputed quite accurately based on non-missing values for weather and heart rate for that same day. This is the intuition behind multivariate imputation. Conceptually, each feature   x j   in our data matrix   X   is modelled as a function   f j   of the other features   X ¬¨ j   . A missing value at  x i,j   can then be imputed using the function   f j   ( X i, ¬¨ j   ) . In reality, the implementation of a specific imputation technique might look very different from this conceptual view. In this study, several approaches to multivariate imputation were explored (see Table 2).  5.5.3   Multiple imputation  So far, we have considered single rounds of univariate or multivariate imputation. However, because many of the multivariate imputation techniques are stochastic, it is common to run multiple independent rounds of imputation on the entire dataset, in what is known as multiple imputation. These rounds can then be either (1) compared to select the one that minimises some cost function, or (2) can be aggregated into a single imputed dataset. The aim of these multiple rounds is to achieve a more accurate estimate of the imputed values. However, when the imputed dataset is then used for subsequent modelling, the uncertainty of these estimates is not considered, meaning there is a greater quantity of noise in the data that the model must overcome. To remedy this, some practitioners keep all versions of the dataset generated from the rounds of multiple imputation and concatenate them instead of aggregating them [   35 ]. If the original dataset was   m   √ó   n   in shape, the multiply-imputed dataset is   km   √ó   n   in shape, where   k   is the number of rounds of multiple imputation. This effectively adds many observations that are slight variants of each other to the dataset, in the hope that the downstream model will make sense of the uncertainty in the imputed values. In this study, a number of multiple imputation strategies were employed (see Table 2). For the MICE technique, the imputation rounds were concatenated into a longer dataset to capture the uncertainty [33]. Page 25\n\nQuantified Sleep : 5   OVERCOMING MISSING DATA   Gianluca Truda  5.6   Baseline dataset with missing values  The unified dataset was filtered down to only numeric features from after   2019-10-05 , resulting in 482 observations and 271 features. Features which had more than 70% of their values missing were removed, leaving 234 features. The remaining data showed a bimodal distribution of nullity. That is, 424 observations had fewer than 15 missing values across all 234 features, whilst the other 119 observations had more than 15 missing values across all the features. A subset of 61 observations were ‚Äúpure‚Äù. That is, they had no missing values in any of their features. An additional column ( is_pure ) was appended to the dataset to label these observations. Only these observations were sampled for scoring model performance in later experiments. This had the advantage of isolating the effect of imputation techniques to only the training data, but came with two caveats. Firstly, there was a huge imbalance between pure and impure features (61:421). Secondly, the target distribution differed between these subsets (Fig. 13a). Data-leaking features with the   oura_   prefix were removed. The resulting   with_nans   dataset of 482 observations and 193 features (including the target) was used as the basis for all the imputations and as a non-imputed baseline. The missing values of this dataset are visualised in Fig. 13b. 20   40   60   80   100   120  0.00  0.01  0.02  0.03  0.04  0.05 Density  Distributions of target feature for 'pure' and 'impure' rows  Pure  Impure  (a) Comparison of target distributions. 193 137 1 482   (b) Missing data matrix.  Figure 13: Left: Comparison of target feature (sleep quality) for ‚Äúpure‚Äù observations, which had no missing data in any of their features, and ‚Äúimpure‚Äù observations, which had some missing values. Right: missing data matrix for   with_nans   dataset.  5.7   Quantifying imputation distance  To quantify the change to a dataset from imputation, the imputation distance metric   D imp.   was defined.   What follows is the derivation of the imputation distance metric from foundational principles of relative entropy. The Jensen-Shannon distance (JSD) between two probability arrays   P   and   Q   is defined as:  JSD ( P   ||   Q ) :=  ‚àö   D KL ( P   ‚Äñ M   ) +   D KL ( Q ‚Äñ M   ) 2   (1) where   M   =   P   + Q  2   is the point-wise mean of the arrays   P   and   Q   and   D KL   is the Kullback-Leibler divergence (relative entropy). Page 26\n\nQuantified Sleep : 5   OVERCOMING MISSING DATA   Gianluca Truda To calculate the JSD for two distributions of some feature, we first have to generate probability array   P   and   Q   for each distribution of the feature. We approximate this by constructing   1000  equal-width bins over the range of each distribution and then counting how many of the observed values fall into those bins. These counts are divided by the number of observations to produce a probability array for each distribution. The JSD has a number of desirable properties. Like KL-divergence, it is a principled information- theoretic measure that is non-negative and is zero only when the distributions are identical. Unlike KL-divergence, however, it is   symmetric   and   smoothed , making it more robust [36]. The JSD was used to compute the change in each feature   j   ‚àà   R n   from the original dataset (with missing values)   X   to the imputed dataset   X ‚Ä≤ . The average distance of an imputation   D imp.   could be estimated by taking the arithmetic mean over all   n   features:  D imp. ( X   ||   X ‚Ä≤ ) :=  1  n  n ‚àë  j =1  JSD   [ P   ( x j   )   ||   Q ( x ‚Ä≤  j   ) ]   (2) The average imputation distances relative to the raw dataset were calculated for each imputation strategy (Table 2).  Name   Distance   Scope   Imputation   Implementation  Univariate mean   0.0923   Univariate   Single   SimpleImputer * Univariate median   0.0535   Univariate   Single   SimpleImputer * Iterative Bayesian ridge (50)   0.0986   Multivariate   Multiple   IterativeImputer * MICE (3) [39]   0.2079   Multivariate   Multiple   IterativeImputer * MICE (15) [39]   0.2292   Multivariate   Multiple   IterativeImputer * KNN (K=3)   0.0658   Multivariate   Single   KNN   ‚Ä†  SoftImpute [40]   0.1319   Multivariate   Multiple   SoftImpute   ‚Ä†  Iterative SVD [41]   0.2147   Multivariate   Multiple   IterativeSVD   ‚Ä†  Matrix factorisation [42]   0.1897   Multivariate   Multiple   MatrixFactorization   ‚Ä†  Table 2: Overview of the imputation strategies used in this study. The name is used to refer to the technique in the paper. The distance between the raw dataset and the imputed dataset was computed using the mean Jenson-Shannon (JSD) distance over all the features (¬ß5.7). A larger distance value indicates more dramatic differences between the distributions of the raw and imputed versions of the dataset. The implementation column refers to the Python class used to implement the technique, from either the Scikit-learn   [37] (*) or   fancyimpute   [38] ( ‚Ä† ) libraries. Univariate imputation of the median had the lowest imputation distance across all features. Univariate mean imputation had a much greater distance than univariate median imputation. This is likely because many of the features had non-normal distributions and the median is far less sensitive to outliers.   Iterative SVD and MICE had the highest imputation distances.   Greater numbers of concatenated MICE iterations (15 versus 3) resulted in a greater imputation distance. Page 27\n\nQuantified Sleep : 6   COLLAPSING TIME WITH MARKOV UNFOLDING   Gianluca Truda  6   Collapsing time with Markov unfolding  6.1   Markov assumption  Building a predictive model of sleep requires us to make the Markov assumption [ 43 ] ‚Äî that the current night‚Äôs sleep depends only on a finite fixed number of previous days‚Äô data. Imagine that we are trying to calculate a probability distribution   P   over the possible sleep scores  y t   ‚àà   [0 ,   100]   on day   t , conditioned on all features from the past. Formally, we are trying to model:  P   ( y t   |   X 1: t ‚àí 1 )   (3) where   y t   is the current night‚Äôs sleep score and   X 1: t ‚àí 1   is the matrix of features for all days prior to day   t . For simplicity,   X 1: t ‚àí 1   includes the vector   y 1: t ‚àí 1 , the previous target values. Eq. 3 implies that the sleep on night   t   depends on all past nights of sleep and all past days of other features. In other words, we require the full history. Now, if we make the Markov assumption:  P   ( y t   |   X 1: t ‚àí 1 ) =   P   ( y t   |   X t ‚àí œÑ   : t ‚àí 1 )   (4) we assume that modelling only the past   œÑ   days produces as good an estimate of the current sleep as looking at the full history. This is a very useful assumption, as it allows us to reframe our time series prediction task to an independent-and-identically-distributed (i.i.d.) prediction task. This, in turn, makes many more techniques ‚Äî for both modelling and interpretation ‚Äî available to us. But how can we assume that the Markov property holds for this data? Clearly, if we set   œÑ   =   t  then the Markov property holds trivially, as we are using the full history. So there must be some  œÑ < t   at which the Markov property breaks down for our data. In reality, we do not care where the property first breaks down, but rather where the amount of information retained is sufficient for our prediction needs. We can estimate the optimal   œÑ   value by analysing our data for autocorrelation, then use it to construct an i.i.d. representation that incorporates the Markov property [43]. The autocorrelation analysis from Section 4.4.3, alongside domain knowledge, highlighted that previous days‚Äô behaviour plays a role in the current characteristics and resulting sleep quality. For instance, I may have had a healthy and balanced day today, but if I was up late partying or revising for an exam the night before, then my sleep is likely to be affected. Page 28\n\nQuantified Sleep : 6   COLLAPSING TIME WITH MARKOV UNFOLDING   Gianluca Truda  6.2   Markov unfolding  We can implement this conversion from a time series to an i.i.d. dataset with a technique I dub  Markov unfolding .   We begin with our   m   √ó   n   data matrix   X .   The data in   X t ‚àí œÑ   : t ‚àí 1   (i.e.   the past   œÑ   days) is ‚Äúunfolded‚Äù into a row vector of length   œÑ n . This is repeated for each time point  t   ‚àà   [ œÑ, m ]   and the resulting vectors are stacked onto   X   to produce a new dataset   X ‚Ä≤   with shape  ( m   ‚àí   œÑ   )   √ó   ( œÑ   + 1) n . 5 x 2   5 x 8  ùúè   = 3  1   6  2   7  3   8  4   9  5   10   5  -   - 1   6  2   7  3   8  4   9  1   6  2   7  3   8  10   4   9  -   -  1   6  2   7  3   8  -   -  1   6  2   7  -   -  -   - -   -  Figure 14: Illustrative example of Markov unfolding a   5   √ó   2   dataset into a   5   √ó   8   dataset using lag of   œÑ   = 3 . After removing the missing values, the final dataset is of shape   2   √ó   8   (outlined). Intuitively, we are copying the columns of the original dataset, shifting them down by   1   row, and stacking them as new columns on the right of the dataset. We repeat this with shifts of   2 ,   3 , ..., œÑ   ; stacking the new columns each time. We have to throw away the first   œÑ   rows from the beginning of the dataset as we did not have enough previous states for them, resulting in missing values. We now have a dataset that is a few rows shorter, but   œÑ   + 1   times the width, than what we started with. We can now treat the rows (observations) in our dataset as totally independent, allowing us to use any supervised learning approach that assumes i.d.d. data. The   œÑ   value was selected by analysing the autocorrelation of key features to set an upper limit (in this case,   œÑ   = 7 ). This is intuitive, as many cycles in behaviour occur at a weekly level, so allowing the models to look up to 7 days back is useful for capturing these patterns. For instance, behaviour around activity, working hours, alcohol consumption, and other lifestyle factors often differs dramatically on weekends. These patterns of behaviour (and their effect on sleep) are often a good predictor of the next week‚Äôs behaviour, making them useful features to include. All the numeric features (including the target,   oura_score ) were unfolded for   œÑ   days prior. This went some of the way to incorporating the Markov assumption into the time series, thus allowing each day to be treated as an independent observation. One major drawback of Markov unfolding is that it can result in low feature efficiency. In other words, too many features, with those from farther back (larger   œÑ   ) being only loosely-correlated to the current ones. This sometimes results in the ‚Äúcurse of dimensionality,‚Äù which can prevent the data from being learnable, given the limited number of observations [ 10   ,   3 ]. This is somewhat mitigated by the use of feature selection (¬ß7.1.2). Page 29\n\nQuantified Sleep : 7   MODEL INTERPRETATION   Gianluca Truda  7   Model interpretation  Using predictive models to capture relationships in the data is integral to observational studies. Models can tell us much more than correlations between pairs of features, as they (1) allow us to control for the effects of other features and (2) can be regularised so that they are desensitised to the noise in the data. There is often a trade-off between the quality and explainability of the model [ 44 ]. In order to gain   descriptive   value from a predictive model, we need techniques for interpretation. There are a number of approaches to model interpretation [ 27 ]. Two of the most relevant approaches for observational n-of-1 QS projects are (1) intrinsically-interpretable models and (2) model-agnostic techniques.  7.1   Interpreting model parameters  Some learning algorithms ‚Äî like linear regression and its variants ‚Äî are   intrinsically   interpretable, as their parameters explain the effect of each feature independently of the other features [   27 ]. Consider the following formula, which describes a standard linear model:  ÀÜ y i   =   Œ≤ bias   +  n ‚àë  j =1  Œ≤ j   x i,j   =   Œ≤ bias   +   Œ≤ 1 x i, 1   +   Œ≤ 2 x i, 2   +   ¬∑ ¬∑ ¬∑   +   Œ≤ n x i,n   (5) where   ÀÜ y i   is the predicted value for observation   i ,   ( Œ≤ 1 , . . . , Œ≤ n , Œ≤ bias )   are the internal model parameters, and   ( x i, 1 , . . . , x i,n )   are the feature values for observation   i .   By analysing these internal model parameters (the   Œ≤ -parameters), we are able to interpret the magnitude and direction of the relationships between each feature and the target feature [27].  7.1.1   Regularised linear models  One major challenge in n-of-1 QS studies is that datasets are wide ‚Äî there are more features than observations. In a linear model, each feature has a corresponding   Œ≤ -parameter. It is well known that having a large number   Œ≤ -parameters allows us to fit arbitrary functions. With our wide dataset, that means we are modelling the noise in the dataset along with the signal, which overfits our model to the data and makes any results spurious [   25 ,   9 ]. One of the best techniques to resolve this is   regularisation , which penalises the model for having large   Œ≤ -parameters [ 25   ]. In Ridge regression, a weighted L2 norm of the   Œ≤ -parameters is added to the loss function. In Lasso regression, a weighted L1 norm is used instead. The mathematical properties of the L1 and L2 norm allow us to shape the effects of the regularisation in desirable ways. In particular, the L1 norm in Lasso regression favours   sparse   Œ≤ -values ‚Äî with values of 0 for features that have only a small effect on the prediction. This serves as built-in feature selection [ 45 ,   25 ]. Only features that are ‚Äúworth their weight‚Äù will have non-zero   Œ≤ -parameters. Both Ridge and Lasso were included as candidate algorithms in this study.  7.1.2   Recursive feature elimination (RFE)  Lasso is a rare example of an intrinsically-interpretable model with built-in feature selection. For other linear models (and tree-based models), best performance can be achieved when pre-selecting the most important features, then fitting a (regularised) model on that subset. RFE [ 46   ] recursively trains some model using various subsets of the features [   47   ]. In the past, feature selection techniques did not consider internal parameters, and instead tried all combinations of features to establish a Page 30\n\nQuantified Sleep : 7   MODEL INTERPRETATION   Gianluca Truda ranking of their importance [   3 ]. This has immense computational cost, as for   n   features a total of   2 n   ‚àí   1   models must be trained ‚Äî one for each subset of features.   RFE makes this process more efficient by utilising internal parameters to help rank feature importance. For best results, the rankings can be averaged over   5 -fold cross-validation. These top features can then be fed to the model. The resulting parameters can be analysed as before. Additionally, the ranking of the features from cross-validated RFE is a good secondary check on which features are most explanatory. RFE was used for both purposes in this study.  7.2   Model-agnostic interpretation  With the proliferation of neural networks, it is increasingly common for the best-fitting model to be a ‚Äúblack box‚Äù. That is, its internal workings are inseparable, making them impossible to interpret in isolation.   Model-agnostic   methods do not rely on internal model parameters. Instead, they rely on access to the dataset and the ability to test the model‚Äôs predictions on various input-output pairs. By systematically varying the inputs, model-agnostic methods can interpret model behaviour and allow us to understand the underlying relationships. This is achieved by building a linear  explanation model   g ( x i )   which is an interpretable approximation of the black-box predictive model  f   ( x i )   for any observation   x i   in our dataset. To construct the explanation model, we turn to the SHapley Additive exPlanations (SHAP) method [   48 ]. Because it is grounded in coalitional Game Theory, it boasts many desirable properties. It is also far more intuitive to interpret than other contemporary techniques, like local interpretable model-agnostic explanations (LIME) [27].  7.2.1   Shapley values  SHAP applies the concept of Shapley values with some algorithmic enhancements. Shapley values were originally demonstrated in Game Theory as a technique for fairly distributing payouts amongst players [ 49 ].   They can be used for model interpretability by reframing the problem: Let each feature be a player and let the total payout for each observation be proportional to the accuracy of the prediction. By evaluating all possible coalitions of features and repeating this for a number of examples, we can calculate Shapley values for each value that each feature takes on [   27 ]. These values represent the average contribution of a feature-value to the prediction. For a model with   n   features, let the set of feature vectors be   N   =   { x 1 ,   x 2 , . . . ,   x n } , such that   x j   is the column vector of values for feature   j . The Shapley values of feature   j   are calculated as:  œÜ j   ( v ) =  1  n !   ¬∑   ‚àë  S ‚äÜ N   \\{ x j   }  | S | !   ¬∑   ( n   ‚àí | S | ‚àí   1)!   ¬∑   [ v   ( S   ‚à™ { x j   } )   ‚àí   v ( S )]   (6) where   S   ‚äÜ   N   \\ { x j   }   denotes a subset   S   of all features   N   that do not include feature   j , and   v   :   S   ‚Üí   R  is a payoff function that evaluates how predictive some subset   S   of the features is, given dataset   X  and a trained model. Intuitively, the Shapley values of a feature   j   are how much each of its observed values shift the model prediction away from the mean prediction. Shapley values have been proven to satisfy a number of axioms in coalitional Game Theory [   49 ]. This makes the technique preferable to earlier approaches like LIME, which fail to ensure that the predictive value is fairly distributed among the features. Moreover, Shapley values allows for contrastive explanations, which many other techniques (including LIME) do not [   27 ]. These are immensely useful for comparing different subsets of the data in terms of the relationships between features ‚Äî e.g. how does a day with terrible sleep compare to one with outstandingly good sleep? Page 31\n\nQuantified Sleep : 8   EXPERIMENTS   Gianluca Truda Whilst extremely computationally expensive 6 , this approach allows much more nuanced interpreta- tions of the relationships between features, as each feature is explained with a   distribution   instead of a mere point estimate. So where interpreting   Œ≤ -parameters gave us an indication of each feature‚Äôs  global   importance, Shapley values give us their   situational   importance ‚Äî based on their effects during each observation.  7.2.2   SHAP  SHapley Additive exPlanations (SHAP) [   48 ] inherits the desirable mathematical properties of the Shapley value, but builds on them in two key ways.   Firstly, SHAP offers methods for global interpretations based on aggregations of Shapley values. Secondly, SHAP can utilise approximation methods that drastically speed up Shapley value computation on certain model architectures [   27 ]. SHAP builds a linear model   g   that approximates the predictive model   f   for any observation   x i   in our dataset:  f   ( x i )   ‚âà   g   ( x i ) =   œÜ bias   +  n ‚àë  j =1  œÜ j   x i,j   (7) where   œÜ j   is the Shapley value of feature   j   for observation   x i,j   . Essentially, SHAP has generated a linear model of the feature contributions for some black box model we gave it, for some specific instance. Now, we can interpret the   œÜ -parameters just as we interpret the   Œ≤ -parameters of any linear model (Eq. 5). Except that   Œ≤ -parameters are   global   and thus apply over all observations in the data, whilst the   œÜ -parameters from SHAP apply to a single observation   x i   ‚àà   X .  8   Experiments  Four experiments were performed to evaluate the techniques presented in this study: (1) assessing the effectiveness of Markov unfolding, (2) comparing imputation techniques, (3) measuring overall predictive performance, (4) final model interpretation. The first three experiments made use of a grid-search over 3 parameters for 10 repeats. The fourth experiment leveraged the results of the prior experiments to train and interpret the most promising model.  Preparing dataset variants : Each of the 10 imputation variants of the dataset was loaded into the grid-search script, duplicated, then transformed with   7 -day Markov unfolding. This resulted in 20 dataset variants of varying sizes.  Learning algorithms : A total of 7 different learning algorithms were included 7 . The first 6 were well-established linear and tree-based algorithms. Lasso and Ridge regression were included as regularised linear models. A basic Decision Tree regressor was included for reference, along with two ensembles of Decision Trees ‚Äî Random Forest (bagging) and XGBoost (boosting). The 7th algorithm was a ‚ÄúNa√Øve regressor‚Äù that always predicts the median value of the target feature from the training set. This served as a baseline for predictive value.  6 In reality, most implementations of Shapley values for model interpretation rely on Monte-Carlo sampling to estimate the values efficiently [27].  7 Earlier experiments found that support vector algorithms had mediocre performance ‚Äî especially without hyperparameter optimisations ‚Äî and fully-connected neural networks were unable to converge due to the limited data, resulting in massive prediction error, as well as excessive training time. These were excluded for the final analysis.  Page 32\n\nQuantified Sleep : 8   EXPERIMENTS   Gianluca Truda  Feature selection : The final datasets often had far more features (columns) than observations (rows), making them incredibly wide and difficult for algorithms to learn effectively [   8 ]. Initially, principal component analysis (PCA) was tested as a means of reducing the feature-space, but the number of components in PCA is limited by the number of observations, making this non-viable for these wide datasets. Recursive feature elimination (RFE) [   46 ] with a Decision Tree base model was used to rank the features independently for each of the 20 dataset variants, based on a single random train-test split of the data. Each non-target feature in the datasets was scaled independently prior to feature selection to speed up convergence.  Grid search : The grid search performed 10 cross-validation repeats over each of the 20 dataset variants. In each repeat, the dataset was split into train- and test- sets with a custom splitting function: each call drew a sample of   40   ‚Äúpure‚Äù observations (¬ß5.6), without repeats, for the test set and kept the remaining observations as the train set. This meant that models were only scored on observations that had complete data and had not undergone imputation ‚Äî which was essential for fair comparison. The train and test sets were scaled independently to avoid data leakage between them. The grid search iterated over all algorithms and values of   n   ‚àà   [2 ,   200] , training each on the   n - highest-ranked features in the train set and scoring the resulting model on the test set. Two of the dataset variants ‚Äî   with_nans   and   pre_markov_with_nans ‚Äî still had missing values. In the case of XGBoost, which can tolerate missing values [   34 ], the scaled training set was given directly to the algorithm. For all other algorithms, the observations with missing values were dropped from the training set before scaling and training.  RMSE metric : The prediction score was measured using the root mean squared error (RMSE) metric: RMSE ( y ,   ÀÜ y ) =  ‚àö ‚àö ‚àö ‚àö   1  m  m ‚àë  i =1  ( y i   ‚àí   ÀÜ y i ) 2   (8) where   y   were the true (target) values,   ÀÜ y   were the predicted values, and   m   = 40   was the number of observations in the test set. RMSE was selected because it is both (1) sensitive to outliers and (2) easily interpreted in the same units ‚Äî sleep score   ‚àà   [0 ,   100]   ‚Äî as the original target feature. Page 33\n\nQuantified Sleep : 9   RESULTS AND DISCUSSION   Gianluca Truda  9   Results and discussion  For each algorithm, dataset variant, and number of features, the RMSE over all 10 repeats was summarised by the mean and standard deviation.  9.1   Effectiveness of Markov unfolding  The best-performing configurations 8   for each model were collected and grouped by whether or not Markov unfolding was applied. Boxplots of the RMSE distributions are shown in Fig. 15. 8  10  12 RMSE  DecisionTreeRegressor   Lasso   NaiveRegressor  No   Yes  Markov unfolded  8  10  12 RMSE  RandomForestRegressor  No   Yes  Markov unfolded  Ridge  No   Yes  Markov unfolded  XGBRegressor  Figure 15: Comparison of prediction error (RMSE) across algorithms between the original dataset and the wider Markov-unfolded dataset. Results are distributions of mean RMSE scores for best- performing hyperparameter combinations for each dataset variant. Boxplots span the interquartile range (IQR) of the distribution, with a line indicating the median. The whiskers extend to the minimum and maximum values observed. Values beyond   1 . 5   times the IQR are considered outliers and plotted as circles. Markov unfolding did allow most algorithms to improve predictive performance, but the improvement was generally small. This was likely because the benefit of the additional information contained in the unfolded features traded off against the added burden of much higher dimensionality [26].  8 The best configurations for each algorithm and dataset were selected by finding the number of features that produced the lowest mean RMSE for that algorithm and dataset.  Page 34\n\nQuantified Sleep : 9   RESULTS AND DISCUSSION   Gianluca Truda By inspection, it is clear that the differences between algorithms were greater than the differences between regular and unfolded datasets in terms of the resulting model error. Lasso yielded the lowest error and saw the greatest benefit from Markov unfolding ( ‚àí 0 . 61 ), but Ridge and XGBoost also saw small improvements. On average, the magnitude of the differences between the regular and Markov-unfolded variants of the datasets was small. This likely indicates limitations in the use of RFE to select features when the datasets are so wide 9 . Lasso was much more effective at leveraging the Markov unfolding than other algorithms, likely due to the sparse L1 regularisation serving as an additional layer of feature selection [   45   ]. The effectiveness of Markov unfolding as a technique is best illustrated by comparing the performance of Lasso across all dataset variants paired with their Markov-unfolded versions. This is shown in Fig. 16. Markov unfolding lowered the prediction error for Lasso across all dataset variants except the variant that underwent no imputation (and thus contained only 21 training observations). These results highlight the immense value of capturing historical data in each observation, provided the algorithm can overcome the increased dimensionality. (iterative_br_50, 0)  (iterative_br_50, 1)  (iterativesvd, 0)  (iterativesvd, 1)  (knn_3, 0)  (knn_3, 1)  (matrixfactorization, 0)  (matrixfactorization, 1)  (mice_15, 0)  (mice_15, 1)  (mice_3, 0)  (mice_3, 1)  (softimpute, 0)  (softimpute, 1)  (univ_imp_mean, 0)  (univ_imp_mean, 1)  (univ_imp_median, 0)  (univ_imp_median, 1)  (with_nans, 0)  (with_nans, 1) [Dataset, Markov unfolded]  6  7  8  9  10  11 RMSE  Lasso performance between 20 and 150 best features across datasets  Figure 16: Distributions of prediction error over all repeats for Lasso model for between 50 and 150 features, across all dataset variants. The narrow version of each dataset is shown in grey. The Markov-unfolded version of each dataset is shown in black. Boxplots span the interquartile range (IQR) of the distribution, with a line indicating the median. The whiskers extend to the minimum and maximum values observed.  9 Manual inspection of the RFE feature rankings for each dataset revealed a great deal of variation in the top features.  Page 35\n\nQuantified Sleep : 9   RESULTS AND DISCUSSION   Gianluca Truda  9.2   Comparison of imputation techniques  Regularised linear algorithms performed the best with imputed data, particularly for the matrix factorisation, KNN, MICE, iterative SVD, and univariate imputation strategies. Fig. 17, compares the best configurations for each algorithm-dataset pair in a heatmap of mean RMSE values over all 10 cross-validation iterations.   This presentation highlights the poor results of the Decision Tree across all datasets, as well as the notable results for Lasso and Ridge when using matrix factorisation, MICE, and univariate median imputation. It is also clear that using no imputation ( with_nans ) resulted in worse results for almost all the algorithms in both the Markov unfolded and pre-Markov treatments. DecisionTreeRegressor  RandomForestRegressor  XGBRegressor  Lasso  Ridge  NaiveRegressor  pre_markov_matrixfactorization  pre_markov_knn_3  pre_markov_mice_3  pre_markov_iterative_br_50  pre_markov_mice_15  pre_markov_univ_imp_mean  pre_markov_univ_imp_median  pre_markov_with_nans  pre_markov_softimpute  pre_markov_iterativesvd  matrixfactorization  knn_3  mice_3  iterative_br_50  mice_15  univ_imp_mean  univ_imp_median  with_nans  softimpute  iterativesvd  Figure 17: Heatmap of mean prediction error (RMSE) over datasets (rows) and algorithms (columns). Colour map: lower values are   colder   (dark blue), medium values are near white, and higher values are   hotter   (dark red). There were weak correlations between imputation distance (¬ß5.7) and prediction error for the tree-based algorithms: Decision Tree ( r   = 0 . 415 ), Random Forest ( r   = 0 . 367 ), XGBoost ( r   = 0 . 499 ). These are well above the (clearly spurious) correlation of the Na√Øve regressor ( r   =   ‚àí 0 . 203 ). The regularised linear models, however, both had negligible correlations: Lasso ( r   =   ‚àí 0 . 276 ), and Ridge ( r   = 0 . 107 ). These correlations were for mean RMSE under the optimal number of features for each dataset. Most of the imputed data was in the contiguous chunk of missing data from the AWARE source at the start of the project. This is visible in the top right of Fig. 13b. To better understand the different classes of imputation and why they produced such different imputation distance scores, it is helpful to look at some examples (Fig. 18). Page 36\n\nQuantified Sleep : 9   RESULTS AND DISCUSSION   Gianluca Truda  (a) Gaussian shape.   (b) Log-normal shape.  (c) Bimodal shape.   (d) Hybrid shape.  Figure 18: Comparison of feature distributions for three notable imputation techniques on different types of underlying distributions. The original data distribution is shown with a solid line. The distribution after imputing missing values is shown with dashed lines, coloured differently for each imputation technique. Fig. 18a: Median imputation copes best with a Gaussian-like distribution, as it minimises the average noise.   However, the multivariate techniques appear to capture much more variance in the data, which gives the final model more information (if it is relevant) to capture underlying relationships. Fig. 18b: A log-normal shape causes univariate imputation to overestimate most imputed values. Median imputation is much less sensitive to the long tail than mean imputation, which explains the lower imputation distance (and better predictive performance). Again, the multivariate imputation techniques appear to capture the underlying properties better. Fig. 18c: The dramatic changes (in location and behaviour) caused by the global pandemic resulted in many features having bimodal distributions.   These resulted in a great deal of error for the median imputation, as it fills values equivalent to the larger mode. In the case of location, this was precisely the wrong mode. Matrix factorisation did a superb job of inferring which values to fill based on other features, thus capturing the underlying distribution quite well. Iterative SVD tracked a similar curve, but also exhibited a failure mode of extremely long (and thin) tails. Note in this case that the feature was only defined on the continuous interval   [0 ,   1] , meaning that the iterative SVD went way beyond plausible imputations for some values. Whilst infrequent, these likely resulted in its much larger imputation distance (and lower predictive performance). Page 37\n\nQuantified Sleep : 9   RESULTS AND DISCUSSION   Gianluca Truda Fig.   18d: Some distributions were hybrids.   The standard deviation of daytime heart rate, for instance, should typically follow a weak power law. But the pandemic changes would have resulted in two different log-normal shapes combining. In this case, the univariate median imputation was overly biased to the peak of the curve, whilst the multivariate imputation techniques appeared to capture more underlying structure. In this specific example, the difference between the iterative SVD and matrix factorisation methods is notable.  9.3   Predictive performance  In general, Lasso had the best predictive results over the 10 cross-validation iterations, except for the outright-best configuration 10 . Most top results were Lasso regression on between 4 and 120 features with univariate median imputation and Markov unfolding (RMSE   6 . 68   ¬±   0 . 62   ‚àí   6 . 82   ¬±   0 . 68 ). However, other top contenders were Lasso with the matrix factorisation imputation and Markov unfolding with 50 to 110 features (RMSE   6 . 84   ¬±   0 . 59   ‚àí   6 . 85   ¬±   0 . 59 ). These had slightly higher error, but also slightly lower variance. Fig. 19 compares the performance of all the algorithms with respect to the number of features for two different datasets.   All algorithms other than the Decision Tree had much lower error when using an imputed dataset. Recall that only non-imputed observations were used to score the algorithms, allowing a direct comparison. Most imputation techniques resulted in more stable results and overall lower error. When there were missing values in the dataset, the median of the target (i.e. Na√Øve regressor) was a better predictor than any of the learning algorithms. When imputation was applied, however, the algorithms could better capture the relationships in the data and outperformed the na√Øve median estimate by a notable magnitude. On the whole, imputation provided the algorithms with vastly more training examples (and variance), resulting in a dramatic improvement in model quality.  (a) Dataset with missing values.   (b) Dataset with matrix factorisation imputation.  Figure 19: Comparison of model prediction error (RMSE) with respect to the number of features for a dataset with missing values (left) and a dataset where missing values were imputing using matrix factorisation (right). Coloured lines represent mean error over 10 independent resamplings. Shaded regions around each line indicate   ¬± 1 œÉ   of variance.  10 Ridge regression on 5 features from the univariate median imputation dataset with Markov unfolding had RMSE of   6 . 67   ¬±   0 . 59 .  Page 38\n\nQuantified Sleep : 9   RESULTS AND DISCUSSION   Gianluca Truda The number of features (which directly relates to the free parameters of the models) had a fairly mild influence on most algorithms. With the exception of Ridge, most algorithms actually reduced their out-of-sample error as the features were increased, instead of overfitting. Random Forest, Lasso, and XGBoost showed almost no trends for these error curves on the imputed dataset (Fig. 19b). This was likely due to regularising effects built into these three algorithms. Lasso uses L1 regularisation on   Œ≤ -parameters [ 45   ], Random Forest is a bagged ensemble ‚Äî which is known to reduce variance [50] ‚Äî and XGBoost has mild L2 regularisation by default [34]. XGBoost also uses default directions in trees to tolerate missing data: when a value is missing, trees automatically follow the paths that maximise gain [   34 ]. We can compare the built-in tolerance to explicit imputation for XGBoost by comparing the performance across Figures 19a and 19b. Close inspection shows that XGBoost performs much better with even a simple explicit imputation than when using its own built-in tolerance for missing values. This reiterates the value of explicit imputation for n-of-1 QS projects.  9.4   Model interpretation  A matrix-factorisation-imputed dataset with Markov unfolding was the dataset variant that yielded the most accurate and consistent predictions 11   with the Lasso algorithm. This combination was selected for the final model interpretation. 5-fold cross-validation of Lasso on all of the observations in the final dataset variant yielded an  R 2 -score of   0 . 546 , with points of greatest error being near the left tail of the distribution.   In other words, nights with very bad sleep were predicted as better than they were (see Fig. 20). A regularisation constant   Œ±   = 0 . 567   was found optimal. 30   40   50   60   70   80   90 Sleep score  30  40  50  60  70  80  90 Model prediction  Predicted sleep vs. actual sleep ( R 2   = 0.546)  Figure 20: Calibration curve for the best algorithm-dataset pairing after 5-fold cross-validation. The vertical axis is the predicted sleep score. The horizontal axis is the true sleep score. The points are coloured by their residuals (prediction error), with lighter colours being higher residuals.  9.4.1   Interpreting cross-validated RFE  RFE with 5-fold cross-validation on the Lasso base revealed that 36 features yielded the best average performance on the selected dataset variant.   The 36 top features are listed in the Appendices (Table 4).  11 Univatiate median imputation and matrix factorisation imputation had similar mean error on Lasso, but matrix factorisation was more consistent (lower   œÉ ). This is clear in Fig. 16.  Page 39\n\nQuantified Sleep : 9   RESULTS AND DISCUSSION   Gianluca Truda  9.4.2   Interpreting cross-validated Lasso  Œ≤ -parameters are sensitive to a number of factors (particularly with regularisation) [ 51   ]. To obtain robust estimates, 20 rounds of 5-fold cross-validation were performed. In each round, 5 different subsets of the final dataset variant were used to fit a Lasso model ( Œ±   = 0 . 567 ). This process resulted in 100 versions of the Lasso model trained on slightly different subsets of 80% of the final dataset variant. The 100 estimates of each   Œ≤ -parameter were used to construct distributions over all features and assess the robustness of the coefficient magnitudes. Because Lasso produces sparse   Œ≤ -parameters, those features which never yielded a coefficient with a magnitude greater than   0 . 5   were ignored. The distributions for the remaining 69 features are shown in Fig. 21. ‚àí\u0005   ‚àí\u0004   ‚àí\u0003   \u0002   \u0003 \u001b\u0012\u0013\u0013\u0016\u0010\u0016\u0012\u001a   importance  sleep_yesterday_duration  sleep_yesterday_midpoint_time  sleep_yesterday_score_total  sleep_yesterday_total  travelling  at_home  hk_act_9h  hk_act_12h  nomie_caf_net_hour_min  nomie_caf_net_hour_range  nomie_caf_net_hour_spread  rescue_shopping  melatonin_hour_taken  melatonin_hour_delta  melatonin_quantity  aw_loc_geohash_u173w_mean  aw_geohash9_num_unique  aw_geohash8_num_unique  aw_hr_heart_rate_std_eve  aw_hr_heart_rate_std_morn  sleep_yesterday_efficiency_-5day  sleep_yesterday_score_disturbances_-4day  sleep_yesterday_score_latency_-4day  sleep_yesterday_ready_score_hrv_balance_-3day  sleep_yesterday_ready_score_sleep_balance_-7day  sleep_yesterday_ready_score_temperature_-5day  at_home_-3day  is_weekend_-2day  hk_act_0h_-6day  hk_act_1h_-7day  hk_act_2h_-1day  hk_act_3h_-7day  hk_act_4h_-1day  hk_act_4h_-5day  hk_act_7h_-5day  hk_act_17h_-2day  hk_act_21h_-1day  nomie_alc_value_sum_-1day  nomie_alc_net_hour_min_-7day  nomie_caf_value_sum_-1day  nomie_caf_value_sum_-3day  nomie_caf_value_sum_-4day  rescue_software_dev_-6day  rescue_total_distracting_time_-3day  rescue_utilities_-3day  cbd_drops_-3day  cbd_hour_taken_-4day  cbd_hour_delta_-3day  zero_hours_-1day  zero_night_eating_-1day  zero_start_hour_delta_-1day  zero_hours_since_prev_fast_-1day  zero_hours_since_prev_fast_-3day  wol_added_to_anki_-3day  wol_made_music_-1day  wol_read_book_-4day  aw_activ_stationary_-7day  aw_calls_call_duration_count_-6day  aw_loc_geohash_u173w_mean_-7day  aw_weather_humidity_median_-6day  aw_weather_humidity_std_-6day  aw_weather_pressure_median_-3day  aw_weather_pressure_std_-3day  aw_weather_rain_median_-5day  aw_weather_wind_speed_std_-3day  aw_weather_wind_speed_std_-4day  aw_hr_heart_rate_median_night_-1day  aw_hr_heart_rate_std_day_-1day  aw_hr_heart_rate_std_night_-1day  Coefficient importance and its variability  Figure 21: Overview of   Œ≤ -parameter variability for features after 20 rounds of 5-fold cross-validation on the best algorithm-dataset pair. Only the features which had non-negligible   Œ≤   parameters (at least one   ‚â•   0 . 5 ) are shown. Each point is a   Œ≤ -parameter from one of the 100 fittings for that feature. Boxplots are superimposed to illustrate the median, interquartile ranges, and non-outlier extremes of each distribution. Page 40\n\nQuantified Sleep : 9   RESULTS AND DISCUSSION   Gianluca Truda Because all the features were scaled prior to fitting, we can directly compare the   Œ≤ -parameter distributions to get an indication of how relevant each feature is. As we see in Fig. 21, many of the   Œ≤ -parameters varied wildly in magnitude as a result of the subset of the data they were fit on. Perhaps the factors that influence sleep varied depending on circumstances ‚Äî such as which country I was in at the time, or what time of year it was. But it is more likely that these wide ranges indicate the very high level of noise in the dataset. The relatively low   R 2 -score makes this a strong possibility. Whilst the parameters varied greatly in magnitude, the direction was very consistent. Most of the features had   Œ≤ -parameters anchored at zero that varied into the positive or negative direction exclusively. This means that although those features were not always deemed relevant by the model, when they   were   deemed relevant, it was always in the same direction. A few of the features had  Œ≤ -parameters with distributions centred well away from zero. These are strong candidates for the most-important features, as they were deemed strongly-relevant by the Lasso model regardless of the subset of the data they were fit on.  9.4.3   Interpreting model with SHAP  SHAP analysis was applied to the optimised Lasso model trained on the final dataset variant. Using the cluster method 12 , SHAP computed the Shapley values for each feature-observation pair and used those to automatically rank the relevant features. These results are presented in a beeswarm plot in Fig. 22. We can see that the majority of features had an negative impact on sleep score, as low (blue) values gather on the right side whilst high (red) values gather on the left.   One interpretation of this is a   subtractive   model of sleep quality, where many factors can detract from a baseline of good sleep. For instance, fewer hours of nighttime eating the previous day ( zero_night_eating_-1day ) pushed the predicted sleep quality up (high SHAP value), whilst more hours of nighttime eating pulled the predicted sleep quality down (low SHAP value). Some features (like   aw_hr_heart_rate_std_morn   and   zero_hours_-1day ) appear to be centred at their mean, with Gaussian-like distributions, whilst others (like   melatonin_quantity   and  wol_read_book_-4day ) clearly reflect their discrete distributions.  12 Running SHAP on a ‚Äúblack box‚Äù model is computationally expensive ‚Äî especially when there are thousands of features to consider. In the case of linear or tree-based models, the computation can be massively accelerated by allowing SHAP to inspect internal parameters [   48   ]. Alternatively, a weighted   k -means clustering can be applied to the dataset prior to a ‚Äúblack box‚Äù SHAP analysis. This method was used, with   k   = 30 . This effectively summarised the data as 30 observations with features that were a weighted average of the points that comprised the cluster. Whilst this was primarily used to reduce the computation time for SHAP, it also served to smooth out a great deal of noise from the dataset and thus provide more robust results.  Page 41\n\nQuantified Sleep : 9   RESULTS AND DISCUSSION   Gianluca Truda ‚àí   ‚àí   ‚àí\b   ‚àí\u0006   \u0004   \u0006   \b  \u0012\u000f   \u0011\u0000(\u0014\u001e'\u0018\u0000 (impact on model output)  sleep_yesterday_ready_score_sleep_balance_-7day zero_hours_-1day rescue_software_dev_-6day aw_hr_heart_rate_std_eve aw_weather_wind_speed_std_-3day travelling aw_hr_heart_rate_std_morn wol_read_book_-4day cbd_hour_delta_-3day sleep_yesterday_score_latency_-4day aw_calls_call_duration_count_-6day nomie_caf_net_hour_spread hk_act_17h_-2day aw_weather_rain_median_-5day aw_geohash8_num_unique melatonin_hour_delta melatonin_quantity aw_weather_pressure_median_-3day aw_loc_geohash_u173w_mean_-7day sleep_yesterday_total aw_activ_stationary_-7day nomie_caf_net_hour_min aw_hr_heart_rate_std_night_-1day zero_night_eating_-1day aw_hr_heart_rate_median_night_-1day  Low High  Feature value  Figure 22: Beeswarm plot for interpreting the final Lasso model using SHAP. Each row is an explanatory feature, in descending order of importance. Each dot represents an observation for that feature. The colour of the dot indicates the observation‚Äôs value for that feature, with low values being cooler and high values being warmer. The horizontal axis is the SHAP value for each observation, indicating the magnitude and direction of its impact on the final model prediction. A common pattern in the beeswarm plot is a strongly-skewed distribution of values on one tail. For example,   nomie_caf_net_hour_spread   measures the variance in the hours when caffeine was consumed throughout the day. A low or medium spread results in a minor increase in sleep quality. However, a high spread results in anywhere from a small to very large decrease in sleep quality. Whilst this does reflect the underlying feature distribution (which is positively skewed), it shows that extreme values can have a large range of effect sizes on the final prediction. Finally, the colour gradients on almost all features change very smoothly with respect to the SHAP value. This reflects the inherently linear nature of the Lasso model used. However, SHAP can be used to interpret any black-box model [ 48 ] and could (in principle) illustrate non-linear relationships captured in the data. Page 42\n\nQuantified Sleep : 9   RESULTS AND DISCUSSION   Gianluca Truda One of the strengths of SHAP is its ability to perform contrastive explanations. We can therefore compare the beeswarm plots of the worst (score   <   50 ) and best (score   >   85 ) nights in the dataset (see Fig. 23). ‚àí   ‚àí   ‚àí\b   ‚àí\u0006   \u0004   \u0006  \u0013\u0010\u000e\u0012\u0000)\u0015\u001f(\u0019\u0000 (impact   on model output)  aw_calls_call_duration_count_-6day sleep_yesterday_score_latency_-4day hk_act_3h_-7day sleep_yesterday_ready_score_sleep_balance_-7day aw_hr_heart_rate_std_morn zero_hours_-1day wol_read_book_-4day melatonin_hour_delta hk_act_4h_-1day aw_geohash8_num_unique hk_act_2h_-1day cbd_hour_delta_-3day melatonin_quantity hk_act_9h sleep_yesterday_total aw_weather_pressure_median_-3day travelling aw_weather_rain_median_-5day nomie_caf_net_hour_spread aw_loc_geohash_u173w_mean_-7day nomie_caf_net_hour_min aw_activ_stationary_-7day aw_hr_heart_rate_std_night_-1day zero_night_eating_-1day aw_hr_heart_rate_median_night_-1day  Low High  Feature value  (a) Sleep score   <   50 ‚àí\u0005   \u0004   \u0005   \u0006   \u0007   \b  \u0012\u000f   \u0011\u0000(\u0014\u001e'\u0018\u0000 (impact on model output)  sleep_yesterday_ready_score_hrv_balance_-3day wol_made_music_-1day hk_act_12h_-6day aw_weather_rain_median_-5day nomie_caf_value_sum_-1day nomie_caf_net_hour_spread aw_weather_wind_speed_std_-3day zero_hours_-1day hk_act_17h_-2day aw_hr_heart_rate_std_eve wol_read_book_-4day aw_calls_call_duration_count_-6day aw_geohash8_num_unique rescue_software_dev_-6day melatonin_hour_delta sleep_yesterday_score_latency_-4day aw_loc_geohash_u173w_mean_-7day aw_weather_pressure_median_-3day melatonin_quantity nomie_caf_net_hour_min sleep_yesterday_total aw_activ_stationary_-7day zero_night_eating_-1day aw_hr_heart_rate_std_night_-1day aw_hr_heart_rate_median_night_-1day  Low High  Feature value   (b) Sleep score   >   85  Figure 23: Contrastive beeswarm plots for 21 nights with terrible sleep quality (left) and 11 nights with superb sleep quality (right). The main difference to note is the reordering of the features. This indicates that some features contributed far more on one extreme of the sleep quality distribution than on the other. For instance,  travelling   appears ninth in the low-scoring nights (23a) but not at all in the high-scoring nights (23b). Moreover, we can see from the distribution of points that not all nights of poor sleep were due to   travelling , but that it was to blame for poor sleep quality when it did occur.  9.4.4   Combined interpretation  The top features from the RFE-based selection, the cross-validated Lasso   Œ≤ -parameters, and SHAP interpretation were combined to find standout features. These can inform future investigations and n-of-1 experiments. By combining the top features from all three interpretation strategies, 16 features were found to be consistent and notable. They are listed along with their full descriptions and relevant importance measures in Table 3. Page 43\n\nQuantified Sleep : 9   RESULTS AND DISCUSSION   Gianluca Truda  Feature name   r   Œ≤   | S |   Description  aw_hr_heart_rate_median_night_-1day   -0.46   -2.17   1.84   Median heart rate in the evening, 1 day prior aw_hr_heart_rate_std_night_-1day   -0.33   -1.21   0.94   Std. heart rate in the evening, 1 day prior zero_night_eating_-1day   -0.44   -0.96   0.99   Hours of eating after sunset, 1 day prior nomie_caf_net_hour_min   -0.02   0.77   0.71   Hour of first caffeine consumption aw_activ_stationary_-7day   0.20   0.75   0.67   Time spent stationary, 7 days prior aw_loc_geohash_u173w_mean_-7day   -0.29   -0.63   0.44   Time in location u173w, 7 days prior melatonin_quantity   -0.21   -0.54   0.47   Quantity of melatonin consumed travelling   -0.21   -0.49   0.17   Whether or not I was travelling long distances sleep_yesterday_total   -0.04   -0.39   0.56   Total time spent sleeping the previous day aw_weather_pressure_median_-3day   0.21   0.39   0.43   Median weather pressure, 3 days prior melatonin_hour_delta   -0.20   -0.37   0.30   The hour melatonin was consumed hk_act_17h_-2day   0.16   0.35   0.23   Activity levels at 17h00, 2 days prior aw_geohash8_num_unique   -0.16   -0.17   0.25   The no. unique level-8 geohashes visited cbd_hour_delta_-3day   -0.25   -0.32   0.21   The hour CBD oil was consumed, 3 days prior wol_read_book_-4day   -0.21   -0.18   0.22   Whether I read a book, 4 days prior zero_hours_-1day   0.35   0.20   0.16   Hours of intermittent fasting, 1 day prior  Table 3: Combined set of model interpretations, showing the 16 most predictive features (roughly ordered) and a written description of what each feature means. The   r   column indicates the Pearson correlation coefficient between the feature and the target in the dataset. The   Œ≤   column indicates the associated   Œ≤ -parameter in the final Lasso model. The   | S |   column indicates the mean absolute Shapley values (over all observations) for each feature after interpretation with SHAP. We can see from the suffixes in Table 3 that 11 of the 16 features were lagged values generated through Markov unfolding 13 . A total of 5 have a 1-day lag, 2 have a 7-day lag, and the remaining 4 have 2-4 day lags. This suggests that history is an important factor in sleep quality. In particular, the previous day and last week on the same day have notable impact. This justifies the need for techniques like Markov unfolding which incorporate history into each observation. It also hints that much of the value of Markov unfolding comes from capturing information from 1 day and one week prior. It is interesting to compare the original correlations ( r -values), the Lasso   Œ≤ -parameters, and the Shapley values for each of these features (see Table 3). All but one of the   r -values have the same positivity as the   Œ≤ -parameters. The exception is   nomie_caf_net_hour_min , which had almost no correlation ( r   =   ‚àí 0 . 02 ). This tells us that correlation analysis correctly identified the direction that each feature ultimately affected sleep quality. However, the magnitudes of these correlations are fairly small and would not have been sufficient to select these 16 features from the full set, based only on correlation (Fig. 7). Most notably,   nomie_caf_net_hour_min   and   sleep_yesterday_total  are important features but displayed negligible correlation to sleep quality. The magnitudes of the   Œ≤ -parameters and the Shapley values correspond closely, except for the   travelling   feature, which SHAP deemed as far less important on average. This is likely a result of SHAP (correctly) down-weighting the travelling feature, as it only has a non-zero value for a handful of observations. This indicates that modelling the data helped isolate which features most impacted sleep quality in a way that simple correlation analysis would not have been capable of. Overall, the results of model interpretation track the direction of simple correlation, but not the magnitude.  13 Recall that the prefix   sleep_yesterday_   is used for a 1-day lag on the   oura_   features to make it easier to remember to remove same-day sleep features that constitute a data leak.   So   sleep_yesterday_total   can be interpreted as   oura_sleep_total_-1day  Page 44\n\nQuantified Sleep : 9   RESULTS AND DISCUSSION   Gianluca Truda  9.5   Feature explanation  Some of the final 16 features are expected. Travelling, eating windows, previous sleep, and melatonin are all known to affect sleep quality [   13 ,   15 ,   14 ,   12 ]. But the direction of some of these effects was unexpected. For instance, melatonin consumption is associated with a   decrease   in sleep quality, when research suggests it should have be increase [ 52 ,   53 ]. The previous night‚Äôs sleep quantity also has an unexpected   decrease   on the present night‚Äôs sleep quality. That implies that there is some kind of trade-off between sleep   quality   and sleep   quantity   on successive nights. These unexpected directions might just be artefacts of the study design, but could also indicate idiosyncrasies in my sleep patterns. Through the process of modelling and interpreting, such unexpected connections are highlighted for future n-of-1 studies. On the other hand, some of the final 16 features were very much unexpected. Specifically, the lag in the features. It is not intuitive that pleasure reading and barometric pressure from many days prior could affect the current night‚Äôs sleep. It is also strange that location changes from an entire week prior are still predictive of the current night‚Äôs sleep. One explanation is that these features merely correlate with other (unmeasured) variables that influence sleep quality, and that this is being captured by the model [   44 ]. Another (complementary) explanation is that the sparsity effect of the Lasso model [ 45 ] caused it to discard all but one feature from each set of highly-correlated features. For instance,   wol_read_book   is highly correlated with a number of Oura-based features, as well as computer usage, location, alcohol consumption, and afternoon activity (Fig. 8a). Given that the Lasso model already includes correlated features for the current day and previous day, it gains no predictive value by including   wol_read_book   with a lag of 0 or 1.   In fact, the L1 regularisation would mean that this extra feature imposes a penalty on the model [ 45 ].   But, including   wol_read_book_-4day   adds information from   earlier   days. And because this reading feature is highly correlated with many other predictive features, it captures a great deal of predictive information from earlier days. This line of reasoning suggests that it is not specifically these 16 features that are most-important for understanding sleep quality. Instead, it is clusters of features that are correlated with these 16 that are of importance. A thorough analysis (which is beyond the scope of this paper) would use results from Table 3 and the dendrogram from Fig.   8 together to build a comprehensive understanding of the relationships affecting sleep quality 14 . The 16 final features are a much reduced subset of the 308 initial features that were explored throughout this observational study, yet they explain the majority of the variation in sleep quality (when controlling for all the other features). The sum of the SHAP scores for the 16 final features is   8 . 59 , while the sum of the SHAP scores for the other 1505 Markov-unfolded features is   2 . 31 . The next step is to design a series of   interventional   n-of-1 QS experiments to explore whether each of these factors is causal and what the effect sizes are. The design and implementation of such studies is outside the scope of this paper, but is well-covered in other literature [7, 54, 2].  14 Indeed, SHAP does include hierarchical interpretation techniques, but they rely on iteratively fitting XGBoost models on different subsets of the features, which is far too computationally expensive for large numbers of features.  Page 45\n\nQuantified Sleep : 10   LIMITATIONS AND FUTURE WORK   Gianluca Truda  10   Limitations and future work  10.1   Ground truth  The lack of accurate ‚Äúground truth‚Äù was a theme at all levels. For instance, the Oura ring ‚Äî whilst a leader in wearable sleep trackers ‚Äî is still vastly less accurate than research-grade polysomnography equipment. Because of the opaque nature of sleep [   12 ], even polysomnography is only an estimation [   16 ]. All of this added a great deal of noise to the target. This made it harder to assess the quality of predictive models. Those models also had the challenge of noisy sensor data and biased event logs as features. Analysis of the underlying distributions of features in the dataset revealed some potential issues. Whilst many biological and environmental factors produce near-normal distributions [   55   ], they were often very skewed or fat-tailed in this dataset. There were also a number of strongly-bimodal distributions caused by the dramatic changes during the first wave of the pandemic.   These distributions are ‚Äúdodgy‚Äù because they deviate [ 28   ] from the perfectly-Gaussian assumptions made by many statistical techniques and learning algorithms [25, 26]. The real-world nature of the dataset meant that there was no ground truth against which to directly evaluate the feature engineering, hierarchical correlation, imputation, Markov unfolding, and model interpretation techniques.   This reduced the power of the evidence presented by the results of this study. Future work could apply the methods of this study to ‚Äúeasier‚Äù datasets and modelling problems to evaluate them in isolation.  10.2   Generalisability  Because this was an n-of-1 study, most results are unlikely to generalise to other individuals. Moreover, many factors ‚Äî the specifics of the tracking tools used, environment, personal behaviour, social factors, pandemic consequences, etc. ‚Äî are likely to vary over time. This means that many of the results of this study may not even generalise to   me   going forward. This is definitely true of specific findings, like the effect of melatonin on my sleep quality. But it may also be true of the results about different techniques used. Whilst Lasso and matrix-factorisation-imputation worked well on this specific dataset, that may not generalise to other n-of-1 QS datasets. Indeed, those who replicate these approaches should also replicate the variety of techniques used. By casting a wide ‚Äúnet‚Äù of possible techniques, it is more likely to find ones that apply best to the specific dataset being modelled.  10.3   Markov unfolding  Markov unfolding was only notably effective in the regularised linear algorithms. This may be because the current implementation increased the dimensionality too much ‚Äî outweighing the value of the historical information. The linear algorithms, especially Lasso, likely dealt with this better because of their regularisation helping prioritise the most important features [   25 ,   45   ]. The predominance of 1-day and 7-day lagged features in the final model interpretation suggests that there may be more sophisticated ways to apply Markov unfolding to maximise the historical information whilst minimising the increase in dimensionality. For example, future work could explore the use of rolling aggregations for the 2-6 day lags. Instead of feature   j   becoming 8 features, it would only become 5:   j ,   j ‚àí 1 ,   j ‚àí 7 ,   j Œº , and   j œÉ   . This captures the information-rich previous day, the cyclical weekly patterns of seven days prior, and a rolling distribution of ‚Äúthe last few days‚Äù. This would also help make features more intuitive and models more interpretable. Page 46\n\nQuantified Sleep : 10   LIMITATIONS AND FUTURE WORK   Gianluca Truda  10.4   Imputation  There were three limitations to the imputation strategy of this paper. Firstly, no ground-truth of error levels across imputation techniques existed for this dataset. The custom distance metric was used as a proxy for the magnitude of change caused by imputation, but this did not directly help select the best-suited imputation algorithm or hyperparameters. Future work can first evaluate imputation techniques on   synthetic   missing values from a sample of the same dataset. The error of the re-imputed values could then be used to select and optimise the imputation method for the dataset. This was beyond the scope of this study, as generating the synthetic missing values in a way that generalises to   real   missing data is a complex topic ‚Äî MAR, MNAR, and MCAR effects (¬ß5.1) all need to be synthesised. Moreover, the fact that there were only 61 observations in the data that did not need imputation would have meant a very biased sample and may have invalidated the synthetic approach on this specific dataset. Secondly, although all features used in imputation were numeric, a subset had an underlying binary structure. In principle, the imputation techniques used should only apply to continuous features [   31 ].   In practise, there were sufficiently few binary features and sufficiently few missing values within them that this was   probably   negligible. Future work could investigate automatic filtering methods for excluding such features. Thirdly, a large number of the imputed values were from a contiguous ‚Äúchunk‚Äù in the AWARE- sourced features from prior to my use of AWARE. This chunk can be clearly seen in the top right of Fig. 13b. It is likely that imputing these values (especially with simpler univariate techniques) resulted in a great deal of additional noise for those features. That may have affected the results in a number of different ways. A key trade-off in this study was between number of observations and number/quality of features. The decision to impute over this large missing chunk was part of that trade-off. Future work could investigate the effects of imputing large chunks of contiguous values on final model interpretation.  10.5   Interpretation  One of the major advantages of SHAP over   Œ≤ -value analysis is that it assigns Shapley values to each feature for each observation, allowing for a nuanced distributional analysis (e.g. Fig. 23). By using a linear final model (Lasso), non-linear feature effects were not able to show up in the SHAP results. It is possible that there were no relevant non-linearities to the most predictive features, but by constraining the scope of this study to a single (linear) model, it became impossible to know. Future work could compare SHAP interpretations over different models and develop techniques for reconciling multiple interpretations.  10.6   Hierarchical clustering  The hierarchical clustering of feature correlations offers many advantages to projects of this nature. Whilst it was used to aid model interpretation, it was under-utilised in feature selection. This was mainly due to it being developed towards the end of this study, when it was too late to overhaul the data pipeline. Future work could (1) validate the hierarchical correlational method‚Äôs efficacy in finding related features, and (2) explore the use of hierarchical correlation for feature selection. The hierarchical correlation of features may offer a better trade-off between accuracy and performance for automated feature selection than RFE or exhaustive search. This is especially relevant to n-of-1 QS projects where most features are weakly correlated to most other features and very weakly correlated with the target [3, 1]. Page 47\n\nQuantified Sleep : 11   CONCLUSIONS   Gianluca Truda  11   Conclusions  This paper presented a case study in how to conduct observational n-of-1 Quantified-Self (QS) research, combining relevant techniques from statistics and machine learning to obtain robust and interpretable results. Several methods were presented for combining heterogeneous data sources and engineering day- level features from different data types and frequencies, including manually-tracked event logs and automatically-sampled weather and geo-spatial data. The resulting dataset was thoroughly analysed ‚Äî for outliers, normality, (auto)correlations, stationarity, and missing data ‚Äî and cleaned accordingly. A notable inclusion was the use of hierarchical clustering of the correlation matrix to identify groups of correlated features. The missing data was organised and filled using a combination of knowledge-based and statistical techniques. The latter included several different imputation methods that have been presented in the literature. Regularised linear algorithms (Lasso and Ridge) performed the best with imputed data, particularly for the matrix factorisation, KNN, MICE, iterative SVD, and univariate imputation strategies. The use of imputation saved hundreds of observations from being discarded and improved overall performance of all the algorithms except the plain Decision Tree. To collapse the time series into a collection of independent observations, the Markov unfolding technique was presented. This added lagged copies of features to each observation to incorporate values from recent history for each engineered feature. Markov unfolding improved the predictive performance of Lasso dramatically, but for other algorithms the improvement was less pronounced. This was likely because the benefit of the additional information traded off against the added burden of much higher dimensionality. Lasso likely performed best because L1 regularisation allowed it to effectively sift through the greater number of features. The paper suggests ways Markov unfolding could be made more feature efficient in future work. From the extensive grid-search, a low-error, low-variance model and dataset combination was selected ‚Äî Lasso regression on a Markov-unfolded version of the dataset which had undergone matrix factorisation imputation. The final model was interpreted in two key ways: (1) by inspecting the internal   Œ≤ -parameters, and (2) using the SHAP framework, which builds local explanatory models for each observation. By repeatedly re-training the Lasso model on different subsets of the dataset, distributions of   Œ≤ -parameters were generated. Features with consistently-large   Œ≤ -coefficients were deemed   globally   important. This was combined with SHAP‚Äôs   situational   assessment of the importance of each feature with respect to each observation ‚Äî which allowed contrastive analysis of extreme examples of sleep quality. These two interpretation techniques were combined to produce a list of the 16 most-predictive features. By comparing the list of predictive features to the hierarchy of correlated features, it became apparent that Lasso‚Äôs ability to learn sparse parameters helped it to find features that were in different correlational clusters, thus making the best use of all the information in the dataset without overfitting. Unfortunately, this made it more complex to infer a   descriptive   model of sleep behaviour. Overall, predictive modelling helped detect relationships in the dataset that simple univariate analysis would not have found. By identifying the factors that most affect sleep, this study showed that it is possible to use an   observational   study to greatly reduce the number of features that need to be considered in   interventional   n-of-1 QS research. Page 48\n\nQuantified Sleep : REFERENCES   Gianluca Truda  12   Practicalities  12.1   Code and data availability  The Python 3 code for methods presented in this study is publicly available as a collection of Jupyter notebooks. These show outputs and documentation inline with the code, making it easier to understand the flow of this study in a sequential order. The code is available under a GNU General Public License (GPLv3), allowing modification and re-use. For the sake of personal data privacy, some outputs and code are redacted from the published notebooks. The dataset from this study will not be made available, as it contains extensive personal information. My current ongoing research into generative differential privacy hopes to find long-term solutions to this trade-off between data privacy and open science. If a version of the dataset does become available in future, it will be made available via the project repository (github.com/gianlucatruda/quantified- sleep).  12.2   Replicating this work  Other QS enthusiasts are encouraged to apply these techniques to their future projects and report on their findings. Much of the progress in this niche of n-of-1 QS occurs outside of the formal scientific literature. One of the goals of this paper was to help bridge the gap between community rules-of-thumb and end-to-end studies. As mentioned, the dataset is not available for privacy reasons.   However, much of the code in the Jupyter notebooks should generalise to other n-of-1 QS projects, provided the sources are similar. Those wishing to replicate the methodology of this study on their own data will need to write their own   ingesters . These are simple Python functions that take in an exported data file (e.g. CSV, JSON, etc.) and return a Pandas dataframe with observations as rows and features as columns. Most of the code was written in a way that minimises the number of changes required to adapt to different sources. Indeed, during the course of this study, I added and updated sources a number of times, finding that much of the code was robust to these changes. Current details of the structure of the code and how to best modify it for your own projects can be found in the repository documentation.  References  [1]   Melanie Swan. The quantified self: Fundamental disruption in big data science and biological discovery.   Big data , 1(2):85‚Äì99, 2013. [2]   Eun Kyoung Choe, Nicole B Lee, Bongshin Lee, Wanda Pratt, and Julie A Kientz. Under- standing quantified-selfers‚Äô practices in collecting and exploring personal data. In   Proceedings of the SIGCHI conference on human factors in computing systems , pages 1143‚Äì1152, 2014. [3]   Mark Hoogendoorn and Burkhardt Funk.   Machine Learning for the Quantified Self . Springer, 2018. ISBN 00278424. doi: 10.1073/pnas.96.11.6558. [4]   Elizabeth O Lillie, Bradley Patay, Joel Diamant, Brian Issell, Eric J Topol, and Nicholas J Schork. The n-of-1 clinical trial: the ultimate strategy for individualizing medicine?   Personal- ized medicine , 8(2):161‚Äì173, 2011. Page 49\n\nQuantified Sleep : REFERENCES   Gianluca Truda [5]   Wes McKinney et al. pandas: a foundational python library for data analysis and statistics.  Python for High Performance and Scientific Computing , 14(9):1‚Äì9, 2011. [6]   Amos Tversky and Daniel Kahneman. Judgment under uncertainty: Heuristics and biases.  science , 185(4157):1124‚Äì1131, 1974. [7]   R Kravitz, N Duan, I Eslick, NB Gabler, HC Kaplan, EB Larson, et al. Design and imple- mentation of n-of-1 trials: a user‚Äôs guide.   Agency for healthcare research and quality, US Department of Health and Human Services , 2014. [8]   Scott Fortmann-Roe. Understanding the bias-variance tradeoff.   URL: http://scott. fortmann- roe. com/docs/BiasVariance. html (h√§mtad 2019-03-27) , 2012. [9]   Douglas M Hawkins. The problem of overfitting.   Journal of chemical information and computer sciences , 44(1):1‚Äì12, 2004. [10]   Vladimir Vapnik.   The nature of statistical learning theory . Springer science & business media, 2013. [11]   Brett Beaulieu-Jones. Machine learning for structured clinical data. In   Advances in Biomedical Informatics , pages 35‚Äì51. Springer, 2018. [12]   Matthew Walker.   Why we sleep: Unlocking the power of sleep and dreams . Simon and Schuster, 2017. [13]   Marie-Pierre St-Onge, Anja Mikic, and Cara E Pietrolungo. Effects of diet on sleep quality.  Advances in Nutrition , 7(5):938‚Äì949, 2016. [14]   Shailesh Bihari, R Doug McEvoy, Elisha Matheson, Susan Kim, Richard J Woodman, and Andrew D Bersten. Factors affecting sleep quality of patients in intensive care unit.   Journal of Clinical Sleep Medicine , 8(3):301‚Äì307, 2012. [15] Teofilo Lee-Chiong.   Sleep medicine: Essentials and review . Oxford University Press, 2008. [16]   Katherine A Kaplan, Jason Hirshman, Beatriz Hernandez, Marcia L Stefanick, Andrew R Hoffman, Susan Redline, Sonia Ancoli-Israel, Katie Stone, Leah Friedman, Jamie M Zeitzer, et al. When a gold standard isn‚Äôt so golden: Lack of prediction of subjective sleep quality from sleep polysomnography.   Biological psychology , 123:37‚Äì46, 2017. [17]   Oura. The accuracy of the oura ring ‚Äì oura help, . URL   https://support.ouraring.com/hc/ en-us/articles/360055999894-The-Accuracy-of-The-Oura-Ring . Accessed: 2021-04-05 11:37:23. [18]   Hannu Kinnunen, Aleksi Rantanen, Tuomas Kentt√§, and Heli Koskim√§ki. Feasible assessment of recovery and cardiovascular health: accuracy of nocturnal hr and hrv assessed via ring ppg in comparison to medical grade ecg.   Physiological measurement , 41(4):04NT01, 2020. [19]   Oura.   How accurate is oura‚Äôs respiratory rate?   - the pulse blog,   .   URL   https:// blog.ouraring.com/how-accurate-is-ouras-respiratory-rate/ .   Accessed: 2021-04-05 11:38:00. [20]   Massimiliano de Zambotti, Leonardo Rosas, Ian M Colrain, and Fiona C Baker. The sleep of the ring: comparison of the ¬Ø oura sleep tracker against polysomnography.   Behavioral sleep medicine , 17(2):124‚Äì136, 2019. Page 50\n\nQuantified Sleep : REFERENCES   Gianluca Truda [21]   Nicholas IYN Chee, Shohreh Ghorbani, Hosein Aghayan Golkashani, Ruth LF Leong, Ju Lynn Ong, and Michael WL Chee. Multi-night validation of a sleep tracking ring in adolescents compared with a research actigraph and polysomnography.   Nature and Science of Sleep , 13: 177, 2021. [22]   Rob ter Horst. Oura ring scientific sleep test (review) - the quantified scientist (youtube). URL   https://www.youtube.com/watch?v=atWcp6FmnbE . Accessed: 2021-04-05 11:38:00. [23]   Gustavo Niemeyer. Tips & Tricks - geohash.org. URL   http://geohash.org/site/tips.html . [24]   Chris Veness. Movable Type Scripts - Geohash. URL   https://www.movable-type.co.uk/ scripts/geohash.jpg . [25]   Andriy Burkov.   The hundred-page machine learning book , volume 1. Andriy Burkov Canada, 2019. [26] Christopher M Bishop.   Pattern recognition and machine learning . springer, 2006. [27]   Christoph Molnar.   Interpretable Machine Learning . 2019.   https://christophm.github.io/ interpretable-ml-book/ . [28]   Nassim Nicholas Taleb.   Statistical consequences of fat tails:   Real world preasymptotics, epistemology, and applications.   arXiv preprint arXiv:2001.10488 , 2020. [29]   Peter J Brockwell, Peter J Brockwell, Richard A Davis, and Richard A Davis.   Introduction to time series and forecasting . Springer, 2016. [30]   Said E Said and David A Dickey. Testing for unit roots in autoregressive-moving average models of unknown order.   Biometrika , 71(3):599‚Äì607, 1984. [31]   Roderick JA Little and Donald B Rubin.   Statistical analysis with missing data , volume 793. John Wiley & Sons, 2019. [32]   Aleksey Bilogur.   Missingno:   a missing data visualization suite.   Journal of Open Source Software , 3(22):547, 2018. [33]   Hyun Kang. The prevention and handling of the missing data.   Korean journal of anesthesiology , 64(5):402, 2013. [34]   Tianqi Chen and Carlos Guestrin. Xgboost: A scalable tree boosting system. In   Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining , pages 785‚Äì794, 2016. [35]   Reza Sahraeian. Reza sahraeian - the industrial challenge of missing data | pydata eindhoven 2020 (youtube). URL   https://www.youtube.com/watch?v=M4CtBKrp59w . Accessed: 2021- 04-27 14:06:00. [36]   Jianhua Lin.   Divergence measures based on the shannon entropy.   IEEE Transactions on Information theory , 37(1):145‚Äì151, 1991. [37]   Fabian Pedregosa, Ga√´l Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al. Scikit-learn:   Machine learning in python.   the Journal of machine Learning research , 12: 2825‚Äì2830, 2011. [38]   Alex Rubinsteyn and Sergey Feldman. fancyimpute: An imputation library for python. URL  https://github.com/iskandr/fancyimpute . Page 51\n\nQuantified Sleep : REFERENCES   Gianluca Truda [39]   S van Buuren and Karin Groothuis-Oudshoorn. mice: Multivariate imputation by chained equations in r.   Journal of statistical software , pages 1‚Äì68, 2010. [40]   Rahul Mazumder, Trevor Hastie, and Robert Tibshirani. Spectral regularization algorithms for learning large incomplete matrices.   The Journal of Machine Learning Research , 11:2287‚Äì2322, 2010. [41]   Olga Troyanskaya, Michael Cantor, Gavin Sherlock, Pat Brown, Trevor Hastie, Robert Tib- shirani, David Botstein, and Russ B Altman.   Missing value estimation methods for dna microarrays.   Bioinformatics , 17(6):520‚Äì525, 2001. [42]   G√°bor Tak√°cs, Istv√°n Pil√°szy, Botty√°n N√©meth, and Domonkos Tikk. Matrix factorization and neighbor based algorithms for the netflix prize problem. In   Proceedings of the 2008 ACM conference on Recommender systems , pages 267‚Äì274, 2008. [43]   Stuart Russel, Peter Norvig, et al.   Artificial intelligence:   a modern approach .   Pearson Education Limited London, 2013. [44] Miguel A Hern√°n and James M Robins. Causal inference, 2010. [45]   Robert Tibshirani. Regression shrinkage and selection via the lasso.   Journal of the Royal Statistical Society: Series B (Methodological) , 58(1):267‚Äì288, 1996. [46]   Xue-wen Chen and Jong Cheol Jeong.   Enhanced recursive feature elimination.   In   Sixth International Conference on Machine Learning and Applications (ICMLA 2007) , pages 429‚Äì 435. IEEE, 2007. [47]   Isabelle Guyon, Jason Weston, Stephen Barnhill, and Vladimir Vapnik. Gene selection for cancer classification using support vector machines.   Machine learning , 46(1):389‚Äì422, 2002. [48]   Scott M Lundberg and Su-In Lee. A unified approach to interpreting model predictions. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors,   Advances in Neural Information Processing Systems 30 , pages 4765‚Äì4774. Curran Associates, Inc., 2017. [49]   Lloyd S Shapley. A value for n-person games.   Contributions to the Theory of Games , 2(28): 307‚Äì317, 1953. [50]   Peter B√ºhlmann, Bin Yu, et al. Analyzing bagging.   The Annals of Statistics , 30(4):927‚Äì961, 2002. [51]   Scikit-Learn. Common pitfalls in interpretation of coefficients of linear models ‚Äî scikit-learn 0.24.1   documentation.   URL   https://scikit-learn.org/stable/auto_examples/ inspection/plot_linear_model_coefficient_interpretation.html?highlight= interpretability . Accessed: 2021-04-15. [52]   Ingeborg M van Geijlswijk, Hubert PLM Korzilius, and Marcel G Smits. The use of exogenous melatonin in delayed sleep phase disorder: a meta-analysis.   Sleep , 33(12):1605‚Äì1614, 2010. [53]   Derk-Jan Dijk and Christian Cajochen.   Melatonin and the circadian regulation of sleep initiation, consolidation, structure, and the sleep eeg.   Journal of biological rhythms , 12(6): 627‚Äì635, 1997. [54]   Azure Grant and Gary Wolf. White paper: Design and implementation of participant-led research in the quantified self community. 2019. [55]   Aidan Lyon. Why are normal distributions normal?   The British Journal for the Philosophy of Science , 65(3):621‚Äì649, 2014. Page 52\n\nQuantified Sleep : A   APPENDICES   Gianluca Truda  A   Appendices  Figure 24: Pairplot matrix over 4 of the most important sleep features. In each row, a feature comprises the vertical axis. In each column a feature comprises the horizontal axis. In cell   i, j , a scatterplot and regression line is shown for   i   vs   j . In cell   i, i , the histogram of feature   i   is shown instead of a redundant scatterplot.  Feature name  sleep_yesterday_midpoint_time sleep_yesterday_rmssd sleep_yesterday_score sleep_yesterday_score_alignment sleep_yesterday_score_deep sleep_yesterday_score_disturbances sleep_yesterday_score_efficiency sleep_yesterday_score_latency travelling hk_act_9h nomie_caf_net_hour_min nomie_caf_net_hour_range nomie_caf_net_hour_spread melatonin_quantity aw_geohash8_num_unique hk_act_2h_-1day hk_act_4h_-1day hk_act_7h_-5day hk_act_17h_-2day hk_act_night_mean_-1day nomie_caf_value_sum_-4day cbd_hour_delta_-3day zero_hours_-1day zero_night_eating_-1day wol_intensive_workout_-2day wol_read_book_-4day aw_activ_stationary_-7day aw_loc_geohash_u173w_mean_-7day aw_weather_pressure_median_-3day aw_weather_rain_median_-5day aw_weather_wind_speed_median_-5day aw_weather_wind_speed_std_-3day aw_hr_heart_rate_median_night_-1day aw_hr_heart_rate_std_day_-1day aw_hr_heart_rate_std_morn_-7day aw_hr_heart_rate_std_night_-1day  Table 4: The 36 most-predictive features (in arbitrary order) after   5 -fold cross-validated recursive feature elimination (RFE) for a Lasso regression model on a markov-unfolded-matrix-factorised variant of the dataset. Page 53",
    "arXiv:2405.02802v1 [stat.CO] 5 May 2024  Permutation time irreversibility in sleep electroencephalograms: Dependence on sleep stage and the effect of equal values  Wenpo Yao 1, 2  1 State Key Laboratory of Organic Electronics and Information Displays, Institute of Advanced Materials, School of Chemistry and Life Sciences, School of Geographic and Biologic Information, Nanjing University of Posts and Telecommunications, Nanjing 210023, China  2 Key Laboratory of Computational Neuroscience and Brain-Inspired Intelligence(Fudan University), Ministry of Education  Time irreversibility (TIR) refers to the manifestation of nonequilibrium brain activity influenced by various physiological conditions; however, the influence of sleep on electroencephalogram (EEG) TIR has not been sufficiently investigated.   In this paper, a comprehensive study on permutation TIR (pTIR) of EEG data under different sleep stages is conducted. Two basic ordinal patterns (i.e., the original and amplitude permutations) are distinguished to simplify sleep EEGs, and then the influences of equal values and forbidden permutation on pTIR are elucidated.   To detect pTIR of brain electric signals, 5 groups of EEGs in the awake, stages I, II, III, and rapid eye movement (REM) stages are collected from the public Polysomnographic Database in PhysioNet. Test results suggested that the pTIR of sleep EEGs significantly decreases as the sleep stage increases (p < 0.001), with the awake and REM EEGs, demonstrating greater differences than others. Comparative analysis and numerical simulations support the importance of equal values. Distribution of equal states, a simple quantification of amplitude fluctuations, significantly increases with the sleep stage (p < 0.001).   If these equalities are ignored, incorrect probabilistic differences may arise in the forward-backward and symmetric permutations of TIR, leading to contradictory results; moreover, the ascending and descending orders for symmetric permutations also lead different outcomes in sleep EEGs. Overall, pTIR in sleep EEGs contributes to our understanding of quantitative TIR and classification of sleep EEGs.  I.   INTRODUCTION  The human brain, which contains large numbers of neurons and interacts with other physiological organs [1, 2], is a highly complex system. Brain activity exhibits evidently nonlinear, nonequilibrium properties and is in- fluenced by various internal and external factors. Sleep is a vital physiological activity for living beings; various changes occur in the physiological systems during sleep, with brain electric activities demonstrating pronounced changes. Therefore, the complex characteristics of sleep electroencephalograms (EEGs) can help in analyzing the sleep mechanisms [3, 4]. Various nonlinear methods, such as fractal approaches and detrended fluctuation analysis, have been used to explore the dynamics of EEGs dur- ing different sleep stages.   Entropy measures [5, 6] are widely employed to detect the complexity of sleep brain signals, such as the Shannon entropy [7, 8], sample en- tropy [9, 10], and multiscale entropy [11]. Among these complex characteristics, the loss of time reversibility is a manifestation of nonequilibrium brain electric activity [12, 13] and has been applied to several neural patholog- ical conditions, including epilepsy [14‚Äì16], Alzheimer‚Äôs disease [17], and alcoholism [18]. Time irreversibility (TIR) [19], also defined as tempo- ral asymmetry (TAS) [20], is an important characteristic of nonequilibrium EEGs.   To quantity TIR, the prob- abilistic differences between the forward-backward pro- cesses or symmetry vectors must be measured [19‚Äì21]; both are nontrivial. In real-world signal processing, TIR is generally quantified by coarse-graining the time series. Probabilistic differences between up and down were in- troduced by Costa [22, 23], Porta [24], and Ehlers et al.   [25, 26] as simplified temporal asymmetries.   La- casa et al.   [27‚Äì29] estimated the irreversibility consid- ering the distinguishability between the in-out distribu- tions of the visibility graph [30].   The in-out difference was then employed to detect irreversible characteristics in effective interactions and particular networked con- nectivity [31, 32].   Given nonequilibrium statistical me- chanics in neuronal spike trains, the network inference and couplings of asymmetric models were investigated via asynchronous update [33, 34].   Symbolic TIR based on a way of coarse-graining or reduction of description is widely adopted in quantitative TIR owing to its com- putational effectiveness and simplified statistical analysis [35, 36]. Among these coarse-graining methods, ordinal patterns convey structural dynamics and do not impose further model assumptions [37‚Äì40]; thus, they are popu- lar in the quantification of TIR [14‚Äì18]. However, several challenges are observed in permutation TIR (pTIR). It should be noted that there are two basic ordinal pat- terns, i.e., original permutation and amplitude permuta- tion; they differently reflect the structural dynamics of any series [40]. Amplitude permutation directly reflects the vector temporal structure, while the application of original permutation might result in conceptual errors in pTIR [15, 41, 42].   Forbidden permutation refers to the missing ordinal pattern in the simplified transformation of a temporal structure.   Amigo et al.   [43‚Äì45] exten- sively analyzed the features of these forbidden ordinal patterns and proposed several methods for chaotic deter-\n\n2 mination in real-world time series analysis.   The distri- butions of forbidden permutation convey important sys- tem information, such as chaotic dynamics, correlation, and nonlinearity [46‚Äì49].   Forbidden permutation is an adverse factor in pTIR because it generates individual permutations and make division-based parameters (e.g., the Kullback-Leibler distance) unsuitable to calculate the probabilistic difference between forbidden and individual permutations [14, 15, 41, 42].   Equal value is another implicated factor because it significantly affects the con- struction of ordinal patterns and permutation analysis. Ma et al.   [50] focused on the indexes of equal values in permutation and modified them into the same sym- bol (rank) for a more accurate characterization of the system structure. Zunino et al. [51] reported erroneous conclusions on permutation entropy (PEn) in the event of equalities in time series; David et al. [52] further iden- tified the weakness of PEn, i.e., the possible ambiguities introduced by equal values in the subsequences.   How- ever, the influence of equal values on pTIR has not been sufficiently analyzed. Equal values are generally assumed to be rare if a process has a continuous distribution [37]. This is partly true; however, equal values are observed in physiological signals such as heartbeats [53, 54] and raw EEGs [55, 56], and they significantly impact per- mutation analysis. Moreover, equal values might gener- ate self-symmetry vectors containing important physical implication (i.e., time reversibility or temporal symme- try) in TIR and produce contradictory findings in real- world series analysis [53, 54]. Furthermore, the different treatment of equal values might lead to inconsistencies between forward-backward and symmetric permutations, thus yielding differences in the quantification of TIR and TAS of time series.   Therefore, the effects on the pTIR during signal processing, particular the TIR and TAS in real-world series analysis, should be comprehensively studied. Owing to these unfavorable factors in the quan- tification of TIR, the time irreversible characteristics of sleep EEGs have not been given the deserved attention. To address this problem, a comprehensive analysis of pTIR and its application in sleep EEG classification is performed.   Accordingly, two basic ordinal patterns are compared to simplify the time series, and several crucial factors in pTIR are clarified.   Subsequently, the distri- butions of equal values and individual permutations that affected the pTIR of sleep EEGs are detected. For com- parison, nonequal permutations of TIR are employed, and PEn is applied to evaluate the complexity of sleep EEGs. Furthermore, several issues are discussed such as equal values in sleep EEGs and the relationship between entropy and TIR. The contributions of this research are as follows:   (1) it elucidates the key factors of pTIR in physiological signal processing, especially the influence of equal values, (2) it explores the time irreversible charac- teristics of EEGs under different sleep conditions, which is helpful for sleep classification.  II.   METHODS A.   Time irreversibility  A process is defined as time reversible if it is invariant under the reversal of the timescale; otherwise, it is time irreversible.   Given below are two statistical definitions of time reversibility: Definition 1. According to Weiss [19], a stationary pro- cess,   X ( t ), is time reversible if   { X ( t 1 ) , X ( t 2 ) , . . . , X ( t m ) }  and   { X ( ‚àí t 1 ) , X ( ‚àí t 2 ) , . . . , X ( ‚àí t m ) }   have the same joint probability distributions for every   t 1 , t 2 , . . . , t m   and   m ; otherwise,   X ( t ) is time irreversible. Definition   2.   Based   on   the   works   of   Kell   [20], if   X ( t )   is   time   reversible,   { X ( t 1 ) , X ( t 2 ) , . . . , X ( t m ) }  and   { X ( ‚àí t 1   +   n ) , X ( ‚àí t 2   +   n ) , . . . , X ( ‚àí t m   +   n ) }  have   the   same   probability   distributions   for   every  t 1 , t 2 , . . . , t m   and   n .   Particularly,   under   n   =  t 1   +   t m ,   symmetric   { X ( t 1 ) , X ( t 2 ) , . . . , X ( t m ) }   and  { X ( t m ) , . . . , X ( t 2 ) , X ( t 1 ) }   have the same joint probabil- ities.   Moreover, the symmetric form of a vector is the same as its counterpart in the time-reversal series. There- fore, TIR is also defined as TAS. To quantify the TIR or TAS of a process, the forward- backward probabilistic difference and symmetric vectors‚Äô probabilistic divergence should be equivalent [21]; how- ever, their applications in real-world processes are differ- ent [14, 15]. The forward-backward approach for TIR is operationally convenient and more reliable in application. Meanwhile, it should have the entire process to obtain the reversed one, which is not feasible if the process is large or uninterrupted; therefore, TIR based on forward- backward differences does not satisfy real-time require- ment.   By contrast, TAS based on the probabilistic dif- ference of symmetric vectors demonstrates real-time per- formance; therefore, it has higher applicability in phys- iological and environmental condition monitoring. Note that TAS based on symmetric vectors has a limitation, i.e., the vector should be faithfully associated with its alternative; otherwise, conceptual misleading may occur [15, 41, 42].  B.   Original and amplitude permutations  TIR can be measured by alternatively calculating the joint probabilistic differences of simplified processes in- stead of the raw process.   Among these simplified mea- sures, pTIR is particularly popular. The ordinal pattern comes naturally from the series and does not pose further model assumptions [37, 40]; hence, it plays an important role in quantitative TIR. According to the representation of a vector structure, there are two basic ordinal patterns, i.e., the original permutation (OrP) and amplitude permutation (AmP) [40, 42]. The OrP consists of the indexes of reorganized\n\n3 values in the original series, while the AmP comprises the positions of the original values in the reordered se- ries.   Given series   X ( i ) =   { x ( i 1 ) , . . . , x ( i i ) , . . . , x ( i m ) } , it is reordered in the ascending or descending order to  X ( j ) =   { x ( j 1 ) , . . . , x ( j j   ) , . . . , x ( j m ) }   e.g., increased as  x ( j 1 )   <   ¬∑ ¬∑ ¬∑   < x ( j j   )   <   ¬∑ ¬∑ ¬∑   < x ( j m ). Then, the OrP and AmP are generated according to the organized indexes of the original and reordered series as Eq. (1).  {   OrP : ( x 1 ,j   , . . . , x i ‚àí 1 ,j   , x i,j   , x i +1 ,j   , . . . , x m,j   ) AmP : ( x i, 1 , . . . , x i,j ‚àí 1   , x i,j   , x i,j +1   , . . . , x i,m )   (1) In   the   construction   of   OrP,   i   increases   from   1 to   m   and   j   is   the   location   of   reorganized   val- ues   in   the   original   series   X ( i ),   i.e.,   OrP j   = ( j 1 , j 2 , . . . , j i ‚àí 1 , j i , j i +1 ,   ¬∑ ¬∑ ¬∑   , j m ‚àí 1 , j m ). In the generation of AmP,   j   increases from 1 to   m   and   i   is the posi- tion of original values in the reordered series   X ( j ), i.e.,  AmP i   =   ( i 1 , i 2 , . . . , i j ‚àí 1 , i j   , i j +1 ,   ¬∑ ¬∑ ¬∑   , i m ‚àí 1 , i m ).   Tak- ing a series with five values   X ( i )   =   { 5 ,   1 ,   7 ,   3 ,   9 }   as an example, the reordered series can be represented as  X ( j ) =   { 1 ,   3 ,   5 ,   7 ,   9 }   in the ascending order.   The in- dexes of reorganized   X ( j ) values in the original   X ( i ) is OrP=(2,4,1,3,5); the positions of the original   X ( i ) values in the reorganized   X ( j ) is AmP=(3,1,4,2,5). Equal values are not rare in real-world signals and are usually generated owing to limitations in signal collec- tion [55, 56], especially the quantization error in analog- to-digital conversion (ADC). Equal values have an im- portant role in the construction of ordinal patterns and permutation analysis [50‚Äì54]; therefore, their indexes in ordinal patterns should be improved accordingly. If there are equal values in series   X ( i ), they can be organized in neighboring orders according to their order of occur- rence; for example,   ¬∑ ¬∑ ¬∑   < x ( i 1 , j 1 ) =   x ( i 2 , j 2 )   <   ¬∑ ¬∑ ¬∑   < x ( i 3 , j 3 ) =   x ( i 4 , j 4 ) =   x ( i 5 , j 5 )   <   ¬∑ ¬∑ ¬∑   . Then, the indexes of equal values can be rewritten to be the same in each group, such as to the smallest indexes as   ¬∑ ¬∑ ¬∑   < x ( i 1 , j 1 ) =  x ( i 1 , j 1 )   <   ¬∑ ¬∑ ¬∑   < x ( i 3 , j 3 ) =   x ( i 3 , j 3 ) =   x ( i 3 , j 3 )   <   ¬∑ ¬∑ ¬∑  [50] or the largest ones as   ¬∑ ¬∑ ¬∑   < x ( i 2 , j 2 ) =   x ( i 2 , j 2 )   <  ¬∑ ¬∑ ¬∑   < x ( i 5 , j 5 ) =   x ( i 5 , j 5 ) =   x ( i 5 , j 5 )   <   ¬∑ ¬∑ ¬∑   , and modify the OrP and AmP accordingly.   Further taking a series with five values   X ( i ) =   { 5 ,   1 ,   9 ,   1 ,   7 }   as an example, the second ‚Äò1‚Äô could be treated as ‚Äò2‚Äô according to its order of occurrence; then, the OrP and AmP become (2,4,1,5,3) and (3,1,5,2,4) in the ascending order, respectively.   In equal-value ordinal patterns, the indexes of equal values are modified to be the smallest; consequently, the OrP and AmP are improved to be (2,2,1,5,3) and (3,1,5,1,4), respectively.   Without equal values, if the length of the series is   m , there exist   m !   ordinal patterns, and there are more motifs if the equality is considered. Equal-value permutation is necessary for the comprehensive reflection of the series‚Äô temporal structure [40, 42]. Figure 1 illus- trates the structures of triple-value series and their OrPs and AmPs. Figure 1 displays the comprehensive temporal struc- tures of triple-value series where equal values have an important role. Furthermore, OrP and AmP are two ba- sic ordinal patterns that differently convey the temporal structure of the series [40]. AmP directly reflects the tem- poral structure of the series because its elements directly correspond to the amplitude of the original sequence el- ement.   Therefore, AmPs of symmetric vectors (e.g.,   y - axis or time symmetric) are all symmetric in Fig. 1, and AmPs of the three temporally self-symmetric vectors are also self-symmetric. By contrast, OrP indirectly reflects the original series structure owing to targets on the re- ordered series, and OrPs of amplitude-symmetric (i.e.,   x - axis symmetry) series are symmetric. The differences be- tween OrP and AmP differently affect permutation anal- ysis.   When ordinal patterns are used as an alternative label or symbol of the series, there are no differences be- tween the two basic permutations, such as in PEn [8, 37]. Otherwise, if ordinal patterns are constructed as a direct replacement of the series structure, OrP and AmP should be dealt with carefully to avoid possible errors, such as in pTIR [15, 41, 42].   In this study, AmP is used as a direct alternative for the temporal structure of the series to avoid possible errors in pTIR.  C.   Permutation time irreversibility  Permutation TIR is the probabilistic difference be- tween forward-backward or symmetry permutations as an alternative to the original series. Owing to the advan- tages of ordinal patterns and their application in quanti- tative TIR, pTIR is widely used in time series analysis. In real world signal analysis, the application of pTIR en- counters some challenges, as listed below: (1) OrP is not a direct reflection of the temporal struc- ture of vectors, as shown in Fig. 1, and its effect on TAS is such that if the probabilistic difference between sym- metric vectors is calculated, symmetric OrPs should not be used. The AmPs of time-symmetric vectors are sym- metric, and symmetric AmPs could be employed as al- ternatives for evaluating TIR [40]. Meanwhile, the OrPs of amplitude-symmetric vectors are symmetric, and sym- metric OrPs should be employed as alternatives for mea- suring amplitude irreversibility [15, 42].   It should be noted that when measuring the joint probabilistic dif- ference of the forward-backward process for TIR, there is no difference between the OrP and AmP. Overall, AmP directly reflects the temporal structure of vectors and is recommended for pTIR. (2)   The   consideration of   equal   values   is   necessary to construct comprehensive and reliable vector struc- tures; more importantly, equal values can generate self- symmetric vectors. Self-symmetric vectors, e.g., the vec- tors and their AmPs in boxes in Fig. 1a) and c), have a special physical implication, i.e.   time reversibility or\n\n4  (1,2,3)  (3,2,1)  (1,3,2)   (3,1,2) (2,1,3) (2,3,1)   (1,1,3) (2,2,1) (1,2,2)   (3,1,1)   (1,1,2) (2,1,1)  (1,1,1)   (1,3,1) (2,1,2) (1,1,3) (3,1,1) (2,2,1) (1,2,2) (1,3,2)   (2,3,1)  (2,1,3) (3,1,2)  y   y x x  (1,2,3)  (3,2,1) (1,1,1)  OrP:  AmP:  a)   b)   c)  time self-symmtry  FIG. 1. OrP and AmP of triple-value series. AmPs are bold and underlined. Indexes of red equal values in the ascending order are modified to be the smallest ones in their corresponding groups. a) OrPs and AmPs of all-up, all-down, and all-equal vectors are always the same. b) Symmetric AmPs of time-symmetric ( y -axis) series are connected by dashed black arrows; symmetric OrPs of   x -axis symmetric series are connected by solid red arrows. c) AmPs of time self-symmetry vectors are symmetric.  temporal symmetry [40, 42].   Furthermore, equal values widely exist in physiological data (either directly col- lected EEGs or indirect heartbeats derived from elec- trocardiography) owing to the nonlinear and irreversible quantization process of signal collection [53, 55,   56]. Therefore, equal values should not be broken by adding small random perturbations or ranked according to their order of appearance, and their indexes in ordinal patterns should be modified accordingly. (3) Forbidden permutations are a special type of for- bidden symbol, i.e., symbols that do not exist for a pro- cess. Forbidden permutations are closely related to sys- tem characteristics [43‚Äì49], but they negatively impact quantitative TIR. Among the pairs of permutations for quantitative TIR, if there exists a forbidden permutation, its corresponding permutation is an individual permuta- tion.   The mathematical difference between the proba- bilities of forbidden and individual permutations is zero or infinite if using division-based parameters, such as the Kullback-Leibler distance. Therefore, such division- based parameters are not suitable for quantitative TIR [14, 15, 41, 42].   It is recommended to use subtraction- based parameters, such as   Y s   in Eq. (2), in quantitative TIR to calculate the probabilistic differences, where   p i  and   p j   probability of corresponding permutations and   p i  should not be less than   p j   .  Y s „Äà p i , p j   „Äâ   =   p i  p i   ‚àí   p j  p i   +   p j  ,   (2) (4) TIR and TAS are statistically consistent;   theo- retically, the probabilistic differences between symmetric permutations and those between forward-backward per- mutations should be the same.   However, the existence of equal values and the traditional treatment that ranks them according to their order of emergence make TIR and TAS different.   Figure 2 illustrates a comparative construction of nonequal and equal-value AmPs consid- ering equal values.  (1,1,1)  (1,2,2)   (2,2,1)   (3,1,1)   (1,1,3) (2,1,2) (1,3,1)  (1,2,3) (1,2,3)   (1,2,3) (2,3,1)   (3,1,2) (1,3,2)   (2,1,3)  equal-value  nonequal  FIG. 2.   AmPs of triple-value series considering equalities. Equal values are represented in red and the crossed greens are their alternatives according to their order of occurrence in the ascending order. In equal-value AmPs (bold and underlined), indexes of red equal values are modified to be the smallest in their corresponding groups.  As evident in Fig. 2, nonequal AmP represents a tem- poral structure of vector without equal values.   Equal values are transformed into ‚Äòfalse up‚Äô in nonequal ordi- nal patterns and their symmetric permutation is ‚Äòreal down‚Äô, but their corresponding permutations in the back- ward series are ‚Äòfalse up‚Äô and ‚Äòreal up‚Äô.   Note that ‚Äòreal down‚Äô in the forward series is ‚Äòreal up‚Äô in the back- ward series; moreover, the probability distributions of ‚Äòup‚Äô in the forward and backward series are both incor- rect. Furthermore, if there are equal values in the process and nonequal permutation is applied, neither TIR nor TAS can be correctly quantified; in addition, the AmPs of symmetric and forward-backward vectors are not the same, leading to inconsistent and even contradictory TIR and TAS in the quantitative nonequilibrium of signal pro-\n\n5 cessing, which will be confirmed in this study.  III.   RESULTS  EEG is a typically complex signal and subject to dif- ferent physiological activities. In this section, EEG data under different sleep conditions are collected from the publicly available PhysioNet [57] to test the sleep stages on pTIR. The probabilistic differences of AmPs are cal- culated using the subtraction-based   Y s   to quantify TIR; TIR and TAS based on equal-value AmP are denoted as pTIR and pTAS, while those based on nonequal AmP are represented as noeTIR and noeTAS, respectively.  A.   Sleep EEGs  The MIT-BIH Polysomnographic Database is a collec- tion of sleep physiologic data.   This database contains information related to the sleep physiological signals of 16 male subjects (age ranging from 32 to 56, mean age 43; weight ranging from 89 to 152 kg, mean weight 119 kg). The database contains over 80 h of four-, six-, and seven-channel polysomnographic recordings, with a stan- dard expert annotation for sleep stages after every 30 s according to the criteria of Rechtschaffen and Kales [58]. EEG signals are recorded from the C4-A1, O2-A1, or C3- O1 channel at a sampling rate of 250 Hz and 12-bit quan- tization. Referring to the annotation files, sleep EEGs in five stages, i.e., awake and sleep stages 1 (SI), 2 (SII), 3 (SIII), and rapid eye movement (REM) are extracted; each stage contained 45 sets of EEG signals with a du- ration of 60 s (15000 points) after visual inspection for artifacts. More detailed information can be found in Ref [57, 59].   The nonparametric Mann‚ÄìWhitney U test is performed to test the statistical differences in pTIR be- tween each of the two stages of sleep EEGs, and Kruskal‚Äì Wallis analysis of variance is applied to measure those in pTIR of sleep EEGs in five stages. Equal values play an important role in the construc- tion of ordinal patterns and might significantly change the probability distribution of permutations; moreover, they convey important physical implication, i.e., time reversibility [14, 15, 40, 42].   The distribution of equal states (DES) [55] is measured by Eq. (3), where   L   de- notes the length of series,   N   ( s ( t ) =   s ( t   +   œÑ   )) represents the number of neighboring equal states with delay   œÑ   . The states of DES indicate EEG values in this report. DES of five groups of sleep EEGs are shown in Fig. 3. DES =   N   ( s ( t ) =   s ( t   +   œÑ   ))  L   ‚àí   œÑ   (3) The results in Fig. 3 are consistent with those obtained in our previous report on the distribution of equal val- ues in sleep EEGs [56].   Raw sleep EEGs have numer- ous neighboring equal values.   Although awake EEGs have minimum equal values, their DES are 12%, and as the sleep stages increase, the DES increase significantly; hence, REM EEGs have almost 34% equal values.   Un- der acceptable data recording resolution, awake EEGs have larger amplitude fluctuations that produce fewer neighboring equal values, and as the depth of sleep in- creases, amplitude fluctuations of the brain‚Äôs electrical activity decrease, thus significantly decreasing the DES. Equal values are generated owing to the limitation of the ADC, i.e., the zero-amplitude fluctuation [55, 56].   Test results suggest that the DES of EEGs under the five sleep conditions are statistically significantly different (p < 0.01 for Mann‚ÄìWhitney U test; p < 0.0001 for Kruskal‚ÄìWallis test), and the DES of REM EEGs are particularly differ- ent between others (p < 0.00001). Therefore, equal values not only have important effects on pTIR, but their distri- bution also serves as a simple parameter for time-domain feature extraction and should not be ignored. The   existence   of   forbidden   permutations   makes division-based parameters unsuitable for pTIR, and their distribution has been widely proved to be closely associ- ated with systematic information [43‚Äì49]. In sleep EEGs, all permutations have their corresponding forms when  m =2 and 3, while the distribution of individual permu- tations is rare when   m =4.   When   m   is 5 and larger, there exist forbidden as well as individual permutations. Further, forbidden permutations contain false forbidden permutations that do not exist because the data length is short, and they decay with the sequence length [44]. Considering false forbidden permutations, if the selected EEG data length is short, the pTIR of classified sleep EEGs might not be reliable. The distribution of individ- ual permutations (DIPs) is expressed in Eq. (4), where  N   ( œÄ I   ) and   N   ( œÄ ) represent the amount of individual per- mutation   œÄ I   and existing permutation   œÄ , respectively. Taking   m =5 as an example, the effect of data length on the DIPs of five groups of sleep EEGs is illustrated in Fig. 4. DIP =   N   ( œÄ I   ) /N   ( œÄ )   (4) Fig. 4 shows that sleep EEG signals contain individual permutations whose probability distributions are affected by the signal length.   With the increase in data length from 1 to 10 s (2500 points), the DIP values of sleep EEGs decrease stepwise and tend to converge when the data length was larger than 20 s (5000 points).   There- fore, when the data length is short, there exist false for- bidden as well as false individual permutations, and they decay when the data length increases.   The DIP is also related to sleep conditions when the EEG length is more than 20 s. SIII and REM EEGs have larger DIPs when awake and SI EEGs exhibit smaller DIPs.   The exis- tence of forbidden and individual permutations suggests\n\n6  -0.03 0 0.03  -0.02 0 0.02  0 0.04  -0.05 0 0.05  0   500   1000   1500   2000   2500  sampling points  -0.01 0 0.01  0 0.1 0.2 0.3 0.4  DES  awake  SI  SII  SIII  REM  =1   =2 SI SII SIII REM awake  \\mV #   *  FIG. 3. Exemplary EEGs in awake, SI‚ÄìSIII, and REM states and the distribution of equal states (mean ¬± standard error) of sleep EEGs. The state in DES is the direct amplitude value during sleep EEGs. # indicates p < 0.0001 across all stages using the Kruskal‚ÄìWallis test and * suggests p < 0.01 between each two stages of sleep EEGs using Mann‚ÄìWhitney U test.  0   5   10   15   20   25   30  length  0 0.2 0.4 0.6  DIP (m=5,   =1)  0   5   10   15   20   25   30  length  0 0.2 0.4 0.6  DIP (m=5,   =2)  awake  SI  SII  SIII  REM  *250   *250  FIG. 4. Distribution of individual permutations (mean ¬± standard error) of wake, SI‚ÄìSIII, and REM EEGs.  that subtraction-based index is a necessity in quantita- tive TIR. Moreover, the length of EEG signals cannot be too low; they should be greater than 30 s in this study, otherwise these false individual permutations will lead to unreliable pTIR for the nonequilibrium analysis of sleep EEGs. Overall, there are equal values and individual permu- tations in sleep EEGs that affect pTIR analysis. Hence, the two basic ordinal patterns must be distinguished con- sidering the necessity of equal-value permutation, the subtraction-based probabilistic difference and require- ment of data length also should be paid attentions in pTIR of sleep EEGs.  B.   pTIR in sleep EEGs  Given the DIPs in sleep EEGs, dimension is set to 2, 3, and 4 in an enumerative manner. The increase in delay is equivalent to the reduction in signal sampling frequency, i.e., 250/ œÑ   Hz [55, 56]. To satisfy the Nyquist sampling rate (i.e., more than twice the signal band), the delay is set to 1‚Äì4, thus maintaining sufficient information about sleep conditions in EEG data. The pTIR of sleep EEGs in awake, SI‚ÄìSIII, and REM stages are shown in Fig. 5. Contrary to the DES in Fig. 3, the pTIR of sleep EEGs exhibit decreasing trends as the sleep depth increase, as shown in Fig. 5.   As the subjects come into sleep from wakefulness, the pTIR of EEG signals significantly de- crease; moreover, as the sleep depth increase, the pTIR consistently decrease.   Particularly, when subjects en- ter the REM state, the pTIR of EEGs show a consid- erable decrease.   The choice of dimension and delay do not affect the trend of EEGs‚Äô pTIR with the increas- ing sleep depth, but it affect the statistical discrimina- tions.   According to statistical results, when   m =3 and  œÑ   =1, the pTIR of EEGs in the five sleep stages exhibit optimal classification (p < 0.0001 for Kruskal‚ÄìWallis test). As shown in Fig. 5, more significant reductions are ob- served in the pTIR of EEGs from the awake to sleep and\n\n7  0 0.002 0.004 0.006 0.008 0.01  pTIR, m=2  0 0.005 0.01 0.015  pTIR,m=3  0 0.01 0.02 0.03  pTIR,m=4  awake   SI   SII   SIII   REM  =1   =2   =3   =4 =4 =3 =2 =1 =4 =3 =2 =1  #  #  * * * *  FIG. 5. pTIR (mean ¬± standard error) of wake, SI‚ÄìSIII, and REM EEGs. # indicates p < 0.0001 across all stages using Kruskal‚Äì Wallis test and * suggests p < 0.01 between pTIR of sleep EEGs and others using Mann‚ÄìWhitney U test.  SIII to REM stages when   m =2 and 3 and   œÑ   =1. There- fore, time irreversible features of brain electric activity decrease as the sleep stages advance, and more significant differences are observed in nonequilibrium features dur- ing the awake‚Äìsleep transformation and REM state. For comparison, the probabilistic differences between sym- metric AmPs, i.e., pTAS, are also calculated. The pTAS and pTIR yielded the same results, suggesting that equal- value AmPs reliably characterize the temporal structure of vectors in sleep EEGs and are not affected by the re- verse process in backward time series. It should be noted that equal values significantly affect the pTIR, and sleep EEGs generally contain numerous equal values [56]. Given the amplitude fluctuations mea- sured by DES in Fig. 3, the noeTIR and noeTAS of EEGs under the five sleep stages are calculated and shown in Fig. 6. As evident in Fig. 6, noeTIR and noeTAS of the five groups of sleep EEGs considerably differed and even showed completely contradictory results based on the nonequal AmP. The comparison shows that noeTIR re- sults exhibited a consistent classification of sleep stages with the pTIR, while noeTAS had contradictory results. Although pTIR and noeTIR demonstrated similar de- creasing trends with the increase in sleep depth, they were not the same in these EEGs.   Statistically, noe- TIR of sleep EEGs was not significantly different, while noeTAS with   m =3 and   œÑ   =1 effectively differed in the five groups of EEGs (p < 0.01 for Mann‚ÄìWhitney U test; p < 0.0001 for Kruskal‚ÄìWallis test). Figure 2 shows that when the signal contained equal elements and was reorga- nized in ascending order, the probabilistic differences of permutations between the forward and backward series were closer to the pTIR, while those of symmetric permu- tations had a greater deviation. Note that neither noe- TIR nor noeTAS yielded correct results. Taking   m =2 as an example, only up, down, and equal forms are observed, among which, equality was transformed into up in both the forward and backward series.   The pTIR, noeTIR, pTAS, and noeTAS were calculated using Eq. (5), where  up p ,   down p , and   equal p   represent the probability of up, down, and equal values, respectively, and   up p /down p   de- notes the probabilistic difference between   up p   and   down p  using   Y s .  Ô£± Ô£¥ Ô£¥ Ô£≤ Ô£¥ Ô£¥ Ô£≥  pTIR : 0 . 5   ‚àó   ( up p /down p   +   down p /up p ) noeTIR : 0 . 5   ‚àó   (   up p   + equal p  down p + equal p   +   down p /up p ) pTAS :   up p /down p  noeTAS : ( up p   +   equal p ) /down p  (5) In Eq. (5), pTIR is the same as pTAS, but different from noeTIR and noeTAS. Due to equal being mistaken as up, both noeTIR and noeTAS wrongly measure the time reversibility of sleep EEGs.   Evidently, if there is no equality, pTIR, noeTIR, pTAS, and noeTAS are the same. To compare with the pTIR, PEn [37, 54], i.e., the Shannon entropy of permutation probability   p ( œÄ ), given in Eq. (6), is further employed in the analysis of sleep EEGs. It is a widely applied statistical parameter used to measure the nonlinear characteristics of complex sys- tems [37]. The selection of OrP and AmP does not affect the calculation of PEn because PEn is the mean informa- tion contained in the existing ordinal patterns [40], while equal values affect PEn in signal analysis [50‚Äì52].   PEn based on equal-value AmP with delay from 1 to 4 and dimension ranging from 2 to 4 of sleep EEGs is displayed in Fig. 7. PEn =   ‚àí   ‚àë   p ( œÄ ) lnp ( œÄ )   (6)\n\n8  0 0.004 0.008  noeTIR, m=2  0 0.005 0.01 0.015  noeTIR, m=3  0 0.01 0.02  noeTIR, m=4  0 0.1 0.2  noeTAS, m=2  0 0.1 0.2 0.3 0.4  noeTAS, m=3  0 0.1 0.2 0.3 0.4 0.5  noeTAS, m=4  awake   SI   SII   SIII   REM  * #  =4 =2   =3 =1   =1   =1   =2   =3   =4 =2   =3   =4  FIG. 6. Contradictory noeTIR and noeTAS (mean ¬± standard error) in wake, SI‚ÄìSIII, and REM EEGs. # indicates p < 0.0001 across all stages using Kruskal‚ÄìWallis test and * suggests p < 0.01 between each of the two stages of sleep EEGs using Mann‚Äì Whitney U test.  0.7 0.8 0.9 1 1.1  PEn, m=2  1.5 2 2.5  PEn, m=3  3 4  PEn, m=4  awake   SI   SII   SIII   REM  =1   =2   =3   =4   =1   =2   =3   =4   =1   =2   =3   =4  FIG. 7. Permutation entropy (mean ¬± standard error) of wake, SI-SIII, and REM EEGs based on equal-value AmP.  As evident from Figs. 7 and 5, PEn is observed to be the opposite of pTIR in the five groups of sleep EEGs. When   m =2, PEn of EEGs increases as the subjects fell asleep and sleep depth increased, suggesting that EEGs have larger complexity with the increase of sleep stages. As   m   increases, no consistent trend is observed in the PEn complexity of EEGs with the increasing sleep stages. Statistically, the PEn of five groups of sleep EEGs is not significantly different.   Therefore, pTIR is more reliable for sleep stage classification owing to the quantification of EEG nonequilibrium features. The contradictory results of pTIR and PEn can be ex- plained by their statistical concepts.   Shannon entropy and TIR compute the difference in probability distribu-\n\n9 tions, but they focus on different sets of probabilistic differences.   PEn calculates the average amount of in- formation contained in the distribution of permutations, i.e., the probabilistic differences in all existing permuta- tions, whereas pTIR measures the difference between for- ward and backward permutation series or that between symmetric permutations of a series. Therefore, when the permutation probability difference is smaller, the entropy complexity of signals will be higher, while the TIR will be smaller. This is the fundamental reason for the opposite outcomes of pTIR and PEn in sleep EEGs, which is con- sistent with the contradictory results obtained in our pre- vious report on heartbeats [54]. Moreover, because they characterize complexity and nonequilibrium features, the results exhibit the diversity of features from different per- spectives of complex physiological signals and enable us to explore complex systems more comprehensively. The comparative analysis of sleep EEGs demonstrated that the TIR, TAS, and Shannon entropy have a complex relationship, as shown in Fig. 8.   TIR and TAS based equal-value AmP share same results while they yielded contradictory outcomes based on nonequal AmP. The trend of noeTIR is consistent with that of pTIR, while noeTAS exhibited different results in the five groups of sleep EEGs. PEn also presented contradictory findings in comparison to pTIR. To determine the difference between these associated measures and the influence of equal val- ues, probability distributions of AmPs are further ana- lyzed numerically. Taking   m =2 and   œÑ   =1 as an example, the probabilities of AmPs with and without equal values of five groups of sleep EEGs are shown in Fig. 8. Figure 8 shows that the distribution of false up (bold  ‚Äò1,2‚Äô ) in nonequal AmPs is a combination of real up (de- noted by ‚Äò1,2‚Äô) and equal (denoted by ‚Äò1,1‚Äô) in equal- value AmPs because equal values are replaced by up patterns, and that of equal values is the DES of sleep EEGs in Fig. 3. The distributions of downs (denoted by ‚Äò2,1‚Äô) are the same in the two types of ordinal patterns. In nonequal AmP, the probability distribution of up in- creases with the sleep depth, while that of down presents the opposite trend.   In equal-value AmP, the probabil- ity distributions of up and down are significantly close, and both decreased as the sleep depth increased. Equal- value AmPs further confirm our conclusion, as shown in Fig. 3, that fluctuations in the EEG amplitude decreased as the sleep depth increased.   Owing to the decrease in amplitude fluctuations in sleep EEGs, the probabilities of both ups and downs in sleep EEGs decrease, while those of equal values (i.e., DES) significantly increase with the sleep depth. The   probabilistic difference   in   AmPs and   different ways to use them directly influenced the different out- comes of pTIR, pTAS, and PEn in sleep EEGs.   Ac- cording to Eq. (5), numerical simulations suggest that the probabilistic difference between false up ( ‚Äò1,2‚Äô ) and down (‚Äò2,1‚Äô) in nonequal AmPs, i.e., (‚Äò1,2‚Äô+‚Äò1,1‚Äô)/‚Äò2,1‚Äô, increased with the sleep depth; hence, noeTAS in Fig. 6 also increased with the sleep depth.   In the backward EEG signal, equal values were transformed into up ‚Äò1,2‚Äô. Therefore, noeTIR is measured using the sum of forward- backward probabilistic differences between up and down, i.e., 0.5*[(‚Äò1,2‚Äô+‚Äò1,1‚Äô)/(‚Äò2,1‚Äô+‚Äò1,1‚Äô)]+‚Äò2,1‚Äô/‚Äò1,2‚Äô, exhibit- ing a decreasing trend in sleep EEGs, as shown in Fig. 6. However, neither noeTIR nor noeTAS truly quantified the nonequilibrium characteristic of sleep EEGs. Mean- while, in equal-value AmPs, pTIR represented the prob- abilistic difference between up and down because equal- ity indicated time reversibility and temporal symmetry, while PEn measured the probabilistic difference between up, down, and equality. Numerical results indicated that the probabilistic difference in up and down decreased as the sleep depth increased, while the average amount of in- formation contained in up, down, and equality increased. Therefore, the pTIR in Fig. 5, i.e., up-down probabilis- tic differences, decreased with the increasing sleep depth, while the PEn of EEGs in Fig. 7 increased with the sleep depth. Hence, the probability distribution of sleep EEG permutation and different usage of probabilistic differ- ence of pTIR, pTAS, and PEn are responsible for the conflicting results in sleep EEGs. In ordinal patterns and permutation analysis, elements are reordered in the ascending order; however, it remains unclear how these methods perform of a series reordered in the descending order. In ordinal patterns, if equal val- ues are organized according to their order of occurrence, they will be treated as down in nonequal permutations in the descending order. If indexes of equal values are mod- ified to be the same in their corresponding groups, the AmP and OrP have the same relationship as that shown in Fig. 1; moreover, the results for TIR, TAS, and PEn show no difference in the ascending order. Otherwise, if the indexes of equal values are not modified, these per- mutation methods might still generate incorrect results as the ascending order. Particularly, noeTAS yields dif- ferent outcomes in the ascending and descending orders. The results of noeTAS ( m =2 and   œÑ   =1) for sleep EEGs are shown in Fig. 9. In the ascending order, noeTAS is the probabilistic dif- ference between ‚Äò up p   +   equal p ‚Äô and ‚Äò down p ‚Äô, while in the descending order, noeTAS is measured by the probabilis- tic difference between ‚Äò down p   +   equal p ‚Äô and ‚Äò up p ‚Äô.   The two noeTAS share consistent results, i.e., their value in- creases as the sleep stage progresses; meanwhile, they are both incorrect. Ordinal pattern is a simplified alternative to the vec- tor; their construction is a coarse-grained procedure to signals. Weak noises and artifacts are eliminated during the generation of permutations; therefore, permutation analysis exhibits evident noise insensitivity [37‚Äì39].   To further test the pTIR, Gaussian noises are added and some frequency components are removed from the sleep EEG data of the five groups. These procedures through\n\n10  pTIR   pTAS noeTIR   noeTAS PEn  0 0.2 0.4 0.6 0.8  Probability distribution  0 0.2 0.4 0.6 0.8  awake  SI  SII  SIII  REM  up   '1,2'   down '2,1'   up '1,2'   equal '1,1' down '2,1'  nonequal AmP   equal-value AmP a)   b)  FIG. 8. Relationship of permutation analysis in sleep EEGs and probability distributions (mean ¬± standard error) of AmPs when dimension is 2 and delay is 1. a) Consistent results of pTIR and pTAS are linked by black solid arrows, while contradictory results of noeTIR and noeTAS are connected by crossed red dashed arrows. b) Probability distributions of down ‚Äò2,1‚Äô in the two types of AmPs are the same, while those of bold   ‚Äò1,2‚Äô   in nonequal AmPs are the sum of those of up ‚Äò1,2‚Äô and equal ‚Äò1,1‚Äô in equal-value AmPs.  0 0.1 0.2 0.3  noeTAS, m=2,   =1  awake  SI  SII  SIII  REM  ascending   descending  FIG. 9.   Different noeTAS (mean ¬± standard error) in wake, SI-SIII, and REM EEG data in ascending and descending ordinal patterns.  software (e.g., MATLAB in this work) eliminate equal values and the information conveyed by DES [56] from sleep EEG data.   Therefore, no difference was observed between TIR and TAS based the ordinal pattern, regard- less of the ascending or descending order. Taking   m =2 and   œÑ   =1 as an example, when Gaussian noises with signal noise ratio (SNR) from 0-0.01 dB are added, the results are not significantly affected that the pTIR values of EEG data decrease as the sleep stage progresses. Alternatively, when a 0.3‚Äì35 Hz bandpass filter is implemented to the sleep EEG data, pTIR also shows a decreased trend with the increase of sleep stages, confirming the robustness of permutation analysis [37‚Äì39]. According to the research on pTIR for sleep classifi- cation, pTIR effectively quantifies nonequilibrium char- acteristics in EEGs, yielding more reliable results than the entropy measure. Owing to the important influence of equal values on ordinal patterns, equal-value permuta- tion is necessary in the pTIR analysis of sleep EEGs. The TIR, TAS, and PEn based on equal-value and nonequal permutations yielded different or even opposite results in the 5 groups of sleep EEG signals; however, this helped us in gaining a deeper understanding of the differences be- tween analytical methods, important role of equal values, and multifaceted characteristics of complex physiological signals.  IV.   DISCUSSIONS  In the research on pTIR in sleep EEGs, several issues should be further discussed. Equal values in time series and their effect on permuta- tion analysis should be given sufficient attention. Equal values are generally ignored considering the limitation resolution of ADC, particularly coarse-grain quantiza- tion. In traditional signal processing theory, an arbitrary time series with a weak stationarity exhibits a continu- ous distribution; therefore, equal values are rare and can be broken numerically by adding small random perturba- tions [37]. The traditional treatment to equality is based on the assumptions that equal values have no significant effect on signal processing and they do not contain infor- mation about systems.   These assumptions are not cor- rect. Equal values significantly impact permutation anal- ysis. Moreover, they are necessary for the comprehensive construction of ordinal patterns [40]. As shown in Fig. 1, irrespective of the OrP or AmP, the structural informa- tion of vectors can be fully displayed only when equal values are considered. The distribution of equal values in some signals conveys important information and has sig- nificant effects on the construction and probability of or- dinal patterns, thus yielding different or even contradic- tory results, such as the results presented in Figs. 5 and 6.\n\n11 According to our previous report, PEn and pTIR exhib- ited contradictory results for PhysioNet heartbeats data with and without equal values [54]. In time reversibility, vectors with equal values might be self-symmetric, such as those in Figs. 1 and 2, and have definitive physical im- plication, i.e., time reversibility and temporal symmetry [40, 42]. Under acceptable ADC resolution, the DES are an effective parameter for quantifying signal amplitude fluctuations in extreme forms, i.e., zero fluctuation. The advantages of DES have been observed in the characteri- zation of sleep and epileptic EEGs [55, 56]; they also ex- hibit reliable performance in heartrate data (derived from electrocardiography) to reflect the decrease in heart rate variability with age and heart failure [53]. If the ADC has a high resolution or the data undergo preprocessing (e.g., software filtering), equal states are rarely observed and amplitude fluctuation information cannon be detected; in this case, a low-pass threshold can be established to filter the differential states for measuring the amplitude fluctu- ation [56]. Otherwise, the equalities can be increased by further coarse graining the digital signal, such as the par- tition symbolic transformation that resembles the ADC. It should be noted that the results of DES were consis- tent with those of pTIR for sleep EEGs. The amplitude fluctuation of signals is the most direct representation of system information, which is influenced by various factors such as frequency composition and dynamic characteris- tics. According to Figs. 3 and 8, the DES of EEG signals increased with the sleep depth, indicating that the am- plitude fluctuation decreased.   In the previous analysis of heartrate signals, amplitude fluctuations in heartrate decreased with age and heart failure, consistent with the theory of loss of complexity [53]. Our results further con- firmed the positive correlation between amplitude fluctu- ations and time irreversible features, and whether there exist other factors closely related to amplitude fluctua- tions require further research. Overall, the distribution of equal values conveyed important information about am- plitude fluctuation and significantly affected signal pro- cessing; moreover, it is required to construct reliable or- dinal patterns and has explicit physical meaning in TIR; hence, equal values cannon be ignored. Time reversibility and temporal symmetry are equiva- lent in statistical definitions, even though they may gen- erate different results in real-world quantification.   In pTIR and pTAS, the construction of ordinal patterns, particularly the treatment of equal values, plays an im- portant role. In traditional ordinal patterns, equal values are generally ranked according to their order of emer- gence. Considering double values, there are three kinds of permutations, namely up, down, and equal. In the tra- ditional ordinal, equal values are neglected and treated as up. As shown in Figs. 2 and 8, the probabilistic difference between ‚Äôup+equal‚Äô and down is calculated in noeTAS, while that between ‚Äòup+equal‚Äô and ‚Äòdown+equal‚Äô is mea- sures in noeTIR. Numerical calculations demonstrated that the difference in forward-backward permutations was closer to the pTIR than that in symmetric permu- tations, but both were wrong. The noeTIR and noeTAS were both incorrect and not the same. Taking an extreme example, for a series of all-equal values, the pTAS is 1, indicating the difference between all up and zero down, while the noeTIR is 0 for the forward and backward se- ries (it is the same as the pTIR of 1). If more values are considered, the situation will become more complex. Next, the relationship between PEn and pTIR requires more discussion.   Test results indicated that pTIR en- ables the more effective classification of sleep stages than PEn, consistent with the results of our previous report on epilepsy EEGs [14]. TIR and Shannon entropy are both statistical parameters for measuring probabilistic differ- ences; they are both widely employed in complex process analysis. Shannon entropy quantifies the static complex- ity and unpredictability considering the amount of infor- mation, i.e., the mean logarithmic calculation of all prob- abilities of permutations. TIR measures nonequilibrium features considering the sum of probabilistic differences between vectors in forward-backward series or pairs of symmetric vectors. Mathematically, if two permutations have larger probabilistic differences, they convey less in- formation while being more nonequilibrium, thus lead- ing to smaller PEn and bigger pTIR. In the special case where all permutations of symmetric vectors have the same probability distribution, PEn reaches a maximum value while pTIR is 0. In another special case where all permutations are single permutations, pTIR is the maxi- mum 1 while PEn varies with the difference among prob- ability distributions. This is the fundamental reason for different or even contradictory results in the same pro- cess. Similar results have also been reported in heartrate analysis [54]; irrespective of nonequal or equal-value per- mutation, PEn and pTIR yielded contradictory results. Such discrepant results of pTIR and PEn inspired us to gain a more comprehensive and profound understanding of the characteristics of complex systems from different perspectives. Forbidden permutation is an important influencing fac- tor that is generally overlooked in the pTIR analysis of real-world signals.   The existence of forbidden permu- tations might generate individual permutations, which have no symmetric form in forward series and de not ex- ist in backward series; moreover, their probabilistic dif- ference is zero or infinite considering division-based pa- rameters, which is not appropriate in quantitative TIR. Associated with forbidden permutations, individual per- mutations also convey information about sleep EEGs. In Fig. 4, the DIPs generally increased with the sleep stage when the data length was larger than 20 s. This may be because as the sleep depth increased, amplitude fluctua- tions, type of temporal structure, and number of ordinal patterns decreased, yielding more forbidden as well as individual permutations.   Similar associations have also\n\n12 been reported in epileptic EEG analysis [14, 55]. Seizure ictal EEGs exhibit abnormally large amplitude fluctua- tions and TIR owing to the development of synchronous neuronal firings, while seizure-free postictal brain activ- ity exhibits rather smooth amplitude fluctuations as well as smaller TIR [55].   Consistently, brain electric signals under ictal and postictal states demonstrate larger and smaller DIP values, respectively [14]. In a series of related studies, Amigo et al. found that the existence of forbid- den patterns is a feature of chaotic dynamics and can be used to distinguish random from pseudorandom orbit generation [43]; subsequently, they identified false for- bidden patterns [44] and detected determinism in noisy time series based on the properties of topological PEn [45].   The decay rate of forbidden permutations [47] in stochastic processes has been reported to be associated with their correlation structures; moreover, nonlinearity in time series can be possibly detected by the number of forbidden permutations [48, 49].   Given the systematic information conveyed by forbidden permutations and as- sociation of DIPs with sleep stages, individual permuta- tions might also be potentially used for feature detection in complex systems.  V.   CONCLUSIONS  In this study, pTIR in sleep EEG particular the depen- dence on sleep stage and the effect of equal EEG values are analyzed. Main findings are summarized below: Permutation TIR is an important measure for the quantification of nonequilibrium EEGs. When symmet- ric vector differences are used for real-time requirements, AmP is more suitable as a direct alternative to vec- tor. Moreover, equal-value ordinal patterns are required because they construct comprehensive vector structures and self-symmetric vectors convey an important physical implication, i.e., time reversibility. Brain electrical activity demonstrates nonequilibrium features that are influenced by sleep conditions.   EEGs during wakefulness exhibit higher pTIR; during sleep and with the advancement of sleep stages, the pTIR values of EEGs significantly decrease. These findings suggest that when people fall asleep, their brain electric activity con- tains less nonequilibrium characteristics.   The effective classification of sleep EEGs suggested that pTIR could serve as an aid for the expert manual annotation of sleep stages. When constructing ordinal patterns, if equal values are ordered according to their order of occurrence, the values of noeTIR and noeTAS may be inconsistent, and even if noeTIR is closer to the actual result, they would both be wrong.   Moreover, noeTAS performs differently over series reordered in the ascending and descending orders. Therefore, the consideration of equal values is necessary to construct reliable permutations, and it is important to modify the indexes of equal values to same forms in permutation TIR. Equal values and individual permutations affect the pTIR, but both DES and DIP contain important infor- mation about sleep EEGs. The DES characterize ampli- tude fluctuations in sleep EEGs such that as the sleep stages advance, DES values significantly increase as am- plitude fluctuations decrease.   The DIP may be related to structures that require further investigation. Comparative analysis of pTIR and PEn as well as nu- merical simulations of permutation probability distribu- tions verified the different and even contradictory results of time reversibility and entropy complexity, thus pro- viding us with valuable insights on statistical measures and enabling us to explore complex physiological signals more comprehensively.  VI.   ACKNOWLEDGMENT  The project is supported by the Natural Science Foun- dation   of   Jiangsu   Province   (Grant   No.BK20220383), Natural   Science   Research   of   Jiangsu   Higher   Educa- tion   Institutions   of   China   (Grant   No.22KJB110003), Natural Science Foundation of Nanjing   University of Posts and Telecommunications (Grant Nos. NY221142, NY222172), Shanghai Municipal Science and Technology, China Major Project (Grant No. 2018SHZDZX01), Key Laboratory of Computational Neuroscience and Brain- Inspired Intelligence (LCNBI) and ZJLab.  [1] A. K. Andrea, B. Misic,   and O. Sporns, Nature Reviews Neuroscience   19 , 17 (2018). [2] A. Bashan, R. P. Bartsch, J. W. Kantelhardt, S. Havlin, and P. C. Ivanov, Nature Communications   3 , 702 (2012). [3] D. Zhao, Y. Wang, Q. Wang,   and X. Wang, Computer methods and programs in biomedicine   175 , 53 (2019). [4] H. Phan and K. Mikkelsen, Physiological Measurement  43 , 04TR01 (2022). [5] Y. Ma, W. Shi, C.-K. Peng,   and A. C. Yang, Sleep medicine reviews   37 , 85 (2018). [6] W. Xiong, L. Faes,   and P. C. Ivanov, Physical Review E   95 , 062114 (2017). [7] F. Hou, L. Zhang, B. Qin, G. Gaggioni, X. Liu,   and G. Vandewalle, Sleep   44   (2021). [8] C. Bandt, Entropy   19 , 197 (2017). [9] X. Liang, J. Xiong, Z. Cao, X. Wang, J. Li,   and C. Liu, Physiological Measurement   42 , 044001 (2021). [10] Y.-H. Wang, I.-Y. Chen, H. Chiueh,   and S.-F. Liang, IEEE   Transactions   on   Instrumentation and   Measure- ment   70 , 1 (2021).\n\n13  [11] V. Miskovic, K. J. MacDonald, L. J. Rhodes,   and K. A. Cote, Human brain mapping   40 , 538 (2019). [12] X. Fang, K. Kruse, T. Lu,   and J. Wang, Reviews of Modern Physics   91 , 045004 (2019). [13] C. W. Lynn, E. J. Cornblath, L. Papadopoulos, M. A. Bertolero, and D. S. Bassett, Proceedings of the National Academy of Sciences   118   (2021). [14] W. P. Yao, J. Dai, M. Perc, J. Wang, D. Yao,   and D. Guo, Nonlinear Dynamics   100 , 907 (2020). [15] W. P. Yao, J. Wang, M. Perc, W. L. Yao, J. Dai, D. Guo, and D. Yao, Communications in Nonlinear Science and Numerical Simulation   96 , 105688 (2021). [16] J. H. Martinez, J. L. Herrera-Diestra,   and M. Chavez, Chaos: An Interdisciplinary Journal of Nonlinear Science  28 , 123111 (2018). [17] J. A. Martin Gonzalo, I. Pulido Valdeolivas, Y. Wang, T.   Wang,   G.   Chiclana   Actis,   M.   d.   C.   Algarra   Lu- cas, I. Palm¬¥ ƒ± Cort¬¥ es, J. Fern¬¥ andez Travieso, M. D. Tor- recillas Narv¬¥ aez,   A. A. Miralles Martinez,   E. Rausel, D. G¬¥ omez Andr¬¥ es,   and M. Zanin, Entropy   21 , 868 (2019). [18] M. Zanin, Chaos:   An Interdisciplinary Journal of Non- linear Science   31 , 103118 (2021). [19] G. Weiss, Journal of Applied Probability   12 , 831 (1975). [20] F. P. Kelly,   Reversibility and stochastic networks   (Cam- bridge University Press, Chichester, 1979). [21] J. B. Ramsey and P. Rothman, Journal of Money Credit & Banking   28 , 1 (1995). [22] M. D. Costa, A. L. Goldberger, and C. K. Peng, Physical Review Letters   95 , 198102 (2005). [23] M. D. Costa, C. K. Peng,   and A. L. Goldberger, Car- diovascular Engineering   8 , 88 (2008). [24] A. Porta, K. R. Casali, A. G. Casali, T. Gnecchi-Ruscone, E. Tobaldini, N. Montano, S. Lange, D. Geue, D. Cysarz, and P. Van Leeuwen, American Journal of Physiology Regulatory Integrative & Comparative Physiology   295 , 550 (2008). [25] P. Guzik, J. Piskorski, T. Krauze, A. Wykretowicz,   and H. Wysocki, Biomedizinische Technik Biomedical Engi- neering   51 , 272 (2006). [26] C. L. Ehlers, J. Havstad, D. Prichard,   and J. Theiler, Journal of Neuroscience the Official Journal of the Soci- ety for Neuroscience   18 , 7474 (1998). [27] L. Lacasa, A. Nunez, E. Roldan, J. M. R. Parrondo, and B. Luque, European Physical Journal B   85 , 217 (2012). [28] L.   Lacasa   and   R.   Flanagan,   Physical   Review   E   92 , 022817 (2015). [29] R. Flanagan and L. Lacasa, Physics Letters A   380 , 1689 (2016). [30] L. Lacasa, B. Luque, F. Ballesteros, L. Jordi,   and J. C. Nuno, Proceedings of the National Academy of Sciences of the United States of America   105 , 4972 (2008). [31] J. F. Donges, R. V. Donner, and J. Kurths, Europhysics Letters   102 , 381 (2013). [32] Y. Zou, R. V. Donner, N. Marwan, J. F. Donges,   and J. Kurths, Physics Reports   787 , 1 (2019). [33] H. Zeng, M. Alava, E. Aurell, J. Hertz,   and Y. Roudi, Physical Review Letters   110 , 210601 (2013). [34] H. Zeng, E. Aurell, M. Alava,   and H. Mahmoudi, Phys- ical Review E   83 , 041135 (2011). [35] C. S. Daw, C. E. A. Finney,   and E. R. Tracy, Review of Scientific Instruments   74 , 915 (2003). [36] C. Cammarota and E. Rogora, Chaos, Solitons & Fractals  32 , 1649 (2007). [37] C. Bandt and B. Pompe, Physical Review Letters   88 , 174102 (2002). [38] C. Bandt, ‚ÄúPermutation entropy and order patterns in long time series,‚Äù in   Time Series Analysis and Forecast- ing   (Springer, 2016) pp. 61‚Äì73. [39] C. Bandt, Statistical Papers   61 , 1565 (2020). [40] W. Yao, W. Yao,   and J. Wang, Physics Letters A   430 , 127977 (2022). [41] W. Yao, W. Yao, J. Wang,   and J. Dai, Physics Letters A   383 , 738 (2019). [42] W. Yao,   W. Yao,   R. Xu,   and J. Wang, Communi- cations in Nonlinear Science and Numerical Simulation  117 , 106925 (2023). [43] J. M. Amigo, L. Kocarev,   and J. Szczepanski, Physics Letters A   355 , 27 (2006). [44] J. M. Amigo, S. Zambrano,   and M. A. Sanju¬¥ an, Euro- physics Letters   79 , 50001 (2007). [45] J. M. Amigo, S. Zambrano,   and M. A. Sanju¬¥ an, Euro- physics Letters   83 , 60005 (2008). [46] M. Zanin, Chaos:   An Interdisciplinary Journal of Non- linear Science   18 , 013119 (2008). [47] L. C. Carpi, P. M. Saco,   and O. Rosso, Physica A: Sta- tistical Mechanics and its Applications   389 , 2020 (2010). [48] C. W. Kulp, L. Zunino, T. Osborne,   and B. Zawadzki, Physical Review E   96 , 022218 (2017). [49] D. Cuesta Frau, Entropy   22 , 494 (2020). [50] C. Bian, C. Qin, Q. D. Ma, and Q. Shen, Physical Review E   85 , 021906 (2012). [51] L. Zunino, F. Olivares, F. Scholkmann, and O. A. Rosso, Physics Letters A   381 , 1883 (2017). [52] D. Cuesta Frau, M. Varela Entrecanales, A. Molina Pico, and B. Vargas, Complexity   2018 , 1324696 (2018). [53] W. Yao, W. Yao,   and J. Wang, Physics Letters A   383 , 1764 (2019). [54] W. Yao, W. Yao, D. Yao, D. Guo, and J. Wang, Applied Physics Letters   116 , 014101 (2020). [55] W. Yao, W. Yao, Y. Ju, Y. Xia, D. Guo,   and D. Yao, Biomedical Signal Processing and Control   69 , 102738 (2021). [56] W. Yao, W. Yao,   and J. Wang, Physiological Measure- ment   44 , 095004 (2023). [57] A. L. Goldberger, L. A. Amaral, L. Glass, J. M. Haus- dorff, P. C. Ivanov, R. G. Mark, J. E. Mietus, G. B. Moody, C. Peng,   and H. E. Stanley, Circulation   101 , e215 (2000). [58] A. Rechtschaffen and A. Kales,   A manual of standard- ized terminology, techniques and scoring system for sleep stages of human subjects   (U.S. Government Printing Of- fice, National Institute of Health Publication, Washing- ton, D.C.,, 1968). [59] Y. Ichimaru and G. B. Moody, Psychiatry and Clinical Neurosciences   53 , 175 (1999).",
    "1  Quantum Anti-Zeno Treatment of Zeno-type Sleep Disorders  Rajat Kumar Pradhan* Rajendra College, Bolangir, Odisha, India-767002 (Date: 19.11.2011)  Abstract  It is proposed that for those sleep disorders of psychological origin which can be considered to be a Quantum Zeno Effect-type phenomenon of   persistence in the waking state   due to the inhibition of the transition to the Deep Sleep state, the treatment may very well lie in the application of the principle of   accelerating the decay by the introduction of a third state   which facilitates the transition as realized in the Quantum Anti-Zeno effect. Steps of practical therapeutic implementation of the program are delineated. Keywords: Quantum Zeno Effect, Quantum Anti-Zeno Effect, Sleep Disorders, Insomnia, States of Consciousness. PACS Numbers: 03.65.Xp, 87.19.Xx, 87.10+e, 87.19La  *email:   rajat@iopb.res.in\n\n2  1. Introduction  Quantum theory[1,2,3] is gradually proving to be the most versatile and the most successful framework for the investigation of diverse phenomena in the realms of matter as well as mind.   It has been proposed that the well-known Quantum Zeno Effect (QZE)[4,5] plays the most important role   in   establishing   the   mind-brain   relationship[6,7]   through   continued   attention.   That   the phenomena in the planes of the physical and the psychical have a lot of parallels and that they can be described by very similar methods was realized long ago by Pauli and Jung[8]. It has also been proposed recently by the present author[9] that the three states of consciousness, viz. waking, dreaming and sleep, experienced daily may be described by the composition of two spin-like quantum mechanical observables characterizing the subject and the object. The formulation is such that it allows for finer experiential modes or levels within each state or band. For example, one can say that the experiential state   |   (   i ,t)>   at time t is that of the i th   thought-form   i . In the waking state   |   1 (   i ,t)>   each thought-form has an objective counterpart   i   in the external physical world whose neural correlate is perceived as that thought-form or mental image   i . Similarly, we can also characterize the dream state at time t as   |   2 (   i ¬¥,t)>   ( ‚Äòt‚Äô is the waking time)   when the dream-form   i ¬¥ corresponding to   i   is experienced.   The continuous streams of such thought-forms make up our daily experience in the waking and dream states. However, the state of deep sleep   |   3 >   happens to be different since it is characterized by   non-perception   of   either   the   internal   thought-forms   or   of   their   external   objective counterparts. It is an objectless and thoughtless state of ignorance or unconsciousness that we call deep sleep. The period spent by a healthy adult in deep sleep is roughly 6-7 hrs/day i.e. about one-third of the period spent in non-sleep. The transition to sleep and also the emergence therefrom is usually through the intermediate state of dream   |   2 >   in healthy and normal persons although the direct route is also available[9]. Insomnia (sleeplessness) then becomes a phenomenon in which the transition from   |   1 >   to   |   3 >   through the direct and the dream routes is inhibited due to any one or more of the three factors: (a) Environmental factors (b) Physiological factors and (c) Psychological factors. In this article, we shall assume that the first two factors are either absent or have been fully taken care of and that the sleep disorder is due only to the psychological causes i.e. the patient tries to sleep at the appropriate time but because of some thoughts running riot in his head he is unable to   ‚Äò switch himself off   ‚Äô   to move into dream and consequently to sleep. (It is to be remembered that normally the pre-sleep dreams are not registered as experience unless  some disturbance wakes one up in the threshold of one‚Äôs entry into deep sleep. ). Just as a person can come directly to   |   1 >   from   |   3 >   when there is some sudden disturbance (external noise or some other such forceful sensory input), so also the sleeping pills can enforce the direct transition to   |   3 >   from   |   1 >   which is more important in the treatment in acute cases. This is because the dream route requires   |   4 > , the fourth state, which is even more difficult to pass on to compared to   |   3 >   in the case of patients with acute sleep disorder. However, once the acuteness is reduced by medication, the case is not cured but reduces to chronic insomnia. Thus, we assume that once the patient is led into   |   2 > , the transition to   |   3 >   is automatic and smooth and the central problem then becomes one of effecting the transition from   |   1 >   to   |   4 >   which will lead naturally to   |   2 >   and from then on to   |   3 > .\n\n3  We propose that this particular type of insomnia can be modeled as a QZE-type inhibition of the transition from   |   1 >   to   |   4 >   due to the persistent experience of the rioting thoughts in the waking state. This persistent experience of the waking state is the counterpart of inhibition of transition due to continuous measurement in QZE. We propose further a non- medicinal treatment of the same disorder basing on the inverse phenomenon of Quantum Anti-Zeno Effect (QAZE) [10,11], wherein the intentional introduction of an auxiliary state  |   1 (   a , t)> facilitates this transition. In section-2 we paraphrase the problem of stress-induced insomnia as a QZE and in section-3   we   present   the   proposed   solution   via   QAZE.   In   section-4   practical   steps   of eliminating the environmental and physical factors and of aiding the QAZE transition are delineated which can be practiced under expert supervision for the first one week or so individually or in groups. Afterwards, the patients may be asked to continue the method of perfecting the QAZE-transition themselves. In section-5 we conclude with a discussion of the limitations of the method and other possible applications. The whole article is written in a non-technical manner so that it is easily accessible to doctors, psychiatrists as well as to the patients and laymen.  2. Insomnia as Quantum Zeno Effect  The majority of secondary insomnia cases happen to be due to psychological factors which delay the onset of sleep beyond limit and the patients complain of uncontrollable thoughts running riot the moment they retire to bed and close their eyes. The problem gets further complicated by the apprehension of recurrence of the same phenomenon every night and this weakens the will of the patients considerably and they complain of recurrent sleepless nights i.e. chronic insomnia. In most of the cases, it is found that the kinds of thoughts that bother them are mostly those of some past or future trouble. It is only very rarely that one gets sleep disorders due to too much of pleasant experiences. Pleasant experiences, fancies and fantasies usually usher in good sleep! It is the unpleasant experiences like disasters and debacles, fears and phobias, failures and frustrations, insults and abuses, mishaps and misfortunes, losses and bereavements, traumas and tortures etc. which one has undergone or is likely to undergo that come to haunt the patient on the bed. The patient may struggle for hours together without getting any semblance of sleep and this phenomenon in chronic cases may continue even beyond a month or so. This is the case that can be taken up as a classic illustration of Quantum Zeno Effect in the psychological domain, where the continuous cognizance of the problematic thoughts   p   by the consciousness prevents the momentary slide into the fourth state which could have brought the dream state on, and which in its sequel would have ushered in deep sleep. It is proposed here that this inhibited transition from   |   1 (   p   ,t)> to   |   4 >   due to continuous observation can be removed by recourse to the inverse process of Quantum Anti-Zeno Effect.  In fact, it seems that all cases of insomnia, including the primary ones of unknown causes, whether chronic or acute, can be considered as being effectively due to this kind of QZE and correspondingly can be cured using QAZE. It is clear that the proposed solution will have to be of the psychological type, and hence, non-medicinal, but one that can easily be practiced by anyone suffering from any kind of insomnia. In this respect, when it comes to the choice of an auxiliary state in QAZE for fixing the attention on, it is worth emphasizing that of the many involuntary processes that continue throughout the day including the period of deep sleep the most important\n\n4  and vitally significant one is respiration and the awareness effortlessly but very effectively be fixed on the breathing process.  3. Insomnia Treatment by Quantum Anti-Zeno Effect  The insomnia patient‚Äôs main trouble is the inability to withdraw the mind from the  problematic thoughts and this can effectively be dealt with by introducing another thought on which the attention can be easily fixed. This new thought will be the auxiliary thought-form with a greater awareness and willful attention than the problematic thought-form and it will decrease the frequency with which the problematic thoughts were engaging the attention. The characteristic restlessness of the mind implies that it gets bored of monotony and one-pointedness and if continuously and consciously it is fed with something monotonous it will easily lapse into sleep. Consciously trying to focus on this auxiliary thought-form will gradually bring in the required transition to the fourth state from which the patient will move into the dream and from then on to deep sleep. This is the program of treatment by the ant-Zeno effect. In many situations in physics, it has been observed that a normal transition is inhibited by the QZE and is accelerated by the QAZE in the presence of the auxiliary state. Further as required by the theory of QAZE, the auxiliary state is of higher energy (i.e. frequency) compared to the problem state and admits of transitions back and forth with it. This is precisely the case here but only thing is that we are considering the application in a psychological setting. The four states of consciousness are depicted in Fig. 1a below and in Fig. 1b we show all the transitions as per the QAZE.  As shown in Fig.1a, for normal persons, the transition from waking to dream through the thin layer of the fourth state is naturally accomplished without any effort and then deep sleep ensues as a matter of course, while for the insomniac this transition is inhibited by the QZE-type continuous dwelling in the problematic waking state   |   1 (   p   ,t)>. In Fig. 1b,   |   1 (   a   ,t)> is the auxiliary waking state with a different thought-form   a ,   introduced   to   divert the attention from   p   and thus disrupt the QZE. Again, there will be a seeming tussle between   a   and   p   to engage the patient‚Äôs  continued attention and in the beginning the auxiliary state may seem to be an additional complication!   It is almost an implementation of the old adage: ‚Äú  set a thief to catch a thief !‚Äù   But, it works, thanks to the mysterious nature of Quantum phenomena which baffle classical thinking, whether applied to the physical or the psychological phenomena, and one finds to  |   4 >  FIG. 1 a :   Schematic of the four states of conscious -  - ness with   |   4 >   as common background  WAKING:   |   1 >  AUXILIARY STATE :   |   1 (   a   ,t)>  PROBLEM   STATE :   |   1 (   p   ,t)>  DREAM STATE:   |   2 >  DEEP SLEEP STATE :   |   3 >  THE FOURTH STATE:   |   4 > ( Both   individual awareness and willful attention  increase vertically upwards in this diagram)  FIG. 1b   : The transitions in the QAZE sequence  DREAM:   |   2 >  DEEP SLEEP:   |   3 >\n\n5  one‚Äôs surprise that in a matter of   about ten minutes to half an hour or so, the patient will be fast asleep via the QAZE transitions! Now comes the question of the exact nature of the auxiliary thought   a , which is of central importance in the entire process. Although   a   could be any pleasant thought-form on which the patient likes to dwell upon for a longer period, it turns out that the most effective, unbiased and natural choice is the   ‚Äò  attention on the breath ‚Äô . Just gently trying to focus on the normal, natural, relaxed breathing will do the trick! Initially, if need be, one may count the exhalations   one   by   one   serially   if   the   disturbance   from   the   thought(s)   p   is   a   bit uncontrollable, but after the first five minutes or so, one may stop counting and try to concentrate   only   on   the   natural   breathing   pattern   without   bothering   much   about   the frequency of   p . In the first few attempts the patient may feel a little tired or bored of the entire exercise, and may, if need be, allowed to have an accompanying mental utterance of some self-chosen holy name or formula ( mantra) depending on the faith and temperament. This has a very helpful effect but it is not absolutely necessary in all cases. Only a little patience on the part of the patient in participating in the whole therapy will work wonders even if   a   is  only the ‚Äòconcentration on the breathing‚Äô.  It is to be emphasized that the conscious focusing of attention on   a   must not be considered as a fight or a battle with the persistence of   p , rather, one should deal with the issue in a very mild and gentle manner allowing the mind its own freedom of dwelling on   p  every now and then. The only job is to focus on   a , and not to fight a battle with   p . As many times as it wonders off to   p , so many times very calmly and gently it should be brought back to   a   without generating any tension or sense of struggle.  4. Practical steps of Anti Zeno-therapy  The most important part of this delicate method of treatment is the preparation stage for the application of the Anti-Zeno therapy to insomnia cases. It is to be emphasized that the three conditions necessary for an early onset of sleep are: (a) a relaxed body (b) a natural rhythmical breathing and (c) a calm, tension-free mind.   In one phrase it is ‚Äòa total relaxation‚Äô of the individual - relaxed body, relaxed breathing and relaxed mind. Therefore, apart from ensuring that the patient has the right kind of cooperative attitude to receive the therapy and a positive attitude towards the efficacy of the therapy the following steps may be noted by the therapist:  Removal/avoidance of all environmental and physiological factors which have the potential to disturb or delay the onset of sleep i.e. stimulating food, drinks, music and video that excite the mind too much. All sensory inputs throughout the day must invariably be of a soothing nature which helps bring about a calm interior. All kinds of worries, cares and anxieties are to be avoided at all costs.  Making available all the helpful factors for inducing sleep such as:   (a) sleeping on back or on the left side (b) remaining fully engaged in some self-chosen work which the patient enjoys doing in the most relaxed manner possible during the day (c) regularity of the daily schedule of life etc.  Instructions may be given directly or through a record-player in a commanding voice to start with, followed by a gradual switch over to a very soothing and sweet voice as the patient is guided into deep sleep. The commands in the beginning lessen the vehemence of the problematic thoughts by much, more so if the treatment is in a group. They also have a very\n\n6  positive impact on the overall receptivity of the patient and the fixing of attention on the breath becomes much easier.  In case of individual patients, constant watch may be kept on the patient‚Äôs eyelids for the  onset of dream through REM-sleep, in which case the instructions may be switched off to allow for sleep to ensue.  In group-therapy sessions, the instructor may switch over to the soothing mode after the first five minutes or so.  The first few instructions should be on lying flat on the back followed by the step-by-step relaxation of the whole body starting with the toes and ending at the crown of the head.  The whole session should be in a very friendly and warm environment where the patient feels completely relieved and relaxed and fully at home.  These are some of the very helpful practical hints which are essential for the therapy. With experience the therapist will gain strength and the success rate will be very high. After a week of guided therapeutic sessions the patients should be watched in one or two do-it-yourself sessions before their release. Once the patient gets confidence in the Anti-Zeno practice, insomnia is effectively fully cured.  5. Discussion & Conclusion  We have proposed for the first time a novel method of treatment of insomnia exploiting the parallelism of the situation involving the states of consciousness with the physics of Quantum Zeno and the Anti-Zeno Effects, which have been experimentally observed in laboratories in many physical systems. A theoretical objection may be raised regarding the efficacy of the procedure in the event of the continuous observation of the breathing leading to another Quantum Zeno Effect involving this new auxiliary state, in which case the patient effectively has now   a   ‚Äì   insomnia in place of   p   ‚Äì   insomnia! This apprehension, however, is without basis since breathing is natural in sleep and is therefore not an obstacle to sleep, while the problematic thoughts are an obstacle. As regards the awareness of breaths which is not natural to sleep, since sleep means non-awareness of everything including breathing, the state of the patient then becomes one of  ‚ÄúYogic   sleep‚Äù   or  Yoga-nidra,   [12],   which   grants   all   the   benefits   of   sleep   (restfulness, rejuvenation, freshness, renewed vigor and vitality etc.) and at the same time takes away all the evils of insomnia (uneasiness, weirdness, heaviness, headache, drowsiness, sloth, stupor, fatigue, etc.), in which case also the patient is cured! Also, as far as the cure is concerned it matters little whether the transition is from   a   or   p   and whether the transition is direct or through intermediate states.  In fact, the Anti-Zeno Therapy proposed here has been somewhat in practice in the theory and practice of Yoga and Meditation[12]. In particular, the step-by-step whole-body-relaxation is an essential part of the practice of a Yogic posture known as   savasana   (the corpse pose) which very often lands the practitioner in deep sleep. Similarly,   ‚Äò concentration on the breath ‚Äô is a preliminary  technique in the practice of concentration and meditation with a view to making the mind one- pointed and finally thoughtless. But in both the cases, the lapse to sleep is the most undesirable event and is considered as an obstacle, since the continuity of awareness is of paramount importance in all yogic practices, and the onset of sleep obviously deprives one of that. But, the failure (lapse- to-sleep) of the Yoga-meditation practitioner is verily th e ‚Äòglorious triumph‚Äô for the insomniac!   And,  it seems that finally there must be some truth in alternative therapies like ‚ÄòYoga‚Äô.\n\n7  It is worth noting that the problematic thought-form   p   is not a singular form but is usually dressed with two or three other associated thought-forms which succeed in keeping the mind revolving, though centered on   p . Thus, there is a difference between   p   and the auxiliary thought-form   a   which is more of a singular nature and thus easily succeeds in getting the mind bored of monotony thereby facilitating the transition to sleep. The application of quantum theory to understand the dynamics of the mind has, of course, its own limitations. For one thing, the physical systems investigated in relation to QZE and QAZE are more or less of known eigenstates with known energy eigenvalues, while here the corresponding property is the willful attention (or awareness) which evolves with time and thus the states corresponding to   p   and   a   do not remain fixed with time. The actual dynamics demands that they gradually shift downwards (see Fig. 1b). It may even so happen that as the attention stabilizes more and more on   a   and, consequently, as the mind starts withdrawing itself,   |   1 (   a   ,t)> may slide below   |   1 (   p   ,t)> and this may bring in another real but beneficial QZE with   |   1 (   a   ,t)>. In this case the QAZE transition may very well involve the dream state   |   2 >   itself because of its closeness to the auxiliary state. In such a situation, whether a similar Anti-zeno therapy will be the helpful in the cases of dreamful insomnia, where   |   2 >   rather than   |   1 >   is the problematic state, needs further investigation.  Acknowledgements  The author gratefully acknowledges the impetus, invitation and inspiration from Reem Ali for writing this article.  References  [1] H. P. Stapp,   Mindful Universe: Quantum mechanics and the Participating Observer , (Springer, Berlin, Heidelberg, New York, 2007).  [2]   J. M. Schwartz, H.P. Stapp, and M. Beauregard,   Quantum theory in neuroscience and Psychology:A neurophysical model of the mind/brain interaction . Phil. Trans. Royal Soc. B 360 (1458) 1306 (2005).  [3]   H. P. Stapp ,   A Model of the Quantum-Classical and Mind-Brain Connections, and of the Role of The Quantum Zeno Effect in the Physical Implementation of Conscious Intent , (2008)  http://arXiv.org/abs/0803.1633  [4] B. Misra and E.C.G. Sudarshan   J. Math. Phys.   18 756,(1977) [5] W. M. Itano, D. J. Heinzen and J.J. Bollinger, and D. J. Wineland,   Phys. Rev.   A 41 2295(1990) [6] E. Manousakis,   Quantum formalism to describe Binocular rivalry .Biosystems, 98, 57-66, (2009) [7] H. P. Stapp ,   The Quantum-Classical and Mind-Brain Linkages: The Quantum Zeno Effect  in Binocular Rivalry ,   http://arXiv.org/abs/0710.5569  [8] W. Pauli and C. G. Jung, Atom and the Archetype, Pauli/Jung, letters, 1932-1958, Ed. C. A. Meier, (Princeton University Press, Princeton, 2001). [9] R. K. Pradhan,   Subject-Object duality and tha states of Consciousness: A Quantum Approach , Neuroquantlogy, 8, 3, 262-278,( 2010)  [10] B. Kaulakys, V. Gontis, Quantum anti-Zeno effect, phys. rev. A 56, 2, 1997, 1050-2947 [11] Qing Ai, Dazhi Xu, Su Yi, A. G. Kofman, C. P. Sun and Franco Nori ,   Quantum anti-Zeno  effect without wave function reduction ,   http://arXiv.org/abs/1007.4859  [12] Swami   Sivananda, ‚Äò How to Get Sound Sleep ‚Äô,   3 rd   edition, DLS Publications, India, (2003).",
    "Accepted Manuscript  ¬© Sleep Research Society 2023. Published by Oxford University Press on behalf of the Sleep Research Society. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.  Multi - Scored Sleep Databases: How to Exploit the  Multiple - Labels in Automated Sleep Scoring  Luigi Fiorillo 1,2,*, ‚Ä† , Davide Pedroncelli 3, ‚Ä† , Valentina Agostini 3 ,  Paolo Favaro 1   and Francesca Dalia Faraci 2  1 Institute of Informatics, University of Bern, Bern, Switzerland,   2 Institute of Digital Technologies for Personalized Healthcare (MeDiTech), Department of Innovative Technologies, University of Applied Sciences and Arts of Southern Switzerland, Lugano, Switzerland,   3 Department of Electronics and Telecommunications, Politecnico di Torino, Torino, Italy.  Institution where work was performed: Institute of Digital Technologies for Personalized Healthcare (MeDiTech), Department of Innovative Technologies, University of Applied Sciences and Arts of Southern Switzerland, Lugano, Switzerland.  ‚Ä†These authors contributed equally to this work.  *Corresponding author. Luigi Fiorillo, Institute of Digital Technologies for Personalized Healthcare (MeDiTech), Department of Innovative Technologies, University of Applied Sciences and Arts of Southern Switzerland, Lugano, Switzerland. Email: luigi.fiorillo@supsi.ch.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Abstract  Study Objectives:   Inter-scorer variability in scoring polysomnograms is a well-known problem. Most of the existing automated sleep scoring systems are trained using labels annotated by a single scorer, whose subjective evaluation is transferred to the model. When annotations from two or more scorers are available, the scoring models are usually trained on   the scorer consensus. The averaged scorer‚Äôs subjectivity is transferred into the model,  losing information about the internal variability among different scorers. In this study, we aim to insert the multiple-knowledge of the different physicians into the training procedure. The goal is to optimize a model training, exploiting the full information that can be extracted from the consensus of a group of scorers.  Methods:   We train two lightweight deep learning based models on three different multi- scored databases. We exploit the label smoothing technique together with a   soft-consensus  ( LS SC ) distribution to insert the multiple-knowledge in the training procedure of the model. We introduce the averaged cosine similarity metric (   ) to quantify the similarity between the hypnodensity-graph generated by the models with- LS SC   and the hypnodensity-graph generated by the scorer consensus.  Results:   The performance of the models improves on all the databases when we train the models with our   LS SC . We found an increase in   (up to 6.4%) between the hypnodensity- graph generated by the models trained with- LS SC   and the hypnodensity-graph generated by the consensus.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Conclusion:   Our approach definitely enables a model to better adapt to the consensus of the group of scorers. Future work will focus on further investigations on different scoring architectures and hopefully large-scale-heterogeneous multi-scored datasets.  Keywords:   automatic sleep stage classification, machine learning, deep learning, multi- scored sleep databases.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Graphical abstract  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Statement of Significance  Visual scoring of polysomnography is a highly subjective procedure. Several studies consistently reported the poor agreement between different physicians scoring the same whole-night recording. Existing sleep scoring algorithms, trained on multi-scored databases, overlook to encode in their models the variability among the scorers. We propose a technique to wholly insert the multiple-knowledge of the different physicians into the training procedure of a scoring algorithm. Our approach enables the model to better adapt to the consensus of the group of scorers. Whenever multi-scored databases are available, future researchers should train their models considering the annotations of all the physicians at the same time, rather than averaging their labels and training their algorithm on the averaged consensus.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Introduction  Sleep disorders represent a significant public health problem that affects millions of people worldwide [1]. Since the late 1950s, the polysomnography (PSG) exam has been the gold standard to study sleep and to identify sleep disorders. It monitors electrophysiological signals such as electroencephalogram (EEG), electrooculogram (EOG), electromyogram (EMG) and electrocardiogram (ECG). The physicians visually extract sleep cycle information from these signals. The whole-night recording is divided in 30-second epochs, and each epoch is classified into one of the five sleep stages (i.e., wakefulness W, stage N1, stage N2, stage N3, and stage REM) according to the AASM guidelines [2]. Worst case scenario, an eight-hour PSG may require up to two hours of tedious repetitive and time-consuming work to be scored. In addition, this manual procedure is highly affected by a low inter-rater scoring agreement (i.e., the agreement between different physicians scoring the same whole-night recording). The inter-rater scoring agreement value ranges from 70% up to slightly more than 80% [3-5]. In [3] the averaged inter-rater agreement of about 83% results from a study conducted on the AASM Inter-scorer reliability dataset, by using sleep stages annotated from more than 2,500 sleep scorers. The agreement was higher than 84% for awake, N2 and REM stages, but it dropped to 63% and 67% for N1 and N3 stages respectively. In fact, the inter- rater agreement varies among sleep stages, patients, sleep disorders and across sleep centers [3], [6].  Since 1960 many different approaches and algorithms have been proposed to automate this time- consuming scoring procedure. Mainly, two different approaches emerged: sleep scoring algorithms learning from well defined features extracted from the knowledge of the experts (shallow learning), and sleep scoring algorithms learning directly from the raw data (deep learning). Thorough reviews about feature based [7-8] and deep learning based [9-10] sleep scoring algorithms can be found in literature. Although the latter algorithms emerged only five years ago, their impressive results have  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  never been reached with the previous conventional feature based approaches. Autoencoders [11], deep neural networks [12], convolutional neural networks [13-20], recurrent neural networks [21- 23] and different combinations of them [24-30] have been all proposed only in these last five years.  Almost all of the above algorithms have been trained on recordings scored by a single expert physician. The first remarkable exception comes from [27], where they consider recordings scored by six different physicians [31]. The scoring algorithm was trained on the six-scorer consensus (i.e., based on the majority vote weighted by the degree of consensus from each physician). In [23] the  Dreem   group introduced two publicly-available datasets scored by five sleep physicians. Similarly, they used the scorer consensus to train their automated scoring system. It has been shown that the performance of an automated sleep scoring system is on-par with the scorer consensus [23,27], and mainly that their best scoring algorithm is better than the best human scorer - i.e., the scorer with the higher consensus among all the physicians in the group. Although they both considered the knowledge from the multiple scorers - by averaging their labels and by training their algorithm on the averaged consensus - they still trained the algorithm on a single one-hot encoded label. Indirectly, they are still transferring the best   scorer‚Äôs subjectivity into the model, and they are not  explicitly training the model to adapt to the consensus of the group of scorers.  In this work, we train two existing lightweight deep learning-based sleep staging algorithms, our DeepSleepNet-Lite (DSN-L) [32] and SimpleSleepNet (SSN) [23], on three open-access multi-scored sleep datasets. First, we assess the performance of both scoring algorithms trained with the labels given by scorer consensus (i.e., majority vote among the different scorers) and compare it to the performance of the individual scorer-experts. Then we propose to exploit label smoothing along with the   soft-consensus   distribution ( base+LS SC ) to insert the multiple-knowledge into the training procedure of the models and to better calibrate the scoring architectures. For the first time in sleep scoring, we are considering the multiple-labels in the training procedure, the annotations of all the  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  scorers are taken into account at the same time. We finally assess the performance and we quantify the similarity between the hypnodensity-graph generated by the models - trained with and without label smoothing - and the hypnodensity-graph generated by the scorer consensus.  In the present work we investigate a different approach in exploiting multi-scored database information. In particular: (1) we demonstrate the efficiency of label smoothing along with the   soft- consensus   distribution in both calibrating and enhancing the performance of both DSN-L and SSN; (2) we show how the model can better resemble the scorer group consensus, leading to a similarity increase between the hypnodensity-graph generated by the model and the hypnodensity-graph generated by the scorer consensus.  Methods  In this section we first present the three publicly available databases used in this study: IS-RC (Inter- scorer Reliability Cohort) [31]; DOD-H (Dreem Open Dataset - Healthy) and DOD-O (Dreem Open Dataset - Obstructive) [23]. We then briefly describe the architectures of the two deep learning- based scoring algorithms DSN-L [32] and SSN [23]. Next, we show how to compute the consensus in a multi-scored dataset, i.e., how to compute the label among multiple-scorers so as to train our  baseline   algorithms and to be able to evaluate their performance. In   Label smoothing with soft- consensus   subsection we describe in detail how to compute the   soft-consensus   distribution, and how to exploit it along with the label smoothing technique during the training procedure. The aim is to show how to insert the multiple-labels of the different scorers into the training procedure of our algorithms. We finally report all the experiments conducted on both DSN-L and SSN algorithms, i.e. , base,   base+LS U   and base+LS SC   models, and the metrics exploited to evaluate their performance.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Datasets  IS-RC.   The dataset contains 70 recordings (0 males and 70 females) from patients with sleep- disordered breathing aged from 40 to 57. The recordings were collected at the University of Pennsylvania. Each recording includes the EEG derivations C3-M2, C4-M1, O1-M2, O2-M1, one EMG channel, left/right EOG channels, one ECG channel, nasal airway pressure, oronasal thermistor, body position, oxygen saturation and abdominal excursion. The recordings are sampled at 128 Hz.  We only consider the single-channel EEG C4-M1 to train our DSN-L architecture, and we use multi- channel EEG, EOG, EMG and ECG to train the SSN architecture. A band-pass Chebyshev IIR filter is applied between [0.3, 35] Hz. Each recording is scored by six clinicians from five different sleep  centers (i.e., University of Pennsylvania, University of Wisconsin at Madison, St. Luke‚Äôs Hospital  (Chesterfield), Stanford University and Harvard University) according to the AASM rules [2]. The dataset contains the following annotations   ,   ,   ,   ,   , and   , where   is a not classified epoch. Some epochs are not scored by all the six physicians, and even for some of them we don't have any annotation (i.e   ). We decided to remove the epochs classified by all the scorers as  . Epochs with less than six annotations are equally taken into account to avoid excessive data loss.  DOD-H.   The dataset contains 25 recordings (19 males and 6 females) from healthy adult volunteers aged from 18 to 65 years. The recordings were collected at the French Armed Forces Biomedical  Research Institute‚Äôs (IRBA) Fatigue and Vigilance Unit (Bretigny -Sur-Orge, France). Each recording includes the EEG derivations C3-M2, C4-M1, F3-F4, F3-M2, F3-O1, F4-O2, O1-M2, O2-M1, one EMG channel, left/right EOG channels and one ECG channel. The recordings are sampled at 512 Hz.  DOD-O.   The dataset contains 55 recordings (35 males and 20 females) from patients suffering from obstructive sleep apnea (OSA) aged from 39 to 62 years. The recordings were collected at the Stanford Sleep Medicine Center. Each recording includes the EEG derivations C3-M2, C4-M1, F4-M1,  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  F3-F4, F3-M2, F3-O1, F4-O2, FP1-F3, FP1-M2, FP1-O1, FP2-F4, FP2-M1, FP2-O2, one EMG channel, left/right EOG channels and one ECG channel. The recordings are sampled at 250 Hz.  We only consider the single-channel EEG C4-M1 to train our DSN-L architecture, and we use all the available channels to train SSN architecture, on both DOD-H and DOD-O. As in [23], a band-pass Butterworth IIR filter is applied between [0.4, 18] Hz to remove residual PSG noise, and the signals are resampled at 100 Hz. The signals are then clipped and divided by 500 to remove extreme values. The recordings from both DOD-H and DOD-O datasets are scored by five physicians from three different sleep centers according to the AASM rules [2].  DOD-H and DOD-O contain the following annotations   ,   ,   ,   ,   , and   , where   is a not classified epoch. All the scorers agree about the   epochs (100% of agreement). Therefore, all of them are removed from the data. Unlike the previous IS-RC database, for each epoch five annotations are always available.  In Table 1 we report a summary of the total number and percentage of the epochs per sleep stage for the DOD-H, DOD-O and IS-RC datasets.  Deep learning-based scoring architectures  DSN-L   [32] is a simplified   feed-forward   version of the original DeepSleepNet by [24]. Unlike the original network, in [32] we proposed to employ only the first   representation learning   block, and we proposed to simply train it with a   sequence-to-epoch   learning approach. The architecture receives in input a sequence of 90-second epochs, and it predicts the corresponding target of the central epoch of the sequence, i.e., many-to-one or sequence-to-epoch classification scheme. The   representation learning   architecture consists of two parallel convolutional neural networks ( CNNs)   branches, with small   and large   filters at the first layer. The principle is to extract high-time resolution patterns with the small filters, and to extract high-frequency resolution patterns with the large ones. This idea comes from the way the signal processing experts define the trade-off between  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  temporal and frequency precision in the feature extraction procedure [33]. Each CNN branch consists of four convolutional layers and two max-pooling layers. Each convolutional layer executes three basic operations: 1-Dimensional convolution of the filters with the sequential input; batch normalization [34]; element-wise rectified linear unit (ReLU) activation function. Then the pooling layers are used to downsample the input. In Figure 1 we report an overview of the architecture, with details about the filter size, the number of filters and the stride size of each convolutional layer. The pooling size and the stride size for each pooling layer are also specified.  SSN   [23] consists of two main parts as shown in Figure 2: (i) The   epoch encoder   part, inspired by [22], or what we refer to as epoch processing block ( EPB ), is designed to process 30-second multi-channel EEG epochs, and it aims at learning epoch-wise features. (ii) The   sequence encoder   part, inspired by [24], or what we refer to as sequence processing block ( SPB ), is designed to process sequences of epochs, and it aims to encode the temporal information (e.g., stage transition rules). The   SPB   block consists of two layers of bidirectional gated recurrent unit (GRU) with skip-connections (SkipGRU) and the final classification layer. The architecture receives in input a sequence of PSG epochs, specifically temporal context is set to twenty-one, and it outputs the corresponding sequences of sleep stages at once, i.e., many-to-many or sequence-to-sequence classification scheme.  In both, DSN-L and SSN, the softmax function and the cross-entropy loss function   (see Supplementary Analyses) are used to train the models to output the probabilities ÃÇ   for the five mutually exclusive classes   , that correspond to the five sleep stages. The cross-entropy loss quantify the agreement between the prediction   and the target   (i.e., sleep stage label) for each sleep epoch .   The aim is to minimize the cross-entropy loss function   , i.e., minimize the distance between the prediction   and the target   .  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  The models are trained end-to-end via backpropagation, using mini-batch Adam gradient-based optimizer [35], with a learning rate   . The training procedure runs up to a maximum number of iterations (e.g., 100 iterations), as long as the break early stopping condition is satisfied (i.e., the validation F1-score stopped improving after more than a certain epochs; the model with the best validation F1-score is used at test time). All the training parameters (e.g., adam-optimizer parameters beta1 and beta2, mini-batch size, learning rate etc.) are all set as recommended in [32] and [23].  In Supplementary Analyses we also report additional mathematical details about both the scoring architectures.  Consensus in multi-scored datasets  Inspired by [23,27], we evaluate the performance of the sleep scoring architectures, as well as the performance of each physician, using the consensus among the five/six different scorers. The majority vote from the scorers has been computed - i.e., we assign to each 30-second epoch the most voted sleep stage among the physicians. In case of ties, we consider the label from the most reliable scorer. The most reliable scorer is the one that is frequently in agreement with all the others. We use the   -   metric proposed in [23] to rank the reliability of each physician, and to finally define the most reliable scorer. We denote with   the total number of scorers and with   the single-scorer. The one-hot encoded sleep stages given by the scorer   are: ÃÇ   , where   is the number of classes, i.e.,  sleep stages, and   is the total number of epochs. The probabilistic consensus ÃÇ   among the  scorers (   excluded) is computed using the following:  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  ÃÇ  ‚àë ÃÇ  ‚àë ÃÇ   (1)  where   is the   -   epoch of   epochs and ÃÇ   , i.e.,   is assigned to a stage if it matches the majority or if it is involved in a tie. The   -   is then computed across all the  epochs as:  -   ‚àë ÃÇ   (2)  where ÃÇ   denotes the probabilistic consensus of the sleep stage chosen by the scorer   for the   -  epoch.   -   , where the zero value is assigned if the scorer   systematically scores all the annotations incorrectly compared to the others, whilst   is assigned if the scorer   is always involved in tie cases or in the majority vote. The   -   is computed for all the scorers, and the values are sorted from the highest - high reliability - to the lowest - low reliability. The   -   is computed for each patient, i.e., the scorers are ranked for each patient, and in case of a tie the top-1 physician will be the one used for that patient.  Label smoothing with   soft-consensus  The predicted sleep stage for each 30-second epoch is associated to a probability value ÃÇ   , which should mirror its ground truth correctness likelihood. When this happens, we can state that the model is well calibrated, or that the model provides a   calibrated confidence   measure along with its prediction [36]. Consider, for example, a model trained to classify images as either containing a dog or not; out of ten test set images it outputs the probability of there being a dog as 0.60 for every image. The model is perfectly calibrated if six dog images are present in the test set. Label smoothing [37] has been shown to be a suitable technique to improve the calibration of the model.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  By default, the cross-entropy loss function   is computed between the prediction   and the target  (i.e., the one-hot encoded sleep stages,   for the correct class and   for all the other classes). Whenever a model is trained with the label smoothing technique, the hard target is usually smoothed with the standard   uniform   distribution   (3) . Thus, the cross-entropy loss function   (4)   is minimized by using the weighted mixture of the target   .  (3)  ‚àë ÃÇ   (4)  where   is the smoothing parameter,   the number of sleep stages,   the weighted mixture of the target and ÃÇ   the output of the model with the predicted probability values.  In our study, we exploit the label smoothing technique to improve the insertion of the knowledge from the multiple-scorers in the learning process. We propose to use the   -   (5)   as our new distribution to smooth the hard target   .  -   (   )   (5)  where   is the set of observations - i.e., annotations given by the different physicians - for the   -  epoch,   is the class index,   is the number of observations and   is the cardinality of the set  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  (   ) . In simple words, the probability value for each sleep stage   is computed as the sum of its occurrences divided by the total number of observations.  -   is the one-dimensional vector that we use to smooth the hard target  (6) , and then minimize the cross-entropy loss function   (7) .  -   (6)  ‚àë ÃÇ   (7)  To make it clearer, we report a practical example on how to compute the   soft-consensus  distribution, and how to exploit it to smooth our labels. Consider the following set of observations  given by five different physicians for the same   -   epoch.  We can calculate the   consensus as following:  -  -  By applying   (5)   and   (6)   we obtain the following   smoothed hard-target with   :  -  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  that corresponds to the one-hot encoded target:  We perform a simple grid-search to set the smoothing hyperparameter   . When the model is trained with the labels smoothed by the   uniform   distribution the   value ranges between  with step   . Extreme values are not considered as for   the model is trained using the standard hot-encoding vector; whilst for values higher than   , e.g.,   , the model would be trained using mainly/only the   uniform   distribution   for each sleep stage. When the model is trained with the labels smoothed by the   -   distribution the   value ranges between  with step   . In the latter case we also investigate an   value equal to   to evaluate the full impact of the consensus distribution on the learning procedure.  Experimental design  We evaluate DSN-L and SSN using the   -fold cross-validation scheme. We set   equal to   for IS-RC,  for DOD-H (leave-one-out evaluation procedure) and   for DOD-O datasets, consistent with what was done in [23]. In Table 2 we summarize the data split for each dataset.  The following experiments are conducted on both DSN-L and SSN models for each dataset:  ‚óè   base . The models are trained without label smoothing.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  ‚óè   base+LS U . The models are trained with label smoothing using the standard   uniform  distribution - i.e., the hard targets (scorer consensus) are weighted with the   uniform  distribution.  ‚óè   base+LS SC . The models are trained with label smoothing using the proposed   soft-consensus   - i.e., the hard targets (scorer consensus) are weighted with the   soft-consensus   distribution.  These models, differently trained, have been evaluated with and without   MC   dropout ensemble technique. In Table 4, Table 5 and Table 6 section   Results   we present the results obtained for each experiment on both DSN-L and SSN evaluated on IS-RC, DOD-H and DOD-O datasets.  Metrics  Performance.  The per-class F1-score, the overall accuracy (Acc.), the macro-averaging F1-score, the weighted- averaging F1-score (i.e., the metric is weighted by the number of true instances for each label, so as  to consider the high imbalance between the sleep stages) and the Cohen‚Äôs kappa have been  computed per-subject from the predicted sleep stages from all the folds to evaluate the performance of our model [38, 39].  Hypnodensity graph.  The hypnodensity-graph is an efficient visualization tool introduced in [27] to plot the probability distribution over each sleep stage for each 30-second epoch over the whole night. Unlike the standard hypnogram sleep cycle visualization tool, the hypnodensity-graph shows the probability of occurrence of each sleep stage for each 30-second epoch; so it is not limited to the discrete sleep stage value (see Figure 3). In our study we have used the hypnodensity-graph to display both the model output - i.e., the probability vectors ÃÇ   - and the multi-scorer   -   probability distributions.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  The Averaged Cosine Similarity (   ) is used to quantify the similarity between the hypnodensity- graph generated by the model and the hypnodensity-graph generated by the   -   . The  has been computed as follows:  ‚àë ÃÇ   ||   ||   ||ÃÇ   ||   (8)  where   is the number of epochs in the whole night,   || ||   is the norm computed for the predicted probability vector ÃÇ   and the   -   ground-truth vector for the   -   epoch. Thus, the cosine-similarity is averaged across all the epochs   to obtain our averaged   unique score of similarity. The cosine-similarity values may range between   i.e., high dissimilarity and   i.e., high similarity between the vectors.  Calibration.  The calibration of the model is evaluated by using the expected calibration error (   ) metric proposed in [40]. By   we compute the difference in expectation between the accuracy  and the   (i.e., the   softmax   output probabilities) values. More in detail, the predictions are divided into   equally spaced bins (with size   ), then we compute the accuracy   and the average predicted probability value   for each bin as follows:  |   |   ‚àë ÃÇ   (9)  |   |   ‚àë ÃÇ   (10)  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  where   is the true label and ÃÇ ÃÇ   is the predicted label for the   -   epoch;   is the group of samples whose predicted probability values fall in   and ÃÇ ÃÇ  is the predicted probability value for sample the   -   30-second epoch. Finally, the  value is computed as the weighted average of the difference between the   and the   among the   bins:  ‚àë   |   |   |   |   (11)  where   is the number of samples in each bin. Perfectly calibrated models have  for all   {   } , resulting in   .  Results  In Table 3 we first report for all the multi-scored databases IS-RC, DOD-H and DOD-O, the overall scorers performance and their   (   ), i.e., the agreement of each scorer with the consensus among the physicians. On IS-RC we have on average a lower inter-scorer agreement (  equal to 0.69, with an F1-score 69.7%) compared to both DOD-H and DOD-O (   equal to 0.89 and 0.88, with an F1-score 88.1% and 86.4% respectively). Consequently, we expect a higher efficiency of our label smoothing with the   soft-consensus   approach ( base+LS SC ) on the experiments conducted on the IS-RC database. The lower the inter-scorer agreement, the lower should be the performance of a model trained with the one-hot encoded labels (i.e., the majority vote weighted by the degree of consensus from each physician).  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  In Table 4 and Table 5 we report the overall performance, the calibration measure and the hypnodensity similarity measure of the three different DSN-L and SSN models on the three databases IS-RC, DOD-H and DOD-O. The performance of the DSN-L   base   models are higher compared to the performance averaged among the scorers on the IS-RC database, but not on the DOD-H and DOD-O databases. In contrast, the performance of the SSN   base   models are always higher than the performance averaged among the scorers on all the databases. We highlight that the results we report for SSN on DOD-H and DOD-O are slightly different compared to the one reported in [23]. We decided to not compute a weight (from 0 to 1) for each epoch, based on how many scorers voted for the consensus. We do not balance the importance of each epoch when we compute the above mentioned metrics. We think it is unfair to constrain any metrics based on the amount of voting physicians. Overall, the results show an improvement in performance on all the databases (i.e overall accuracy, MF1-score, Cohen's kappa (   ), and F1-score) from the baseline ( base ) and the label smoothing with the   uniform   distribution ( base+LS U ) models, to the ones trained with label smoothing along with the proposed   soft-consensus   distribution (ie.   base+LS SC ).  The   is the metric that best quantifies the ability of the model in adapting to the consensus of the group of scorers. A higher   value means a higher similarity between the hypnodensity-graph generated by the model and the hypnodensity-graph generated by the   soft-consensus   (i.e., the model better adapts to the consensus of the group of physicians). As all the other metrics the  value is computed per subject, but here we report the mean and also the standard deviation across subjects   . We found a significant improvement in the   value from the   base   and the  base+LS U   models to the   base+LS SC   models on all the databases and on both DSN-L (p-values < 0.01) and SSN (p-values < 0.05). Hence, our approach enables both DSN-L and SSN architectures to significantly adapt to the group consensus on all the multi-scored datasets.  We could easily infer that the SSN architecture is better (i.e., higher performance) compared to our  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  DSN-L architecture. The purpose of our study is not to highlight whether one architecture is better than the other, but we can not fail to notice the high values of confidence (the   value is the average of the softmax output max-probabilities) obtained on the SSN based models. High values of confidence still persist despite smoothing the labels (with both   uniform   and soft-consensus distributions) during the training procedure. The SSN architecture is not highly responsive to the changes in probability values we implemented on the one-hot encoded labels. It always rely/overfit on the   probability value given for each epoch, i.e., the consensus among the five/six different scorers. Indeed, on the IS-RC, which is the database with the lower inter-scorer agreement, the SSN  base+LS SC   model reaches a higher value of F1-score, i.e., 81.6%, compared to our DSN-L   base+LS SC  model, i.e., 75.9% , but a lower value of   (0.817 on SSN and 0.836 on DSN-L, with a p-value < 0.01). The SSN model overfit to the majority vote or the   probability value given for each epoch, whilst the DSN-L better adapts to the consensus of the group of scorers (i.e., better encodes the variability among the physicians).  The last statement is also strengthened by the Supplementary Figure S1 and Figure S2. For DSN-L and SSN we report the   values across all the experimented   values, on both the   base+LS U   and the   base+LS SC   models tested on the three databases. As expected, the DSN-L model shows a high sensitivity in   values to changes in Œ± -hyperparameter across all databases. This sensitivity is not as strong with the SSN model.  Moreover, we want to stress that the standard   uniform   distribution is not as efficient as the proposed   soft-consensus   distribution in encoding the scorer‚Äôs variability. By using the   uniform  distribution we are not able to learn as well the complexity of the degree of agreement between the different physicians. Indeed, in Supplementary Figure S1, on the DSN-L model, we clearly show how the   value proportionally increases with the Œ± -hyperparameter only by using the proposed   soft-  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  consensus   distribution. In Figure 4 we also show, on a patient from the DOD-O dataset, how we achieve a higher   value with the proposed   base+LS SC   model with the   soft-consensus   distribution, compared to   base+LS U   model with the standard   uniform   distribution. The graph clearly highlights the differences between the output probabilities predicted by the different models. The probabilities predicted using our approach   base+LS SC   (d) are closer to the ground-truth (a) compared to the ones predicted from the other models (e.g. refer to min. 300 and to the probabilities associated with the sleep stage N3).  Discussion  Many deep learning based approaches are available and from a technical point of view there is not that much that is left to be done to improve their performance. It is not reasonable to reach a performance higher than the gold standard that is used to train the architectures. Infact, the real limitation is the low inter-rater agreement due to subjective interpretation.  Therefore in this paper we focus on how to better integrate the inter-rater agreement information into the automated sleep scoring algorithms. Presently, information about the variability is not completely exploited. The algorithms are trained on the majority vote consensus, leading to overfitting on the majority vote weighted by the degree of consensus from each physician.  We introduce a   more complete methodology to integrate scorer‚Äôs variability in the training  procedure. We demonstrate the efficiency of label smoothing along with the   soft-consensus  distribution in encoding the scorers‚Äôs variability into the training procedure of both DS N-L and SSN scoring algorithms. The results show an improvement in overall performance from the   base   models to the ones trained with   base+LS SC . We introduce the averaged cosine similarity metric to better quantify the similarity between the probability distribution predicted by the models and the ones generated by the scorer consensus. We obtain a significant improvement in the   values from the  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  base   models to the   base+LS SC   models on both DSN-L and SSN architectures. Based on the reported high confidence values, we found that SSN tends to overfit on each dataset. Specifically, it tends to overfit on the majority vote weighted by the degree of consensus from each physician, but does not encode as well their variability.  To our knowledge, our work is the first attempt to transfer the variability, the uncertainty and the noise among multiple-scorers to an automated sleep scoring system.  We have proved the strength of our approach and especially the use of the soft-consensus distribution by comparing it with the   base   models and the implemented models trained with label smoothing but using the uniform distribution. We clearly show on all the experiments the higher overall performance and   values achieved with the soft-consensus distribution.  In order to generalize our approach, there are two big limitations. The first is that a far bigger datasets, highly heterogeneous (with different diagnosis, age range, gender etc.) scored by multiple scorers would be necessary. The second is that the recordings exploited in this study are not labeled by a homogeneous group of board certified sleep scorers. Further studies should be carried out to better quantify the resilience and the reproducibility of the proposed approach. To achieve a high- performance sleep scoring algorithm, we must take into account both the variability of the recordings and the variability between the different sleep scorers. We should train our sleep scoring models on PSG recordings from different large-scale-heterogeneous data cohorts, and ideally with each recording scored by multiple physicians.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  In summary, the possibility of exploiting the full set of information that is hidden in a multi-scored dataset would certainly enhance automated deep learning algorithms performance. The present approach enables us to better adapt to the consensus of the group of scorers, and, as a consequence, to better quantify the disagreement we have between the different scorers. The  proposed approach results quite effective in encoding the complexity of the scorers‚Äô consensus  within the classification algorithm, whose importance is often underestimated.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Funding  Prof. F. D. Faraci was supported by SPAS: Sleep Physician Assistant System project, from Eurostars funding programme. Prof. P. Favaro was supported by the IRC Decoding Sleep: From Neurons to Health and Mind, from the University of Bern, Switzerland.  Disclosure Statement  Conflicts of interest. The authors declare that they have no conflict of interest. Financial Disclosure: none. Non financial Disclosure: none.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  References  [1] National Center on Sleep Disorders Research, National Inst. Health Sleep Disorders Res. Plan, Bethesda, MD, USA, 2011.  [2] C. Iber, S. Ancoli-Israel, A. L. Chesson, and S. F. Quan, The AASM Manual for the Scoring of Sleep and Associated Events: Rules, Terminology, and Technical Specifications. Westchester, IL, USA: American Academy Sleep Medicine, 2007.  [3] Rosenberg RS, Van Hout S. The American academy of sleep medicine inter-scorer  reliability program: sleep stage scoring. J Clin Sleep Med 2013;9(01):81e7.  [4] Younes M, Raneri J, Hanly P. Staging sleep in polysomnograms: analysis of  inter-scorer variability. J Clin Sleep Med 2016;12(06):885e94.  [5] Muto V, Berthomier C, Schmidt C, Vandewalle G, Jaspar M, Devillers J, et al.  0315 Inter-and intra-expert variability in sleep scoring: comparison between  visual and automatic analysis. Sleep 2018;41(suppl_1):A121.  [6] Danker-hopfe H, Anderer P, Zeitlhofer J, Boeck M, Dorn H, Gruber G, et al.  Interrater reliability for sleep scoring according to the Rechtschaffen & Kales  and the new AASM standard. J Sleep Res 2009;18(1):74e84.  [7] Aboalayon K, Faezipour M, Almuhammadi W, Moslehpour S. Sleep stage  classification using EEG signal analysis: a comprehensive survey and new  investigation. Entropy 2016;18(9):272.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  *8+ Ronzhina M, Janou≈°ek O, Kol√°≈ôov√° J, Nov√°kov√° M, Honz√≠k P, Provazn√≠k I. Sleep scoring using  artificial neural networks. Sleep medicine reviews. 2012 Jun 1;16(3):251-63.  *9+ L. Fiorillo et al., ‚ÄúAutomated sleep scoring: A review of the latest approaches,‚Äù Sleep Medicine  Reviews, vol. 48, pp. 101204, 2019.  *10+ O. Faust et al., ‚ÄúA review of automated sleep stage   scoring based on physiological signals for the  new millennia,‚Äù Comput Methods Programs Biomed, vol. 176, pp. 81‚Äì 91, 2019.  *11+ Tsinalis, Orestis, Paul M. Matthews, and Yike Guo. ‚ÄùAutomatic sleep stage scoring using time - frequency analysis and stacked spar se autoencoders.‚Äù Annals of biomedical engineering 44.5 (2016):  1587-1597.  *12+ Dong, Hao, et al. ‚ÄùMixed neural network approach for temporal sleep stage classification.‚Äù IEEE  Transactions on Neural Systems and Rehabilitation Engineering 26.2 (2017): 324-333.  *13+ Vilamala, Albert, Kristoffer H. Madsen, and Lars K. Hansen. ‚ÄùDeep convolutional neural networks for interpretable analysis of EEG sleep stage scoring.‚Äù 2017 IEEE 27th International Workshop on  Machine Learning for Signal Processing (MLSP). IEEE, 2017.  *14+ Chambon, Stanislas, et al. ‚ÄùA deep learning architecture for temporal sleep stage classification using multivariate and multimodal time series.‚Äù IEEE Transactions on Neural Systems and  Rehabilitation Engineering 26.4 (2018): 758-769.  [15] Cui, Zh ihong, et al. ‚ÄùAutomatic Sleep Stage Classification Based on Convolutional Neural  Network and Fine- Grained Segments.‚Äù Complexity 2018 (2018).  *16+ Patanaik, Amiya, et al. ‚ÄùAn end -to-end framework for real-time automatic sleep stage  classification.‚Äù Sleep 4 1.5 (2018): zsy041.  *17+ Sors, Arnaud, et al. ‚ÄùA convolutional neural network for sleep stage scoring from raw single -  channel EEG.‚Äù Biomedical Signal Processing and Control 42 (2018): 107 -114.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  [18] Yildirim, Ozal, Ulas Baran Baloglu, and U. Rajendra Achary a. ‚ÄùA deep learning model for automated sleep stages classification using psg signals.‚Äù International journal of environmental  research and public health 16.4 (2019): 599  [19] Olesen AN, J√∏rgen Jennum P, Mignot E, Sorensen HB. Automatic sleep stage classification with deep residual networks in a mixed-cohort setting. Sleep. 2021 Jan;44(1):zsaa161.  [20] Perslev M, Darkner S, Kempfner L, Nikolic M, Jennum PJ, Igel C. U-Sleep: resilient high-frequency sleep staging. NPJ digital medicine. 2021 Apr 15;4(1):1-2.  *21+ Michielli, Nicola, U. Rajendra Acharya, and Filippo Molinari. ‚ÄùCascaded LSTM recurrent neural  network for automated sleep stage classification using single- channel EEG signals.‚Äù Computers in  biology and medicine 106 (2019): 71-81.  [22] H. Phan, F. An dreotti, N. Cooray, O. Y. Ch√©n, and M. De Vos, ‚ÄúSeqSleepNet: end -to-end  hierarchical recurrent neural network for sequence-to- sequence automatic sleep staging,‚Äù IEEE  Trans. on Neural Systems and Rehabilitation Engineering (TNSRE), vol. 27, no. 3, pp. 400 ‚Äì 410, 2019.  *23+ A. Guillot, F. Sauvet, E. H. During, and V. Thorey, ‚ÄúDreem   open datasets: Multi-scored sleep  datasets to compare human and automated sleep staging,‚Äù IEEE Transactions on Neural Systems and  Rehabilitation Engineering, vol. 28, no. 9, pp. 1955 ‚Äì 1965, 2020.  *24+ Supratak, Akara, et al. ‚ÄùDeepSleepNet: A model for auto matic sleep stage scoring based on raw single- channel EEG.‚Äù IEEE Transactions on Neural Systems and Rehabilitation Engineering 25.11  (2017): 1998-2008.  *25+ Biswal, Siddharth, et al. ‚ÄùExpert - level sleep scoring with deep neural networks.‚Äù Journal of the  American Medical Informatics Association 25.12 (2018): 1643-1650.  *26+ Malafeev, Alexander, et al. ‚ÄùAutomatic human sleep stage scoring using deep neural networks.‚Äù  Frontiers in neuroscience 12 (2018): 781.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  [27] Stephansen, Jens B., et al. Neural network analysis of sleep stages enables efficient diagnosis of narcolepsy. Nature communications, 2018, 9.1: 1-15.  [28] Mousavi, Sajad; AFGHAH, Fatemeh; ACHARYA, U. Rajendra. SleepEEGNet: Automated sleep stage scoring with sequence to sequence deep learning approach. PloS one, 2019, 14.5: e0216456.  [29] Phan, Huy, et al. XSleepNet: Multi-view sequential model for automatic sleep staging. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2021.  U-Sleep  [30] Maurice Abou Jaoude, Haoqi Sun, Kyle R Pellerin, Milena Pavlova, Rani A Sarkis, Sydney S Cash, M Brandon Westover, Alice D Lam, Expert-level automated sleep staging of long-term scalp electroencephalography recordings using deep learning,   Sleep , Volume 43, Issue 11, November 2020, zsaa112, https://doi.org/10.1093/sleep/zsaa112  [31] Kuna ST, Benca R, Kushida CA, Walsh J, Younes M, Staley B, Hanlon A, Pack AI, Pien GW, Malhotra A. Agreement in computer-assisted manual scoring of polysomnograms across sleep centers. Sleep. 2013 Apr 1;36(4):583-9.  [32] Fiorillo L, Favaro P, Faraci FD. Deepsleepnet-lite: A simplified automatic sleep stage scoring model with uncertainty estimates. IEEE Transactions on Neural Systems and Rehabilitation Engineering. 2021 Oct 14;29:2076-85.  [33] Cohen, Mike X. Analyzing neural time series data: theory and practice. MIT press, 2014.  [34] Ioffe S, Szegedy C. Batch normalization: Accelerating deep network training by reducing internal covariate shift. InInternational conference on machine learning 2015 Jun 1 (pp. 448-456). PMLR.  [35] Kingma DP, Ba J. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980. 2014 Dec 22.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  [36] Guo C, Pleiss G, Sun Y, Weinberger KQ. On calibration of modern neural networks. InInternational Conference on Machine Learning 2017 Jul 17 (pp. 1321-1330). PMLR.  [37] Szegedy C, Vanhoucke V, Ioffe S, Shlens J, Wojna Z. Rethinking the inception architecture for computer vision. InProceedings of the IEEE conference on computer vision and pattern recognition 2016 (pp. 2818-2826).  [38] Cohen, Jacob. A coefficient of agreement for nominal scales. Educational and psychological measurement, 1960, 20.1: 37-46.  [39] Sokolova, Marina; Lapalme, Guy. A systematic analysis of performance measures for classification tasks. Information processing & management, 2009, 45.4: 427-437.  [40] Naeini, Mahdi Pakdaman; Cooper, Gregory F.; Hauskrecht, Milos. Obtaining well calibrated probabilities using bayesian binning. AAAI Conference on Artificial Intelligence. AAAI Conference on Artificial Intelligence. NIH Public Access, 2015. p. 2901.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Figure Captions  Figure 1.   DeepSleepNet-Lite architecture. An overview of the   representation learning   architecture from [24], with our   sequence-to-epoch  training approach.  Figure 2.   SimpleSleepNet architecture.  An overview of the SimpleSleepNet architecture from [23].   represent the hidden states of the GRU layers from the previous epoch of the sequence and   the hidden states of the GRU layers from the next epoch of the sequence.   is the embedding of the current epoch.  Figure 3.   Hypnogram and hypnodensity-graph from the scorers labels.  Example of hypnogram and hypnodensity-graph for a subject from the DOD-H with the highest percentage 14% of N1 sleep stages. For each 30-second epoch we report on top the hypnogram, i.e., the discrete sleep stage values (majority vote from the scorers labels); on bottom the hypnodensity- graph, i.e., the cumulative probabilities of each sleep stage ( soft- consensus computed from the scorers labels). The hypnodensity-graph allows us to better appreciate the low level of agreement of a specific sleep stage among the different scorers. In this example, the sleep stages N1 are often associated with a high percentage of residual probability in awake or N2, thus at the transitions from one sleep stage to another.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Figure 4.   Hypnodensity-graphs from the scorers labels and from the predicted probabilities from the experimented models.  Example of hypnodensity-graphs for a subject from the DOD-O. (a) Soft-consensus computed from the scorers labels; (b) DSN-L   base   model; (c) DSN-L   base+LS U ; (d) DSN-L   base+LS SC   . We also report the ACS value computed between the hypodensity-graph associated to soft-consensus and the ones generated from the predicted probabilities of each model. We reach a higher   value with the proposed   base+LS SC   model with the   soft-consensus   distribution (d), compared to the baseline (b) and the   base+LS U   model with the standard   uniform   distribution (c).  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Tables  Table 1  Number and percentage of 30-second epochs per sleep stage for the IS-RC, DOD-H and DOD-O datasets.  W   N1   N2   N3   R   Total  IS - RC  24517  (29.1%)  3773  (4.5%)  40867  (48.5%)  3699  (4.4%)  11475  (13.6%)  84331  DOD - H  3075  (12.5%)  1463  (5.9%)  12000  (48.7%)  3442  (14.0%)  4685  (19.0%)  24665  DOD - O  10520  (19.8%)  2739  (5.1%)  26213  (49.2%)  5617  (10.6%)  8147  (15.3%)  53236  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Table 2  Data split on the IS-RC, DOD-H and DOD-O datasets.  Size  Experimental  Setup  Held - out  Validation Set  Held - out  Test Set  IS - RC   70   10-fold CV   13 subjects   7 subject  DOD - H   25   25-fold CV   6 subjects   1 subjects  DOD - O   55   10-fold CV   12 subjects   6 subjects  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Table 3  Scorers performance on IS-RC, DOD-H and DOD-O datasets with   (   ), overall accuracy (%Acc.), macro F1- score (%MF1), Cohen‚Äôs Kappa ( k ), weighted-averaging F1-score (%F1) and % per-class F1-score. The scorer with the best performance (i.e., high agreement with the consensus among the different physicians) is indicated in bold.  Overall Metrics   Per - Class F1 - Score  Scorers   SA   Acc.   MF1   k   F1   W   N1   N2   N3   R  IS - RC  Scorer - 1   0.79   83.0   69.5   0.72   83.8   83.1   47.2   87.3   48.0   82.1  Scorer - 2   0.81   89.4   72.8   0.82   89.2   91.3   57.6   92.5   32.9   89.8  Scorer - 3   0.53   40.7   26.5   0.11   40.8   29.8   14.7   54.5   17.9   15.6  Scorer - 4   0.52   38.9   26.1   0.12   40.5   28.6   14.7   54.2   15.4   17.5  Scorer - 5   0.70   73.7   61.6   0.63   75.8   88.7   36.9   70.2   25.8   86.2  Scorer - 6   0.79   87.2   77.2   0.81   88.2   92.5   54.6   89.4   59.8   89.5  Average   0.69   68.7   55.5   0.53   69.7   68.9   37.6   74.7   33.3   63.5  DOD - H  Scorer - 1   0.88   87.0   81.5   0.81   87.4   87.5   60.0   89.4   84.8   85.7  Scorer - 2   0.91   89.3   84.1   0.84   89.7   87.4   65.1   91.6   84.3   92.2  Scorer - 3   0.92   90.6   84.5   0.86   90.4   89.9   67.5   92.1   77.9   95.3  Scorer - 4   0.84   82.6   76.7   0.75   83.1   76.5   49.1   85.4   80.7   92.0  Scorer - 5   0.92   89.9   83.6   0.85   89.9   86.7   66.0   92.1   81.0   92.2  Average   0.89   87.9   82.1   0.82   88.1   85.5   61.5   90.0   81.7   91.5  DOD - O   Scorer - 1   0.87   85.0   75.1   0.77   84.6   90.0   49.5   85.2   67.6   83.3  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Scorer - 2   0.87   85.0   78.2   0.78   86.0   89.3   58.4   85.4   69.1   88.6  Scorer - 3   0.88   86.0   75.0   0.78   84.6   91.0   54.3   86.5   56.1   87.0  Scorer - 4   0.88   86.7   77.7   0.80   87.2   91.2   59.3   89.4   62.9   85.8  Scorer - 5   0.91   89.9   82.3   0.84   90.0   93.7   68.3   90.7   70.5   88.2  Average   0.88   86.5   77.6   0.79   86.4   91.0   58.0   87.3   65.2   86.5  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Table 4  Overall metrics, per-class F1-score, calibration and   hypnodensity graph similarity measures of the DSN-L models obtained from 10-fold cross-validation on IS-RC dataset, from 25-fold cross- validation on DOD-H dataset, and from 10-fold cross-validation on DOD-O dataset. Best shown in bold.  Overall Metrics   Pe r - Class F1 - Score   Calibration   Hypn.  Models   Acc.   MF1   k   F1   W   N1   N2   N3   R   ECE  IS - RC  base   -   69.6   50.6   0.56   70.0   81.6   11.8   71.9   27.2   60.7   0.096   79.0   0.772   0.075  base+LS U   0.4   74.8   57.0   0.63   75.8   83.3   24.3   79.0   30.6   67.7   0.296   45.2   0.806   0.042  base+LS SC   0.6   75.8   56.5   0.69   75.9   83.5   19.5   79.7   33.3   66.4   0.190   56.7   0.836   0.041  DOD - H  base   -   76.9   70.0   0.68   77.2   79.7   39.5   78.8   76.5   75.2   0.163   92.7   0.817   0.097  base+LS U   0.2   75.3   68.7   0.66   75.2   78.8   40.0   75.9   72.0   76.8   0.059   68.9   0.829   0.068  base+LS SC   0.8   80.2   72.4   0.72   80.4   80.4   42.3   83.4   77.6   78.8   0.016   81.4   0.873   0.053  DOD - O  base   -   77.3   67.8   0.66   78.0   80.7   41.2   81.0   68.1   68.3   0.131   90.2   0.840   0.073  base+LS U   0.1   77.5   68.0   0.67   78.2   80.8   41.9   80.4   68.4   68.7   0.009   78.4   0.859   0.072  base+LS SC   1   79.4   69.6   0.69   79.9   80.4   43.8   83.5   72.5   68.1   0.009   78.3   0.878   0.061  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Table 5  Overall metrics, per-class F1-score, calibration and   hypnodensity graph similarity measures of the SSN models obtained from 10-fold cross-validation on IS-RC dataset, from 25-fold cross- validation on DOD-H dataset, and from 10-fold cross-validation on DOD-O dataset. Best shown in bold.  Overall Metrics   Per - Class F1 - Score   Calibration   Hypn.  Models   Acc.   MF1   k   F1   W   N1   N2   N3   R   ECE  IS - RC  base   -   81.8   60.8   0.72   80.8   86.3   29.9   85.3   24.3   78.1   0.174   99.4   0.806   0.052  base+LS U   0.3   82.5   59.8   0.72   81.1   86.5   28.8   86.5   18.7   78.7   0.169   99.3   0.811   0.058  base+LS SC   0.7   83.1   60.2   0.73   81.6   86.7   27.6   86.8   20.1   79.8   0.162   99.2   0.817   0.047  DOD - H  base   -   87.1   80.2   0.81   87.1   83.6   55.5   90.0   83.3   89.0   0.126   99.7   0.890   0.047  base+LS U   0.4   87.6   81.0   0.81   87.5   85.5   57.3   90.2   82.1   90.3   0.120   99.5   0.899   0.034  base+LS SC   0.5   88.8   82.3   0.83   88.7   86.4   58.8   90.9   83.2   92.1   0.108   99.6   0.907   0.039  DOD - O  base   -   85.3   75.9   0.77   85.2   88.2   50.4   87.1   65.9   88.0   0.145   99.7   0.889   0.056  base+LS U   0.1   85.6   75.8   0.78   85.2   88.2   51.2   87.3   64.3   88.4   0.141   99.6   0.893   0.052  base+LS SC   1   86.8   77.7   0.79   86.7   89.0   51.0   88.3   69.3   91.1   0.125   99.2   0.906   0.043  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Table 6  Overall metrics and   hypnodensity graph similarity measures on the DSN-L and SSN   base+LS SC  models, obtained from 10-fold cross-validation on IS-RC dataset, from 25-fold cross-validation on DOD-H dataset, and from 10-fold cross-validation on DOD-O dataset with and without   MC . Best shown in bold.  Overall Metrics   Hypn.  Acc.   MF1   k   F1  IS - RC  DSN - L  w/o MC   75.8   56.5   0.69   75.9   0.836   0.041  w/   MC   78.6   57.6   0.67   78.0   0.850   0.036  SSN  w/o MC   83.1   60.2   0.73   81.6   0.817   0.047  w/   MC   83.0   59.2   0.73   81.1   0.818   0.048  DOD - H  DSN-L  w/o MC   80.2   72.4   0.72   80.4   0.873   0.053  w/   MC   84.4   75.9   0.76   84.2   0.906   0.026  SSN  w/o MC   88.8   82.3   0.83   88.7   0.907   0.039  w/   MC   89.1   82.6   0.84   89.0   0.910   0.039  DOD - O  DSN - L  w/o MC   79.4   69.6   0.69   79.9   0.878   0.061  w/   MC   80.7   70.8   0.71   80.9   0.889   0.059  SSN  w/o MC   86.8   77.7   0.79   86.7   0.906   0.043  w/   MC   87.1   78.0   0.80   86.9   0.909   0.041  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Figure 1  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Figure 2  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Figure 3  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Figure 4  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023",
    "SLEEP, Vol. 39, No. 2, 2016 327 Motor Cortex Impairment in COPD‚ÄîAlexandre et al.  SLEEP DISORDERED BREATHING Brain Damage and Motor Cortex Impairment in Chronic Obstructive Pulmonary Disease: Implication of Nonrapid Eye Movement Sleep Desaturation  Francois Alexandre, PhD 1,2   ; Nelly Heraud, PhD   2,3   ; Anthony M.J. Sanchez, PhD   4,5   ; Emilie Tremey, PhD   2,3   ; Nicolas Oliver, MD   2   ; Philippe Guerin, MD   3   ; Alain Varray, PhD 1  1 Movement To Health Laboratory, Euromov, University of Montpellier, Montpellier, France;   2 Clinique du Souffle La Vallonie, Fontalvie, Lod√®ve, France;   3 Clinique du Souffle  Les Clarines, Fontalvie, Riom-es-Montagnes, France;   4   UMR866 Dynamique Musculaire et M√©tabolisme, INRA, University of Montpellier, Montpellier, France;   5   Laboratoire  Performance Sant√© Altitude, EA 4604, University of Perpignan Via Domitia, Font-Romeu, France  Study Objectives:   Nonrapid eye movement (NREM) sleep desaturation may cause neuronal damage due to the withdrawal of cerebrovascular reactivity. The current study (1) assessed the prevalence of NREM sleep desaturation in nonhypoxemic patients with chronic obstructive pulmonary disease (COPD) and (2) compared a biological marker of cerebral lesion and neuromuscular function in patients with and without NREM sleep desaturation.  Methods:   One hundred fifteen patients with COPD (Global Initiative for Chronic Obstructive Lung Disease [GOLD] grades 2 and 3), resting PaO 2   of 60‚Äì80  mmHg, aged between 40 and 80 y, and without sleep apnea (apnea-hypopnea index < 15) had polysomnographic sleep recordings. In addition, twenty-nine  patients (substudy) were assessed i) for brain impairment by serum S100B (biological marker of cerebral lesion), and ii) for neuromuscular function via motor cortex activation and excitability and maximal voluntary quadriceps strength measurement.  Results:   A total of   51.3% patients (n = 59) had NREM sleep desaturation (NREM   Des ). Serum S100B was higher in the NREM   Des   patients of the substudy  (n = 14): 45.1 [Q1: 37.7, Q3: 62.8] versus 32.9 [Q1: 25.7, Q3: 39.5] pg.ml   ‚àí1   (P = 0.028). Motor cortex activation and excitability were lower in NREM   Des   patients (both P = 0.03), but muscle strength was comparable between groups (P = 0.58).  Conclusions:   Over half the nonhypoxemic COPD patients exhibited NREM sleep desaturation associated with higher values of the cerebral lesion biomarker and lower neural drive reaching the quadriceps during maximal voluntary contraction. The lack of muscle strength differences between groups suggests a compensatory mechanism(s). Altogether, the results are consistent with an involvement of NREM sleep desaturation in COPD brain impairment.  Clinical Trial Registration:   The study was registered at www.clinicaltrials.gov as NCT01679782.  Keywords:   central nervous system, cerebral cortex, electromyography, muscle weakness, voluntary activation  Citation:   Alexandre F, Heraud N, Sanchez AM, Tremey E, Oliver N, Guerin P, Varray A. Brain damage and motor cortex impairment in chronic obstructive pulmonary disease: implication of nonrapid eye movement sleep desaturation.   SLEEP   2016;39(2): 327 ‚Äì335.  INTRODUCTION  Patients with chronic obstructive pulmonary disease (COPD) present several neurological disorders that directly affect daily life. These disorders include cognitive dysfunction, which degrades quality of life by, for example, decreasing driving ability. 1   In our laboratory, we previously showed that motor cortex impairment could be involved in COPD muscle weak- ness due to inadequate motor cortex activation.   2 The origin of the cerebral dysfunction in patients with COPD remains unelucidated. The potential role of hypoxemia in triggering neuronal damage and dysfunction by cerebral ox- ygen deprivation has often been hypothesized.   3   However, sev- eral studies have provided evidence of cerebral dysfunction in nonhypoxemic COPD patients, indicating that hypoxemia   per se   is not the main factor. 4‚Äì6   This observation is unsurprising because an adequate oxygen supply to the brain is perma- nently ensured through cerebrovascular oxygen (O   2   ) reactivity. During hypoxemia or oxygen desaturation, cerebrovascular O   2   reactivity prevents cerebral hypoxia by increasing cerebral  blood flow (CBF) up to 200%. 7,8   Consequently, the resting CBF  is much higher in hypoxemic than in nonhypoxemic COPD patients and healthy controls. 9,10   For the same reason, CBF in - creases in COPD during exercise-induced desaturation. 11   This  pii: sp- 00025 -15   http://dx.doi.org/10.5665/sleep.5438  Significance  This study reveals that over half of COPD patients (grade 2 and 3) nonhypoxemic at rest have nocturnal desaturation during nonrapid eye movement sleep stages. These patients also present an increased cerebral lesion biomarker and a reduced motor cortex activation and excitability during quadriceps voluntary contractions. These results are consistent with the development of cerebral lesions in case of nonrapid eye movement sleep desaturation, and corroborate the hypothesis of an absence of cerebrovascular reactivity during these stages. The prevention of nonrapid eye movement sleep desaturation thus appears as a relevant clinical perspective to prevent COPD brain injury or even to restore brain function.  results in adequate cerebral oxygen delivery even in the case of hypoxemia. 11   As a whole, these studies provide evidence that cerebrovascular O   2   reactivity prevents brain hypoxia in COPD. Unfortunately, cerebrovascular reactivity is impaired during nonrapid eye movement (NREM) sleep stages. 12‚Äì15   Numerous  studies have reported an unexpected absence of CBF modula - tion during NREM sleep (but not during rapid eye movement [REM] sleep) in individuals who experience NREM sleep de- saturation. 12‚Äì15   Indeed, by decreasing arterial saturation of ox- ygen (SaO   2 ) artificially by 5% to 10%, Meadows et al. 15   found  a consistent CBF increase in wake states, whereas it tended to  decrease during slow wave sleep in hypoxemia. Therefore, if the arterial oxygen content falls below the normal value during NREM sleep, it may not be compensated, potentially leading to neuronal injury. 16 Nocturnal desaturation is frequent in nonhypoxemic COPD patients. The prevalence of COPD patients who are normoxic  while awake and who spend at least 30% of the total sleep time  (TST) with a saturation of peripheral oxygen (SpO   2 ) below  90% ranges from 38% to 70%. 17‚Äì19   To the best of our knowledge, the prevalence of  NREM sleep desaturation in COPD has never been specifi - cally assessed. It is generally acknowledged that the deepest\n\nSLEEP, Vol. 39, No. 2, 2016 328 Motor Cortex Impairment in COPD‚ÄîAlexandre et al.  desaturation occurs during REM sleep. However, because  REM sleep represents only about 13% of the TST in COPD,   20  patients with COPD and nocturnal desaturation (for at least  30% of TST) also necessarily experience desaturation for a sig -  nificant proportion of NREM sleep.  Central nervous system (CNS) injury in COPD was re- cently evidenced by magnetic resonance imaging (MRI) and  measurement of serum S100B levels. 21,22   S100B is a calcium  binding protein, mainly produced by astrocytes,   23   that is re- leased in the blood circulation in response to glia cell activa- tion during acute and chronic conditions of brain damage.   24  An increase in serum S100B concentration has been described  in a wide range of neurological disorders such as acute isch- emic and traumatic brain injury and hypoxic brain damage.   25‚Äì27  Serum S100B is considered as a surrogate biomarker for neu - ronal injury   28   and has the main advantage of providing an easy- to-use assessment of cerebral damage.   29 The aim of the study was twofold: to determine the preva- lence of patients with COPD who are nonhypoxemic but ex- perience nocturnal desaturation during NREM sleep; and to compare CNS injury and neuromuscular function in patients experiencing desaturation and those who are not during NREM sleep and assess the repercussions of desaturation on neural drive during maximal voluntary muscle contraction. We hy-  pothesized higher levels of serum S100B associated with lower  motor cortex activation and lower muscle strength in patients with COPD who experience desaturation during NREM sleep.  METHODS Participants  The study was conducted between 2012 and 2014 at the Cli -  nique du Souffle La Vallonie in Lodeve, France, and the Cli -  nique du Souffle Les Clarines in Riom-es-Montagnes, France.  Over this period, 1,213 patients taking part in a 4-w inpa- tient pulmonary rehabilitation program underwent a routine  medical examination in the first days following admission,  composed of anthropometric evaluation, resting pulmonary function assessment, resting blood gas assessment, the 6-min walk test, and polysomnographic sleep (PSG) recordings. after completion, patient records were screened to identify those pa-  tients who met the following criteria: between 40 and 80 y old,  diagnosis of COPD with postbronchodilator forced expiratory  volume in 1 sec (FEV 1 ) between 30% and 80% of predicted  values (corresponding to grades 2 and 3 of the Global Initia-  tive for Chronic Obstructive Lung Disease [GOLD] classifica - tion 30 ), resting partial pressure of oxygen (PaO   2 ) between 60 and 80 mmHg, and an apnea-hypopnea index (AHI) lower than 15 events per hour. One hundred fifteen patients fulfilled  these criteria and were thus selected for a study to determine the prevalence of NREM sleep desaturation in nonhypoxemic  COPD patients (Figure 1).  In a second step, we compared the neuromuscular function between patients with COPD with and without NREM sleep desaturation. Over a 6-mo period, a total of 29 consecutive patients underwent additional blood sampling and neuromus- cular assessment. Patients were not eligible for neuromuscular assessment if they were unable to give written consent or per- form the experimental maneuvers, were on medication known to impair brain function, or had impaired visual function, a pacemaker, current or past alcohol abuse, an exacerbation in the past 4 w, or neurologic or neuromuscular disease. Proce- dures were approved by the local Ethics Committee (Comit√©  de protection des personnes Sud Est VI, number AU980) and  complied with the principles of the Declaration of Helsinki for human experimentation. The study was registered at www.  clinicaltrials.gov as NCT01679782.  Design  All tests were completed within the first week after admis -  sion. All participants were first evaluated for anthropometric  parameters, resting pulmonary function, resting blood gases, the 6-min walk test, and polysomnographic sleep (PSG) re- cordings. The patients eligible for neuromuscular assessment were then probed and underwent medical examination after giving written consent. These patients were familiarized with  the neuromuscular tests on the first day. Blood samples were collected the next day at patient wake-up, and between 06:30 and 07:30. The neuromuscular tests took place in the morning.  The design of the neuromuscular tests is detailed in the Pro- tocol section.  Measurements  Pulmonary function test  Diagnosis and staging of COPD were based on spirometry  (V6200 Autobox, Sensormedics Corp., Yorba Linda, CA, USA). Measurements included forced vital capacity (FVC) and FEV 1 .  The presence of persistent airflow obstruction and thus COPD was defined by a postbronchodilator FEV 1 /FVC ratio < 70%. The FEV 1   values were compared with the predicted values of Quanjer et al.   31  Figure 1 ‚ÄîFlow diagram of the trial. The patients were assessed for eligibility at the beginning of a 4-w inpatient pulmonary rehabilitation  program. All tests were completed within the first week following  admission.\n\nSLEEP, Vol. 39, No. 2, 2016 329 Motor Cortex Impairment in COPD‚ÄîAlexandre et al.  Blood gas analysis  Blood gases (PaO 2   and partial arterial pressure of carbon dioxide [PaCO   2 ]) collected from the radial artery were measured in the resting patients while they breathed room air, using a blood gas  analyzer (ABL 825, Radiometer Medical, Bronshoj, Denmark).  Polysomnographic sleep recordings  PSG was performed using standard techniques and manually analyzed according to the latest guidelines of the American Academy of Sleep Medicine.   32   Stage epoch classification and  SpO   2   were exported at 1 Hz in a text file. Then the percentage  of SpO   2   below 90% during NREM sleep was analyzed with an automatic routine developed in MATLAB (MATLAB 8.0, The  MathWorks, Inc., Natick, MA, USA). Patients who spent more  than 10% with SpO 2   below 90% during NREM sleep were classified as NREM sleep desaturators (NREM Des ), and non- NREM sleep desaturators otherwise (NREM   noDes ), according to published data giving evidence of cognitive dysfunction for similar levels of desaturation.   33  Exercise-induced desaturation  Exercise-induced desaturation was assessed during a 6-min walk test,   34   which was performed indoors along a 15-m cor- ridor following the current international recommendations.   35 The SpO   2   was monitored throughout the test with a digital pulse oximeter (Nonin Medical, Inc. Minneapolis, MN, USA).  S100B measurement  Blood serum was obtained by centrifuging the blood samples for 10 min at 4,000 rpm and was kept frozen at ‚àí80¬∞C until studied. Serum samples were analyzed for human S100B using commer - cial enzyme-linked immunosorbent assay kits (EMD Millipore,  Billerica, MA, USA). S100B concentrations are expressed in pg/ mL and the limit of detection was 2.74 pg/mL. More details on S100B measurement can be found in the supplemental material.  Torque and electromyography recordings  Maximal quadriceps torque was studied during isometric max-  imal voluntary contractions (MVCs) of the dominant leg with hip and knee angles set at 90¬∞ and using the same settings as  previously described.   2   The surface electromyography (EMG) signal of the vastus medialis was recorded using bipolar, silver chloride, surface electrodes. The surface EMG signal was am-  plified (√ó1000) and recorded at a sampling frequency of 4096 Hz (Biopac MP100, Biopac Systems, Santa Barbara, CA, USA).  Neuromuscular excitability and activation  Peripheral nerve stimulation was used to measure peripheral  voluntary   activation   (peripheral   VA),   muscle   contractility  (peak twitch), muscle excitability (M-wave), and spinal excit- ability (H-wave). The femoral nerve of the dominant leg was stimulated with a constant-current, high-voltage stimulator (DS7AH, Digitimer, Hertforshire, UK). A recruitment curve was performed at rest to determine which intensities to use during the protocol to elicit maximal M-waves (Mmax) and H-waves (Hmax). Transcranial magnetic stimulation was used to measure cor-  tical voluntary activation (cortical VA) and corticospinal excit - ability. Single transcranial magnetic stimulation (TMS) pulses of 1-ms duration were delivered over the motor cortex using  a Magstim 200 (Magstim Co., Whitland, UK). A recruitment curve was performed during voluntary contraction at 10%  of the maximal quadriceps torque in order to determine the maximal intensity.   36   The intensity at which the highest motor- evoked potentials (MEP) was observed was then used during  the protocol to assess cortical VA and corticospinal excitability.  More details on the peripheral nerve and transcranial mag- netic stimulation procedures are provided in the supplemental material.  Protocol  The neuromuscular tests consisted of four MVCs of the knee extensors, each separated by 2 min of recovery (Figure 2). Par - ticipants were asked to maintain maximal effort for at least  4 sec. A double pulse at 100 Hz was delivered at the Mmax  intensity over the femoral nerve during the force plateau of the  first two MVCs (superimposed doublet) and 2 sec after relax - ation (control doublet), according to the twitch interpolation  Figure 2 ‚ÄîExperimental design. Gray rectangles represent voluntary quadriceps contractions at maximal (MVC) or submaximal intensity at 50 and 30% of MVC. Superimposed and control doublets, maximal M-waves (Mmax), and maximal H-waves (Hmax) were delivered via electrical stimulation over the femoral nerve. Motor-evoked potentials (MEP) were delivered over the motor cortex via transcranial magnetic stimulation.\n\nSLEEP, Vol. 39, No. 2, 2016 330 Motor Cortex Impairment in COPD‚ÄîAlexandre et al.  technique.   37   A single transcranial magnetic stimulation pulse was delivered over the motor cortex to elicit MEPs during the  force plateau of the last two MVCs. Three single pulses at Mmax intensity or Hmax intensity separated by 10 sec were delivered twice between MVCs to elicit Mmax and Hmax at rest, respectively (see Figure 2 for more details). After the MVCs, three submaximal voluntary contractions (SVCs) with visual feedback were performed at 50% and 30% of MVC. A  single transcranial magnetic stimulation pulse was delivered  during the force plateau of each SVC to elicit superimposed twitch responses at 30% and 50% of MVC. Then the transcra - nial magnetic stimulation resting twitch was determined by extrapolation of the linear regression between voluntary force  and the superimposed twitch evoked at 30%, 50%, and during MVC. 38  Data Analysis  Maximal quadriceps torque (Q MVC ) was selected as the highest  torque plateau of 500 ms from the four MVCs. Muscle contrac - tile properties were evaluated by the quadriceps peak twitch (Q   Pt ) from the highest twitch response induced by femoral nerve stimulation at rest. Muscle excitability was determined as the highest Mmax peak-to-peak amplitude induced by femoral nerve stimulation at rest. Spinal excitability was determined as the highest Hmax peak-to-peak amplitude normalized with respect to muscle ex- citability (i.e., Hmax/Mmax).  The amount of neural drive to the muscle was quantified  by the root mean square of the vastus medialis EMG signal (EMG   RMS ) during the highest torque plateau of 500 ms normal - ized with respect to muscle excitability (i.e., EMG   RMS   /Mmax).  Peripheral VA was calculated via femoral nerve stimulation  according to the twitch interpolation technique 37   as follows:  Peripheral VA (%) = [1 ‚àí ((superimposed doublet) ‚ÅÑ (control doublet)) √ó 100] Motor cortex activation (cortical VA) was calculated via transcranial magnetic stimulation. Because the relationship  between   superimposed   transcranial   magnetic   stimulation twitch and voluntary force is not linear for intensities below  25% of MVC (reduced cortical and spinal excitability at low  force levels 39 ), the transcranial magnetic stimulation resting twitch was estimated by extrapolation of the linear regression between voluntary force and the superimposed twitch evoked  at 30% of MVC, 50% of MVC, and during MVC. 38   The cortical  VA was calculated as follows 38   :  Cortical VA (%) = [1 ‚àí ((superimposed twitch) ‚ÅÑ (estimated resting twitch)) √ó 100]  Corticospinal excitability was assessed by the amplitude of the maximal MEP induced by transcranial magnetic stimu-  lation during MVCs, normalized with respect to muscle ex - citability (i.e., MEP/Mmax). The cortical silent period (CSP) duration was measured as the time between MEP onset and the return of voluntary EMG activity. The central motor conduc- tion time (CMCT) was calculated from the delay between the stimulus artifact and MEP onset.  Statistical Analysis  All statistical analyses were performed using Statistica software  (StatSoft, Inc., version 6.0, Tulsa, OK, USA). All data were ex - amined for normality using a Shapiro-Wilk test. Differences between NREM   Des   and NREM   noDes   patients were studied using unpaired   t -tests for parametric data, and nonparametric Mann- Whitney   U   tests otherwise. The required sample size for the sub- study was calculated on the level of voluntary activation (main  outcome), based on a between-groups difference of 20%. 40   With  a 5% significance level and a power of 90%, the required sample  size was ten per group. Data are reported as mean and standard deviation (SD) or median and quartiles (lower and upper quar- tiles labeled respectively by Q1 and Q3) in the case of nonpara-  metric statistics. The significance level was set at P ‚â§ 0.05.  RESULTS Prevalence of NREM Sleep Desaturation  The main characteristics of the NREM   noDes   and NREM   Des   pa- tients are depicted in Table 1. The NREM   Des   group was com-  posed of 59 patients (51.3% of the study sample), meaning that over half of the patients with COPD spent more than 10% of  NREM sleep time with SpO   2   below 90%. Mean SpO 2   during  NREM sleep was 92.9 ¬± 1.51% in the NREM noDes   patients  versus 88.9 ¬± 1.96% in the NREM Des   patients (P < 0.001). There was no significant difference between the NREM Des   and NREM   noDes   patients regarding age (P = 0.78), weight (P = 0.98), body mass index (BMI; P = 0.71), FEV 1   (P = 0.32), FEV 1 /FVC (P = 0.13), blood gases (P = 0.15 and P = 0.98 for PaO   2   and PaCO   2 , respectively) or AHI (P = 0.81).  Subsample Characteristics and Blood Sample Analysis  The NREM   Des   and NREM   noDes   patients who took part in the  neuromuscular tests (n = 29) did not exhibit any significant dif -  ferences regarding age, weight, BMI, FEV 1 , FEV 1 /FVC, blood  gases, or time to desaturate during exercise (Table 2). The total sleep time, arousal index, and AHI were also comparable be-  tween groups (P = 0.26, 0.97, and 0.92, respectively). Serum levels of S100B were significantly higher in the NREM Des   com- pared with NREM   noDes   patients (P = 0.028). The values were 45.1 [Q1: 37.7, Q3: 62.8] versus 32.9 [Q1: 25.7, Q3: 39.5] pg.mL ‚àí1   in the NREM   Des   and NREM   noDes   patients, respectively (Figure 3).  Quadriceps Torque and Voluntary Activation  The data are presented in Figure 4. There were no significant  differences on Q MVC   (P = 0.58) or Q Pt   (P = 0.48) between the  NREM   Des   and NREM   noDes   patients. Q MVC   values were 101.1 ¬± 39 and 110.9 ¬± 61 Nm, and Q Pt   values were 41 ¬± 20 and 37 ¬± 16 Nm,  for the NREM   Des   and NREM   noDes   patients, respectively. Con-  versely, peripheral VA was significantly lower in the NREM Des  patients (90.7 ¬± 7.6 versus 95.9 ¬± 3.3%, P = 0.022). The cortical VA was also decreased in the NREM Des   group compared with NREM   noDes   and was 89.5% [Q1: 85.8, Q3: 93.6] versus 94.1% [Q1: 93.6, Q3: 96.8), respectively (P = 0.03, Figure 4B).  Electrophysiological Data  The data are presented in Table 3. EMG   RMS   /Mmax and MEP/  Mmax were significantly lower in the NREM Des   compared\n\nSLEEP, Vol. 39, No. 2, 2016 331 Motor Cortex Impairment in COPD‚ÄîAlexandre et al.  with NREM   noDes   patients (P = 0.031 and P = 0.03, respectively). Mmax amplitude (P = 0.08), Hmax/Mmax (P = 0.66), CSP (P = 0.28) and CMCT (P = 0.88) were not significantly dif   - ferent between groups.  DISCUSSION  The major findings of the study were that more than half of the nonhypoxemic COPD patients spent more than 10% of NREM  sleep time with SpO   2   below 90%, and the nonhypoxemic COPD patients who spent more than 10% of NREM sleep time  in desaturation had reduced motor cortex activation and ex- citability during maximal voluntary contractions and higher  serum S100B concentrations.  Prevalence of NREM Sleep Desaturation  The prevalence of O 2   desaturation during sleep is thought to be  in the range of 38% to 70% in nonhypoxemic COPD patients,  and our data are consistent with this range. 17‚Äì19   In the current  Table 1 ‚ÄîCharacteristics of the patients included in the study.  Total Sample   NREM noDes   NREM Des   P  n (% total sample)   115 (100%)   56 (48.7%)   59 (51.3%) Sex M/F   61/54   29/27   32/27  Age, y   64.28 (9.2)   64.04 (9.3)   64.53 (9.1)   0.78  Weight, kg   79.5 (19.2)   79.5 (19)   79.5 (19.6)   0.98  BMI, kg.m   ‚àí2   28.7 (6.31)   28.5 (6.03)   28.9 (6.6)   0.71  FEV   1 , L   1.48 (0.56)   1.53 (0.58)   1.43 (0.54)   0.32 FEV   1   , % of predicted values   55.7 (15.5)   56.9 (15.5)   54.6 (15.5)   0.44 FEV   1   /FVC %   54.1 (10.7)   55.7 (10.4)   52.6 (10.9)   0.13 PaO   2   , mmHg   68.7 (5.2)   69.4 (5.78)   68 (4.54)   0.15 PaCO 2   , mmHg   39.4 (5.56)   39.5 (5.8)   39.4 (4.5)   0.98 SaO   2   , %   92.9 (2.39)   93.3 (2.41)   92.5 (2.32)   0.07 AHI, events.h   ‚àí1   6.58 (4.93)   6.43 (5.38)   6.73 (4.5)   0.81 % of NREM sleep time with SpO   2   < 90%   29 (35.4)   0.89 [0, 2.1]   46.2 [25.3, 89.9]   < 0.001  Values are means (standard deviation) or median [Q1, Q3 quartiles] in the case of nonparametric statistics. % of NREM sleep time with SpO 2   < 90% is  the percentage of time spent with pulse oxygen saturation below 90% during the NREM sleep stage. AHI, apnea-hypopnea index; BMI, body mass index,  FEV 1   , forced expiratory volume in 1 sec, FVC, forced vital capacity, PaCO   2   , arterial carbon dioxide tension; PaO   2   , arterial oxygen tension; SaO   2   , arterial oxygen saturation.  Table 2 ‚ÄîCharacteristics of the patients who took part in the neuromuscular tests.  NREM noDes   (n = 15)   NREM Des   (n = 14)   P  Sex M/F   10/5   9/5 Age, y   61.5 (8.57)   61.7 (6.09)   0.93 Weight, kg   69.5 (18.3)   74.6 (19.3)   0.46  BMI, kg.m   ‚àí2   25 (6.66)   25.9 (5.85)   0.69 FEV 1 , L   1.28 (0.54)   1.36 (0.57)   0.71  FEV   1   , % of predicted values   45.9 (15.5)   49.1 (16.8)   0.61 FEV   1   /FVC %   46.5 (11.5)   46.6 (11.5)   0.98 PaO   2   mmHg   73.5 (6.33)   71.6 (10.5)   0.56 PaCO 2   mmHg   38.9 (3.78)   41.1 (5.85)   0.35 SaO   2   %   94.4 (1.68)   93.7 (3.04)   0.44 % of 6 MWT time with SpO   2   < 90%   41.1 (35.6)   59.5 (40.7)   0.20 Total sleep time, min   370.2 (92.4)   324.9 (86.8)   0.26 Arousal index, events.h ‚àí1   16.1 (9.64)   16.3 (11.66)   0.97 AHI, events.h   ‚àí1   6.77 (7.91)   7.42 (6.81)   0.84 % of NREM sleep time with SpO   2   < 90%   0.6 [0, 5]   50.45 [16.6, 69]   < 0.001  Values are means (standard deviation) or median [Q1, Q3 quartiles] in the case of nonparametric statistics. % of 6 MWT time with SpO 2   < 90% is the percentage of time spent with pulse oxygen saturation below 90% during the 6 min walking test. % of NREM sleep time with SpO   2   < 90% is the percentage  of time spent with pulse oxygen saturation below 90% during the nonrapid eye movement (NREM) sleep stage. AHI, apnea-hypopnea index; BMI, body  mass index; FEV 1   , force expiratory volume in 1 sec; FVC, forced vital capacity; PaCO   2   , arterial carbon dioxide tension; PaO   2   , arterial oxygen tension; SaO   2   , arterial oxygen saturation.\n\nSLEEP, Vol. 39, No. 2, 2016 332 Motor Cortex Impairment in COPD‚ÄîAlexandre et al.  study, we used a cutoff of only 10% of the NREM sleep time,  with SpO 2   below 90% to diagnose NREM sleep desaturation. As NREM sleep desaturation has never been specifically assessed in  COPD, our choice was dictated by the criteria used to diagnose desaturation during TST. Although no clear consensus exists, a percentage of the TST with SpO 2   below 90% is frequently cited  in the literature. 41   We opted for a 10% criterion with SpO 2   below  90% as it has classically been used to study brain impairment. 33  This study is the first to assess the prevalence of NREM sleep  desaturation in COPD. Although it is indisputable that the deepest O 2   desaturation occurs during REM sleep, 41   a few studies have observed NREM sleep desaturation in patients with COPD who experience nocturnal desaturation. 42,43   Our results are consistent with these observations and provide further evidence that O   2   de- saturation during sleep is not restricted to REM sleep in COPD. It should be noted that the mechanisms responsible for NREM desaturation cannot be determined from our results, although the phenomenon seems unlikely to be explained by obstructive sleep apnea (OSA). Indeed, patients with severe OSA were excluded, and the AHIs were comparable in the two groups of patients with and without NREM sleep desaturation.  Furthermore, the mechanisms are unlikely to involve the levels  of diurnal PaO   2   , given the absence of diurnal PaO   2   differ- ences between the groups. This result is unsurprising because PaO   2   changes during sleep are not correlated with the diurnal PaO   2   levels in COPD. 44   Two important candidates to explain desaturation during sleep in COPD, especially during REM sleep, are alveolar hypoventilation and ventilation-perfusion mismatching. 41   Their potential implication in NREM sleep de- saturation remains to be investigated.  Effect of NREM Sleep Desaturation on Neuronal Damage and Neuromuscular Function  The second purpose of the study was to assess the repercus- sions of NREM sleep desaturation on neuronal damage and  neuromuscular function. To do so, serum S100B, an easy-to-  use and cost-effective biomarker of neuronal damage,   25‚Äì28   was analyzed in a subgroup of patients with COPD. The ability of  serum S100B to detect brain impairment was recently con -  firmed in COPD and found to be associated with hippocampal  atrophy and impaired cognitive function.   22   In the current study,  we observed a higher S100B concentration in patients with  NREM sleep desaturation, but without having the possibility to  localize the impaired brain areas. The higher serum S100B con - centrations could be linked to confounding factors other than NREM sleep desaturation, such as decreased sleep quality or sleep deprivation. 45   Importantly, we did not find any differences  between the patients who did and did not experience desatura- tion during NREM sleep regarding TST and the arousal index.  Figure 4 ‚Äî (A)   Maximal quadriceps torque (Q MVC ), quadriceps peak  twitch (Q Pt   ) and peripheral voluntary activation (peripheral VA) in patients with COPD experiencing desaturation (NREM   Des ) and nondesaturation (NREM   noDes ).   (B)   Medians and quartile box plots of motor cortex activation (cortical VA) in patients with COPD experiencing desaturation (NREM   Des ) and nondesaturation (NREM   noDes ) (nonparametric data). NREM, nonrapid eye movement.  A B Figure 3 ‚ÄîMedian and quartiles box plots of serum S100B concentration in the patients with COPD experiencing desaturation (NREM   Des ) and nondesaturation (NREM   noDes ) (non-parametric data). NREM = nonrapid eye movement.\n\nSLEEP, Vol. 39, No. 2, 2016 333 Motor Cortex Impairment in COPD‚ÄîAlexandre et al.  The functional repercussions of neuronal damage can be  numerous. We chose to focus specifically on neuromuscular  function and its effect on maximal quadriceps strength, as pe- ripheral muscle weakness is one of the main deleterious sys- temic effects in COPD. 46   By stimulating the motor cortex, we  observed lower MEP/M amplitude in the NREM   Des   patients during maximal voluntary contractions. The MEP/M ampli-  tude reflects both spinal and cortical excitability. 47   In the cur-  rent study, the comparable H-reflex amplitude observed in  the NREM   Des   and NREM   noDes   patients indicates that the lower MEP/M could not be attributed to lower spinal excitability and thus is mainly explained by reduced motor cortex excitability.  Furthermore, the reduced cortical excitability was associated  with lower motor cortex activation as well as lower quadri-  ceps motor unit activation (as measured by peripheral VA and  EMG   RMS   /M). These results support the hypothesis that patients with COPD who experience NREM sleep desaturation have reduced neural drive reaching the quadriceps muscle during  MVC because of motor cortical output failure.  Impaired neural drive to the quadriceps has been a contro- versial topic in COPD. One study reported lower activation at the muscle level in patients with COPD compared with healthy controls, 40   whereas others did not. 48,49   More recently, we found lower cortical activity through neuroimaging assessment in  patients with COPD during MVCs. 2   By using the neuroim - aging technique, it was not possible to infer that the lower cortical activity resulted in lower cortical output.   2   In the cur- rent study, we assessed the cortical motor output with a more direct approach by stimulating the motor cortex. Our results  confirm that cortical output is impaired in COPD but that it  mainly concerns those patients with NREM sleep desaturation, as the values of voluntary activation reached by the NREM   noDes  patients (around 95%) were substantially similar to those of  healthy subjects reported in other studies.   38,49   In addition, our data suggest that the discrepancies in previous studies might be explained by differences in the number of patients with COPD who experience NREM desaturation, which was not taken into account in previous works. Maximal muscle torque depends in part on the ability to activate the muscle. 50   In addition, as the relationship between  peripheral VA and torque is curvilinear, small modulations in peripheral VA induce much larger Q   MVC   changes at near- maximal contraction intensities.   51,52   For example, it was shown that a 5.7% increase in peripheral VA induced a 20.4% increase  in Q MVC. 52   Conversely, a 3% decrease in peripheral VA caused by neuromuscular fatigue has been associated with a 11% de - crease in Q MVC. 45   Therefore, the relatively low peripheral VA  for NREM   Des   compared with NREM   noDes   patients (average of  5.2% less) should have expressed a greater loss of strength in these patients than the average of 9% (nonsignificant) strength reduction (101 versus 111 Nm, P = 0.58). The finding that  the NREM   Des   patients reached the same torque level as the NREM   noDes   patients could be explained by low statistical power, or it may suggest a compensatory mechanism(s). Concerning  the first explanation, it is important to note that the SD of the  Q MVC   data are in accordance with those of other studies.   53   In addition, the current Q MVC   data are far from the level of sta-  tistical significance and we calculated the   a posteriori   number  of subjects needed to obtain 90% statistical power (400 par - ticipants). These observations are in accordance with a limited experimental effect, if proven. Any potential compensatory mechanism is unlikely to be linked to a difference in intrinsic muscle capacity (due to higher muscle mass or contractility) because Q   Pt   was comparable between groups. Muscle torque at a joint is the result of contributions from both agonist and antagonist muscles. In a condition of decreased agonist torque (due to lower cortical activation), any lower torque developed  by the antagonist knee flexor muscles during maximal quadri - ceps contraction in the NREM   Des   group could account for the comparable resultant torque; that is, comparable Q MVC . Unfor- tunately, the antagonist activity was not assessed in this study, but this hypothesis is supported by a study carried out by Simoneau et al.   54   These authors reported no differences in the  resultant maximal torque of the dorsiflexors in elderly subjects compared with young subjects, despite a 40% decrease in ago - nist maximal torque. This was explained by an activation of the  antagonist plantar flexor muscle during maximal dorsiflexion  that was almost twofold lower in the elderly, showing that in some circumstances maximal voluntary torque can apparently  be preserved despite a significant decrease in agonist torque.  Study Limitations  Serum S100B, which was used as a marker of CNS injury, has  the advantage of being a strong, sensitive, and easy-to-use marker of neuronal damage.   29   However, although S100B is a  marker of cerebral damage, it does not inform the location of the damage and cannot be used to localize the impaired brain areas. Computed tomography and MRI are likely to provide  Table 3 ‚ÄîElectrophysiological responses to transcranial magnetic and femoral nerve stimulation.  NREM noDes   (n = 15)   NREM Des   (n = 14)   P  Mmax amplitude mV   2.44 [1.64, 3.22]   4.32 [2.12, 7.9]   0.08 Hmax/Mmax   0.259 (0.208)   0.220 (0.153)   0.66 EMG   RMS /Mmax   0.077 (0.040)   0.046 (0.029)   0.031 MEP/Mmax   0.529 (0.143)   0.285 (0.243)   0.03 CSP ms   110 (20.3)   101 (14.2)   0.28 CMCT ms   20.6 (3.8)   20.2 (5.71)   0.88  Values are means (standard deviation) or median [Q1, Q3 quartiles] in the case of non-parametric statistics. CMCT, central motor conduction time;  CSP, corticospinal silent period; EMG   RMS   , root mean square of the vastus medialis electromyogram; MEP, motor-evoked potential; Mmax, maximal M-wave.\n\nSLEEP, Vol. 39, No. 2, 2016 334 Motor Cortex Impairment in COPD‚ÄîAlexandre et al.  useful complementary information on the cerebral damage in   patients   with   COPD   experiencing   desaturation   during NREM sleep. We did not directly assess the cerebrovascular O   2   reactivity during sleep. Therefore, although our results are highly con- sistent with an effect of NREM sleep desaturation on brain impairment, the occurrence of brain hypoxia during NREM sleep in the patients experiencing desaturation could only be inferred from the literature data. 12,13,55,56   A study to address the effect of correcting NREM sleep desaturation on serum  S100B levels and motor cortex impairment would address  this limitation.  CONCLUSION  NREM sleep desaturation is far from negligible as it concerns approximately one of two patients with moderate to severe COPD and a resting PaO   2   between 60 and 80 mmHg. The pa - tients with COPD who experience desaturation during NREM sleep exhibited an elevated level of a biomarker of CNS injury  (i.e., serum S100B) and lower neural drive during quadriceps MVCs due to impaired cortical motor output. The observation  that quadriceps muscle weakness was not more marked in the patients who experience desaturation suggests the existence of compensatory mechanisms whose nature and origin remain to be determined. Overall, the results are consistent with an involvement of NREM sleep desaturation in triggering CNS injury and decreasing neural drive to the quadriceps in COPD. The prevention of NREM sleep desaturation may well be an important clinical perspective to promote cerebral plasticity in  COPD. Further studies are needed to determine the extent to which reversing neural activity is beneficial for the maximal  voluntary force and functional capacity of patients with COPD.  REFERENCES  1.   Orth M, Diekmann C, Suchan B, et al. Driving performance in patients  with chronic obstructive pulmonary disease. J Physiol Pharmacol  2008;59:539‚Äì47.  2.   Alexandre F, Heraud N, Oliver N, Varray A. Cortical implication in  lower voluntary muscle force production in non-hypoxemic COPD  patients. PloS Oone 2014;9:e100961.  3.   Zheng GQ, Wang Y, Wang XT. Chronic hypoxia-hypercapnia influences cognitive function: a possible new model of cognitive  dysfunction in chronic obstructive pulmonary disease. Med  Hypotheses 2008;71:111‚Äì3.  4.   Dodd JW, Getov SV, Jones PW. Cognitive function in COPD. Eur Respir J 2010;35:913‚Äì22.  5.   Gupta PP, Sood S, Atreja A, Agarwal D. A comparison of cognitive functions in non-hypoxemic chronic obstructive pulmonary disease (COPD) patients and age-matched healthy volunteers using mini- mental state examination questionnaire and event-related potential,  P300 analysis. Lung India 2013;30:5‚Äì11.  6.   Liesker JJ, Postma DS, Beukema RJ, et al. Cognitive performance in patients with COPD. Respir Med 2004;98:351‚Äì6.  7.   Harris AD, Murphy K, Diaz CM, et al. Cerebral blood flow response to acute hypoxic hypoxia. NMR Biomed 2013;26:1844‚Äì52.  8.   Shapiro W, Wasserman AJ, Baker JP, Patterson JL Jr. Cerebrovascular  response to acute hypocapnic and eucapnic hypoxia in normal  man. J Clin Invest 1970;49:2362‚Äì8.  9.   Albayrak R, Fidan F, Unlu M, et al. Extracranial carotid Doppler ultrasound evaluation of cerebral blood flow volume in COPD patients. Respir Med 2006;100:1826‚Äì33. 10.   Yildiz S, Kaya I, Cece H, et al. Impact of COPD exacerbation on cerebral blood flow. Clin Imaging 2012;36:185‚Äì90.  11.   Vogiatzis I, Louvaris Z, Habazettl H, et al. Cerebral cortex oxygen  delivery and exercise limitation in patients with COPD. Eur Respir J  2013;41:295‚Äì301.  12.   Hajak G, Klingelhofer J, Schulz-Varszegi M, Sander D, Ruther  E. Sleep apnea syndrome and cerebral hemodynamics. Chest  1996;110:670‚Äì9.  13.   Balfors EM, Franklin KA. Impairment of cerebral perfusion  during obstructive sleep apneas. Am J Respir Crit Care Med  1994;150:1587‚Äì91.  14.   Meyer JS, Ishikawa Y, Hata T, Karacan I. Cerebral blood flow in normal and abnormal sleep and dreaming. Brain Cogn 1987;6:266‚Äì94.  15.   Meadows GE, O‚ÄôDriscoll DM, Simonds AK, Morrell MJ, Corfield DR. Cerebral blood flow response to isocapnic hypoxia during slow-wave sleep and wakefulness. J Appl Physiol 2004;97:1343‚Äì8.  16.   Corfield DR, Meadows GE. Control of cerebral blood flow during sleep and the effects of hypoxia. Adv Exp Med Biol 2006;588:65‚Äì73.  17.   Lacasse Y, Series F, Vujovic-Zotovic N, et al. Evaluating nocturnal oxygen desaturation in COPD--revised. Respir Med 2011;105:1331‚Äì7.  18.   Levi-Valensi P, Weitzenblum E, Rida Z, et al. Sleep-related oxygen  desaturation and daytime pulmonary haemodynamics in COPD  patients. Eur Respir J 1992;5:301‚Äì7.  19.   Chaouat A, Weitzenblum E, Kessler R, et al. Sleep-related O2 desaturation and daytime pulmonary haemodynamics in COPD  patients with mild hypoxaemia. Eur Respir J 1997;10:1730‚Äì5. 20.   McSharry DG, Ryan S, Calverley P, Edwards JC, McNicholas WT. Sleep quality in chronic obstructive pulmonary disease. Respirology  2012;17:1119‚Äì24.  21.   Lahousse L, van den Bouwhuijsen QJ, Loth DW, et al. Chronic  obstructive pulmonary disease and lipid core carotid artery plaques in the elderly: the Rotterdam Study. Am J Respir Crit Care Med  2013;187:58‚Äì64.  22.   Li J, Fei GH. The unique alterations of hippocampus and cognitive  impairment in chronic obstructive pulmonary disease. Respir Res  2013;14:140.  23.   Reeves RH, Yao J, Crowley MR, et al. Astrocytosis and axonal proliferation in the hippocampus of S100b transgenic mice. Proc Natl  Acad Sci U S A 1994;91:5359‚Äì63. 24.   Van Eldik LJ, Wainwright MS. The Janus face of glial-derived S100B: beneficial and detrimental functions in the brain. Restor Neurol Neurosci 2003;21:97‚Äì108.  25.   Vos PE, Lamers KJ, Hendriks JC, et al. Glial and neuronal proteins in  serum predict outcome after severe traumatic brain injury. Neurology  2004;62:1303‚Äì10.  26.   Abraha HD, Butterworth RJ, Bath PM, Wassif WS, Garthwaite J, Sherwood RA. Serum S-100 protein, relationship to clinical outcome in acute stroke. Ann Clin Biochem 1997;34:546‚Äì50.  27.   Bottiger BW, Mobes S, Glatzer R, et al. Astroglial protein S-100 is an  early and sensitive marker of hypoxic brain damage and outcome after  cardiac arrest in humans. Circulation 2001;103:2694‚Äì8.  28.   Sen J, Belli A. S100B in neuropathologic states: the CRP of the brain? J Neurosci Res 2007;85:1373‚Äì80.  29.   Pham N, Fazio V, Cucullo L, et al. Extracranial sources of S100B do not affect serum levels. PloS One 2010;5:e12691. 30.   GOLD. Global Strategy for the Diagnosis, Management and Prevention of COPD. Global Initiative for Chronic Obstructive Lung Disease (GOLD), 2014.Available from: http://www.goldcopd.org/.  31.   Quanjer PH, Tammeling GJ, Cotes JE, Pedersen OF, Peslin R, Yernault JC. Lung volumes and forced ventilatory flows. Report Working Party Standardization of Lung Function Tests, European Community for Steel and Coal. Official Statement of the European Respiratory Society. Eur Respir J Suppl 1993;16:5‚Äì40.  32.   Berry RB, Budhiraja R, Gottlieb DJ, et al. Rules for scoring respiratory events in sleep: update of the 2007 AASM Manual for the  Scoring of Sleep and Associated Events. Deliberations of the Sleep  Apnea Definitions Task Force of the American Academy of Sleep Medicine. J Clin Sleep Med 2012;8:597‚Äì619.\n\nSLEEP, Vol. 39, No. 2, 2016 335 Motor Cortex Impairment in COPD‚ÄîAlexandre et al.  33.   Park SY, Kim SM, Sung JJ, et al. Nocturnal hypoxia in ALS is related  to cognitive dysfunction and can occur as clusters of desaturations.  PloS One 2013;8:e75324.  34.   van Gestel AJ, Clarenbach CF, Stowhas AC, et al. Prevalence and  prediction of exercise-induced oxygen desaturation in patients with chronic obstructive pulmonary disease. Respi Int Rev Thorac Dis  2012;84:353‚Äì9.  35.   Brooks D, Solway S, Gibbons WJ. ATS statement on six-minute walk test. Am J Respir Crit Care Med 2003;167:1287.  36.   Temesi J, Gruet M, Rupp T, Verges S, Millet GY. Resting and  active motor thresholds versus stimulus-response curves to determine transcranial magnetic stimulation intensity in quadriceps  femoris. J Neuroeng Rehabil 2014;11:40.  37.   Allen GM, Gandevia SC, McKenzie DK. Reliability of measurements of muscle strength and voluntary activation using twitch interpolation.  Muscle Nerve 1995;18:593‚Äì600.  38.   Sidhu SK, Bentley DJ, Carroll TJ. Cortical voluntary activation of the  human knee extensors can be reliably estimated using transcranial  magnetic stimulation. Muscle Nerve 2009;39:186‚Äì96.  39.   Lee M, Gandevia SC, Carroll TJ. Cortical voluntary activation can  be reliably measured in human wrist extensors using transcranial  magnetic stimulation. Clin Neurophysiol 2008;119:1130‚Äì8. 40.   Vivodtzev I, Flore P, Levy P, Wuyam B. Voluntary activation during  knee extensions in severely deconditioned patients with chronic  obstructive pulmonary disease: benefit of endurance training. Muscle Nerve 2008;37:27‚Äì35.  41.   Weitzenblum E, Chaouat A. Sleep and chronic obstructive pulmonary  disease. Sleep Med Rev 2004;8:281‚Äì94.  42.   Becker HF, Piper AJ, Flynn WE, et al. Breathing during sleep in  patients with nocturnal desaturation. Am J Respir Crit Care Med 1999;159:112‚Äì8. 43.   Zanchet RC, Viegas CA. Nocturnal desaturation: predictors and the  effect on sleep patterns in patients with chronic obstructive pulmonary  disease and concomitant mild daytime hypoxemia. J Bras Pneumol 2006;32:207‚Äì12.  44.   Koo KW, Sax DS, Snider GL. Arterial blood gases and pH during  sleep in chronic obstructive pulmonary disease. Am J Med  1975;58:663‚Äì70.  45.   Papaiordanidou M, Guiraud D, Varray A. Kinetics of neuromuscular  changes during low-frequency electrical stimulation. Muscle Nerve  2010;41:54‚Äì62.  46.   Barnes PJ, Celli BR. Systemic manifestations and comorbidities of COPD. Eur Respir J 2009;33:1165‚Äì85.  47.   Fryer G, Pearce AJ. The effect of lumbosacral manipulation on corticospinal and spinal reflex excitability on asymptomatic participants. J Manipulative Physiol Ther 2012;35:86‚Äì93.  48.   Mador MJ, Deniz O, Aggarwal A, Kufel TJ. Quadriceps fatigability after single muscle exercise in patients with chronic obstructive  pulmonary disease. Am J Respir Crit Care Med 2003;168:102‚Äì8.  49.   Seymour JM, Ward K, Raffique A, et al. Quadriceps and ankle dorsiflexor strength in chronic obstructive pulmonary disease. Muscle Nerve 2012;46:548‚Äì54. 50.   Klass M, Baudry S, Duchateau J. Voluntary activation during maximal  contraction with advancing age: a brief review. Eur J Appl Physiol  2007;100:543‚Äì51.  51.   Herbert RD, Gandevia SC. Twitch interpolation in human muscles: mechanisms and implications for measurement of voluntary activation. J Neurophysiol 1999;82:2271‚Äì83. 52.   Kooistra RD, de Ruiter CJ, de Haan A. Conventionally assessed voluntary activation does not represent relative voluntary torque  production. Eur J Appl Physiol 2007;100:309‚Äì20.  53.   Menon MK, Houchen L, Harrison S, Singh SJ, Morgan MD, Steiner  MC. Ultrasound assessment of lower limb muscle mass in response to  resistance training in COPD. Respir Res 2012;13:119.  54.   Simoneau EM, Billot M, Martin A, Van Hoecke J. Antagonist  mechanical contribution to resultant maximal torque at the ankle joint  in young and older men. J Electromyogr Kinesiol 2009;19:e123‚Äì31.  55.   Olopade C, Mensah E, Gupta R, et al. Noninvasive determination of brain tissue oxygenation during sleep in obstructive sleep apnea: a  near-infrared spectroscopic approach. Sleep 2007;30:1747‚Äì55.  56.   Matsuo A, Inoue Y, Namba K, Chiba H. Changes in cerebral  hemoglobin indices in obstructive sleep apnea syndrome with  nasal continuous positive airway pressure treatment. Sleep Breath 2011;15:487‚Äì92.  ACKNOWLEDGMENTS  The authors thank Professor Robin Candau and Dr. Henri Bernardi for  assistance and the use of their facilities for serum data analyses, and  Dr. Mathieu Gueugnon for assistance in Matlab analyses. Furthermore,  the authors also thank the patient‚Äôs association Apard for the use of the polysomnograph.  SUBMISSION & CORRESPONDENCE INFORMATION  Submitted for publication January, 2015 Submitted in final revised form August, 2015 Accepted for publication September, 2015 Address correspondence to: Francois Alexandre, Movement To Health (M2H), Euromov, University of Montpellier, 700 avenue du Pic Saint Loup, 34090 Montpellier, France; Tel: (+33) 434 432 632; Fax: (+33) 434 432 644;  Email: alexandre.francois88@gmail.com  DISCLOSURE STATEMENT  This was not an industry supported study. Dr. Alexandre was partially  supported by a grant in aid from the French Ministry through the  ‚ÄúAssociation Nationale de la Recherche et de la Technologie‚Äù (National Agency for Research and Technology). The authors have no other funding  to declare. The authors have indicated no financial conflicts of interest. The work was performed at the Clinique du Souffle La Vallonie, Fontalvie, 800 avenue Joseph Vallot, 34700 Lod√®ve, France, and Clinique du Souffle Les Clarines, Fontalvie, Route de Condat, Le S√©dour Sud, 15400 Riom-es- Montagnes, France."
  ],
  "embeddings": [
    [
      -0.050053227692842484,
      -0.02924860641360283,
      0.02398059144616127,
      0.0625954121351242,
      0.0625738799571991,
      0.04024507477879524,
      -0.08147680014371872,
      0.02243458852171898,
      0.04151425510644913,
      -0.09577696770429611,
      -0.10011780261993408,
      -0.0640774816274643,
      0.009210672229528427,
      0.05852324888110161,
      -0.08533082902431488,
      -0.07749656587839127,
      0.06993016600608826,
      0.03610985726118088,
      -0.09961949288845062,
      0.03377746418118477,
      0.047603487968444824,
      0.0463576577603817,
      0.10790368914604187,
      0.015789901837706566,
      0.04710376635193825,
      -0.024680746719241142,
      0.005303571466356516,
      -0.0592716783285141,
      -0.08061543852090836,
      0.0038176283705979586,
      0.0020846871193498373,
      0.05218855291604996,
      -0.03378525748848915,
      0.023179633542895317,
      -0.018414918333292007,
      -0.0042678238824009895,
      -0.003020444419234991,
      0.04544176906347275,
      -0.04358392581343651,
      0.03967103734612465,
      0.0658663958311081,
      -0.046449124813079834,
      0.011797803454101086,
      0.014347589574754238,
      0.05677102506160736,
      0.017626719549298286,
      -0.07183835655450821,
      -0.05752340704202652,
      -0.04888822138309479,
      0.10870403051376343,
      -0.05950357764959335,
      -0.002793854335322976,
      -0.016309920698404312,
      0.10835409164428711,
      0.025856122374534607,
      -0.011147643439471722,
      -0.012049098499119282,
      -0.012531054206192493,
      -0.053838882595300674,
      0.02407102845609188,
      0.0011745479423552752,
      -0.022685164585709572,
      -0.0076261889189481735,
      -0.04216599091887474,
      0.012325330637395382,
      0.07863712310791016,
      -0.09385442733764648,
      -0.006396031938493252,
      -0.003272558329626918,
      -0.010646400041878223,
      0.0026604742743074894,
      0.022677715867757797,
      -0.05416272208094597,
      0.03179109841585159,
      -0.02363322302699089,
      0.06128087639808655,
      0.10558153688907623,
      0.043657079339027405,
      0.07821564376354218,
      -0.08473984897136688,
      0.05318739265203476,
      0.06485430896282196,
      0.015726760029792786,
      -0.0029194091912359,
      0.06357438862323761,
      0.00015742037794552743,
      0.046560805290937424,
      0.06325994431972504,
      -0.048919882625341415,
      0.0033000309485942125,
      0.017876850441098213,
      0.03065991774201393,
      -0.03492903709411621,
      0.017145967110991478,
      0.07558723539113998,
      0.04081646725535393,
      -0.01883174292743206,
      -0.008529214188456535,
      -0.016451463103294373,
      0.014117599464952946,
      0.0038751077372580767,
      0.03936343640089035,
      0.02418653294444084,
      -0.026953253895044327,
      0.020377881824970245,
      0.03314243257045746,
      0.05813669040799141,
      -0.01682909019291401,
      0.07090607285499573,
      -0.07000651210546494,
      -0.004681704565882683,
      0.07519510388374329,
      -0.02833554893732071,
      -0.03466235473752022,
      0.09939577430486679,
      0.060911037027835846,
      0.020357847213745117,
      0.05879358947277069,
      0.06090846657752991,
      0.1116555780172348,
      -0.04416313394904137,
      -0.004546680022031069,
      0.06939038634300232,
      -0.08906007558107376,
      0.03353945538401604,
      -0.015713106840848923,
      -0.15103574097156525,
      8.010886736994377e-33,
      0.01373402401804924,
      -0.04030830040574074,
      0.025363583117723465,
      0.01175931841135025,
      0.004748965613543987,
      -0.06869816780090332,
      -0.08688632398843765,
      0.04937541484832764,
      0.00043007690692320466,
      0.030910704284906387,
      -0.12384864687919617,
      0.0465015172958374,
      -0.025567812845110893,
      0.07235332578420639,
      0.04147481545805931,
      0.013415658846497536,
      -0.030124766752123833,
      0.06411112844944,
      -0.029236407950520515,
      -0.031041502952575684,
      0.015998918563127518,
      -0.041088495403528214,
      0.032782211899757385,
      -0.013227192685008049,
      -0.0037111928686499596,
      0.003818599507212639,
      0.02868880331516266,
      0.045196834951639175,
      -0.06736364215612411,
      -0.002897179452702403,
      -0.09991981089115143,
      -0.0199216790497303,
      0.05321548134088516,
      -0.053229570388793945,
      0.029520299285650253,
      -0.04957825690507889,
      0.006986468564718962,
      0.03683668002486229,
      0.02810697816312313,
      -0.03937433287501335,
      -0.08123967796564102,
      0.05095082148909569,
      -0.012666430324316025,
      -0.018132301047444344,
      -0.019739577546715736,
      -0.03998409956693649,
      0.004813977517187595,
      -0.010897289961576462,
      -0.014089968055486679,
      -0.058067403733730316,
      -0.026444820687174797,
      -0.009481760673224926,
      -0.02052219584584236,
      -0.08980762213468552,
      -0.11285648494958878,
      0.060373179614543915,
      -0.002477124333381653,
      0.01699702814221382,
      -0.005253609735518694,
      0.05266372486948967,
      0.05303838104009628,
      0.05563710629940033,
      -0.04997878149151802,
      0.006368814501911402,
      0.016178254038095474,
      0.02613355964422226,
      -0.04425039142370224,
      0.019194696098566055,
      0.019285334274172783,
      -0.05048811063170433,
      0.03801313415169716,
      -0.0004648397443816066,
      0.06332027912139893,
      -0.010341647081077099,
      0.023854076862335205,
      -0.041388995945453644,
      0.035229843109846115,
      0.024548785760998726,
      -0.08823391795158386,
      0.001125384820625186,
      0.04237549006938934,
      0.047412555664777756,
      -0.06352175027132034,
      -0.06154318526387215,
      -0.060216277837753296,
      0.0036562434397637844,
      0.019655756652355194,
      -0.015325314365327358,
      -0.04962785542011261,
      -0.005662932526320219,
      -0.07960875332355499,
      -0.020956380292773247,
      -0.0038035002071410418,
      -0.032313842326402664,
      -0.037750355899333954,
      -7.280300100227032e-33,
      -0.04617203027009964,
      0.008722743019461632,
      -0.12386530637741089,
      -0.018292414024472237,
      0.08010251075029373,
      0.004964508581906557,
      0.019388658925890923,
      -0.029314927756786346,
      -0.04375453665852547,
      -0.04261124134063721,
      0.0810212716460228,
      -0.08214300125837326,
      0.03270643204450607,
      -0.04206273704767227,
      0.035740360617637634,
      -0.043715063482522964,
      -0.0654623806476593,
      0.022565392777323723,
      -0.0014847774291411042,
      0.08915995061397552,
      0.09706442803144455,
      0.036283526569604874,
      -0.14421610534191132,
      -0.017680346965789795,
      -0.04557964578270912,
      0.02869787998497486,
      -0.009163348004221916,
      0.1740345060825348,
      -0.030952088534832,
      -0.07882490009069443,
      0.010603460483253002,
      -0.009082240052521229,
      -0.1450430452823639,
      0.008903982117772102,
      0.03137591853737831,
      0.04307622089982033,
      0.04384716972708702,
      -0.07290362566709518,
      -0.04487159103155136,
      -0.06834640353918076,
      0.10903257131576538,
      0.03291444107890129,
      -0.07605600357055664,
      -0.019713692367076874,
      0.026857413351535797,
      -0.0067122019827365875,
      -0.05261832848191261,
      -0.027346856892108917,
      0.004119404125958681,
      0.002400594064965844,
      0.0049663265235722065,
      -0.028889136388897896,
      -0.06975105404853821,
      0.05553733929991722,
      -0.012716416269540787,
      -0.05350617319345474,
      -0.007841386832296848,
      -0.028272420167922974,
      -0.02941436506807804,
      0.029591603204607964,
      -0.03533259406685829,
      -0.022071560844779015,
      -0.07179006189107895,
      -0.05410394072532654,
      0.061952631920576096,
      0.025218600407242775,
      0.013820243068039417,
      -0.033643826842308044,
      0.03204818442463875,
      0.046557389199733734,
      -0.05582211911678314,
      -0.03256063163280487,
      0.025261282920837402,
      0.0286797434091568,
      -0.032809387892484665,
      -0.02413969300687313,
      -0.008593769744038582,
      -0.02627188339829445,
      -0.04134782403707504,
      -0.04407189041376114,
      -0.01825573481619358,
      -0.1712663620710373,
      -0.05355309322476387,
      0.07552390545606613,
      -0.018410323187708855,
      0.022669030353426933,
      0.08970977365970612,
      0.02130207233130932,
      0.07538371533155441,
      0.0206594280898571,
      -0.07466573268175125,
      0.019750773906707764,
      -0.10941833257675171,
      0.01833966374397278,
      -0.012021634727716446,
      -6.126229834535479e-8,
      0.006934434175491333,
      0.06022890284657478,
      0.010979801416397095,
      0.023347921669483185,
      -0.01986915059387684,
      -0.06937627494335175,
      -0.017525851726531982,
      0.04030389338731766,
      -0.02382061257958412,
      0.05470972880721092,
      0.10621404647827148,
      -0.013384947553277016,
      0.014334229752421379,
      -0.094780333340168,
      -0.030077695846557617,
      -0.005997803993523121,
      -0.019832683727145195,
      0.09562505036592484,
      0.017470819875597954,
      0.03931024298071861,
      0.08654819428920746,
      0.03245220333337784,
      0.00033405813155695796,
      -0.0575113520026207,
      0.12612974643707275,
      -0.04187299311161041,
      -0.020704511553049088,
      0.08327172696590424,
      -0.030831383541226387,
      -0.04092887416481972,
      0.05664505809545517,
      0.009118705056607723,
      0.02980176918208599,
      -0.03216846287250519,
      0.01965101808309555,
      0.011112517677247524,
      0.05906292423605919,
      0.01124729122966528,
      0.009374807588756084,
      0.10743484646081924,
      -0.03771774470806122,
      0.026189900934696198,
      -0.05856974050402641,
      0.02074875868856907,
      0.006944174412637949,
      -0.06012331694364548,
      0.0044739730656147,
      -0.03614235669374466,
      0.0825575739145279,
      0.018954148516058922,
      0.02207784354686737,
      -0.04190569370985031,
      0.02603575401008129,
      0.04882759228348732,
      0.03276175633072853,
      0.049604278057813644,
      -0.01185278594493866,
      -0.0407879501581192,
      -0.02075081504881382,
      0.030530670657753944,
      0.04485853388905525,
      -0.026420176029205322,
      -0.0577489398419857,
      0.022661032155156136
    ],
    [
      -0.019491462036967278,
      -0.02682466059923172,
      -0.005726881790906191,
      0.0016886264784261584,
      0.050942711532115936,
      0.030266359448432922,
      -0.08878526836633682,
      0.08609054982662201,
      0.059031616896390915,
      0.05862386152148247,
      0.003811572678387165,
      -0.00634006317704916,
      0.06727337837219238,
      0.048787761479616165,
      -0.029483530670404434,
      -0.004581569693982601,
      0.030978716909885406,
      0.06772305816411972,
      -0.03106221742928028,
      0.04532037675380707,
      0.046584948897361755,
      0.035902947187423706,
      0.07355891913175583,
      0.03431723266839981,
      0.03973649442195892,
      0.03868117183446884,
      0.041752997785806656,
      -0.06569027900695801,
      -0.0698111355304718,
      0.08580312877893448,
      -0.07973388582468033,
      0.05994364619255066,
      0.010490751825273037,
      -0.026867374777793884,
      -0.03777184337377548,
      -0.004081350285559893,
      0.06653902679681778,
      0.03905550763010979,
      -0.10176385194063187,
      0.04059205204248428,
      0.0018820364493876696,
      -0.021558387205004692,
      -0.09244702756404877,
      -0.05727384611964226,
      -0.019013868644833565,
      -0.06614691764116287,
      -0.04545798897743225,
      0.0017858067294582725,
      -0.07349289953708649,
      0.11996510624885559,
      -0.03276776522397995,
      -0.026798661798238754,
      -0.028358835726976395,
      0.0022462918423116207,
      0.011083928868174553,
      -0.05599338933825493,
      -0.05146801099181175,
      -0.026283130049705505,
      0.052134737372398376,
      0.02381741814315319,
      -0.06434129178524017,
      0.0024838242679834366,
      0.05207176133990288,
      -0.059190068393945694,
      0.07247642427682877,
      0.04573017358779907,
      0.023868059739470482,
      -0.002233468694612384,
      -0.018504351377487183,
      -0.0912579894065857,
      -0.009849593043327332,
      -0.07189469039440155,
      0.06999526917934418,
      0.03312290087342262,
      0.0045123654417693615,
      0.03274032846093178,
      0.07614411413669586,
      0.02382812090218067,
      0.006822183728218079,
      -0.12717637419700623,
      -0.013771407306194305,
      0.11216003447771072,
      0.0055956426076591015,
      0.02752726338803768,
      -0.006791730411350727,
      0.002384791849181056,
      0.04126001521945,
      0.09601245820522308,
      -0.046514399349689484,
      0.004599441308528185,
      0.010327166877686977,
      -0.021038737148046494,
      -0.03570256754755974,
      0.057281360030174255,
      0.05844056233763695,
      -0.004741843789815903,
      -0.014068721793591976,
      0.031897395849227905,
      -0.010740523226559162,
      -0.13850565254688263,
      -0.04614197462797165,
      0.00124854885507375,
      -0.005338919349014759,
      0.07837937772274017,
      -0.014204242266714573,
      0.009813482873141766,
      -0.02430804818868637,
      -0.07070334255695343,
      -0.06640776991844177,
      -0.003036607289686799,
      0.005453657358884811,
      0.06335285305976868,
      -0.014510070905089378,
      0.03458208963274956,
      0.07870674878358841,
      0.009148701094090939,
      0.03823858126997948,
      0.03944437578320503,
      -0.006584957707673311,
      0.00820304173976183,
      0.01742658205330372,
      -0.007872896268963814,
      0.07614797353744507,
      -0.06041666865348816,
      -0.005968728102743626,
      -0.02906697615981102,
      0.013686313293874264,
      6.535185087967493e-33,
      -0.017742441967129707,
      -0.014526057057082653,
      -0.003971446305513382,
      0.07121151685714722,
      -0.051086049526929855,
      0.05536230280995369,
      -0.03929617628455162,
      0.09840955585241318,
      0.04236297681927681,
      -0.005961154121905565,
      -0.06253152340650558,
      -0.03548272326588631,
      -0.00433315010741353,
      -0.02827722206711769,
      -0.015515544451773167,
      0.07918194681406021,
      0.006024188827723265,
      -0.06851737201213837,
      -0.020862694829702377,
      0.01651095785200596,
      -0.00815851055085659,
      0.008501602336764336,
      0.09578293561935425,
      0.05952499061822891,
      -0.02580568566918373,
      0.011980118229985237,
      0.0002802294911816716,
      0.06091267243027687,
      -0.019100425764918327,
      -0.008889232762157917,
      -0.041522324085235596,
      -0.10850020498037338,
      0.02895997278392315,
      -0.0802086740732193,
      0.0345110259950161,
      -0.007065795361995697,
      0.039701711386442184,
      0.05129074305295944,
      -0.08320806920528412,
      0.029039185494184494,
      -0.0815814957022667,
      0.0029513323679566383,
      -0.04984916374087334,
      -0.0312877781689167,
      0.031029189005494118,
      -0.021926727145910263,
      0.0028021428734064102,
      -0.02717399038374424,
      0.008289135992527008,
      0.0024665272794663906,
      -0.020634502172470093,
      0.019860368221998215,
      -0.04864906892180443,
      -0.06632038950920105,
      -0.08303551375865936,
      0.01847825199365616,
      -0.03443023934960365,
      -0.027249587699770927,
      -0.12095563858747482,
      0.05746298283338547,
      -0.018053622916340828,
      -0.012650374323129654,
      0.022479461506009102,
      -0.060726337134838104,
      -0.054074667394161224,
      -0.0016682434361428022,
      -0.008509627543389797,
      -0.028475940227508545,
      -0.005358083173632622,
      -0.09544390439987183,
      0.07868766039609909,
      -0.06842897087335587,
      0.0705542042851448,
      0.0241587832570076,
      0.03361817076802254,
      0.0019435336580500007,
      0.052594397217035294,
      0.0628696084022522,
      -0.03702440857887268,
      -0.09844055026769638,
      -0.010595269501209259,
      0.06410905718803406,
      0.0066162594594061375,
      -0.014771283604204655,
      -0.02889280393719673,
      -0.027086833491921425,
      0.03388611227273941,
      0.06630339473485947,
      -0.10743188112974167,
      -0.07500452548265457,
      -0.0015363928396254778,
      -0.05685550719499588,
      0.03057737462222576,
      0.013432174921035767,
      0.007859313860535622,
      -8.771579253454219e-33,
      -0.040060706436634064,
      -0.031321264803409576,
      0.0024774810299277306,
      -0.09018471091985703,
      0.040367335081100464,
      0.0014582581352442503,
      0.05085424333810806,
      -0.021445203572511673,
      -0.012289469130337238,
      -0.11716897785663605,
      0.041162047535181046,
      -0.0399041473865509,
      -0.031827230006456375,
      -0.06411538273096085,
      0.0022085667587816715,
      0.1036936491727829,
      -0.08521389216184616,
      0.015510296449065208,
      -0.04921407252550125,
      0.06782522052526474,
      0.019380958750844002,
      -0.05331018567085266,
      -0.04724433273077011,
      -0.044459860771894455,
      0.09103074669837952,
      0.07901277393102646,
      0.04815525561571121,
      0.07939112931489944,
      0.003971127327531576,
      0.024320587515830994,
      0.05233093723654747,
      0.07154563069343567,
      -0.05953628569841385,
      0.02261476032435894,
      0.033128660172224045,
      0.008777589537203312,
      -0.0237430427223444,
      -0.0006842822767794132,
      -0.059871431440114975,
      -0.05354107916355133,
      0.007058813702315092,
      0.030113687738776207,
      0.027602113783359528,
      -0.0256193857640028,
      0.011581378057599068,
      0.10543548315763474,
      0.04914082959294319,
      -0.04492868110537529,
      0.016306225210428238,
      0.02464849315583706,
      0.0910058319568634,
      0.05379732698202133,
      -0.05110328271985054,
      0.076924629509449,
      -0.02095322497189045,
      0.01824035309255123,
      0.03158780559897423,
      0.06597647815942764,
      -0.007524949964135885,
      0.014722066931426525,
      0.06335125863552094,
      -0.04897703975439072,
      -0.03176288679242134,
      -0.061616040766239166,
      0.07512050122022629,
      -0.04127897322177887,
      0.0000669743021717295,
      -0.03990839421749115,
      0.061509475111961365,
      -0.0019547538831830025,
      -0.008992581628262997,
      -0.08003094047307968,
      0.00855071097612381,
      -0.04574856534600258,
      -0.033805686980485916,
      -0.05576549470424652,
      -0.026325739920139313,
      -0.016631443053483963,
      -0.0257282592356205,
      0.004500276874750853,
      -0.043836984783411026,
      -0.09786861389875412,
      -0.01605493389070034,
      0.0019392630783841014,
      -0.05905812233686447,
      -0.14689910411834717,
      0.05309551581740379,
      -0.040637947618961334,
      0.04341914504766464,
      0.021145816892385483,
      -0.06964225322008133,
      0.026222551241517067,
      -0.1700831949710846,
      -0.01693623512983322,
      0.052926205098629,
      -6.361484139461027e-8,
      0.1416962742805481,
      -0.044740259647369385,
      -0.004977610893547535,
      0.02141374535858631,
      0.04269208386540413,
      -0.07724279910326004,
      -0.039779357612133026,
      0.0653047040104866,
      0.02689751237630844,
      0.1076812744140625,
      0.005995412822812796,
      0.046029724180698395,
      -0.0069938478991389275,
      -0.006384655367583036,
      -0.010097630321979523,
      -0.05375317856669426,
      -0.04352123662829399,
      0.08077099174261093,
      0.017542704939842224,
      0.036692798137664795,
      0.04894958809018135,
      0.012048404663801193,
      -0.10090569406747818,
      -0.09032601863145828,
      0.02591230720281601,
      -0.07825516909360886,
      0.01001768745481968,
      0.002390411449596286,
      0.03516586869955063,
      -0.10575062781572342,
      0.07913114875555038,
      -0.02149774320423603,
      0.019641883671283722,
      -0.04171520471572876,
      -0.006018745247274637,
      -0.06677158921957016,
      0.022739777341485023,
      0.046285368502140045,
      -0.05735434964299202,
      0.11252205818891525,
      -0.009884626604616642,
      -0.03684739023447037,
      -0.0587025061249733,
      0.021110301837325096,
      0.07251764088869095,
      -0.038030900061130524,
      -0.011226286180317402,
      0.04710644483566284,
      0.03472005948424339,
      0.03206317499279976,
      -0.060246434062719345,
      -0.051611464470624924,
      0.02101469784975052,
      -0.07823244482278824,
      -0.03676954656839371,
      0.05357872694730759,
      -0.001154717174358666,
      -0.033392105251550674,
      0.0008145564352162182,
      -0.052660200744867325,
      -0.0187664981931448,
      -0.031048782169818878,
      -0.007516914512962103,
      -0.021854689344763756
    ],
    [
      -0.010708766989409924,
      0.04504923149943352,
      -0.005727467127144337,
      0.04570191353559494,
      0.02299998328089714,
      0.07366620004177094,
      -0.026386963203549385,
      0.029288560152053833,
      0.07948072999715805,
      0.061747223138809204,
      -0.0030292081646621227,
      -0.009478949941694736,
      0.034133490175008774,
      0.03830587491393089,
      -0.022867247462272644,
      0.035369616001844406,
      0.06518539786338806,
      0.033152561634778976,
      -0.020696744322776794,
      0.025351060554385185,
      0.058516278862953186,
      0.012027755379676819,
      0.12310367077589035,
      -0.005546586588025093,
      0.0022164620459079742,
      0.06566385179758072,
      0.03445291891694069,
      -0.08529657870531082,
      -0.04915269836783409,
      0.013298655860126019,
      0.016716770827770233,
      0.022976594045758247,
      -0.006831374950706959,
      -0.06616964191198349,
      -0.0049851564690470695,
      0.006435333751142025,
      0.07017294317483902,
      0.0616464763879776,
      -0.07744969427585602,
      -0.006604647263884544,
      -0.029284806922078133,
      0.01299036294221878,
      -0.04136680066585541,
      -0.10402552783489227,
      -0.07875780761241913,
      -0.044242966920137405,
      0.00205601891502738,
      -0.040953248739242554,
      -0.09498578310012817,
      -0.023256225511431694,
      -0.03712688013911247,
      -0.0049794623628258705,
      0.010392692871391773,
      0.040015630424022675,
      0.0020537865348160267,
      -0.0050313882529735565,
      0.004089879337698221,
      0.030830612406134605,
      0.07531401515007019,
      0.074839286506176,
      -0.024767713621258736,
      0.030533354729413986,
      0.022093582898378372,
      0.006308818235993385,
      0.03398580104112625,
      0.10630529373884201,
      -0.06921014189720154,
      -0.026167025789618492,
      -0.04114830121397972,
      -0.07751069217920303,
      -0.051389530301094055,
      -0.022913480177521706,
      0.0504138320684433,
      0.018897196277976036,
      0.014373833313584328,
      0.07998331636190414,
      0.12824982404708862,
      0.04340873658657074,
      0.10741206258535385,
      -0.14011983573436737,
      -0.020726924762129784,
      0.0856710895895958,
      0.004808479454368353,
      -0.06960204988718033,
      -0.047652967274188995,
      0.013308408670127392,
      0.07985875755548477,
      0.05785488337278366,
      0.005222967825829983,
      -0.011244614608585835,
      0.036159347742795944,
      -0.0311137568205595,
      -0.054422855377197266,
      -0.0051110778003931046,
      0.08164326101541519,
      -0.013068117201328278,
      -0.03329697251319885,
      0.053147509694099426,
      -0.053061455488204956,
      -0.10878822207450867,
      0.07299443334341049,
      0.045606210827827454,
      0.016006004065275192,
      0.04063517600297928,
      0.024718642234802246,
      0.002949453191831708,
      0.00043838442070409656,
      -0.10124114155769348,
      -0.043852515518665314,
      -0.048056915402412415,
      -0.13454942405223846,
      -0.007720577996224165,
      -0.029492730274796486,
      -0.0020151338540017605,
      0.03389173746109009,
      -0.015490773133933544,
      -0.013367894105613232,
      0.014180311933159828,
      0.0395672544836998,
      -0.03606117516756058,
      0.11265724897384644,
      -0.010632911697030067,
      0.06653767079114914,
      -0.07524234056472778,
      0.05415080487728119,
      -0.06678085774183273,
      -0.11969907581806183,
      8.098815918487792e-33,
      -0.04682239517569542,
      -0.04316065460443497,
      -0.036199286580085754,
      0.05211515352129936,
      -0.018348684534430504,
      -0.03209393844008446,
      0.04505200311541557,
      0.024481307715177536,
      -0.0035394812002778053,
      0.03571006655693054,
      -0.10852102935314178,
      -0.025396248325705528,
      0.02184031903743744,
      0.017370106652379036,
      0.007526386063545942,
      0.06836678087711334,
      -0.10418454557657242,
      -0.01628125086426735,
      -0.024124421179294586,
      -0.014441629871726036,
      -0.051164284348487854,
      0.024366097524762154,
      0.1298656165599823,
      0.10226897895336151,
      -0.0034190069418400526,
      -0.016702920198440552,
      -0.059553325176239014,
      -0.025356804952025414,
      -0.0034805061295628548,
      0.01434286404401064,
      0.011207664385437965,
      0.007807580754160881,
      0.0012808352475985885,
      -0.0435083732008934,
      -0.03113853931427002,
      0.015256932005286217,
      0.0710875615477562,
      0.0026962219271808863,
      -0.043014708906412125,
      -0.017306938767433167,
      -0.03926674649119377,
      0.016366995871067047,
      -0.01781010441482067,
      0.03577633202075958,
      0.013286983594298363,
      -0.04461989551782608,
      -0.004640605766326189,
      -0.022025112062692642,
      0.016541019082069397,
      -0.013598612509667873,
      0.0399857722222805,
      0.011130282655358315,
      -0.054375920444726944,
      -0.11161640286445618,
      -0.05612288415431976,
      0.07852990180253983,
      0.013995902612805367,
      0.05886847898364067,
      -0.052073411643505096,
      -0.04902168735861778,
      0.030775491148233414,
      -0.012897190637886524,
      -0.01613570749759674,
      -0.07214359194040298,
      0.00866248644888401,
      0.008011429570615292,
      0.05154632404446602,
      0.020829347893595695,
      -0.014743817038834095,
      -0.11733192205429077,
      0.04665980488061905,
      -0.0600777268409729,
      0.0047484808601439,
      0.0417342372238636,
      0.05905379354953766,
      -0.04280185326933861,
      0.054072875529527664,
      -0.029903704300522804,
      -0.01677584834396839,
      -0.08957792818546295,
      0.006512012332677841,
      -0.02217213436961174,
      -0.008663490414619446,
      -0.053086474537849426,
      -0.07022539526224136,
      -0.10963920503854752,
      -0.0028820065781474113,
      0.012149187736213207,
      -0.07865796983242035,
      0.02245219051837921,
      -0.02742875926196575,
      0.004852197133004665,
      0.07485099881887436,
      0.045405276119709015,
      -0.021494358777999878,
      -1.0489700898399275e-32,
      -0.0036868818569928408,
      -0.018085146322846413,
      -0.016941582784056664,
      -0.09147923439741135,
      -0.02949163317680359,
      -0.016383333131670952,
      -0.030560459941625595,
      -0.12204895168542862,
      -0.005279550328850746,
      -0.10695096850395203,
      -0.003207565750926733,
      -0.06317535042762756,
      0.026410022750496864,
      -0.08932912349700928,
      0.04453357309103012,
      -0.014505107887089252,
      0.017242589965462685,
      0.06875886768102646,
      -0.02023208513855934,
      0.0181535966694355,
      0.023435188457369804,
      -0.004117196891456842,
      -0.09265772998332977,
      -0.06285861879587173,
      0.018225669860839844,
      0.05895095691084862,
      0.021946553140878677,
      0.0607331357896328,
      0.020932022482156754,
      -0.03352294862270355,
      -0.002901683561503887,
      0.020793940871953964,
      -0.0058286841958761215,
      0.04427272081375122,
      0.009205766953527927,
      -0.033965639770030975,
      -0.0049257706850767136,
      -0.0034959728363901377,
      -0.0533817820250988,
      -0.10667862743139267,
      0.01458126399666071,
      0.05404537171125412,
      0.014094097539782524,
      0.0015463002491742373,
      0.021768590435385704,
      0.018473375588655472,
      -0.02041287161409855,
      -0.04897433891892433,
      -0.003854810493066907,
      -0.0076515269465744495,
      0.09000155329704285,
      0.04373863339424133,
      -0.09110716730356216,
      -0.010522610507905483,
      -0.035522494465112686,
      0.05306525528430939,
      0.1042129248380661,
      0.010786877013742924,
      -0.03546195477247238,
      0.026962177827954292,
      0.05537137761712074,
      0.053433578461408615,
      -0.06280510872602463,
      -0.0028004373889416456,
      0.09012752026319504,
      0.014852938242256641,
      -0.11269515752792358,
      -0.07727008312940598,
      0.0618242509663105,
      -0.024421826004981995,
      -0.016194486990571022,
      -0.0210728757083416,
      -0.012533577159047127,
      -0.09988167881965637,
      0.006591983139514923,
      0.002410725224763155,
      -0.047916900366544724,
      -0.006571554578840733,
      -0.05443911999464035,
      0.026811590418219566,
      -0.015403812751173973,
      -0.057332951575517654,
      0.053450483828783035,
      -0.01623382978141308,
      -0.09220179170370102,
      -0.05455509573221207,
      0.021868480369448662,
      -0.027997400611639023,
      0.08686897903680801,
      -0.048843152821063995,
      -0.022695982828736305,
      0.03707710653543472,
      -0.10464094579219818,
      0.0025782689917832613,
      -0.0005851995665580034,
      -6.83318788219367e-8,
      0.13129572570323944,
      0.012399069964885712,
      0.07049128413200378,
      0.023961130529642105,
      0.025550656020641327,
      -0.04786664620041847,
      0.017338328063488007,
      0.025807397440075874,
      -0.08222732692956924,
      0.09083365648984909,
      -0.04445241764187813,
      0.033580243587493896,
      0.03170151263475418,
      -0.03507089242339134,
      0.06489934772253036,
      -0.12167686223983765,
      0.015928246080875397,
      -0.022744616493582726,
      0.008803251199424267,
      0.01503800880163908,
      0.063297338783741,
      0.022931402549147606,
      -0.036761295050382614,
      -0.08039624243974686,
      0.04083221033215523,
      -0.06334968656301498,
      -0.004731760825961828,
      -0.018922654911875725,
      -0.04556780681014061,
      -0.045914698392152786,
      0.0757046565413475,
      0.023798175156116486,
      0.0014204359613358974,
      -0.059225331991910934,
      0.027362806722521782,
      -0.11457889527082443,
      0.02310549095273018,
      0.054001711308956146,
      -0.05634770914912224,
      0.10423246026039124,
      0.04060899838805199,
      0.049745745956897736,
      0.04152943193912506,
      -0.002197815105319023,
      0.012690938077867031,
      0.017499621957540512,
      -0.03401409462094307,
      -0.05249372124671936,
      0.012074591591954231,
      0.053261447697877884,
      -0.018577629700303078,
      0.006319032516330481,
      -0.00901095476001501,
      -0.05761140212416649,
      -0.004544517491012812,
      0.05062117055058479,
      0.06644422560930252,
      0.011441580019891262,
      -0.0272616408765316,
      -0.061981286853551865,
      0.07956500351428986,
      0.04820110648870468,
      0.008779517374932766,
      0.027480775490403175
    ],
    [
      -0.021364498883485794,
      -0.11718352138996124,
      0.04862551763653755,
      0.06699716299772263,
      0.057726021856069565,
      0.05493989586830139,
      0.001011074404232204,
      -0.06197643280029297,
      0.06642911583185196,
      -0.024832865223288536,
      -0.09403472393751144,
      -0.08098449558019638,
      0.05572483316063881,
      0.01318360585719347,
      -0.014532260596752167,
      0.0248557161539793,
      0.013626737520098686,
      0.08654442429542542,
      -0.05108864977955818,
      0.01851504296064377,
      0.10868802666664124,
      0.008408701978623867,
      0.04627394303679466,
      0.05419255048036575,
      -0.019277233630418777,
      -0.016374902799725533,
      0.0614362508058548,
      -0.061483122408390045,
      -0.041271064430475235,
      -0.06528729945421219,
      0.011246509850025177,
      0.017697082832455635,
      -0.010596230626106262,
      -0.05370105430483818,
      0.027778008952736855,
      -0.026246225461363792,
      -0.05742577090859413,
      -0.05650952085852623,
      -0.0013162418035790324,
      0.014056731015443802,
      0.07213988900184631,
      0.04688519611954689,
      0.00002673321432666853,
      -0.027512041851878166,
      -0.025574197992682457,
      0.008585421368479729,
      0.024496648460626602,
      -0.1586379110813141,
      -0.04994674026966095,
      0.05401790514588356,
      0.02482575550675392,
      -0.03645457699894905,
      -0.07563573867082596,
      0.01240549236536026,
      0.06282150000333786,
      0.04188815876841545,
      -0.02605142444372177,
      -0.004765452817082405,
      0.07217235118150711,
      -0.044435884803533554,
      -0.008475368842482567,
      0.035892415791749954,
      0.0017264840425923467,
      -0.06962382793426514,
      0.08821339160203934,
      0.03689514473080635,
      -0.08007431775331497,
      0.04019428417086601,
      0.014354986138641834,
      -0.0887262225151062,
      -0.06652916967868805,
      0.03090384230017662,
      -0.0016784019535407424,
      -0.019837941974401474,
      0.06116273254156113,
      0.06199732795357704,
      0.08321129530668259,
      0.06630649417638779,
      0.04484963044524193,
      -0.024160096421837807,
      -0.0010509882122278214,
      0.031594034284353256,
      0.007528709247708321,
      -0.08494914323091507,
      -0.00001357126166112721,
      -0.014614250510931015,
      0.0710376650094986,
      0.05706184357404709,
      0.020520461723208427,
      0.026102419942617416,
      -0.029283110052347183,
      -0.02632921375334263,
      -0.08357396721839905,
      0.03201805800199509,
      0.05575111135840416,
      0.001509849913418293,
      0.04216672480106354,
      0.05680759623646736,
      0.09357990324497223,
      -0.014620326459407806,
      0.05000247433781624,
      0.018053514882922173,
      0.002874972065910697,
      0.0171675868332386,
      0.05070829764008522,
      0.04937507584691048,
      0.05782591924071312,
      0.01907605677843094,
      -0.0522724874317646,
      0.010681835003197193,
      -0.04234212264418602,
      0.0019968883134424686,
      0.043208613991737366,
      0.03460042551159859,
      0.08558950573205948,
      0.033366404473781586,
      -0.0020339067559689283,
      0.050942812114953995,
      0.08146403729915619,
      -0.04234923794865608,
      0.05423577129840851,
      -0.06086720898747444,
      -0.003866155631840229,
      -0.1294718086719513,
      0.03756549581885338,
      -0.04650706797838211,
      -0.13517755270004272,
      5.000518070909471e-33,
      0.0013113250024616718,
      -0.007059953175485134,
      -0.0454612597823143,
      -0.004760566167533398,
      0.06537248194217682,
      -0.12403259426355362,
      -0.09824690222740173,
      -0.03612605109810829,
      -0.005128832999616861,
      0.05769088491797447,
      -0.09606415778398514,
      0.03808043524622917,
      -0.01695464551448822,
      -0.025865444913506508,
      0.026065370067954063,
      0.011112941429018974,
      -0.021022897213697433,
      -0.01452784612774849,
      0.05808958783745766,
      -0.07368826121091843,
      -0.017613064497709274,
      0.05026663839817047,
      0.03910757973790169,
      0.03170662373304367,
      -0.04304344207048416,
      -0.0034996401518583298,
      -0.005773007869720459,
      -0.014240973629057407,
      -0.08147893100976944,
      0.03285954147577286,
      -0.0017937002703547478,
      0.026607414707541466,
      0.027578169479966164,
      0.0206757765263319,
      0.04834188520908356,
      -0.015100034885108471,
      0.07819880545139313,
      0.04516523331403732,
      -0.036400049924850464,
      -0.0867256224155426,
      -0.023011982440948486,
      0.05690685287117958,
      -0.03417310491204262,
      -0.009796530939638615,
      0.03589702025055885,
      -0.00950545258820057,
      0.01038387231528759,
      0.0839770957827568,
      0.05115135759115219,
      -0.011304333806037903,
      -0.005559013225138187,
      -0.07859767228364944,
      -0.011816265992820263,
      0.009023868478834629,
      -0.062104932963848114,
      -0.01881122589111328,
      -0.010034102015197277,
      -0.02530345506966114,
      -0.028754353523254395,
      0.07201828807592392,
      -0.027735518291592598,
      -0.010407179594039917,
      0.05754539370536804,
      0.008271066471934319,
      0.13797830045223236,
      0.07170804589986801,
      -0.07741603255271912,
      -0.059900589287281036,
      -0.025030745193362236,
      -0.05274103209376335,
      0.07679851353168488,
      0.025519441813230515,
      0.05467402935028076,
      -0.022305067628622055,
      0.0065236338414251804,
      -0.03487571328878403,
      -0.015045884996652603,
      0.01338079571723938,
      -0.13289959728717804,
      -0.03385169431567192,
      0.002808778313919902,
      -0.004133609589189291,
      -0.09051641076803207,
      -0.04037478566169739,
      -0.04585442319512367,
      0.0395338237285614,
      0.06890691816806793,
      0.047632478177547455,
      -0.09052246809005737,
      0.023288575932383537,
      0.016558239236474037,
      -0.07293333113193512,
      0.09362683445215225,
      -0.027557238936424255,
      -0.046483393758535385,
      -5.1888631226379106e-33,
      -0.030927766114473343,
      -0.0535147562623024,
      -0.04748266190290451,
      -0.04179883003234863,
      -0.002271434525027871,
      0.07029414176940918,
      0.007467696443200111,
      0.009017388336360455,
      -0.08643052726984024,
      -0.017998984083533287,
      0.0448625348508358,
      -0.031700871884822845,
      -0.008318985812366009,
      0.03323801979422569,
      0.003579086856916547,
      -0.10242491960525513,
      -0.009362134151160717,
      0.003226391738280654,
      0.01693541184067726,
      0.0617981031537056,
      -0.05418892949819565,
      0.02476559393107891,
      -0.060988400131464005,
      -0.078123077750206,
      0.06989721953868866,
      0.0643596276640892,
      -0.07990776002407074,
      0.18700547516345978,
      0.05794887617230415,
      0.05532710999250412,
      -0.08602920919656754,
      0.02464613877236843,
      -0.10620654374361038,
      -0.048623718321323395,
      0.012519917450845242,
      0.03196779265999794,
      0.03707634657621384,
      0.017284289002418518,
      0.007324171252548695,
      -0.04346538335084915,
      0.0699240043759346,
      0.002960075857117772,
      0.031077291816473007,
      -0.06231513246893883,
      0.09447187930345535,
      0.03706751763820648,
      -0.04092378541827202,
      -0.009903009049594402,
      -0.01121939904987812,
      -0.013701952062547207,
      0.059720661491155624,
      0.004307237919420004,
      0.00492788664996624,
      0.0031004457268863916,
      -0.0520012266933918,
      0.06177467480301857,
      0.05873788520693779,
      -0.014599784277379513,
      0.042097169905900955,
      -0.01458349172025919,
      -0.05875519663095474,
      -0.00791286863386631,
      -0.03703104332089424,
      -0.07732145488262177,
      0.03348477557301521,
      0.04498005285859108,
      -0.03926479443907738,
      -0.038594771176576614,
      0.09019044041633606,
      0.025265788659453392,
      -0.012584013864398003,
      -0.020602822303771973,
      0.06727162003517151,
      0.04373588413000107,
      0.0041119251400232315,
      -0.007670378312468529,
      -0.02788185514509678,
      -0.025228288024663925,
      -0.009219375438988209,
      0.013078281655907631,
      -0.03387926518917084,
      -0.07136344164609909,
      0.004211035091429949,
      -0.0498691089451313,
      -0.02632194198668003,
      -0.06906908750534058,
      -0.0006817911635152996,
      0.004517708905041218,
      0.07300324738025665,
      -0.05179283022880554,
      -0.006942613050341606,
      -0.01791471429169178,
      -0.05941758677363396,
      -0.0348346121609211,
      -0.01919727958738804,
      -5.411961012669053e-8,
      0.01733124814927578,
      -0.03871303051710129,
      -0.004256761632859707,
      0.03988233581185341,
      0.001251950510777533,
      0.012193463742733002,
      0.10143157839775085,
      -0.06562141329050064,
      -0.04052333906292915,
      0.08491664379835129,
      0.13168500363826752,
      -0.025028064846992493,
      0.07649275660514832,
      -0.06225129961967468,
      -0.006373938173055649,
      0.0780065506696701,
      -0.046252720057964325,
      0.08636865019798279,
      -0.0038890596479177475,
      -0.09317382425069809,
      0.012793070636689663,
      -0.019606249406933784,
      -0.07286357879638672,
      -0.03103073313832283,
      0.06201617047190666,
      -0.04273931682109833,
      -0.029482685029506683,
      0.04205697774887085,
      -0.04619831219315529,
      -0.03146563097834587,
      0.08453590422868729,
      -0.010140656493604183,
      0.006794148124754429,
      -0.029831020161509514,
      -0.07495442032814026,
      -0.014706891030073166,
      0.03211341053247452,
      -0.03541804477572441,
      0.03431513532996178,
      0.07332630455493927,
      -0.041714198887348175,
      0.009080247953534126,
      -0.10506590455770493,
      -0.032824475318193436,
      -0.008947622030973434,
      -0.00043125220690853894,
      0.06164390966296196,
      -0.07925303280353546,
      0.013292939402163029,
      0.042717404663562775,
      -0.04751046746969223,
      0.008947057649493217,
      0.009264948777854443,
      -0.0659887045621872,
      -0.028849337249994278,
      -0.022863198071718216,
      0.021741477772593498,
      -0.0028534019365906715,
      -0.0024324245750904083,
      -0.0054754335433244705,
      0.007125892676413059,
      0.049478888511657715,
      -0.011177880689501762,
      -0.030664434656500816
    ],
    [
      -0.05823478102684021,
      -0.008080312050879002,
      -0.004293746314942837,
      0.08301806449890137,
      0.018774231895804405,
      -0.04846293106675148,
      0.03705940023064613,
      0.004637034144252539,
      0.02851065620779991,
      0.008046308532357216,
      -0.0928749367594719,
      -0.07952460646629333,
      0.04751414433121681,
      0.03114551305770874,
      0.04491673409938812,
      -0.012923356145620346,
      0.11556536704301834,
      0.049184128642082214,
      -0.11316540837287903,
      -0.03214351460337639,
      0.058195412158966064,
      -0.007730682380497456,
      0.05081337317824364,
      0.00037301023257896304,
      0.0015037893317639828,
      -0.03373783826828003,
      0.001371579710394144,
      -0.09641857445240021,
      -0.015781013295054436,
      0.007173236925154924,
      0.00023362814681604505,
      0.0975276529788971,
      -0.03794772922992706,
      0.029402511194348335,
      -0.037653978914022446,
      -0.0035131475888192654,
      -0.03302004933357239,
      -0.006933882832527161,
      0.005262944847345352,
      -0.04205836355686188,
      -0.008532685227692127,
      -0.04089884087443352,
      -0.006929412949830294,
      -0.03472934290766716,
      0.00045683945063501596,
      -0.04131031781435013,
      0.004153722897171974,
      -0.0017656175186857581,
      -0.016836808994412422,
      0.03641100972890854,
      -0.11216841638088226,
      -0.0464433990418911,
      -0.0602782666683197,
      0.005243445746600628,
      -0.02264983579516411,
      0.038977742195129395,
      0.0578303337097168,
      0.05412618815898895,
      0.0029060340020805597,
      0.00386093114502728,
      -0.07127959281206131,
      -0.08867410570383072,
      -0.0013741633156314492,
      0.004049133509397507,
      0.029879532754421234,
      0.02698247879743576,
      0.006534004118293524,
      -0.03923245146870613,
      0.022773828357458115,
      0.016658931970596313,
      -0.037102263420820236,
      0.05363466218113899,
      -0.08024749159812927,
      0.0002463077544234693,
      -0.06308115273714066,
      0.041795022785663605,
      0.04747806489467621,
      -0.010478533804416656,
      0.10493156313896179,
      -0.033356521278619766,
      0.012338779866695404,
      0.006789456587284803,
      -0.021583184599876404,
      -0.005527057684957981,
      0.05745229497551918,
      -0.0020221106242388487,
      0.09960578382015228,
      0.06256474554538727,
      0.0438556931912899,
      -0.04011353477835655,
      0.06232912093400955,
      0.005220305640250444,
      -0.02140215039253235,
      0.014121906831860542,
      0.04727672412991524,
      0.020321214571595192,
      0.03071308694779873,
      0.0033994049299508333,
      -0.022213725373148918,
      0.07869234681129456,
      0.020924709737300873,
      0.09394456446170807,
      0.07016777992248535,
      -0.06674638390541077,
      -0.0337916724383831,
      0.03462532162666321,
      0.038237541913986206,
      0.018451126292347908,
      -0.003070729086175561,
      -0.07181983441114426,
      -0.009752449579536915,
      0.08705811947584152,
      0.029311789199709892,
      0.0056726448237895966,
      -0.00789550133049488,
      0.04339970648288727,
      0.059970956295728683,
      -0.02753942646086216,
      0.07158754765987396,
      0.07782549411058426,
      0.058124251663684845,
      0.046387821435928345,
      0.04222656041383743,
      -0.11276772618293762,
      0.06619930267333984,
      -0.0107662882655859,
      -0.06297098845243454,
      7.016941611184838e-33,
      0.026829421520233154,
      0.0024108446668833494,
      0.005608110688626766,
      -0.03326881304383278,
      0.011287613771855831,
      -0.024264132604002953,
      0.038514643907547,
      0.09227944165468216,
      -0.04062776267528534,
      -0.0261450856924057,
      -0.007616827264428139,
      0.05046232417225838,
      -0.03172441944479942,
      0.007664985954761505,
      0.08722817897796631,
      0.010809137485921383,
      -0.036293331533670425,
      0.025754062458872795,
      -0.027467189356684685,
      -0.04255980998277664,
      0.0806504487991333,
      -0.08576302230358124,
      0.025860203430056572,
      0.0046358914114534855,
      0.03218685835599899,
      0.0006596384919248521,
      0.04560615494847298,
      -0.07394035160541534,
      -0.001193545525893569,
      0.01620654948055744,
      -0.0644601434469223,
      -0.013545875437557697,
      -0.11052767187356949,
      0.05662688985466957,
      0.043661944568157196,
      -0.048799362033605576,
      0.010595454834401608,
      -0.08168074488639832,
      0.016803616657853127,
      -0.04133315756917,
      -0.07665599137544632,
      0.05056021362543106,
      0.05391903221607208,
      -0.008157717064023018,
      -0.08977290987968445,
      -0.08447239547967911,
      -0.021699916571378708,
      -0.0037432280369102955,
      0.0016263227444142103,
      -0.006830218248069286,
      0.07133449614048004,
      0.016140107065439224,
      -0.018610093742609024,
      -0.05399365723133087,
      -0.05620343238115311,
      -0.002057645469903946,
      0.0382874459028244,
      0.026379697024822235,
      -0.006309411488473415,
      0.12749628722667694,
      -0.010995954275131226,
      -0.042932312935590744,
      0.014044555835425854,
      0.018946798518300056,
      -0.009951747953891754,
      0.03054101951420307,
      -0.09668028354644775,
      0.05862656608223915,
      0.10948172956705093,
      -0.028082776814699173,
      0.037251219153404236,
      -0.024285485967993736,
      0.07092027366161346,
      -0.013173511251807213,
      0.05455682799220085,
      -0.02631889469921589,
      0.09305419772863388,
      -0.05847197026014328,
      -0.03133143484592438,
      -0.018507912755012512,
      0.06317102909088135,
      -0.005862125661224127,
      -0.02814088948071003,
      -0.06234053522348404,
      -0.005925947800278664,
      -0.079343281686306,
      0.01719248853623867,
      -0.044262032955884933,
      -0.09889104962348938,
      -0.04818949103355408,
      -0.08055533468723297,
      0.0038322992622852325,
      0.0375652052462101,
      -0.01721813902258873,
      -0.05212175101041794,
      -5.157119265035939e-33,
      -0.046459097415208817,
      -0.14359119534492493,
      -0.007674569264054298,
      0.14541268348693848,
      0.060604218393564224,
      -0.09733344614505768,
      0.03595740348100662,
      -0.09082364290952682,
      -0.0865287035703659,
      -0.06965412199497223,
      -0.07703426480293274,
      -0.010265721008181572,
      0.06492908298969269,
      0.00015472079394385219,
      0.07930294424295425,
      -0.025131061673164368,
      0.02358553744852543,
      -0.04647118225693703,
      -0.02344822697341442,
      0.12919747829437256,
      0.021885331720113754,
      0.12808109819889069,
      -0.09845703840255737,
      -0.0635354220867157,
      -0.019752684980630875,
      0.017497828230261803,
      -0.043675731867551804,
      0.07566025853157043,
      0.0096909049898386,
      -0.020337706431746483,
      -0.029727386310696602,
      -0.06494663655757904,
      -0.09593646973371506,
      -0.04458603635430336,
      0.0006363748689182103,
      0.022849872708320618,
      0.07034868746995926,
      -0.008685128763318062,
      -0.02198314666748047,
      0.03784385696053505,
      0.12442351132631302,
      -0.0309345331043005,
      -0.017655624076724052,
      -0.0381975881755352,
      0.03178337216377258,
      0.11678671836853027,
      -0.10316845774650574,
      -0.026941154152154922,
      -0.033948689699172974,
      0.012315142899751663,
      0.013386694714426994,
      0.010993740521371365,
      -0.025445574894547462,
      0.024853408336639404,
      -0.008541221730411053,
      -0.07683389633893967,
      -0.04455365985631943,
      -0.08105672895908356,
      -0.0526295006275177,
      -0.01272913720458746,
      -0.044054243713617325,
      0.008489325642585754,
      0.08183329552412033,
      -0.03269876539707184,
      0.08477619290351868,
      -0.00730383163318038,
      0.014569547027349472,
      -0.08542315661907196,
      0.011506144888699055,
      -0.023330267518758774,
      -0.008809094317257404,
      -0.023993950337171555,
      -0.002447964157909155,
      0.06709082424640656,
      0.01628553308546543,
      0.04340468347072601,
      0.013249785639345646,
      -0.046368081122636795,
      0.01504726056009531,
      -0.04549640044569969,
      -0.021559886634349823,
      0.0025038919411599636,
      -0.021315861493349075,
      -0.018047835677862167,
      -0.02784394472837448,
      0.05501040443778038,
      0.06223588436841965,
      0.06528988480567932,
      0.07531195878982544,
      0.0091654472053051,
      -0.0819048285484314,
      0.018119387328624725,
      -0.06877939403057098,
      0.025095462799072266,
      -0.03934180364012718,
      -5.128661584308247e-8,
      0.030460814014077187,
      -0.0041391439735889435,
      0.03754046559333801,
      0.02792893536388874,
      0.053919266909360886,
      -0.04760557413101196,
      -0.017757771536707878,
      0.0398203581571579,
      0.006816169247031212,
      0.008573588915169239,
      0.137749582529068,
      -0.041705481708049774,
      0.03141548112034798,
      0.003157961880788207,
      0.03479843959212303,
      0.055638138204813004,
      -0.005605279467999935,
      -0.027683109045028687,
      -0.07479535788297653,
      -0.039320383220911026,
      0.005617969203740358,
      0.05085339769721031,
      -0.022873612120747566,
      0.04910705238580704,
      0.0573698915541172,
      0.018022075295448303,
      0.053782906383275986,
      0.11166660487651825,
      0.09208233654499054,
      -0.028711849823594093,
      0.025249334052205086,
      -0.017788685858249664,
      -0.006706458516418934,
      -0.025080136954784393,
      0.04794861003756523,
      -0.05564191937446594,
      -0.010744143277406693,
      0.030579278245568275,
      0.025791477411985397,
      0.0632014200091362,
      0.03254767879843712,
      0.02286372520029545,
      -0.02953009307384491,
      0.04251956567168236,
      0.08524397760629654,
      -0.05982868745923042,
      -0.06800443679094315,
      -0.03514844924211502,
      -0.009460188448429108,
      -0.016135256737470627,
      0.005384351592510939,
      -0.08132900297641754,
      -0.0693010464310646,
      0.032488949596881866,
      0.04858442023396492,
      -0.011907840147614479,
      0.02456953004002571,
      -0.055353980511426926,
      0.019705532118678093,
      0.026884080842137337,
      0.05981050431728363,
      -0.027370184659957886,
      -0.11661656200885773,
      0.011982467025518417
    ],
    [
      -0.02485288679599762,
      0.042138438671827316,
      0.03660392016172409,
      0.02512102574110031,
      0.031351279467344284,
      -0.03894203156232834,
      0.04415634647011757,
      -0.008672453463077545,
      0.02304917387664318,
      0.05147209390997887,
      -0.1278749406337738,
      0.0023897341452538967,
      0.04609095677733421,
      -0.06552732735872269,
      0.026057766750454903,
      0.045816391706466675,
      0.08372648805379868,
      -0.009232349693775177,
      -0.04551200568675995,
      0.0015722336247563362,
      0.0733509287238121,
      -0.021161410957574844,
      0.04208974912762642,
      -0.028835507109761238,
      0.005755848716944456,
      -0.017964622005820274,
      0.05178235471248627,
      -0.015915391966700554,
      -0.018870403990149498,
      -0.0007069863495416939,
      -0.025450468063354492,
      0.0005031140171922743,
      0.04976542294025421,
      -0.07341146469116211,
      -0.046333108097314835,
      0.03187702223658562,
      -0.07737371325492859,
      -0.004101673141121864,
      -0.032238785177469254,
      0.03724462166428566,
      0.007923025637865067,
      0.009786923415958881,
      -0.046961747109889984,
      0.010229293256998062,
      -0.08021093904972076,
      0.022277100011706352,
      -0.05893746763467789,
      0.02220306545495987,
      -0.051657892763614655,
      -0.0574595108628273,
      0.08158066868782043,
      -0.03791683912277222,
      -0.07611413300037384,
      0.06579821556806564,
      0.07460195571184158,
      -0.016247287392616272,
      -0.015981484204530716,
      0.021579500287771225,
      0.06988157331943512,
      0.024496620520949364,
      -0.009444030001759529,
      -0.001660175621509552,
      0.00027890174533240497,
      -0.046753231436014175,
      0.03541915491223335,
      0.05228012427687645,
      0.012044291943311691,
      0.01441988442093134,
      -0.029541894793510437,
      0.004265209659934044,
      -0.05661403015255928,
      -0.010640758089721203,
      -0.0435086227953434,
      -0.06853622198104858,
      -0.07279537618160248,
      -0.01054874062538147,
      0.05906933918595314,
      0.05845107138156891,
      0.09314743429422379,
      -0.0013456842862069607,
      0.009651409462094307,
      0.07105405628681183,
      0.024685828015208244,
      -0.1145157516002655,
      -0.013210952281951904,
      -0.0653562992811203,
      -0.04942675307393074,
      0.02783721126616001,
      0.16308368742465973,
      -0.07971978932619095,
      0.03018840216100216,
      0.15118743479251862,
      -0.025412969291210175,
      0.02291507087647915,
      0.1152101457118988,
      -0.029762500897049904,
      -0.04496694356203079,
      -0.0260273776948452,
      0.017797550186514854,
      0.04509598761796951,
      0.048821885138750076,
      -0.011390876024961472,
      0.034085940569639206,
      0.002564601134508848,
      0.028958585113286972,
      -0.07553089410066605,
      0.009835491888225079,
      0.045895908027887344,
      0.033983759582042694,
      -0.03267570585012436,
      0.019249984994530678,
      0.09307543188333511,
      0.01723860576748848,
      -0.007841067388653755,
      -0.06029564514756203,
      0.0682436153292656,
      0.07021758705377579,
      0.0015987805090844631,
      0.0378604456782341,
      0.05408059433102608,
      -0.03826941177248955,
      -0.06340017914772034,
      0.06198602914810181,
      -0.07103388756513596,
      0.031021684408187866,
      -0.02388600818812847,
      -0.05814165994524956,
      1.5717197010218945e-33,
      -0.03389761969447136,
      -0.0172418262809515,
      -0.02333616279065609,
      -0.11006751656532288,
      0.04010452330112457,
      -0.006576569750905037,
      0.01815018616616726,
      -0.006231984123587608,
      -0.05253131315112114,
      -0.013978635892271996,
      -0.02056766115128994,
      0.040033746510744095,
      -0.04312864691019058,
      0.009264083579182625,
      0.11310675740242004,
      -0.05981010943651199,
      -0.008882859721779823,
      0.031008724123239517,
      0.07194841653108597,
      -0.12024672329425812,
      0.05411841720342636,
      -0.005151805933564901,
      0.04036514461040497,
      -0.01474600750952959,
      0.0026201196014881134,
      -0.000699987227562815,
      -0.006514677777886391,
      -0.13922539353370667,
      0.00959804467856884,
      0.028311649337410927,
      -0.03219141438603401,
      -0.04608706384897232,
      -0.010952824726700783,
      -0.026686720550060272,
      0.006544625386595726,
      0.019565129652619362,
      -0.022784410044550896,
      0.007591931615024805,
      0.0033585182391107082,
      -0.04827375337481499,
      -0.05387585237622261,
      -0.015074148774147034,
      0.0705208107829094,
      -0.014576024375855923,
      -0.07555905729532242,
      -0.014616982080042362,
      0.039828937500715256,
      -0.03225351870059967,
      -0.0028750807978212833,
      0.015928156673908234,
      0.011205672286450863,
      -0.048934802412986755,
      -0.016254320740699768,
      -0.05706999450922012,
      -0.040211040526628494,
      -0.04701368510723114,
      0.013212988153100014,
      0.09094205498695374,
      0.023833265528082848,
      0.14234359562397003,
      -0.022296961396932602,
      -0.003931062761694193,
      0.033320557326078415,
      0.017204349860548973,
      0.029125260189175606,
      0.029046252369880676,
      -0.0637582391500473,
      -0.007124465890228748,
      0.04626040905714035,
      -0.005754375364631414,
      0.03352171182632446,
      -0.05161671340465546,
      0.11801332235336304,
      -0.047394558787345886,
      0.0049887606874108315,
      0.00032621578429825604,
      0.052268195897340775,
      -0.004663539119064808,
      -0.14239054918289185,
      -0.01703573390841484,
      -0.04287135601043701,
      0.01508645061403513,
      -0.04655075445771217,
      -0.11960331350564957,
      0.011064812541007996,
      -0.08724921941757202,
      0.023957496508955956,
      -0.012017091736197472,
      -0.09878360480070114,
      0.025412438437342644,
      -0.026905475184321404,
      -0.004234691616147757,
      0.04999284818768501,
      -0.005149334203451872,
      -0.0015458745183423162,
      -8.24950088628077e-34,
      0.0033978503197431564,
      -0.024094685912132263,
      0.0034484637435525656,
      -0.008804082870483398,
      0.022662349045276642,
      -0.017392180860042572,
      -0.0032699580769985914,
      -0.10946208983659744,
      -0.06355106085538864,
      -0.044500745832920074,
      -0.050735633820295334,
      0.001834774506278336,
      0.0018687959527596831,
      0.028514442965388298,
      0.0024157122243195772,
      -0.03195501118898392,
      -0.013473371043801308,
      0.029827764257788658,
      -0.02690424956381321,
      0.07588329166173935,
      0.014513794332742691,
      0.05612357333302498,
      -0.0533091276884079,
      0.013613920658826828,
      0.00029852180159650743,
      0.06306356936693192,
      0.0296758022159338,
      0.14672309160232544,
      0.041183408349752426,
      -0.01520642451941967,
      -0.13205449283123016,
      -0.024311652407050133,
      -0.1064879447221756,
      0.04978688061237335,
      0.07337876409292221,
      0.03827713057398796,
      0.033194102346897125,
      0.06998127698898315,
      -0.01939297839999199,
      0.05334576964378357,
      0.0374603196978569,
      -0.03207648918032646,
      0.017868978902697563,
      0.022120187059044838,
      0.02453293651342392,
      -0.013388031162321568,
      -0.029510674998164177,
      0.02331082709133625,
      -0.08107826858758926,
      -0.07240211218595505,
      0.06605646759271622,
      -0.06272953003644943,
      -0.04206053167581558,
      0.10874532908201218,
      -0.08006454259157181,
      0.0006445806357078254,
      -0.005897635128349066,
      0.0685051828622818,
      -0.04461048170924187,
      0.0037681306712329388,
      0.0859166756272316,
      -0.006681963801383972,
      0.011907252483069897,
      0.0308803990483284,
      0.04416116327047348,
      -0.0009678815258666873,
      -0.00022590899607166648,
      -0.11175922304391861,
      0.036991801112890244,
      0.014009874314069748,
      -0.10380800813436508,
      -0.02600906789302826,
      0.009074526838958263,
      -0.002242549555376172,
      -0.005903318058699369,
      0.08770490437746048,
      0.04427020251750946,
      0.004034225828945637,
      -0.0796191468834877,
      -0.0126195028424263,
      -0.05618688091635704,
      0.06890479475259781,
      -0.023278195410966873,
      -0.0698985755443573,
      0.004061394836753607,
      -0.044171154499053955,
      0.05716434866189957,
      0.0003613362496253103,
      0.04303572326898575,
      0.005265452433377504,
      -0.06368210911750793,
      -0.03234225511550903,
      -0.03915845975279808,
      0.07070537656545639,
      -0.09811054170131683,
      -4.698892652754694e-8,
      0.004787556827068329,
      -0.022209348157048225,
      0.06729143857955933,
      -0.01349519845098257,
      0.11116398125886917,
      -0.04588610678911209,
      0.04171718657016754,
      -0.10303344577550888,
      -0.04999179020524025,
      0.049286071211099625,
      0.1276831328868866,
      0.006126438733190298,
      0.05194126069545746,
      -0.03247200325131416,
      -0.013202192261815071,
      0.018689291551709175,
      -0.0610772930085659,
      0.0021810131147503853,
      -0.003776031080633402,
      0.0020293083507567644,
      -0.03720675781369209,
      0.016048772260546684,
      -0.025524314492940903,
      0.04622830078005791,
      0.09282391518354416,
      0.009215985424816608,
      0.004382970277220011,
      -0.015180868096649647,
      0.09544306993484497,
      0.07313799858093262,
      0.02746286243200302,
      0.00919276848435402,
      0.07695644348859787,
      0.058544453233480453,
      0.02690950036048889,
      0.01555978786200285,
      -0.019386302679777145,
      0.003781357314437628,
      0.008337074890732765,
      0.12476608157157898,
      0.06996411830186844,
      0.003235397394746542,
      -0.00887193065136671,
      -0.013495287857949734,
      -0.03491195663809776,
      -0.0017463980475440621,
      -0.08337640017271042,
      0.018602190539240837,
      0.086006298661232,
      0.06445542722940445,
      0.019401157274842262,
      -0.03815120458602905,
      -0.05020475760102272,
      0.0031541031785309315,
      0.03478095680475235,
      -0.09200793504714966,
      -0.024686429649591446,
      -0.022288409993052483,
      0.044946614652872086,
      0.02626260183751583,
      -0.017503047361969948,
      0.01464779768139124,
      -0.07325240224599838,
      0.008218138478696346
    ],
    [
      -0.020489700138568878,
      -0.04178495705127716,
      0.05266366899013519,
      0.03735848888754845,
      0.055271029472351074,
      0.027819626033306122,
      -0.06510161608457565,
      0.0034953176509588957,
      0.15787145495414734,
      0.020796459168195724,
      -0.03306293487548828,
      0.015306907705962658,
      0.03164772689342499,
      0.062013737857341766,
      0.02176644094288349,
      0.02306852862238884,
      -0.05647141486406326,
      0.050005339086055756,
      -0.028224818408489227,
      0.09888061881065369,
      0.12009619921445847,
      -0.002804146148264408,
      0.07121623307466507,
      -0.011921588331460953,
      0.001347253448329866,
      -0.027330884709954262,
      0.01578480191528797,
      -0.0607469417154789,
      -0.015979979187250137,
      -0.059418030083179474,
      -0.03324754536151886,
      0.08019860088825226,
      -0.005329566076397896,
      -0.0057072932831943035,
      0.033237915486097336,
      0.028783762827515602,
      0.04558373615145683,
      0.026699194684624672,
      -0.09689152240753174,
      0.030162658542394638,
      0.0761614665389061,
      -0.024786483496427536,
      -0.03845643252134323,
      -0.01624879240989685,
      -0.047877538949251175,
      -0.006451478227972984,
      -0.07973552495241165,
      -0.08353279531002045,
      -0.11050672084093094,
      0.07536645978689194,
      -0.047373216599226,
      -0.017919057980179787,
      -0.07456884533166885,
      0.05008074641227722,
      0.01676766574382782,
      0.018957560881972313,
      -0.03377879410982132,
      -0.006264128722250462,
      0.01605764590203762,
      -0.03785839304327965,
      -0.0863540917634964,
      0.045837149024009705,
      -0.022147664800286293,
      -0.028340179473161697,
      0.0395643413066864,
      0.07199481874704361,
      0.007555272430181503,
      -0.03789146617054939,
      0.004526661243289709,
      0.020810812711715698,
      -0.08390647172927856,
      -0.02049839496612549,
      -0.03092370368540287,
      -0.02197612263262272,
      0.01314781978726387,
      -0.031223434954881668,
      0.040500979870557785,
      0.0005087194731459022,
      0.0006426182808354497,
      -0.06173964589834213,
      0.06241042912006378,
      0.05020790919661522,
      -0.02144249901175499,
      -0.05044861510396004,
      -0.040627919137477875,
      0.01051443349570036,
      0.030011123046278954,
      0.10494294762611389,
      -0.055659130215644836,
      -0.02176322042942047,
      -0.0116026746109128,
      0.017408087849617004,
      -0.05027323216199875,
      0.005267246160656214,
      0.1417606621980667,
      0.023539407178759575,
      -0.010358619503676891,
      0.022917067632079124,
      0.15152104198932648,
      -0.04133620485663414,
      0.00490600848570466,
      -0.004181552212685347,
      0.0050156801007688046,
      -0.01333540864288807,
      -0.003872165223583579,
      -0.012852117419242859,
      -0.00756138376891613,
      -0.09958288818597794,
      0.0127039086073637,
      0.021992677822709084,
      0.032301098108291626,
      0.026959259063005447,
      0.07689444720745087,
      0.018469829112291336,
      0.08629816025495529,
      0.04874766990542412,
      -0.04366067424416542,
      0.08463640511035919,
      0.05950552225112915,
      0.06741992384195328,
      0.06651056557893753,
      -0.06402646005153656,
      0.036099642515182495,
      -0.0891963541507721,
      -0.01569961942732334,
      -0.028515055775642395,
      -0.07418385148048401,
      6.426220435066113e-33,
      0.03308927267789841,
      -0.06840665638446808,
      -0.021107258275151253,
      0.0815100222826004,
      -0.0044088889844715595,
      -0.049288179725408554,
      -0.0385623499751091,
      -0.0401882641017437,
      0.004313834011554718,
      0.0024655137676745653,
      -0.08297289907932281,
      0.030837196856737137,
      -0.03468843549489975,
      -0.033237114548683167,
      -0.0056218598037958145,
      0.0054810186848044395,
      0.040760625153779984,
      0.052942026406526566,
      -0.038509342819452286,
      -0.05041195824742317,
      0.018733931705355644,
      0.02890537865459919,
      0.030315063893795013,
      0.021259287372231483,
      -0.028916675597429276,
      0.003813002724200487,
      -0.04535971209406853,
      0.010704604908823967,
      -0.08618460595607758,
      0.008064864203333855,
      -0.01644231006503105,
      0.009990064427256584,
      -0.07862697541713715,
      0.015103179030120373,
      -0.015399671159684658,
      -0.01280855480581522,
      0.05394868552684784,
      0.005860497709363699,
      -0.03595639020204544,
      -0.021588928997516632,
      -0.07751306146383286,
      0.050356488674879074,
      -0.00898961815983057,
      -0.005630678962916136,
      0.018211858347058296,
      -0.06891575455665588,
      0.0202900692820549,
      0.09066398441791534,
      0.02759021706879139,
      0.023887841030955315,
      0.05076814442873001,
      -0.04330567270517349,
      0.00820083450525999,
      -0.0693853497505188,
      -0.09536916017532349,
      0.0488101989030838,
      -0.0426848903298378,
      -0.017598800361156464,
      -0.06670724600553513,
      0.09237466007471085,
      0.03700719028711319,
      0.008412076160311699,
      0.011654253117740154,
      0.011468349024653435,
      0.021909138187766075,
      0.07647722959518433,
      -0.09775296598672867,
      -0.060185715556144714,
      0.03950023278594017,
      0.01737029477953911,
      0.06971420347690582,
      -0.06551874428987503,
      0.033141788095235825,
      0.0004684050800278783,
      0.061742912977933884,
      -0.037089984863996506,
      0.00968406442552805,
      0.07226454466581345,
      -0.11378096044063568,
      -0.03539857268333435,
      0.06189775839447975,
      0.05211033672094345,
      -0.04654369875788689,
      -0.09240150451660156,
      -0.049959905445575714,
      -0.055121246725320816,
      0.04947231337428093,
      0.006816974375396967,
      -0.1501891016960144,
      -0.000729317544028163,
      -0.00588945671916008,
      -0.052494410425424576,
      0.09943409264087677,
      0.036279190331697464,
      0.009538312442600727,
      -8.070075081610187e-33,
      -0.011923221871256828,
      -0.06316613405942917,
      -0.0011163068702444434,
      -0.07144662737846375,
      0.04219812527298927,
      0.04092699661850929,
      0.025170905515551567,
      -0.006099053658545017,
      -0.010526838712394238,
      -0.08298312872648239,
      0.05844518914818764,
      -0.018576810136437416,
      0.014468302018940449,
      -0.052138518542051315,
      0.011014408431947231,
      -0.004016639199107885,
      0.07757312804460526,
      0.007670127786695957,
      -0.04612312838435173,
      0.0653795525431633,
      0.03198893740773201,
      0.0009675616165623069,
      -0.11129188537597656,
      -0.08064914494752884,
      0.0070679523050785065,
      0.073671355843544,
      -0.019962184131145477,
      0.11075560748577118,
      0.01708185113966465,
      -0.05001602694392204,
      -0.06795543432235718,
      -0.03036348521709442,
      -0.10747451335191727,
      0.005448685027658939,
      -0.02314632013440132,
      -0.002387173241004348,
      -0.018742818385362625,
      -0.0005101316492073238,
      -0.019708406180143356,
      -0.10397104918956757,
      0.08657214045524597,
      0.012184134684503078,
      0.05392349883913994,
      -0.0960410088300705,
      0.09918490797281265,
      0.012905549257993698,
      0.004504829179495573,
      -0.06884625554084778,
      -0.020991282537579536,
      -0.07902879267930984,
      0.0026640049181878567,
      0.05460427328944206,
      -0.015152242965996265,
      0.018808424472808838,
      -0.0357196070253849,
      0.051857706159353256,
      -0.05247999727725983,
      -0.026495855301618576,
      -0.004583672154694796,
      0.02563609555363655,
      0.012275039218366146,
      0.021821871399879456,
      -0.02120475098490715,
      0.019854549318552017,
      0.07667452841997147,
      0.0359174907207489,
      -0.001653877436183393,
      -0.11475300788879395,
      0.05273644998669624,
      -0.049584854394197464,
      -0.002548173302784562,
      -0.013889878056943417,
      -0.01682760752737522,
      0.07060781866312027,
      0.03128708899021149,
      -0.00047061030636541545,
      0.0019164655823260546,
      -0.08017216622829437,
      -0.03871368244290352,
      -0.057897940278053284,
      -0.10281427204608917,
      -0.08588819205760956,
      -0.059843312948942184,
      -0.030300188809633255,
      -0.08907060325145721,
      -0.03368222340941429,
      0.05121227353811264,
      -0.0838441476225853,
      0.1281471997499466,
      -0.02117500826716423,
      -0.031368281692266464,
      -0.000570755684748292,
      -0.06839302182197571,
      -0.007911981083452702,
      0.029984774067997932,
      -6.002282759709487e-8,
      0.05976060405373573,
      -0.041270893067121506,
      -0.002555763116106391,
      0.007554732263088226,
      0.0055769882164895535,
      0.014412201009690762,
      0.07472163438796997,
      0.008559479378163815,
      -0.016076115891337395,
      0.057654011994600296,
      0.08946090191602707,
      -0.01152763795107603,
      0.11006143689155579,
      -0.07554440945386887,
      -0.005694815889000893,
      0.027875786647200584,
      -0.02555287815630436,
      0.04406216740608215,
      -0.0018378555541858077,
      -0.045165762305259705,
      -0.004742523189634085,
      -0.029871325939893723,
      -0.036262381821870804,
      -0.028176605701446533,
      0.007705010939389467,
      0.018672939389944077,
      -0.03433455899357796,
      0.03151106834411621,
      -0.003581003053113818,
      -0.028017805889248848,
      -0.017544910311698914,
      0.008298194967210293,
      0.0026215824764221907,
      0.052856530994176865,
      -0.040177155286073685,
      0.00008524754230165854,
      0.08274993300437927,
      -0.0038239234127104282,
      0.005776206962764263,
      0.1750597208738327,
      0.050393424928188324,
      -0.0576954260468483,
      -0.045956388115882874,
      -0.0007360846502706409,
      0.010915861465036869,
      -0.04244976118206978,
      -0.00035921871312893927,
      -0.025710005313158035,
      0.021806878969073296,
      0.057513102889060974,
      0.025963066145777702,
      -0.047955650836229324,
      -0.06298495829105377,
      -0.0437801256775856,
      -0.04301329702138901,
      0.018291639164090157,
      0.015916725620627403,
      -0.0315738171339035,
      0.05698176845908165,
      -0.061238985508680344,
      0.05843271687626839,
      -0.02439182996749878,
      -0.049019522964954376,
      0.01979673095047474
    ],
    [
      0.013389567844569683,
      0.020111804828047752,
      -0.0037707665469497442,
      0.07312532514333725,
      0.07021722942590714,
      0.052542224526405334,
      -0.08525272458791733,
      0.041415393352508545,
      0.09238744527101517,
      0.021557288244366646,
      -0.01964913122355938,
      -0.057897768914699554,
      0.007792262360453606,
      0.030451186001300812,
      -0.023274801671504974,
      0.04061650112271309,
      0.06551884859800339,
      0.019714409485459328,
      -0.006487845443189144,
      0.02008482813835144,
      0.05693267658352852,
      0.011782649904489517,
      0.12670926749706268,
      -0.0005118278204463422,
      0.04525173828005791,
      0.039030253887176514,
      0.029838915914297104,
      -0.043987538665533066,
      -0.053122829645872116,
      0.018747417256236076,
      0.0007864619255997241,
      0.055215347558259964,
      0.014543416909873486,
      -0.05400290712714195,
      -0.02723950706422329,
      -0.011437512934207916,
      0.07062500715255737,
      0.02261953614652157,
      -0.10438746213912964,
      0.032871559262275696,
      0.011966458521783352,
      0.039651110768318176,
      -0.05203598365187645,
      -0.0750056654214859,
      -0.043273575603961945,
      -0.050311408936977386,
      -0.030043920502066612,
      -0.0488729253411293,
      -0.10633979737758636,
      0.03839883580803871,
      -0.003528299042955041,
      -0.011659560725092888,
      -0.03710903972387314,
      0.035471998155117035,
      0.006729502230882645,
      -0.03884498402476311,
      -0.06617256999015808,
      -0.0011295360745862126,
      0.07384390383958817,
      0.05314420536160469,
      -0.030961407348513603,
      0.05473671108484268,
      0.01992335356771946,
      -0.019101442769169807,
      0.05713983252644539,
      0.10030622035264969,
      -0.06931586563587189,
      -0.009643509984016418,
      0.01066051796078682,
      -0.011455509811639786,
      -0.0757613256573677,
      -0.04647531360387802,
      0.020352663472294807,
      0.06653048098087311,
      -0.013250363059341908,
      0.010999406687915325,
      0.17890070378780365,
      0.04274262115359306,
      0.031078683212399483,
      -0.14519120752811432,
      0.00851503200829029,
      0.10788296163082123,
      0.04785020276904106,
      0.0278156828135252,
      -0.04191417992115021,
      0.028511354699730873,
      0.11814654618501663,
      0.07229715585708618,
      -0.06283996999263763,
      -0.0035068003926426172,
      0.032078590244054794,
      0.004275802057236433,
      -0.03556181490421295,
      -0.018298182636499405,
      0.07973279803991318,
      -0.04448642581701279,
      -0.058720022439956665,
      0.033260345458984375,
      -0.02986116148531437,
      -0.11758346855640411,
      -0.020031722262501717,
      0.032565079629421234,
      -0.020022211596369743,
      0.07571853697299957,
      -0.007486291229724884,
      0.0018982517067342997,
      -0.01756460964679718,
      -0.11665849387645721,
      -0.046220563352108,
      0.014120059087872505,
      -0.030162900686264038,
      0.054826270788908005,
      0.002052223775535822,
      0.030924363061785698,
      0.10809537023305893,
      -0.04383217543363571,
      -0.0030123395845294,
      0.03758668154478073,
      0.07134147733449936,
      0.025002561509609222,
      0.05819128826260567,
      -0.0038000973872840405,
      0.061193954199552536,
      -0.117287777364254,
      0.009223666042089462,
      -0.03374920040369034,
      -0.03091992810368538,
      7.38436588042136e-33,
      -0.06093587353825569,
      -0.037393562495708466,
      0.018747514113783836,
      0.0341050922870636,
      -0.028587274253368378,
      0.04226931184530258,
      -0.01859143376350403,
      0.05644490197300911,
      0.053522784262895584,
      -0.015649402514100075,
      -0.10405287891626358,
      -0.05163269117474556,
      -0.011050540953874588,
      -0.01655094511806965,
      0.02283705770969391,
      0.07568471133708954,
      -0.08861511945724487,
      0.015943825244903564,
      -0.0441783107817173,
      -0.0019208230078220367,
      -0.06303706765174866,
      -0.02639443427324295,
      0.058176420629024506,
      0.056435536593198776,
      0.0174171831458807,
      -0.014322130009531975,
      -0.012004205957055092,
      0.03384922817349434,
      -0.022165920585393906,
      -0.018963653594255447,
      -0.004564880393445492,
      -0.004149912390857935,
      -0.005453094374388456,
      -0.10676637291908264,
      0.01066977996379137,
      0.01177949458360672,
      0.08872834593057632,
      0.02102869190275669,
      -0.057261254638433456,
      -0.017993532121181488,
      -0.08323399722576141,
      0.019689954817295074,
      -0.018119564279913902,
      0.016172315925359726,
      -0.006232306826859713,
      -0.048761699348688126,
      -0.0051590087823569775,
      -0.038503438234329224,
      0.05338326096534729,
      -0.00656350189819932,
      -0.016164466738700867,
      -0.0004096203192602843,
      -0.04637574404478073,
      -0.12506550550460815,
      -0.07949173450469971,
      0.08667144179344177,
      -0.03370581567287445,
      -0.00022946609533391893,
      -0.11052369326353073,
      0.04165378212928772,
      0.0009871326619759202,
      -0.055137693881988525,
      -0.017965858802199364,
      -0.08300656825304031,
      -0.018097583204507828,
      0.027591662481427193,
      0.048384737223386765,
      0.018891310319304466,
      -0.004477181937545538,
      -0.10511549562215805,
      0.026516873389482498,
      -0.07564010471105576,
      0.069402314722538,
      0.002811797196045518,
      0.0034703330602496862,
      -0.03683101758360863,
      0.08416970074176788,
      0.01870874874293804,
      -0.04227456822991371,
      -0.04349881038069725,
      -0.018203359097242355,
      -0.004834766034036875,
      -0.014684602618217468,
      -0.09813656657934189,
      0.015046309679746628,
      -0.08769712597131729,
      0.019405655562877655,
      0.0191652812063694,
      -0.07347586005926132,
      -0.04079573228955269,
      -0.013699830509722233,
      -0.022921312600374222,
      0.051065072417259216,
      0.022719701752066612,
      -0.040217332541942596,
      -8.692179018159989e-33,
      -0.007264156825840473,
      -0.02071242406964302,
      -0.016553962603211403,
      -0.07442160695791245,
      0.0571189783513546,
      -0.0400468111038208,
      0.0007000979385338724,
      -0.03699827194213867,
      -0.007111735641956329,
      -0.08177778869867325,
      0.04607902839779854,
      -0.06609591841697693,
      0.04939613863825798,
      -0.10532135516405106,
      0.04996299371123314,
      0.016339322552084923,
      -0.020474763587117195,
      0.01745297946035862,
      -0.00738138472661376,
      0.05323103070259094,
      0.04786929488182068,
      -0.061983563005924225,
      -0.08385986089706421,
      -0.09602587670087814,
      0.04606841877102852,
      0.06405116617679596,
      0.02766605094075203,
      0.087408147752285,
      0.04966984689235687,
      -0.041236188262701035,
      0.047901466488838196,
      0.047350868582725525,
      -0.054859697818756104,
      0.010713550262153149,
      0.02685610018670559,
      0.0022918174508959055,
      -0.02381586655974388,
      0.011537925340235233,
      -0.03549063950777054,
      -0.08582092076539993,
      0.06361271440982819,
      0.0531596802175045,
      0.002643527463078499,
      -0.035416893661022186,
      0.02883276157081127,
      0.08639395236968994,
      0.03564879298210144,
      -0.01867324486374855,
      0.041752927005290985,
      0.03371523693203926,
      0.10129810869693756,
      0.04351373389363289,
      -0.08955767750740051,
      0.03253266587853432,
      0.004999072756618261,
      -0.01937437802553177,
      0.05678325146436691,
      -0.03438258916139603,
      0.0029425485990941525,
      0.022542091086506844,
      0.04236777126789093,
      0.01770639792084694,
      -0.040690936148166656,
      -0.014977562241256237,
      0.07296579331159592,
      -0.03525737673044205,
      -0.043296437710523605,
      -0.07320806384086609,
      -0.011554553173482418,
      -0.03957580402493477,
      -0.02350957877933979,
      -0.03460635244846344,
      0.007236977107822895,
      -0.051693227142095566,
      -0.050535235553979874,
      -0.04772810637950897,
      -0.028884954750537872,
      -0.008983281441032887,
      -0.05242963507771492,
      0.01041312888264656,
      -0.05061569809913635,
      -0.1080295592546463,
      0.042755287140607834,
      -0.020281994715332985,
      -0.09229660034179688,
      -0.07676959037780762,
      0.008388767018914223,
      -0.01825254037976265,
      0.09506707638502121,
      0.024410733953118324,
      -0.025597942993044853,
      -0.003202820895239711,
      -0.11442844569683075,
      0.009798867627978325,
      -0.001267866464331746,
      -6.145166508986222e-8,
      0.14148423075675964,
      0.0070082200691103935,
      0.03319668769836426,
      0.02966160513460636,
      0.02549331821501255,
      -0.05337497591972351,
      0.030053697526454926,
      0.05039667338132858,
      -0.05336739122867584,
      0.09088470041751862,
      -0.023583194240927696,
      0.04952668026089668,
      0.007706905715167522,
      -0.019756345078349113,
      0.012689873576164246,
      -0.0715215727686882,
      -0.007262843661010265,
      0.015738172456622124,
      0.041386183351278305,
      0.0376628041267395,
      0.05126515030860901,
      0.021136585623025894,
      -0.06652005016803741,
      -0.06554688513278961,
      0.008439520373940468,
      0.013060382567346096,
      0.01374373771250248,
      0.015985634177923203,
      0.0026468343567103148,
      -0.06504113227128983,
      0.11179329454898834,
      0.005688034929335117,
      0.039613593369722366,
      -0.02795097976922989,
      -0.036328043788671494,
      -0.10328610241413116,
      -0.02500913292169571,
      0.08161338418722153,
      -0.0538204126060009,
      0.1606639325618744,
      0.024251705035567284,
      0.044165223836898804,
      -0.017495902255177498,
      -0.004057572688907385,
      0.019206224009394646,
      -0.02381855994462967,
      -0.035029660910367966,
      0.01888132095336914,
      0.011119530536234379,
      0.04347477853298187,
      -0.017864562571048737,
      -0.0663258358836174,
      -0.0016528564738109708,
      -0.05586516484618187,
      0.010277139954268932,
      0.05568375810980797,
      0.03431091830134392,
      -0.020193617790937424,
      0.009972936473786831,
      -0.023101113736629486,
      0.03568674251437187,
      -0.013118071481585503,
      0.009795158170163631,
      0.02932509407401085
    ],
    [
      0.002524100709706545,
      -0.11027561128139496,
      0.012005267664790154,
      0.033581383526325226,
      -0.013992752879858017,
      0.08510054647922516,
      -0.028388051316142082,
      -0.029047932475805283,
      0.07569881528615952,
      0.022287823259830475,
      -0.09137488156557083,
      0.018724383786320686,
      0.06904218345880508,
      -0.009147810749709606,
      0.019624371081590652,
      0.09850375354290009,
      0.019326457753777504,
      0.05863140523433685,
      0.02970488741993904,
      0.03996044769883156,
      0.07224853336811066,
      -0.04875635728240013,
      0.06645514070987701,
      0.011234086006879807,
      -0.06306891143321991,
      0.020362550392746925,
      -0.007140486501157284,
      0.02355891279876232,
      -0.024731861427426338,
      -0.06708929687738419,
      0.0069506545551121235,
      0.05697038397192955,
      -0.025850627571344376,
      -0.017390180379152298,
      -0.04108796268701553,
      0.02188201993703842,
      -0.08756086975336075,
      -0.027336187660694122,
      -0.032706357538700104,
      -0.035497892647981644,
      0.04029114171862602,
      -0.00008869799057720229,
      0.03473599627614021,
      -0.003119637258350849,
      -0.03766527771949768,
      0.02800973318517208,
      0.034256044775247574,
      -0.05720971152186394,
      -0.05910656601190567,
      -0.04447515681385994,
      0.005753722973167896,
      -0.03462279587984085,
      -0.059280816465616226,
      0.13929180800914764,
      0.015224461443722248,
      0.10943792015314102,
      -0.042153872549533844,
      0.07197181135416031,
      -0.011819436214864254,
      0.001696732477284968,
      -0.11461351811885834,
      0.03871483728289604,
      0.026619162410497665,
      -0.07276545464992523,
      0.0805601105093956,
      0.054443590342998505,
      -0.11647877097129822,
      -0.0006285519921220839,
      -0.023243337869644165,
      -0.08061385154724121,
      -0.0036662807688117027,
      -0.007970579899847507,
      -0.037383612245321274,
      -0.0804351195693016,
      -0.022159120067954063,
      0.0075348420068621635,
      0.05266633629798889,
      0.04501515254378319,
      0.039698220789432526,
      -0.041128434240818024,
      0.021719614043831825,
      0.06251394748687744,
      0.01348076481372118,
      0.023913951590657234,
      0.03177551552653313,
      0.01828595995903015,
      0.02949013002216816,
      0.03733748942613602,
      -0.0009501432068645954,
      -0.0034802479203790426,
      0.03541138768196106,
      -0.0915808230638504,
      -0.09380245953798294,
      -0.05222898721694946,
      0.03535640612244606,
      -0.040667902678251266,
      0.0021412153728306293,
      0.041056640446186066,
      -0.0112043721601367,
      0.0038281723391264677,
      0.019111569970846176,
      0.033080875873565674,
      -0.01609218120574951,
      -0.02745344303548336,
      -0.033304035663604736,
      0.04530583694577217,
      0.019988955929875374,
      0.014244037680327892,
      0.011711450293660164,
      -0.006342289503663778,
      -0.0541902594268322,
      0.06015405058860779,
      -0.02108266018331051,
      0.11296568810939789,
      0.03584054112434387,
      -0.00156620261259377,
      0.001681885332800448,
      0.039752401411533356,
      0.09517303854227066,
      -0.03176281228661537,
      -0.005439403001219034,
      -0.0004835254803765565,
      0.04894166439771652,
      -0.11651953309774399,
      0.03738240897655487,
      -0.030429372563958168,
      -0.1057932898402214,
      5.9761486273912145e-33,
      0.025205466896295547,
      -0.07074207067489624,
      -0.02575552649796009,
      -0.06265008449554443,
      0.041225068271160126,
      -0.03976025804877281,
      0.00009311942994827405,
      0.011151270009577274,
      0.05657520145177841,
      -0.0024413305800408125,
      -0.09576745331287384,
      -0.023617040365934372,
      0.021678587421774864,
      0.04319220036268234,
      0.01064850203692913,
      -0.06431052088737488,
      -0.09746603667736053,
      -0.059948310256004333,
      0.03696950897574425,
      -0.05788786709308624,
      -0.011380353011190891,
      0.020677678287029266,
      0.052976034581661224,
      -0.012487232685089111,
      -0.059285879135131836,
      -0.060265880078077316,
      0.005900288466364145,
      0.061941683292388916,
      -0.015246941708028316,
      0.03370383381843567,
      -0.038666773587465286,
      0.028487488627433777,
      0.020390087738633156,
      -0.036027662456035614,
      0.02770051918923855,
      0.02891969121992588,
      -0.01209344994276762,
      -0.0630251094698906,
      -0.019456196576356888,
      -0.019373411312699318,
      0.0071089123375713825,
      -0.005912798922508955,
      -0.08070123195648193,
      -0.006987751927226782,
      -0.029190057888627052,
      -0.09641743451356888,
      -0.00007795211422489956,
      0.007055720314383507,
      0.09974876046180725,
      -0.024593334645032883,
      0.036657243967056274,
      -0.025469737127423286,
      -0.0006327881710603833,
      -0.10568142682313919,
      -0.06986933201551437,
      0.003514795331284404,
      -0.014437989331781864,
      0.015627840533852577,
      -0.0333191454410553,
      0.07916726917028427,
      -0.042418621480464935,
      -0.00029906517011113465,
      0.027652300894260406,
      -0.002976070623844862,
      0.06912408769130707,
      0.10215265303850174,
      -0.09736974537372589,
      -0.05102863535284996,
      0.02233864739537239,
      -0.032320279628038406,
      0.05362633243203163,
      -0.004536186344921589,
      0.02266586944460869,
      -0.03987882658839226,
      0.01917128823697567,
      -0.002412461908534169,
      0.058889228850603104,
      0.12117969989776611,
      0.023980598896741867,
      -0.029194967821240425,
      0.05390423536300659,
      -0.08324643969535828,
      -0.07764095813035965,
      0.04114239662885666,
      0.009275942109525204,
      -0.010723315179347992,
      0.08403171598911285,
      -0.043946120887994766,
      -0.08125985413789749,
      0.018170520663261414,
      0.09187950938940048,
      -0.01523401029407978,
      0.03916211053729057,
      0.06064439192414284,
      -0.04383740946650505,
      -5.638420651534325e-33,
      -0.05789045989513397,
      -0.06714106351137161,
      0.007306890096515417,
      -0.036017775535583496,
      -0.03420686349272728,
      0.07144077867269516,
      0.01641569286584854,
      -0.05038238689303398,
      -0.13571633398532867,
      -0.059620872139930725,
      0.03159948065876961,
      0.019250046461820602,
      -0.037469033151865005,
      -0.004509827587753534,
      0.05906948074698448,
      -0.08824151009321213,
      0.02736043930053711,
      0.01315153669565916,
      -0.033678218722343445,
      -0.006931255105882883,
      0.02661076746881008,
      0.09170158207416534,
      -0.07275649905204773,
      -0.014462755993008614,
      0.055457036942243576,
      0.044040657579898834,
      0.03554578498005867,
      0.14334699511528015,
      0.0696650817990303,
      0.056595705449581146,
      -0.011938794516026974,
      0.05857505649328232,
      -0.14764121174812317,
      -0.06669609248638153,
      0.023139044642448425,
      0.06499351561069489,
      0.012868277728557587,
      -0.0036411865148693323,
      -0.08635827153921127,
      -0.06273817270994186,
      0.09452416002750397,
      0.02515966072678566,
      0.04840241000056267,
      -0.020908568054437637,
      0.03320949897170067,
      0.0387200266122818,
      -0.09987247735261917,
      0.039041608572006226,
      -0.03885136917233467,
      0.019517267122864723,
      -0.005772131960839033,
      -0.05180833116173744,
      -0.006480611860752106,
      -0.05516822636127472,
      -0.027861159294843674,
      0.017464831471443176,
      -0.02287207543849945,
      -0.03851601481437683,
      0.03726163133978844,
      -0.06245609372854233,
      -0.06893662363290787,
      0.033804457634687424,
      -0.041396141052246094,
      -0.08853625506162643,
      0.083063043653965,
      0.013399996794760227,
      0.02101851813495159,
      -0.06099794805049896,
      0.08350800722837448,
      0.0062331827357411385,
      -0.0010304396273568273,
      0.05323127657175064,
      0.09786254167556763,
      -0.022146042436361313,
      0.02770504169166088,
      0.028661252930760384,
      -0.028761358931660652,
      -0.024168141186237335,
      -0.03049851395189762,
      -0.07562113553285599,
      -0.025755831971764565,
      0.016197767108678818,
      -0.057244136929512024,
      -0.06488011032342911,
      0.010108664631843567,
      -0.028121713548898697,
      -0.03227217495441437,
      0.028738021850585938,
      0.10353411734104156,
      -0.00520778214558959,
      -0.015267170034348965,
      -0.006492504850029945,
      -0.11674640327692032,
      0.006333163473755121,
      0.018472235649824142,
      -5.0550656993664234e-8,
      -0.010744359344244003,
      -0.07412346452474594,
      -0.002047285670414567,
      0.0449054017663002,
      0.03173984959721565,
      -0.06371311843395233,
      0.06344939023256302,
      0.017763201147317886,
      -0.03185177966952324,
      -0.009811058640480042,
      0.13138577342033386,
      0.01917845755815506,
      0.04135485365986824,
      -0.053597837686538696,
      0.021170375868678093,
      0.07562951743602753,
      0.050036199390888214,
      0.03753609582781792,
      0.014427021145820618,
      -0.04461689665913582,
      0.032617393881082535,
      -0.10464619845151901,
      0.042739104479551315,
      0.04262972250580788,
      0.11890339106321335,
      -0.049357254058122635,
      0.007705422583967447,
      0.08039921522140503,
      -0.05627463385462761,
      -0.03090701252222061,
      0.12750427424907684,
      -0.004104945342987776,
      0.02672474831342697,
      0.021051986142992973,
      -0.021744471043348312,
      0.031949132680892944,
      0.058318715542554855,
      0.016961954534053802,
      0.005222528241574764,
      0.05077613145112991,
      0.01583414524793625,
      -0.014840707182884216,
      -0.02244778349995613,
      0.02751448005437851,
      -0.01247015967965126,
      -0.05211642012000084,
      -0.011769981123507023,
      0.021169818937778473,
      0.0001726116461213678,
      -0.05578286945819855,
      -0.055177513509988785,
      0.027927396818995476,
      0.025122467428445816,
      0.035201553255319595,
      -0.04005172848701477,
      -0.04448606073856354,
      0.026805585250258446,
      -0.025369014590978622,
      0.04829951748251915,
      -0.04238593205809593,
      0.03723059222102165,
      0.05389809608459473,
      0.004237331449985504,
      -0.03504960611462593
    ],
    [
      -0.04741168022155762,
      -0.006064461078494787,
      0.09689256548881531,
      0.05343573912978172,
      0.04889686033129692,
      0.03586107864975929,
      -0.027413658797740936,
      -0.052034299820661545,
      0.03909469023346901,
      -0.09104318916797638,
      -0.10623456537723541,
      -0.15059074759483337,
      -0.059587348252534866,
      0.04152799770236015,
      -0.06317277252674103,
      -0.07187166064977646,
      0.0614713616669178,
      0.01292039267718792,
      -0.08712895959615707,
      0.032855723053216934,
      0.09173116832971573,
      -0.01206666324287653,
      0.06042657047510147,
      0.026146359741687775,
      0.014771224930882454,
      -0.005150902085006237,
      0.04242788255214691,
      -0.04299803450703621,
      -0.050653886049985886,
      -0.014102029614150524,
      0.041070833802223206,
      0.03326332941651344,
      -0.013394095934927464,
      0.06870938837528229,
      -0.08990778774023056,
      -0.002046865876764059,
      0.010353140532970428,
      0.013633946888148785,
      -0.014176031574606895,
      0.032497018575668335,
      0.03517807647585869,
      0.009659306146204472,
      0.006034846883267164,
      0.024449244141578674,
      0.08641844987869263,
      0.06296838074922562,
      0.018987620249390602,
      -0.12876056134700775,
      -0.04860389977693558,
      0.06405746936798096,
      -0.030129611492156982,
      0.017919057980179787,
      -0.0029393855948001146,
      0.0856664851307869,
      0.022274814546108246,
      0.052394479513168335,
      0.01652177982032299,
      0.004680422134697437,
      -0.0011855385964736342,
      0.030504556372761726,
      -0.02788832038640976,
      -0.04507739841938019,
      0.01433019619435072,
      -0.07023230940103531,
      0.007486550137400627,
      0.039240095764398575,
      0.006031768396496773,
      0.02216479927301407,
      0.00474160723388195,
      -0.023482980206608772,
      -0.06291976571083069,
      0.06148342043161392,
      -0.0388876348733902,
      0.006575223058462143,
      0.003790618386119604,
      0.07481104880571365,
      0.059262339025735855,
      -0.010867295786738396,
      0.08633076399564743,
      -0.12083284556865692,
      0.023899134248495102,
      0.011211912147700787,
      0.01348968781530857,
      -0.013311239890754223,
      0.11399125307798386,
      0.014657032676041126,
      0.04595157876610756,
      0.07599736750125885,
      -0.061299629509449005,
      -0.018057867884635925,
      -0.015832653269171715,
      -0.013403009623289108,
      -0.011540419422090054,
      -0.006799494847655296,
      0.05982177332043648,
      0.10410761088132858,
      -0.021629957482218742,
      -0.02656792849302292,
      0.0983446016907692,
      0.013889116235077381,
      -0.004522813484072685,
      0.0230704378336668,
      0.015258433297276497,
      0.04058406129479408,
      -0.026783546432852745,
      -0.013395054265856743,
      0.09775154292583466,
      -0.017623459920287132,
      0.020329661667346954,
      -0.04413970932364464,
      0.0457942858338356,
      0.046109285205602646,
      0.011507727205753326,
      -0.005534730385988951,
      0.0852876752614975,
      0.02782309055328369,
      -0.03862401098012924,
      0.06526771187782288,
      0.07846266031265259,
      0.0893356204032898,
      0.00025740842102095485,
      -0.023129902780056,
      0.02909744158387184,
      -0.06105960160493851,
      0.007353024557232857,
      0.014148056507110596,
      -0.09704422950744629,
      6.313173143347534e-33,
      0.02497982047498226,
      -0.048504408448934555,
      0.023131737485527992,
      -0.00822510663419962,
      -0.0021588080562651157,
      -0.06743089109659195,
      -0.0796496793627739,
      0.07764644175767899,
      0.02495620958507061,
      0.06584979593753815,
      -0.06618688255548477,
      0.03681906312704086,
      -0.06347950547933578,
      0.0360150970518589,
      0.01795961707830429,
      0.005150496028363705,
      -0.05329723656177521,
      0.042084310203790665,
      0.0030315981712192297,
      -0.04678436368703842,
      0.07423488795757294,
      -0.06556961685419083,
      0.0003480458108242601,
      -0.043792638927698135,
      0.030851110816001892,
      0.02079101838171482,
      0.016360711306333542,
      0.007260380312800407,
      -0.013445105403661728,
      0.008387679234147072,
      -0.12509611248970032,
      0.04793452098965645,
      0.012565961107611656,
      -0.02491566352546215,
      0.048041895031929016,
      -0.022510381415486336,
      0.04344018176198006,
      0.05773979425430298,
      0.032250892370939255,
      0.009761949069797993,
      -0.00045017979573458433,
      0.02455848827958107,
      0.0023445116821676493,
      -0.04693462327122688,
      -0.05017438530921936,
      -0.055685609579086304,
      0.04105186089873314,
      0.020723968744277954,
      0.046277567744255066,
      -0.05281933397054672,
      -0.035862281918525696,
      -0.064116470515728,
      -0.01614672690629959,
      -0.13567672669887543,
      -0.02172650583088398,
      0.0442672036588192,
      0.03743765503168106,
      0.015331579372286797,
      0.011012891307473183,
      0.11222188919782639,
      -0.026393556967377663,
      0.0666179209947586,
      -0.005098144523799419,
      0.031602416187524796,
      -0.011320576071739197,
      -0.001265015103854239,
      -0.019236696884036064,
      0.09644866734743118,
      0.031275518238544464,
      -0.03329011797904968,
      0.01082032360136509,
      0.03272177651524544,
      0.02925536222755909,
      -0.0691031813621521,
      0.05712321773171425,
      0.0027459124103188515,
      0.06326328963041306,
      0.0353667251765728,
      -0.09287578612565994,
      0.03171306475996971,
      0.05864807218313217,
      0.022471919655799866,
      -0.059971850365400314,
      -0.060012754052877426,
      -0.02056720107793808,
      -0.04804793372750282,
      0.036992114037275314,
      -0.028489630669355392,
      -0.09777089208364487,
      -0.03706065192818642,
      -0.044155895709991455,
      -0.033147409558296204,
      0.00907342042773962,
      0.010318676009774208,
      -0.07958175987005234,
      -5.3567453891124265e-33,
      0.008767728693783283,
      0.002435152418911457,
      -0.07491552084684372,
      0.0023549648467451334,
      0.07894273847341537,
      0.0014608193887397647,
      0.033658869564533234,
      -0.0015887839253991842,
      -0.004265032708644867,
      -0.04017576947808266,
      0.019507190212607384,
      -0.09463442116975784,
      0.0628441795706749,
      -0.035989850759506226,
      -0.001573651097714901,
      -0.033506494015455246,
      -0.08636676520109177,
      -0.00490975147113204,
      -0.04067157208919525,
      0.05711757764220238,
      -0.026321079581975937,
      0.07406526058912277,
      -0.10968288779258728,
      -0.04143477603793144,
      -0.05858134478330612,
      0.012739477679133415,
      0.01366475410759449,
      0.1331167221069336,
      -0.012431522831320763,
      -0.02927647903561592,
      -0.05693909898400307,
      -0.08528953790664673,
      -0.11674129217863083,
      -0.04308635741472244,
      -0.022913966327905655,
      0.05675862729549408,
      0.07657765597105026,
      -0.05916888639330864,
      -0.056187618523836136,
      -0.06000104546546936,
      0.10120730102062225,
      0.05823579430580139,
      -0.06416544318199158,
      -0.025707516819238663,
      0.004614016506820917,
      0.013609221205115318,
      -0.061773911118507385,
      0.01201967615634203,
      0.01856987178325653,
      0.052554886788129807,
      0.029574409127235413,
      -0.024946117773652077,
      -0.09480717778205872,
      -0.054644957184791565,
      -0.05653277784585953,
      -0.051941707730293274,
      -0.014660650864243507,
      -0.013927571475505829,
      0.04365133121609688,
      0.04090170934796333,
      -0.09217467159032822,
      -0.060365792363882065,
      -0.008898982778191566,
      -0.04036099463701248,
      0.009034119546413422,
      0.013024172745645046,
      -0.010489953681826591,
      -0.01189843937754631,
      0.06097177788615227,
      0.02916613221168518,
      -0.014644765295088291,
      -0.026003655046224594,
      0.030506987124681473,
      0.03985123336315155,
      -0.010836598463356495,
      -0.03272147476673126,
      0.022841323167085648,
      -0.04314592108130455,
      -0.03878984600305557,
      -0.042055461555719376,
      0.07194291055202484,
      -0.11104682087898254,
      -0.06793206930160522,
      0.08069445937871933,
      0.015927420929074287,
      0.08235973864793777,
      0.03724714741110802,
      0.043450817465782166,
      0.10396822541952133,
      -0.05126136541366577,
      -0.06733202189207077,
      -0.006406922359019518,
      -0.12649919092655182,
      0.037219393998384476,
      -0.014134546741843224,
      -5.43648255302287e-8,
      -0.038154441863298416,
      0.02688412554562092,
      0.06659034639596939,
      0.02206563763320446,
      0.02073424682021141,
      -0.10749125480651855,
      0.0471305176615715,
      0.03855712711811066,
      -0.02235051430761814,
      0.02203294448554516,
      0.1562231481075287,
      -0.009207326918840408,
      -0.006244373042136431,
      -0.05851190909743309,
      -0.01769028790295124,
      0.051741451025009155,
      0.013748087920248508,
      0.06375587731599808,
      0.013324975036084652,
      -0.03807293623685837,
      0.02120268903672695,
      0.02078315243124962,
      0.02659108303487301,
      -0.0805724710226059,
      0.1254282146692276,
      -0.04363920912146568,
      -0.0433526411652565,
      0.07078969478607178,
      -0.01705595664680004,
      -0.03326161950826645,
      0.022138752043247223,
      -0.024171054363250732,
      0.016622625291347504,
      -0.013225353322923183,
      -0.018323255702853203,
      -0.005085587501525879,
      0.0007453181897290051,
      0.01090243924409151,
      -0.02023841254413128,
      0.035615142434835434,
      -0.030239326879382133,
      0.04391953721642494,
      -0.054465461522340775,
      -0.019558027386665344,
      -0.002735982183367014,
      -0.07416251301765442,
      -0.006997328717261553,
      -0.019540637731552124,
      0.07781982421875,
      0.007348637096583843,
      -0.00027920660795643926,
      -0.0560702420771122,
      0.06587009876966476,
      0.05436620116233826,
      0.07464998215436935,
      0.06403838098049164,
      0.01300109177827835,
      -0.03161328285932541,
      0.015253853052854538,
      0.03751020133495331,
      0.052419260144233704,
      0.03622864559292793,
      -0.07741686701774597,
      -0.0052313432097435
    ],
    [
      0.006839264649897814,
      -0.013053003698587418,
      0.02145952731370926,
      0.014412404969334602,
      0.012515323236584663,
      0.021394072100520134,
      -0.07114054262638092,
      -0.004908363800495863,
      0.05623853579163551,
      -0.05642860382795334,
      -0.0909905955195427,
      -0.04176672175526619,
      0.006414123810827732,
      0.05290873721241951,
      -0.024032127112150192,
      -0.061115626245737076,
      0.029773132875561714,
      0.04865708202123642,
      -0.0716501921415329,
      0.032141245901584625,
      0.11761263012886047,
      0.006626523099839687,
      0.0730658546090126,
      -0.03491466864943504,
      0.02264717034995556,
      -0.0108387665823102,
      0.016455259174108505,
      -0.03805457428097725,
      -0.030696984380483627,
      -0.03796026110649109,
      0.023945877328515053,
      0.0032399389892816544,
      -0.0024411031045019627,
      0.03974059969186783,
      -0.04985015094280243,
      0.1151762381196022,
      0.037825390696525574,
      0.03108399175107479,
      -0.05336355045437813,
      0.011715630069375038,
      0.016958165913820267,
      0.05364443361759186,
      -0.0030628107488155365,
      -0.013380668126046658,
      0.07839076220989227,
      0.007613144349306822,
      -0.0423438586294651,
      -0.06432060897350311,
      -0.0425286702811718,
      0.020036259666085243,
      -0.053910113871097565,
      -0.032047152519226074,
      -0.047756485641002655,
      0.09990209341049194,
      0.00521471444517374,
      0.03862059488892555,
      -0.08623560518026352,
      -0.021342603489756584,
      -0.03310617431998253,
      -0.021700754761695862,
      -0.0935380682349205,
      0.003966568037867546,
      0.06555959582328796,
      -0.0753442719578743,
      -0.037916816771030426,
      0.06662227213382721,
      -0.0052854460664093494,
      -0.03492796793580055,
      0.0255143865942955,
      0.00894143059849739,
      -0.03404532000422478,
      -0.04869481176137924,
      0.0018101054010912776,
      -0.014326399192214012,
      -0.10473403334617615,
      0.08236858248710632,
      0.13499511778354645,
      -0.04085966944694519,
      0.026234373450279236,
      -0.04923227056860924,
      0.07661262899637222,
      0.013882521539926529,
      -0.006212499458342791,
      -0.05422114208340645,
      0.03581748902797699,
      0.005416334141045809,
      0.013273793272674084,
      0.02026141621172428,
      -0.10403773933649063,
      0.01169158797711134,
      0.0887073501944542,
      -0.012897553853690624,
      -0.02538120374083519,
      -0.009590577334165573,
      0.1099712923169136,
      -0.006309208460152149,
      -0.05902582406997681,
      0.04063212871551514,
      0.015625135973095894,
      -0.019964441657066345,
      0.040782324969768524,
      0.022679686546325684,
      -0.006367584224790335,
      -0.0060550677590072155,
      0.008319685235619545,
      0.0008957609534263611,
      0.10432613641023636,
      -0.054725296795368195,
      0.03415379673242569,
      -0.0297992043197155,
      0.03195108100771904,
      0.06387214362621307,
      -0.0077533721923828125,
      0.009041042067110538,
      0.09914546459913254,
      0.11641878634691238,
      -0.04833937808871269,
      0.06412848085165024,
      0.07877033203840256,
      0.09841743856668472,
      0.006927078124135733,
      -0.056559160351753235,
      0.03342965617775917,
      -0.0995139554142952,
      0.030637871474027634,
      -0.01770167052745819,
      -0.10242965072393417,
      6.046939468591625e-33,
      0.02968961000442505,
      -0.012818767689168453,
      0.007392833475023508,
      0.0043683769181370735,
      -0.022086244076490402,
      -0.0394439734518528,
      -0.033584389835596085,
      0.05679315701127052,
      0.04440930113196373,
      0.046178922057151794,
      -0.09584435075521469,
      0.032631922513246536,
      0.008820928633213043,
      0.04699375480413437,
      -0.004697759635746479,
      -0.012976609170436859,
      -0.1001925840973854,
      0.041141778230667114,
      -0.04342401772737503,
      -0.07142814993858337,
      0.009357460774481297,
      -0.0671103447675705,
      0.03975411877036095,
      -0.01344316452741623,
      -0.021298551931977272,
      0.04915449395775795,
      -0.014591777697205544,
      0.04971400275826454,
      -0.015003800392150879,
      -0.0037197954952716827,
      -0.08713012933731079,
      -0.00873358454555273,
      -0.02207178622484207,
      0.023442132398486137,
      -0.019379375502467155,
      -0.001416172250173986,
      -0.01017972081899643,
      0.06524777412414551,
      0.031824611127376556,
      0.01100553572177887,
      -0.040571779012680054,
      0.08432583510875702,
      0.027197672054171562,
      0.007047856692224741,
      0.040803030133247375,
      -0.03977919742465019,
      0.017717909067869186,
      0.018563272431492805,
      0.04194187372922897,
      -0.013779101893305779,
      -0.010835763067007065,
      -0.08536029607057571,
      -0.016160568222403526,
      -0.12865659594535828,
      -0.041787561029195786,
      0.09325366467237473,
      0.006284117233008146,
      0.057780783623456955,
      -0.019134007394313812,
      0.10151217132806778,
      -0.012342932634055614,
      0.05000351369380951,
      -0.030430302023887634,
      0.03961371257901192,
      0.0014930106699466705,
      0.05625159665942192,
      -0.0960865169763565,
      -0.0057945107109844685,
      0.0195412989705801,
      -0.03873768821358681,
      0.04498763382434845,
      0.0027598205488175154,
      0.07201854139566422,
      -0.06182444095611572,
      0.03508364036679268,
      0.0035996015649288893,
      0.021634498611092567,
      0.07212404161691666,
      -0.09413518756628036,
      -0.02553451620042324,
      0.09361951798200607,
      0.04406168311834335,
      -0.03880038484930992,
      -0.02879299409687519,
      -0.02416246011853218,
      -0.049924496561288834,
      0.02611001953482628,
      0.016965579241514206,
      -0.10182727128267288,
      0.02650631032884121,
      -0.03510952740907669,
      0.057532843202352524,
      0.04335661977529526,
      -0.01753542572259903,
      -0.05478492006659508,
      -4.7542013112183226e-33,
      -0.010969089344143867,
      -0.01175833959132433,
      -0.060470543801784515,
      0.00013332028174772859,
      0.05507952719926834,
      0.03865477815270424,
      0.04239482060074806,
      -0.047119878232479095,
      -0.021730445325374603,
      -0.10376905649900436,
      0.022668015211820602,
      -0.051550090312957764,
      0.021097231656312943,
      -0.023595431819558144,
      0.015078775584697723,
      -0.06309744715690613,
      -0.07647816836833954,
      0.003759770654141903,
      -0.00998552143573761,
      0.10331298410892487,
      0.011027008295059204,
      0.020230058580636978,
      -0.11753088235855103,
      -0.01804894395172596,
      0.026070188730955124,
      0.09658177942037582,
      -0.002241908572614193,
      0.10047046840190887,
      0.037434302270412445,
      -0.10229802876710892,
      0.012103461660444736,
      -0.015466525219380856,
      -0.12429193407297134,
      0.012475314550101757,
      -0.022486554458737373,
      0.07243754714727402,
      0.015355164185166359,
      -0.0028273998759686947,
      -0.060759641230106354,
      -0.06968504935503006,
      0.09456094354391098,
      0.10084658861160278,
      0.001029093167744577,
      -0.014361808076500893,
      0.0022518218029290438,
      0.0420861579477787,
      0.02461119554936886,
      -0.07857014983892441,
      -0.07101752609014511,
      0.004380081780254841,
      -0.02627912349998951,
      -0.009438819251954556,
      -0.11402074247598648,
      0.02729620598256588,
      -0.04560790956020355,
      0.003666914300993085,
      -0.0856868252158165,
      0.030001657083630562,
      -0.005413563456386328,
      0.029265692457556725,
      0.003844107035547495,
      -0.015805548056960106,
      -0.045098502188920975,
      -0.09491950273513794,
      0.04575079306960106,
      0.06528924405574799,
      -0.0026444511022418737,
      -0.008525809273123741,
      0.0561613030731678,
      0.0039970544166862965,
      -0.02969254180788994,
      -0.01770293340086937,
      -0.028187619522213936,
      0.016436493024230003,
      -0.001772780902683735,
      0.010071408934891224,
      0.01372055895626545,
      -0.08141148835420609,
      -0.061687398701906204,
      -0.06640543043613434,
      0.03465762361884117,
      -0.11501672863960266,
      -0.09201139956712723,
      0.06165396422147751,
      0.0046513755805790424,
      0.05710240826010704,
      0.05265292152762413,
      -0.014876598492264748,
      0.08361033350229263,
      -0.017155619338154793,
      -0.06332094967365265,
      0.024786893278360367,
      -0.037559833377599716,
      0.008640834130346775,
      -0.008954700082540512,
      -5.7504266237629054e-8,
      -0.019489185884594917,
      0.008245701901614666,
      0.0637047290802002,
      -0.00034222277463413775,
      -0.0031752074137330055,
      -0.11058193445205688,
      0.048179347068071365,
      0.02066158503293991,
      -0.09392943233251572,
      0.03851354867219925,
      0.09440268576145172,
      -0.013493743725121021,
      0.015147959813475609,
      -0.08752436190843582,
      0.021648677065968513,
      -0.026707181707024574,
      -0.034599971026182175,
      0.10847773402929306,
      0.03095843829214573,
      0.02400004118680954,
      0.051728565245866776,
      -0.01859198324382305,
      -0.044367481023073196,
      -0.03383396565914154,
      0.1310991793870926,
      -0.03380174934864044,
      0.0047189644537866116,
      0.024414297193288803,
      -0.03303098678588867,
      -0.00448412261903286,
      -0.01677069626748562,
      -0.008336175233125687,
      0.06895212829113007,
      -0.0006457799463532865,
      -0.006238542031496763,
      -0.044972486793994904,
      0.09184873104095459,
      -0.0038922724779695272,
      -0.01607460528612137,
      0.09316354244947433,
      -0.009337125346064568,
      -0.02844785712659359,
      -0.05179786682128906,
      -0.004040610510855913,
      -0.02286464162170887,
      -0.10058198124170303,
      0.012816756032407284,
      -0.030828533694148064,
      0.07863987982273102,
      0.019052287563681602,
      0.02431708760559559,
      -0.06357346475124359,
      0.030255427584052086,
      -0.002550209639593959,
      0.03576516732573509,
      0.05048515275120735,
      0.005206721369177103,
      -0.05755965784192085,
      0.004828885197639465,
      0.06677833199501038,
      0.07248891890048981,
      -0.014861413277685642,
      -0.07966624945402145,
      -0.005056231748312712
    ],
    [
      -0.03355849161744118,
      -0.045696113258600235,
      -0.046907227486371994,
      0.08347053080797195,
      0.05048545449972153,
      0.0953800156712532,
      -0.04525284841656685,
      -0.07382890582084656,
      0.0022689790930598974,
      0.02192038670182228,
      -0.08311769366264343,
      -0.10149883478879929,
      -0.03485620766878128,
      0.04727863892912865,
      -0.029666371643543243,
      0.05566982552409172,
      -0.0012130351969972253,
      0.05717971920967102,
      0.031492069363594055,
      0.030636016279459,
      0.059089429676532745,
      -0.013806719332933426,
      0.11180353909730911,
      -0.007180987391620874,
      0.05780124291777611,
      0.003984927199780941,
      -0.001732311095111072,
      -0.019595427438616753,
      0.006438240874558687,
      -0.03425338864326477,
      -0.0012056110426783562,
      0.08501328527927399,
      0.007494606077671051,
      -0.05383872613310814,
      -0.027228111401200294,
      0.017225302755832672,
      0.023848097771406174,
      -0.013618092983961105,
      -0.029811199754476547,
      -0.011650420725345612,
      0.07002139836549759,
      -0.006202885415405035,
      -0.05712967738509178,
      -0.02955949492752552,
      -0.044179122895002365,
      -0.008384385146200657,
      -0.008194836787879467,
      -0.07478935271501541,
      -0.07922806590795517,
      0.03702555224299431,
      0.01888149045407772,
      0.01752074621617794,
      -0.03143490478396416,
      0.0813470110297203,
      0.05280161276459694,
      0.009105050936341286,
      -0.016854608431458473,
      -0.030766893178224564,
      0.05355610325932503,
      0.04135818034410477,
      -0.0619158037006855,
      0.02260790392756462,
      0.04503864422440529,
      -0.11457033455371857,
      0.05066515877842903,
      0.08064274489879608,
      -0.04144252464175224,
      -0.002656039781868458,
      -0.015625281259417534,
      -0.07597780972719193,
      -0.10128746181726456,
      0.009751860983669758,
      0.08273247629404068,
      0.03491191938519478,
      -0.046976085752248764,
      0.028749780729413033,
      0.11237744987010956,
      0.05141834914684296,
      0.07214286923408508,
      -0.11100643873214722,
      -0.034047771245241165,
      0.07591281086206436,
      -0.02603418193757534,
      -0.005348873324692249,
      0.03295144438743591,
      0.09617584943771362,
      0.0425788089632988,
      0.08776627480983734,
      -0.025754641741514206,
      0.01042758859694004,
      0.020765414461493492,
      -0.020031731575727463,
      -0.09599059075117111,
      -0.03627706319093704,
      0.08582514524459839,
      -0.04395129159092903,
      -0.0002566940966062248,
      -0.01857389509677887,
      0.0649048462510109,
      -0.050145260989665985,
      0.04322566092014313,
      0.014381451532244682,
      0.024806931614875793,
      0.06648804992437363,
      0.03929394483566284,
      0.058988381177186966,
      -0.00919722206890583,
      -0.036357298493385315,
      -0.046390146017074585,
      0.009818640537559986,
      -0.05916232988238335,
      0.05906004086136818,
      0.03838181495666504,
      0.058223653584718704,
      0.07056617736816406,
      0.027606450021266937,
      -0.007736539002507925,
      0.07286648452281952,
      0.0958644449710846,
      0.023615753278136253,
      0.0477711521089077,
      0.01979757472872734,
      0.04859689623117447,
      -0.10069381445646286,
      0.010292688384652138,
      -0.07027607411146164,
      -0.13472089171409607,
      3.6570984746004656e-33,
      0.036554086953401566,
      -0.04021025821566582,
      -0.051722705364227295,
      0.017650257796049118,
      -0.004238989669829607,
      -0.005115775391459465,
      -0.03975500911474228,
      0.019244497641921043,
      0.01086274441331625,
      0.08722865581512451,
      -0.06753292679786682,
      0.0391840860247612,
      0.01123909279704094,
      -0.04057679325342178,
      0.06590588390827179,
      0.03888383507728577,
      -0.061201371252536774,
      -0.03737035393714905,
      0.04909539222717285,
      -0.05874389782547951,
      -0.038369402289390564,
      -0.02722824178636074,
      0.050365593284368515,
      0.001818150165490806,
      -0.008536618202924728,
      -0.008110735565423965,
      -0.008362476713955402,
      0.012288111262023449,
      -0.023034414276480675,
      0.030806487426161766,
      -0.038477104157209396,
      -0.03646118566393852,
      0.017743239179253578,
      -0.039691705256700516,
      -0.018264753744006157,
      -0.02467029169201851,
      0.017394596710801125,
      0.002149750478565693,
      -0.09042465686798096,
      0.015094268135726452,
      -0.04408857598900795,
      0.028690949082374573,
      0.013904152438044548,
      -0.01241170521825552,
      -0.03434755280613899,
      -0.009337857365608215,
      0.03723366931080818,
      0.040562476962804794,
      0.0869535282254219,
      -0.038500141352415085,
      0.0405958816409111,
      -0.0867711678147316,
      0.0014959919499233365,
      -0.12401118874549866,
      -0.09776423126459122,
      0.060048095881938934,
      -0.03411763906478882,
      -0.022863149642944336,
      -0.030898839235305786,
      0.026614438742399216,
      -0.04468018189072609,
      -0.048132363706827164,
      0.0029359033796936274,
      -0.013168041594326496,
      0.045562002807855606,
      -0.010180541314184666,
      -0.10446520149707794,
      0.02126213163137436,
      0.0039187208749353886,
      -0.02339480258524418,
      0.03179573267698288,
      0.005937784444540739,
      0.05579517036676407,
      -0.027988668531179428,
      0.036686141043901443,
      0.03149469196796417,
      0.06397231668233871,
      0.05236910656094551,
      -0.08466732501983643,
      -0.10574716329574585,
      0.11946109682321548,
      0.07918433845043182,
      0.02375802956521511,
      -0.040918104350566864,
      -0.028369277715682983,
      -0.060109201818704605,
      0.026837170124053955,
      0.0933951660990715,
      -0.15081937611103058,
      -0.019858388230204582,
      -0.025254959240555763,
      -0.026875607669353485,
      0.05177200958132744,
      -0.05804761126637459,
      -0.024852348491549492,
      -3.0293540018766396e-33,
      -0.027869274839758873,
      -0.041276730597019196,
      -0.011848242953419685,
      -0.0691327452659607,
      -0.0018122665351256728,
      -0.035260625183582306,
      0.03389131650328636,
      -0.06489598751068115,
      -0.06451991200447083,
      -0.06566352397203445,
      0.04214269667863846,
      -0.002602214924991131,
      0.05925748497247696,
      -0.06432222574949265,
      0.07892487198114395,
      -0.04431129992008209,
      -0.07864996045827866,
      0.04767927527427673,
      0.01950695924460888,
      0.06190011650323868,
      -0.04006063938140869,
      0.03871889039874077,
      -0.13453266024589539,
      -0.04785317927598953,
      0.07192522287368774,
      0.07530515640974045,
      -0.016795696690678596,
      0.1239142119884491,
      0.07093940675258636,
      -0.02233358845114708,
      -0.09900295734405518,
      0.013180737383663654,
      -0.07345250248908997,
      -0.040260229259729385,
      0.10426106303930283,
      -0.040001094341278076,
      -0.004638122860342264,
      -0.019332805648446083,
      -0.01644589938223362,
      -0.09054963290691376,
      0.05619259551167488,
      0.06330720335245132,
      -0.05493941158056259,
      0.006209289655089378,
      0.058985140174627304,
      0.044603247195482254,
      -0.03044882044196129,
      0.0005484040011651814,
      -0.029213961213827133,
      0.046253494918346405,
      0.032138947397470474,
      -0.03186895325779915,
      -0.12886805832386017,
      -0.043632231652736664,
      -0.05359087884426117,
      0.049933865666389465,
      0.03454912081360817,
      -0.023746240884065628,
      0.06414906680583954,
      0.019665967673063278,
      0.026552913710474968,
      0.03534248098731041,
      -0.028752390295267105,
      -0.03361178934574127,
      -0.007740188855677843,
      0.044164884835481644,
      -0.00897951703518629,
      -0.01672281324863434,
      0.07440697401762009,
      0.021610794588923454,
      0.025936925783753395,
      0.03353995829820633,
      0.03823240473866463,
      -0.04182826727628708,
      0.009037917479872704,
      -0.021300463005900383,
      -0.003226418048143387,
      -0.01610632799565792,
      0.0024259218480437994,
      -0.003585436614230275,
      0.025142336264252663,
      -0.10252467542886734,
      -0.019901849329471588,
      0.03827610984444618,
      0.03630288690328598,
      -0.04227322340011597,
      -0.020253986120224,
      0.03216521069407463,
      0.10594996064901352,
      -0.08955351263284683,
      -0.03633144870400429,
      -0.0075815171003341675,
      -0.15741141140460968,
      -0.005529776681214571,
      0.007015029434114695,
      -5.14606313117838e-8,
      0.019667336717247963,
      -0.06066317483782768,
      -0.01903483271598816,
      0.08141380548477173,
      0.016252892091870308,
      -0.03760909661650658,
      0.05546536669135094,
      -0.03216473385691643,
      -0.05112411826848984,
      0.02065426856279373,
      0.04057857394218445,
      -0.03949287161231041,
      0.05497374013066292,
      -0.025971079245209694,
      0.006400410085916519,
      0.0328306145966053,
      -0.01455802284181118,
      0.0693284422159195,
      -0.027862735092639923,
      -0.006219248287379742,
      0.03389189764857292,
      0.030571406707167625,
      -0.0003243646933697164,
      0.016015293076634407,
      0.07216763496398926,
      -0.11280941963195801,
      -0.05039951577782631,
      0.03971247747540474,
      0.03277059271931648,
      -0.07804666459560394,
      0.06663832813501358,
      0.00556313619017601,
      0.04660838842391968,
      0.00958919245749712,
      0.017871936783194542,
      0.01498692762106657,
      -0.006626407615840435,
      0.025168821215629578,
      -0.023826412856578827,
      0.12213706970214844,
      0.04739438742399216,
      0.022384099662303925,
      -0.056068260222673416,
      -0.015811484307050705,
      0.020506562665104866,
      -0.06439006328582764,
      0.012912578880786896,
      -0.029805069789290428,
      0.0035112109035253525,
      -0.002067247638478875,
      -0.03078620135784149,
      -0.006609165575355291,
      0.031153809279203415,
      0.034814320504665375,
      0.008541237562894821,
      0.05004558712244034,
      -0.011595717631280422,
      -0.015919193625450134,
      0.00074954325100407,
      0.013661971315741539,
      0.030309515073895454,
      0.04679466784000397,
      0.034966278821229935,
      -0.026498256251215935
    ],
    [
      -0.038291461765766144,
      -0.07157956063747406,
      0.05222432315349579,
      0.013544603250920773,
      0.043469104915857315,
      0.04687725380063057,
      -0.0018006634199991822,
      -0.007709525991231203,
      0.05285866931080818,
      -0.04754846915602684,
      -0.08431816101074219,
      -0.03682929649949074,
      -0.006510126404464245,
      0.0259687639772892,
      -0.058385949581861496,
      -0.0953567624092102,
      0.006924172397702932,
      0.05674339830875397,
      -0.004282407462596893,
      0.005865780171006918,
      0.1409902274608612,
      0.028127923607826233,
      0.08487934619188309,
      -0.011277480982244015,
      -0.02002989500761032,
      -0.015761572867631912,
      0.03024434857070446,
      -0.01634201593697071,
      -0.04912624508142471,
      -0.039112064987421036,
      0.011643733829259872,
      0.03482292219996452,
      0.01340558659285307,
      0.04142168536782265,
      -0.04965643212199211,
      0.02376570925116539,
      -0.021345682442188263,
      -0.029765021055936813,
      -0.09628584235906601,
      0.00920996442437172,
      0.021360039710998535,
      0.018854623660445213,
      0.030160702764987946,
      -0.010857107117772102,
      0.07657209038734436,
      -0.003408772172406316,
      -0.051041219383478165,
      -0.12068828195333481,
      -0.0314343124628067,
      0.042750969529151917,
      -0.027954325079917908,
      -0.020990613847970963,
      -0.009324658662080765,
      0.10631062835454941,
      -0.028052911162376404,
      -0.013343666680157185,
      -0.05857625603675842,
      -0.0030571254901587963,
      0.008783130906522274,
      0.0653209239244461,
      -0.0605383925139904,
      0.012516679242253304,
      0.03597455471754074,
      -0.05424773693084717,
      -0.00999694038182497,
      0.06870485842227936,
      -0.010713420808315277,
      0.01491718739271164,
      0.02371748723089695,
      -0.030542470514774323,
      -0.08043225854635239,
      -0.018829060718417168,
      0.006777511909604073,
      -0.0019254992948845029,
      -0.09821031242609024,
      0.02969198115170002,
      0.14378848671913147,
      0.011427382007241249,
      0.08186562359333038,
      -0.044518157839775085,
      -0.007763667963445187,
      0.05466039851307869,
      0.005504633765667677,
      -0.08625448495149612,
      0.037321142852306366,
      0.027149608358740807,
      0.03893075883388519,
      0.05357830971479416,
      -0.07214938849210739,
      -0.02100672759115696,
      0.07738815993070602,
      -0.05554823577404022,
      -0.030131962150335312,
      -0.01414806954562664,
      0.06864898651838303,
      0.04977282136678696,
      -0.02147730067372322,
      0.04389970377087593,
      0.019563347101211548,
      -0.008638221770524979,
      0.007211305666714907,
      0.08007015287876129,
      0.02750490978360176,
      -0.020929178223013878,
      0.017081931233406067,
      -0.009192937053740025,
      0.052295997738838196,
      -0.011032789945602417,
      0.0650739073753357,
      -0.05252021178603172,
      -0.05357452481985092,
      0.048916902393102646,
      -0.04263387992978096,
      0.006490426603704691,
      0.07339493930339813,
      0.02823418565094471,
      -0.046009182929992676,
      0.025877682492136955,
      0.09316293895244598,
      0.12300451844930649,
      0.034004759043455124,
      -0.042176924645900726,
      0.004922141321003437,
      -0.08926519751548767,
      0.06998495012521744,
      0.0026030424050986767,
      -0.12273848056793213,
      3.392201189984648e-33,
      -0.02806767262518406,
      -0.009772065095603466,
      -0.020756026729941368,
      -0.014550736173987389,
      -0.03675257787108421,
      -0.023728709667921066,
      -0.05232000723481178,
      0.11034203320741653,
      0.019994238391518593,
      0.07218549400568008,
      -0.10599181801080704,
      0.04697580635547638,
      0.005464587826281786,
      0.06422770768404007,
      0.04088214039802551,
      0.026206381618976593,
      -0.05744590982794762,
      0.04302186891436577,
      -0.01365590188652277,
      -0.04687120020389557,
      0.02475569024682045,
      -0.04909006506204605,
      0.08355087041854858,
      -0.009221700020134449,
      -0.005940346512943506,
      0.05875293165445328,
      -0.02010296657681465,
      -0.011283091269433498,
      -0.0549568347632885,
      0.014776328578591347,
      -0.045724205672740936,
      0.007176424376666546,
      0.010963180102407932,
      -0.03144567087292671,
      0.028825482353568077,
      -0.037833284586668015,
      0.030946051701903343,
      0.07754611223936081,
      0.0071961535140872,
      -0.06458345800638199,
      -0.056070275604724884,
      0.03930028900504112,
      -0.00331823225133121,
      0.032230593264102936,
      0.04236046224832535,
      -0.02989448420703411,
      -0.013888116925954819,
      0.02403797209262848,
      0.05700478330254555,
      0.002644556574523449,
      -0.008271584287285805,
      -0.0644349604845047,
      -0.06374327838420868,
      -0.07274746149778366,
      -0.04341581463813782,
      0.09066202491521835,
      0.011587321758270264,
      0.03833406791090965,
      -0.03391028568148613,
      0.053040146827697754,
      -0.020079784095287323,
      0.06256534159183502,
      0.0479799248278141,
      -0.015559392981231213,
      0.04646173492074013,
      0.0218560341745615,
      -0.06555381417274475,
      0.033790215849876404,
      -0.018875325098633766,
      -0.06555996090173721,
      0.043825894594192505,
      -0.040842246264219284,
      0.04898475855588913,
      0.04113258793950081,
      0.03450753912329674,
      0.0234222412109375,
      0.011502450332045555,
      0.026515226811170578,
      -0.12100869417190552,
      -0.008778998628258705,
      0.06573230028152466,
      0.019352693110704422,
      -0.024095404893159866,
      -0.07284656167030334,
      0.013271025381982327,
      -0.06036427617073059,
      0.00828491523861885,
      0.02385105937719345,
      -0.1045248731970787,
      -0.013356552459299564,
      -0.04654765874147415,
      0.040555212646722794,
      0.043571535497903824,
      0.008403140120208263,
      -0.06712137162685394,
      -3.1380519644971766e-33,
      -0.01591726392507553,
      0.02097253128886223,
      -0.07868172228336334,
      -0.01871316507458687,
      0.05053353309631348,
      -0.047891177237033844,
      0.061454758048057556,
      -0.00176116987131536,
      -0.03352167829871178,
      -0.01493059378117323,
      0.028944972902536392,
      -0.0489516481757164,
      0.046303048729896545,
      0.020267227664589882,
      0.04498625546693802,
      0.007416704203933477,
      -0.07036293298006058,
      0.018705304712057114,
      -0.04248746111989021,
      0.13891291618347168,
      0.010345636866986752,
      0.06949792802333832,
      -0.14362867176532745,
      -0.04912959784269333,
      0.0003309636958874762,
      0.06417471170425415,
      0.041209399700164795,
      0.12204858660697937,
      0.016200251877307892,
      -0.08510152250528336,
      -0.03462792560458183,
      -0.04900817573070526,
      -0.08829516172409058,
      0.007485700771212578,
      -0.007601106073707342,
      -0.009350234642624855,
      0.032546572387218475,
      -0.0834612250328064,
      -0.038926366716623306,
      -0.03679361566901207,
      0.10452383011579514,
      0.1052534356713295,
      0.002318848390132189,
      -0.039023980498313904,
      0.020575806498527527,
      -0.0019329292699694633,
      -0.04109756648540497,
      0.017559688538312912,
      -0.012088309973478317,
      -0.020885437726974487,
      -0.019573688507080078,
      0.006755797658115625,
      -0.0771472305059433,
      0.009631158784031868,
      -0.03644081577658653,
      -0.0014283763011917472,
      -0.10314158350229263,
      0.021003611385822296,
      -0.055701639503240585,
      -0.0077450028620660305,
      0.035567134618759155,
      -0.0016133632743731141,
      0.029537394642829895,
      -0.004009875003248453,
      0.0445680096745491,
      0.018946925178170204,
      0.041400689631700516,
      -0.03543821722269058,
      0.03929376229643822,
      -0.045950647443532944,
      0.010847731493413448,
      0.0015118165174499154,
      0.00683405390009284,
      0.08562446385622025,
      -0.027673132717609406,
      -0.012600883841514587,
      0.004151094239205122,
      -0.06396304070949554,
      -0.06175912916660309,
      -0.12114140391349792,
      0.0023553879000246525,
      -0.10929399728775024,
      -0.051146186888217926,
      0.10219991952180862,
      -0.004855941981077194,
      0.0077154855243861675,
      0.0789128988981247,
      0.009807701222598553,
      0.09787789732217789,
      -0.08234485983848572,
      -0.057596247643232346,
      0.04870937392115593,
      -0.06393571943044662,
      0.04918525740504265,
      0.01449545007199049,
      -5.1573788795167275e-8,
      -0.003420318244025111,
      -0.04447363689541817,
      0.07066735625267029,
      0.004871020093560219,
      0.010911324992775917,
      -0.12051041424274445,
      0.03040212206542492,
      -0.0002746804093476385,
      -0.06445194035768509,
      -0.01992672309279442,
      0.11283716559410095,
      -0.007474515121430159,
      -0.016750775277614594,
      -0.05854753032326698,
      0.021166274324059486,
      -0.041319169104099274,
      0.04614043980836868,
      0.08007533103227615,
      0.011922163888812065,
      0.007952677085995674,
      0.05885901302099228,
      -0.024432431906461716,
      0.01241601537913084,
      0.007916228845715523,
      0.13592912256717682,
      -0.02677825465798378,
      -0.008207473903894424,
      0.05344858020544052,
      -0.006025329697877169,
      -0.04320725053548813,
      0.05606774240732193,
      0.03362303599715233,
      0.03439949452877045,
      0.013703789561986923,
      -0.012917552143335342,
      -0.026161378249526024,
      0.06460221111774445,
      -0.023945437744259834,
      -0.02240755595266819,
      0.09724941104650497,
      0.0015879642451182008,
      -0.059715572744607925,
      -0.04479045793414116,
      -0.01160160731524229,
      -0.031300924718379974,
      -0.07441278547048569,
      0.09379009157419205,
      -0.1401437520980835,
      0.08647412806749344,
      0.03808065876364708,
      -0.02170940302312374,
      -0.052723199129104614,
      -0.02431625686585903,
      -0.03949287533760071,
      0.05032395198941231,
      0.015264013782143593,
      0.0326414592564106,
      -0.06498607993125916,
      -0.008566840551793575,
      0.0036275703459978104,
      0.0443180575966835,
      -0.007146697957068682,
      -0.06820712238550186,
      0.013578381389379501
    ],
    [
      -0.030501902103424072,
      -0.052943650633096695,
      -0.016840623691678047,
      0.08452295511960983,
      0.050830114632844925,
      0.03088655322790146,
      -0.022629527375102043,
      0.009916622191667557,
      0.04578559100627899,
      0.000834594713523984,
      -0.05976307764649391,
      -0.06272263824939728,
      0.003756418591365218,
      0.08361564576625824,
      -0.030328411608934402,
      0.04408181086182594,
      -0.011699252761900425,
      0.0480630025267601,
      -0.027193868532776833,
      -0.02800370566546917,
      0.07939335703849792,
      0.07033274322748184,
      0.10252394527196884,
      0.031125880777835846,
      0.008538506925106049,
      0.004515852779150009,
      0.03326398879289627,
      -0.10228656977415085,
      -0.055896129459142685,
      0.0029698689468204975,
      -0.05183239281177521,
      0.10887827724218369,
      0.00010895808372879401,
      0.006099627818912268,
      0.03978467732667923,
      0.009391091763973236,
      0.05935600772500038,
      0.04284033179283142,
      -0.09193529933691025,
      0.023364685475826263,
      0.04174422100186348,
      0.026239948347210884,
      0.011831142008304596,
      -0.06264256685972214,
      -0.06131013482809067,
      -0.03248977288603783,
      -0.10051082074642181,
      -0.09178616106510162,
      0.004885165952146053,
      0.10962888598442078,
      -0.07215062528848648,
      -0.02438075840473175,
      -0.03244556486606598,
      0.10583815723657608,
      0.07943081110715866,
      -0.009401711635291576,
      -0.06471727788448334,
      -0.044192124158144,
      0.04785717651247978,
      0.015007439069449902,
      -0.04829932004213333,
      0.052892837673425674,
      0.026447108015418053,
      -0.04204964265227318,
      0.0644361600279808,
      0.08163902908563614,
      -0.02887050248682499,
      0.00003071027094847523,
      -0.023889033123850822,
      -0.017066406086087227,
      -0.07990933209657669,
      -0.04929835721850395,
      0.010053880512714386,
      0.045017458498477936,
      -0.026806136593222618,
      0.03167816251516342,
      0.09586337953805923,
      -0.0036591568496078253,
      0.07000557333230972,
      -0.095354363322258,
      -0.012506293132901192,
      0.08987290412187576,
      0.02654225006699562,
      -0.054579075425863266,
      0.0034699742682278156,
      0.00022846706269774586,
      0.09527479857206345,
      0.04483272135257721,
      -0.1043982282280922,
      0.023612376302480698,
      0.03304905444383621,
      -0.019101213663816452,
      0.018221743404865265,
      0.023119023069739342,
      0.07452583312988281,
      0.023709505796432495,
      -0.0147273950278759,
      -0.042397934943437576,
      0.013030987232923508,
      -0.04819376766681671,
      0.003168606897816062,
      0.08650324493646622,
      0.055172547698020935,
      0.028098423033952713,
      -0.019114967435598373,
      -0.005578093696385622,
      0.02822166495025158,
      -0.08248790353536606,
      -0.04528062418103218,
      -0.03458981588482857,
      -0.04410545155405998,
      0.026254937052726746,
      0.02395201288163662,
      -0.015801172703504562,
      0.0838051438331604,
      -0.02315976284444332,
      0.0012420082930475473,
      0.06024443358182907,
      0.02031758241355419,
      0.06128481402993202,
      0.005724540911614895,
      -0.022712185978889465,
      0.042609091848134995,
      -0.07235774397850037,
      -0.005281136836856604,
      -0.06297356635332108,
      -0.1454983502626419,
      5.070937896705403e-33,
      0.04771912842988968,
      -0.060563281178474426,
      0.01835372857749462,
      0.01792917773127556,
      -0.010085104033350945,
      -0.09663815796375275,
      -0.05544979125261307,
      0.031247619539499283,
      0.016829341650009155,
      0.025853337720036507,
      -0.07218003273010254,
      0.0016152787720784545,
      0.043418265879154205,
      -0.013109255582094193,
      0.030955608934164047,
      0.0643458366394043,
      -0.02554902248084545,
      0.0029445502441376448,
      -0.05618975684046745,
      0.05274002254009247,
      0.007144100498408079,
      0.007458836305886507,
      0.07175280153751373,
      0.020674709230661392,
      0.004515782929956913,
      0.025224976241588593,
      -0.04711493104696274,
      -0.004173034802079201,
      -0.019924145191907883,
      0.018788164481520653,
      -0.008325167931616306,
      0.008035078644752502,
      -0.029986996203660965,
      -0.02568882144987583,
      -0.017888056114315987,
      -0.020032746717333794,
      0.041402462869882584,
      0.00006579699402209371,
      -0.049655038863420486,
      0.029738223180174828,
      -0.08637432008981705,
      0.02813505195081234,
      -0.05223926901817322,
      0.03939058631658554,
      0.0027770011220127344,
      -0.0256298016756773,
      0.00794392079114914,
      0.029347656294703484,
      0.0256977342069149,
      -0.016428375616669655,
      0.037088509649038315,
      -0.024447768926620483,
      -0.04981604591012001,
      -0.08477120846509933,
      -0.136145681142807,
      0.08832211047410965,
      -0.01746402494609356,
      -0.05703093484044075,
      0.0022979266941547394,
      0.05405319109559059,
      0.04875024035573006,
      -0.045639943331480026,
      0.0008079761173576117,
      -0.06929179280996323,
      0.004909777082502842,
      0.0182163305580616,
      -0.05111442506313324,
      -0.02818654663860798,
      0.00035536233917810023,
      -0.07803742587566376,
      0.030936438590288162,
      -0.01879611797630787,
      0.06070294603705406,
      0.016195230185985565,
      0.061903126537799835,
      -0.04056008160114288,
      0.039989031851291656,
      -0.009148837998509407,
      -0.10974564403295517,
      -0.0056312126107513905,
      0.039576757699251175,
      0.0028262012638151646,
      -0.005462344735860825,
      -0.09939590096473694,
      -0.04797988757491112,
      -0.11544297635555267,
      0.005278247874230146,
      0.0342649482190609,
      -0.14223361015319824,
      -0.03974097967147827,
      -0.06594065576791763,
      -0.015950292348861694,
      0.044870760291814804,
      0.005461299791932106,
      -0.058977339416742325,
      -5.54932883265955e-33,
      -0.022189920768141747,
      -0.054482344537973404,
      -0.0392458476126194,
      -0.08104944229125977,
      0.0046203164383769035,
      -0.017064522951841354,
      -0.007979556918144226,
      -0.05089586228132248,
      0.014369006268680096,
      -0.046036817133426666,
      0.07790778577327728,
      -0.06727688014507294,
      0.024733785539865494,
      -0.06173044443130493,
      0.03671596199274063,
      0.0015134913846850395,
      -0.007047973107546568,
      0.046227797865867615,
      -0.08440220355987549,
      0.05666445195674896,
      0.018812309950590134,
      0.034318603575229645,
      -0.12776057422161102,
      -0.03355110064148903,
      0.051681678742170334,
      0.07803893834352493,
      -0.01086527667939663,
      0.07714631408452988,
      0.004217666108161211,
      -0.003285663668066263,
      -0.011283577419817448,
      0.007272673305124044,
      -0.08539470285177231,
      -0.027197349816560745,
      0.0014402157394215465,
      -0.020710980519652367,
      0.025235414505004883,
      -0.02049379236996174,
      -0.06369362026453018,
      -0.0821387767791748,
      0.11586223542690277,
      0.07386019080877304,
      -0.013671948574483395,
      -0.03699387609958649,
      0.04769153520464897,
      0.030806316062808037,
      -0.07743559777736664,
      0.01724056527018547,
      0.001532968133687973,
      0.024730321019887924,
      0.0950385183095932,
      0.03163663670420647,
      -0.018421104177832603,
      0.026588354259729385,
      -0.02885480970144272,
      0.03266020119190216,
      -0.05866173654794693,
      -0.023078126832842827,
      0.0014658888103440404,
      0.026546550914645195,
      0.02833005227148533,
      -0.027077114209532738,
      -0.051804810762405396,
      0.04402798041701317,
      0.02980281412601471,
      -0.01870109513401985,
      -0.028596900403499603,
      -0.1040683165192604,
      0.010252445936203003,
      -0.01753401756286621,
      0.001935337670147419,
      -0.007145843002945185,
      0.017581123858690262,
      0.023950744420289993,
      -0.02020469680428505,
      -0.03846782445907593,
      -0.0026482336688786745,
      -0.04638281092047691,
      -0.0539688840508461,
      -0.012495914474129677,
      0.0405072346329689,
      -0.12532703578472137,
      0.023385634645819664,
      0.054786454886198044,
      -0.05447198078036308,
      -0.05783073604106903,
      0.11829588562250137,
      -0.020000338554382324,
      0.0897059291601181,
      -0.05023498833179474,
      -0.06681964546442032,
      -0.02081550844013691,
      -0.17452771961688995,
      0.019750412553548813,
      0.019759878516197205,
      -5.498100463796618e-8,
      0.06330733001232147,
      -0.06182998791337013,
      -0.01719539240002632,
      0.04976453632116318,
      0.0005183350876905024,
      -0.027940217405557632,
      0.012199269607663155,
      0.056117378175258636,
      -0.031567174941301346,
      0.09675440192222595,
      0.07839750498533249,
      -0.02623628079891205,
      0.01388508453965187,
      -0.08755888789892197,
      0.011833933182060719,
      0.0093921460211277,
      0.008725530467927456,
      0.05056248977780342,
      0.017116401344537735,
      -0.006347430404275656,
      0.01706697791814804,
      0.008933835662901402,
      -0.018282297998666763,
      -0.0017013205215334892,
      0.09547651559114456,
      -0.03191215544939041,
      0.03101518377661705,
      0.06968409568071365,
      -0.02786155417561531,
      -0.09370364248752594,
      0.05043628811836243,
      0.0024374097120016813,
      0.03729479759931564,
      -0.003584625432267785,
      -0.020732302218675613,
      -0.039184652268886566,
      0.07561124116182327,
      -0.016405800357460976,
      -0.031846556812524796,
      0.13199064135551453,
      0.02561911940574646,
      0.02872864343225956,
      -0.011945907957851887,
      0.005777984857559204,
      0.0644523873925209,
      -0.06392718851566315,
      0.05821211263537407,
      -0.018985722213983536,
      0.11517466604709625,
      0.03894330561161041,
      0.011629299260675907,
      -0.04216040298342705,
      0.037549830973148346,
      -0.00018574825662653893,
      0.047921258956193924,
      0.08393901586532593,
      -0.02597787044942379,
      0.02215665951371193,
      0.017085107043385506,
      -0.011053827591240406,
      0.11153578758239746,
      -0.006165585480630398,
      -0.030486077070236206,
      0.026220930740237236
    ],
    [
      -0.0403028279542923,
      -0.0392315536737442,
      -0.046793192625045776,
      0.11330629140138626,
      0.04117465764284134,
      0.05942467600107193,
      -0.07839608937501907,
      0.02090253308415413,
      0.04959910735487938,
      -0.00341898575425148,
      -0.10842961072921753,
      -0.02390267141163349,
      -0.0013221264816820621,
      0.0331311896443367,
      0.027463164180517197,
      0.05721049755811691,
      0.0685778558254242,
      0.09770909696817398,
      -0.023436924442648888,
      0.05447280406951904,
      0.06644084304571152,
      0.01087433472275734,
      0.08390171825885773,
      0.04164760932326317,
      -0.039691466838121414,
      0.010882498696446419,
      0.020314760506153107,
      -0.03144875168800354,
      -0.12178178876638412,
      0.0011112664360553026,
      -0.011533571407198906,
      0.04554412141442299,
      0.038526032119989395,
      0.010313482955098152,
      0.032348938286304474,
      -0.03405606374144554,
      -0.02439374104142189,
      -0.016566483303904533,
      -0.003596086986362934,
      -0.04218310862779617,
      0.03738800808787346,
      0.006893868092447519,
      0.0005465439171530306,
      -0.00584057904779911,
      -0.05891579017043114,
      -0.05796433240175247,
      0.025529203936457634,
      -0.020260436460375786,
      -0.028016865253448486,
      0.028863154351711273,
      -0.0721350610256195,
      -0.019522804766893387,
      -0.04836755245923996,
      0.11134408414363861,
      0.04262075200676918,
      0.03866690769791603,
      -0.027069099247455597,
      -0.01845388486981392,
      0.005067887715995312,
      0.03631269186735153,
      -0.06223950535058975,
      0.018152957782149315,
      0.06726837158203125,
      -0.03030938096344471,
      0.05195968970656395,
      0.08908096700906754,
      -0.12964577972888947,
      -0.014277328737080097,
      -0.06833996623754501,
      -0.09302174299955368,
      -0.07222583144903183,
      -0.07195497304201126,
      0.03320019692182541,
      0.0605761855840683,
      0.01369137316942215,
      0.055523715913295746,
      0.037648677825927734,
      0.011293294839560986,
      0.012781062163412571,
      -0.06339661777019501,
      0.04333358258008957,
      0.0513639822602272,
      0.058443427085876465,
      0.039894476532936096,
      -0.00863646063953638,
      -0.04326321929693222,
      0.05957862362265587,
      0.11248163133859634,
      0.004806642420589924,
      0.08527478575706482,
      0.08109639585018158,
      -0.03256100043654442,
      0.00041369174141436815,
      -0.011760780587792397,
      0.0445156954228878,
      -0.028897970914840698,
      -0.08833350986242294,
      0.0035376069135963917,
      0.00945988204330206,
      -0.034544941037893295,
      -0.08329115062952042,
      0.07685291022062302,
      -0.007858281955122948,
      -0.03889414295554161,
      -0.012296018190681934,
      0.07487179338932037,
      0.013602233491837978,
      -0.054137587547302246,
      0.019697031006217003,
      0.006144309416413307,
      -0.008451241068542004,
      0.04035281017422676,
      -0.013298261910676956,
      0.03514963760972023,
      0.09135840088129044,
      -0.02065587416291237,
      0.06786951422691345,
      0.09240471571683884,
      0.06561540812253952,
      0.0009638681658543646,
      0.027156705036759377,
      -0.018783211708068848,
      0.10629834979772568,
      -0.09385114163160324,
      0.04896553233265877,
      -0.00930642057210207,
      -0.08239054679870605,
      2.7863699523410647e-33,
      0.05370155721902847,
      -0.006344818975776434,
      0.03184621036052704,
      -0.019912680611014366,
      0.04315464571118355,
      -0.047519393265247345,
      -0.024502983316779137,
      -0.0010727207409217954,
      0.024040570482611656,
      0.04781335964798927,
      -0.04697407782077789,
      -0.032689038664102554,
      -0.014975390397012234,
      0.07444901764392853,
      -0.0025589268188923597,
      0.07950279116630554,
      -0.026598747819662094,
      -0.07791248708963394,
      0.05970826745033264,
      0.0014881185488775373,
      -0.0639989897608757,
      0.003957970067858696,
      0.07122812420129776,
      -0.00030305914697237313,
      -0.026677345857024193,
      -0.005063610151410103,
      0.011271581053733826,
      0.07479618489742279,
      -0.03470369428396225,
      -0.02032180316746235,
      -0.07457823306322098,
      -0.08630263805389404,
      0.11038929969072342,
      -0.026510033756494522,
      0.027289990335702896,
      0.004652440082281828,
      0.0006696786731481552,
      -0.012140732258558273,
      -0.05882583186030388,
      0.008277925662696362,
      0.03782214969396591,
      0.04161607474088669,
      -0.11405466496944427,
      -0.00836868304759264,
      0.009907866828143597,
      -0.049474749714136124,
      -0.03680763021111488,
      0.013792281970381737,
      0.048755742609500885,
      0.08367050439119339,
      0.05055778846144676,
      -0.0005264164065010846,
      -0.028129715472459793,
      -0.057738520205020905,
      -0.04060381278395653,
      -0.04746859148144722,
      0.015292190946638584,
      0.022359805181622505,
      -0.021048173308372498,
      0.03292791172862053,
      -0.05161688104271889,
      -0.05435558781027794,
      0.023665590211749077,
      0.006969748064875603,
      0.08408043533563614,
      0.030547726899385452,
      -0.08749013394117355,
      -0.04870201647281647,
      -0.0803939700126648,
      -0.0313132107257843,
      0.0063888756558299065,
      -0.05472204089164734,
      0.0951070562005043,
      0.05627907067537308,
      -0.005952166859060526,
      -0.04427536949515343,
      -0.00008908568270271644,
      0.03816834092140198,
      -0.011887773871421814,
      -0.07241211086511612,
      0.047944676131010056,
      0.018878838047385216,
      -0.04347047582268715,
      0.016642946749925613,
      -0.06641258299350739,
      0.04852867126464844,
      -0.0001771037932485342,
      0.07300399988889694,
      -0.027278201654553413,
      -0.0684041753411293,
      0.04151224344968796,
      -0.058497995138168335,
      0.05679599568247795,
      0.055858172476291656,
      -0.08746086806058884,
      -3.26753413660819e-33,
      -0.048478614538908005,
      -0.11016293615102768,
      -0.04069899022579193,
      -0.07595013827085495,
      0.02156243473291397,
      0.027587657794356346,
      -0.048481106758117676,
      -0.05033458024263382,
      0.028687262907624245,
      -0.02261197566986084,
      0.05427296832203865,
      -0.0227158572524786,
      0.06005219370126724,
      -0.03660183399915695,
      0.049222175031900406,
      -0.01584249548614025,
      -0.00661828787997365,
      0.02952568046748638,
      -0.07224755734205246,
      0.011053835973143578,
      -0.029877809807658195,
      0.049228109419345856,
      -0.022786956280469894,
      -0.04853905737400055,
      0.03764963522553444,
      0.09312143921852112,
      0.08674675226211548,
      0.1664724200963974,
      0.020270084962248802,
      0.014587325043976307,
      0.026551639661192894,
      0.08224033564329147,
      -0.14286722242832184,
      -0.08952473849058151,
      0.07083971053361893,
      0.0005260894540697336,
      -0.008729711174964905,
      -0.04509074240922928,
      -0.05880662053823471,
      -0.09607554227113724,
      0.059949811547994614,
      0.03944683447480202,
      -0.0346999429166317,
      -0.04072566330432892,
      0.005419990047812462,
      0.06085160747170448,
      0.007126565556973219,
      -0.046702791005373,
      0.006141625810414553,
      0.0278912540525198,
      0.01434287242591381,
      -0.05369345843791962,
      0.00466591352596879,
      -0.018834233283996582,
      -0.0016866055084392428,
      -0.03903908282518387,
      -0.0019157700007781386,
      0.0036776000633835793,
      0.02862507849931717,
      0.0029240453150123358,
      -0.057562876492738724,
      0.06196711212396622,
      0.018496761098504066,
      -0.07487988471984863,
      0.08334150165319443,
      -0.00012703238462563604,
      0.00007903890946181491,
      -0.045286692678928375,
      0.0161365307867527,
      0.005684887524694204,
      0.026123691350221634,
      -0.07201166450977325,
      0.032059360295534134,
      0.02352955751121044,
      -0.029880143702030182,
      0.043370410799980164,
      -0.05530259385704994,
      0.011983086355030537,
      -0.016139019280672073,
      0.055286705493927,
      -0.018873196095228195,
      -0.11616002023220062,
      -0.051735907793045044,
      -0.0025923640932887793,
      -0.053263451904058456,
      -0.058673907071352005,
      -0.00924043357372284,
      0.03921174630522728,
      0.03752835467457771,
      0.04557327181100845,
      -0.023604242131114006,
      -0.03794137388467789,
      -0.06934735924005508,
      -0.019810957834124565,
      -0.03901585936546326,
      -4.908912032419721e-8,
      0.07760979980230331,
      -0.10529973357915878,
      -0.011837544851005077,
      0.019883932545781136,
      0.002085869200527668,
      -0.053512297570705414,
      0.028497496619820595,
      -0.032818883657455444,
      -0.05221925303339958,
      0.05744506046175957,
      0.10588856041431427,
      -0.0049698506481945515,
      0.018403274938464165,
      -0.0036854760255664587,
      -0.05450825020670891,
      0.001938067376613617,
      0.014039348810911179,
      0.00888139195740223,
      0.00295323901809752,
      0.04737977683544159,
      -0.06994116306304932,
      -0.050985969603061676,
      -0.036286842077970505,
      -0.06599349528551102,
      0.11200704425573349,
      -0.0492585152387619,
      0.03916284441947937,
      0.0677337795495987,
      0.010704269632697105,
      -0.05729497969150543,
      0.03542928025126457,
      -0.015454442240297794,
      0.07905109226703644,
      0.02522316575050354,
      -0.05449929088354111,
      -0.09586647152900696,
      0.08916795253753662,
      -0.029934421181678772,
      0.026050012558698654,
      0.08177166432142258,
      0.022619077935814857,
      0.031245499849319458,
      -0.11149513721466064,
      -0.02588401921093464,
      -0.006314069498330355,
      -0.0226389579474926,
      -0.031721848994493484,
      0.04808133468031883,
      -0.02434963919222355,
      -0.027300860732793808,
      -0.044843126088380814,
      -0.0305112823843956,
      0.005892150104045868,
      0.030927639454603195,
      -0.05484630540013313,
      0.03529917076230049,
      0.012882073409855366,
      0.04089963436126709,
      0.050408970564603806,
      -0.10582511872053146,
      0.01156466081738472,
      -0.039704419672489166,
      0.0037797957193106413,
      -0.0342416949570179
    ],
    [
      -0.018114594742655754,
      -0.003416710300371051,
      0.09115419536828995,
      0.14242032170295715,
      0.042088888585567474,
      0.02056185156106949,
      -0.039371307939291,
      -0.008450155146420002,
      0.04983725771307945,
      0.005002560093998909,
      -0.06877303123474121,
      -0.024180304259061813,
      0.017043082043528557,
      0.07002034038305283,
      -0.04743185266852379,
      -0.050560832023620605,
      0.03641814738512039,
      -0.014155464246869087,
      -0.04889320954680443,
      -0.03368676081299782,
      0.06350050866603851,
      0.056483104825019836,
      0.0644184798002243,
      0.107220858335495,
      -0.010361545719206333,
      0.06262774765491486,
      0.026787418872117996,
      -0.01709868758916855,
      -0.08912116289138794,
      -0.005528618115931749,
      -0.03836815804243088,
      0.04721425473690033,
      0.015611863695085049,
      -0.05216096714138985,
      0.009885410778224468,
      0.037488728761672974,
      0.029241785407066345,
      0.07442563027143478,
      -0.07187188416719437,
      0.013399685733020306,
      -0.008122737519443035,
      -0.029657037928700447,
      0.02770734578371048,
      -0.032292596995830536,
      0.031323302537202835,
      -0.017270686104893684,
      -0.07234473526477814,
      -0.08390044420957565,
      -0.07650870829820633,
      0.00906311348080635,
      -0.059449367225170135,
      0.012301314622163773,
      -0.01747044362127781,
      0.07937435060739517,
      0.04757818579673767,
      0.013022804632782936,
      -0.03549238294363022,
      -0.016849976032972336,
      0.02508547157049179,
      0.017871547490358353,
      -0.0101098557934165,
      0.006766264792531729,
      -0.01972254551947117,
      -0.014804132282733917,
      0.05709323287010193,
      0.10496823489665985,
      -0.10334012657403946,
      0.03414624556899071,
      0.013364779762923717,
      0.001738715567626059,
      -0.10319101810455322,
      -0.02915647253394127,
      -0.07186197489500046,
      0.041345953941345215,
      -0.02601492963731289,
      0.09353190660476685,
      0.0914711132645607,
      0.021546341478824615,
      0.07945474237203598,
      -0.025000223889946938,
      -0.005605447571724653,
      0.04653045907616615,
      0.002561471424996853,
      -0.012644533067941666,
      0.043956976383924484,
      -0.007591264322400093,
      0.08399873226881027,
      0.12269902974367142,
      -0.05758679285645485,
      -0.02153584733605385,
      0.015985334292054176,
      0.022375954315066338,
      -0.011921570636332035,
      -0.03221116214990616,
      0.08737863600254059,
      0.006905234884470701,
      -0.002756736474111676,
      -0.018086059018969536,
      0.041397757828235626,
      0.010114425793290138,
      0.027344105765223503,
      0.08384963870048523,
      0.025388548150658607,
      -0.0009838686091825366,
      0.016599001362919807,
      0.012523063458502293,
      0.0050748237408697605,
      -0.023316439241170883,
      0.02626286819577217,
      -0.022548306733369827,
      -0.08964330703020096,
      0.014130587689578533,
      -0.005041067488491535,
      -0.03993438929319382,
      0.08461108058691025,
      0.0670146718621254,
      0.015030443668365479,
      0.07670586556196213,
      0.026699285954236984,
      0.07329616695642471,
      0.06294552236795425,
      -0.05471065640449524,
      0.07011479884386063,
      -0.016255909577012062,
      0.07244950532913208,
      -0.013680546544492245,
      -0.13305822014808655,
      3.392754039671519e-33,
      0.025502754375338554,
      -0.041455548256635666,
      0.0316116064786911,
      0.01762491464614868,
      0.04219520092010498,
      -0.0948135256767273,
      -0.06381615996360779,
      0.016036219894886017,
      0.08629753440618515,
      0.042672619223594666,
      -0.0034850798547267914,
      0.06200891360640526,
      -0.05797743424773216,
      0.0008143577142618597,
      0.04683763533830643,
      0.024796806275844574,
      -0.08683585375547409,
      0.030793245881795883,
      -0.06410405039787292,
      -0.03672665357589722,
      -0.005190372467041016,
      -0.07636076956987381,
      0.0127674899995327,
      0.026020905002951622,
      0.01091006025671959,
      0.05345918610692024,
      0.06809226423501968,
      0.05539197847247124,
      -0.07120733708143234,
      -0.00546378456056118,
      -0.03468058258295059,
      -0.025567034259438515,
      -0.03906140476465225,
      -0.07418809086084366,
      -0.04011276364326477,
      -0.03909878805279732,
      0.03712634742259979,
      -0.006515142973512411,
      0.006943651009351015,
      -0.03067532740533352,
      -0.04438535124063492,
      -0.026260772719979286,
      0.021852869540452957,
      -0.041982658207416534,
      -0.009118599817156792,
      -0.014195299707353115,
      0.07143288850784302,
      -0.04440830647945404,
      -0.012553350999951363,
      -0.004955863580107689,
      -0.030005045235157013,
      -0.04387064278125763,
      -0.04759851470589638,
      -0.10720700770616531,
      -0.12135666608810425,
      0.12891355156898499,
      0.05849626660346985,
      -0.042698971927165985,
      -0.05316329747438431,
      0.07315392792224884,
      -0.014811423607170582,
      0.03323858976364136,
      -0.02065611071884632,
      -0.041008688509464264,
      0.03286535665392876,
      -0.0019169412553310394,
      0.006099467631429434,
      0.073820561170578,
      -0.006855595391243696,
      0.006368615198880434,
      0.016175225377082825,
      -0.0440482497215271,
      0.06447521597146988,
      0.0030918619595468044,
      0.07078434526920319,
      -0.03824423998594284,
      0.00971016101539135,
      0.013402111828327179,
      -0.03983277827501297,
      0.0009731664904393256,
      0.04774489626288414,
      -0.04431252181529999,
      0.02811659872531891,
      -0.11096631735563278,
      -0.020704714581370354,
      -0.06210838630795479,
      0.021789075806736946,
      -0.018724242225289345,
      -0.11484203487634659,
      -0.012729314155876637,
      -0.09481018036603928,
      0.0019350823713466525,
      0.00876199547201395,
      0.06393072754144669,
      -0.08215442299842834,
      -3.6774852200635704e-33,
      -0.09453523904085159,
      -0.06001076102256775,
      -0.029660139232873917,
      0.011212904937565327,
      0.014037190936505795,
      -0.007958420552313328,
      -0.0047984360717237,
      -0.01537317968904972,
      0.045472897589206696,
      -0.10112014412879944,
      -0.002625189023092389,
      -0.07883020490407944,
      0.06656409054994583,
      0.032327327877283096,
      -0.005241035483777523,
      0.07054897397756577,
      -0.03912074863910675,
      -0.031238680705428123,
      -0.036035433411598206,
      0.09627380222082138,
      -0.013122403994202614,
      0.038173381239175797,
      -0.041038017719984055,
      -0.09492407739162445,
      -0.05145444720983505,
      0.06968721002340317,
      0.024740437045693398,
      0.13808917999267578,
      0.007680063135921955,
      -0.03912459313869476,
      0.0017228239448741078,
      -0.06946337223052979,
      -0.12044192105531693,
      -0.03435526043176651,
      -0.013465101830661297,
      0.021570784971117973,
      0.0383438766002655,
      -0.03721648082137108,
      -0.03692134842276573,
      -0.06499207764863968,
      0.12438147515058517,
      0.059788864105939865,
      -0.05300651863217354,
      -0.032493822276592255,
      0.009997048415243626,
      0.027768978849053383,
      -0.06190767139196396,
      -0.016487551853060722,
      -0.0023963626008480787,
      0.04415305331349373,
      0.014043658040463924,
      0.030181273818016052,
      -0.052896227687597275,
      0.07179077714681625,
      -0.041091226041316986,
      -0.016407083719968796,
      0.050366953015327454,
      -0.008510091342031956,
      -0.040966905653476715,
      0.030917145311832428,
      -0.012185895815491676,
      -0.031817998737096786,
      -0.029788345098495483,
      -0.05197274312376976,
      0.08551319688558578,
      0.01106337085366249,
      0.0230155810713768,
      -0.05595311149954796,
      0.02135239727795124,
      -0.01339736208319664,
      -0.023097746074199677,
      -0.013466272503137589,
      -0.004847157746553421,
      -0.025402383878827095,
      0.015507788397371769,
      0.014626258052885532,
      -0.06313785910606384,
      -0.010215080343186855,
      -0.0777493566274643,
      -0.07192640006542206,
      0.012312335893511772,
      -0.1376388520002365,
      -0.023834284394979477,
      0.01576877385377884,
      0.004072913434356451,
      0.01952100731432438,
      0.06324057281017303,
      0.01340900082141161,
      0.0763150155544281,
      -0.03254646435379982,
      -0.06084161996841431,
      0.06665720790624619,
      -0.1159738078713417,
      0.07929540425539017,
      -0.028758209198713303,
      -5.163719052347915e-8,
      0.024087660014629364,
      0.017119454219937325,
      0.03991515561938286,
      -0.01661061868071556,
      0.06989289075136185,
      -0.0902109444141388,
      -0.014058460481464863,
      0.0414716899394989,
      -0.04709431529045105,
      0.035672057420015335,
      0.057642966508865356,
      -0.03126447647809982,
      -0.0155726233497262,
      0.002954239957034588,
      -0.013624227605760098,
      0.0006671943119727075,
      0.05517667159438133,
      0.07620853185653687,
      0.0027823499403893948,
      -0.039050519466400146,
      0.06415275484323502,
      0.002848563715815544,
      -0.07251312583684921,
      -0.04346027970314026,
      0.11996430903673172,
      -0.02230963110923767,
      0.023230360820889473,
      0.06499679386615753,
      0.04942594841122627,
      -0.02629261277616024,
      0.04251638054847717,
      0.0029155495576560497,
      0.03093586675822735,
      -0.04178715869784355,
      -0.019470974802970886,
      0.016644569113850594,
      0.10546393692493439,
      -0.07528183609247208,
      -0.05957338213920593,
      0.0740329697728157,
      -0.04108436033129692,
      0.05857781320810318,
      -0.04901673644781113,
      0.01122395321726799,
      0.0055594355799257755,
      -0.013505118899047375,
      -0.046332038938999176,
      -0.05476729944348335,
      0.06998012214899063,
      0.03561792150139809,
      0.021255124360322952,
      -0.057456642389297485,
      0.046391308307647705,
      0.0022985534742474556,
      0.04907513037323952,
      0.05462915822863579,
      0.08476527035236359,
      0.024542665109038353,
      0.023495592176914215,
      -0.01142547931522131,
      0.04849511384963989,
      -0.012959631159901619,
      -0.06498818099498749,
      0.04428983852267265
    ],
    [
      -0.0039859251119196415,
      -0.05434296652674675,
      0.07728993892669678,
      -0.021301094442605972,
      0.013112742453813553,
      0.013421798124909401,
      0.0400426983833313,
      -0.024440370500087738,
      0.1511179804801941,
      0.030654143542051315,
      -0.028199123218655586,
      -0.026555135846138,
      0.05057096853852272,
      0.016007350757718086,
      -0.002941872226074338,
      -0.044701989740133286,
      -0.01852421462535858,
      -0.02065616101026535,
      -0.03362632542848587,
      0.02370707504451275,
      0.10020249336957932,
      -0.060392484068870544,
      0.010479026474058628,
      -0.05909416824579239,
      -0.026315977796912193,
      0.03763918951153755,
      0.01901897042989731,
      -0.018725911155343056,
      -0.012326788157224655,
      -0.09327363222837448,
      -0.034365732222795486,
      0.04735241085290909,
      -0.024857280775904655,
      -0.0002809882571455091,
      -0.03181668370962143,
      0.004745465703308582,
      0.03197844326496124,
      -0.03319358825683594,
      -0.07767388224601746,
      0.00016655464423820376,
      0.04548915848135948,
      0.00223718723282218,
      0.0037773624062538147,
      -0.0641445443034172,
      0.01430622860789299,
      0.06009340286254883,
      0.030656039714813232,
      -0.15856681764125824,
      -0.0956910252571106,
      -0.00490204244852066,
      -0.012017570436000824,
      0.10045622289180756,
      -0.034044232219457626,
      0.06262265145778656,
      -0.02111729048192501,
      0.02135150507092476,
      0.001287518534809351,
      0.043206725269556046,
      0.022456441074609756,
      0.04411587864160538,
      -0.06845451146364212,
      0.04273942857980728,
      0.07244002819061279,
      -0.06446363031864166,
      0.07689739763736725,
      0.08969752490520477,
      0.000010856300832529087,
      -0.06039780005812645,
      -0.005975362844765186,
      -0.038491036742925644,
      -0.08198285847902298,
      -0.0014273577835410833,
      -0.017849644646048546,
      -0.028318116441369057,
      -0.050840381532907486,
      0.050366681069135666,
      0.0562482625246048,
      -0.022770872339606285,
      0.0036728051491081715,
      -0.09217730164527893,
      -0.04680701345205307,
      0.023262251168489456,
      0.027266576886177063,
      -0.015052160248160362,
      0.028341205790638924,
      0.0011068822350353003,
      0.03384982794523239,
      0.09084255248308182,
      -0.03069152869284153,
      0.04268328845500946,
      0.010026147589087486,
      -0.03953472152352333,
      -0.018146736547350883,
      -0.00912892259657383,
      0.0856037586927414,
      0.06255975365638733,
      0.026478465646505356,
      0.04981636628508568,
      0.11955388635396957,
      -0.03031321056187153,
      0.01543625257909298,
      0.028968721628189087,
      -0.027795862406492233,
      0.04615321755409241,
      -0.0023478693328797817,
      0.022394385188817978,
      0.05183558166027069,
      -0.059510260820388794,
      0.01198927778750658,
      -0.02203935757279396,
      -0.04616805538535118,
      0.0565682128071785,
      0.038467515259981155,
      0.08661123365163803,
      0.026896774768829346,
      0.02729467861354351,
      -0.0748598724603653,
      0.10763604193925858,
      0.12252483516931534,
      -0.027492888271808624,
      0.09426125884056091,
      -0.03933049738407135,
      0.06194201484322548,
      -0.07354000210762024,
      0.03902151435613632,
      -0.027887487784028053,
      -0.06599478423595428,
      7.076051344615936e-33,
      -0.035649918019771576,
      0.0018167586531490088,
      -0.011202109977602959,
      -0.047010041773319244,
      0.011910956352949142,
      -0.020339224487543106,
      -0.04247484728693962,
      0.019564127549529076,
      0.058803655207157135,
      0.05080888047814369,
      -0.049937859177589417,
      0.05039322376251221,
      0.057801198214292526,
      -0.013363045640289783,
      0.010752021335065365,
      0.018849974498152733,
      -0.03035208210349083,
      0.02210995741188526,
      -0.022141017019748688,
      -0.1129569485783577,
      0.050828784704208374,
      -0.02144790068268776,
      0.03633156046271324,
      -0.010418196208775043,
      -0.034417301416397095,
      0.01652591861784458,
      -0.0702214166522026,
      0.0006206708494573832,
      -0.05723525583744049,
      -0.005995892453938723,
      0.006962033454328775,
      0.03109576739370823,
      -0.0338798426091671,
      -0.04628264158964157,
      0.015171392820775509,
      -0.04174923151731491,
      0.07859614491462708,
      0.04234958812594414,
      0.013564273715019226,
      0.003589482279494405,
      0.003374699503183365,
      0.04553356394171715,
      0.006716038566082716,
      0.015151900239288807,
      0.03664287552237511,
      -0.019485898315906525,
      0.046597711741924286,
      0.08241847157478333,
      0.05306458845734596,
      0.010502257384359837,
      -0.08460765331983566,
      -0.09260521829128265,
      0.018627207726240158,
      -0.1063605397939682,
      -0.007506642024964094,
      0.015786541625857353,
      0.00725041376426816,
      0.025973431766033173,
      -0.0340951569378376,
      0.10540155321359634,
      -0.02419949509203434,
      0.0859624519944191,
      0.04291105270385742,
      -0.057606957852840424,
      0.04554113373160362,
      -0.004587275441735983,
      -0.10041174292564392,
      -0.04271285980939865,
      0.02567710541188717,
      -0.02350999228656292,
      0.06995978206396103,
      0.040986157953739166,
      0.04786045849323273,
      -0.02918204851448536,
      0.07806793600320816,
      -0.04817354679107666,
      -0.01907501183450222,
      0.0693715438246727,
      -0.07731543481349945,
      -0.0958266407251358,
      0.008127095177769661,
      -0.025565342977643013,
      -0.0304048340767622,
      -0.08965370059013367,
      -0.0258595272898674,
      -0.022193657234311104,
      0.01927887462079525,
      0.0115181440487504,
      -0.17422768473625183,
      -0.01589992828667164,
      0.06781890988349915,
      -0.03045782446861267,
      0.062165819108486176,
      -0.004449757747352123,
      -0.11279183626174927,
      -6.668879937958266e-33,
      -0.03939079865813255,
      -0.02522878907620907,
      -0.018888477236032486,
      0.01472284272313118,
      0.07223260402679443,
      -0.009020947851240635,
      0.08553555607795715,
      0.0077765570022165775,
      -0.03183864429593086,
      -0.0685872808098793,
      0.07332869619131088,
      -0.025174684822559357,
      -0.0014635997358709574,
      0.005663893185555935,
      0.02823113463819027,
      -0.035862892866134644,
      0.007794292643666267,
      0.09325892478227615,
      -0.009977592155337334,
      0.09703628718852997,
      -0.0714329406619072,
      0.04072682186961174,
      -0.07359579205513,
      -0.031856928020715714,
      0.022424301132559776,
      0.11338102072477341,
      0.03608737885951996,
      0.06632788479328156,
      0.02316214144229889,
      -0.00034403573954477906,
      -0.04972995072603226,
      0.019753839820623398,
      -0.11618088185787201,
      0.024910544976592064,
      0.029951991513371468,
      -0.03846431151032448,
      0.020983897149562836,
      -0.0609775111079216,
      -0.03229577839374542,
      -0.062285687774419785,
      0.08719727396965027,
      0.1312817484140396,
      0.032172512263059616,
      -0.07989653944969177,
      0.028915027156472206,
      0.05609744042158127,
      -0.0395524725317955,
      -0.007446458097547293,
      -0.029632791876792908,
      -0.019334957003593445,
      0.05270460620522499,
      0.022273609414696693,
      -0.06475028395652771,
      -0.0326068215072155,
      -0.028176363557577133,
      0.01824100874364376,
      -0.0167473666369915,
      0.019608426839113235,
      0.0255870521068573,
      0.024715032428503036,
      -0.02331765554845333,
      -0.001551149063743651,
      0.07157779484987259,
      -0.012781037017703056,
      0.004780877381563187,
      0.047526322305202484,
      0.0035113245248794556,
      -0.029625123366713524,
      0.05738363787531853,
      -0.06360994279384613,
      0.029863299801945686,
      -0.03652750700712204,
      0.02066195011138916,
      -0.029673242941498756,
      0.0055144657380878925,
      0.034598011523485184,
      0.030077584087848663,
      -0.04692384600639343,
      -0.025492867454886436,
      -0.10082077234983444,
      -0.07179535180330276,
      -0.03791666030883789,
      -0.09651058912277222,
      -0.061505258083343506,
      -0.07981263101100922,
      0.010163163766264915,
      -0.013536759652197361,
      -0.001149123185314238,
      0.0817401260137558,
      -0.04749840125441551,
      -0.030090458691120148,
      0.027734648436307907,
      -0.06568580120801926,
      0.02846689149737358,
      0.06055057421326637,
      -5.7510625595114107e-8,
      0.04538595676422119,
      -0.05522625148296356,
      0.02991745062172413,
      0.051951345056295395,
      0.03826495632529259,
      -0.019199173897504807,
      0.0718369111418724,
      -0.06235139071941376,
      -0.07465440034866333,
      -0.010298393666744232,
      0.13345159590244293,
      -0.017523426562547684,
      0.058019738644361496,
      -0.07267694920301437,
      0.04771297797560692,
      0.02802959270775318,
      0.00044911581790074706,
      0.02557467669248581,
      -0.016086647287011147,
      -0.05799976736307144,
      0.004328983370214701,
      -0.032770298421382904,
      -0.06537390500307083,
      -0.04542268440127373,
      0.04557779058814049,
      0.043634943664073944,
      -0.027716726064682007,
      -0.03511359170079231,
      -0.014810770750045776,
      -0.07120615988969803,
      0.03076634742319584,
      -0.02311648055911064,
      0.05500255897641182,
      0.0046812319196760654,
      0.019491367042064667,
      -0.04506561905145645,
      0.035046208649873734,
      0.007858434692025185,
      -0.006832416635006666,
      0.12322528660297394,
      -0.026176171377301216,
      -0.08005037903785706,
      -0.08435327559709549,
      0.0073188054375350475,
      0.046662215143442154,
      -0.033272258937358856,
      0.02827063947916031,
      -0.07243264466524124,
      0.00046678874059580266,
      -0.03289054334163666,
      -0.04356661066412926,
      -0.03798506781458855,
      -0.019263798370957375,
      -0.0702725425362587,
      0.009494556114077568,
      0.019438423216342926,
      0.005750584416091442,
      -0.012699867598712444,
      -0.013335766270756721,
      -0.031230328604578972,
      0.11316066980361938,
      0.040986962616443634,
      -0.08506027609109879,
      -0.039435118436813354
    ],
    [
      -0.0862414538860321,
      0.007877588272094727,
      -0.04279585927724838,
      0.08092848211526871,
      -0.034819670021533966,
      0.05688481032848358,
      0.05670889839529991,
      -0.031200192868709564,
      0.13016866147518158,
      0.011861167848110199,
      -0.0652695745229721,
      -0.010418886318802834,
      -0.00362091395072639,
      0.007099635899066925,
      0.02554173581302166,
      0.029399141669273376,
      0.04110652580857277,
      0.03809477761387825,
      -0.03228391706943512,
      0.06643848121166229,
      0.04288046434521675,
      -0.027673417702317238,
      0.049199726432561874,
      -0.017680896446108818,
      -0.01575998030602932,
      0.021116182208061218,
      0.033698756247758865,
      -0.07879845052957535,
      0.025314832106232643,
      0.01190291065722704,
      0.01155026350170374,
      0.14582064747810364,
      -0.06269629299640656,
      -0.03142427280545235,
      -0.013040811754763126,
      -0.005541274324059486,
      -0.022852465510368347,
      0.02248499169945717,
      -0.06399606913328171,
      -0.059791941195726395,
      0.06778506189584732,
      0.05687185749411583,
      -0.1059550940990448,
      -0.03215968608856201,
      -0.023723406717181206,
      0.009319370612502098,
      0.06278865039348602,
      -0.029237858951091766,
      -0.06652818620204926,
      -0.11630746722221375,
      -0.08746565878391266,
      0.026787683367729187,
      -0.03623262047767639,
      0.10952520370483398,
      0.013658602721989155,
      0.03932798653841019,
      0.010665223002433777,
      0.050927694886922836,
      -0.10970843583345413,
      -0.039281755685806274,
      -0.06532592326402664,
      0.026889050379395485,
      -0.0016748529160395265,
      -0.005054608918726444,
      0.13753865659236908,
      0.04203571379184723,
      -0.05556318536400795,
      -0.0012079030275344849,
      0.010546964593231678,
      -0.04638834297657013,
      -0.07263042777776718,
      -0.0081714428961277,
      -0.040153175592422485,
      -0.06700596958398819,
      0.012868172489106655,
      -0.01889510452747345,
      0.04522457718849182,
      0.04050757363438606,
      0.004521229304373264,
      -0.03269201144576073,
      0.028205446898937225,
      0.019189324229955673,
      0.06487478315830231,
      -0.07677284628152847,
      -0.01280367560684681,
      0.08459991216659546,
      0.0404789000749588,
      0.05769861489534378,
      -0.057975150644779205,
      0.050092149525880814,
      0.025442562997341156,
      -0.03868631273508072,
      -0.07582420110702515,
      -0.019592206925153732,
      0.10951287299394608,
      -0.036325156688690186,
      0.04317382350564003,
      0.019994189962744713,
      0.07915903627872467,
      0.015128170140087605,
      0.11212925612926483,
      0.019009053707122803,
      0.008816100656986237,
      -0.022082190960645676,
      0.025935964658856392,
      0.031895216554403305,
      0.02622593194246292,
      -0.07164418697357178,
      -0.02517414465546608,
      0.017166467383503914,
      -0.057721469551324844,
      -0.060241781175136566,
      0.0017366270767524838,
      -0.01661701686680317,
      -0.008252804167568684,
      0.02762899361550808,
      0.029621805995702744,
      0.15168945491313934,
      0.02343423292040825,
      0.011719764210283756,
      0.06839220225811005,
      -0.06650859117507935,
      0.025602979585528374,
      -0.05257784202694893,
      0.03641956299543381,
      0.017989106476306915,
      -0.08405189216136932,
      4.901707485147288e-33,
      -0.0112437903881073,
      -0.06873595714569092,
      -0.035341259092092514,
      -0.034255411475896835,
      0.03373194485902786,
      -0.022450095042586327,
      0.015247486531734467,
      -0.04976467043161392,
      0.012385819107294083,
      0.014607004821300507,
      -0.017966508865356445,
      0.03175170719623566,
      0.08759170770645142,
      0.013402985408902168,
      0.021720172837376595,
      0.014462324790656567,
      -0.10663717985153198,
      -0.03738314285874367,
      0.04148462414741516,
      -0.08938930183649063,
      0.0029954477213323116,
      0.08270261436700821,
      -0.0219525508582592,
      -0.026689432561397552,
      -0.031229620799422264,
      0.03625210002064705,
      0.020253192633390427,
      0.01844729669392109,
      -0.10468719899654388,
      0.000666008039843291,
      0.013451104052364826,
      0.08493614941835403,
      -0.09048602730035782,
      -0.07073867321014404,
      0.0010128222638741136,
      -0.013422748073935509,
      0.029449617490172386,
      0.0008661285974085331,
      -0.04392314329743385,
      -0.08109626173973083,
      -0.025495430454611778,
      -0.021434109658002853,
      -0.032445020973682404,
      0.034731972962617874,
      -0.0019094895105808973,
      -0.014401479624211788,
      0.04311962425708771,
      0.017510205507278442,
      0.0295683816075325,
      -0.04266113415360451,
      0.0022360312286764383,
      -0.09736748039722443,
      -0.07109897583723068,
      -0.07193771749734879,
      -0.06108615919947624,
      -0.008741007186472416,
      0.06505435705184937,
      0.02429153583943844,
      -0.019099511206150055,
      0.03549489378929138,
      -0.08596538752317429,
      -0.04764179512858391,
      0.007403731346130371,
      -0.02866053394973278,
      0.012093435041606426,
      -0.03561091423034668,
      -0.13466399908065796,
      -0.08940146118402481,
      -0.007812539115548134,
      0.030242161825299263,
      0.004060450010001659,
      0.03685920313000679,
      0.06867154687643051,
      0.007642653770744801,
      0.023880546912550926,
      -0.08069731295108795,
      0.015740351751446724,
      0.00996191706508398,
      -0.07586990296840668,
      0.0351712740957737,
      0.07251813262701035,
      0.003479959676042199,
      -0.04061535373330116,
      0.0007730976212769747,
      -0.050063829869031906,
      0.01075590681284666,
      -0.024388257414102554,
      -0.054063234478235245,
      -0.09971096366643906,
      0.0075624375604093075,
      0.017494283616542816,
      -0.032249998301267624,
      0.13274215161800385,
      0.004061052110046148,
      -0.05078742280602455,
      -5.4843456682361704e-33,
      -0.015261281281709671,
      -0.030758272856473923,
      -0.037043966352939606,
      -0.021276837214827538,
      0.07706848531961441,
      -0.013393179513514042,
      -0.04386742040514946,
      0.007315307855606079,
      -0.053048595786094666,
      -0.06858095526695251,
      0.04753195121884346,
      0.03822849690914154,
      0.059753261506557465,
      0.0802174061536789,
      0.00182232609950006,
      -0.02092112973332405,
      0.015963539481163025,
      -0.016545793041586876,
      -0.006207028403878212,
      0.030827099457383156,
      -0.014498275704681873,
      0.022314012050628662,
      -0.05747343227267265,
      -0.060282252728939056,
      0.0252003725618124,
      0.03493889048695564,
      0.10046933591365814,
      0.0734194740653038,
      0.002660581609234214,
      -0.012088604271411896,
      0.004588244948536158,
      -0.09466104209423065,
      -0.12912394106388092,
      0.003827151842415333,
      -0.010586006566882133,
      0.010221457108855247,
      0.06760549545288086,
      -0.021960416808724403,
      -0.09052858501672745,
      -0.115170419216156,
      0.011735481210052967,
      -0.0034702031407505274,
      0.09075658023357391,
      -0.035991597920656204,
      0.028016718104481697,
      -0.010591117665171623,
      -0.05262945219874382,
      0.015553190372884274,
      -0.12714718282222748,
      0.046917058527469635,
      0.04379265755414963,
      0.05600089207291603,
      -0.09078750014305115,
      0.04098116233944893,
      -0.009991778060793877,
      0.0037410161457955837,
      -0.01109446119517088,
      -0.0215365719050169,
      0.05878770351409912,
      0.004677400924265385,
      0.00015370453184004873,
      0.004715678282082081,
      0.04238039255142212,
      0.0265911053866148,
      0.09358453750610352,
      0.021444527432322502,
      0.009878788143396378,
      0.05446323752403259,
      0.048986755311489105,
      -0.06437262147665024,
      0.006773060187697411,
      -0.002534380415454507,
      0.004586217924952507,
      0.05903793126344681,
      0.018297942355275154,
      0.03545165807008743,
      0.00701155373826623,
      -0.02821076102554798,
      -0.011758354492485523,
      -0.011878673918545246,
      -0.052079860121011734,
      -0.054801564663648605,
      -0.01915389485657215,
      0.009495064616203308,
      -0.0648227110505104,
      -0.030444981530308723,
      -0.023674802854657173,
      -0.0024506563786417246,
      0.056795015931129456,
      -0.05421796441078186,
      -0.03194738179445267,
      0.028020741418004036,
      -0.04098252207040787,
      -0.003857131814584136,
      0.019675282761454582,
      -5.5419665301315035e-8,
      0.054827675223350525,
      -0.15210478007793427,
      -0.0022566907573491335,
      0.06730201095342636,
      0.024610571563243866,
      -0.04186601936817169,
      0.09136170148849487,
      0.009011177346110344,
      -0.15553322434425354,
      0.043777402490377426,
      0.06680377572774887,
      0.004083212930709124,
      0.036560751497745514,
      -0.0049682362005114555,
      0.025135107338428497,
      0.0425921231508255,
      -0.00997799914330244,
      0.03365993872284889,
      0.00023848919954616576,
      -0.06683041900396347,
      0.058675043284893036,
      -0.0032376879826188087,
      -0.025990579277276993,
      -0.009115350432693958,
      0.049235932528972626,
      0.00706569105386734,
      -0.04497341811656952,
      -0.019392361864447594,
      -0.05629025027155876,
      -0.03075571171939373,
      0.03220692276954651,
      0.03450702503323555,
      0.08880241960287094,
      0.05525979399681091,
      -0.03701246902346611,
      -0.06875862926244736,
      0.050422653555870056,
      -0.018245795741677284,
      -0.06329817324876785,
      0.10247746109962463,
      0.05180203914642334,
      -0.01126603689044714,
      -0.004693645518273115,
      0.021058565005660057,
      0.054187972098588943,
      -0.06770805269479752,
      0.015871437266469002,
      -0.044703900814056396,
      0.04619399458169937,
      0.05962808057665825,
      0.01256448496133089,
      0.07322851568460464,
      0.023899957537651062,
      -0.01813875511288643,
      -0.023321473971009254,
      0.0004162247641943395,
      0.03547252342104912,
      0.017534950748085976,
      -0.008589152246713638,
      0.040085915476083755,
      0.11796445399522781,
      0.02857353538274765,
      -0.0061371661722660065,
      0.033222347497940063
    ],
    [
      0.03002842888236046,
      0.03979307785630226,
      -0.016291983425617218,
      0.030381035059690475,
      0.030840124934911728,
      0.037359412759542465,
      0.061158061027526855,
      0.0626743957400322,
      0.07081054896116257,
      -0.04672550410032272,
      -0.08688363432884216,
      -0.03405566141009331,
      0.09603482484817505,
      0.04596550017595291,
      -0.03274405375123024,
      -0.04235008358955383,
      0.05435217544436455,
      0.018833057954907417,
      -0.05512959137558937,
      0.014160475693643093,
      0.048738814890384674,
      0.010562125593423843,
      0.07181277126073837,
      0.0651472881436348,
      -0.006721631158143282,
      -0.04825790971517563,
      -0.025520633906126022,
      -0.03872382640838623,
      -0.0565481074154377,
      -0.011179936118423939,
      -0.005920020397752523,
      0.08559457957744598,
      0.06467196345329285,
      -0.003620227100327611,
      -0.04281372204422951,
      -0.04908493161201477,
      -0.03645365312695503,
      0.07591241598129272,
      -0.0553242564201355,
      0.024555645883083344,
      0.03578164055943489,
      -0.017491571605205536,
      0.02827795222401619,
      -0.012183630838990211,
      0.003842191305011511,
      0.009705523028969765,
      -0.1472918540239334,
      -0.04934324696660042,
      -0.07125809788703918,
      0.15124839544296265,
      -0.1355975866317749,
      -0.026561396196484566,
      -0.020016439259052277,
      0.05866774916648865,
      -0.006660762708634138,
      0.031742341816425323,
      0.007094855885952711,
      -0.018847068771719933,
      0.0030123144388198853,
      0.06136861816048622,
      -0.0736469253897667,
      0.010333426296710968,
      -0.01821800135076046,
      0.019657369703054428,
      0.07142225652933121,
      0.06558293104171753,
      -0.05216020345687866,
      -0.012274413369596004,
      -0.01613418385386467,
      -0.03897630795836449,
      -0.07779518514871597,
      0.06441567093133926,
      -0.021572094410657883,
      0.020564021542668343,
      -0.016255829483270645,
      0.035088665783405304,
      0.04345518723130226,
      -0.0740300789475441,
      0.04607706144452095,
      -0.012148949317634106,
      -0.012911845929920673,
      0.05594785511493683,
      0.02813495136797428,
      -0.034912433475255966,
      0.042108748108148575,
      -0.016512230038642883,
      0.10673944652080536,
      0.06987732648849487,
      0.0037963842041790485,
      0.03147143870592117,
      0.02319711446762085,
      0.005755309481173754,
      0.015123599208891392,
      -0.0026477400679141283,
      0.041485659778118134,
      0.006266556680202484,
      -0.013808146119117737,
      -0.039865151047706604,
      0.0003467846545390785,
      0.03977283090353012,
      0.0044624158181250095,
      0.0576288141310215,
      -0.0034949681721627712,
      -0.05860332399606705,
      0.012557320296764374,
      -0.01538589783012867,
      0.014061949215829372,
      -0.0358198918402195,
      0.005679427180439234,
      -0.07501626014709473,
      -0.04413952678442001,
      0.08833584934473038,
      0.0015416431706398726,
      -0.009848017245531082,
      0.026904242113232613,
      0.07485591620206833,
      0.02785833179950714,
      0.10534605383872986,
      0.09328115731477737,
      0.05870679393410683,
      0.004895768593996763,
      -0.036885444074869156,
      0.06919775903224945,
      -0.09113708883523941,
      0.015364715829491615,
      -0.06730769574642181,
      -0.08193042129278183,
      6.153464603373064e-33,
      -0.020093590021133423,
      -0.03636539354920387,
      0.03479098901152611,
      0.011730404570698738,
      -0.006516662891954184,
      -0.04066181927919388,
      -0.07609657943248749,
      0.049429818987846375,
      0.021610653027892113,
      -0.022927962243556976,
      -0.0856439396739006,
      0.06949716061353683,
      -0.004153641406446695,
      0.06020335853099823,
      0.09750954806804657,
      0.03514522686600685,
      -0.025421656668186188,
      0.1001189574599266,
      -0.03610856831073761,
      0.018168039619922638,
      0.02390398271381855,
      -0.029360884800553322,
      0.0711047574877739,
      0.04516679048538208,
      -0.017166994512081146,
      0.029831629246473312,
      -0.03353061154484749,
      0.0480683259665966,
      -0.022915489971637726,
      0.0003122822963632643,
      -0.0679595023393631,
      -0.014393790625035763,
      0.02932192198932171,
      -0.04108564555644989,
      0.014972961507737637,
      -0.04804447293281555,
      0.00029127439484000206,
      -0.007501671556383371,
      0.015985477715730667,
      -0.0242842435836792,
      -0.07336097955703735,
      0.04263455420732498,
      0.06952559947967529,
      -0.015704559162259102,
      -0.049443069845438004,
      0.044025592505931854,
      -0.0028396490961313248,
      0.0014070861507207155,
      -0.037525005638599396,
      -0.02539326436817646,
      -0.0718693733215332,
      0.014830530621111393,
      -0.018325593322515488,
      -0.09077280759811401,
      -0.09559842944145203,
      0.04743676632642746,
      -0.008704823441803455,
      -0.009554342366755009,
      -0.03922528401017189,
      0.012295174412429333,
      0.04963607341051102,
      -0.0025050288531929255,
      0.03479804843664169,
      -0.0611874982714653,
      0.05712032690644264,
      0.056851282715797424,
      -0.011674420908093452,
      -0.04801304265856743,
      0.06712455302476883,
      -0.0831565409898758,
      -0.012894144281744957,
      -0.0012966978829354048,
      0.015620597638189793,
      0.010567926801741123,
      -0.014467630535364151,
      -0.016019238159060478,
      0.033483825623989105,
      0.033180177211761475,
      -0.030363358557224274,
      -0.09190907329320908,
      0.044308289885520935,
      0.004259567707777023,
      -0.061436209827661514,
      -0.0887175053358078,
      0.03187061473727226,
      -0.013360784389078617,
      0.008967314846813679,
      0.020294861868023872,
      -0.1679396778345108,
      0.01475602574646473,
      -0.06642841547727585,
      -0.013962449505925179,
      0.014637998305261135,
      0.05775904655456543,
      -0.0584808848798275,
      -6.680218315655916e-33,
      -0.14237473905086517,
      -0.03369633108377457,
      -0.040115825831890106,
      -0.010739123448729515,
      0.08206215500831604,
      -0.04537978768348694,
      0.009909817017614841,
      -0.051760945469141006,
      -0.03190053254365921,
      0.026629170402884483,
      -0.003286129329353571,
      -0.06867005676031113,
      -0.009679784998297691,
      -0.023877054452896118,
      0.026656953617930412,
      0.0422491729259491,
      -0.04300415515899658,
      0.0594167523086071,
      -0.04892520233988762,
      0.1014900803565979,
      0.025730770081281662,
      0.0895993635058403,
      -0.07706978917121887,
      -0.017531743273139,
      -0.014481239020824432,
      0.10131683200597763,
      0.010727002285420895,
      0.05765718221664429,
      -0.008487202227115631,
      -0.04127340018749237,
      -0.02062835730612278,
      -0.043774962425231934,
      -0.14713609218597412,
      -0.0023516162764281034,
      0.03918590769171715,
      -0.04971231892704964,
      -0.009334544651210308,
      -0.10868653655052185,
      -0.01573016680777073,
      0.010427751578390598,
      0.05556529387831688,
      0.07301577180624008,
      -0.10661108791828156,
      -0.028928358107805252,
      0.03754616156220436,
      0.013029712252318859,
      -0.059453144669532776,
      -0.09897623211145401,
      0.02678811550140381,
      0.014098583720624447,
      -0.011093229055404663,
      0.0035756737925112247,
      -0.059734392911195755,
      0.0581776387989521,
      -0.05480187386274338,
      -0.060631148517131805,
      0.0104000149294734,
      -0.02639508619904518,
      -0.014160767197608948,
      -0.014015410095453262,
      -0.014421224594116211,
      -0.026095112785696983,
      -0.0272819884121418,
      -0.012891123071312904,
      0.09083563089370728,
      0.036383576691150665,
      0.04376588016748428,
      -0.014491311274468899,
      -0.04824268817901611,
      0.03719169646501541,
      0.003798751626163721,
      -0.0029278816655278206,
      0.04040662944316864,
      -0.015221918001770973,
      -0.0388258621096611,
      -0.04004325345158577,
      -0.056441809982061386,
      -0.013128727674484253,
      -0.10337623208761215,
      -0.059546686708927155,
      -0.008340704254806042,
      -0.15436431765556335,
      0.009601944126188755,
      0.08344850689172745,
      -0.056732796132564545,
      -0.018007153645157814,
      0.14888638257980347,
      -0.03672242537140846,
      0.02114083245396614,
      0.02407757379114628,
      0.015882758423686028,
      0.08436070382595062,
      -0.0683961808681488,
      0.054978303611278534,
      -0.014564571902155876,
      -6.569458577132536e-8,
      0.018796473741531372,
      -0.06666270643472672,
      -0.02567819319665432,
      0.049674127250909805,
      -0.013335748575627804,
      -0.04360692948102951,
      -0.07660472393035889,
      -0.015302905812859535,
      -0.07821371406316757,
      0.04680619016289711,
      0.10358192771673203,
      -0.036699358373880386,
      0.06188736483454704,
      -0.030392898246645927,
      0.013585273176431656,
      0.018555443733930588,
      -0.030003244057297707,
      0.09159720689058304,
      -0.03379769250750542,
      0.0028664746787399054,
      0.053888965398073196,
      -0.011137865483760834,
      -0.005329039413481951,
      -0.06259556114673615,
      0.07424845546483994,
      0.017960958182811737,
      0.0034863760229200125,
      0.025992942973971367,
      0.022555509582161903,
      0.026641041040420532,
      0.04979422688484192,
      -0.021675823256373405,
      0.02172241546213627,
      0.022858334705233574,
      0.01634596660733223,
      0.0001009744155453518,
      0.0390213318169117,
      -0.0966050997376442,
      -0.008401883766055107,
      0.12664997577667236,
      -0.015598857775330544,
      0.0012291435850784183,
      -0.08544034510850906,
      0.04925934597849846,
      0.09475880116224289,
      -0.06786725670099258,
      0.038193248212337494,
      -0.018779776990413666,
      0.04986198619008064,
      0.0496852844953537,
      0.02151748351752758,
      -0.044761285185813904,
      -0.017918288707733154,
      0.006888938136398792,
      0.08747057616710663,
      0.0028252964839339256,
      0.0012650166172534227,
      -0.0044516935013234615,
      0.011805077083408833,
      0.0657343864440918,
      0.057740550488233566,
      -0.034118615090847015,
      -0.03287876397371292,
      -0.012779259122908115
    ],
    [
      -0.0029252218082547188,
      -0.04370589926838875,
      -0.014798536896705627,
      0.04738366976380348,
      -0.02133866399526596,
      0.07628532499074936,
      -0.05962241813540459,
      0.044973600655794144,
      0.06432992219924927,
      0.044250890612602234,
      -0.03619738668203354,
      -0.012890295125544071,
      0.052101366221904755,
      0.03811738267540932,
      -0.03554379194974899,
      0.012086627073585987,
      0.05248471349477768,
      0.11111807823181152,
      -0.045831114053726196,
      0.06213783845305443,
      0.09294389188289642,
      0.06304620951414108,
      0.06766421347856522,
      0.01959138549864292,
      0.019199933856725693,
      0.04853196069598198,
      -0.07102160900831223,
      -0.07504535466432571,
      -0.041054610162973404,
      0.01949859969317913,
      -0.035242777317762375,
      0.055432528257369995,
      -0.04260332137346268,
      0.0038138169329613447,
      0.022516965866088867,
      -0.05368011072278023,
      0.014892644248902798,
      0.035857200622558594,
      -0.08934785425662994,
      -0.03389083594083786,
      -0.030238958075642586,
      0.001345180906355381,
      -0.06810463219881058,
      -0.03402959555387497,
      -0.06191636621952057,
      0.005468175280839205,
      -0.056034352630376816,
      -0.0021249353885650635,
      -0.08470108360052109,
      0.06513017416000366,
      0.01993044838309288,
      -0.012301520444452763,
      -0.02955297753214836,
      0.03986286744475365,
      0.004055321216583252,
      0.0015653218142688274,
      -0.0626600980758667,
      -0.0039490084163844585,
      -0.02801666408777237,
      0.04383666813373566,
      -0.09078808128833771,
      0.030735211446881294,
      0.08861759305000305,
      -0.034223854541778564,
      0.05979534983634949,
      0.04742073267698288,
      -0.044891394674777985,
      -0.07454315572977066,
      -0.03019554726779461,
      -0.03530136123299599,
      -0.05314665660262108,
      -0.11070310324430466,
      0.009171012789011002,
      0.0005569051136262715,
      -0.0728866383433342,
      0.004303844645619392,
      0.08252673596143723,
      -0.07132330536842346,
      0.018247483298182487,
      -0.10874123126268387,
      0.06165517121553421,
      0.0670839175581932,
      -0.01380275096744299,
      0.011256551370024681,
      0.014507153071463108,
      0.034291282296180725,
      0.04442233964800835,
      0.12796062231063843,
      -0.0425754152238369,
      0.004656633827835321,
      0.029347186908125877,
      0.010265184566378593,
      -0.11495515704154968,
      -0.0272513497620821,
      0.06327514350414276,
      -0.061479680240154266,
      -0.024915648624300957,
      0.035698968917131424,
      0.014647410251200199,
      -0.07806587219238281,
      0.07066700607538223,
      0.03049447387456894,
      0.040168363600969315,
      0.006681518163532019,
      -0.010197881609201431,
      0.03003351390361786,
      0.06990572065114975,
      -0.12295802682638168,
      -0.0035163527354598045,
      0.03359729424118996,
      -0.014981923624873161,
      0.05413917452096939,
      -0.01841861382126808,
      0.04738385230302811,
      0.10279824584722519,
      0.0757383182644844,
      -0.08689691126346588,
      0.0960005670785904,
      0.04716178774833679,
      0.0070051150396466255,
      0.02057054080069065,
      -0.07920841127634048,
      0.06257708370685577,
      -0.112330861389637,
      0.05935385078191757,
      -0.0030346575658768415,
      -0.05462917685508728,
      4.301855289316567e-33,
      0.04469422250986099,
      -0.03479515761137009,
      -0.010860622860491276,
      -0.011774539947509766,
      0.0013276744866743684,
      -0.0889534056186676,
      -0.00844668224453926,
      0.07621271908283234,
      0.03565305843949318,
      0.02661590650677681,
      -0.011923038400709629,
      -0.021981256082654,
      -0.000290683499770239,
      0.010241161100566387,
      0.012412254698574543,
      0.0683845803141594,
      -0.014741583727300167,
      -0.055675216019153595,
      0.025129515677690506,
      -0.04047041013836861,
      0.025226663798093796,
      0.002394885290414095,
      0.06543972343206406,
      0.04025053232908249,
      -0.009996066801249981,
      -0.043947484344244,
      -0.07832644134759903,
      0.05557939410209656,
      -0.04423734173178673,
      0.009742106311023235,
      0.004590316209942102,
      -0.05292302370071411,
      -0.04688335582613945,
      -0.05931410565972328,
      -0.006077006459236145,
      -0.02289920300245285,
      0.006636683829128742,
      0.026859961450099945,
      -0.06326758116483688,
      0.03637311980128288,
      -0.06665249168872833,
      0.03657021000981331,
      -0.047407910227775574,
      -0.03031766787171364,
      -0.01982075721025467,
      -0.09594420343637466,
      0.005614472087472677,
      0.025170743465423584,
      0.04163585230708122,
      0.008998511359095573,
      0.0370437353849411,
      -0.06427463889122009,
      0.02093086577951908,
      -0.09393924474716187,
      -0.010337695479393005,
      0.02613260969519615,
      0.008349732495844364,
      0.014992943964898586,
      -0.048320360481739044,
      0.0429781936109066,
      -0.0026777847670018673,
      0.039129506796598434,
      -0.01592487096786499,
      0.00015763365081511438,
      0.045033909380435944,
      0.032478295266628265,
      -0.08548389375209808,
      0.03933028504252434,
      -0.01954844780266285,
      -0.023663628846406937,
      0.06494560092687607,
      -0.05100822076201439,
      0.0567798838019371,
      0.009858210571110249,
      0.06399635970592499,
      -0.0027979365549981594,
      0.028301723301410675,
      0.0814727172255516,
      -0.09096085280179977,
      -0.03679625317454338,
      0.07535938918590546,
      0.07250478863716125,
      -0.06785004585981369,
      -0.06884594261646271,
      0.007252840790897608,
      -0.061181873083114624,
      0.030955281108617783,
      0.0627085268497467,
      -0.09483804553747177,
      -0.031049763783812523,
      0.10134418308734894,
      -0.03082314319908619,
      -0.002417525975033641,
      -0.015109354630112648,
      -0.05661388114094734,
      -5.75401729662625e-33,
      -0.03619944304227829,
      0.0012851681094616652,
      -0.013979680836200714,
      -0.012582361698150635,
      0.014982818625867367,
      0.06470924615859985,
      0.013895750977098942,
      -0.002464849269017577,
      -0.00768778333440423,
      -0.12933574616909027,
      0.02789137326180935,
      -0.027705201879143715,
      -0.03219781443476677,
      -0.0027034026570618153,
      0.09323037415742874,
      -0.004402481950819492,
      -0.11538311839103699,
      0.0316837914288044,
      -0.06024380400776863,
      0.07008878886699677,
      0.03692067414522171,
      -0.016544833779335022,
      -0.02594582736492157,
      0.005239509046077728,
      0.06185382604598999,
      0.054526373744010925,
      -0.04206879064440727,
      0.04937908425927162,
      0.06606870889663696,
      -0.03416477516293526,
      0.07419189065694809,
      0.056733325123786926,
      -0.13950952887535095,
      0.011684753000736237,
      0.025474179536104202,
      -0.02446035109460354,
      0.0010300130816176534,
      0.031486187130212784,
      -0.07484328746795654,
      -0.04042578116059303,
      0.01837795600295067,
      0.06603524088859558,
      0.05314895138144493,
      0.042107269167900085,
      0.10867833346128464,
      -0.001382993534207344,
      -0.012753354385495186,
      -0.1269613653421402,
      -0.037148430943489075,
      0.006786833517253399,
      0.02249891497194767,
      0.05087031051516533,
      -0.0632389709353447,
      0.01758190430700779,
      0.037725359201431274,
      0.037307530641555786,
      -0.003469921415671706,
      0.004333608318120241,
      -0.06194085255265236,
      -0.006767971906810999,
      0.038396552205085754,
      0.0507245808839798,
      -0.059272486716508865,
      -0.07198481261730194,
      0.0799681767821312,
      0.004938287660479546,
      -0.0161433145403862,
      0.018029509112238884,
      0.11738734692335129,
      0.010794715955853462,
      -0.06010990962386131,
      -0.08427038043737411,
      -0.028934583067893982,
      0.002315016696229577,
      0.028850391507148743,
      0.06450557708740234,
      0.046561695635318756,
      -0.0003244820691179484,
      -0.033466823399066925,
      0.0032627785112708807,
      -0.013390828855335712,
      -0.021350592374801636,
      -0.022954387590289116,
      -0.007791025098413229,
      -0.01149836927652359,
      0.008189821615815163,
      -0.020690808072686195,
      -0.06350957602262497,
      0.12240643799304962,
      -0.03625568747520447,
      -0.028964128345251083,
      -0.0022656249348074198,
      -0.09386807680130005,
      -0.005333369132131338,
      0.0009476025006733835,
      -5.270799974255169e-8,
      -0.019219350069761276,
      -0.017986798658967018,
      0.03766782209277153,
      0.03355032950639725,
      -0.0023042771499603987,
      -0.045521389693021774,
      0.08627603948116302,
      -0.045698270201683044,
      -0.04829811677336693,
      0.08016661554574966,
      0.07103601098060608,
      -0.027602100744843483,
      0.05678499862551689,
      -0.08320526033639908,
      0.00523553928360343,
      -0.019743159413337708,
      -0.008939680643379688,
      0.037689223885536194,
      0.020005445927381516,
      0.03977598249912262,
      0.02795698493719101,
      -0.04311438649892807,
      -0.058750227093696594,
      -0.028150178492069244,
      0.03503939509391785,
      -0.08261838555335999,
      -0.020845741033554077,
      -0.022684821859002113,
      0.000053901512728771195,
      -0.03979871794581413,
      -0.0019914028234779835,
      -0.004130270332098007,
      0.010325646959245205,
      -0.04690200835466385,
      0.013024658896028996,
      -0.08158683031797409,
      0.1014251559972763,
      0.018682638183236122,
      -0.030130678787827492,
      0.1762407124042511,
      0.018211178481578827,
      0.003699067747220397,
      -0.013354821130633354,
      0.014272605068981647,
      0.08776532858610153,
      -0.05862998589873314,
      -0.014976898208260536,
      -0.06714921444654465,
      0.0012974417768418789,
      -0.09462250024080276,
      -0.0629551038146019,
      -0.041259657591581345,
      -0.036665283143520355,
      0.005465612281113863,
      -0.08661272376775742,
      0.045709505677223206,
      -0.03692621737718582,
      0.024242153391242027,
      -0.0011134302476420999,
      -0.07485219091176987,
      0.004237193148583174,
      0.011388423852622509,
      -0.02560371160507202,
      -0.0070338076911866665
    ]
  ],
  "metadatas": [
    {
      "filename": "Paper_10_Automatic_sleep_stage_classification_with_deep_res.pdf",
      "title": "Paper_10_Automatic_sleep_stage_classification_with_deep_res.pdf"
    },
    {
      "filename": "Paper_11_Cord_blood_vitamin_D_level_and_night_sleep_duratio.pdf",
      "title": "Paper_11_Cord_blood_vitamin_D_level_and_night_sleep_duratio.pdf"
    },
    {
      "filename": "Paper_12_Sleep_and_its_relation_to_cognition_and_behaviour_.pdf",
      "title": "Paper_12_Sleep_and_its_relation_to_cognition_and_behaviour_.pdf"
    },
    {
      "filename": "Paper_15_Diversity_and_noise_effects_in_a_model_of_homeosta.pdf",
      "title": "Paper_15_Diversity_and_noise_effects_in_a_model_of_homeosta.pdf"
    },
    {
      "filename": "Paper_14_Sleep_time_Compute__Beyond_Inference_Scaling_at_Te.pdf",
      "title": "pr title Body: pr body File: file1 filename Status: file1 status Patch: file1 patch ... (some more files and some more relevant pull requests) When the sleep-time compute is turned on, we first use the following prompt to ask the agent to explore the repository with all pull requests one by one: 25"
    },
    {
      "filename": "Paper_13_Dynamic_gNodeB_Sleep_Control_for_Energy_Conserving.pdf",
      "title": "Paper_13_Dynamic_gNodeB_Sleep_Control_for_Energy_Conserving.pdf"
    },
    {
      "filename": "Paper_18_Quantification_of_Sleep_Fragmentation_Through_the_.pdf",
      "title": "Paper_18_Quantification_of_Sleep_Fragmentation_Through_the_.pdf"
    },
    {
      "filename": "Paper_16_Night_sleep_duration_trajectories_and_associated_f.pdf",
      "title": "Paper_16_Night_sleep_duration_trajectories_and_associated_f.pdf"
    },
    {
      "filename": "Paper_19_SWS_promoting_MHb_IPN_MRN_circuit_opposes_the_thet.pdf",
      "title": "Paper_19_SWS_promoting_MHb_IPN_MRN_circuit_opposes_the_thet.pdf"
    },
    {
      "filename": "Paper_17_Data_Efficient_Sleep_Staging_with_Synthetic_Time_S.pdf",
      "title": "Paper_17_Data_Efficient_Sleep_Staging_with_Synthetic_Time_S.pdf"
    },
    {
      "filename": "Paper_1_Sleep_Staging_from_Electrocardiography_and_Respira.pdf",
      "title": "Paper_1_Sleep_Staging_from_Electrocardiography_and_Respira.pdf"
    },
    {
      "filename": "Paper_3_Fetal_Sleep__A_Cross_Species_Review_of_Physiology_.pdf",
      "title": "Paper_3_Fetal_Sleep__A_Cross_Species_Review_of_Physiology_.pdf"
    },
    {
      "filename": "Paper_20_Sleep_Model____A_Sequence_Model_for_Predicting_the.pdf",
      "title": "Paper_20_Sleep_Model____A_Sequence_Model_for_Predicting_the.pdf"
    },
    {
      "filename": "Paper_2_A_Large_Collection_of_Real_world_Pediatric_Sleep_S.pdf",
      "title": "Paper_2_A_Large_Collection_of_Real_world_Pediatric_Sleep_S.pdf"
    },
    {
      "filename": "Paper_4_Microbes_in_the_Moonlight__How_the_Gut_Microbiota_.pdf",
      "title": "Microbes in the Moonlight: How the Gut Microbiota Influences Sleep  Author: Enso O. Torres Alegre  Affiliation: Pontifical Catholic University of Chile, Santiago, Chile  Email: onill@uc.cl  ORCID: https://orcid.org/0000 - 0002 - 6798 - 8776  Co - authors: None  Conflict of Interest Statement  The author declares no conflicts of interest related to this work.  Funding Statement  No external funding was received to support the preparation of this manuscript.  Data Availability Statement  No new datasets were generated or analyzed for this review. All data discussed in the  manuscript are derived from previously published studies cited in the References  section.  Ethics Approval Statement  Ethics approval was not required for this review article, as it does not involve new  human or animal research.  Patient Consent Statement  Not applicable. This article does not contain any studies involving human  participants.  Permission to Reproduce Material  Figures created using BioRender.com are original to the author. No previously  published material was reproduced.  Clinical Trial Registration  Not applicable. This manuscript does not report results of a clinical trial."
    },
    {
      "filename": "Paper_5_Quantified_Sleep__Machine_learning_techniques_for_.pdf",
      "title": "Paper_5_Quantified_Sleep__Machine_learning_techniques_for_.pdf"
    },
    {
      "filename": "Paper_7_Permutation_time_irreversibility_in_sleep_electroe.pdf",
      "title": "Paper_7_Permutation_time_irreversibility_in_sleep_electroe.pdf"
    },
    {
      "filename": "Paper_6_Quantum_Anti_Zeno_Treatment_of_Zeno_type_Sleep_Dis.pdf",
      "title": "Paper_6_Quantum_Anti_Zeno_Treatment_of_Zeno_type_Sleep_Dis.pdf"
    },
    {
      "filename": "Paper_9_Multi_Scored_Sleep_Databases__How_to_Exploit_the_M.pdf",
      "title": "Paper_9_Multi_Scored_Sleep_Databases__How_to_Exploit_the_M.pdf"
    },
    {
      "filename": "Paper_8_Brain_Damage_and_Motor_Cortex_Impairment_in_Chroni.pdf",
      "title": "Paper_8_Brain_Damage_and_Motor_Cortex_Impairment_in_Chroni.pdf"
    }
  ],
  "_documents": [
    {
      "id": "doc_0_1765979788191",
      "fileName": "Paper_10_Automatic_sleep_stage_classification_with_deep_res.pdf",
      "content": "1 of 28  TITLE PAGE  Title  Automatic sleep stage classification with deep residual networks in a mixed-cohort setting  Authors and affiliations  Alexander Neergaard Olesen 1,2,3 , Poul Jennum 3* , Emmanuel Mignot 2* , Helge Bjarup Dissing S√∏rensen 1* ,  1 Department of Health Technology, Technical University of Denmark, Kgs. Lyngby, Denmark  2 Stanford Center for Sleep Sciences and Medicine, Stanford University, Palo Alto, CA, USA  3 Danish Center for Sleep Medicine, Department of Clinical Neurophysiology, Rigshospitalet, Glostrup, Denmark  *These authors have contributed equally  Corresponding author  Alexander Neergaard Olesen , aneol@dtu.dk  Department of Health Technology, Technical University of Denmark  √òrsteds Plads, building 349, room 010  2800 Kgs. Lyngby, Denmark  Institution where work was performed  Stanford Center for Sleep Sciences and Medicine, Stanford University  Department of Health Technology, Technical University of Denmark\n\n2 of 28  ABSTRACT  Study Objectives:   Sleep stage scoring is performed manually by sleep experts and is prone to subjective interpretation  of scoring rules with low intra- and interscorer reliability. Many automatic systems rely on few small-scale databases for  developing models, and generalizability to new datasets is thus unknown. We investigated a novel deep neural network  to assess the generalizability of several large-scale cohorts.  Methods:   A deep neural network model was developed using 15.684 polysomnography studies from five different  cohorts. We applied four different scenarios: 1) impact of varying time-scales in the model; 2) performance of a single  cohort on other cohorts of smaller, greater or equal size relative to the performance of other cohorts on a single cohort; 3)  varying the fraction of mixed-cohort training data compared to using single-origin data; and 4) comparing models trained  on combinations of data from 2, 3, and 4 cohorts.  Results:   Overall classification accuracy improved with increasing fractions of training data (0.25%: 0.782 ¬± 0.097, 95%  CI [0.777 ‚Äì 0.787]; 100%: 0.869 ¬± 0.064, 95% CI [0.864 ‚Äì 0.872]), and with increasing number of data sources (2: 0.788  ¬± 0.102, 95% CI [0.787 ‚Äì 0.790]; 3: 0.808 ¬± 0.092, 95% CI [0.807 ‚Äì 0.810]; 4: 0.821 ¬± 0.085, 95% CI [0.819 ‚Äì 0.823]).  Different cohorts show varying levels of generalization to other cohorts.  Conclusions:   Automatic sleep stage scoring systems based on deep learning algorithms should consider as much data as  possible from as many sources available to ensure proper generalization. Public datasets for benchmarking should be  made available for future research.  Keywords  Automatic sleep stage classification, computational sleep science, machine learning, deep learning\n\n3 of 28  STATEMENT OF SIGNIFICANCE  Manual annotation of polysomnography studies is subject to human bias with multiple studies showing variations in how  sleep experts score sleep. Most research in automatic sleep stage classification models use small-scale data from a single  origin, and it is unknown how these models generalize to new data. We developed an algorithm for automatic scoring of  sleep stages using raw polysomnography data and obtain state-of-the-art classification performance on a large number of  test subjects. Our algorithm was tested under different conditions to compare generalizability. We found that using data  from many different sources improves classification performance, and that models trained on single-origin data generalize  inconsistently to new data. Future researchers should take multiple datasets into account when developing sleep scoring  models.\n\n4 of 28  INTRODUCTION  Sleep staging is important to the analysis of human sleep with about 845,000 sleep studies performed in 2014 in the US  alone 1 .   Briefly,   a   standard   clinical   sleep   study   consists   of   a   full-night   polysomnography   (PSG)   comprising  electroencephalography (EEG), electrooculography (EOG), electromyography (EMG), electrocardiography (ECG),  thoraco-abdominal inductance plethysmography, oronasal thermal flow, nasal pressure, and blood saturation recordings.  These studies are then evaluated by experts for the presence of events of clinical relevance, as determined by standards  created by the American Academy of Sleep Medicine (AASM), such as the number of blood oxygen desaturations, micro-  arousals, leg movements, periods of cessated breathing, etc. Furthermore, the overall sleep architecture is captured in a  hypnogram conducted by labeling every 30 s of PSG data into one of five stages of sleep: wakefulness (W), rapid eye  movement (REM) sleep, and non-REM stage 1, 2, and 3 (N1, N2, N3). The latter three stages are distinguished by distinct  EEG amplitude and frequency distributions, the presence of specific EEG micro-events and arousability differences  reflecting sleep depth. Sleep stage labeling is summarized in key metrics, such as the percentage of total sleep time (TST)  spent in any of the five stages (%W, or wake after sleep onset, WASO; %REM; %N1; %N2; %N3), and visually in the  form of a hypnogram, which shows temporal progression of sleep stages across the night. Current clinical practice (gold  standard) of sleep study analysis is manual scoring and annotation of sleep stages and sleep events based on guidelines  from the AASM 2 .   These guidelines, based on observations made in healthy young males almost 70 years ago are  problematic for several reasons: a) technicians will never score the same data the exact same way as another technician,  or even the same way twice 3‚Äì7 ; b) normal sleep from healthy young males may not reflect sleep patterns of patients  referred to sleep clinics; and c) the 30 s epoch rule is arbitrary and was based on physical limitations of recording  equipment when PSGs were recorded on paper.  Automatic sleep stage classification has not yet seen wide-spread adoption in clinical practice despite ongoing research  demonstrating feasibility and industrial interests 8 . A major issue has been a lack of available data for designing and  training models. The publicly available PhysioNet Sleep-EDF and the expanded version 9,10   has been used extensively for  training both shallow and deep learning-based machine learning models 11‚Äì13 , but given its small sample size and  homogeneity (most papers use the same healthy 20 subjects), it is questionable how well models derived from this data  generalize to unseen data, even if high classification performance is often reported 8 . Other databases which have been  extensively used include the St. Vincent‚Äôs University Hospital and University College Dublin Sleep Apnea Database ( ùëõ   =  25 ) 9,14 , and the Montreal Archive of Sleep Studies (MASS,   ùëõ   = 200 ) 13,15‚Äì19 . The argument for using deep learning-based  models to classify high-dimensional electrophysiological data, e.g. PSGs, into discrete outcomes such as sleep stages is  compelling, because of their ability to capture variability in the underlying, highly complex, data representations, that\n\n5 of 28  might be missed by machine learning methods relying on manual feature engineering. In the image, speech, and natural  language processing domains, the success of deep learning models using untransformed data have been unsurpassed in  the last decade, thanks largely due to the availability of ever-increasing amounts of compute resources and more  significantly very large, robust and diverse datasets 20 .  Recently deep learning models for automatic sleep stage classification have been developed and validated using two or  more databases or cohorts 21‚Äì23 , or using a single large volume cohort 22,24,25 . The assumption has been that by incorporating  multiple sources of variance in the dataset used for training (e.g. from multiple technicians, sites, recording setups,  equipment, etc.), final models will be better at generalizing to new, unseen data. However, no study to date has  investigated multiple, large-scale cohorts for automatic sleep stage classification, or how different cohorts generalize to  one another.  In this work, we describe a deep learning-based sleep stage classification algorithm trained and validated on raw PSG  data from multiple, large-scale cohorts for a total of 15,684 studies, that outputs a probability distribution over all sleep  stages at a given time resolution. Considering the amount of data available, our aim was to evaluate: 1) how well does  performance of individual cohorts generalize to others; 2) how much data is needed for accurate sleep staging; 3) how  many cohorts are necessary for that same goal; and 4) which is better, more data, or more diverse data. To our knowledge,  this is one of the largest, if not the largest, study on automatic sleep stage classification in terms of PSG volume and  diversity.\n\n6 of 28  METHODS  Cohort descriptions  To investigate and conclude on generalizability of any machine learning or sleep stage classification model, multiple  heterogenous datasets must be used for training, validation and testing purposes. In this work, we collected datasets from  five different sources, each dataset containing a diverse collection of subjects presenting with multiple disease phenotypes.  Details of the separate cohorts are shown in Table 1 along with reported   p -values highlighting cohort differences. Each  cohort was split into a training, validation and testing   subset   in proportions of 87.5%, 2.5% and 10%, respectively, using  random sampling without replacement among unique subjects, so that no subject is shared between subsets. With these  percentages, we maximize the number of PSGs available for training, while still reserving enough PSGs for validation  and testing. Collecting all the separate subsets across cohorts forms a training, validation, and testing   partition , containing  the respective subsets from all five cohorts.  Institute of Systems and Robotics, University of Coimbra Sleep Cohort (ISRUC)  This cohort contains 126 recordings from 118 unique subjects recorded at the Sleep Medicine Centre of the Hospital of  Coimbra University, Portugal, in the period 2009‚Äì2013 26 . The cohort comprises three subgroups: subgroup I contains 100  PSGs of subjects with diagnosed sleep disorders, generally sleep apnea; subgroup II contains 16 recordings of eight  subjects most of which are also diagnosed with sleep apnea; and subgroup III contains recordings from 10 subjects with  no diagnosed sleep disorders. All PSGs were recorded with the same recording hardware and software and each was  scored by two technicians for sleep stages and sleep events according to the AASM guidelines. ISRUC-Sleep is a freely  accessible resource and all data and PSG files can be located at https://sleeptight.isr.uc.pt/ISRUC_Sleep/.  The MrOS Sleep Study (MrOS)  The MrOS sleep study is part of the larger Osteoporotic Fractures in Men Study, which aims to understand the  relationships between sleep disorders, fractures, and vascular diseases in community-dwelling men 27‚Äì29 . It consists of  2,907 in-home PSG recordings with an additional 1,026 follow-up PSG studies from subjects recruited from six different  clinical centers in the USA. Each recording was annotated by an expert technician according to Rechtschaffen and Kales  (R&K) criteria for sleep staging 30 . For compatibility with AASM guidelines, we combined stages labeled S3 and S4 into  N3. All data were accessed from the National Sleep Research Resource (NSRR) repository 31,32 .  The Sleep Heart Health Study (SHHS)\n\n7 of 28  The SHHS is a large, multi-center study on cardiovascular outcomes related to sleep disorders with a specific focus on  sleep-disordered breathing 33,34 . The cohort consists of 6,441 subjects above 40 years old recruited between 1995 and 1998  undergoing in-home PSG (SHHS Visit 1) with subsequent follow-up PSG between 2001 and 2003 in 3,295 subjects  (SHHS Visit 2). PSG recordings were annotated for sleep stages by trained and certified technicians according to R&K  rules. From the original cohort we extracted 5,793 PSGs and annotations from Visit 1, and 2,651 from Visit 2, and  aggregated S3 and S4 stages into N3 similar to MrOS. All data were accessed from NSRR repository.  Wisconsin Sleep Cohort (WSC)  WSC is a population-based study of sleep-disordered breathing in government workers in Wisconsin, USA that was  initiated in 1988 35,36 . In this work, we used 2412 PSGs from 1091 unique   subjects in the WSC sample scored by expert  technicians according to R&K rules with subsequent merging of S3 and S4 into N3.  Stanford Sleep Cohort (SSC)  PSGs from this cohort originate from patients referred for sleep disorders evaluation and recorded at the Stanford Sleep  Clinic since 1999. The specific sample used in this study represents a small subset ( n   = 772) of the whole cohort, which  was selected and described in detail in previous studies 37,38   scored according to R&K or AASM guidelines according to  prevailing standard at the time of evaluation.  Signal pre-processing pipeline  Electrophysiological signals corresponding to the minimum acceptable montage for sleep staging available across all  cohorts were extracted for each PSG. These included a central EEG (either C3 or C4 referenced to the contra-lateral  mastoid), left and right EOG referenced to the contra-lateral mastoid, and a single submentalis EMG. The choice between  C3 and C4 was determined based on the lowest total signal energy across the entire duration of the PSG to avoid excessive  signal popping. Other methods to determine appropriate channels include algorithms based on shortest Mahalanobis  distance to an already determined reference distribution 21 , but was not investigated in this study. All signals were  resampled to   f s   = 128 Hz   using a polyphase filtering procedure irrespective of original sampling frequency; and  subsequently filtered using a zero-phase approach with 4 th   order Butterworth IIR filters (0.5 to 35 Hz band pass for EEG  and EOG; 10 Hz high pass for EMG) in accordance with AASM filter specifications 2 . Each signal was normalized to zero  mean and unit variance to accommodate differences in recording equipment and baselines; and to compress the dynamic  range into something easily trainable for the neural network architecture. We denote by   ùê∂   the number of input signals  supplied to the neural network, where in this case   ùê∂   = 4 .\n\n8 of 28  Machine learning problem  We designate by   ùí≥   ‚àà ‚Ñù ‡Æº √ó ‡Øç   the set of 30 s input data segments with   C   input channels and segment length   T , and the  corresponding classifications by   ùí¥   =   { ùë¶   ‚àà ‚Ñù ‡¨æ  ‡ØÑ   | ‚àë   ùë¶ ‡Øú   = 1 ‡Øú   } , where   K   = 5 corresponds to the five sleep stages. Thus,   ùë¶   is a  probability simplex, which maps to the ordered set   ùíÆ   =   { W, N1, N2, N3, REM }   by the argmax function such that  argmax   ùë¶   ‚à∂   ùí¥   ‚Üí   ùíÆ . Furthermore, as we are potentially interested in classifying multiple sleep stages at once, we extend  the problem of classifying a single sleep stage given   ùë•   ‚àà   ùí≥   to a sequence-to-sequence problem, in which we desire to  learn a differentiable function representation   Œ¶ , that maps a sequence of 30 s epochs   ùê±   ‚àà ‚Ñù ‡Æº √ó ‡∞à‡Øç   to their corresponding  label probabilities   ùê≤   ‚àà ‚Ñù ‡ØÑ √ó ‡∞à , where   ùõº   is a parameter that controls the sequence length. If e.g.   ùõº   = 8 , the sequence   x  contains 4 min of successive PSG data described by 8 epochs of length 30 seconds. Furthermore, we denote by   ‚ü¶ ùëé ,   ùëè ‚üß   the  set of integers from   ùëé   to   ùëè , i.e.   ‚ü¶ ùëé ,   ùëè ‚üß   ‚â°   { ùëõ   ‚àà ‚Ñï | ùëé   ‚â§   ùëõ   ‚â§   ùëè } , and by   ‚ü¶ ùëÅ ‚üß   the shorthand form of   ‚ü¶ 1,   ùëÅ ‚üß .  Network architecture  As the representation of   Œ¶ , we adapted and extended a previously published neural network architecture for automatic  sleep stage classification, which was based on a variant of the ResNet-50 architecture commonly used for two-dimensional  image classification tasks, but adapted and re-trained from scratch for the specific use-case of one-dimensional, time-  dependent signals in the PSG 24 . This network has the advantage that it does not require any manual feature engineering  and extraction compared to previous state of the art sleep stage classification models 21 . An overview of the proposed  network architecture is provided graphically in Figure 1 and Table 2. Briefly, the architecture consists of four modules:  1)   an initial mixing module   ùúë mix   ‚à∂ ‚Ñù ‡¨µ √ó ‡Æº √ó ‡Øç   ‚Üí ‚Ñù ‡Æº √ó ‡¨µ √ó ‡Øç  2)   a feature extraction module   ùúë feat   ‚à∂ ‚Ñù ‡Æº √ó ‡¨µ √ó ‡Øç   ‚Üí ‚Ñù ‡Øô ‡∞¨ ‡¨∂ ‡≥É‡∞∂‡∞≠ √ó ‡¨µ √ó ‡Øç   ‡¨∂   ‡≥É ‚ÅÑ  3)   a temporal processing module   ùúë temp   ‚à∂ ‚Ñù ‡Øô ‡∞¨ ‡¨∂ ‡≥É‡∞∂‡∞≠ √ó ‡¨µ √ó ‡Øç   ‡¨∂   ‡≥É ‚ÅÑ   ‚Üí ‚Ñù ‡¨∂‡Ø° ‡≥ì √ó ‡Øç   ‡¨∂   ‡≥É ‚ÅÑ   , and  4)   a classification module   ùúë clf   ‚à∂ ‚Ñù ‡¨∂‡Ø° ‡≥ì √ó ‡Øç   ‡¨∂   ‡≥É ‚ÅÑ   ‚Üí ‚Ñù ‡ØÑ √ó ‡Øç   ‡¨∂   ‡≥É ‚ÅÑ   .  Thus, we obtain a differentiable representation of the function   Œ¶ ‚à∂ ‚Ñù ‡Æº √ó ‡Øç   ‚Üí ‚Ñù ‡ØÑ √ó ‡Øç   ‡¨∂   ‡≥É ‚ÅÑ   as  Œ¶ ( ùê± )   =   ùúë clf   ‡µ¨ ùúë temp   ·âÄ ùúë feat ‡µ´ ùúë mix ( ùê± ) ‡µØ ·âÅ ‡µ∞   .  The output of this function is the matrix   ùê≤   ‚àà ‚Ñù ‡ØÑ √ó ‡Øç   ‡¨∂   ‡≥É ‚ÅÑ   containing sleep stage probabilities in the sequence of PSG data  evaluated every second.  Mixing module\n\n9 of 28  The raw input data is input to this module, which encourages non-linear channel mixing similar to what has been proposed  in recent literature 16,39‚Äì41 . The module is realized using a single 2D convolutional operation outputting   ùê∂   feature maps  computed using single-strided   ùê∂   √ó 1   kernels followed by rectified linear unit (ReLU) activations.  Feature extraction (residual network) module  This is comprised of a succession of   R   residual blocks (see Figure 1), which are responsible for the bulk feature extraction  from the channel-mixed data. Each residual block is realized using bottlenecks of first a   1 √ó 1   convolution to reduce the  number of feature maps, then a   1 √ó 3   convolution and lastly a   1 √ó 1   convolution to finally increase the number of feature  maps. Each convolution operation was followed by a batch normalization 42   and ReLU activation except after the last  convolutional layer, where shortcut projections are added before the activation 43 . This type of block structure enables the  design and training of very deep networks without the risk of vanishing gradients due to the projection shortcuts 44 .  Temporal processing module  This module is realized by a bidirectional gated recurrent unit (GRU) 45   in order to accommodate temporal dependencies  in the PSG. The GRU runs through the temporal dimension of the output from   ùúë ‡≠§‡≠£‡≠ü‡≠≤   of   ùëá   2 ‡Øã ‚ÅÑ   time steps each containing  ùëì ‡¨¥ 2 ‡Øã‡¨æ‡¨µ   features and outputs   ùëõ ‡Øõ   features in each direction for each time step. By running both forward and backward, we  can accommodate that technicians base their scoring on looking backwards as well as ahead in time in each time segment  (typically 30 s).  Classification module  The final module in the architecture performs actual classification based on the forward and backward features for each  time step outputted from   ùúë ‡≠≤‡≠£‡≠´‡≠Æ   . It is realized by a single convolutional operation with a subsequent softmax activation to  compute a probability distribution over the   K   sleep stage classes, such that the probability of sleep stage   ùëñ   at time step   ùëõ  is given by   ùë¶ ‡Øú  ( ‡Ø° )   =   ‡±õ‡±Æ‡±¶   ( ‡≥å   ‡≥î )  ‚àë   ‡±õ‡±Æ‡±¶   ( ‡≥å   ‡≥ñ ) ‡≥ñ   , where   ùëé ‡Øú   ‚àà   ùíÇ   is the activation of the last layer in the network and   ùëò   =   ‚ü¶ ùêæ ‚üß .  Loss function  The network was trained end-to-end with respect to a loss function, that takes the output probabilities from the network  ùê≤   = Œ¶ ( ùê± )   and calculates the loss as  ‚Ñí ( ùê≤ )   =   ‚àí   ‡∑ç   ‡∑ç   ùë° ‡Øû ( ‡Ø° )   log ·âÄ ùë¶ ·á±  ‡Øû  ( ‡Ø° ) ·âÅ  ‡ØÑ  ‡Øû ‡≠Ä ‡¨µ  ‡¨∑‡¨¥   ‡∞õ ‚ÅÑ  ‡Ø° ‡≠Ä ‡¨µ  ,  (1)\n\n10 of 28  ùë¶ ‚Ä≤ ‡Øû  ( ‡Ø° )   =   1  ùúè   ‡∑ç   ùë¶ ‡Øû  ( ‡Øú )  ‡∞õ‡Ø°  ‡Øú ‡≠Ä ‡∞õ ( ‡Øù ‡¨ø   ‡¨µ ) ‡¨æ ‡¨µ  ,  (2)  which is the cross-entropy between successive time-averaged classifications (parameterized by the number of successive  one-second predictions   ùúè ), and the ground truth labels   ùë°   broadcasted to   30   ùúè ‚ÅÑ   labels per 30 s segment. This way, we can  acquire predictions every second, that can be combined in time at intervals given by   ùúè .  Experimental setups  We set up three different experiments in this study.  A)   We wished to investigate the effect of increasing the complexity of the recurrent module by varying the number of  units   ùëõ ‡Øõ   in the module   ùúë temp   in the space   ùëõ ‡Øõ   = 2 ‡Øû   ,   ùëò   ‚àà   ‚ü¶ 6,11 ‚üß . We hypothesize that there exists a sweet-spot in the  number of hidden units that balances computational complexity with classification performance, i.e. classifying a  sequence of sleep stage labels given a corresponding sequence of outputs from   ùúë feat . The results of this experiment  were furthermore used to determine parameters for models in subsequent experiments.  B)   Since we have several cohorts at our disposition of both clinical and research origin, we can investigate the  compatibility and inherent generalizability of the different cohorts in two ways: 1) we set aside a single cohort for  testing, while we train the models on the remaining four (leave-one-cohort-out, LOCO training); and 2) we train on  a single cohort, while we set aside the remaining four for testing (leave-one-cohort-in, LOCI training).  C)   Generalizability can also be investigated in another way, which can answer the question of how many data sources  is necessary. We trained models with all possible 2-, 3-, and 4-combinations of cohorts, i.e. one run trained on ISRUC  and MrOS training data, another run with ISRUC and SHHS train data, a third with ISRUC and SSC, etc., with all  runs subjected to subsequent evaluation on the test partition.  D)   Previous studies have already investigated the performance of automatic sleep staging algorithms using shallow  machine learning models. At the time of writing however, none have investigated the effect of available training data  for deep learning models at this magnitude (up to tens of thousands). We therefore trained models on 0.25%, 0.5%,  1%, 5%, 10%, 25%, 50%, 75% and 100% of the data available for training. Specifically, some of these fractions of  the total number of PSGs correspond roughly to the number of PSGs in the training partitions in each cohort, allowing  for direct comparisons between training a model with mixed- and single-cohort training data.  Common for all experiments were the default parameter values   ùê∂   = 4 ,   ùëì ‡Ø¶   = 128 Hz ,   ùëá   =   ùúèùëì ‡Ø¶ ,   ùêæ   = 5 ,   ùëÖ   = 7 , and   ùëì ‡¨¥   = 4  for the number of input channels, sampling frequency, the sequence length, the number of sleep stages, the number of  consecutive residual blocks, and the base filter kernel size, respectively. All models were trained for 50 epochs (passes\n\n11 of 28  through the training partition) and the model with the highest Cohen‚Äôs kappa value on the validation partition was  subsequently selected for testing. All models were trained end-to-end with backpropagation using the Adam optimizer 46  with a learning rate of   10 ‡¨ø   ‡¨∏   ,   ùõΩ ‡¨µ   = 0.9 , and   ùõΩ ‡¨∂   = 0.999   to minimize the loss function specified by Eq. (1) and Eq. (2). All  network weights and bias terms were initialized using the uniform Glorot initialization scheme 47 .  Performance metrics and model evaluation  For each experiment we evaluated model performance using the overall accuracy (Acc) and Cohen‚Äôs kappa (Œ∫) in order  to into account the possibility of chance agreement between the model gold standard. Given a confusion matrix   ùêÇ   with  element   ùëê ‡Øú‡Øù   being the number of epochs belonging to sleep stage   ùëñ   but classified to be in sleep stage   ùëó , we define the  overall accuracy for a given model as  Acc   =   ‚àë   ùëê ‡Øú‡Øù ‡Øú‡≠Ä‡Øù  ‚àë   ùëê ‡Øú‡Øù ‡Øú , ‡Øù  i.e. the sum of the trace of   ùêÇ   divided by the total count. The Cohen‚Äôs kappa metric is defined as  Œ∫ =   ùëù ‡Ø¢   ‚àí   ùëù ‡Øò  1 ‚àí   ùëù ‡Øò  where   ùëù ‡Ø¢   =   Acc is the observed agreement (i.e. accuracy) and   ùëù ‡Øò   is the expected chance agreement, which can be  reformulated in terms of the outer product between the row and column sums (class-specific recall and precision) of   ùêÇ .  Data and source code availability  All model training and testing code was implemented in PyTorch v. 1.2 48 . Model performances were assessed using  custom   Python   scripts   using   scikit-learn 49 .   Source   code   and   pre-trained   models   will   be   made   available   at  https://github.com/neergaard/deep-sleep-pytorch.git   and   https://github.com/Stanford-STAGES/deep-sleep-pytorch.git  upon publication of this paper. Data from ISRUC are publicly available at   https://sleeptight.isr.uc.pt/ISRUC_Sleep/ , while  access to data from MrOS and SHHS can be requested from the NSRR. Anonymized PSG data from SSC including  selected demographic data are available at   https://stanfordmedicine.app.box.com/s/r9e92ygq0erf7hn5re6j51aaggf50jly .\n\n12 of 28  RESULTS  In this section we report on the results of the three experiments described in the   Experimental setups   section.  Temporal context impact on model performance  In Figure 2 we show how the model performance depends on the temporal context and complexity of the temporal  processing module, when evaluating the model on the validation partition. Results are further detailed in Table S1.  Specifically, we observe a drastic change in Cohen‚Äôs kappa just by introducing a simple recurrent unit into the network  as shown in Figure 2a, where Cohen‚Äôs kappa increases from   0.645 ¬± 0.126   ( 95%   CI : [0.633 ‚àí 0.657] )   at   ùëõ ‡Øõ   = 0   to  0.720 ¬± 0.120   ( 95%   CI : [0.709 ‚àí 0.731] )   at   ùëõ ‡Øõ   = 64 . We did not observe any major changes when increasing the  number of hidden units beyond 64, although we did see a maximum Cohen‚Äôs kappa of   0.734 ¬± 0.111   ( 95%   CI : [0.723 ‚àí  0.744] )   at   ùëõ ‡Øõ   = 1024 , which is shown in the inset in Figure 2a. We observed a general increase in Cohen‚Äôs kappa when  classifying longer sequences than 2 min ( 0.726 ¬± 0.114, 95%   CI : [0.715 ‚àí 0.737] ), but did not see any major  differences when classifying over more than 3 min sequences ( 0.733 ¬± 0.123, 95%   CI : [0.721 ‚àí 0.744] ). Subsequent  models were fixed with   ùëõ ‡Øõ   = 1024   corresponding to a sequence length of 5 min.  Model classifications converge to 30 s predictions given sufficient training data  Furthermore, we analyzed the classification performance of the model given a specific sequence length by looking at the  average prediction accuracy across all 5 min sequences in all subject PSGs in the test partition, similar to what Brink-  Kjaer et al. has shown previously 50 . In Figure 2c, we show how the average classification accuracy in a 5 min sequence  both depends on the amount of data and the frequency of evaluating the model output, i.e. every 1 s or across 30 s. The  average classification accuracy was found to be slightly lower in the beginning of each 5 min sequence (see Figure 2c),  both when training a model with less (500 training subjects) and more (75% of total training subjects). Interestingly, when  training with less data, we also observed a lower accuracy in the beginning and end of each 30 s segment relative to the  accuracy in the middle section, which was not the case when training with more data.  Choice of cohort impacts classification performance on test set  In Figure 3 we show how training on different cohorts yield differing results in subsequent testing performance, here  expressed in heatmaps as both overall accuracy (Figure 3a), and Cohen‚Äôs kappa (Figure 3b) averaged across all   ùëÅ   =  1,584   subject PSGs in the test partition. The first two columns show the performance on the cohort on the x-axis, when  training on the specific cohort on the y-axis. Since the training subset in ISRUC is small compared to the other cohorts,  we trained the model in the left-most column with weight decay of   10 ‡¨ø   ‡¨∏   to compensate for the risk of overfitting, however,\n\n13 of 28  by comparing the left and middle columns, we did not observe any specific gain in classification performance by doing  so. The right-most column shows the test performance for each cohort, when excluding that cohort from training. We  observe a significant spread in classification accuracy across the different cohorts with prediction on ISRUC being  poorest, while prediction on MrOS data being best. Further details can be found in Table S2.  More data is good, diverse data is better  We observed a general increase in classification performance both in terms of overall accuracy and Cohen‚Äôs kappa, when  including more data in the model training phase in both the mixed- and single-cohort setting (Figure 4a, Table S3).  Classification performance was consistently lower in the single-cohort setting compared to the corresponding mixed-  cohort setting. Interestingly, we found that training a model with just 0.25% of mixed-cohort training data still achieved  an acceptable accuracy comparable to training a model with only SHHS data, while using all available training data  increased that performance by almost 10 percentage points. Furthermore, we observed that the model trained with 100%  of the training partition reached a state-of-the-art level of performance with an overall accuracy of   0.869 ¬± 0.064  ( 95%   CI :   [ 0.865 ‚àí 0.872 ] ) and Cohen‚Äôs kappa of   0.799 ¬± 0.098   ( 95%   CI :   [ 0.794 ‚àí 0.804 ] ) (Table S3). The model  furthermore performs well with respect to classifying individual sleep stages as shown in the confusion matrix in Figure  4b. However, the model still has difficulties classifying and distinguishing between certain sleep stages, especially  between N2, N1, and N3; and W, N2, and N1.  Increasing the number of data sources improves classification performance  On average, we saw an increase in overall accuracy, when increasing the number of cohorts from 2 to 4 using 500 PSGs  in each configuration, see Figure 5 and Table S4. Specifically, we found that the average overall accuracy increased from  0.788 ¬± 0.102   ( 95%   CI :   [ 0.787 ‚àí 0.790 ] ) in the 2-cohort configuration to   0.808 ¬± 0.092   ( 95%   CI :   [ 0.807 ‚àí 0.810 ] )  and   0.821 ¬± 0.085   ( 95%   CI :   [ 0.819 ‚àí 0.823 ] ) in the 4-cohort configuration.\n\n14 of 28  DISCUSSION  In this work, we present an end-to-end deep learning-based model for fully automatic micro- and macro-sleep stage  classification. Using all of the available data sources for training our model, we reached an overall accuracy on test  partition of   0.869 ¬± 0.064   ( 95%   CI :   [ 0.865 ‚àí 0.872 ] ), and a Cohen‚Äôs kappa of   0.799 ¬± 0.098   ( 95%   CI :   [ 0.794 ‚àí  0.804 ] ), which is in the very high end of the substantial agreement category for observer agreement 51 . We found that  individual cohorts exhibit major differences in overall accuracy and Cohen‚Äôs kappa when subjected to both training and  testing conditions and specifically, we found that average performance on the test partition in the LOCI configurations  varied significantly from   0.676 ¬± 0.124   ( 95%   CI :   [ 0.670 ‚àí 0.682 ] ) when training on ISRUC, to   0.837 ¬± 0.084  ( 95%   CI :   [ 0.833 ‚àí 0.841 ] ) when training on SHHS. Each individual cohort also showed large deviations in predictive  performance when tested on the other cohorts. For example, when conditioned on SHHS data, the lowest average accuracy  was 0.721 on SSC test data compared to the highest at 0.872 on SHHS test data, while conditioning on SSC training data,  the lowest average accuracy was 0.704 on ISRUC test data compared to 0.824 on WSC test data. Classification  performance was generally higher on the test set when using the LOCO configuration, except for SHHS (higher in LOCI)  and SSC (no difference). We also found that having data from multiple sources always resulted in better-performing  models compared to training on single cohorts. Increasing the number of data sources increased classification  performance, although this was non-significant. In the design of the model, we observed that model performance was  enhanced by the addition of the recurrent module (bGRU), a phenomenon likely reflecting the fact that sleep stage scoring  at a specific time in one subject can be influenced by signal content (frequency, amplitude, presence of micro-events) at  later time steps. However, the complexity of the module given by the number of hidden units did not affect performance.  In all our experiments, we also evaluated the performance of the model every 1 s compared to the performance evaluated  every 30 s and found them to be similar, which indicates the model is stable in classification in periods corresponding to  an epoch of data.  Only a handful of studies have previously reported results when using multiple cohorts 21‚Äì23 . Some authors have reported  a drop from 81.9% to 77.7% when training on the Massachusetts General Hospital cohort (MGH) and testing on MGH  and SHHS, respectively 22 , while others have shown significant drops from 89.8% to 81.4% and 72.1% on two separate  hold-out sets from Singapore and USA 23 . We also observed similar trends in our LOCI and LOCO experiments, where  excluding the training subset of a cohort from the training partition resulted in a significant drop in performance on the  respective test subset from that cohort. A benefit of our LOCI and LOCO experiments is the possibility for direct  benchmarking against previous publications using specific cohorts in their experiments. For example, we obtain an  accuracy of 0.805 in the LOCO-SHHS training-testing case compared to 0.777 previously reported by Biswal et al. 22 ,\n\n15 of 28  both of which reflect classification performance when SHHS had not been used for training; and an accuracy of 0.865 in  the LOCI-WSC case compared to 0.841 reported by Olesen et al.   24 , where both have been using a subset of WSC for  training the model. Interestingly, we obtained the same level of performance on the SHHS data in our LOCI experiment  as reported by Sors et al. (87% accuracy, 81% Cohen‚Äôs kappa) even though they only used single-EEG for their  experiments 52 . Other works that have investigated single- vs. multi-channel models for automatic sleep stage classification  have found that models generally benefit from having more channels available for training 16,18,22 . It may be that some  cohorts share different characteristics that makes them more suitable for single- or multi-channel models, but this is  speculative and would need to be verified in subsequent studies.  Our study is not without limitations. We only optimized our network architecture with respect to the temporal processing  module and therefore cannot assess what impact different design choices for the other modules would have had on final  performance. For example, the EMG signal has different statistical properties and spectral content, and separate, parallel  architectures for EMG and EEG/EOG feature extraction may be warranted, as proposed by others 16,21 . Other studies have  however shown equal performance in large cohorts using a similar channel mixing approach as proposed here 24 . Another  limitation is found in our training runs, as we did not consider balancing our data with respect to the proportion of sleep  stages, which may or may not have had impact on overall performance. It is well established that there is significant  variation in scoring and validation of N1/REM and N2/N3 3,5,7 , which challenges the training for any classification  algorithm. Some researchers have experimented balancing the cost of misclassifying sleep stages by weighting them by  their inverse frequency of occurrence and found no significant improvement 24,52 , while others have experimented with  balancing the sleep stage frequencies in each batch of data input to the neural network model 16 , but more rigorous research  in resampling or over/under-sampling techniques is warranted in this regard. We ultimately decided against experimenting  with balancing our sleep stages in each batch, as we prioritized flexibility with regards to the length of input sequences  fed to the network. All our models ran through at least 50 epochs of training (passes through the training partition), which  might have induced a bias in the configurations with larger cohorts. For example, one pass through the training partition  in the LOCI-ISRUC case corresponds to much less data than one pass through the LOCI-SHHS case. However, since we  selected the best performing model based on Cohen‚Äôs kappa across all 50 epochs, we have allowed for more effective  training in cases with less available training data. We observed that models using less data in the training partition  generally had to run for longer time (i.e. more epochs) before converging.  In future studies on automatic sleep stage classification algorithms, we strongly recommend researchers to test and report  results on not just hold-out test partitions, but also on cohorts completely unseen by the model both during training and\n\n16 of 28  testing/validation. Our experiments indicate that even though good performance can be achieved on hold-out data using  a single cohort, this does not necessarily translate into good generalization performance. Such approach requires  availability of many publicly available, high-quality, well-documented databases with easily accessible PSG data,  associated annotations and related patient information. In this regard, websites such as the NSRR, which contains several  large databases with clinical data as well as PSG and annotation data in a standardized format 31,32 , are an invaluable  resource for researchers. We also propose that the sleep science community establishes a common reference dataset on  which researchers in machine learning can benchmark their models, similar to what the computer vision and general  machine learning community has done with the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 53 , an  annual competition in which researchers submit their models to test in various competitions.  In summary, we have developed an automatic sleep stage classification algorithm based on deep learning, that can  accurately classify sleep stages at a flexible resolution with a state-of-the-art classification performance of 87% accuracy  on a test set of 1,584 PSGs. We trained and tested our model using five cohorts with varying numbers of PSGs covering  multiple phenotypes with specific focus on how well cohorts can generalize to each other. We found that different cohorts  generalize very differently both in intra- and inter-cohort settings (LOCI vs. LOCO experiments). Furthermore, we also  found that having more data sources significantly improve classification performance and generalizability to the extent  that even just a small number of training PSGs can reach high classification performance by including many different  sources. To our knowledge, this is one of the largest, if not the largest, study on automatic sleep stage classification in  terms of PSG volume, diversity, and performance.\n\n17 of 28  ACKNOWLEDGMENTS  Some of the computing for this project was performed on the Sherlock cluster. We would like to thank Stanford University  and the Stanford Research Computing Center for providing computational resources and support that contributed to these  research results.  The authors would also like to thank the National Sleep Research Resource (https://www.sleepdata.org) team for their  work in collecting, organizing and making available some of the PSG data used in this study.  The authors would also like to thank Julie Anja Engelhard Christensen, PhD, for her editorial work on this paper.\n\n18 of 28  DISCLOSURE STATEMENT  A. N. Olesen has received funding from The Klarman Family Foundation; Technical University of Denmark; University  of Copenhagen; Reinholdt W. Jorck og Hustrus Fonden; Otto M√∏nsteds Fond; Stibofonden; Knud H√∏jgaards Fond;  Augustinus Fond; and Vera og Carl Johan Michaelsens Fond. E. Mignot has received partial funding by the Klarman  Family Foundation, has received research support from Jazz Pharmaceuticals, is a consultant for Rhythm (a sleep  consumer product company) and Alairion (a sleep apnea pharmacology company), and is on the speakers' bureau for Vox  Media.\n\n19 of 28  REFERENCES  1.   Chiao W, Durr ML. Trends in sleep studies performed for Medicare beneficiaries.   Laryngoscope . 2017;127(12):2891-2896.  doi:10.1002/lary.26736  2.   Berry RB, Albertario CL, Harding SM, et al.   The AASM Manual for the Scoring of Sleep and Associated Events: Rules, Terminology and  Technical Specifications.   2.5. Darien, Il: American Academy of Sleep Medicine; 2018.  3.   Younes M, Raneri J, Hanly P. Staging sleep in polysomnograms: Analysis of inter-scorer variability.   J Clin Sleep Med . 2016;12(6):885-  894. doi:10.5664/jcsm.5894  4.   Younes M. The case for using digital EEG analysis in clinical sleep medicine.   Sleep Sci Pract . 2017;1(2). doi:10.1186/s41606-016-0005-0  5.   Younes M, Kuna ST, Pack AI, et al. Reliability of the American Academy of Sleep Medicine Rules for Assessing Sleep Depth in Clinical  Practice.   J Clin Sleep Med . 2018;14(02):205-213. doi:10.5664/jcsm.6934  6.   Rosenberg RS, Van Hout S. The American Academy of Sleep Medicine Inter-scorer Reliability Program: Sleep Stage Scoring.   J Clin Sleep  Med . 2013;9(1):81-87. doi:10.5664/jcsm.2350  7.   Norman RG, Pal I, Stewart C, Walsleben JA, Rapoport DM. Interobserver Agreement Among Sleep Scorers From Different Centers in a  Large Dataset.   Sleep . 2000;23(7):1-8. doi:10.1093/sleep/23.7.1e  8.   Fiorillo L, Puiatti A, Papandrea M, et al. Automated sleep scoring: A review of the latest approaches.   Sleep Med Rev . 2019;48:101204.  doi:10.1016/j.smrv.2019.07.007  9.   Goldberger AL, Amaral LAN, Glass L, et al. PhysioBank, PhysioToolkit, and PhysioNet.   Circulation . 2000;101(23):e215-e220.  doi:10.1161/01.CIR.101.23.e215  10.   Kemp B, Zwinderman AH, Tuk B, Kamphuisen HAC, Obery√© JJL. Analysis of a sleep-dependent neuronal feedback loop: The slow-wave  microcontinuity of the EEG.   IEEE Trans Biomed Eng . 2000;47(9):1185-1194. doi:10.1109/10.867928  11.   Vilamala A, Madsen KH, Hansen LK. Deep convolutional neural networks for interpretable analysis of EEG sleep stage scoring. In:   2017  IEEE 27th International Workshop on Machine Learning for Signal Processing (MLSP) . Tokyo, Japan: IEEE; 2017:1-6.  doi:10.1109/MLSP.2017.8168133  12.   Phan H, Andreotti F, Cooray N, Chen OY, Vos M De. Automatic Sleep Stage Classification Using Single-Channel EEG: Learning  Sequential Features with Attention-Based Recurrent Neural Networks. In:   2018 40th Annual International Conference of the IEEE  Engineering in Medicine and Biology Society (EMBC) . IEEE; 2018:1452-1455. doi:10.1109/EMBC.2018.8512480  13.   Supratak A, Dong H, Wu C, Guo Y. DeepSleepNet: A Model for Automatic Sleep Stage Scoring Based on Raw Single-Channel EEG.   IEEE  Trans Neural Syst Rehabil Eng . 2017;25(11):1998-2008. doi:10.1109/TNSRE.2017.2721116  14.   ≈ûen B, Peker M, √áavu≈üo«ßlu A, √áelebi F V. A comparative study on classification of sleep stage based on EEG signals using feature  selection and classification algorithms.   J Med Syst . 2014;38(3). doi:10.1007/s10916-014-0018-0  15.   O‚ÄôReilly C, Gosselin N, Carrier J, Nielsen T. Montreal archive of sleep studies: An open-access resource for instrument benchmarking and  exploratory research.   J Sleep Res . 2014;23(6):628-635. doi:10.1111/jsr.12169  16.   Chambon S, Galtier MN, Arnal PJ, Wainrib G, Gramfort A. A Deep Learning Architecture for Temporal Sleep Stage Classification Using  Multivariate and Multimodal Time Series.   IEEE Trans Neural Syst Rehabil Eng . 2018;26(4):758-769. doi:10.1109/TNSRE.2018.2813138  17.   Andreotti F, Phan H, Cooray N, Lo C, Hu MTM, De Vos M. Multichannel Sleep Stage Classification and Transfer Learning using  Convolutional Neural Networks. In:   2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society  (EMBC) . IEEE; 2018:171-174. doi:10.1109/EMBC.2018.8512214  18.   Phan H, Andreotti F, Cooray N, Chen OY, De Vos M. Joint Classification and Prediction CNN Framework for Automatic Sleep Stage  Classification.   IEEE Trans Biomed Eng . 2019;66(5):1285-1296. doi:10.1109/TBME.2018.2872652\n\n20 of 28  19.   Phan H, Andreotti F, Cooray N, Chen OY, De Vos M. SeqSleepNet: End-to-End Hierarchical Recurrent Neural Network for Sequence-to-  Sequence Automatic Sleep Staging.   IEEE Trans Neural Syst Rehabil Eng . 2019;27(3):400-410. doi:10.1109/TNSRE.2019.2896659  20.   LeCun Y, Bengio Y, Hinton G. Deep learning.   Nature . 2015;521(7553):436-444. doi:10.1038/nature14539  21.   Stephansen JB, Olesen AN, Olsen M, et al. Neural network analysis of sleep stages enables efficient diagnosis of narcolepsy.   Nat Commun .  2018;9(1):5229. doi:10.1038/s41467-018-07229-3  22.   Biswal S, Sun H, Goparaju B, Westover MB, Sun J, Bianchi MT. Expert-level sleep scoring with deep neural networks.   J Am Med  Informatics Assoc . 2018;25(12):1643-1650. doi:10.1093/jamia/ocy131  23.   Patanaik A, Ong JL, Gooley JJ, Ancoli-Israel S, Chee MWL. An end-to-end framework for real-time automatic sleep stage classification.  Sleep . 2018;41(5):1-11. doi:10.1093/sleep/zsy041  24.   Olesen AN, Jennum P, Peppard P, Mignot E, Sorensen HBD. Deep residual networks for automatic sleep stage classification of raw  polysomnographic waveforms. In:   2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society  (EMBC) . IEEE; 2018:1-4. doi:10.1109/EMBC.2018.8513080  25.   Biswal S, Kulas J, Sun H, et al. SLEEPNET: Automated Sleep Staging System via Deep Learning. July 2017:1-17.  http://arxiv.org/abs/1707.08262.  26.   Khalighi S, Sousa T, Santos JM, Nunes U. ISRUC-Sleep: A comprehensive public dataset for sleep researchers.   Comput Methods Programs  Biomed . 2016;124:180-192. doi:10.1016/j.cmpb.2015.10.013  27.   Blank JB, Cawthon PM, Carrion-Petersen M Lou, et al. Overview of recruitment for the osteoporotic fractures in men study (MrOS).  Contemp Clin Trials . 2005;26(5):557-568. doi:10.1016/j.cct.2005.05.005  28.   Orwoll E, Blank JB, Barrett-Connor E, et al. Design and baseline characteristics of the osteoporotic fractures in men (MrOS) study ‚Äî A  large observational study of the determinants of fracture in older men.   Contemp Clin Trials . 2005;26(5):569-585.  doi:10.1016/j.cct.2005.05.006  29.   Blackwell T, Yaffe K, Ancoli-Israel S, et al. Associations Between Sleep Architecture and Sleep-Disordered Breathing and Cognition in  Older Community-Dwelling Men: The Osteoporotic Fractures in Men Sleep Study.   J Am Geriatr Soc . 2011;59(12):2217-2225.  doi:10.1111/j.1532-5415.2011.03731.x  30.   Rechtschaffen A, Kales A, eds.   A Manual of Standardized Terminology, Techniques and Scoring System for Sleep Stages of Human  Subjects . Washington, DC: National Institute of Health; 1968.  31.   Dean DA, Goldberger AL, Mueller R, et al. Scaling Up Scientific Discovery in Sleep Medicine: The National Sleep Research Resource.  Sleep . 2016;39(5):1151-1164. doi:10.5665/sleep.5774  32.   Zhang G-Q, Cui L, Mueller R, et al. The National Sleep Research Resource: towards a sleep data commons.   J Am Med Informatics Assoc .  2018;0(June):1-8. doi:10.1093/jamia/ocy064  33.   Redline S, Sanders MH, Lind BK, et al. Methods for obtaining and analyzing unattended polysomnography data for a multicenter study.  Sleep Heart Health Research Group.   Sleep . 1998;21(7):759-767. http://www.ncbi.nlm.nih.gov/pubmed/11300121.  34.   Quan SF, Howard B V, Iber C, et al. The Sleep Heart Health Study: design, rationale, and methods.   Sleep . 1997;20(12):1077-1085.  http://www.ncbi.nlm.nih.gov/pubmed/9493915.  35.   Young T, Finn L, Peppard PE, et al. Sleep Disordered Breathing and Mortality: Eighteen-Year Follow-up of the Wisconsin Sleep Cohort.  Sleep . 2008;31(8):291-292. doi:10.5665/sleep/31.8.1071  36.   Young T, Palta M, Dempsey J, Skatrud J, Weber S, Badr S. The Occurrence of Sleep-Disordered Breathing among Middle-Aged Adults.   N  Engl J Med . 1993;328(17):1230-1235. doi:10.1056/NEJM199304293281704  37.   Andlauer O, Moore H, Jouhier L, et al. Nocturnal Rapid Eye Movement Sleep Latency for Identifying Patients With Narcolepsy/Hypocretin\n\n21 of 28  Deficiency.   JAMA Neurol . 2013;70(7):891. doi:10.1001/jamaneurol.2013.1589  38.   Moore H, Leary E, Lee S-Y, et al. Design and Validation of a Periodic Leg Movement Detector.   PLoS One . 2014;9(12):e114565.  doi:10.1371/journal.pone.0114565  39.   Chambon S, Thorey V, Arnal PJ, Mignot E, Gramfort A, Neurospin CEA. A deep learning architecture to detect events in EEG signals  during sleep. In:   2018 IEEE 28th International Workshop on Machine Learning for Signal Processing (MLSP) . IEEE; 2018:1-6.  40.   Chambon S, Thorey V, Arnal PJ, Mignot E, Gramfort A. DOSED: A deep learning approach to detect multiple sleep micro-events in EEG  signal.   J Neurosci Methods . 2019;321:64-78. doi:10.1016/j.jneumeth.2019.03.017  41.   Olesen AN, Chambon S, Thorey V, Jennum P, Mignot E, Sorensen HBD. Towards a Flexible Deep Learning Method for Automatic  Detection of Clinically Relevant Multi-Modal Events in the Polysomnogram. In:   2019 41st Annual International Conference of the IEEE  Engineering in Medicine and Biology Society (EMBC) . IEEE; 2019:556-561. doi:10.1109/EMBC.2019.8856570  42.   Ioffe S, Szegedy C. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. In:   Proceedings of the  32nd International Conference on Machine Learning . Vol 37. Lille, France: JMLR: W&CP; 2015. doi:10.1007/s13398-014-0173-7.2  43.   He K, Zhang X, Ren S, Sun J. Identity Mappings in Deep Residual Networks. In:   Computer Vision -- ECCV 2016 . Vol abs/1603.0. ;  2016:630-645. doi:10.1007/978-3-319-46493-0_38  44.   He K, Zhang X, Ren S, Sun J. Deep Residual Learning for Image Recognition. In:   IEEE Conference on Computer Vision and Pattern  Recognition (CVPR) . ; 2015:770-778. doi:10.1109/CVPR.2016.90  45.   Cho K, van Merrienboer B, Bahdanau D, Bengio Y. On the Properties of Neural Machine Translation: Encoder‚ÄìDecoder Approaches. In:  Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation . Stroudsburg, PA, USA: Association  for Computational Linguistics; 2014:103-111. doi:10.3115/v1/W14-4012  46.   Kingma DP, Ba J. Adam: A Method for Stochastic Optimization. In:   3rd International Conference on Learning Representations (ICLR) .  San Diego, CA; 2015:1-15. http://arxiv.org/abs/1412.6980.  47.   Glorot X, Bengio Y. Understanding the difficulty of training deep feedforward neural networks.   Proc Thirteen Int Conf Artif Intell Stat  PMLR . 2010;9:249-256.  48.   Paszke A, Gross S, Chintala S, et al. Automatic differentiation in PyTorch. In:   31st Conference on Neural Information Processing Systems  (NIPS) . Long Beach, CA, USA; 2017.  49.   Pedregosa F, Varoquaux G, Gramfort A, et al. Scikit-learn: Machine Learning in Python.   J Mach Learn Res . 2011;12:2825-2830.  50.   Brink-Kjaer A, Olesen AN, Peppard PE, et al.   Automatic Detection of Cortical Arousals in Sleep and Their Contribution to Daytime  Sleepiness .; 2019. http://arxiv.org/abs/1906.01700.  51.   Landis JR, Koch GG. The Measurement of Observer Agreement for Categorical Data.   Biometrics . 1977;33:159-174.  52.   Sors A, Bonnet S, Mirek S, Vercueil L, Payen JF. A convolutional neural network for sleep stage scoring from raw single-channel EEG.  Biomed Signal Process Control . 2018;42:107-114. doi:10.1016/j.bspc.2017.12.001  53.   Russakovsky O, Deng J, Su H, et al. ImageNet Large Scale Visual Recognition Challenge.   Int J Comput Vis . 2015:211-252.  doi:10.1007/s11263-015-0816-y\n\n22 of 28  FIGURE CAPTIONS LIST  Figure 1: Model overview. a) The input is a sequence of data   ùê±   containing raw signal data from EEG, EOG-L/R, and  EMG channels, which is supplied to the network modules in sequence. The feature extraction module consists of   ùëÖ  repeated blocks of residual units, see panel to the right. The output of the model is a matrix   ùê≤   containing class probabilities  for each sleep stage for each time step, which can be visualized either directly as a hypnodensity, or by   arg max ùê≤   as a  hypnogram. The ‚ÄúA‚Äù and ‚ÄúM‚Äù labels in the hypnogram plots corresponds to automatic and manual hypnograms. b)  Schematic of a single residual block in the feature extraction module. Convolutional layers are described by the kernel  size   √ó   number of filters using a stride value of 1. Shortcut uses 1x1 convolutions with added zero-padding to maintain  temporal dimension. Conv, convolutional layer; BatchNorm, batch normalization; ReLU, rectified linear unit;   ùëì ‡¨¥ , base  number of filters ( ùëì ‡¨¥   = 4) .\n\n23 of 28  Figure 2: Temporal context changes model performance. a) Cohen's kappa as a function of the number of hidden units in  the recurrent block. Inset shows zoom of Cohen's kappa for non-zero hidden unit values. b) Cohen's kappa as a function  of sequence length. c) Prediction accuracy averaged across all 5-minute sequences in the test partition with a small and  large training partition. Full lines are predictions evaluated every 1 s, while dashed lines show predictions averaged every  30 s. Values are shown for panels a), b) as mean with 95% confidence intervals.\n\n24 of 28  Figure 3: Individual cohorts influence classification performance on test partition ( ùëÅ = 1,584 ). As an example, training  on MrOS in a LOCI configuration, the performance on the test subset of WSC is 0.815. The diagonals in all three  configurations shows the performance for the same subjects in the test subsets in the respective cohorts making possible  direct comparisons between LOCI and LOCO. For aggregated metrics and more summary statistics, please see   Error!  Reference source not found. . LOCI, leave-one-cohort-in; LOCI-wd, LOCI with weight decay; LOCO, leave-one-cohort-  out; ISRUC, Institute of Systems and Robotics, University of Coimbra Sleep Cohort; MrOS, MrOS Sleep Study; SHHS,  Sleep Heart Health Study; SSC, Stanford Sleep Cohort; WSC, Wisconsin Sleep Cohort.\n\n25 of 28  Figure 4: Training on mixed data increased predictive performance compared to individual cohorts of similar size. a)  There is a gain in predictive performance by mixing data from various sources consistent across the size of the training  dataset. b) Confusion matrix for a model trained on 100% of the available training partition data. The model shows  excellent performance overall, with most misclassification happening between W and N1, and N1, N2, and N3. This is  somewhat consistent with clinical experience, since N1 is a transition stage between wake and the deeper stages of sleep  with much frequency content overlap with both W and N2.\n\n26 of 28  Figure 5: Number of cohorts in training partition increases model performance. Each datapoint is shown as the overall  accuracy aggregated across all subjects for a specific training configuration. For example, the bottom dot in column 2 (3  cohort configuration) shows the performance on the test set (overall accuracy   0.755 ¬± 0.109, 95% CI:   [ 0.750 ‚àí 0.760 ] ),  when training with 500 PSGs randomly and evenly drawn from the Stanford Sleep Cohort, the Institute of Systems and  Robotics, University of Coimbra Sleep Cohort, and the Wisconsin Sleep Cohort. Notice the scale on the y-axis.\n\n27 of 28  TABLES  Table 1: Cohort demographics.  ISRUC   MrOS   SHHS   SSC   WSC   p -value  N (female)   126 (50)   3932 (0)   8444 (4458)   767 (319)   2401 (1103)   0  Age, years   49.8 ¬± 15.9  [20.0-85.0]  77.6 ¬± 5.6  [67.0-90.0]  64.5 ¬± 11.2  [39.0-90.0]  45.7 ¬± 14.5  [13.0-104.8]  59.7 ¬± 8.4  [37.2-82.3]  0  BMI, kg/m2   -   27.1 ¬± 3.8  [16.0-47.0]  28.2 ¬± 5.1  [18.0-50.0]  27.2 ¬± 6.5  [9.8-78.7]  31.6 ¬± 7.2  [17.5-70.6]  1.03e-171  TST, min   350.0 ¬± 67.3  [87.5-479.0]  352.1 ¬± 71.9  [39.0-626.0]  374.1 ¬± 69.4  [68.0-605.0]  361.0 ¬± 83.5  [0.0-661.0]  364.1 ¬± 63.6  [19.5-575.0]  4.07e-38  SL, min   17.7 ¬± 20.5  [0.0-144.5]  24.7 ¬± 26.9  [1.0-402.0]  24.2 ¬± 25.7  [0.0-349.0]  93.5 ¬± 58.9  [0.5-404.0]  33.2 ¬± 21.4  [0.5-333.0]  0  REML, min   125.6 ¬± 61.4  [7.0-323.0]  104.8 ¬± 75.1  [0.0-590.0]  91.7 ¬± 58.8  [0.0-471.0]  140.9 ¬± 88.0  [0.0-464.0]  128.3 ¬± 76.0  [3.5-514.0]  2.81e-173  WASO, min   76.2 ¬± 49.8  [7.5-251.0]  117.5 ¬± 67.6  [4.0-487.0]  80.2 ¬± 54.7  [2.0-378.0]  79.5 ¬± 55.0  [3.5-367.0]  73.6 ¬± 45.9  [3.0-325.0]  4.74e-233  SE, %   78.8 ¬± 14.1  [19.5-98.3]  75.5 ¬± 12.4  [12.0-99.0]  80.5 ¬± 11.0  [11.3-99.0]  77.4 ¬± 14.8  [0.0-98.0]  77.1 ¬± 11.2  [4.1-95.6]  4.23e-117  N1, %   13.3 ¬± 5.8  [1.8-33.1]  8.3 ¬± 6.4  [0.0-70.0]  5.5 ¬± 4.0  [0.0-39.1]  11.7 ¬± 10.2  [0.0-92.0]  10.8 ¬± 6.9  [1.0-88.4]  0  N2, %   31.9 ¬± 10.3  [4.4-89.3]  62.5 ¬± 10.0  [21.0-95.0]  56.9 ¬± 11.5  [10.9-100.0]  62.8 ¬± 24.9  [0.0-636.0]  66.0 ¬± 9.4  [9.1-93.3]  0  N3, %   19.6 ¬± 8.0  [0.0-41.1]  36.0 ¬± 31.8  [0.0-259.0]  17.5 ¬± 11.6  [0.0-70.1]  9.0 ¬± 9.3  [0.0-73.0]  7.2 ¬± 7.8  [0.0-47.5]  0  REM, %   13.3 ¬± 6.3  [0.0-37.8]  19.3 ¬± 6.8  [0.0-44.0]  20.1 ¬± 6.3  [0.0-48.0]  16.3 ¬± 7.2  [0.0-40.0]  16.0 ¬± 6.2  [0.0-38.2]  1.12e-203  ArI, /h   20.2 ¬± 10.0  [2.1-72.0]  23.7 ¬± 12.1  [1.0-105.0]  18.9 ¬± 10.5  [0.0-110.4]  125.0 ¬± 124.2  [1.0-729.0]  -   0  AHI, /h   13.1 ¬± 13.2  [0.0-82.2]  13.7 ¬± 14.6  [0.0-89.0]  18.1 ¬± 16.2  [0.0-161.8]  13.5 ¬± 19.2  [0.0-98.6]  7.0 ¬± 9.4  [0.0-72.6]  0  PLMI, /h   8.0 ¬± 27.4  [0.0-292.8]  35.7 ¬± 37.5  [0.0-233.0]  -   7.0 ¬± 18.1  [0.0-139.9]  -   1.22e-169  Cohort data represented as mean ¬± SD [range] unless noted. Arousal annotations were not available for WSC; PLMI was  not available for SHHS and WSC; BMI was not available for ISRUC. N: number of subjects; TST: total sleep time; SL:  sleep latency; REML: REM latency; WASO: wake after sleep onset; SE: sleep efficiency; ArI: arousal index; AHI:  apnea/hypopnea index; PLMI: periodic leg movement index; ; ISRUC: Institute of Systems and Robotics, University of  Coimbra Sleep Cohort; MrOS: The Osteoporotic Fractures in Men Sleep Study; SHHS: Sleep Heart Health Study; SSC:  Stanford Sleep Cohort; WSC: Wisconsin Sleep Cohort.\n\n28 of 28  Table 2: Overview of model architecture.  Module   Type   # filters/units   Kernel size   Stride   Activation   Output size  ùê±   Input   ‚àí   ‚àí   ‚àí   ‚àí   1   √ó   ùê∂   √ó   ùëá  ùùã mix   2D convolution   ùê∂   ( 1 ,   ùê∂ )   1   ‚àí   ùê∂   √ó   1   √ó   ùëá  Batch normalization   ‚àí   ‚àí   1   ReLU   ùê∂   √ó   1   √ó   ùëá  ùùã feat  ( ùíì )   ,   ùíì   ‚àà   ‚ü¶ ùëπ ‚üß   ‚Ä† Residual module   ùëì ‡¨¥ 2 ‡Ø• ‡¨ø   ‡¨µ / ùëì ‡¨¥ 2 ‡Ø• ‡¨ø   ‡¨µ / 4 ùëì ‡¨¥ 2 ‡Ø• ‡¨ø   ‡¨µ   ( 1 , 1 ) / ( 1 , 3 ) / ( 1 , 1 )   ( 1 , 1 ) / ( 1 , 2 )   ReLU   ùëì ‡¨¥ 2 ‡Ø•   √ó   1   √ó   ùëá   2 ‡Ø•  ‚ÅÑ  ùùã temp   Bidirectional GRU   ùëõ ‡Øõ   ‚àí   ‚àí   ‚àí   2 ùëõ ‡Øõ   √ó   ùëá   2 ‡Øã  ‚ÅÑ  ùùã clf   1D convolution   ùêæ   2 ùëõ ‡Øõ   1   Softmax   ùêæ   √ó   ùëá   2 ‡Øã  ‚ÅÑ  Kernel sizes correspond to the first, second and third convolutional layer in each residual block. Stride counts correspond  to the residual block and the subsequent maximum pooling operation. ReLU, rectified linear unit; GRU, gated recurrent  unit;   ùê∂ , number of input channels;   ùëá , length of segment in samples;   ùëì ‡¨¥ , base number of filters in residual blocks;   ùëÖ ,  number of residual blocks;   ùëõ ‡Øõ , number of hidden units in GRU;   ùêæ , number of sleep stage classes.   ‚Ä† SeeFigure 1.\n\n2 of 5  SUPPLEMENTARY TABLES  Table S1: Temporal context impact on model performance in validation partition ( ùëõ   = 426 ).  Overall accuracy   Cohen‚Äôs kappa  Mean   SD   Median   95% CI, mean   Mean   SD   Median   95% CI, mean  Hidden units  0   0.779   0.083   0.794   [0.771-0.787]   0.645   0.126   0.660   [0.633-0.657]  64   0.818   0.079   0.837   [0.810-0.825]   0.720   0.120   0.745   [0.709-0.731]  128   0.821   0.080   0.841   [0.813-0.829]   0.724   0.121   0.745   [0.713-0.736]  256   0.820   0.082   0.843   [0.812-0.828]   0.725   0.124   0.751   [0.713-0.736]  512   0.822   0.079   0.841   [0.815-0.830]   0.727   0.119   0.752   [0.716-0.739]  1024   0.828   0.072   0.845   [0.821-0.835]   0.734   0.111   0.758   [0.723-0.744]  2048   0.823   0.080   0.843   [0.816-0.831]   0.729   0.122   0.757   [0.717-0.740]  Sequence length  2 min   0.821   0.075   0.840   [0.814-0.828]   0.726   0.114   0.754   [0.715-0.737]  3 min   0.826   0.080   0.845   [0.818-0.833]   0.733   0.123   0.762   [0.721-0.744]  4 min   0.828   0.079   0.849   [0.820-0.835]   0.734   0.122   0.762   [0.722-0.745]  5 min   0.828   0.072   0.845   [0.821-0.835]   0.734   0.111   0.758   [0.723-0.744]  10 min   0.829   0.075   0.848   [0.822-0.836]   0.734   0.113   0.759   [0.723-0.745]  Window length  1 s   0.824   0.074   0.843   [0.817-0.831]   0.728   0.113   0.752   [0.717-0.738]  3 s   0.824   0.074   0.845   [0.817-0.832]   0.728   0.113   0.752   [0.717-0.739]  5 s   0.825   0.074   0.843   [0.818-0.832]   0.728   0.113   0.752   [0.717-0.739]  10 s   0.825   0.074   0.844   [0.818-0.832]   0.729   0.113   0.753   [0.718-0.739]  15 s   0.826   0.074   0.845   [0.818-0.833]   0.729   0.113   0.755   [0.719-0.740]  30 s   0.829   0.075   0.848   [0.822-0.836]   0.734   0.113   0.759   [0.723-0.745]  The   Hidden units   variable corresponds to varying the complexity in the recurrent module by increasing the number of  hidden units.   Sequence length   indicate the length of the sequence of 30 epochs, while   Window length   correspond to  varying the evaluation frequency.\n\n3 of 5  Table S2: Performance characteristics for LOCI and LOCO training configurations.  N   PSGs  Overall accuracy   Cohen‚Äôs kappa  Mean   SD   Median   95% CI, mean   Mean   SD   Median   95% CI, mean  LOCI-wd  ISRUC   1584   0.679   0.123   0.701   [0.673-0.685]   0.542   0.169   0.574   [0.533-0.550]  MrOS   1584   0.821   0.077   0.835   [0.817-0.825]   0.727   0.114   0.745   [0.721-0.733]  SHHS   1584   0.834   0.088   0.858   [0.830-0.839]   0.750   0.132   0.786   [0.744-0.757]  SSC   1584   0.762   0.094   0.774   [0.757-0.767]   0.639   0.129   0.654   [0.633-0.646]  WSC   1584   0.758   0.105   0.773   [0.753-0.764]   0.633   0.145   0.653   [0.626-0.640]  LOCI  ISRUC   1584   0.676   0.124   0.700   [0.670-0.682]   0.539   0.170   0.574   [0.531-0.547]  MrOS   1584   0.826   0.074   0.839   [0.822-0.829]   0.732   0.111   0.748   [0.726-0.737]  SHHS‚Ä°   1584   0.837   0.084   0.858   [0.833-0.841]   0.754   0.127   0.786   [0.748-0.761]  SSC   1584   0.773   0.088   0.785   [0.769-0.777]   0.657   0.125   0.671   [0.651-0.663]  WSC   1584   0.763   0.101   0.776   [0.758-0.768]   0.641   0.140   0.659   [0.635-0.648]  LOCO  ISRUC‚Ä†   52   0.749   0.081   0.764   [0.727-0.771]   0.648   0.119   0.682   [0.616-0.680]  126   0.757   0.071   0.766   [0.744-0.769]   0.661   0.101   0.682   [0.643-0.678]  MrOS‚Ä†   371   0.843   0.066   0.851   [0.836-0.849]   0.757   0.104   0.776   [0.746-0.767]  3932   0.841   0.069   0.854   [0.838-0.843]   0.752   0.107   0.775   [0.749-0.755]  SHHS   846   0.805   0.076   0.815   [0.800-0.810]   0.705   0.109   0.722   [0.698-0.712]  8444   0.800   0.081   0.811   [0.798-0.801]   0.697   0.115   0.713   [0.694-0.699]  SSC   76   0.793   0.086   0.809   [0.744-0.812]   0.680   0.120   0.700   [0.653-0.707]  766   0.798   0.086   0.815   [0.792-0.805]   0.690   0.123   0.711   [0.681-0.699]  WSC‚Ä†   239   0.826   0.065   0.835   [0.818-0.834]   0.720   0.096   0.736   [0.708-0.732]  2411   0.824   0.068   0.837   [0.821-0.827]   0.718   0.100   0.736   [0.714-0.722]  Metrics are aggregated across all subjects for each cohort in test partition ( ùëÅ   = 1,584   PSGs). Statistics in italics  correspond to evaluating performance on entire cohort. PSG: polysomnography; LOCI-wd: leave-one-cohort-in with  weight decay; LOCO: leave-one-cohort-out; ISRUC: Institute of Systems and Robotics, University of Coimbra Sleep  Cohort; MrOS: The Osteoporotic Fractures in Men Sleep Study; SHHS: Sleep Heart Health Study; SSC: Stanford Sleep  Cohort; WSC: Wisconsin Sleep Cohort; ‚Ä†: significantly better than corresponding LOCI; ‚Ä°: significantly better than  corresponding LOCO.\n\n4 of 5  Table S3: Model performance of test partition with varying fractions of training data.  Overall accuracy   Cohen‚Äôs kappa  Mean   SD   Median   95% CI, mean   Mean   SD   Median   95% CI, mean  Fraction (%)  0.25   0.782   0.097   0.801   [0.777-0.787]   0.671   0.141   0.696   [0.664-0.678]  0.50   0.804   0.086   0.824   [0.800-0.808]   0.696   0.131   0.724   [0.689-0.702]  1   0.824   0.079   0.840   [0.820-0.828]   0.730   0.118   0.753   [0.724-0.736]  5   0.841   0.074   0.856   [0.837-0.844]   0.757   0.113   0.780   [0.751-0.763]  10   0.850   0.069   0.864   [0.847-0.853]   0.770   0.108   0.791   [0.765-0.775]  25   0.858   0.066   0.873   [0.854-0.861]   0.782   0.102   0.804   [0.777-0.787]  50   0.860   0.063   0.874   [0.856-0.863]   0.787   0.097   0.809   [0.782-0.792]  75   0.867   0.062   0.882   [0.864-0.870]   0.797   0.096   0.818   [0.792-0.802]  100   0.869   0.064   0.883   [0.865-0.872]   0.799   0.098   0.820   [0.794-0.804]  Increasing the available training data increased performance on the test partition ( ùëÅ   = 1,584 ) shown here as aggregated  metrics across all subjects. No statistical difference was found by comparing confidence intervals (CI) between models  trained with 75% and 100% of available training data, which indicates a saturation in training.\n\n5 of 5  Table S4: Model performance on test partition ( ùëÅ   = 1,584 ) with varying number of cohorts in training partition.  Training cohorts   Overall accuracy   Kappa  Mean   SD   Median   95% CI, mean   Mean   SD   Median   95% CI, mean  2  Overall   0.788   0.102   0.811   [0.787-0.790]   0.683   0.143   0.710   [0.681-0.685]  ISRUC-MrOS   0.781   0.102   0.804   [0.776-0.786]   0.675   0.143   0.703   [0.668-0.682]  ISRUC-SHHS   0.808   0.097   0.835   [0.804-0.813]   0.717   0.142   0.756   [0.710-0.724]  ISRUC-SSC   0.735   0.103   0.753   [0.729-0.740]   0.613   0.140   0.638   [0.606-0.620]  ISRUC-WSC   0.745   0.107   0.758   [0.740-0.750]   0.628   0.140   0.642   [0.621-0.635]  MrOS-SHHS   0.829   0.081   0.849   [0.825-0.833]   0.740   0.124   0.769   [0.734-0.746]  MrOS-SSC   0.796   0.090   0.816   [0.791-0.800]   0.683   0.133   0.708   [0.677-0.690]  MrOS-WSC   0.805   0.087   0.822   [0.801-0.809]   0.699   0.126   0.722   [0.693-0.705]  SHHS-SSC   0.816   0.090   0.839   [0.812-0.821]   0.722   0.129   0.755   [0.716-0.729]  SHHS-WSC   0.824   0.089   0.846   [0.820-0.828]   0.733   0.128   0.762   [0.727-0.739]  SSC-WSC   0.742   0.110   0.755   [0.737-0.748]   0.620   0.145   0.634   [0.613-0.627]  3  Overall   0.808   0.092   0.830   [0.807-0.810]   0.711   0.131   0.739   [0.709-0.713]  ISRUC-MrOS-SHHS   0.820   0.092   0.844   [0.815-0.825]   0.732   0.134   0.766   [0.725-0.738]  ISRUC-MrOS-SSC   0.798   0.088   0.816   [0.794-0.802]   0.694   0.129   0.720   [0.688-0.700]  ISRUC-MrOS-WSC   0.811   0.083   0.828   [0.807-0.815]   0.711   0.119   0.735   [0.705-0.717]  ISRUC-SHHS-SSC   0.807   0.090   0.828   [0.803-0.812]   0.714   0.126   0.739   [0.708-0.721]  ISRUC-SHHS-WSC   0.817   0.091   0.842   [0.813-0.822]   0.728   0.128   0.759   [0.722-0.735]  ISRUC-SSC-WSC   0.755   0.109   0.775   [0.750-0.760]   0.639   0.150   0.670   [0.631-0.646]  MrOS-SHHS-SSC   0.833   0.071   0.848   [0.829-0.837]   0.744   0.109   0.766   [0.739-0.750]  MrOS-SHHS-WSC   0.840   0.073   0.854   [0.836-0.843]   0.753   0.109   0.774   [0.748-0.759]  MrOS-SSC-WSC   0.795   0.088   0.811   [0.791-0.800]   0.687   0.123   0.706   [0.681-0.693]  SHHS-SSC-WSC   0.807   0.101   0.833   [0.802-0.812]   0.710   0.142   0.744   [0.703-0.717]  4  Overall   0.821   0.085   0.840   [0.819-0.823]   0.728   0.124   0.755   [0.726-0.731]  ISRUC-MrOS-SHHS-SSC   0.827   0.078   0.843   [0.823-0.831]   0.739   0.115   0.764   [0.733-0.744]  ISRUC-MrOS-SHHS-WSC   0.835   0.075   0.850   [0.831-0.838]   0.747   0.112   0.768   [0.742-0.753]  ISRUC-MrOS-SSC-WSC   0.794   0.097   0.817   [0.789-0.799]   0.687   0.139   0.716   [0.680-0.694]  ISRUC-SHHS-SSC-WSC   0.819   0.091   0.843   [0.814-0.823]   0.728   0.131   0.759   [0.721-0.734]  MrOS-SHHS-SSC-WSC   0.830   0.076   0.846   [0.826-0.834]   0.741   0.112   0.763   [0.736-0.747]  The total number of training records were fixed at   ùëÅ   = 500   for all configurations. ISRUC: Institute of Systems and  Robotics, University of Coimbra Sleep Cohort; MrOS: The Osteoporotic Fractures in Men Sleep Study; SHHS: Sleep  Heart Health Study; SSC: Stanford Sleep Cohort; WSC: Wisconsin Sleep Cohort.",
      "embedding": [
        -0.050053227692842484,
        -0.02924860641360283,
        0.02398059144616127,
        0.0625954121351242,
        0.0625738799571991,
        0.04024507477879524,
        -0.08147680014371872,
        0.02243458852171898,
        0.04151425510644913,
        -0.09577696770429611,
        -0.10011780261993408,
        -0.0640774816274643,
        0.009210672229528427,
        0.05852324888110161,
        -0.08533082902431488,
        -0.07749656587839127,
        0.06993016600608826,
        0.03610985726118088,
        -0.09961949288845062,
        0.03377746418118477,
        0.047603487968444824,
        0.0463576577603817,
        0.10790368914604187,
        0.015789901837706566,
        0.04710376635193825,
        -0.024680746719241142,
        0.005303571466356516,
        -0.0592716783285141,
        -0.08061543852090836,
        0.0038176283705979586,
        0.0020846871193498373,
        0.05218855291604996,
        -0.03378525748848915,
        0.023179633542895317,
        -0.018414918333292007,
        -0.0042678238824009895,
        -0.003020444419234991,
        0.04544176906347275,
        -0.04358392581343651,
        0.03967103734612465,
        0.0658663958311081,
        -0.046449124813079834,
        0.011797803454101086,
        0.014347589574754238,
        0.05677102506160736,
        0.017626719549298286,
        -0.07183835655450821,
        -0.05752340704202652,
        -0.04888822138309479,
        0.10870403051376343,
        -0.05950357764959335,
        -0.002793854335322976,
        -0.016309920698404312,
        0.10835409164428711,
        0.025856122374534607,
        -0.011147643439471722,
        -0.012049098499119282,
        -0.012531054206192493,
        -0.053838882595300674,
        0.02407102845609188,
        0.0011745479423552752,
        -0.022685164585709572,
        -0.0076261889189481735,
        -0.04216599091887474,
        0.012325330637395382,
        0.07863712310791016,
        -0.09385442733764648,
        -0.006396031938493252,
        -0.003272558329626918,
        -0.010646400041878223,
        0.0026604742743074894,
        0.022677715867757797,
        -0.05416272208094597,
        0.03179109841585159,
        -0.02363322302699089,
        0.06128087639808655,
        0.10558153688907623,
        0.043657079339027405,
        0.07821564376354218,
        -0.08473984897136688,
        0.05318739265203476,
        0.06485430896282196,
        0.015726760029792786,
        -0.0029194091912359,
        0.06357438862323761,
        0.00015742037794552743,
        0.046560805290937424,
        0.06325994431972504,
        -0.048919882625341415,
        0.0033000309485942125,
        0.017876850441098213,
        0.03065991774201393,
        -0.03492903709411621,
        0.017145967110991478,
        0.07558723539113998,
        0.04081646725535393,
        -0.01883174292743206,
        -0.008529214188456535,
        -0.016451463103294373,
        0.014117599464952946,
        0.0038751077372580767,
        0.03936343640089035,
        0.02418653294444084,
        -0.026953253895044327,
        0.020377881824970245,
        0.03314243257045746,
        0.05813669040799141,
        -0.01682909019291401,
        0.07090607285499573,
        -0.07000651210546494,
        -0.004681704565882683,
        0.07519510388374329,
        -0.02833554893732071,
        -0.03466235473752022,
        0.09939577430486679,
        0.060911037027835846,
        0.020357847213745117,
        0.05879358947277069,
        0.06090846657752991,
        0.1116555780172348,
        -0.04416313394904137,
        -0.004546680022031069,
        0.06939038634300232,
        -0.08906007558107376,
        0.03353945538401604,
        -0.015713106840848923,
        -0.15103574097156525,
        8.010886736994377e-33,
        0.01373402401804924,
        -0.04030830040574074,
        0.025363583117723465,
        0.01175931841135025,
        0.004748965613543987,
        -0.06869816780090332,
        -0.08688632398843765,
        0.04937541484832764,
        0.00043007690692320466,
        0.030910704284906387,
        -0.12384864687919617,
        0.0465015172958374,
        -0.025567812845110893,
        0.07235332578420639,
        0.04147481545805931,
        0.013415658846497536,
        -0.030124766752123833,
        0.06411112844944,
        -0.029236407950520515,
        -0.031041502952575684,
        0.015998918563127518,
        -0.041088495403528214,
        0.032782211899757385,
        -0.013227192685008049,
        -0.0037111928686499596,
        0.003818599507212639,
        0.02868880331516266,
        0.045196834951639175,
        -0.06736364215612411,
        -0.002897179452702403,
        -0.09991981089115143,
        -0.0199216790497303,
        0.05321548134088516,
        -0.053229570388793945,
        0.029520299285650253,
        -0.04957825690507889,
        0.006986468564718962,
        0.03683668002486229,
        0.02810697816312313,
        -0.03937433287501335,
        -0.08123967796564102,
        0.05095082148909569,
        -0.012666430324316025,
        -0.018132301047444344,
        -0.019739577546715736,
        -0.03998409956693649,
        0.004813977517187595,
        -0.010897289961576462,
        -0.014089968055486679,
        -0.058067403733730316,
        -0.026444820687174797,
        -0.009481760673224926,
        -0.02052219584584236,
        -0.08980762213468552,
        -0.11285648494958878,
        0.060373179614543915,
        -0.002477124333381653,
        0.01699702814221382,
        -0.005253609735518694,
        0.05266372486948967,
        0.05303838104009628,
        0.05563710629940033,
        -0.04997878149151802,
        0.006368814501911402,
        0.016178254038095474,
        0.02613355964422226,
        -0.04425039142370224,
        0.019194696098566055,
        0.019285334274172783,
        -0.05048811063170433,
        0.03801313415169716,
        -0.0004648397443816066,
        0.06332027912139893,
        -0.010341647081077099,
        0.023854076862335205,
        -0.041388995945453644,
        0.035229843109846115,
        0.024548785760998726,
        -0.08823391795158386,
        0.001125384820625186,
        0.04237549006938934,
        0.047412555664777756,
        -0.06352175027132034,
        -0.06154318526387215,
        -0.060216277837753296,
        0.0036562434397637844,
        0.019655756652355194,
        -0.015325314365327358,
        -0.04962785542011261,
        -0.005662932526320219,
        -0.07960875332355499,
        -0.020956380292773247,
        -0.0038035002071410418,
        -0.032313842326402664,
        -0.037750355899333954,
        -7.280300100227032e-33,
        -0.04617203027009964,
        0.008722743019461632,
        -0.12386530637741089,
        -0.018292414024472237,
        0.08010251075029373,
        0.004964508581906557,
        0.019388658925890923,
        -0.029314927756786346,
        -0.04375453665852547,
        -0.04261124134063721,
        0.0810212716460228,
        -0.08214300125837326,
        0.03270643204450607,
        -0.04206273704767227,
        0.035740360617637634,
        -0.043715063482522964,
        -0.0654623806476593,
        0.022565392777323723,
        -0.0014847774291411042,
        0.08915995061397552,
        0.09706442803144455,
        0.036283526569604874,
        -0.14421610534191132,
        -0.017680346965789795,
        -0.04557964578270912,
        0.02869787998497486,
        -0.009163348004221916,
        0.1740345060825348,
        -0.030952088534832,
        -0.07882490009069443,
        0.010603460483253002,
        -0.009082240052521229,
        -0.1450430452823639,
        0.008903982117772102,
        0.03137591853737831,
        0.04307622089982033,
        0.04384716972708702,
        -0.07290362566709518,
        -0.04487159103155136,
        -0.06834640353918076,
        0.10903257131576538,
        0.03291444107890129,
        -0.07605600357055664,
        -0.019713692367076874,
        0.026857413351535797,
        -0.0067122019827365875,
        -0.05261832848191261,
        -0.027346856892108917,
        0.004119404125958681,
        0.002400594064965844,
        0.0049663265235722065,
        -0.028889136388897896,
        -0.06975105404853821,
        0.05553733929991722,
        -0.012716416269540787,
        -0.05350617319345474,
        -0.007841386832296848,
        -0.028272420167922974,
        -0.02941436506807804,
        0.029591603204607964,
        -0.03533259406685829,
        -0.022071560844779015,
        -0.07179006189107895,
        -0.05410394072532654,
        0.061952631920576096,
        0.025218600407242775,
        0.013820243068039417,
        -0.033643826842308044,
        0.03204818442463875,
        0.046557389199733734,
        -0.05582211911678314,
        -0.03256063163280487,
        0.025261282920837402,
        0.0286797434091568,
        -0.032809387892484665,
        -0.02413969300687313,
        -0.008593769744038582,
        -0.02627188339829445,
        -0.04134782403707504,
        -0.04407189041376114,
        -0.01825573481619358,
        -0.1712663620710373,
        -0.05355309322476387,
        0.07552390545606613,
        -0.018410323187708855,
        0.022669030353426933,
        0.08970977365970612,
        0.02130207233130932,
        0.07538371533155441,
        0.0206594280898571,
        -0.07466573268175125,
        0.019750773906707764,
        -0.10941833257675171,
        0.01833966374397278,
        -0.012021634727716446,
        -6.126229834535479e-8,
        0.006934434175491333,
        0.06022890284657478,
        0.010979801416397095,
        0.023347921669483185,
        -0.01986915059387684,
        -0.06937627494335175,
        -0.017525851726531982,
        0.04030389338731766,
        -0.02382061257958412,
        0.05470972880721092,
        0.10621404647827148,
        -0.013384947553277016,
        0.014334229752421379,
        -0.094780333340168,
        -0.030077695846557617,
        -0.005997803993523121,
        -0.019832683727145195,
        0.09562505036592484,
        0.017470819875597954,
        0.03931024298071861,
        0.08654819428920746,
        0.03245220333337784,
        0.00033405813155695796,
        -0.0575113520026207,
        0.12612974643707275,
        -0.04187299311161041,
        -0.020704511553049088,
        0.08327172696590424,
        -0.030831383541226387,
        -0.04092887416481972,
        0.05664505809545517,
        0.009118705056607723,
        0.02980176918208599,
        -0.03216846287250519,
        0.01965101808309555,
        0.011112517677247524,
        0.05906292423605919,
        0.01124729122966528,
        0.009374807588756084,
        0.10743484646081924,
        -0.03771774470806122,
        0.026189900934696198,
        -0.05856974050402641,
        0.02074875868856907,
        0.006944174412637949,
        -0.06012331694364548,
        0.0044739730656147,
        -0.03614235669374466,
        0.0825575739145279,
        0.018954148516058922,
        0.02207784354686737,
        -0.04190569370985031,
        0.02603575401008129,
        0.04882759228348732,
        0.03276175633072853,
        0.049604278057813644,
        -0.01185278594493866,
        -0.0407879501581192,
        -0.02075081504881382,
        0.030530670657753944,
        0.04485853388905525,
        -0.026420176029205322,
        -0.0577489398419857,
        0.022661032155156136
      ],
      "metadata": {
        "title": "Paper_10_Automatic_sleep_stage_classification_with_deep_res.pdf",
        "createdAt": "2025-12-17T13:56:28.191Z"
      },
      "fileObj": {}
    },
    {
      "id": "doc_1_1765979789158",
      "fileName": "Paper_11_Cord_blood_vitamin_D_level_and_night_sleep_duratio.pdf",
      "content": "C ord - blood   vitamin D level   and night sleep duration in pre schoolers in the EDEN  mother - child birth cohort  Chu Yan Yong 1,2 , Eve Reynaud 1,2 , Anne Forhan 1,2 , Patricia Dargent - Molina 1,2 , Barbara  Heude 1,2 , Marie - Aline Charles 1,2 , Sabine Plancoulaine 1,2 ; on   behalf of the EDEN study group.  Affiliations:  1   INSERM, UMR1153, Epidemiology and Statistics Sorbonne Paris Cit√© Research Center  (CRESS), early ORigins of Child Health And Development Team (ORCHAD), Villejuif, F -  94807 France;  2   Univ   Paris - Descartes, UMRS 1153, Paris, France;  Address correspondence to:  Sabine Plancoulaine, INSERM, UMR1153, Epidemiology and Statistics Sorbonne Paris Cit√©  Research   Center   (CRESS),   early   ORigins   of   Child   Health   And   Development   Team  (ORCHAD), 16 Av Paul   Vaillant Couturier, 94 807 Villejuif Cedex, FRANCE,  Email:   sabine.plancoulaine@inserm.fr  Phone: + 33 1 45 59 51 09.  Ethical approval and consent to participate:  The study was approved by the ethics re search committee of Bic√™tre Hospital (Comit√©  Consultatif de Protection des Personnes dans la Recherche Biom√©dicale) and by the Data  Protection Authority (Commission Nationale de l‚ÄôInformatique et des Libert√©s).\n\nABSTRACT  Objecti ve :   25 - hydroxyvitamin   D   ( 25OHD )   deficiency   has   been   associated   with   sleep  disorders in adults.   Only   three   cross - sectional   stud ies   were   performed   in children and show ed  an   association between   25OHD   deficiency   and   both   obstructive sleep apnea syndrome and  primary snoring . No   longitudinal stud y   has been   performed in children   from   the general  population.   We analyzed the association   between cord - blood vitamin D level   at birth   and  night - sleep duration trajectories for children between 2 and 5 - 6 years   old   in a non - clinical  cohort.  Method :   We included   264   c hildren from the French   EDEN mother - child birth - cohort   with  both   co rd - blood   25OHD   level   determined   by   radio - immunoassay   at birth ,   and   night - sleep  trajectories   for children   between 2 and 5 - 6 years   old   obtained by the group - based   trajectory  modeling method .   Association s   between   25OHD   and sleep trajectories w ere   assessed by  multinomial logistic regression adjusted for maternal and child characteristics.  Results:   The trajectories s hort   sleep ( < 10h 30 /night), medium - low   sleep ( 10h30 - 11h00 /night),  medium - high sleep ( ‚âà 11h30/night), long   sleep ( ‚â• 11h30/night) and   changing   sleep (decreased  from   ‚â• 11h30 to   10 h 30 - 11 h 00 /night) represented 5%, 46% , 37% , 4% and 8% of the children ,  respectively .   The   me an   25OHD   level   wa s 1 9   ng/ml ( SD=11, range   3 to 63 ).   It was   12 (SD=7),  20 (SD=11), 19 (SD=10), 14 (SD=7) and 16 (SD=8) ng/ml   for children   with   short, medium -  low, medium - high, long a nd changing   sleep   trajector ies ,   respectively .   On   adjusted   analysis ,  for   each 1 - ng/ml decrease   in   25OHD   level, the odd s   of   belong ing   to   the   short   sleep   versus  medium - high   sleep   trajectory   was increased   ( odds ratio   =1. 12 ,   95%   confidence interval   [1.01 -  1.25] ) .   We found no   other   significant   association between 25OHD   level   and   other trajectories.  Conclusion :   L ow   25OHD   level   at birth   may be   associated with   increased   probability of being  a   persistent   short   sleeper   in preschool years.   These results need confirmation .  Keywords:   pediatric sleep, vitamin D, epidemiology, cohort,\n\n1.   Introduction  V itamin   D , a steroid   hormone,   is involved in bone metabolism promoting digestive calcium  absorption,   apoptosis   and   angiogenesis ,   decreasing   cell   proliferation.   It   has   an  immunomodulatory,   anti - infectious,   anti - inflammatory   and   anti - tumor   role.   Vitamin   D  deficiency has been ass ociated with many pathological conditions including osteoporosis,  microbial infections, cardiovascular diseases, cancers, autoimmune diseases, asthma and  allergy (reviewed in   [1] ).   It   is common in the general population (up to 80% of European  adolescents)   [2,3] . The   known   risk factors for   vitamin D   deficiency in adults and children in  the general population are pigmented skin, obesity, self - limitation of solar exposure and   use  of   sunscree ns,   and   poor dietary intake of   vitamin D   ( e.g.,   fatty fish, egg ,   milk)   [4,5] . There is  a seasonal variation in   vitamin D   levels   [6] ,   with   higher   level s   in summer and lower   levels   in  winter.  Cross - sectional studies have recently suggested a   role   for   vitamin D   and its metabolism in  sleep   [7,8] , in   particular   in the development of symptoms such as obstructive sleep apnea   [9] ,  diurnal somnolence   [10] ,   and   restless leg syndrome   [11]   in adults. In   older people ,   vitamin D  deficiency was   found   associated with poor sleep (short duration or low effic iency )   [12]   that  was   improved by supplementation   [13] . In children, only   three   cross - sectional   stud ies   ha ve  been published and show ed   association s   between   vitamin D   deficiency and obstructive sleep  apnea syndrome   and primary snoring   [14 ‚Äì 16] .  Here we aimed   to   analy z e   the   association   between   cord - blood   vitamin D   level   at birth   and  night - sleep duration   trajectories   in children   between 2 and 5 - 6   years   old   in   a non - clinical  cohort.  2.   Material and methods  2.1.   Study   population  The EDEN study aims at investigating the pre -   and post - natal determinants of child health and  development. Details of the EDEN study protocol have been previously published   [17] .  Briefly, pregnant women under 24 weeks of amenorrhea were recruited between 2003 and  2006 in the university hospitals of Poitiers and Nancy. Those under 18 years, unable to give  informed consent, functionally illiterate in French, with a history of diabe tes, planning on  changing address or without social security coverage were excluded from the cohort.   Women  with m ultiple pregnancies were also excluded.   A total of   1899 children were enlisted at birth.  Written informed consent was obtained twice from paren ts: at enrolment and after the child‚Äôs\n\nbirth. The study was approved by   a n   ethics research committee and by the   national d ata  protection a uthority .  2.2.   Measures   and   participant   characteristics  2.2.1.   Cord - blood   vitamin D   measurement  Cord - blood   samples   were   collected   immediately   after   birth   (vaginal   delivery)   or   after  extraction of the fetus   via   uterine incision (elective cesarean section)   and   were centrifuged  within 24   h of collection. The ser um was separated and stored at   - 80 o C . Serum   25 -  hydro xyvitamin D ( 25OH D ) , representative of overall   v it amin   D stored in the body,   was  measured by immunochemiluminescent immunoassay performed on the LIAISON platform  ( DiaSorin ,   Sallugia, Italy). The intra -   and inter - assay coefficient   of variation was   <   10%  whatever the measured   level .   This measure was performed   for   a subsample of   375 children  from   the EDEN cohort   that correspond to infants who had quantitative   ultrasonography  measurements of bone status at   age   1 year   ( i.e. ,   infants examined from April 2006 onward )  [18] .  2.2.2.   Night - sleep duration trajectories   in children   between 2 and 5 - 6 years   old  Night - sleep duration   was   collected at age 2, 3 and 5 - 6 years   by   using parental self -  administered questionnaires and   was   calculated   on the basis of   the answers to the following  questions: ‚ÄúUsually, at what time does your child go to bed?‚Äù, ‚ÄúUsually, at what time does  your child wak e up?‚Äù. Responses were recorded in hours and minutes   (e.g., 10h30) .   \"Group -  based trajectory modeling\" developed by Nagin et al .   [19] , implemented under SAS (PROC  TRAJ) and data - driven ,   was used to identify night - sleep duration trajectories among 1205  children from the cohort   whose   parents had answered the questions regarding night - sleep  durations   for   at least two   of three   age   points. The method is based on the   underlying  hypothesis that   within a population there are inherent groups that evolve according to  different sleep patterns. The groups are not directly identifiable or pre - established by sets of  characteristics but   are   statistically determined   by   each series of responses   by   using   maximum  likelihood.  Five night - sleep duration trajectories were established   as   previously reported   [20]   (Figure 1):  s hort   sleep   (SS, <10 h 30/night, 4.9% of 1205 children),   m edium - l ow   sleep   (MLS, 10 h 30 -  11 h 00/night, 47.8%),   m edium - h igh   sleep   (MHS,   about   11 h 30/night, 37.2%),   l ong   sleep   (LS,  ‚â• 11 h 30/night, 4.5%) and   c hanging   s leep (CS, i.e. ,   LS then MLS, 5.6%). Each child was  assigned   to the trajectory to which he/she belonged with the highest probability. Only children\n\nwith both an   assign ed   trajectory and cord - blood vitamn D measure were included in the  current study.  2.2.3.   Socio - demographic and health characteristics  H ousehold socio - economic and demographic factors as well as maternal characteristics were  collected at inclusion : maternity ward   of recruitment   (N ancy/Poitiers) , h ousehold   monthly  income   (<1500, 1500 - 3000 and   ‚â• 3000 euros , US dollar equivalent: < $ 1600,   $ 1600 - 3250, >  $ 3250) ,   maternal education level (< high - school, high school diploma   to 2 - year university  degree , >2 - year university de gree) ,   and maternal   age at delivery .   Body mass index (BMI)  before pregnancy was calculated   by   using reported height and weight.   Child‚Äôs   sex   and season  of birth was collected from   maternity medical charts .   Because of   French regulation s , ethnic  origin was   not collected. However, we collect ed   information on geographic origin of parents  and grandparents. Children were considered of European origin   if   both parents and maternal  grandparents were   born in a European country .  2.3.   Statistical analys i s  A total of 264 children presented available data for both 25OHD measure and sleep trajectory  and were included in the present analysis.   They were compared to   non - included children for  maternal and child characteristics   by   chi - square and   Student   t   test.   The   association s   between  socio - demographic   and   health   characteristics   and   night - sleep   duration   trajectories   and  between   cord blood   vitamin D   level   and night - sleep trajectories   were   assessed   by multiple  multinomial logistic regression (SAS 9.3 ,   SAS Institute I nc, Cary, NC, USA).   M ultivariable  m odels   estimate d   odds ratio s   (ORs)   and 95% confidence intervals (CIs)   associated with   a   1 -  unit decrease   in   25OHD   level .   C onfounding factors were identified from   the   literature and  selected   by   using the Directed Acyclic   Graphs method ( www.dagitty.net )   [21] . The   resulting  model   adjusted   for   recruitment   centre,   maternal   education,   familial   income,   family  geographical origin, pre - pregnancy   maternal   BMI,   maternal age   at del ivery , child‚Äôs   sex   and  season of birth.  3.   Results  Compared to non - included children,   for   the   264   children in the study , mothers   were   older (30  vs 29 years, p=0.003) and   more educated (4 1 % vs 30%   >2 - year university degree,   p< 0.0001 )  and   had   higher incomes (32% vs 26%   with   income >3000 euros, p< 0.0002 ).   Included  children were frequently   boys   ( 60 %   vs 5 1 %, p=0.0 2 ), born in spring (4 3 %   vs 28%, p< 0.0001 )  and   had   higher   mean 25OHD   level   (1 9   vs 1 5   ng/ml, p =0.00 3 ) .   Distribution of n ight - sleep  duration trajector ies   did not differ between included and excluded children   (p=0. 47 ) .   Table 1\n\nprovide s   the characteristics of included children.   The   me an   25OHD   level   was 1 2   ( SD=7 ) ,   20  ( SD=11 ) , 1 9   ( SD=10 ) , 16   ( SD=8 ) , and 1 4   ( SD=7 )   ng/ml   for the SS, MLS, MHS, CS and LS  trajectories, respectively.   Crude and adjusted   ORs   of belonging to a given sleep trajectory  versus the   MHS   trajectory (reference) are presented in   F igure 2. After adjustment ,   ORs  remained stable and   each 1 - ng/ml decrease   in   25OHD   level   was associated with 12%  increased   odds of   belong ing   to the SS trajectory (vs the MHS trajectory).   Only the   estimated  OR   for   belonging to   the LS trajectory   was modified by adjustment and   increased from   1.06  [ 95% CI   0.98 - 1.14 ] to   1.10 [1.00 - 1.23 ]   for each 1 - ng/ml decrease   in   25OHD   level , remaining  bordeline significant.  4.   Discussion  This is the first   longitudinal study   exploring 25OHD   level   in   newborns   from   the   general  population and its association with sleep duration   during   preschool   age .   On   adjusted analysis,  for each 1 - ng/ml decrease in 25OHD level, the odds of belonging to the SS versus MHS  trajectory was increased 12%.  We report   general ly   low   serum   25OHD   level   at birth   in this sample of children ,   which  suggests   global vitamin D defici ency   in   French   newborns   and their mother s .   The American  Association of Pediatrics estimated that 25OHD   level   should be   ‚â• 20 ng/ml in   infant s   and  children   [22] ,   whereas   the Endocrine Society recommend s   a 25OHD   level   >30   ng/ml   [23] .   In  our study,   only   41%   and 16%   of children presented such   25OHD levels   at birth , respectively .  The prevalence of 25OHD deficiency   (< 20   ng/ml)   wa s   lower   than   that   reported   in   infant cord  blood   in   the United States   [24]   and in a recent French study   [25] ,   which showed   about two  thirds   of newborns with 25OHD   level   < 20   ng/ml .   This   discrepancy   may be due to the  population selection   at inclusion ,   which thus differ ed   from the targeted population   [17]   and  the   follow - up as described ,   with   older mothers,   having   higher   incomes and educat ion   and  higher 25OHD levels in included   than excluded   children .  Cord - blood   25OHD   level s   differed   according to night - sleep trajectories .   We observed a mean  level of about   the recommended level of   20 ng /ml for MHS and MLS trajectories   for children  between 2 and 5 - 6 years   old ;   th ese   two   trajectories   are   nearest to   the recommended sleep  durations for children of this age range   [26] .   D ecreased   cord - blood   25OHD   level   was  associated with an increased   odds of   b elonging to the SS trajectory between 2 and 5 - 6 years  old   (i.e. ,   persistent   night - sleep duration <10h30   between 2 and 5 - 6 years   old ) , which suggests  an   early effect of   25OHD   level   on sleep or sleep regulation.   The a ssociation between   low  25OHD serum   level   and   short sleep duration   was   shown   in cross - sectional   studies   in adults ,\n\nespecially in   older people   i n several countries ( United States , Korea and Brazil)   [12,27 ‚Äì 29] .  However, n o study on sleep duration   was   performed   in   children.  P hysiological links   have been   observed   between vitamin D and sleep ,   suggesting that vitamin  D has direct effects on   the   initiation and mainte n ance of sleep   [30] .   Indeed,   the   v itamin D  receptor   is involved in brain development   [31]   and   ha s   been found in many cerebral regions,  including   those   that regulate sleep   [32 ‚Äì 38] .   Trials   of   vitamin D supplementation in adults  with sleep troubles showed sleep amelioration, including increased sleep dur ation   [35,39] .  However,   vitamin D deficiency   occur r ing in   early   childhood   during brain development   may  lead to   persi s tent sleep troubles.  25OHD easily cross es the   placenta barrier ,   with   a   strong correlation between cord   blood   and  maternal serum values   [40] .   The vitamin D pool of   the   fetus and newborn depends on their  mother‚Äôs   vitamin D   status.   Vitamin D supplementation during pregnancy should limit vitamin  D deficiency in infant s   and may favor both brain development and   healthy   sleep in children.  While already   applied   during pregnancy, supplementation seems insufficient and sho uld be  reinforced   [25] .   Increased c hild‚Äôs sleep duration with vitamin D supplementation need s  further exploration.  The s trengths of this study are the general population sample   and the longitudinal data for  sleep duration   in children .   This study also presents   some   limitations.   The a ttrition discussed  above   restrict s the generalization of the results. However, included and excluded children did  not differ   by   sleep trajector y   distribution ,   and 25OHD   level   was   measured   in the context of  another study objective , with blinding   to sleep data. Thus,   the   bias should be minimal.  However,   because   the studied sample size was   greatly   reduced , the   sampling fluctuations (i.e. ,  confidence i ntervals) were increased   and   results   need to be replicated   in   a   larger population .  5.   Conclusion  In this first longitudinal study exploring   the   relation   between 25OHD level at birth and sleep  duration in preschool years, we   suggest   that low 25OHD level is associated with increased  odds of   children   in a French birth cohort   between 2 and 5 - 6 years old   to be persistent short  sleeper s . These results need to be confirmed in larger sample of children from   the   general  population.\n\nAcknowle dgments  Collaborators: We thank the EDEN mother - child cohort study group (I. Annesi - Maesano, J.Y  Bernard, J. Botton, M.A. Charles, P. Dargent - Molina, B. de Lauzon - Guillain, P. Ducimeti√®re,  M. de Agostini, B. Foliguet, A. Forhan, X. Fritel, A. Germa, V. Gou a, R. Hankard, B. Heude,  M. Kaminski, B. Larroque‚Ä†, N. Lelong, J. Lepeule, G. Magnin, L. Marchand, C. Nabet, F.  Pierre, R. Slama, M.J. Saurel - Cubizolles, M. Schweitzer, O. Thiebaugeorges).  We thank all funding sources for the EDEN study: Foundation for me dical research (FRM),  National Agency for Research (ANR), National Institute for Research in Public health  (IRESP: TGIR cohorte sant√© 2008 program), French Ministry of Health (DGS), French  Ministry of Research, INSERM Bone and Joint Diseases National Resea rch (PRO - A) and  Human Nutrition National Research Programs, Paris ‚Äì Sud University, Nestl√©, French National  Institute for Population Health Surveillance (InVS), French National Institute for Health  Education (INPES), the European Union FP7 programs (FP7/2007 - 2013, HELIX, ESCAPE,  ENRIECO,Medall projects), Diabetes National Research Program (in collaboration with the  French Association of Diabetic Patients (AFD), French Agency for Environmental Health  Safety (now ANSES), Mutuelle G√©n√©rale de l‚ÄôEducation Nationa le complementary health  insurance (MGEN), French national agency for food security, French speaking association for  the study of diabetes and metabolism (ALFEDIAM).\n\nReferences  [1]   Pludowski P, Holick MF, Wagner CL, Hollis BW, Grant WB, Shoenfeld Y, et al.  Vitamin   D   effects   on   musculoskeletal   health,   immunity,   autoimmunity,   cardiovascular  disease, cancer, fertility, pregnancy, dementia and mortality ‚Äî A review of recent evidence.  A utoimmun Rev 2013;12:976 ‚Äì 89.  [2]   Braegger C, Campoy C, Colomb V, Decsi T, Domellof M, Fewtrell M, et al. Vitamin  D in the healthy European paediatric population. J Pediatr Gastroenterol Nutr 2013;56:692 ‚Äì  701. doi:10.1097/MPG.0b013e31828f3c05.  [3]   Gonz√°lez - G ross M, Valtue√±a J, Breidenassel C, Moreno LA, Ferrari M, Kersting M, et  al. Vitamin D status among adolescents in Europe: the Healthy Lifestyle in Europe by  Nutrition   in   Adolescence   study.   Br   J   Nutr   2012;107:755 ‚Äì 64.  doi:10.1017/S0007114511003527.  [4]   Bacc hetta J, Ranchin B, Dubourg L, Cochat P. Vitamine D   : un acteur majeur en  sant√©   ? Arch P√©diatrie 2010;17:1687 ‚Äì 95. doi:10.1016/j.arcped.2010.09.003.  [5]   Holick MF. Vitamin D deficiency. N Engl J Med 2007;357:266 ‚Äì 281.  [6]   Karag√ºzel G, Dilber B, √áan G, √ñkten   A, De ƒü er O, Holick MF. Seasonal Vitamin D  Status of Healthy Schoolchildren and Predictors of Low Vitamin D Status: J Pediatr  Gastroenterol Nutr 2014;58:654 ‚Äì 60. doi:10.1097/MPG.0000000000000274.  [7]   McCarty DE, Chesson AL, Jain SK, Marino AA. The link betwe en vitamin D  metabolism   and   sleep   medicine.   Sleep   Med   Rev   2014;18:311 ‚Äì 9.  doi:10.1016/j.smrv.2013.07.001.  [8]   de Oliveira DL, Hirotsu C, Tufik S, Andersen ML. The interfaces between vitamin D,  sleep and pain. J Endocrinol 2017;234:R23 ‚Äì 36. doi:10.1530 /JOE - 16 - 0514.  [9]   Mete T, Yalcin Y, Berker D, Ciftci B, Guven SF, Topaloglu O, et al. Obstructive sleep  apnea   syndrome   and   its   association   with   vitamin   D   deficiency.   J   Endocrinol   Invest  2013;36:681 ‚Äì 685.  [10]   McCarty DE, Reddy A, Keigley Q, Kim PY, Marino A A. Vitamin D, Race, and  Excessive Daytime Sleepiness. J Clin Sleep Med 2012. doi:10.5664/jcsm.2266.  [11]   Balaban H, Yƒ±ldƒ±z √ñK, √áil G,   ≈û ent√ºrk   ƒ∞ A, Erselcan T, Bolayƒ±r E, et al. Serum 25 -  hydroxyvitamin D levels in restless legs syndrome patients. Sleep Med 2 012;13:953 ‚Äì 7.  doi:10.1016/j.sleep.2012.04.009.  [12]   Massa J, Stone KL, Wei EK, Harrison SL, Barrett - Connor E, Lane NE, et al. Vitamin  D and Actigraphic Sleep Outcomes in Older Community - Dwelling Men: The MrOS Sleep  Study. Sleep 2015;38:251 ‚Äì 7. doi:10.5665/s leep.4408.  [13]   Majid MS, Ahmad HS, Bizhan H, Mohammad Hosein HZ, Mohammad A. The effect  of vitamin D supplement on the score and quality of sleep in 20 ‚Äì 50 year - old people with sleep  disorders   compared   with   control   group.   Nutr   Neurosci   2017:1 ‚Äì 9.  doi:10.108 0/1028415X.2017.1317395.  [14]   Ozgurhan G, Vehapoglu A, Vermezoglu O, Temiz RN, Guney A, Hacihamdioglu B.  Risk assessment of obstructive sleep apnea syndrome in pediatric patients with vitamin D  deficiency:   A   questionnaire - based   study.   Medicine   (Baltimore)   2016;95:e4632.  doi:10.1097/MD.0000000000004632.  [15]   Kheirandish - Gozal L, Peris E, Gozal D. Vitamin D levels and obstructive sleep apnoea  in children. Sleep Med 2014;15:459 ‚Äì 63. doi:10.1016/j.sleep.2013.12.009.  [16]   Zicari AM, Occasi F, Di Mauro F, Lollobri gida V, Di Fraia M, Savastano V, et al.  Mean Platelet Volume, Vitamin D and C Reactive Protein Levels in Normal Weight Children  with   Primary   Snoring   and   Obstructive   Sleep   Apnea   Syndrome.   PLOS   ONE  2016;11:e0152497. doi:10.1371/journal.pone.0152497.  [17]   Heu de B, Forhan A, Slama R, Douhaud L, Bedel S, Saurel - Cubizolles M - J, et al.  Cohort   Profile:   The   EDEN   mother - child   cohort   on   the   prenatal   and   early   postnatal\n\ndeterminants   of   child   health   and   development.   Int   J   Epidemiol   2015;45:353 ‚Äì 63.  doi:10.1093/ije/dyv151 .  [18]   Regnault N, Botton J, Forhan A, Hankard R, Thiebaugeorges O, Hillier TA, et al.  Determinants of early ponderal and statural growth in full - term infants in the EDEN mother -  child cohort study. Am J Clin Nutr 2010;92:594 ‚Äì 602. doi:10.3945/ajcn.2010.2929 2.  [19]   Nagin   D.   Group - based   modeling   of   development.   Cambridge,   Mass:   Harvard  University Press; 2005.  [20]   Plancoulaine S, Reynaud E, Forhan A, Lioret S, Heude B, Charles M - A, et al. Night  sleep duration trajectories and associated factors among preschool   children from the EDEN  cohort. Sleep Med 2018. doi:10.1016/j.sleep.2018.03.030.  [21]   Textor J, Hardt J, Kn√ºppel S. DAGitty: A Graphical Tool for Analyzing Causal  Diagrams. Epidemiology 2011;22:745. doi:10.1097/EDE.0b013e318225c2be.  [22]   Wagner CL, Greer F R, and the Section on Breastfeeding and Committee on Nutrition.  Prevention of Rickets and Vitamin D Deficiency in Infants, Children, and Adolescents.  PEDIATRICS 2008;122:1142 ‚Äì 52. doi:10.1542/peds.2008 - 1862.  [23]   Holick MF, Binkley NC, Bischoff - Ferrari HA,   Gordon CM, Hanley DA, Heaney RP,  et al. Evaluation, Treatment, and Prevention of Vitamin D Deficiency: an Endocrine Society  Clinical Practice Guideline. J Clin Endocrinol Metab 2011;96:1911 ‚Äì 30. doi:10.1210/jc.2011 -  0385.  [24]   Marshall I, Mehta R, Ayers C, D humal S, Petrova A. Prevalence and risk factors for  vitamin D insufficiency and deficiency at birth and associated outcome. BMC Pediatr  2016;16. doi:10.1186/s12887 - 016 - 0741 - 4.  [25]   Ceccaldi P - F, Pejoan H, Breau N, Diallo D, Ducarme G, Poujade O, et al. Fre nch  prenatal Vitamin D recommended supplementation: Enough or not? J Gynecol Obstet Hum  Reprod 2017;46:35 ‚Äì 41. doi:10.1016/j.jgyn.2016.02.009.  [26]   Paruthi S, Brooks LJ, D‚ÄôAmbrosio C, Hall WA, Kotagal S, Lloyd RM, et al.  Recommended Amount of Sleep for Pedi atric Populations: A Consensus Statement of the  American   Academy   of   Sleep   Medicine.   J   Clin   Sleep   Med   2016;12:785 ‚Äì 6.  doi:10.5664/jcsm.5866.  [27]   Kim JH, Chang JH, Kim DY, Kang JW. Association Between Self - Reported Sleep  Duration   and   Serum   Vitamin   D   Level   in   Elderly   Korean   Adults.   J   Am   Geriatr   Soc  2014;62:2327 ‚Äì 32. doi:10.1111/jgs.13148.  [28]   Piovezan RD, Hirotsu C, Feres MC, Cintra FD, Andersen ML, Tufik S, et al.  Obstructive sleep apnea and objective short sleep duration are independently associated with  the   risk   of   serum   vitamin   D   deficiency.   PLOS   ONE   2017;12:e0180901.  doi:10.1371/journal.pone.0180901.  [29]   Bertisch SM, Sillau S, de Boer IH, Szklo M, Redline S. 25 - Hydroxyvitamin D  Concentration and Sleep Duration and Continuity: Multi - Ethnic Study of Atheros clerosis.  Sleep 2014.  [30]   Mizoguchi A, Eguchi N, Kimura K, Kiyohara Y, Qu W - M, Huang Z - L, et al.  Dominant localization of prostaglandin D receptors on arachnoid trabecular cells in mouse  basal forebrain and their involvement in the regulation of non - rapid   eye movement sleep. Proc  Natl Acad Sci 2001;98:11674 ‚Äì 11679.  [31]   Eyles DW, Burne THJ, McGrath JJ. Vitamin D, effects on brain development, adult  brain function and the links between low levels of vitamin D and neuropsychiatric disease.  Front Neuroendocrin ol 2013;34:47 ‚Äì 64. doi:10.1016/j.yfrne.2012.07.001.  [32]   Musiol IM, Stumpf WE, Bidmon H - J, Heiss C, Mayerhofer A, Bartke A. Vitamin d  nuclear binding to neurons of the septal, substriatal and amygdaloid area in the siberian  hamster   (Phodopus   sungorus)   brain .   Neuroscience   1992;48:841 ‚Äì 8.   doi:10.1016/0306 -  4522(92)90272 - 4.\n\n[33]   Stumpf WE, Bidmon HJ, Li L, Pilgrim C, Bartke A, Mayerhofer A, et al. Nuclear  receptor sites for vitamin D - soltriol in midbrain and hindbrain of Siberian hamster (Phodopus  sungorus) asses sed by autoradiography. Histochemistry 1992;98:155 ‚Äì 64.  [34]   Stumpf WE, O‚ÄôBrien LP. 1,25 (OH)2 vitamin D3 sites of action in the brain. An  autoradiographic study. Histochemistry 1987;87:393 ‚Äì 406.  [35]   Gominak SC, Stumpf WE. The world epidemic of sleep disord ers is linked to vitamin  D deficiency. Med Hypotheses 2012;79:132 ‚Äì 5. doi:10.1016/j.mehy.2012.03.031.  [36]   Eyles DW, Smith S, Kinobe R, Hewison M, McGrath JJ. Distribution of the Vitamin  D   receptor   and   1 Œ± - hydroxylase   in   human   brain.   J   Chem   Neuroanat   2005 ;29:21 ‚Äì 30.  doi:10.1016/j.jchemneu.2004.08.006.  [37]   Garcion E, Wion - Barbot N, Montero - Menei CN, Berger F, Wion D. New clues about  vitamin D functions in the nervous system. Trends Endocrinol Metab 2002;13:100 ‚Äì 105.  [38]   Saper CB, Scammell TE, Lu J. Hypothal amic regulation of sleep and circadian  rhythms. Nature 2005;437:1257.  [39]   Huang W, Shah S, Long Q, Crankshaw AK, Tangpricha V. Improvement of pain,  sleep, and quality of life in chronic pain patients with vitamin D supplementation. Clin J Pain  2013;29:341 ‚Äì 7. doi:10.1097/AJP.0b013e318255655d.  [40]   Zasimovich A, Fija ≈Ç kowska A, Che ≈Ç chowska M, Maciejewski T. Maternal serum  vitamin D and parathormone concentrations during gestation and in umbilical cord blood   ‚Äì  pilot study. J Matern Fetal Neonatal Med 2017:1 ‚Äì 9.   doi:10.1080/14767058.2016.1277705.  [41]   Plancoulaine S, Reynaud E, Forhan A, Lioret S, Heude B, Charles MA. Night sleep  duration trajectories and associated factors among preschool children from the EDEN cohort.  Press n.d. doi:10.1016/j.sleep.2018.03.030.\n\nTable 1 . Description of the studied population (N=264) from the EDEN   mother - child   cohort   by night - sleep duration trajectories .  Total   SS (N=14, 5%)  MLS (N=121,  46%)  MHS (N=98,  37%)   CS (N=20, 8%)   LS (N=11, 4%)  n (%) or mean  ( SD )  n (%) or mean  ( SD )  n (%) or mean  ( SD )  n (%) or mean  ( SD )  n (%) or mean  ( SD )  n (%) or mean  ( SD )  p -  value  Maternal  characteristics  Recruitment center  (Poitiers)   122 (46%)   5 (36%)   52 (43%)   49 (50%)   7 (35%)   9 (82%)   0.08  Family   income  ( ‚Ç¨ /month)   0.82  <1500   22 (8%)   1 (7%)   10 (8%)   8 (8%)   3 (15%)   0 (0%)  [1500 - 3000]   157 (60%)   10 (72%)   74 (61%)   54 (55%)   13 (65%)   6 (55%)  >3000   85 (32%)   3 (21%)   37 (31%)   36 (37%)   4 (20%)   5 (45%)  Maternal education level   0.41  <High school   50 (19%)   4 (28%)   20   (17%)   19 (19%)   6 (30%)   1 (9%)  High school   to   2 - year  university   degree   106 (40%)   5 (36%)   52 (43%)   35 (36%)   6 (30%)   8 (73%)  >2 year university  degree   108 (41%)   5 (36%)   49 (40%)   44 (45%)   8 (40%)   2 (18%)  Maternal age at delivery  (years)   30 (5)   30 (5)   30   (4)   31 (5)   30 (5)   30 (4)   0.87  Pre - pregnancy BMI   23 (4)   23 (3)   23 (4)   23 (4)   22 (6)   24 (5)   0.93  Child characteristics  Sex   ( b oy)   156 (60%)   12 (86%)   78 (64%)   53 (54%)   8 (40%)   5 (45%)   0.05  Birth season   0.89  Spring   113 (43%)   5 (36%)   50 (41%)   46 (47%)   8 (40%)   4 (37%)  Summer   65 (25%)   1 (7%)   34 (28%)   23 (24%)   4 (20%)   3 (27%)  Autumn   53 (20%)   5 (36%)   22 (18%)   18 (18%)   5 (25%)   3 (27%)  Winter   33 (12%)   3 (21%)   15 (13%)   11 (11%)   3 (15%)   1 (9%)\n\nCord - b lood 25OHD  level   (ng/ml)   19 (11)   12   (7)   20 (11)   19 (10)   16 (8)   14 (7)   0.02  <10   59 (23%)   6 (43%)   23 (19%)   22 (23%)   6 (30%)   2 (18%)  10 - 20   98 (37%)   6 (43%)   39 (32%)   39 (40%)   7 (35%)   7 (64%)  21 - 29   64 (24%)   2 (14%)   33 (27%)   21 (21%)   6 (30%)   2 (18%)  ‚â• 30   43 (16%)   0 (0%)   26 (22%)   16 (16%)   1   (5%)   0 (0%)  * SS =   s hort   s leep (<10 h 30/night), MLS =   medium - low sleep   (10 h 30 - 11 h 00/night), MHS =   medium - high sleep   ( about   11 h 30/night), CS =  c hanging   s leep (i.e. ,   LS then MLS) and LS=   l ong   s leep ( ‚â• 11 h 30/night).\n\nFigure 1.   Night - sleep duration trajectories   for   EDEN preschool children (N=1205). Full lines  represent mean sleep duration trajectories. Black circles =   s hort sleep (SS, 4.9% of the  children): triangles =   m edium - l ow sleep (MLS, 47.8% of the children); diamonds =   m edium -  h i gh sleep (MHS, 37.2% of the children), squares =   c hanging   sleep   (CS, 5.6% of the children)  and white circles =   l ong sleep (LS, 4.5% of the children). Dashed lines represent the 95%  confidence intervals   for   the trajectory estimations. Figure from Plancoulai ne et al.   [41] .  9  9,5  10  10,5  11  11,5  12  12,5  13  2   2,5   3   3,5   4   4,5   5   5,5  Night sleep duration (hours)  Age (years)\n\nFigure 2.   Unadjusted (in grey) and a djusted   (in black)   odds ratio s   for 1 - ng/ml decrease   in  25OHD   level by   sleep duration trajectories.   SS =   short sleep (<10h30/night), MLS = medium -  low sleep (10h30 - 11h00/night), MHS = medium - high sleep (about 11h30/night), CS =  changing sleep (i.e., LS then MLS) and LS= long sleep ( ‚â• 11h30/night).   MHS is the reference  trajectory.  0,9   1   1,1   1,2   1,3  LS  CS  MHS (ref)  MLS  SS  Odds ratios and 95% confidence intervals  Night sleep duration trajectories",
      "embedding": [
        -0.019491462036967278,
        -0.02682466059923172,
        -0.005726881790906191,
        0.0016886264784261584,
        0.050942711532115936,
        0.030266359448432922,
        -0.08878526836633682,
        0.08609054982662201,
        0.059031616896390915,
        0.05862386152148247,
        0.003811572678387165,
        -0.00634006317704916,
        0.06727337837219238,
        0.048787761479616165,
        -0.029483530670404434,
        -0.004581569693982601,
        0.030978716909885406,
        0.06772305816411972,
        -0.03106221742928028,
        0.04532037675380707,
        0.046584948897361755,
        0.035902947187423706,
        0.07355891913175583,
        0.03431723266839981,
        0.03973649442195892,
        0.03868117183446884,
        0.041752997785806656,
        -0.06569027900695801,
        -0.0698111355304718,
        0.08580312877893448,
        -0.07973388582468033,
        0.05994364619255066,
        0.010490751825273037,
        -0.026867374777793884,
        -0.03777184337377548,
        -0.004081350285559893,
        0.06653902679681778,
        0.03905550763010979,
        -0.10176385194063187,
        0.04059205204248428,
        0.0018820364493876696,
        -0.021558387205004692,
        -0.09244702756404877,
        -0.05727384611964226,
        -0.019013868644833565,
        -0.06614691764116287,
        -0.04545798897743225,
        0.0017858067294582725,
        -0.07349289953708649,
        0.11996510624885559,
        -0.03276776522397995,
        -0.026798661798238754,
        -0.028358835726976395,
        0.0022462918423116207,
        0.011083928868174553,
        -0.05599338933825493,
        -0.05146801099181175,
        -0.026283130049705505,
        0.052134737372398376,
        0.02381741814315319,
        -0.06434129178524017,
        0.0024838242679834366,
        0.05207176133990288,
        -0.059190068393945694,
        0.07247642427682877,
        0.04573017358779907,
        0.023868059739470482,
        -0.002233468694612384,
        -0.018504351377487183,
        -0.0912579894065857,
        -0.009849593043327332,
        -0.07189469039440155,
        0.06999526917934418,
        0.03312290087342262,
        0.0045123654417693615,
        0.03274032846093178,
        0.07614411413669586,
        0.02382812090218067,
        0.006822183728218079,
        -0.12717637419700623,
        -0.013771407306194305,
        0.11216003447771072,
        0.0055956426076591015,
        0.02752726338803768,
        -0.006791730411350727,
        0.002384791849181056,
        0.04126001521945,
        0.09601245820522308,
        -0.046514399349689484,
        0.004599441308528185,
        0.010327166877686977,
        -0.021038737148046494,
        -0.03570256754755974,
        0.057281360030174255,
        0.05844056233763695,
        -0.004741843789815903,
        -0.014068721793591976,
        0.031897395849227905,
        -0.010740523226559162,
        -0.13850565254688263,
        -0.04614197462797165,
        0.00124854885507375,
        -0.005338919349014759,
        0.07837937772274017,
        -0.014204242266714573,
        0.009813482873141766,
        -0.02430804818868637,
        -0.07070334255695343,
        -0.06640776991844177,
        -0.003036607289686799,
        0.005453657358884811,
        0.06335285305976868,
        -0.014510070905089378,
        0.03458208963274956,
        0.07870674878358841,
        0.009148701094090939,
        0.03823858126997948,
        0.03944437578320503,
        -0.006584957707673311,
        0.00820304173976183,
        0.01742658205330372,
        -0.007872896268963814,
        0.07614797353744507,
        -0.06041666865348816,
        -0.005968728102743626,
        -0.02906697615981102,
        0.013686313293874264,
        6.535185087967493e-33,
        -0.017742441967129707,
        -0.014526057057082653,
        -0.003971446305513382,
        0.07121151685714722,
        -0.051086049526929855,
        0.05536230280995369,
        -0.03929617628455162,
        0.09840955585241318,
        0.04236297681927681,
        -0.005961154121905565,
        -0.06253152340650558,
        -0.03548272326588631,
        -0.00433315010741353,
        -0.02827722206711769,
        -0.015515544451773167,
        0.07918194681406021,
        0.006024188827723265,
        -0.06851737201213837,
        -0.020862694829702377,
        0.01651095785200596,
        -0.00815851055085659,
        0.008501602336764336,
        0.09578293561935425,
        0.05952499061822891,
        -0.02580568566918373,
        0.011980118229985237,
        0.0002802294911816716,
        0.06091267243027687,
        -0.019100425764918327,
        -0.008889232762157917,
        -0.041522324085235596,
        -0.10850020498037338,
        0.02895997278392315,
        -0.0802086740732193,
        0.0345110259950161,
        -0.007065795361995697,
        0.039701711386442184,
        0.05129074305295944,
        -0.08320806920528412,
        0.029039185494184494,
        -0.0815814957022667,
        0.0029513323679566383,
        -0.04984916374087334,
        -0.0312877781689167,
        0.031029189005494118,
        -0.021926727145910263,
        0.0028021428734064102,
        -0.02717399038374424,
        0.008289135992527008,
        0.0024665272794663906,
        -0.020634502172470093,
        0.019860368221998215,
        -0.04864906892180443,
        -0.06632038950920105,
        -0.08303551375865936,
        0.01847825199365616,
        -0.03443023934960365,
        -0.027249587699770927,
        -0.12095563858747482,
        0.05746298283338547,
        -0.018053622916340828,
        -0.012650374323129654,
        0.022479461506009102,
        -0.060726337134838104,
        -0.054074667394161224,
        -0.0016682434361428022,
        -0.008509627543389797,
        -0.028475940227508545,
        -0.005358083173632622,
        -0.09544390439987183,
        0.07868766039609909,
        -0.06842897087335587,
        0.0705542042851448,
        0.0241587832570076,
        0.03361817076802254,
        0.0019435336580500007,
        0.052594397217035294,
        0.0628696084022522,
        -0.03702440857887268,
        -0.09844055026769638,
        -0.010595269501209259,
        0.06410905718803406,
        0.0066162594594061375,
        -0.014771283604204655,
        -0.02889280393719673,
        -0.027086833491921425,
        0.03388611227273941,
        0.06630339473485947,
        -0.10743188112974167,
        -0.07500452548265457,
        -0.0015363928396254778,
        -0.05685550719499588,
        0.03057737462222576,
        0.013432174921035767,
        0.007859313860535622,
        -8.771579253454219e-33,
        -0.040060706436634064,
        -0.031321264803409576,
        0.0024774810299277306,
        -0.09018471091985703,
        0.040367335081100464,
        0.0014582581352442503,
        0.05085424333810806,
        -0.021445203572511673,
        -0.012289469130337238,
        -0.11716897785663605,
        0.041162047535181046,
        -0.0399041473865509,
        -0.031827230006456375,
        -0.06411538273096085,
        0.0022085667587816715,
        0.1036936491727829,
        -0.08521389216184616,
        0.015510296449065208,
        -0.04921407252550125,
        0.06782522052526474,
        0.019380958750844002,
        -0.05331018567085266,
        -0.04724433273077011,
        -0.044459860771894455,
        0.09103074669837952,
        0.07901277393102646,
        0.04815525561571121,
        0.07939112931489944,
        0.003971127327531576,
        0.024320587515830994,
        0.05233093723654747,
        0.07154563069343567,
        -0.05953628569841385,
        0.02261476032435894,
        0.033128660172224045,
        0.008777589537203312,
        -0.0237430427223444,
        -0.0006842822767794132,
        -0.059871431440114975,
        -0.05354107916355133,
        0.007058813702315092,
        0.030113687738776207,
        0.027602113783359528,
        -0.0256193857640028,
        0.011581378057599068,
        0.10543548315763474,
        0.04914082959294319,
        -0.04492868110537529,
        0.016306225210428238,
        0.02464849315583706,
        0.0910058319568634,
        0.05379732698202133,
        -0.05110328271985054,
        0.076924629509449,
        -0.02095322497189045,
        0.01824035309255123,
        0.03158780559897423,
        0.06597647815942764,
        -0.007524949964135885,
        0.014722066931426525,
        0.06335125863552094,
        -0.04897703975439072,
        -0.03176288679242134,
        -0.061616040766239166,
        0.07512050122022629,
        -0.04127897322177887,
        0.0000669743021717295,
        -0.03990839421749115,
        0.061509475111961365,
        -0.0019547538831830025,
        -0.008992581628262997,
        -0.08003094047307968,
        0.00855071097612381,
        -0.04574856534600258,
        -0.033805686980485916,
        -0.05576549470424652,
        -0.026325739920139313,
        -0.016631443053483963,
        -0.0257282592356205,
        0.004500276874750853,
        -0.043836984783411026,
        -0.09786861389875412,
        -0.01605493389070034,
        0.0019392630783841014,
        -0.05905812233686447,
        -0.14689910411834717,
        0.05309551581740379,
        -0.040637947618961334,
        0.04341914504766464,
        0.021145816892385483,
        -0.06964225322008133,
        0.026222551241517067,
        -0.1700831949710846,
        -0.01693623512983322,
        0.052926205098629,
        -6.361484139461027e-8,
        0.1416962742805481,
        -0.044740259647369385,
        -0.004977610893547535,
        0.02141374535858631,
        0.04269208386540413,
        -0.07724279910326004,
        -0.039779357612133026,
        0.0653047040104866,
        0.02689751237630844,
        0.1076812744140625,
        0.005995412822812796,
        0.046029724180698395,
        -0.0069938478991389275,
        -0.006384655367583036,
        -0.010097630321979523,
        -0.05375317856669426,
        -0.04352123662829399,
        0.08077099174261093,
        0.017542704939842224,
        0.036692798137664795,
        0.04894958809018135,
        0.012048404663801193,
        -0.10090569406747818,
        -0.09032601863145828,
        0.02591230720281601,
        -0.07825516909360886,
        0.01001768745481968,
        0.002390411449596286,
        0.03516586869955063,
        -0.10575062781572342,
        0.07913114875555038,
        -0.02149774320423603,
        0.019641883671283722,
        -0.04171520471572876,
        -0.006018745247274637,
        -0.06677158921957016,
        0.022739777341485023,
        0.046285368502140045,
        -0.05735434964299202,
        0.11252205818891525,
        -0.009884626604616642,
        -0.03684739023447037,
        -0.0587025061249733,
        0.021110301837325096,
        0.07251764088869095,
        -0.038030900061130524,
        -0.011226286180317402,
        0.04710644483566284,
        0.03472005948424339,
        0.03206317499279976,
        -0.060246434062719345,
        -0.051611464470624924,
        0.02101469784975052,
        -0.07823244482278824,
        -0.03676954656839371,
        0.05357872694730759,
        -0.001154717174358666,
        -0.033392105251550674,
        0.0008145564352162182,
        -0.052660200744867325,
        -0.0187664981931448,
        -0.031048782169818878,
        -0.007516914512962103,
        -0.021854689344763756
      ],
      "metadata": {
        "title": "Paper_11_Cord_blood_vitamin_D_level_and_night_sleep_duratio.pdf",
        "createdAt": "2025-12-17T13:56:29.158Z"
      },
      "fileObj": {}
    },
    {
      "id": "doc_2_1765979790076",
      "fileName": "Paper_12_Sleep_and_its_relation_to_cognition_and_behaviour_.pdf",
      "content": "S leep and its relation to cognition and behavior in preschool - aged children   of the general  population : a systematic review  Short title :   Sleep, cognition and behavior in   preschoolers  Authors : Eve Reynaud 1 ,2,3 , Marie - Fran√ßoise Vecchierini MD, PhD 4 ,   Barbara Heude PhD 1 ,2 , Marie - Aline  Charles MD, PhD 1 ,2 , Sabine Plancoulaine MD, PhD 1 ,2  Affiliations :   1   INSERM, UMR1153, Epidemiology and Statistics Sorbonne Paris Cit√© Research Center  (CRESS), early ORigins of Child Health And Development Team (ORCHAD), Villejuif, F - 94807 France;  2   Paris - Descartes University, Paris, France;  3   Ecole des Hautes Etudes en S ant√© Publique (EHESP), Rennes, F - 35043 France  4   H√¥pital H√¥tel Dieu, Centre du Sommeil et de la Vigilance, AP - HP, Paris, France; Sorbonne Paris Cit√©,  EA 7320 VIFASOM, Universit√© Paris Descartes, Paris, France.  Address correspondence to : Sabine Plancoulaine , INSERM U1153, Team 6 ORCHAD, 16 Avenue Paul  Vaillant Couturier, 94807 Villejuif Cedex, France, [sabine.plancoulaine@inserm.fr], + 33 145 - 595 - 109  Conflict of interest :   There are no financial or non - financial conflict s   of interes t.   This research did not  receive any specific grant from funding agencies in the public, commercial, or not - for - profit sectors  Author   contributorship :   Eve   Reynaud   and   Sabine   Plancoulaine   developed   the   search   strategy   and  conducted   the   selection   of   articles ,   data   extraction   and   reporting.   Eve   Reynaud   drafted   the   initial  manuscript under the supervision of Sabine Plancoulaine . Marie - Fran√ßoise Vecchierini contributed to the  search strategy, and gave guidance for the summary o f the data.   Barbara Heude and Marie - Aline Charles  gave guidance   on child development and systematic review methodology . All authors have reviewed   the  draft versions of the   manuscript   and approved the final   version   as submitted .\n\nAbstract  Background:   While   the relations between sleep, cognition and behavior have been extensively studied in  adolescents and school - aged children, very little attention has been given to preschoolers.  Objective:   In this   systematic review,   o ur   aim   was   to   survey   articles that address   the link between sleep  and both cognition and behavior in preschoolers (24   to   72   months   old).  Methods:   Four electronic databases were searched, namely Medline, Web of Science, PsycINFO and  ERIC, completed by forward and backward cit ation search.  Results:   Among the 1 590   articles identified   ( minus   duplicates) , 2 6   met the inclusion criteria.   Globally,  studies with the largest sample sizes   (N=13)   found that   a   greater   quantity or quality of sleep was  associated with better behavioral and   cognitive outcomes , while   the   others were   less   consistent .  Conclusion:   Although the   current   literature seems to indicate that sleep is related to behavioral and  cognitive development as early as preschool years,   the   strength   of the associations (i.e.   effect sizes )   w as  relatively small .   In addition to   taking stock of the   available data, this systematic review   identifies   potential  sources of improvement   for future research .  Abbreviations  BT Bedtime, CBCL Child Behavior Checklist, NSD Night Sleep   Duration, NA Non - available, NS Non -  significant, NW Night - waking, PBQ Preschool Behavior Questionnaire, PKBS   Preschool and Kindergarten  Behaviors Scale , SDQ Strength and Difficulty Questionnaire, SE Sleep efficiency, SOL sleep onset latency,  SP sleep proble ms, SD total sleep duration, WT wake up time\n\nS ummary  This is the first systematic review   of the literature on   sleep and its relation to cognition and behavior in  preschool - aged children.   In comparison with the literature   focused   on school - aged children,   knowledge  involving   preschoolers is rather sparse. A total of 26 studies were included   in this review , which revealed  a high degree of   heterogeneity regarding the type and means of measur ing   sleep variables and  behavioral and cognitive   variables , as well as the statistical methods employed.   Amongst   the 13 articles  with   the largest   sample size s   ( top   50% of the included studies,   12   different   populations ) , 12 found that a  higher quantity or quality of sleep was associated with better behavioral and/ or cognitive outcomes.  Results point to an association between sleep, behavior and cognition as early as preschool years , but  the strengths of associations reported in the articles were relatively small .   S tudies with a smaller sample  size were less   concordant . It is consistent with our findings that the strengths of association are small,  and thus require   large sample size s   to ensure   statistical detection power . D ifferent   aspects of sleep   were  not   associated with   all cognitive or behavioral features   in the same way ,   which   underscores   the need for  specific   measures   rather than   general   ones   such as ‚Äúsleep problems‚Äù or ‚Äúbehavior problems‚Äù   to   be able to  decipher   the   relationships .   There is   also   a need for large longitudinal studies using   objective measures  and   accounting for   confounding factors.   The child‚Äôs genotype has recently been shown to have a  moderating role in the association between sleep and behavior,   and should be further explored .  Keywords  Sleep, preschool, cognition,   behavior, systematic review\n\nI NTRODUCTION  Debate continues over the precise function of sleep ,   especially with regard to   its   role   in   cogn itive and  behavioral capacities   (Stickgold and   Walker, 2005; Vertes and Siegel, 2005) .   In the literature, s everal  hypotheses   explain   how sleep   might be   related to cognition and behavior. The ‚Äúvigilance hypothesis‚Äù, as  described by Vriend et al .   ( 2015) ,   is perhaps   the most instinctive one.   It postulates that sleepiness is an  intermediate lin k .   A lack of sleep   induces   sleepiness   ‚Äì   as shown in experimental studies on adolescents  and school - aged children   (Carskadon et al., 1981; Fallone et al., 2001)   ‚Äì   which in turn has been  associated with   conduct problems ,   reduce d   attention, processing spee d   and   working memory   (Calhoun et  al., 2012) .   This hypothesis proposes   that   sleep plays a passive role , while other s   suggest   an active role  such as ‚Äúsleep - dependent memory consolidation‚Äù ,   ‚Äúsynaptic homeostasis‚Äù   and ‚Äúamygdala medial -  prefrontal cortex connectivity‚Äù .   The   mechanism   by   which   newly acquir ed knowledge become s   long - lasting  memories , called   ‚Äú memory consolidation ‚Äù ,   is one of the cognitive   processes   for which the link to sleep has  been the most studied   (Stickgold, 2005) .   Memories   are transferred from the hippocampal regi on to the  neo - cortex   through local synaptic consolidation processes and systems - level reorganization . There is  increasing evidence that this process is sleep - dependent   (Marshall et al., 2006) .   In parallel, the ‚Äúsynaptic  homeostasis‚Äù hypothesis stipulate s that to compensate   for   the persistent strengthening of synapses  occurring during daytime activit y,   a synaptic downscaling takes place   during   slow wave   sleep   activity ,  allowing   for   better neuroplasticity   (Tononi and Cirelli, 2006) .   The   lack of synaptic plasticity ,   induced by  inadequate sleep,   could   impair memory   (Tononi and Cirelli, 2014) ,   and   play a role in depression   (Liu et  al., 2017)   and maladaptive behavior   (Kolb and Gibb, 2014) .   Another hypothesis is that sleep alters  connectivity between the amygdala and   the   medial - prefrontal cortex, as observed in an experimental  study conducted by Yoo et al .   (2007) . Since those structure s   seem to play an important rol e in the  regulation of emotions   (Phelps and LeDoux, 2005)   and behavior   (Amat et al., 2005) ,   a lack of sleep could  have a negative impact on these functions .  T he relation between sleep,   cognition and /or   behavior has been extensively studied in adolescents and  school - aged children   (Astill et al., 2012; Vriend et al., 2015) .   According to   the   Astill et al ‚Äôs   meta - analysis  (2012) ,   sleep duration   in sc hool - aged children   i s   positively   associated with   executive functioning   and\n\nmultiple - domain cognitive function ,   and   negatively associated with   internalizing and externalizing  behavior .   No associations were   found   with   sustained attention and memory .   However,   there has been  little focus on   preschoolers.   This constitutes   a gap in our knowledge ,   as sleep research on older children  cannot be   inferred to apply   to preschoolers for numerous reasons. Sleep physiology, sleep need and  sleep maturation   evolve very rapid ly in the first years of life, simultaneously to brain maturation   (Louis et  al., 1997; Olini and Huber, 2014) .   Additionally, the   causes of   insufficient quantity or quality of sleep can  be quite different according to the child‚Äôs age, and may   give rise to   distinct symptoms.   W hile the brain and  the circadian rhythm are still in maturation, inadequate sleep   may   disturb   a   child ‚Äôs   development and thus  be more likely to   have   long - term effect s   than when sleep disturbance occurs in   adults, and different  windows of   exposure throughout childhood could lead to diverse consequences.  A   systematic   review   of the literature   on nap sleep among preschoolers   was   recently published   (Thorpe et  al., 2015) ,   showing inconsistent results . Authors report this   may be   due to   variation in age and   in   habitual  napping status of the samples .   I n this article, we aim to   survey   all available publications   focusing on   the  link between sleep ,   cognition and /or   behavior in preschoolers , excluding studies focusing exclusively on  naps .   This systematic review   includes   studies   published in English,   conducted on children   of   the general  pop ulation   (non - clinical sample) .  M ETHODS  The   Cochrane handbook   (Higgins and Green, 2008)   and t he   Preferred Reporting Items for Systematic  Reviews and Meta - analyses   statement   (Moher et al., 2009)   (PRISMA guidelines)   were   followed to  ensure ,   respectively ,   optimal methodology and optimal reporting   (Supplementary data 1) . This review   has  been   declared in the PROSPERO database (number CRD42015029647).  Eligibility   criteria  To be eligible, articles had to conform to   a number of   criteria. The exposure variable had to be a measure  of   night or   total   sleep   duration ,   of   difficulty initiat ing   or maintaining sleep ,   or   of   sleep timing. The outcome  variable needed to be a measure of cognition or behavior.   T he study population   had to   be   a sample of the\n\ngeneral population   (not a clinical sample) , with no selection according to the cognitive or behavioral status  of the child or   according to his or her sleep. The average age of the population had to be   at least 2 and  less than   6   y ears   when the sleep and cognition measures were made. Moreover, only published original  articles (no conference abstract s , review s   or   case report s ) wri tten in English were eligible.  Information source and search strategy  The search strategy was   implemented   in two main steps. The first one consisted in a wide - ranging  search of   four   electronic databases ,   namely Medline, Web of Science, PsycINFO and ERIC   up to   April  30,   2016 . To ensure maximum sensitivity, no terms were used to exclude clinical studies, so that potential  control groups could be included in our review. For all   the   databases ,   a search by title and abstract  included the following words and their synonyms ( t he   exact   phrases are available in the supplementary  data   2 ):   Sleep, Insomnia, night - waking,   child, preschoolers, cognition, learning, teacher rating,  performance, intelligenc e, IQ, memory, attention deficit, sustained attention, behavior,   conduct,  internalizing, externalizing.   For the Medline database, in addition to the title and abstract search, a  second phrase was created to use Medical Subject Headings terms (hierarchicall y organized keywords  also called MeSH terms):   Sleep, sleep disorders, child, preschool, child behavior, social behavior,  behavioral symptoms, affect, temperament, intelligence, internal - external control, achievement, child  behavior disorders, memory, verba l learning, cognition, psychomotor, performance.  In the second step, we   conducted   backward and forward citation search es   for all the articl es   retained  after   the   initial screening of the title and abstract. Backward citation searching consists in identifyin g  additional articles by reviewing the reference list of the selected articles, while forward citation searching  consists in reviewing articles that cite the selected article. For the lat t er,   we used   the forward citation  searching tools of both ‚ÄúPubMed‚Äù and ‚ÄúWeb of Science‚Äù.  Article selection  Two investigators selected the articles in two steps, and were blind to each other‚Äôs selection th rough out  the whole process. The first   selection was based on a   screening process of   the title and abstract and the  second   one   was made   after reading the full text.\n\nData extraction   and reporting  The data extracted from the articles were the age of the child (average and range) at each measure, the  recruitment date,   the   gender   ratio, the sleep measure (the exposure variable), the cognitive and  behavioral measures (the outcomes), the measurement tool used and by whom, the control variables  included in the final model, the strength of the association (beta, correlation, odds - ratio , mean difference)  and finally the significance of the association assessed by p - value. Data   w ere   extracted from the articles  by the two investigators   separately , and   only concern ed   the analyses of interest for this review, i.e.  sample size, study design,   and control for confounding factors. Therefore,   descriptions   do not necessarily  reflect the entire original article. The same remark applies to the risk of bias in assessment. If the article  presented cross - sectional and longitudinal analyses, only the lon gitudinal ones were included. Similarly, if  both unadjusted and multivariable analyses were available, the latter were reported. The child behavior  checklist‚Äôs total problems scale   (Achenbach, 1991) ,   but not its subscales, contains several questions  regarding sleep difficulties.   Thus,   analyses using the total problems scale of the child behavior checklist  were not reported.  Risk of bias  We assessed the risk of bias in each article using a   5 - criteria   scale,   derived from the   Newcastle Ottawa  Quality Assessment Scale for Cohort studies   (Wells et al., 2003) .   The first two criteria take into  consideration classification bias, the t hird confounding bias, the fourth the lack of temporality and the fifth  statistical detection power.   Each of th e se elements accounted for a point on the risk of bias scale 1)   t he  exposure (sleep variable) was not measured objectively; 2)   t he outcome   (behavior or cognition)   was  assessed by someone who was   not   blin d   to the sleep status; 3)   there were no statistical adjustment s   to  take into account   the   main confounding factors (household income or parental education, child‚Äôs sex, and  child‚Äôs age if age r ange > 6 months); 4) the study had a cross - sectional   design   (i.e. sleep was assessed  at the same time as the outcome); 5) The sample size was   less than   500 children.   The maximum score of  5 indicates a higher risk of bias. The purpose of the scale is solel y to give a general indication to readers  o f   the   level of   confidence that can be given to the results .   N o article s   were excluded based on this scale.\n\nA same article may obtain a risk of bias   range   instead of a single   score   if it uses   multiple   methods. For  example, in   the   same article ,   some cognitive measures might be assessed by a professional using a  validated tool, while others might be   assessed   based on   parent s‚Äô   perception .  Data synthesis  A systematic qualitative synthesis was performed. No   reliable   quantitative synthesis   could be produced  due to a great diversity of sleep, cognition and /or   behavior measures, and   to   great variety   in the data  analysis methods, within a relatively low number of articles .\n\nRESULTS  Selection and description of the   studies included  The flow chart in Figure 1 summarizes the selection procedure , in accordance with the   PRISMA  guidelines   (Moher et al., 2009) .   Out of the   1590   articles initially   identified ( minus   duplicates),   1511   were  excluded for not meeting inclusion criteria after title and abstract screening, and 53 were excluded after  full text screening.   We performed forward and backward citation search es   on the articles   that were  selected for   the full text assessment, which resulted in the inclusion of   seven   new articles.   In total , 2 6  articles were included and are described in Table 1.  Out of the 2 6   selected articles,   all reported observational studies. M ore than   half   were based on   data  collected in   North American children ( nine   in the USA,   six   in Canada). The countr ies   of origin of the  children in the remaining articles   were   Australia (four), Europe (five   in   total, one   in each of the following:  Switzerland, Italy, Neth erland s , G ermany and Finland) and Japan (two ).  As described in Figure 2, 1 4   articles   ( 54 %)   had an estimated risk of bias of   4   or more out of 5.   Eighteen  ( 69 %) articles reported a   cross - sectional   analysis, 1 3   (50%) had a population size   below   500   and   23  ( 88 %) used   su bjective measures of sleep. Regarding the outcome,   1 4   articles   (5 4 %) used measures  assessed by someone   who was   not   blind   to   the   child   sleep status   and three   had a combination of blind  and non - blind assessors.   Twenty - one   articles   ( 73 %)   did not   meet   minimum   adjustment   criteria   (namely  any socio - economic factor s , child‚Äôs sex, and child‚Äôs age if age range > 6 months).  Figure 3 shows the number of article s   per exposure and per outcome.   In total, 24   different questionnaires  for sleep, behavior and cognition were used, and are reported in supp lementary   data   3 .   Regarding  exposure,   over half of the   articles focused on the child‚Äôs sleep duration , 13 for night sleep duration (NSD)  and   six   for total sleep   duration (TSD) .   A few   examined   indicators of   difficulty initiating and maintaining  sleep such as night - waking   (NW)   (n= 8 ) , sleep onset latency   (SOL)   (n=5) , sleep efficiency   (SE)   (n=2)   and  insomnia   (I)   (n=1) .   S leep problem s (SP)   (n=6)   were studied with   varying definitions .   In even fewer cases,  bedtime   (BT)   (n=3) and   wake - up time   (WT)   (n=1)   were also   investigated . Regarding the outcome,   23   of\n\nthe publications   raised the question of an   association between sleep and behavior. Cognition was less  frequently   studied   ( n=7)   with   a notable focus on lan guage   skills   ( five out of seven   articles).  Sleep and behavior  A summary of the association s   found between sleep and behavior is presented in Table 2.  Sleep and externalizing behavior  Aggressiveness and   conduct problems  Aggressive behavior has been found to be positively associated with insomnia   (Armstrong et al., 2014) ,  sleep problems   (Hall et al., 2007; Hatzinger et al., 2010)   and bedtime   (Komada et al., 2011) .   R esults  showing   night sleep duration were divergent, and no associations were found with sleep onset latency  (Hatzinger et al., 20 10)   nor sleep efficiency   (Hatzinger et al., 2010) .   More specifically ,   i n   the   Armstrong et  al .   study   (2014)   of   396 children aged 54 months ,   those   with insomnia had a higher mean score on the  hostile - aggressive scale of the P reschool   B ehavior   Q uestionnaire (PBQ)   (0.81¬± 0.26). Hall et al .   (2007)  found that sleep problems at age 3 accounted for 5.1% of the variance on the C hild   B ehavior   C heck   L ist  (CBCL)   scale of aggressive behavior at age 4   (n= 1317 ) . The   correlation between aggressive behavior  (measured by CBCL) and bedtime on week day s   was r=0.11   (p<0.01)   at age s 2 to 3 and 4 to 5   in   the  Komada et al. study   (2011) .   Furthermore ,   Komada et al.   (2011)   showed that   shorter   night   sleep duration  was associated with more aggressive   behavior in   children between the age of 24 to   36 months (N=905),  but not for those between the ages of 48 to 60 months (N=841).   Hatzinger et al .   (2010)   also found a lack  of association in 84 children aged 59 months .   These results seem to indicate that shorter night sleep  duration is associated with more aggressive behavior in younger children only. However Scharf   et al .  (2013)   did find a positive association in their sample of 8950 children aged 48 months.   Children who slept  less than 9.44 hours   per night   had an increased risk of being frequently aggressive (measured by  P reschool and Kindergart en Behaviors Scale or P KBS) with an OR of 1.81 CI 95% [1.36 - 2.41].   Thus,   we  could not determine whether the inconsistencies in   the   results were due to difference s   in sample size or  in sample age .\n\nThere were disparities in the results on conduct problems .   These   might be   caused by differences in  sample size and thus detection power.   Wada et al .   (2013)   and Hatzinger et al .   (2010)   found in 431 and 84  children ,   respectively, that none of   the   studied sleep exposures   -   namely night and t otal sleep duration,  sleep onset latency, night - waking sleep efficiency, sleep problems, bedtime and wake - up time   -   were  associated with conduct problems. In studies with larger sample size, children who had more night -  waking   (Hiscock et al., 2007; Lehmkuhl et al., 2008) ,   longer sleep onset latency   (Hiscock et al., 2007;  Lehmkuhl et al., 2008) ,   and more sleep problems   (Hiscock et al., 2007; Quach et al., 2012) ,   had   a   higher  risk of conduct problems.  More specifically, i n   the   Hiscock et al. study   (2007)   of   4983   children aged   57 months ,   those   who woke at  night   or   had difficulty getting to sleep 4 nights per week or more, had   a higher   score   on the SDQ conduct  problem scale   of 0.6   CI 95%   [ 0.5 - 0.8 ]   and 1.0   point s   CI   95%   [ 0.8 - 1.2 ] ,   respectively. Compared to   the  children   with no sleep problems, those with a moderate to severe sleep problem, as declared by parents,  had   a mean difference of   1.1   point s   CI 95%   [ 0.9 - 1.3 ]   on that same scale.   Although   the   definition of sleep  problems was different   in   Quach et al.   (2012) ,   they   found   very similar results   in   1512   children aged   68  months ,   with a mean difference   in   the   conduct problems score   of   1.0   point s   CI 95%   [ 0.7 - 1.2 ]   between no  sleep problems and moderate to severe sleep problems.   We note that   the only study using objective  measure s   of sleep found no significant association   (Hatzinger et al., 2010) .  Attention and hyperactivity problems  Some sleep parameters , such as later bedtime   (Komada et al., 2011) ,   and global sleep problems  (O‚ÄôCallaghan et al., 2010) ,   were positively associated with attention problems .   Regarding the strength of  these   associations,   the correlation between   the   c oncurrent   score of   attention problems   (measure d   by the  CBCL)   and bedtime   was   r=0.10   ( p<0.01 )   in   Komada et al .   study   (2011) .   Children   who had s leep problems  occurring ‚Äúoften ‚Äù   between the age of 2 and 4 years   had increased risk of   persistent   attention problems  ( above the 90 th   percentile on the CBCL attention scale   at age 5 and 14) with an adjusted OR of 3.84   CI  95%   [2.23 - 6.64] for boys, and 4.42   CI 95%   [2.27 - 8.63] for girls in   t he   O‚ÄôCallaghan et al .   study   (2010) .   No  link s   were found with night - waking   (Hall et al., 2012) ,   sleep onset latency   (Vaughn et al., 2015) ,   sleep  efficiency   (Hatzinger et al., 2010)   nor wake - up time variability   (Vaughn et al., 2015) .   Regarding night\n\nsleep duration, Paavonen et al .   (2009)   described a positive association when attention pr oblems were  assessed   by parents, but not when   assessed   by teachers.   These results could be indicative of a potential  bias when the person reporting the behavioral measure is not blind to the sleep status, although   the  authors   also   point out other plausible   explanations for the discrepancy . For instance, the teacher  response rate was   low , and not missing at random   since it   was lower   for children with   greater   behavioral  difficulties according to parents.   Four other studies   (Komada et al., 2011; Lam et al., 2011; Touchette et  al., 2007; Vaughn et al., 2015)   reported a lack of association regardless of who evaluated the   child‚Äôs  attention.  D issimilarities   in results   were observed   for every studied   association between a sleep factor and  hyperactivity problems.  Sleep and internalizing behavior  Anxious, depressed  In   the   Jansen et al. study   (2011)   of   4782   c hildren   aged   24 months , those   who   slept less than 12.5 hours  per day at age 2 years ,   compared to those who slept more   than 13.5 hours ,   had   an increased risk   of  anxiety or depressive symptoms at age 3 (defined as being above the 80 th   percentile on the CBCL  anxious/depressed symp toms scale) with an adjusted OR of   1.47   CI 95%   [1.20 - 1.79]. Results were  similar when looking at the child‚Äôs night - waking, with an adjusted OR of 1.32   CI 95%   [1.14 - 1.54]   for  children who woke   once or twice   per night on average compare d to those who never woke.   Similarly,  Zaidman et al.   (2015)   found   in   1487   children aged   29 months   that   those   who woke 20 minutes or more  per night ,   compared to those who did not wake ,   had higher anxiety and depression on an adapted s cale  of the PBQ .   In Komada et al.   (2011) ,   the correlation between the CBCL anxious/depressed symptoms  scale   and bed time   was r=0.09   ( p<0.01 ) .   The associations were not significant when studying night   sleep  duration   (Komada et al., 2011)   and inso mnia   (Armstrong et al., 2014) .  Emotional   symptoms  Studies   with   the   lowest sample sizes   reported non - significant results   for   all sleep measu res, namely night  sleep duration   (Hatzinger et al., 2010; Wada et al., 2013) ,   total sleep duration   (Wada et al., 2013) ,   night -\n\nwakin g   (Hall et al., 2012; Hatzinger et al., 2010; Wada et al., 2013) , sleep onset latency   (Hatzinger et al.,  2010; Wada et al., 2013) ,   sleep problems   (Hatzinger et al., 2010) ,   bedtime   (Wada et al., 2013)   and sleep  efficiency   (Hatzinger et al., 2010)   in children aged around 60 months .   In contrast , those with larger  sample sizes reported significant results   for   all reported measures . N ight - waking   (Hiscock et al., 2007;  Lehmkuhl et al., 2008) ,   sleep onset latency   (Hiscock et al., 2007; Lehmkuh l et al., 2008)   and sleep  problem s   (Hiscock et al., 2007; Quach et al., 2012)   were positively and s ignificantly associated with  emotional problems   in children aged between   57   and   68   months . Although the sample size might not be  the sole factor explain ing   the differences in results, it seems that lack of statistical power was common in  this matter. Other   internalizing behaviors were seldom investigated , thereby   limiting a comprehensive  synthesis.  Sleep, s ocial behavior and peer relation s  Children with shorter night   sleep   (Vaughn et al., 2015; Wada et al., 2013 )   or who   globally   had more sleep  problems   (Hiscock et al., 2007;   Quach et al., 2012) ,   were reported   as   show ing   less prosocial behavior.  However, no significant association was found ,   either with total sleep duration, bedtime   n or sleep  efficiency. Lehmkuhl et al .   (2008)   surprisingly   found   among 1388 children aged 66 months   that children  w ith longer sleep onset latency   displayed   more prosocial behavior (N=1338) where Hiscock et al.   (2007)  found the opposite in 4983   children. The main difference in method in the two articles was that   Lehmkuhl  et al.   (2008)   reported simple bivariate analyses while Hiscock et al.   (2007)   adjusted for age, gender and  household income. Two other articles with   smaller   sample sizes (in 62 and 437 children ,   respectively)  f ound no significant association   (Vaughn   et al., 2015; Wada et al., 2013) .   In each article, v ery similar  results were   observed   for the   outcome denoted by acceptance by peers .  Sleep and Cognition  E ven fewer   studies have investigated the link between   sleep and cognition   in preschoolers   (N=7) .   They  are presented in   T able 3.   Out of the four articles studying the   association between night sleep duration  and receptive vocabulary capacities , three found a positive association . In   the   L am et al.   (2011)   cross -  sectional   study   among   59   children aged   36   to   60 months ,   actigraphy - measured   night sleep was positively\n\ncorrelated with   a   better   score on the PPVT - IV   receptive vocabulary   scale   ( age adjusted   r=0.29, p=0.03 ) .  Also using actigraphy and the PPVT - IV   in a cross - sectional study , Vaughn et al.   (2015)   found   in   62  children aged   50 months   a correlation of r=0.45 (p<0.01) after adjusting for age, sex and ethnicity.   In their  longitudinal study   of   1492   children , Touchette et al .   (2007)   described four night - sleep patterns from age  2.5 to 6: 11 - hour persistent, 10 - hour persistent, short increasing, and short persistent.   Compared to  children who slept 11 - hour persistently,   those   who had short persistent duration were at hi gher risk   of a  low PPVT - measured receptive vocabulary score   (p=0.001), but no significant association   w as   found with  other   sleep patterns . Dionne et al.   (2011)   found   that   parental reports of   night sleep duration   at 30 months  was not associated with   concurrent   receptive vocabulary (assessed by the MCDI),   no r predictive of the   60  month s   receptive vocabulary (assessed by the PPVT)   in   1029   children .   Hiscock   et al.   (2007)   found   that  sleep problems were associated with literacy and numeracy but not with receptive vocabulary.   No  associations   were found between any cognitive outcome and total sleep duration, night - waking, sleep  onset latency or sleep efficiency.  D ISCUSSION  Amongst the 13 articles with the largest sample sizes   ( top   50% of the selected studies ,   12 different  population s ) , 12 found that   a higher quantity or quality of sleep was associated with better behavioral  and /or   cognitive outcomes .   Results point to an association between sleep, behavior and cognition as  early as in preschool years.   Studies with a smaller sample size   were less   con sistent . The strengths of  associations reported in the articles were relatively small, which explains the need for a large sample size  to find consistent results.   The studies were heterogeneous in many regards: the type and means of  measures   for the sleep variables differed but also the behavioral and cognitive   variables , as well as the  statistical methods employed.   Results differ ed   according to the   specific   exposure and outcome  considered , as well as the method employed, but too few studies w ere   performed   to fully understand  specific associations.  In comparison with the literature based on school - aged children, knowledge   involving   preschoolers is  rather sparse. Astill et al.   (2012)   conducted a systemati c review using similar selection criteria and   found\n\nover 80 studies   examining the association between sleep and cognition or behavior in children between  the age s   of 5 and 12.   According to their meta - analysis,   the association between   sleep duration   and bot h  cognition (r=0.08) and behavior (r=0.09)   in school - aged children was   small but significant.   Our findings  suggest th e se associations could be found as early as preschool - years.  Quality of included   s tudies  Unlike what   is seen   in the day - time sleep literature   (Thorpe et al., 2015) ,   no experimental studies   have  been   performed on preschoolers‚Äô night   sleep. Although they provide better strength of evidence than  observational studies,   experiments in very young children   raise ethical   concerns   and   problems of   parental  acceptance , which explains their absence .   Furthermore , experimental studies would not   ma ke it possible  to   observ e the   effect of   long - term   suboptimal sleep.  Most of the studies included   do not   use   objective   sleep measures ,   only   three   used actigraphy,   and none  used polysomnography , the gold standard in sleep measures .   Objective   measures   can be   expensive   to  record and to analyze especially   for   large r   sample s . It can also be   difficult to obtain   access to  polysomnographic equipment for research purposes ,   which   no doubt   further limit s   its   use.   Actigraphy is a  non - invasive   objective   method which is becoming more and more accessible,   we can thus expect   a great  increase in objective sleep measures   in future research.   However ,   some concerns have been raised  regarding the   validity   of this measure in preschool - aged children. When compared to polysomnography ,  correlation s   were   above   0.80 for sleep latency, sleep duration and sleep efficiency but   below   0.40 for the  number of awakening s   (B√©langer et al., 2013) .   Sitnick et al.   (2008)   suggest videotaping as a   more reliable  alternative.  Presumably for similar reasons, behavioral and cognitive data were often collected using questionnaires  completed   by the parents, who are not blind to   the   child ‚Äôs   sleep status. Evaluation by an external  investigator, ideally a   psychologist ,   limits   the risk of a bias in the outcome estimators.   Failure to consider  confounding   factors was a nother common risk of bias .   This   shortcoming   limits the interpretation of the  results   since it becomes impossible to determine   whether the associations found, or the lack of  associations, are   dependent   on   other factors.   T his risk of bias can be   easily   reduced   by statistical  adjustment,   if   data on co n founders   are   collected . Cross - sectional designs also make the interpretation of\n\nt he results quite difficult , as   they prevent   determin ing   whether the sleep   outcome   occurred before or after  the behavior or cognitive impairment. The chronology of events is especially important in this field of  research, as there are bidirectional associations between sleep, and both cognition and behavior  (Touchette et al., 2009) .  R eporting bias  The growing literature regarding publication bias and selective reporting bias suggests they are  widespread   (Dwan et al., 2008) . It is likely that they are even more   frequent   in reviews including  observational studies ,   since their registration is   not   required (unlike clinical trials).   Non - significant   results  that are   published are also less   frequently   cited in other publications, reducing the likelihood of being  identified.   Reporting   biases are complex to observe but we did find   dissimilarities   in several studies  between   the   measures used   in the analyses   and   those   apparently   available.   It is possible that a uthors  solely reported associations with significant results, omitting other measures .   One way to counter this  ubiquitous problem would be to plan   the study of   exposures and outcomes ahead of analyses .  The aim of   this review   is   to present available peer reviewed literature   ‚Äì   the gray literature was   therefore  not searched. While this allows a higher quality of included articles, it may reinforce the impact of  publication bias.  Variability in definitions   and means of measure  The variability in definitions of outcomes and exposure limits the present understanding of the  associations between sleep ,   behavior and cognition. For example, in the   s ix   articles studying ‚Äúsleep  problems‚Äù   (Hall et al., 2007; Hatzinger et al., 2010; Hiscock et al., 2007; O‚ÄôCallaghan et al., 2010; Quach  et al., 2012; Troxel et al., 20 13) ,   none had similar definitions. While most included a notion of difficulty  initiating or maintaining sleep, some also included sleep habits, some mixed dyssomnia and parasomnia  and others included only one simple question assessing parent s ‚Äô   perception of the child ‚Äôs   sleep.   T he  means to measure the outcome   also varied greatly ,   with 13 different tools used to assess behavior and  eight   for cognition (described in supp lementary   data   3 ).   The q uality and comparability could easily be  enhanced if th e studies focused on specific aspects of both exposure and outcome,   especially since one\n\ncannot assume that different   specific   sleep exposures are related to all cognitive or behavioral features in  the same way .  Future d i rections  This study highlights the   need to reduce publishing bias as well as bias within studies. For the   latter ,  recommendations are to explore the association between specific sleep, behavioral and cognitive  measures through longitudinal studies, to seek sufficie nt statistical power and use objective sleep  measures, as well as having the behavioral or cognitive outcome assessed by an investigator blind of the  sleep status, and report all available analyses. Reporting bias and confounding bias   ‚Äì   as well as vague  re sults arising from the study of nonspecific sleep, cognitive and/or behavioral measures   ‚Äì   can be easily  reduced if taken into account during the planning process. Reporting the children‚Äôs age precisely and  limiting the age range in a same analysis could al so improve interpretation.  It is of note that some recent studies have focused on less typical sleep aspects such as daily variations  (Spruyt et al., 2016)   and chronotype   (Doi et al., 2015) .   Others have explored sleep hygiene, such as  bedtime routine   (Mindell et al., 2015) ,   showing the importance of educating parents on the matter. Mindell  et al.   (1994)   found in their study that treatment of sleep disturbance improved day - time behavior. New  findings also report a differential role of sleep according to the child‚Äôs genotype   (Bouvette - Turcot et al.,  2015) .   Our present understandi ng in this field could be greatly improved by these innovative research  approaches.  A r ecent   systematic review   and meta - analysis   found   behavioral interventions   to be   efficient in reducing  sleep problems in children   (Meltzer   et al.,   2014) .   The interventions   for preschool - aged children included  sleep education, graduated extinction, structured bedtime routine and sleep programs. According to the ir  meta - analyses,   the standard mean deviation between the intervention and control group was   0.33 (0.48 ‚Äì  0.18), and th e mean night waking frequency in the intervention groups was 0.26 standard deviations  lower (0.35 ‚Äì 0.17).   It would be interesting to investigate if such interventions also improve cognition and  behavior\n\nCONCLUSION  In this systematic review, we took stock   of the available data on the question of   the association between  sleep, behavior and cognition in preschoolers,   and   suggested ways to improve   future research   on   the  subject .   T he current literature seems to indicate that sleep is related to behavioral and c ognitive  development as early as in preschool years.\n\nACKNOWLEDGEMENTS  We thank Dr Frank Ramus, who shared his expertise on child cognitive and behavioral development. We  also thank Pr Isabelle Boutron, co - convenor of the Bias Methods group of the Cochrane Collaboration, for  her guidance in the systematic review method.\n\nREFERENCES  Achenbach, T.M. Manual for Child Behavior Checklist 4 - 18. Univ Vermont/Dept Psychiatry , 1991.  Amat, J., Baratta, M.V., Paul, E., Bland, S.T., Watkins, L.R., Maier, S.F. Medial prefrontal cortex determines  how stressor controllability affects behavior and dorsal raphe nucleus. Nat. Neurosci., 2005, 8: 365 ‚Äì 371.  Armstrong, J.M., Ruttle, P.L., Klein,   M.H., Essex, M.J., Benca, R.M. Associations of child insomnia, sleep  movement, and their persistence with mental health symptoms in childhood and adolescence. Sleep,  2014, 37: 901 ‚Äì 909.  Astill, R.G., Van der Heijden, K.B., Van IJzendoorn, M.H., W, J. Slee p, cognition, and behavioral problems in  school - age children: A century of research meta - analyzed. Psychol. Bull., 2012, 138: 1109 ‚Äì 1138.  Bates, J.E., Viken, R.J., Alexander, D.B., Beyers, J., Stockton, L. Sleep and adjustment in preschool children:  sleep   diary reports by mothers relate to behavior reports by teachers. Child Dev., 2002, 73: 62 ‚Äì 74.  B√©langer, M. - √à., Bernier, A., Paquet, J., Simard, V., Carrier, J. Validating actigraphy as a measure of sleep for  preschool children. J. Clin. Sleep Med. JCSM Of f. Publ. Am. Acad. Sleep Med., 2013, 9: 701 ‚Äì 706.  Bouvette - Turcot, A. - A., Pluess, M., Bernier, A., et al.   Effects of Genotype and Sleep on Temperament.  Pediatrics, 2015, 136: e914 - 921.  Bruni, O., Lo Reto, F., Miano, S., Ottaviano, S. Daytime behavioral co rrelates of awakenings and bedtime  resistance in preschool children.   Suppl. Clin. Neurophysiol., 2000, 53: 358 ‚Äì 361.  Calhoun, S.L., Fernandez - Mendoza, J., Vgontzas, A.N., et al.   Learning, attention/hyperactivity, and conduct  problems as sequelae of excessi ve daytime sleepiness in a general population study of young children.  Sleep, 2012, 35: 627 ‚Äì 632.  Carskadon, M.A., Harvey, K., Dement, W.C. Sleep loss in young adolescents.   Sleep, 1981, 4: 299 ‚Äì 312.  Dionne, G., Touchette, E., Forget - Dubois, N., et al.   Asso ciations between sleep - wake consolidation and  language development in early childhood: a longitudinal twin study. Sleep, 2011, 34: 987 ‚Äì 995.  Doi, Y., Ishihara, K., Uchiyama, M. Associations of chronotype with social jetlag and behavioral problems in  presch ool children. Chronobiol. Int., 2015, 32: 1101 ‚Äì 1108.  Dwan, K., Altman, D.G., Arnaiz, J.A., et al. Systematic Review of the Empirical Evidence of Study Publication  Bias and Outcome Reporting Bias. PLoS ONE, 2008, 3: e3081.  Fallone, G., Acebo, C., Arnedt,   J.T., Seifer, R., Carskadon, M.A. Effects of acute sleep restriction on behavior,  sustained attention, and response inhibition in children. Percept. Mot. Skills, 2001, 93: 213 ‚Äì 229.  Gregory, A.M., Cousins, J.C., Forbes, E.E., et al. Sleep items in the chil d behavior checklist: a comparison  with sleep diaries, actigraphy, and polysomnography. J. Am. Acad. Child Adolesc. Psychiatry, 2011, 50:  499 ‚Äì 507.  Hall, W.A., Scher, A., Zaidman - Zait, A., Espezel, H., Warnock, F. A community - based study of sleep and  behav iour problems in 12 -   to 36 - month - old children. Child Care Health Dev., 2012, 38: 379 ‚Äì 389.  Hall, W.A., Zubrick, S.R., Silburn, S.R., Parsons, D.E., Kurinczuk, J.J. A model for predicting behavioural sleep  problems in a random sample of Australian pre - schoo lers. Infant Child Dev., 2007, 16: 509 ‚Äì 523.  Hatzinger, M., Brand, S., Perren, S., et al. Sleep actigraphy pattern and behavioral/emotional difficulties in  kindergarten children: association with hypothalamic - pituitary - adrenocortical (HPA) activity. J. Psy chiatr.  Res., 2010, 44: 253 ‚Äì 261.  Higgins, J.P.T., Green, S. eds Cochrane Handbook for Systematic Reviews of Interventions. Wiley - Blackwell,  Chichester, England; Hoboken, NJ , 2008.  Hiscock, H., Canterford, L., Ukoumunne, O.C., Wake, M. Adverse associatio ns of sleep problems in  Australian preschoolers: national population study. Pediatrics, 2007, 119: 86 ‚Äì 93.  Iwasaki, M., Iwata, S., Iemura, A., et al. Utility of subjective sleep assessment tools for healthy preschool  children: a comparative study between s leep logs, questionnaires, and actigraphy. J. Epidemiol. Jpn.  Epidemiol. Assoc., 2010, 20: 143 ‚Äì 149.\n\nJansen, P.W., Saridjan, N.S., Hofman, A., Jaddoe, V.W.V., Verhulst, F.C., Tiemeier, H. Does disturbed  sleeping precede symptoms of anxiety or depression in   toddlers? The generation R study. Psychosom.  Med., 2011, 73: 242 ‚Äì 249.  Jung, E., Molfese, V.J., Beswick, J., Jacobi - Vessels, J., Molnar, A. Growth of Cognitive Skills in Preschoolers:  Impact of Sleep Habits and Learning - Related Behaviors. Early Educ. Dev. , 2009, 20: 713 ‚Äì 731.  Kolb, B., Gibb, R. Searching for the principles of brain plasticity and behavior. Cortex J. Devoted Study Nerv.  Syst. Behav., 2014, 58: 251 ‚Äì 260.  Komada, Y., Abe, T., Okajima, I., et al. Short sleep duration and irregular bedtime are   associated with  increased behavioral problems among Japanese preschool - age children. Tohoku J. Exp. Med., 2011, 224:  127 ‚Äì 136.  Lam, J.C., Mahone, E.M., Mason, T., Scharf, S.M. The effects of napping on cognitive function in  preschoolers. J. Dev. Behav. Ped iatr. JDBP, 2011, 32: 90 ‚Äì 97.  Lehmkuhl, G., Fricke - Oerkermann, L., Wiater, A., Mitschke, A. Sleep disorders in children beginning school:  their causes and effects. Dtsch. √Ñrztebl. Int., 2008, 105: 809 ‚Äì 814.  Lim, J., Dinges, D.F. A meta - analysis of the impa ct of short - term sleep deprivation on cognitive variables.  Psychol. Bull., 2010, 136: 375 ‚Äì 389.  Liu, W., Ge, T., Leng, Y., et al.   The Role of Neural Plasticity in Depression: From Hippocampus to Prefrontal  Cortex. Neural Plast., 2017, 2017: 6871089.  Louis, J., Cannard, C., Bastuji, H., Challamel, M.J. Sleep ontogenesis revisited: a longitudinal 24 - hour home  polygraphic study on 15 normal infants during the first two years of life. Sleep, 1997, 20: 323 ‚Äì 333.  Mahone, E.M., Pillion, J.P., Hiemenz, J.R.   initial development of an auditory continuous performance test  for preschoolers. J. Atten. Disord., 2001, 5: 93 ‚Äì 106.  Marshall, L., Helgad√≥ttir, H., M√∂lle, M., Born, J. Boosting slow oscillations during sleep potentiates memory.  Nature, 2006, 444: 610 ‚Äì 613.  Meltzer, L.J., Mindell, J.A. Systematic review and meta - analysis of behavioral interventions for pediatric  insomnia. J. Pediatr. Psychol., 2014, 39: 932 ‚Äì 948.  Minde, K., Faucon, A., Falkner, S. Sleep problems in toddlers: effects of treatment on their da ytime  behavior. J. Am. Acad. Child Adolesc. Psychiatry, 1994, 33: 1114 ‚Äì 1121.  Mindell, J.A., Li, A.M., Sadeh, A., Kwon, R., Goh, D.Y.T. Bedtime routines for young children: a dose -  dependent association with sleep outcomes. Sleep, 2015, 38: 717 ‚Äì 722.  Moher,   D., Liberati, A., Tetzlaff, J., Altman, D.G., PRISMA Group Preferred reporting items for systematic  reviews and meta - analyses: the PRISMA statement. J. Clin. Epidemiol., 2009, 62: 1006 ‚Äì 1012.  Nathanson, A.I., Fries, P.T. Television Exposure, Sleep Time, a nd Neuropsychological Function Among  Preschoolers. Media Psychol., 2014, 17: 237 ‚Äì 261.  O‚ÄôCallaghan, F.V., Al Mamun, A., O‚ÄôCallaghan, M., et al. The link between sleep problems in infancy and  early childhood and attention problems at 5 and 14 years: Evidenc e from a birth cohort study. Early  Hum. Dev., 2010, 86: 419 ‚Äì 424.  Olini, N., Huber, R. Ageing and sleep: sleep in all stages of human development. ESRS European sleep  medicine textbook. European Sleep Research Society. (2014).  Paavonen, E.J., Porkka - Heisk anen, T., Lahikainen, A.R. Sleep quality, duration and behavioral symptoms  among 5 - 6 - year - old children. Eur. Child Adolesc. Psychiatry, 2009, 18: 747 ‚Äì 754.  Phelps, E.A., LeDoux, J.E. Contributions of the amygdala to emotion processing: from animal models t o  human behavior. Neuron, 2005, 48: 175 ‚Äì 187.  Quach, J., Hiscock, H., Wake, M. Sleep problems and mental health in primary school new entrants: cross -  sectional community - based study. J. Paediatr. Child Health, 2012, 48: 1076 ‚Äì 1081.  Sadeh, A. A Brief Screen ing Questionnaire for Infant Sleep Problems: Validation and Findings for an Internet  Sample. Pediatrics, 2004, 113: e570 ‚Äì e577.\n\nScharf, R.J., Demmer, R.T., Silver, E.J., Stein, R.E.K. Nighttime sleep duration and externalizing behaviors of  preschool childr en. J. Dev. Behav. Pediatr. JDBP, 2013, 34: 384 ‚Äì 391.  Sitnick, S.L., Goodlin - Jones, B.L., Anders, T.F. The use of actigraphy to study sleep disorders in preschoolers:  some concerns about detection of nighttime awakenings. Sleep, 2008, 31: 395 ‚Äì 401.  Spruyt,   K., Alaribe, C.U., Nwabara, O.U. Daily dynamics in sleep and behavior of young African - American  children: A convoluted dyad?! Int. J. Psychophysiol. Off. J. Int. Organ. Psychophysiol., 2016, 99: 57 ‚Äì 66.  Stickgold, R. Sleep - dependent memory consolidation.   Nature, 2005, 437: 1272 ‚Äì 8.  Stickgold, R., Walker, M.P. Sleep and memory: the ongoing debate. Sleep, 2005, 28: 1225 ‚Äì 1227.  Thorpe, K., Staton, S., Sawyer, E., Pattinson, C., Haden, C., Smith, S. Napping, development and health from  0 to 5 years: a systemat ic review. Arch. Dis. Child., 2015, 100: 615 ‚Äì 622.  Tononi, G., Cirelli, C. Sleep function and synaptic homeostasis. Sleep Med. Rev., 2006, 10: 49 ‚Äì 62.  Tononi, G., Cirelli, C. Sleep and the price of plasticity: from synaptic and cellular homeostasis to memo ry  consolidation and integration.   Neuron, 2014, 81: 12 ‚Äì 34.  Touchette, E., C√¥t√©, S.M., Petit, D., et al.   Short nighttime sleep - duration and hyperactivity trajectories in  early childhood. Pediatrics, 2009, 124: e985 - 993.  Touchette, E., Petit, D., S√©guin, J .R., Boivin, M., Tremblay, R.E., Montplaisir, J.Y. Associations between sleep  duration patterns and behavioral/cognitive functioning at school entry. Sleep, 2007, 30: 1213 ‚Äì 1219.  Troxel, W.M., Trentacosta, C.J., Forbes, E.E., Campbell, S.B. Negative emotio nality moderates associations  among attachment, toddler sleep, and later problem behaviors.   J. Fam. Psychol. JFP J. Div. Fam. Psychol.  Am. Psychol.   Assoc. Div. 43, 2013, 27: 127 ‚Äì 136.  Vaughn, B.E., Elmore - Staton, L., Shin, N., El - Sheikh, M. Sleep as a supp ort for social competence, peer  relations, and cognitive functioning in preschool children. Behav. Sleep. Med., 2015, 13: 92 ‚Äì 106.  Vertes, R.P., Siegel, J.M. Time for the sleep community to take a critical look at the purported role of sleep  in memory proc essing. Sleep, 2005, 28: 1228 - 1229; discussion 1230 - 1233.  Vriend, J., Davidson, F., Rusak, B., Corkum, P. Emotional and Cognitive Impact of Sleep Restriction in  Children. Sleep Med. Clin., 2015, 10: 107 ‚Äì 115.  Wada, K., Nakamura, K., Tamai, Y., et al. Associations of endogenous melatonin and sleep - related factors  with behavioral problems in preschool Japanese children. Ann. Epidemiol., 2013, 23: 469 ‚Äì 474.  Weissbluth, M. Sleep duration, temperament, and Conners‚Äô   ratings of three - year - old children. J. Dev.  Behav. Pediatr. JDBP, 1984, 5: 120 ‚Äì 123.  Wells, G., Brodsky, L., Shea, B., et al. An Evaluation of the Newcastle Ottawa Scale: An Assessment Tool for  Evaluating the Quality of Non - Randomized Studies. XI Interna tional Cochrane Colloquium Book of  Abstracts. p. p.26. , Barcelona (2003).  Yoo, S. - S., Gujar, N., Hu, P., Jolesz, F.A., Walker, M.P. The human emotional brain without sleep -- a  prefrontal amygdala disconnect. Curr. Biol. CB, 2007, 17: R877 - 878.  Zaidman - Za it, A., Hall, W.A. Children‚Äôs night waking among toddlers: relationships with mothers‚Äô and  fathers‚Äô parenting approaches and children‚Äôs behavioural difficulties. J. Adv. Nurs., 2015, 71: 1639 ‚Äì 1649.\n\nFigures  Figure 1 .   Systematic   review f low chart , following PRISMA guidelines   (Moher et al., 2009)  Figure 2.   Quality of i ncluded s tud ies .   a)   Article   distribution according to the   five   quality criteria,   b) Paper  distribution according to the total risk of bias (sum of the   five   quality criteria)  Figure 3 .   Number of articles per exposure and per outcome   (NSD night sleep duration, SP sleep  problems, NW night - waking, TSD total sleep   duration, SOL sleep onset latency, BT bedtime, SE sleep  efficiency, WT wake up time)\n\nIdentification Screening Eligibility Inclusion  Records identified through database searching  ‚Ä¢   Medline   n=2645  ‚Ä¢   PsycINFO   n=465  ‚Ä¢   Web of science n=154  ‚Ä¢   ERIC n=20  Records identified through  ‚Ä¢   F orward   citation   searching   n= 4  ‚Ä¢   Backward   citation   searching   n= 3  N=3291  Title and abstract screening  N=1590  Full text screening  N=79  Inclusion  N=26  53 articles did not meet inclusion criteria after full text screening  ‚Ä¢   Population selection based on the child‚Äôs cognitive or  behavioral capacities N=14  ‚Ä¢   Population selection based on the child‚Äôs sleep N=8  ‚Ä¢   Population selection based on other criteria N=4  ‚Ä¢   Average age at exposure measure <2yrs N=3  ‚Ä¢   Average age at the outcome measure >6yrs N=10  ‚Ä¢   Non eligible sleep measure (snoring, co - sleeping, composite  score including factors other than sleep) N=11  ‚Ä¢   The outcome is not a behavioral or cognitive measure N=3  1511 articles did not meet inclusion criteria  after title and abstract screening  1701 duplicates removed\n\n12%, n=3  42%, n=11  27%, n=7  15%, n=4  4%, n=1  0%, n=0  5 (highest risk of bias)  4  3  2  1  0  a) Article distribution   according   to the 5   quality   criteria  b) Article distribution   according   to the total   risk   of   bias   ( sum   of the 5   criteria )  50%, n=13  81%, n=21  69%, n=18  54%, n=14  88%, n=23  Sample size <500 children  No adjustment, incomplete adjustment  Cross-sectionall setting  Outcome investigator not blind of sleep status  Subjective exposure measurement\n\n13  8  6   6   5  3   2   1   1  20  13  5  8  5  2   1   2  0  5  10  15  20  25  Number of articles  Sleep   Behavior   Cognition\n\nTable 1. Description of the 26 included studies  Author, year   N   Country  Objective  sleep  measure  Design  Age in months (¬±SD or range)   Control   for  confounding  factors   a  Risk of  bias   b  At exposure   At outcome if  different  Armstrong et al. ( 2014)   396   USA   No   CS   c   54(¬±NA)   -   No   c   5   c  Bates et al. ( 2002)   184   USA   No   CS   58.8(¬±6.5)   -   Partial   4  Bouvette - Turcot et al.   (2015)   209   CAN   No   L   12 to 36   d   36(¬±NA)   Yes   3  Bruni   et al.   (2000)   194   ITA   No   CS   27(22 - 38)   -   No   5  Dionne et al.   (2011)   1029   CAN   No   L   31(¬±0.8)   31(¬±0.8) & 63(¬±3.0)   No   c   2   c  Hall et al. (2007)   1317   AUS   No   L   36(¬±NA)   c   48(¬±NA)   Partial   3  Hall et al.   (2012)   58   CAN   No   CS   24.7(¬±7.0)   -   No   4 - 5  Hatzinger et al.   (2010)   82   CHE   Yes   CS   58.9(¬±5.8)   -   No   3  Hiscock et al.   (2007)   4983   AUS   No   CS   56.9(51 - 67)   -   Both   2 - 4  Jansen et al.   (2011)   4782   NLD   No   L   24(¬±NA)   36(¬±NA)   Yes   2  Jung et al.   (2009)   67   USA   No   L   42.1(¬±3.3)   42 to 65   d   No   3  Komada et al.   (2011)   1746   JPN   No   CS   (24 - 36) & (48 - 60)   -   No   c   4   c  Lam et al.   (2011)   59   USA   Yes   CS   51.6(36 - 60)   -   Partial   3  Lehmkuhl et al.   (2008)   1388   DEU   No   CS   66.2(¬±NA)   -   No   4  Nathanson   and   Fries   (2014)   107   USA   No   CS   53.4(¬±8.7)   -   Partial   4  O‚ÄôCallaghan et al.   (2010)   4204   AUS   No   CS   c   (24 - 48)   e   60(¬±NA)   Partial   c   4   c  Paavonen et al.   (2009)   297   FIN   No   CS   (60 - 72)   -   Partial   4  Quach et al.   (2012)   1512   AUS   No   CS   68.4(¬±4.8)   -   Partial   4  Scharf et al.   ( 2013)   8950   USA   No   CS   48(¬±NA)   -   Partial   4  Touchette et al.   (2007)   f   1492   CAN   No   L   30 to 72   d   61(¬±3.6)   c   Yes   1  Touchette et al.   (2009)   f   2057   CAN   No   L   18 to 60   d   -   No   c   3   c  Troxel et al.   (2013)   776   USA   No   L   24(¬±NA) & 36(¬±NA)   54(¬±NA)   Partial   2  Vaughn et al.   (2015)   62   USA   Yes   CS   49.8(¬±7.4)   -   Partial   3  Wada et al.   (2013)   437   JPN   No   CS   61.4(¬±10.8)   -   Yes   4  Weissbluth   (1984)   60   USA   No   CS   36.1(36 - 38)   -   No   5  Zaidman - Zait and   Hall   (2015)   1487   CAN   No   CS   c   29(¬±NA)   -   Partial   4  a   Adjustment on sex, socio economic factors, and age when sample age range >6 months  b   From 0 to 5, a higher score indicating a   higher risk of bias  c   Concern   the analyses of interest to the review  d   Repeated measures  e   M easure assessed at 60 months   (retrospective)  f   Same study sample  AUS = Australia, CAN = Canada, CHE = Switzerland, DEU = Germany, FIN = Finland,   ITA = Italy, JPN = Japan, NLD = Netherlands, USA =United  States of America ,   L longitudinal analysis, CS cross - sectional analysis, NA Non - available data\n\nTable 2 Associations between sleep and behavior in preschoolers  TSD   NSD   I   NW   SOL   SE   SP   BT   WT  EXTERNALIZING BEHAVIOR  Aggressiveness  Armstrong et al.   ( 2014)   +**  Hall et al.   ( 2007)   +***  Hall et al.   ( 2012)   NS  Hatzinger et al.   ( 2010)   +**  Komada et al.   ( 2011) , 24 - 36   mo   - **   +**  Komada et al.   ( 2011) ,   48 - 60   mo   NS   +**  Scharf et al.   ( 2013)   - ***  Zaidman - Zait and Hall   ( 2015)   +*  Anger  Schar f et al.   ( 2013)   - **  Attention problems  Hall et al.   ( 2012)   NS  Komada et al.   ( 2011) , 24 - 60   mo   NS   +**  Lam et al.   ( 2011)   NS  O‚ÄôCallaghan et al.   ( 2010)   +***  Paavonen et al.   ( 2009) ,   p arents report   - **  Paavonen et al.   ( 2009) ,   t eacher report   NS  Touchette et al.   ( 2007)   NS  Vaughn et al.   ( 2015)   NS   NS   NS  Conduct problems  Hatzinger et al.   ( 2010) , boys   NS   +*   NS   NS  Hatzinger et al.   ( 2010) , girls   NS   NS   NS   NS  Hiscock et al.   ( 2007)   +***   +***   +***  Lehmkuhl et al.   ( 2008)   +**   +**  Quach et al.   ( 2012)   +***  Wada et al.   ( 2013)   NS   - *   NS   NS   NS   NS  Scharf et al.   ( 2013)   ( Annoying behavior)   NS  Scharf et al.   ( 2013)   ( Tantrums)   - *  Hyperactivity  Armstrong et al.   ( 2014)   +**  Hatzinger et al.   ( 2010) , boys   NS   +*   NS   NS  Hatzinger et al.   ( 2010) , girls   NS   NS   NS   NS  Lam et al.   ( 2011)   NS  Lehmkuhl et al.   ( 2008)   NS   +**  Quach et al.   ( 2012)   +***  Scharf et al.   ( 2013)   - **  Touchette et al.   ( 2009)   - ***  Wada et al.   ( 2013)   NS   NS   +*   NS   NS   +*  Zaidman - Zait and Hall   ( 2015)   +***  Hyperactivity and impulsivity  Touchette et al.   ( 2007)   - * **   a  Hyperactivity and attention  Hiscock et al.   ( 2007)   +***   +***   +***  Impulsivity  Scharf et al.   ( 2013)   - ***  Opposition  Zaidman - Zait and Hall   ( 2015)   +**  Non - specific externalizing behavior  Bruni et al.   ( 2000)   +*  Hall et al.   ( 2012)   NS  Paavonen et al.   ( 2009) ,   parents report   NS\n\nTable   2 continued)  TSD   NSD   I   NW   SOL   SE   SP   BT   WT  Paavonen et al.   (2 009) ,   teacher report   NS  Scharf et al.   (2 013)   - ***  Troxel et al.   (2 013)   +*  Weissbluth   ( 1984)   NS   NS  INTERNALIZING BEHAVIOR  Anxious, depressed  Armstrong et al.   (2 014)   NS  Hall et al.   (2 012)   NS  Jansen et al.   (2 011)   - *   +*  Komada et al.   (2 011) ,   24 - 36   mo   NS   +**  Komada et al.   (2 011) ,   48 - 60   mo   NS   +**  Zaidman - Zait and Hall   (2 015)   +*  Separation anxiety  Zaidman - Zait and Hall   (2 015)   +***  Emotional symptoms  Hall et al.   (2 012)   NS  Hatzinger et al.   (2 010)   NS   NS   NS   NS   NS  Hiscock et al.   (2 007)   +***   +***   +***  Lehmkuhl et al.   (2 008)   +**   +**  Quach et al.   (2 012)   +***  Wada et al.   (2 013)   NS   NS   NS   NS   +*   NS  Withdrawn, shyness  Hall et al.   (2 012)   NS  Zaidman - Zait and Hall   (2 015)   +**  Somatization  Bruni et al.   (2 000)   +**  Hall et al.   (2 012)   NS  Non - specific internalizing behavior  Bruni et al.   (2 000)   NS  Hall et al.   (2 012)   NS  Paavonen et al.   (2 009) ,   parents report   - *  Paavonen et al.   (2 009) ,   teacher report   NS  Troxel et al.   (2 013)   +**  SOCIABILITY  Prosocial behavior  Hiscock et al.   (2 007)   - ***   - ***   - ***  Lehmkuhl et al.   (2 008)   NS   +**  Quach et al.   (2 012)   - ***  Vaughn et al.   (2 015)   +*   NS   NS  Wada et al.   (2 013)   NS   NS   NS   NS   - *   - **  Peer relation problems  Hiscock et al.   (2 007)   +**   +***   +***  Lehmkuhl et al.   (2 008)   NS   NS  Quach et al.   (2 012)   +***  Vaughn et al.   (2 015)   - **   NS   NS  Wada et al.   (2 013)   NS   NS   NS   NS   NS   +**  NON - SPECIFIC BEHAVIOR PROBLEMS  Armstrong et al.   (2 014)   +*  Bates et al.   (2 002)   NS   NS   NS  Bouvette - Turcot et al.   ( 2 015)  ‚â• 1 copy of the 5 - HTTLRPR   b   short allele  - ***  Bouvette - Turcot et al.   ( 2 015)  no copy of the 5 - HTTLRPR   b   short allele  NS\n\nTable 2 continued)  TSD   NSD   I   NW   SOL   SE   SP   BT   WT  Hiscock et al.   (2 007)   +***   +***   +***  Lehmkuhl et al.   (2 008)   +**   +**  Paavonen et al.   (2 009) ,   teacher report   NS  Quach et al.   (2 012)   +***  Wada et al.   (2 013)   NS   NS   +*   NS   +*   +*  Note: +,   -   and NS   indicate   a positive, negative and non - significant statistical association  Abbreviations stand for: TSD total sleep duration, NSD night sleep duration, I insomnia, NW night - waking,  SOL sleep onset latency,   SE sleep efficiency,   SP sleep problems, BT bed time, WT wake - up time.  * p<0.05, ** p ‚â§ 0.01, ***p ‚â§ 0.001  a   When compared to the 11 - hour persistent sleep duration trajectory, the short increasing duration  trajectory is a risk factor p=0.001, but no significant association   was   found with other categories  b   Serotonin - transporter - linked polymorphic region of the serotonin transporter gene (SLC6A4)\n\nTable 3 Associations between sleep and cognition in preschoolers.  TSD   NSD   NW   SOL   SE   SP  Executive function  Lam et al.   (20 11)   ACPT - P Omission error   NS  Lam et al.   (20 11)   ACPT - P Commission error   - *  Lam et al.   (20 11)   ACPT - P Mean response time   NS  Lam et al.   (20 11)   ACPT - P Variability   NS  Nathanson and Fries   (20 14)   NS  Memory  Lam et al.   (20 11)   NS  Language  Dionne et al.   (20 11)   Receptive Vocabulary   NS  Hiscock et al.   (20 07)   Receptive Vocabulary   NS   NS   NS  Hiscock et al.   (20 07)   Literacy and numeracy   NS   NS   +***  Lam et al.   (20 11)   Receptive Vocabulary   +*  Vaughn et al.   (20 15)   Receptive Voc abulary   +**   NS   NS  Touchette et al.   (20 07)   Rec eptive Vocabulary   +***   a  Non - specific cognition  Jung et al.   (20 09)   General conceptual ability   +*  Touchette et al.   (20 07)   Non - verbal abilities   +***   b  Note: +,   -   and NS   indicate   a positive, negative and non - significant statistical association  Abbreviations stand for: TSD total sleep duration, NSD night sleep duration, NW night - waking, SOL sleep  onset latency, SE sleep   efficiency, SP sleep problems.  * p<0.05, ** p ‚â§ 0.01, ***p ‚â§ 0.001  ACPT - P Auditory continuous performance test for preschoolers   (Mahone et al.   (2 001)  a   with the reference being children who slept 11 - hour persistently, children who had short persistent  duration were at higher risk (p=0.001), but no significant association   was   found with other categories  b   with the reference being children who slept 11 - ho ur persistently, children who had short increasing  duration were at higher risk (p=0.001), but no significant association   was   found with other categories",
      "embedding": [
        -0.010708766989409924,
        0.04504923149943352,
        -0.005727467127144337,
        0.04570191353559494,
        0.02299998328089714,
        0.07366620004177094,
        -0.026386963203549385,
        0.029288560152053833,
        0.07948072999715805,
        0.061747223138809204,
        -0.0030292081646621227,
        -0.009478949941694736,
        0.034133490175008774,
        0.03830587491393089,
        -0.022867247462272644,
        0.035369616001844406,
        0.06518539786338806,
        0.033152561634778976,
        -0.020696744322776794,
        0.025351060554385185,
        0.058516278862953186,
        0.012027755379676819,
        0.12310367077589035,
        -0.005546586588025093,
        0.0022164620459079742,
        0.06566385179758072,
        0.03445291891694069,
        -0.08529657870531082,
        -0.04915269836783409,
        0.013298655860126019,
        0.016716770827770233,
        0.022976594045758247,
        -0.006831374950706959,
        -0.06616964191198349,
        -0.0049851564690470695,
        0.006435333751142025,
        0.07017294317483902,
        0.0616464763879776,
        -0.07744969427585602,
        -0.006604647263884544,
        -0.029284806922078133,
        0.01299036294221878,
        -0.04136680066585541,
        -0.10402552783489227,
        -0.07875780761241913,
        -0.044242966920137405,
        0.00205601891502738,
        -0.040953248739242554,
        -0.09498578310012817,
        -0.023256225511431694,
        -0.03712688013911247,
        -0.0049794623628258705,
        0.010392692871391773,
        0.040015630424022675,
        0.0020537865348160267,
        -0.0050313882529735565,
        0.004089879337698221,
        0.030830612406134605,
        0.07531401515007019,
        0.074839286506176,
        -0.024767713621258736,
        0.030533354729413986,
        0.022093582898378372,
        0.006308818235993385,
        0.03398580104112625,
        0.10630529373884201,
        -0.06921014189720154,
        -0.026167025789618492,
        -0.04114830121397972,
        -0.07751069217920303,
        -0.051389530301094055,
        -0.022913480177521706,
        0.0504138320684433,
        0.018897196277976036,
        0.014373833313584328,
        0.07998331636190414,
        0.12824982404708862,
        0.04340873658657074,
        0.10741206258535385,
        -0.14011983573436737,
        -0.020726924762129784,
        0.0856710895895958,
        0.004808479454368353,
        -0.06960204988718033,
        -0.047652967274188995,
        0.013308408670127392,
        0.07985875755548477,
        0.05785488337278366,
        0.005222967825829983,
        -0.011244614608585835,
        0.036159347742795944,
        -0.0311137568205595,
        -0.054422855377197266,
        -0.0051110778003931046,
        0.08164326101541519,
        -0.013068117201328278,
        -0.03329697251319885,
        0.053147509694099426,
        -0.053061455488204956,
        -0.10878822207450867,
        0.07299443334341049,
        0.045606210827827454,
        0.016006004065275192,
        0.04063517600297928,
        0.024718642234802246,
        0.002949453191831708,
        0.00043838442070409656,
        -0.10124114155769348,
        -0.043852515518665314,
        -0.048056915402412415,
        -0.13454942405223846,
        -0.007720577996224165,
        -0.029492730274796486,
        -0.0020151338540017605,
        0.03389173746109009,
        -0.015490773133933544,
        -0.013367894105613232,
        0.014180311933159828,
        0.0395672544836998,
        -0.03606117516756058,
        0.11265724897384644,
        -0.010632911697030067,
        0.06653767079114914,
        -0.07524234056472778,
        0.05415080487728119,
        -0.06678085774183273,
        -0.11969907581806183,
        8.098815918487792e-33,
        -0.04682239517569542,
        -0.04316065460443497,
        -0.036199286580085754,
        0.05211515352129936,
        -0.018348684534430504,
        -0.03209393844008446,
        0.04505200311541557,
        0.024481307715177536,
        -0.0035394812002778053,
        0.03571006655693054,
        -0.10852102935314178,
        -0.025396248325705528,
        0.02184031903743744,
        0.017370106652379036,
        0.007526386063545942,
        0.06836678087711334,
        -0.10418454557657242,
        -0.01628125086426735,
        -0.024124421179294586,
        -0.014441629871726036,
        -0.051164284348487854,
        0.024366097524762154,
        0.1298656165599823,
        0.10226897895336151,
        -0.0034190069418400526,
        -0.016702920198440552,
        -0.059553325176239014,
        -0.025356804952025414,
        -0.0034805061295628548,
        0.01434286404401064,
        0.011207664385437965,
        0.007807580754160881,
        0.0012808352475985885,
        -0.0435083732008934,
        -0.03113853931427002,
        0.015256932005286217,
        0.0710875615477562,
        0.0026962219271808863,
        -0.043014708906412125,
        -0.017306938767433167,
        -0.03926674649119377,
        0.016366995871067047,
        -0.01781010441482067,
        0.03577633202075958,
        0.013286983594298363,
        -0.04461989551782608,
        -0.004640605766326189,
        -0.022025112062692642,
        0.016541019082069397,
        -0.013598612509667873,
        0.0399857722222805,
        0.011130282655358315,
        -0.054375920444726944,
        -0.11161640286445618,
        -0.05612288415431976,
        0.07852990180253983,
        0.013995902612805367,
        0.05886847898364067,
        -0.052073411643505096,
        -0.04902168735861778,
        0.030775491148233414,
        -0.012897190637886524,
        -0.01613570749759674,
        -0.07214359194040298,
        0.00866248644888401,
        0.008011429570615292,
        0.05154632404446602,
        0.020829347893595695,
        -0.014743817038834095,
        -0.11733192205429077,
        0.04665980488061905,
        -0.0600777268409729,
        0.0047484808601439,
        0.0417342372238636,
        0.05905379354953766,
        -0.04280185326933861,
        0.054072875529527664,
        -0.029903704300522804,
        -0.01677584834396839,
        -0.08957792818546295,
        0.006512012332677841,
        -0.02217213436961174,
        -0.008663490414619446,
        -0.053086474537849426,
        -0.07022539526224136,
        -0.10963920503854752,
        -0.0028820065781474113,
        0.012149187736213207,
        -0.07865796983242035,
        0.02245219051837921,
        -0.02742875926196575,
        0.004852197133004665,
        0.07485099881887436,
        0.045405276119709015,
        -0.021494358777999878,
        -1.0489700898399275e-32,
        -0.0036868818569928408,
        -0.018085146322846413,
        -0.016941582784056664,
        -0.09147923439741135,
        -0.02949163317680359,
        -0.016383333131670952,
        -0.030560459941625595,
        -0.12204895168542862,
        -0.005279550328850746,
        -0.10695096850395203,
        -0.003207565750926733,
        -0.06317535042762756,
        0.026410022750496864,
        -0.08932912349700928,
        0.04453357309103012,
        -0.014505107887089252,
        0.017242589965462685,
        0.06875886768102646,
        -0.02023208513855934,
        0.0181535966694355,
        0.023435188457369804,
        -0.004117196891456842,
        -0.09265772998332977,
        -0.06285861879587173,
        0.018225669860839844,
        0.05895095691084862,
        0.021946553140878677,
        0.0607331357896328,
        0.020932022482156754,
        -0.03352294862270355,
        -0.002901683561503887,
        0.020793940871953964,
        -0.0058286841958761215,
        0.04427272081375122,
        0.009205766953527927,
        -0.033965639770030975,
        -0.0049257706850767136,
        -0.0034959728363901377,
        -0.0533817820250988,
        -0.10667862743139267,
        0.01458126399666071,
        0.05404537171125412,
        0.014094097539782524,
        0.0015463002491742373,
        0.021768590435385704,
        0.018473375588655472,
        -0.02041287161409855,
        -0.04897433891892433,
        -0.003854810493066907,
        -0.0076515269465744495,
        0.09000155329704285,
        0.04373863339424133,
        -0.09110716730356216,
        -0.010522610507905483,
        -0.035522494465112686,
        0.05306525528430939,
        0.1042129248380661,
        0.010786877013742924,
        -0.03546195477247238,
        0.026962177827954292,
        0.05537137761712074,
        0.053433578461408615,
        -0.06280510872602463,
        -0.0028004373889416456,
        0.09012752026319504,
        0.014852938242256641,
        -0.11269515752792358,
        -0.07727008312940598,
        0.0618242509663105,
        -0.024421826004981995,
        -0.016194486990571022,
        -0.0210728757083416,
        -0.012533577159047127,
        -0.09988167881965637,
        0.006591983139514923,
        0.002410725224763155,
        -0.047916900366544724,
        -0.006571554578840733,
        -0.05443911999464035,
        0.026811590418219566,
        -0.015403812751173973,
        -0.057332951575517654,
        0.053450483828783035,
        -0.01623382978141308,
        -0.09220179170370102,
        -0.05455509573221207,
        0.021868480369448662,
        -0.027997400611639023,
        0.08686897903680801,
        -0.048843152821063995,
        -0.022695982828736305,
        0.03707710653543472,
        -0.10464094579219818,
        0.0025782689917832613,
        -0.0005851995665580034,
        -6.83318788219367e-8,
        0.13129572570323944,
        0.012399069964885712,
        0.07049128413200378,
        0.023961130529642105,
        0.025550656020641327,
        -0.04786664620041847,
        0.017338328063488007,
        0.025807397440075874,
        -0.08222732692956924,
        0.09083365648984909,
        -0.04445241764187813,
        0.033580243587493896,
        0.03170151263475418,
        -0.03507089242339134,
        0.06489934772253036,
        -0.12167686223983765,
        0.015928246080875397,
        -0.022744616493582726,
        0.008803251199424267,
        0.01503800880163908,
        0.063297338783741,
        0.022931402549147606,
        -0.036761295050382614,
        -0.08039624243974686,
        0.04083221033215523,
        -0.06334968656301498,
        -0.004731760825961828,
        -0.018922654911875725,
        -0.04556780681014061,
        -0.045914698392152786,
        0.0757046565413475,
        0.023798175156116486,
        0.0014204359613358974,
        -0.059225331991910934,
        0.027362806722521782,
        -0.11457889527082443,
        0.02310549095273018,
        0.054001711308956146,
        -0.05634770914912224,
        0.10423246026039124,
        0.04060899838805199,
        0.049745745956897736,
        0.04152943193912506,
        -0.002197815105319023,
        0.012690938077867031,
        0.017499621957540512,
        -0.03401409462094307,
        -0.05249372124671936,
        0.012074591591954231,
        0.053261447697877884,
        -0.018577629700303078,
        0.006319032516330481,
        -0.00901095476001501,
        -0.05761140212416649,
        -0.004544517491012812,
        0.05062117055058479,
        0.06644422560930252,
        0.011441580019891262,
        -0.0272616408765316,
        -0.061981286853551865,
        0.07956500351428986,
        0.04820110648870468,
        0.008779517374932766,
        0.027480775490403175
      ],
      "metadata": {
        "title": "Paper_12_Sleep_and_its_relation_to_cognition_and_behaviour_.pdf",
        "createdAt": "2025-12-17T13:56:30.076Z"
      },
      "fileObj": {}
    },
    {
      "id": "doc_3_1765979790984",
      "fileName": "Paper_15_Diversity_and_noise_effects_in_a_model_of_homeosta.pdf",
      "content": "arXiv:1209.5046v1 [physics.bio-ph] 23 Sep 2012  Diversity and noise effects in a model of homeostatic regulation of the sleep-wake cycle  Marco Patriarca 1 , 2 , ‚àó   Svetlana Postnova 3 , 4 , ‚Ä†   Hans A. Braun 5 , ‚Ä°   Emilio Hern¬¥ andez-Garc¬¥ ƒ±a 1 , ¬ß   and Ra¬¥ ul Toral 1 , ¬∂  1   IFISC, Instituto de F¬¥ ƒ±sica Interdisciplinar y Sistemas Complejos (CSIC-UIB), Campus Universitat de les Illes Balears, E-07122 Palma de Mallorca, Spain ‚àó‚àó  2   National Institute of Chemical Physics and Biophysics, R¬® avala 10, 10143 Tallinn, Estonia  3   School of Physics, The University of Sydney, Physics Annex, A29, NSW 2006 Sydney, Australia  4   Center for Integrated Research and Understanding of Sleep, The University of Sydney, Glebe Point Rd, 431, NSW 2037 Sydney, Australia and  5   Neurodynamics Group, Physiology Institute, Marburg University, Deutschhausstr. 2, D-35037 Marburg, Germany  Abstract  Recent advances in sleep neurobiology have allowed development of physiologically based mathe- matical models of sleep regulation that account for the neuronal dynamics responsible for the regu- lation of sleep-wake cycles and allow detailed examination of the underlying mechanisms. Neuronal systems in general, and those involved in sleep regulation in particular, are noisy and heterogeneous by their nature. It has been shown in various systems that certain levels of noise and diversity can significantly improve signal encoding. However, these phenomena, especially the effects of diversity, are rarely considered in the models of sleep regulation. The present paper is focused on a neuron- based physiologically motivated model of sleep-wake cycles that proposes a novel mechanism of the homeostatic regulation of sleep based on the dynamics of a wake-promoting neuropeptide orexin. Here this model is generalized by the introduction of intrinsic diversity and noise in the orexin- producing neurons, in order to study the effect of their presence on the sleep-wake cycle. A simple quantitative measure of the quality of a sleep-wake cycle is introduced and used to systematically study the generalized model for different levels of noise and diversity. The model is shown to exhibit a clear diversity-induced resonance: that is, the best wake-sleep cycle turns out to correspond to an intermediate level of diversity at the synapses of the orexin-producing neurons.   On the other hand, only a mild evidence of stochastic resonance is found, when the level of noise is varied. These results show that disorder, especially in the form of quenched diversity, can be a key-element for an efficient or optimal functioning of the homeostatic regulation of the sleep-wake cycle. Furthermore, this study provides an example of a constructive role of diversity in a neuronal system that can be extended beyond the system studied here.  This paper has been published as: M. Patriarca, S. Postnova, H.A. Braun, E. Hern¬¥ andez-Garc¬¥ ƒ±a, R. Toral,  Diversity and Noise Effects in a Model of Homeostatic Regulation of the Sleep-Wake Cycle , PLoS Comput. Biol.   8 (8): e1002650 (2012)  doi:10.1371/journal.pcbi.1002650  ‚àó Electronic address: marcop@ifisc.uib-csic.es  ‚Ä† Electronic address: postnova@physics.usyd.edu.au  ‚Ä° Electronic address: braun@staff.uni-marburg.de  ¬ß Electronic address: emilio@ifisc.uib-csic.es  ¬∂ Electronic address: raul@ifisc.uib-csic.es  ‚àó‚àó URL:   http://ifisc.uib-csic.es  Author Summary  All biological systems are inherently noisy and hetero- geneous.   Disorder is mostly expected to disturb proper functioning of a system, like it can be the case with noise in a radio signal.   However, it has been demonstrated by numerous studies that noise can actually improve sig- nal encoding ‚Äì the so-called stochastic resonance phe- nomenon.   Recently, it was discovered that quenched di- versity (heterogeneity) can also enhance the response of a system to an external perturbation (diversity-induced res- onance). In this study we investigate the role of noise and diversity in a neuronal model of sleep-wake cycles based on the dynamics of the wake-promoting orexin neurons that is crucial for stability of wake and sleep states. We demonstrate that suitable levels of diversity introduced in the orexin neurons can significantly improve the quality of the sleep-wake cycle, and may be essential for proper sleep-wake periodicity.   Noise, on the other hand, pro- vides only a mild improvement.\n\n2  I.   INTRODUCTION  Disorder, which originates from both noise and diver- sity, is naturally present in all biological systems.   In neuronal systems some examples are the random open- ing and closing of ion channels, the multitude of stochas- tic input currents in the neurons, and the diversity of shapes, sizes, and electrophysiological properties of the neurons [1, 2]. Disorder is often considered to be harmful to the systems‚Äô functioning and to information encoding. However, it was likewise repeatedly demonstrated that a certain level of disorder can facilitate signal encoding by enhancing system‚Äôs response to an external stimuli. For instance, quenched diversity clearly shows its construc- tive role in the phenomenon of diversity-induced reso- nance, in which an assembly of heterogeneous excitable units presents an optimal response to an external forcing for a suitable intermediate degree of heterogeneity [3‚Äì5]. Similar constructive effects can be observed in the pres- ence of noise. For example, interplay of noise and nonlin- ear forces produces the directed motion of motor proteins [6], order-disorder transitions, oscillations, and synchro- nization in assemblies of excitable units [7‚Äì9], and an op- timized system response in the ubiquitous phenomenon of stochastic resonance [10, 11], e.g. in ion-channels and neurons [12‚Äì17]. In the present study we examine the effects of noise and diversity (heterogeneity) in a physiologically based neu- ronal model of sleep-wake cycles [18]. This model intro- duces a novel mechanism of the homeostatic regulation of sleep based on the dynamics of a wake-promoting neu- ropeptide orexin (also called hypocretin), assuming de- pression of orexinergic synapses during wakefulness and their recovery during sleep. This mechanism is based on the experimental findings of the essential role of orexin system in maintaining wakefulness and its ability to in- tegrate the sleep-wake relevant information coming from many brain areas [19, 20] and respond to changes in the body external and internal environments by encoding the body activity state, energy balance, sensory and emo- tional stimuli [21, 22]. In the original model interaction between only two representative neurons is simulated:   the orexin neuron and the local glutamate neuron that are reciprocally con- nected to each other according to the experimentally es- tablished physiological connections [23]. Both orexin and glutamate neurons are firing during wakefulness and are silent during sleep. The transitions between firing and si- lence are governed by the interplay between the circadian input and homeostatic mechanisms as initially proposed by Borbely [24]. For simplicity, in this model only a sin- gle type of orexin neurotransmitter (instead of the two types actually known) is considered, and it is assumed that the system can be either in the wake state or in a generic non-Rapid Eye Movement sleep state, without specifying ultradian structure of sleep.   Also this model did not consider noise effects, and diversity could not be included since there are only two neurons present. In the present paper we extend the above described two-neuron model to a more realistic multi-unit model with heterogeneous neurons. The aim of the study is to first of all investigate how the presence of diversity in the neuronal population affects sleep-wake transitions, since it is well-known that neurons are highly heterogeneous by their nature. In particular, within the orexin neurons population significant intrinsic diversity can be found: different electrophysiological properties, sizes in the di- ameter range 15-40   Œº m, and various shapes such as a spherical, fusiform, or multipolar [19, 22, 25]. Secondly, also stochastic fluctuations, representing current noise, are added to the model and the response of the system is studied for different levels of noise. The question natu- rally arises, to what extent noise and diversity are essen- tial ingredients for the functioning of assemblies of neu- rons and other complex systems, and what is the optimal level of noise and diversity required for the emergence of an optimal response to external stimuli. It is shown be- low that the model under study presents both diversity- induced resonance and stochastic resonance, but the for- mer appears more clear and robust, since it is always associated with a regular almost-periodic spiking-silence activity, rather than to the irregular random transitions characterizing the stochastic resonance regime.  II.   MATERIALS AND METHODS  In this section the two-neuron model of sleep-wake cy- cles [18] is described and some examples of dynamics in the presence of an external periodic signal are illustrated. Further, this model is extended to account for multiple neurons dynamics and heterogeneity, and a simple quan- titative criterion to estimate the quality of a sleep-wake cycle is introduced.   This criterion will be used in the Results section to compare sleep-wake cycles dynamics obtained at different parameter sets.  A.   The two-neuron model  The original model of the homeostatic regulation of sleep has a minimal structure consisting of two represen- tative interacting neurons A and B, as depicted in Fig. 1. The neuron A simulates a representative neuron from the orexinergic neuronal population, while the neuron B represents a local glutamate interneuron (for details see [18]). The state of wakefulness or sleep is determined by the firing regime of neurons A and B, since these neurons are known to fire during wakefulness and be almost silent during sleep (see e.g. [22]). Interaction between the neurons A and B takes place through glutamate and orexin neurotransmitters, as de- tailed below.   The neuron A is acted upon by a stimu- lus in pace with the circadian rhythm, here treated as a periodic external signal ‚Äî a simplification justified by its independence from the homeostatic process [26].\n\n3  FIG. 1:   Scheme of the two-neuron model of the sleep- wake cycle [18].   The A   ‚Üí   B red arrow from the orexin- producing neuron A (red circle) to the neuron B (blue circle) represents the glutamate projection as well as the orexin pro- jection regulating the homeostatic process.   The blue arrow represents the B   ‚Üí   A glutamate projection. The neuron A is also acted upon by a periodic signal representing the effect of the circadian clock.  The homeostatic process itself is described by an addi- tional macroscopic variable   M   ( t ) simulating availability of orexin. Dynamics of the neurons A and B are based on a Hodgkin-Huxley-type model [27]. The membrane poten- tials of the neurons A ( V A ( t )) and B ( V B ( t )) are thus calculated as:  C A  dV A  dt   =   I ext   +   Œæ A   ‚àí   I A , L   ‚àí   I A , Na   ‚àí   I A , K   ‚àí   I A , gl   (1)  ‚â°   I ext   +   Œæ A   ‚àí   g L [ V A ‚àí E L ]   ‚àí   g Na [ V A ‚àí E Na ] a A , Na  ‚àí   g K [ V A ‚àí E K ] a A , K   ‚àí   g gl [ V A ‚àí E gl ] a A , gl , C B  dV B  dt   =   Œæ B   ‚àí   I B , L   ‚àí   I B , Na   ‚àí   I B , K   ‚àí   I B , gl   ‚àí   I ox   (2)  ‚â°   Œæ B   ‚àí   g L [ V B ‚àí E L ]   ‚àí   g Na [ V B ‚àí E Na ] a B , Na  ‚àí g K [ V B   ‚àí   E K ] a B , K   ‚àí   g gl [ V B ‚àí E gl ] a B , gl   ‚àí   g ox [ V B ‚àí E ox ] a ox ,  where   C p   ( p   = A ,   B) are the membrane capacitances per   unit   area   of   the   respective   neurons,   I Œ±   ( Œ±   = L ,   Na ,   K ,   gl ,   ox) are the ionic currents,   g Œ±   are the max- imum conductances, and   E Œ±   are the equilibrium poten- tials.   The capacitance values are taken as   C A   =   C B   = 1 Œº F / cm 2 . The values of all the other model parameters are listed in Table I. In the following we give a detailed explanation of dif- ferent parts of the model.  ‚Ä¢   External forces . The current   I ext   acting on the neu- ron A and the noise currents   Œæ p ( t ),   p   = A ,   B, can be considered as external forces, in the sense that they do not depend on the system variables. The   external current   I ext ( t ) is assumed to simulate a stimulus associated with the circadian rhythm. For simplicity in the present study a periodic pulse input is used to introduce circadian activation of the system:   œÑ   ,   I ext ( t ) =   I ext ( t   +   œÑ   ).   Such cur- rent can be interpreted as an awakening effect of an alarm clock or some other disturbance coming with a period of 24 hours. In the following we em- ploy a train of rectangular pulses with length   œÑ 0  ( œÑ 0   < œÑ   ) and height   I 0 , as depicted in Fig. 2-top,  I ext ( t )   =   I 0   ,   nœÑ   ‚â§   t   < nœÑ   +   œÑ 0   ,  =   0   ,   nœÑ   +   œÑ 0   ‚â§   t   <   ( n   + 1) œÑ ,   (3) where   n   is an integer. This simple form is chosen because it is convenient for carrying out a system- atic study of the neuron response at different pa- rameters sets. However, it should be kept in mind that it represents a drastic simplification, and more realistic shapes of circadian currents can also be used [18]. The   noise   term   Œæ p ( t ) represents fluctuating cur- rents that are known to be always present in neu- rons. For simplicity, we assume zero-average Gaus- sian white-noise processes:  „Äà Œæ p ( t ) „Äâ   = 0;  „Äà Œæ p ( t )   Œæ p ‚Ä≤   ( s ) „Äâ   = 2   D p   Œ¥ p,p ‚Ä≤   Œ¥ ( t ‚àí s ) ,   p, p ‚Ä≤   = A ,   B ,   (4) with   D p   being the noise intensity.  ‚Ä¢   Internal   dynamics .   The   leakage,   sodium,   and potassium currents   I p,Œ±   ( p   = A ,   B;   Œ±   = L ,   Na ,   K) in the equation of the neuron   p   depend only on the variables of the   same   neuron   p   and, thus, describe the neuronal internal dynamics. The   leakage currents   I p, L   =   g L ( V p   ‚àí   E L ) repre- sent a flow of ions with a small conductance   g L   ‚âà  0 . 1   Œº S / cm 2   driving the membrane potential toward the negative value   E L   ‚âà ‚àí 60 mV. The depolarizing   Na-currents   I p, Na   =   g Na ( V p   ‚àí  E Na )   a p, Na   have a maximum conductance   g Na   = 3   Œº S / cm 2   and a large positive equilibrium potential  E Na   = 50 mV.   The activation variables   a p, Na ( t ), with 0   ‚â§   a p, Na   ‚â§   1, represent the fraction of open ion-channels contributing to the Na current.   Be- cause of their fast activation relative to the other time scales, the Na-current is assumed to be ac- tivated instantaneously, according to its voltage- dependency:  a p, Na   = Œ¶( S Na ( V p   ‚àí   W Na ))   ,   (5) where Œ¶( x ) is the sigmoid function Œ¶( x ) =   1  1 + exp( ‚àí x )   ,   (6)  S Na   is the steepness of the sigmoid function and  W Na   is the half-activation potential. The   repolarizing   K-currents   I p, K   =   g K ( V p   ‚àí  E K )   a p, K   are characterized by a maximum conduc- tance   g K   = 4   Œº S / cm 2 , a large negative equilib- rium potential   E K   =   ‚àí 90 mV, and a longer activa- tion time than the depolarizing Na-current, namely\n\n4  TABLE I:   Parameters of the two-neuron model [18].  Conductance   Equilibrium   Slope   Threshold   Time  Potential   Parameter   Potential   Scales  ( Œº S / cm 2 )   (mV)   (mV ‚àí 1 )   (mV)   (ms)  L (Leakage current)   g L   = 0 . 1   E L   =   ‚àí 60  Na (Sodium current)   g Na   = 3   E Na   = 50   S Na   = 0 . 25   W Na   =   ‚àí 25   ( œÑ Na   ‚âà   0)  K (Potassium current)   g K   = 4   E K   =   ‚àí 90   S K   = 0 . 25   W K   =   ‚àí 25   œÑ K   = 2  gl (Glutamate current)   g gl   = 0 . 15   E gl   = 50   S gl   = 1   W gl   =   ‚àí 20   œÑ gl   = 30  ox (Orexin current)   g ox   = 0 . 135   E ox   = 50   S ox   = 1   W ox   =   ‚àí 20   œÑ ox   = 300  g ox   = 0 . 2   œÑ   + ox   = 7500  œÑ   ‚àí  ox   = 920  Periodic current   œÑ   = 24000  œÑ 0   = 500  œÑ K   = 2 ms. Consequently, the dynamics of the K- currents activation variables are modelled as  da p, K  dt   =   ‚àí   1  œÑ K  [ a p, K   ‚àí   Œ¶( S K ( V p   ‚àí   W K ))]   ,   (7) where Œ¶( x ) is defined in Eq. (6).  Couplings . The neurons A and B are mutually cou- pled by chemical synapses through the glutamate- induced ( I p , gl ) and the orexin-induced ( I ox ) cur- rents.   Unlike the Na and K currents,   I p , gl   and  I ox   depend on the activity of both presynaptic and postsynaptic neurons. The activation variables  a p , gl   and   a ox   depend on the appearance of a spike in the presynaptic neuron, i.e.   on the presynap- tic voltage. Additionally these currents depend on the voltage of the postsynaptic neuron, similarly to other ionic currents.   Both glutamate and orexin are excitatory neurotransmitters, so they are as- sumed to open depolarizing ion channels, such as Na-channels. The activations of the glutamate-induced currents are modeled as:  da p , gl  dt   =   ‚àí   1  œÑ gl  [   a p , gl   ‚àí   Œ¶( S gl ( V ¬Ø p   ‚àí W gl )) ]   ,  ¬Ø p   = B   if   p   = A;   ¬Ø p   = A if   p   = B .   (8) This equation is similar to Eq. (7) but has the important   difference   that   the   equilibrium   value Œ¶( S gl ( V ¬Ø p ‚àí W gl )) for the activation variable   a p , gl   de- pends on the membrane potential   V ¬Ø p   of the   other  neuron ¬Ø p   (¬Ø p   = B if   p   = A, ¬Ø p   = A if   p   = B).   The time constant   œÑ gl   = 30 ms accounts for the delay coming from the activation of glutamate receptors, and the following activation of ion channels. The   orexin-induced current   represents the effect of orexin produced by the neuron A and acting on the neuron B. It is modeled in a form similar to the glutamate-induced current.   This current provides a simplified description of the effects of orexin on the neuron B which appear after a complex series of processes, involving production of orexin in the soma of the neurons, its release in the synaptic cleft, and activation of G-protein coupled metabotropic receptors. The dynamics of the activation variable  a ox ( t ) depend not only on the membrane poten- tial   V A ( t ), but are also related to the availability of orexin at time   t , described by the additional vari- able   M   ( t ) (0   ‚â§   M   ‚â§   1).   The dynamics of the variables   a ox ( t ) and   M   ( t ) are defined by the equa- tions:  da ox  dt   =   ‚àí   1  œÑ ox  [ a ox   ‚àí M   √ó   Œ¶( S ox ( V A   ‚àí W ox ))]   ,   (9)  dM  dt   =   ‚àí   1  œÑ   + ox  ( M   ‚àí 1)  ‚àí   1  œÑ   ‚àí  ox  M   √ó   Œ¶( S ox ( V A   ‚àí W ox )) .   (10) The term   M   √ó   Œ¶( S ox ( V A   ‚àí   W ox )) in the Eq. (9) reflects activation of the synaptic current due to appearance of a spike in the presynaptic neuron A. At the same time it determines the rate of orexin availability reduction in Eq. (10) due to spiking of the neuron A with a time constant   œÑ   ‚àí  ox .   The first term in Eq. (10) determines recovery rate of the orexin availability with time constant   œÑ   + ox . The meaning of the product   M   ( t )   √ó   Œ¶( S ox ( V A   ‚àí  W ox )) is that there is orexin-induced activity in neuron B if (1) there is enough orexin available above a critical threshold [ M   ( t )   > M critical ], and (2) the neuron A is in the firing state [Œ¶( t )   ‚âà   1]. The time constants   œÑ   ¬±  ox   accounting for the orexin dynamics are much longer than the time constants associated with ionic current terms. The time con- stant   œÑ ox   of the homeostatic regulation process is even longer, being of the order of magnitude of the daily period   œÑ   . For numerical convenience, simulations are made over rescaled daily and orexin time scales: the daily\n\n5  FIG. 2:   Response of the two-neuron model . Main variables and inter-spike times   Œ¥t p   ( p   = A ,   B)   versus   time for a pulse height   I 0   = 0 . 895 mA (left) and   I 0   = 0 . 893 mA (right), see text for details.  period was assumed to be   œÑ   = 24 s, instead of  œÑ   = 24 h, achieved through a suitable rescaling, which was applied to the orexin time scale   œÑ ox   and the production and reduction times   œÑ   ¬±  ox . The other time parameters are left unchanged.   Since such rescaled   œÑ ox   and   œÑ   ¬±  ox   are still much larger than any other time scale of the microscopic dynamics, the rescaling does not change the main results of the simulations.   See [18] for a detailed validation of such rescaling procedure.\n\n6 All the parameter values for the currents are listed in Table I. It is assumed that the neurons A and B share the same parameter values, unless specified otherwise. Such an assumption is justified, because the major properties of these neurons required for the model are the tonic firing (periodic single spike activity) and silent states. Without any external input both neurons should be in a silent state, while they are brought to firing activity in response to depolarization. Therefore, change of param- eters in a physiologically allowed range would primarily lead to the different amount of depolarization needed to excite neurons, and would not affect the major outcomes of the simulations. The system defined above is essentially an excitable feedback system, i.e. both the external input of sufficient strength and the AB coupling are essential elements for maintaining firing activity of the neurons. Orexin-related dynamics, with the associated long time scales, are ex- pected to direct the homeostatic sleep process, which reg- ulates the sleep-wake transitions. The healthy sleep-wake cycles in this system are realized as follows:  ‚Ä¢   Initiating wakefulness . A sufficiently strong or long external signal or a stimulus associated to the cir- cadian rhythm, e.g. the idealized rectangular pulse considered here, activates the system and induces firing activity in the neuron A. Due to the excita- tory synaptic connection from A to B, the neuron B is also activated.  ‚Ä¢   Maintaining wakefulness . Once the pulse is finished and the external current is zero, the system remains in the wake state (i.e.   both neurons A and B are firing) due to reciprocal excitation between the neu- rons. The firing activity lasts for a fraction   q   of the daily period   œÑ   .   Ideally one can assume   q   = 2 / 3, corresponding to 16 hours for a day of 24 hours, i.e. 16 seconds for the daily period   œÑ   = 24 s with the time scales of the model considered here.  ‚Ä¢   Initiating sleep .   The firing stops in both neurons due to decreased availability of orexin according to the dynamics of   M   ( t ). This is associated witch the transition from wake to sleep. Two examples of the two-neuron model dynamics with- out noise are illustrated in Fig. 2.   The left part of the figure represents the response obtained for a pulse length  œÑ 0   = 500 ms and height   I 0   = 0 . 895   Œº A / cm 2 .   In each period orexin is depleted during the neuronal activity and recovered while the neurons are silent.   The stimu- lus parameters used in this example have been intention- ally chosen close to the critical firing threshold, so that by slightly reducing the pulse height or length, the peri- odic appearance of a continuous time interval of spiking regime is lost.   Such case is demonstrated in the right hand side of the figure, where the current pulse height is slightly lower,   I 0   = 0 . 893 mA, while all the other param- eters are kept the same. There the prolonged wake state is induced only every other day, because the input is in- sufficient to induce sustained spiking at the same levels of orexin availability.   By reducing the pulse amplitude or duration even further it is possible to observe different behaviors such as triple or higher-order periodicities.  FIG. 3:   Scheme of the heterogeneous model . Example of model system with   N A   = 5 orexin-producing neurons   { A i } ,  i   = 1 , . . . N A   (red spheres) and one neuron B (blue sphere). The neurons A interact with each other through an all-to-all coupling (red lines). Blue and red projections have a meaning similar to those of Fig. 1:   the neuron B is coupled to the neurons A i   through parallel glutamate projections, while each neuron A i   is coupled to neuron B through a glutamate and an orexin projection. The neurons A are also acted upon by a stimulus representing the effect of the circadian clock (gray arrows).  B.   The heterogeneous model  As a step toward a more realistic model we generalize the two-neuron model into a heterogeneous multi-neuron model.   For simplicity we first increase the number of orexin neurons only.   To do this we replace the single neuron A by a set of   N A   neurons   { A i }   ( i   = 1 , . . . , N A ), while still maintaining only one neuron B. Also, in this paper we assume that the diversity is constant in time in order to consider the simplest case possible. In reality a certain level of heterogeneity is observed in all neuronal parameters. However, given that our model neurons are simple pacemaking neurons such diversifica- tion of different model parameters (in a physiologically allowed range) would simply lead to slightly different fir- ing rates of the neurons. This, in turn, will result in di- versity in activations of synaptic currents, which can be\n\n7 mimicked by simply diversifying their activation thresh- olds.   Thus, in the following we can limit ourselves to studying the effects of diversity in activation thresholds of synaptic currents without loss of generality. Further- more, as a first step, the heterogeneity is only introduced in the glutamate-induced currents to avoid having a too complicated system, which would become difficult to un- derstand. With regard to the coupling topology among the orexin neurons, so far there is no detailed experimental data. Therefore, for simplicity, we chose an all-to-all coupling via gap junctions, but other variations can be tested in the future. The intensity of the coupling has been chosen large enough to ensure that the neurons A i   respond in pace to the external current. The equations of the two- neuron model are modified accordingly.  ‚Ä¢   Dynamics of the neurons   A i .   The membrane po- tentials   V   ( i ) A   ( t ) of the neurons A i , are described by equations analogous to Eq. (1):  C A  dV   ( i ) A  dt  =   I ext   +   Œæ ( i ) A   ‚àí   I   ( i ) A , L   ‚àí   I   ( i ) A , Na   ‚àí   I   ( i ) A , K   ‚àí   I   ( i ) A , gl   ‚àí   ‚àë  j  I ij  =   I ext   +   Œæ ( i ) A   ‚àí   g L [ V   ( i ) A   ‚àí E L ]   ‚àí   g Na [ V   ( i ) A   ‚àí E Na ]   a   ( i ) A , Na  ‚àí g K [ V   ( i ) A   ‚àí E K ]   a   ( i ) A , K   ‚àí   g gl [ V   ( i ) A   ‚àí E gl ]   a   ( i ) A , gl  ‚àí k   int  ‚àë  j  [ V   ( i ) A   ‚àí   V   ( j ) A   ]   .   (11) The current terms are similar to those in the two- neuron model, apart from the additional coupling currents between two generic neurons A i   and A j   ,  I ij   =   k   int ( V   ( i ) A   ‚àí V   ( j ) A   ), with   i, j   = 1 , . . . , N A , where  k   int   is the gap junctions conductance that can be treated as coupling strength. The currents‚Äô activa- tion variables   a   ( i ) A , Na   and   a   ( i ) A , K   are modeled in accord with the equations of the two-neuron model. Note that the specific values of the activation variables will be different for different neurons since they de- pend on voltages of each particular neuron A i . For simplicity the same external current   I ext ( t ) given by Eq. (3) is assumed to act on all neurons A i   (see Fig. 3).   The noise terms   Œæ ( i ) A   ( t ) as well as the noise   Œæ B ( t ) acting on the neuron B (see be- low) are also defined similarly and assumed to be statistically independent from each other. For con- venience the properties of all stochastic forces are written together ( i, j   = 1 , . . . , N A ):  „Äà Œæ ( i ) A   ( t ) „Äâ   =   „Äà Œæ B ( t ) „Äâ   = 0   ,  „Äà Œæ ( i ) A   ( t )   Œæ B ( s ) „Äâ   = 0 ,  „Äà Œæ ( i ) A   ( t )   Œæ ( j ) A   ( s ) „Äâ   = 2   D A   Œ¥ i,j   Œ¥ ( t ‚àí s )   ,  „Äà Œæ B ( t )   Œæ B ( s ) „Äâ   = 2   D B   Œ¥ ( t ‚àí s )   .   (12)  ‚Ä¢   Connections from the neuron B to the neurons   A i . The neuron B has glutamatergic synaptic inputs to each of the neurons A i   as depicted in Fig. 3. Diversity is introduced in the activation thresholds of the glutamate-induced currents according to the following equation for the activation variables:  da   ( i ) A , gl  dt   =   ‚àí   1  œÑ gl  [  a   ( i ) A , gl   ‚àí   Œ¶( S gl ( V B   ‚àí W   ( i ) B , gl ))  ]  .   (13) The thresholds   W   ( i ) B , gl   adopt different values for each neuron A i   that are independently extracted from a probability distribution defined later in the text.  ‚Ä¢   Connections from the neurons   A i   to the neuron B . Each of the neurons A i   has synaptic projections to the neuron B. This is translated in the model by replacing the single glutamate- and orexin-induced currents with their averages such that Eqs. (8) and (9) for the activation variables become:  da B , gl  dt  =   ‚àí   1  œÑ gl  [  a B , gl   ‚àí   1  N A  N A ‚àë  i =1  Œ¶( S gl ( V   ( i ) A   ‚àí W   ( i ) A , gl ))  ]  , (14)  da B , ox  dt  =   ‚àí   1  œÑ ox  [  a B , ox   ‚àí   1  N A  N A ‚àë  i =1  M   ( i ) Œ¶( S ox ( V   ( i ) A   ‚àí W ox ))  ]  (15) Note that diversity is again introduced in the ac- tivation thresholds of the glutamate-induced cur- rents   W   ( i ) A , gl   corresponding to heterogeneous (A i   ‚Üí  B) synapses located at the neuron B. Due to the dif- ferences in the A i   neurons, the orexin availability function   M   ( i ) ( t ) is different for different neurons, although still following Eq. (10). The above described set of equations constitutes the multi-neuron heterogeneous model of the homeostatic regulation of sleep. Numerical results were obtained us- ing a variation of the Runge-Kutta 2nd-order method, which is suitable for equations with stochastic terms, namely the Heun method [28].   Identical initial condi- tions were assumed for all neurons, corresponding to a silent state.  C.   Quantifying the quality of the sleep-wake cycle  In this section a heuristic criterion is introduced in or- der to evaluate and compare the quality of the system responses obtained for different external signals or inter- nal parameter values.\n\n8 For this purpose, the period   œÑ   is divided into a ‚Äúday‚Äù wakefulness sub-period of length   œÑ 1   =   qœÑ   and a ‚Äúnight‚Äù sleep sub-period of length   œÑ 2   = (1   ‚àí   q ) œÑ   , with   œÑ   =   œÑ 1   +   œÑ 2 . The quantity   q   is defined as a   wake fraction .   A typical sleep-wake cycle with an eight-hour sleep sub-period has  q   = 2 / 3.   For the day corresponding to the   n -th period ( nœÑ, ( n +1) œÑ   ), the ‚Äúday‚Äù is represented by the sub-interval ( nœÑ, nœÑ   +   œÑ 1 ) = ( nœÑ,   ( n   +   q ) œÑ   ), which covers the first frac- tion   q   of the period, while the ‚Äúnight‚Äù extends in the complementary fraction (1   ‚àí   q ) of the period in the time interval ( nœÑ   + œÑ 2 , ( n +1) œÑ   ) = (( n + q ) œÑ, ( n +1) œÑ   ). For each period   n   = 0 ,   1 , . . .   , we compute wakefulness time intervals ‚àÜ t (1)  n   and ‚àÜ t (2)  n   spent by the system in the wake state during the day, ‚àÜ t (1)  n   , and night, ‚àÜ t (2)  n   . The wake/sleep state is identified with the spiking/silent regime. A simple quantitative estimate of the quality of the sleep-wake cycle can, thus, be done through the fol- lowing linear function of the wakefulness time intervals,  r (‚àÜ t (1) ,   ‚àÜ t (2) ) =   ‚àÜ t (1)  œÑ 1  ‚àí   ‚àÜ t (2)  œÑ 2  ,   (16) where ‚àÜ t ( Œ± )   =   ‚àë  n   ‚àÜ t ( Œ± )  n   /N sp ,   Œ±   = 1 ,   2, represent the average of the wakefulness time intervals during the day ( Œ±   = 1) and during the night ( Œ±   = 2), with   N sp   being the total number of periods of the simulation. The fractions ‚àÜ t ( Œ± ) /œÑ Œ±   ( Œ±   = 1 ,   2) can vary in the in- terval (0 ,   1); then the coefficient   r   in Eq. (16) is limited in the interval ( ‚àí 1 ,   1).   The maximum value   r   = 1 cor- responds to an optimal cycle with ‚àÜ t (1)   =   œÑ 1   (wakeful- ness during the entire day) and ‚àÜ t (2)   = 0 (sleep during the entire night); any deviation from the optimal state ( r   = 1) comes either from values ‚àÜ t (1)   < œÑ 1   (implying some sleep during the day) or values ‚àÜ t (2)   >   0 (meaning at least some wakefulness in the night). See the support- ing information in the Appendix for further details on the definition of the time intervals ‚àÜ t (1) , ‚àÜ t (2)   and the coefficient   r .  III.   RESULTS  In this section we study how the presence of disor- der affects the system response and discuss the main dif- ferences compared to the two-neuron model.   The term ‚Äúdisorder‚Äù is used here to refer to either   noise , i.e. dis- order in time (stochastic terms in the external current), or   diversity , i.e a quenched heterogeneity in the neuronal parameters.   These two aspects are studied separately. For the sake of simplicity, we examine the response of the system to a periodic stimulus represented by a train of short rectangular pulses as defined in Materials and Methods. In each of the examples considered, the initial con- figuration in the absence of noise and diversity is the same as the sub-threshold state illustrated in Fig. 2-right with a double-periodic response. It is obtained for a re- duced height of the current pulse   I 0   = 0 . 893 mA, while  FIG. 4:   Effect of noise in neurons   { A i } . (A). Ten periods of the raster plots of neuron B for different intensities   D A  of the noise acting on neurons   { A i } .   Vertical dashed lines mark the beginning of the pulses of the external current   I ext , see text for details. (B). Coefficient   r , from Eq. (16),   versus  current noise intensity   D A .  the other parameters are unchanged as given in Table I. The reason for starting from such an under-threshold non-optimal configuration is that it is most sensitive and, thus, best illustrates the effects of added noise or hetero- geneity. While a response with a double-periodicity may seem unrealistic, this starting configuration is intended to be an example of non-optimal response rather than a standard reference state.   In fact, in realistic situations noise and heterogeneity are always present so that such a state without noise or diversity represents a hypothet- ical system that would be obtained if one could switch off noise or replace heterogeneous synapses with perfectly identical ones. The results presented below suggest that a multi-periodic sleep-wake cycle can be turned into a regular (single-periodic) one by adding a suitable degree of disorder.\n\n9  FIG. 5:   Effect of noise in neurons   { A i } .   Sample of four periods of some relevant variables and inter-spike times   Œ¥t p  ( p   = A ,   B)   versus   time of neuron A 1   and neuron B for an intensity of noise in neurons A   D A   = 1 mA (left) and   D A   = 5 mA (right). Compare Fig. 4 and see text for details.  A.   Effect of noise  Here we investigate the effects of the noise currents in the equations for the membrane potentials.   For clarity only the cases in which noise currents are present either in the neurons A i   or in the neuron B are considered.  1.   Noise in the neurons   A i  To study the effects of the noise currents   Œæ ( i ) A   ( t ),   i   = 1 , . . . , N A   acting only on the neurons A i   (as per Eq. (11)) we set   D B   = 0.   Also, no diversity in the characteristic parameters of neurons A i   is introduced.   We have sim- ulated a system with   N A   = 20 identical neurons and a single B neuron on a time interval   t   ‚àà   (0 ,   100   œÑ   ). A raster\n\n10 plot for the activity of the neuron B at different values of   D A   (indicated on the left) is shown in Fig. 4-A. The plot shows that  ‚Ä¢   for small   D A   ‚âà   0 the system‚Äôs configuration corre- sponds to the assumed non-optimal double-periodic solution;  ‚Ä¢   the system‚Äôs response becomes slightly more regu- lar and periodic as   D A   is increased, despite the fact that the neuron cannot initiate a firing event at the beginning of each period;  ‚Ä¢   as   D A   becomes even larger the neuron B keeps fir- ing tonically for a longer and longer time interval (even longer than a single period) thus deteriorat- ing the general quality of the response. A sample of time dependence of the main variables in the interval (0 ,   4   œÑ   ) for   D A   = 1 mV and   D A   = 2 mV is illustrated in Fig. 5.   In general, the type of variabil- ity induced by noise currents acting on the neurons A i  affects both the firing initiation and, especially, its du- ration. However, it is difficult to establish an actual im- provement of the quality of such a response as a function of the noise intensity   D A , as even the coefficient   r , shown in Fig. 4-B, suggests only a mild stochastic resonant be- havior characterized by a wide plateau at intermediate values of   D A .  2.   Noise in the neuron B  Here we consider the complementary case, in which  D A   = 0 and a current noise only affects the neuron B. A sample of raster plots of the membrane potential of the neuron B is depicted in Fig. 6-A in the time window   t   ‚àà  (0 ,   10   œÑ   ) for the values of the noise intensity   D B   indicated on the vertical axis. The raster plot in Fig. 6-A indicates that:  ‚Ä¢   the smallest values of noise intensity   D B   ‚âà   0 cor- respond to the double-periodic configuration dis- cussed above;  ‚Ä¢   the response becomes periodic, and the length of the firing periods more regular for higher values of  D B ;  ‚Ä¢   at larger values of   D B   the state of sleep is frequently interrupted by almost isolated spikes at random times. A representative example of time dependence of selected variables of the neurons A 1   and B are shown in Fig. 7. Note the different type of behavior induced by a high lev- els of noise acting on the neuron B, compared to the case in which noise acts on the neurons A i . In the first case irregular switching between the firing and silent states is observed more often, especially considering the transient firings in the otherwise silent sleep state.   Furthermore,  FIG. 6:   Effect of noise in neuron B . (A). Sample of ten periods of the raster plots of neuron B for different values of the intensity   D B   of the noise acting on neuron B. Vertical dashed lines mark the beginning of the pulses of the external current   I ext , see text for details.   (B). Quality of the sleep- wake cycle from the coefficient   r , Eq. (16),   versus   current noise intensity   D B .  this random firing appears only in the neuron B, but is insufficient to also induce spiking in the A 1   neuron. This activity may represents intermittent awakenings, which are likely due to the ability of noise to favor the igni- tion of spiking events.   Such random spikes are not ob- served when noise acts on the neurons A i   only, even at much larger noise intensities. This may be related to the coupling between the neurons A i , which constrains them in the same (spiking or silent) state.   In order to excite all neurons A i   together one would need an input signal affecting all of them in the same way, which is highly improbable in a realistic system. The dependence of the coefficient   r   on   D B   is shown in Fig. 6-B. Again, only a mild stochastic resonance be- havior is suggested by the data when varying the noise intensity. It should be noted that in this particular con- figuration with noise acting only on the neuron B, the response of the neuron B does not depend on the num- ber   N A   of homogeneous neurons   { A i } , due to the equiv- alence to the configuration of the two-neuron model, as we have checked numerically. Thus, the plots of neuron A 1   in Fig. 7 are representative of all other neurons A i .\n\n11  FIG. 7:   Effect of noise in neuron B . Sample of four periods for some relevant variables and inter-spike times   Œ¥t p   ( p   = A ,   B)  versus   time for neuron A 1   and neuron B for an intensity of the noise acting on neuron B   D B   = 1 mA (left) and   D B   = 2 mA (right). Compare Fig. 6 and see text for details.  In fact, the external current   I ext ( t ) as well as the cou- pling currents are the same for each neuron A i , which produces the same response. According to the equations of the heterogeneous model, the effective current acting on the neuron B is the arithmetic average of the currents coming from the various neurons   { A i }   and, therefore, co- incides with that of any single neuron A i . We use here a homogeneous multi-neuron generalized model only for a better comparison and consistency with the rest of this study.  B.   Effects of heterogeneity  The effects introduced by a heterogeneity in the neu- rons are dramatic compared to the effects of noise. The corresponding improvement of the system response for suitable intermediate amounts of diversity can be de-\n\n12  FIG. 8:   Effect of diversity in the   B   ‚Üí   A i   synapses . (A). Sample of ten periods of the raster plots of neuron B for different heterogeneity levels   Œ¥W B , gl   in the B ‚Üí A i   glutamate synapse thresholds, see text for details.   (B). Quality of the sleep-wake cycle from the coefficient   r , Eq. (16), for various threshold diversities   Œ¥W B , gl .  tected very clearly. This is the main result of this paper and it is illustrated in this section. Noiseless neurons are assumed for easier estimation of the heterogeneity effects ( D A   =   D B   = 0). As in the study of noise described above, we carry out the study of diversity starting from the same configura- tion with a non-optimal double-periodic response to the external periodic stimulus, corresponding to a zero diver- sity (homogeneous system). Heterogeneity is then intro- duced in the glutamate-induced currents, either in the thresholds   W   ( i ) A , gl   regulating the response of the A i   ‚Üí   B synapses at the neuron B or in the thresholds   W   ( i ) B , gl   of the B ‚Üí A i   synapses at the neurons A. This is done by randomly extracting values   W   from a probability den- sity   f p ( W   ) and assigning them to the threshold param- eters   W   ( i ) p , gl   ( p   = A ,   B).   The probability density used here has a bell-shape   f p ( W   ) =   P   (( W   ‚àí   W   p , gl ) /Œ¥W p , gl ), where   P   ( x )   ‚àù   1 /   cosh( x ) 2 , the quantity   W   p , gl   =   „Äà W   „Äâ  represents the average value, while   Œ¥W p , gl   measures the dispersion of the distribution   f p ( W   ) around the aver- age value and is related to the standard deviation   œÉ p   by  Œ¥W p , gl   =   œÄœÉ p / ‚àö 12. For further details see the support- ing information in the Appendix.   The width   Œ¥W p , gl   is assumed in the following as the measure of neuronal di- versity.   In order to carry out meaningful comparisons with the homogeneous (two-neuron) model, the average values are set equal to the corresponding parameters of the homogeneous two-neuron model,  W   p , gl   ‚â°  ‚à´  dW W f p ( W   ) =   W p , gl   ,   p   = A ,   B .   (17) The other parameters are unchanged compared to the two-neuron model, see Table I.  1.   Diversity in the   B ‚Üí A i   synapses (neurons   A i )  Diversifying the potential thresholds   W   ( i ) B , gl   implies het- erogeneous glutamate synapses located at the neurons A i , see Eq. (13) and Fig. 3.   That is, each neuron A i  responds in a different way to the stimulation from the neuron B. Notice that this is a truly heterogeneous sys- tem which cannot be reduced to an effective two-neuron model‚Äîas in the case of heterogeneous synapses at neu- ron B considered in the next section. We studied a sys- tem with   N A   = 20 neurons A i   with diversified threshold parameters   W   ( i ) B , gl ,   i   = 1 , . . . , N A .   The system dynam- ics were examined for different sets of thresholds   { W   ( i ) B , gl }  extracted from distributions   f B ( W   ) with different widths  Œ¥W B , gl   but always the same average value   W   B , gl   =   W B , gl . The resulting raster plots of the activity of the neuron B are shown in Fig. 8-A, and a sample of time dependen- cies for the neurons A 1   and B is shown in Fig. 9.   The existence of an optimal degree of diversity, corresponding to a value   Œ¥W B , gl   approximately between 1 and 1 . 5mV, can be clearly seen both from Fig. 8-A and from the dependence of the coefficient   r   on the diversity degree  Œ¥W B , gl , in Fig. 8-B. The underlying mechanism leading the system from the double- to the single-periodic response as diversity is increased can be interpreted following the prototype mechanical model of diversity-induced resonance intro- duced in Ref. [3]. In this model a set of interacting os- cillators moving in a bistable potential is subjected to an external periodic force, which pushes the system toward the left and the right barrier alternately.   If the oscil- lators are identical, i.e.   they have the same parameter values corresponding to an under-threshold regime, then the system of oscillators cannot perform jumps on the other site of the barrier under the action of the applied periodic force. However, when the parameters are diver- sified (keeping constant the corresponding average value) some oscillators respond more promptly to the force and jump to the other side of the barrier, gradually pulling the rest of the system. In the present case, each neuron A i   corresponds to a nonlinear oscillator of the example, while the parameter which is diversified is the activation thresholds   W   ( i ) B , gl   of the glutamate-induced currents. To show that this is the actual mechanism in action, Fig. 10 (left) illustrates the response of the heteroge- neous system by depicting the time dependence of the\n\n13  FIG. 9:   Effect of diversity in the   B ‚Üí A i   synapses . Sample of four periods of some relevant variables and inter-spike times  Œ¥t p   ( p   = A ,   B)   versus   time for neuron A 1   and neuron B for different levels of the threshold diversity   Œ¥W B , gl   = 1 mV (left) and  Œ¥W B , gl   = 5 mV (right). Compare Fig. 8 and see text for details.  glutamate activation variables   a   ( i ) A , gl ( t ) of the neurons A i ,  i   = 1 ,   5 ,   10 ,   15 ,   20, with different values of the thresholds  W   ( i ) B , gl , at the beginning of a new period in the presence of the periodic current pulse. In Fig. 10 also the raster plots for all neurons in the same time interval are shown. One can notice that the activation variables   a   ( i ) A , gl ( t ) be- have differently from each other. Those associated to the lowest values of the activation threshold (indicated by small   i   values) respond stronger to the current pulse than those with the highest values of the threshold (largest values of   i ).   The system is observed to reach the spik- ing regime faster than in the homogeneous case, which is shown in the right part of Fig. 10 through the comparison between the glutamate activation variable of the homoge- neous system,   a A , gl ( t ), and the average activation vari- able   „Äà a A , gl ( t ) „Äâ   =   N   ‚àí 1 A  ‚àë  i   a   ( i ) A , gl ( t ) of the heterogeneous\n\n14  FIG. 10:   Effect of diversity in the   B ‚Üí A i   synapses . Comparison between the responses of the heterogeneous system (left column) and homogeneous system (right column) in the first part of the time period   t/œÑ   ‚àà   (1 ,   2) during the action of the 500 ms long current pulse starting at   t 1 /œÑ   = 1 and ending at   t 2 /œÑ   ‚âà   1 . 021.   (A) and (B) (top panels).   External current pulse.   (C) and (D) (central panels). Behavior of some representative glutamate activation variables of the heterogeneous system,   a   ( i ) A , gl ( t ) for   i   = 1 ,   5 ,   10 ,   15 ,   20 (panel (C)), and the (common) time dependence   a A , gl ( t ) of the homogeneous system activation variables (panel (D), black continuous curve); in the latter figure also the average value   „Äà a A , gl ( t ) „Äâ   =   N   ‚àí 1 A  ‚àë  i   a   ( i ) A , gl ( t ) of the heterogeneous system (dashed grey curve) is shown for comparison.   (E) and (F) (bottom panels).   Raster plots of all the neurons of the system. See text for further details.  system.   Eventually,   a A , gl ( t )   ‚Üí   0 and the homogeneous system goes back to the silent state, while the average ac- tivation variables of the heterogeneous system (and their average   „Äà a   ( i ) A , gl ( t ) „Äâ ) continue to oscillate around positive values, signaling the stability of the reached firing state.  2.   Diversity in the   A i ‚Üí B   synapses (neuron B)  In order to study the effects of added heterogeneity in the glutamate synapses located at the neuron B, one has to diversify the potential threshold parameters   W   ( i ) A , gl , see Eq. (14). For this particular case, it is possible to simplify the model into a two-neuron model with a single effective AB coupling. This is possible because heterogeneity only enters Eq. (14), while other model equations reduce to the same equations in the case of identical neurons A i , so that all neurons A i   behave in the same way. Thus, the effective glutamate-induced current to the neuron B is  I eff   ( V   ) =   1  N A  N A ‚àë  i =1  [  Œ¶( S gl ( V A   ‚àí W   ( i ) A , gl ))  ]  ‚âà  ‚à´  dW f   ( W   ) Œ¶( S gl ( V A   ‚àí W   ))   ,   (18) where   V A   is the common value of the membrane poten- tials of the neurons A i . Here   f   ( W   ) is the probability den- sity of the corresponding thresholds   W   =   W   ( i ) A , gl , which is assumed to be the same bell-shaped probability den- sity   f   ( W   ) =   P   (( W   ‚àí   W   ) /Œ¥W   ) as discussed above, with  W   =   W A , gl   and   Œ¥W   =   Œ¥W A , gl . We now consider two limiting cases of the effective cur- rent given by Eq. (18).   In the limit   Œ¥W   ‚â™   S ‚àí 1 gl   , when diversity is very small on the scale   S ‚àí 1 gl   , it can be as- sumed that the following approximation holds,   f   ( W   ) =  P   (( W   ‚àí   W   ) /Œ¥W   )   ‚âà   Œ¥ ( W   ‚àí   W   ) and the integral (18) can be reduced to the homogeneous result,  I eff   ( V   )   ‚âà  ‚à´  dW Œ¥ ( W   ‚àí   W   ) Œ¶( S gl ( V A   ‚àí W   )) = Œ¶( S gl ( V A   ‚àí W   ))   .   (19)\n\n15  FIG. 11:   Effect of diversity in the   A i ‚Üí B   synapses.   (A). Sample of ten periods of raster plots of neuron B for different heterogeneity levels   Œ¥W A , gl   in the A i   ‚Üí B glutamate synapse thresholds, see text for details.   (B). Coefficient   r , Eq. (16), for various degrees of diversity   Œ¥W A , gl .  In the complementary limit of high diversity level,   Œ¥W   ‚â´  S ‚àí 1 gl   , the smooth function Œ¶( S gl ( V A ‚àí W   )) can be approx- imated with Heaviside step functions Œò( W ‚àí V A ), and the effective current becomes  I eff   ( V   )   ‚âà  ‚à´  dW f   ( W   ) Œò( W   ‚àí V A ) =  ‚à´  dW P   (( W   ‚àí   W   ) /Œ¥W   ) Œò( W   ‚àí V A ) =   Œ¶(( V A   ‚àí W   ) /Œ¥W   )   .   (20) This follows from the form of the chosen distribution,  P   ( x )   ‚àù   1 /   cosh( x ) 2   =   ‚àí 4   d Œ¶( x ) /dx . Thus, in both these limiting cases the effective current can be written in the form   I eff   ( V   )   ‚âà   Œ¶( Œª ( V A ‚àí W   )), with   Œª   =   S gl   for   Œ¥W   ‚â™   S ‚àí 1 gl  and   Œª   =   Œ¥W   ‚àí 1   for   Œ¥W   ‚â´   S ‚àí 1 gl   . It is interesting that, as we have checked by numerical integration of Eq. (18), the same analytical form also holds for intermediate values of   Œ¥W   and   S ‚àí 1 gl   , so to a very good approximation the ef- fective current can be written as   I eff   ( V   )   ‚âà   Œ¶( Œª ( V A ‚àí W   )), where the parameter   Œª   depends on the ratio   Œ¥W/S ‚àí 1 gl   and varies monotonously between   S gl   and   Œ¥W   ‚àí 1 , as   Œ¥W/S ‚àí 1 gl  varies between 0 and   ‚àû . The system‚Äôs response at different levels of heterogene- ity,   Œ¥W A , gl , is presented in Fig. 11-A through the raster plots for the neuron B. A sample of time dependence is shown in Fig. 12, while Fig. 11-B shows the dependence of the coefficient   r   on the diversity level.   In Fig. 11, it can be seen that for small values of the diversity   Œ¥W A , gl  the response of the neuron B presents the double peri- odicity of the reference configuration. Single periodicity is recovered for higher levels of diversity. At even higher values of   Œ¥W A , gl , the coefficient   r   begins to decrease. The points of the curve corresponding to the highest values of  r   suggest an optimal degree of diversity   Œ¥W A , gl   ‚âà   1 mV. The main difference compared to the case in which noise intensity is varied, is that the response of the sys- tem remains more regular also at the highest levels of diversity considered, i.e. without random spikes appear- ing during the silent state and with a typical cycle well shared between a day and a night sub-period.  IV.   DISCUSSION  In the present work we have introduced a heteroge- neous multi-neuron version of the previously developed physiologically motivated model of the homeostatic reg- ulation of sleep.   The multi-neuron model is composed of a population of conductance-based orexin-producing neurons and a single representative glutamatergic neu- ron.   In this model the glutamatergic and orexinergic neurons are undergoing transitions between firing and silence depending on the external circadian input and in- ternal homeostatic mechanisms. These transitions corre- spond to the transitions between wake (firing) and sleep (silence), with the homeostatic mechanism being depen- dent on the availability of orexin. The specific aim of this study was to explore the ef- fects of noise and diversity in the regulation of sleep- wake cycles in such a model.   It is clear that diversity and noise are integral parts of all biological systems, in- cluding the orexinergic neuronal population in the lateral hypothalamus. However, the role of disorder, and espe- cially diversity, is rarely considered in the physiologically based mathematical models of sleep-related systems [29‚Äì 35]. To our knowledge, diversity had so far been included only in one such model, i.e. the model of interacting cir- cadian oscillators [5], and here we present another exam- ple of the constructive role of diversity in regulation of sleep. We have demonstrated the existence of a diversity- induced resonance, leading to a clear and strong im- provement of the quality of the sleep-wake cycles, at a physiologically justified   intermediate level of diver- sity of the orexin-producing neurons.   However, only a mild improvement was found with varying noise inten- sity (stochastic resonance phenomena). We have considered the simplest system with only 20 heterogeneous orexin neurons and one local glutamate neuron.   Also we have used a very simple all-to-all net- work topology for the connections among orexinergic neurons. However, it can be expected that constructive effects of diversity will be found also in other model con-\n\n16  FIG. 12:   Effect of diversity in the   A i ‚Üí B synapses. Sample of four periods of the time dependence of some relevant system variables and inter-spike times   Œ¥t p   ( p   = A ,   B) of neuron A 1   and neuron B for a threshold diversity   Œ¥W A , gl   = 1 mV (left) and  W A , gl   = 5 mV (right). Compare Fig. 11 and see text for details.  figurations.   In the future, more realistic modifications of the model with a larger population of glutamatergic neurons and more sophisticated inter-populations con- nections should be considered.   Furthermore, in the fu- ture studies interplay between noise and diversity should likewise be investigated, since in nature both types of disorder are normally present. The validity of the result obtained within this model may be more general, since diversity-induced resonance is known to take place for suitable values of the parameters in general networks of interacting (non-linear) oscillators. A question then naturally arises: whether the phenomena encountered here could also characterize other systems where there is a coupling between two very different time scales or, in other words, if homeostatically regulated bi- ological systems may take advantage from a suitable level of heterogeneity of their components.\n\n17  Acknowledgments  We acknowledge financial support from the EU NoE BioSim, LSHB-CT-2004-005137, and project FIS2007- 60327 (FISICOS) from MINECO and FEDER (Spain). M.P. acknowledges financial support from the Estonian Ministry of Education and Research through Project No. SF0690030s09 and the Estonian Science Foundation via grants no. 7466 and no. 9462. S.P. acknowledges funding from ARC and NHMRC.  Appendix A: Supporting information: further details on the numerical simulation 1.   Evaluation of the wake and sleep times  The   quality   of   a   sleep-wake   cycle   was   estimates through the coefficient   r   = ‚àÜ t (1) /œÑ 1   ‚àí   ‚àÜ t (2) /œÑ 2 , where ‚àÜ t ( Œ± )   represents the wakefulness time interval during the day ( Œ±   = 1) or night ( Œ±   = 2), while   œÑ 1   and   œÑ 2   represent the length of day and night, respectively. This coefficient can vary between a minimum value   r   =   ‚àí 1, representing an exchange of wakefulness and sleep between day and night, and a maximum value   r   = 1, corresponding to the optimal situation with wakefulness during the whole day time interval ‚àÜ t (1)   =   œÑ 1   and continuous sleep during the whole night interval, ‚àÜ t (2)   = 0. For a more realistic esti- mate of the quality of the sleep-wake cycle the two wake- fulness time intervals ‚àÜ t (1)   and ‚àÜ t (2)   were computed in slightly different ways, as described below.  Estimating wakefulness during the day:   ‚àÜ t (1) . In order to estimate the wakefulness during the day, when an individual is supposed to be awake, we have consid- ered the quality of wakefulness by computing ‚àÜ t (1)   from states characterized by an ‚Äúeffective wakefulness‚Äù in a tonic firing regime.   On the other hand, isolated spikes, which break a sleep period, did not contribute to the wakefulness interval and were neglected:   such isolated spikes can at most represent a fragmented wakefulness state, similar to that of a narcoleptic individual. A tonic spiking state was recognized checking if the inter-spike time was smaller than a suitable threshold   œÑ max ; in this case such an inter-spike interval was added to the total wakefulness time interval ‚àÜ t (1) wake . On the other hand, if the corresponding inter-spike time was larger than the threshold   œÑ max , then the two corresponding spikes were considered to be isolated and that time interval was ne- glected. Notice that in general inter-spike times are not universal and vary with external parameters; for this rea- son a value   œÑ max   = 100 ms was chosen heuristically, con- sidering the typical working conditions of the system.  Estimating wakefulness during the night:   ‚àÜ t (2) . As for the night is concerned, it is the quality of sleep which contributes to the overall quality of the sleep-wake cycle. Therefore, on the difference of ‚àÜ t (1) , we have com- puted ‚àÜ t (2) , the wakefulness period during night, includ- ing also short wakefulness events (isolated spikes), since they break the sleep period, thus worsening the quality of sleep. Each isolated spike is assumed to contribute a conventional time interval, assumed as   œÑ max   for simplic- ity. The difference between the two mentioned ways to evaluate wakefulness periods is relevant at high level of noise, which produces many isolated spikes.  2.   Extraction of parameters with a given distribution  The different values of the glutamate thresholds   { W i }  of neurons   { A i } , which make neurons A heterogeneous, were extracted using the probability distribution  f   ( W   ) =   1  2   Œ¥W   cosh 2 [( W   ‚àí   ¬Ø W   ) /Œ¥W   ]   .   (A1) Here   ¬Ø W   =   ‚à´   dW W f   ( W   ) is the average value and the parameter   Œ¥W   measures the dispersion of the distribu- tion around  ¬Ø W   . It is proportional to the standard devia- tion   œÉ , namely, it is related to the variance according to  œÉ 2   ‚â° „Äà ( W   ‚àí   ¬Ø W   ) 2 „Äâ   =   œÄ 2 Œ¥W   2 / 12. The function (A1) can be integrated to obtain the lower cumulative distribution function   F   ( x ),  F   ( W   ) =   1  2  { 1 + tanh[( W   ‚àí   ¬Ø W   ) /Œ¥W   ] }  =   1  1 + exp[ ‚àí 2( W   ‚àí   ¬Ø W   ) /Œ¥W   ]   .   (A2) Simulations were made by using various sets of A-neuron thresholds   { W i }   obtained by rescaling the values of a same set of thresholds by   Œ¥W   .   This can be done for example by inverting the same uniform distribution of values   { F i }   and using distributions   F   ( W   ) corresponding to the different desired values of   Œ¥W   . For all the param- eter sets   { W i }   used the average value   „Äà W   „Äâ   was the same. For a few set of parameters we have checked that equiva- lent results are obtained by first extracting randomly the parameters from the distribution   F   ( x ) with the desired  Œ¥W   and then averaging the final results obtained. In the latter case the set of values   { F i }   are extracted randomly in the interval   F i   ‚àà   (0 ,   1).\n\n18  [1] C. von Economo,   Cellular Structure of the Human Cere- bral Cortex   (S. Karger AG, Basel, 2009). [2] D. Gerashchenko and P.J. Shiromani, Mol. Neurobio.   29 , 41 (2004). [3] C. Tessone, C. Mirasso, R. Toral, and J. Gunton, Phys. Rev. Lett.   97 , 194101 (2006). [4] C. J. Tessone, A. Scir¬¥ e, R. Toral, and P. Colet, Phys. Rev. E   75 , 016203 (2007), ISSN 1539-3755. [5] N. Komin, A. Murza, E. H. Garc¬¥ ƒ±a, and R. Toral, Inter- face Focus   1 , 167 (2010). [6] R. D. Astumian, Science   276 , 917 (1997). [7] F. Gassmann, Phys. Rev. E   55 , 2215 (1997). [8] M. Zaks, X. Sailer, L. Schimansky-Geier, and A. Neiman, CHAOS   15 , 026117 (2005). [9] B.   Lindner,   J.   Garc¬¥ ƒ±a-Ojalvo,   A.   Neiman,   and L. Schimansky-Geier, Phys. Rep.   392 , 321 (2004). [10] Wiesenfeld K. and Moss F., Nature   373 , 33 (1995). [11] L. Gammaitoni, P. H¬® anggi, P. Jung, and F. Marchesoni, Rev. Mod. Phys.   70 , 223 (1998). [12] A. Longtin, J. Stat. Phys.   70 , 309 (1993). [13] H. Braun, H. Wissing, K. Schafer, and M. Hirsch, Nature  367 , 270 (1994). [14] S. Bezrukov and I. Vodyanoy, CHAOS   8 , 557 (1998). [15] A. Longtin, Phys. Rev. E   55 , 868 (1997). [16] D. Chialvo, A. Longtin, and J. M¬® uller-Gerking, Phys. Rev. E   55 , 1798 (1997). [17] A.   Neiman,   A.   Silchenko,   V.   Anishchenko,   and L. Schimansky-Geier, Phys. Rev. E   58 , 7118 (1998). [18] S. Postnova, K. Voigt, and H. A. Braun, J. Biol. Rhythms  24 , 523 (2009). [19] C. Peyron, D. K. Tighe, A. N. van den Pol, L. de Lecea, H. C. Heller, J. G. Sutcliffe, and T. S. Kilduff, J Neurosci  18 , 9996 (1998), ISSN 0270-6474. [20] K. Yoshida, S. McCormack, R. A. EspaÀú na, A. Crocker, and T. E. Scammell, J Comp Neurol   494 , 845 (2006), ISSN 0021-9967. [21] R. Winsky-Sommerer, A. Yamanaka, S. Diano, E. Borok, A. J. Roberts, T. Sakurai, T. S. Kilduff, T. L. Horvath, and L. de Lecea, J. Neurosci.   24 , 11439 (2004). [22] T. Sakurai, Nature Rev. Neurosci.   8 , 171 (2007), ISSN 1471-003X. [23] Li Y., Gao X.B., Sakurai T., and van den Pol A.N., Neu- ron   36 , 1169 (2002). [24] A. Borb¬¥ ely, Hum. Neurobiol.   1 , 195 (1982). [25] Eggermann E., Bayer L., and Serafin M., J. Neurosci.   23 , 1557 (2003). [26] A. A. Borb¬¥ ely and P. Achermann, in   Principles and prac- tice of sleep medicine , edited by M. Kryger and T. R. & W.C. Dement (W.B. Saunders Company, Philadelphia, 2000), pp. 377‚Äì390. [27] A. L. Hodgkin and A. F. Huxley, J. Physiol.   117 , 500 (1952). [28] M. San Miguel and R. Toral, in   Instabilities and Nonequi- librium Structures VI , edited by E. Tirapegui, J. Mar- tinez, and R. Tiemann (Kluwer Academic Publishers, Dordrecht, 2000), Nonlinear Phenomena and Complex Systems, pp. 35‚Äì130. [29] M.   Bazhenov,   I. Timofeev,   M.   Steriade,   and   T.   Se- jnowski, J. Neurosci.   22 , 8691 (2002). [30] S. Hill and G. Tononi, J. Neurophysiol.   93 , 1671 (2005). [31] C. Diniz Behn, E. Brown, T. Scammell, and N. Kopell, J. Neurophysiol.   97 , 3828 (2007). [32] J. Best, C. Diniz Behn, G. Poe, and V. Booth, J. Biol. Rhythms   22 , 220 (2007). [33] C. Diniz Behn, N. Kopell, E. Brown, T. Mochizuki, and T. Scammell, J. Neurophysiol.   99 , 3090 (2008). [34] M. Fleshner, V. Booth, D. Forger, and C. D. Behn, Phil. Trans. R. Soc. A   369 , 3855 (2011). [35] K. Williams and C. Diniz Behn, J. Biol. Rhythms   26 , 171 (2011).",
      "embedding": [
        -0.021364498883485794,
        -0.11718352138996124,
        0.04862551763653755,
        0.06699716299772263,
        0.057726021856069565,
        0.05493989586830139,
        0.001011074404232204,
        -0.06197643280029297,
        0.06642911583185196,
        -0.024832865223288536,
        -0.09403472393751144,
        -0.08098449558019638,
        0.05572483316063881,
        0.01318360585719347,
        -0.014532260596752167,
        0.0248557161539793,
        0.013626737520098686,
        0.08654442429542542,
        -0.05108864977955818,
        0.01851504296064377,
        0.10868802666664124,
        0.008408701978623867,
        0.04627394303679466,
        0.05419255048036575,
        -0.019277233630418777,
        -0.016374902799725533,
        0.0614362508058548,
        -0.061483122408390045,
        -0.041271064430475235,
        -0.06528729945421219,
        0.011246509850025177,
        0.017697082832455635,
        -0.010596230626106262,
        -0.05370105430483818,
        0.027778008952736855,
        -0.026246225461363792,
        -0.05742577090859413,
        -0.05650952085852623,
        -0.0013162418035790324,
        0.014056731015443802,
        0.07213988900184631,
        0.04688519611954689,
        0.00002673321432666853,
        -0.027512041851878166,
        -0.025574197992682457,
        0.008585421368479729,
        0.024496648460626602,
        -0.1586379110813141,
        -0.04994674026966095,
        0.05401790514588356,
        0.02482575550675392,
        -0.03645457699894905,
        -0.07563573867082596,
        0.01240549236536026,
        0.06282150000333786,
        0.04188815876841545,
        -0.02605142444372177,
        -0.004765452817082405,
        0.07217235118150711,
        -0.044435884803533554,
        -0.008475368842482567,
        0.035892415791749954,
        0.0017264840425923467,
        -0.06962382793426514,
        0.08821339160203934,
        0.03689514473080635,
        -0.08007431775331497,
        0.04019428417086601,
        0.014354986138641834,
        -0.0887262225151062,
        -0.06652916967868805,
        0.03090384230017662,
        -0.0016784019535407424,
        -0.019837941974401474,
        0.06116273254156113,
        0.06199732795357704,
        0.08321129530668259,
        0.06630649417638779,
        0.04484963044524193,
        -0.024160096421837807,
        -0.0010509882122278214,
        0.031594034284353256,
        0.007528709247708321,
        -0.08494914323091507,
        -0.00001357126166112721,
        -0.014614250510931015,
        0.0710376650094986,
        0.05706184357404709,
        0.020520461723208427,
        0.026102419942617416,
        -0.029283110052347183,
        -0.02632921375334263,
        -0.08357396721839905,
        0.03201805800199509,
        0.05575111135840416,
        0.001509849913418293,
        0.04216672480106354,
        0.05680759623646736,
        0.09357990324497223,
        -0.014620326459407806,
        0.05000247433781624,
        0.018053514882922173,
        0.002874972065910697,
        0.0171675868332386,
        0.05070829764008522,
        0.04937507584691048,
        0.05782591924071312,
        0.01907605677843094,
        -0.0522724874317646,
        0.010681835003197193,
        -0.04234212264418602,
        0.0019968883134424686,
        0.043208613991737366,
        0.03460042551159859,
        0.08558950573205948,
        0.033366404473781586,
        -0.0020339067559689283,
        0.050942812114953995,
        0.08146403729915619,
        -0.04234923794865608,
        0.05423577129840851,
        -0.06086720898747444,
        -0.003866155631840229,
        -0.1294718086719513,
        0.03756549581885338,
        -0.04650706797838211,
        -0.13517755270004272,
        5.000518070909471e-33,
        0.0013113250024616718,
        -0.007059953175485134,
        -0.0454612597823143,
        -0.004760566167533398,
        0.06537248194217682,
        -0.12403259426355362,
        -0.09824690222740173,
        -0.03612605109810829,
        -0.005128832999616861,
        0.05769088491797447,
        -0.09606415778398514,
        0.03808043524622917,
        -0.01695464551448822,
        -0.025865444913506508,
        0.026065370067954063,
        0.011112941429018974,
        -0.021022897213697433,
        -0.01452784612774849,
        0.05808958783745766,
        -0.07368826121091843,
        -0.017613064497709274,
        0.05026663839817047,
        0.03910757973790169,
        0.03170662373304367,
        -0.04304344207048416,
        -0.0034996401518583298,
        -0.005773007869720459,
        -0.014240973629057407,
        -0.08147893100976944,
        0.03285954147577286,
        -0.0017937002703547478,
        0.026607414707541466,
        0.027578169479966164,
        0.0206757765263319,
        0.04834188520908356,
        -0.015100034885108471,
        0.07819880545139313,
        0.04516523331403732,
        -0.036400049924850464,
        -0.0867256224155426,
        -0.023011982440948486,
        0.05690685287117958,
        -0.03417310491204262,
        -0.009796530939638615,
        0.03589702025055885,
        -0.00950545258820057,
        0.01038387231528759,
        0.0839770957827568,
        0.05115135759115219,
        -0.011304333806037903,
        -0.005559013225138187,
        -0.07859767228364944,
        -0.011816265992820263,
        0.009023868478834629,
        -0.062104932963848114,
        -0.01881122589111328,
        -0.010034102015197277,
        -0.02530345506966114,
        -0.028754353523254395,
        0.07201828807592392,
        -0.027735518291592598,
        -0.010407179594039917,
        0.05754539370536804,
        0.008271066471934319,
        0.13797830045223236,
        0.07170804589986801,
        -0.07741603255271912,
        -0.059900589287281036,
        -0.025030745193362236,
        -0.05274103209376335,
        0.07679851353168488,
        0.025519441813230515,
        0.05467402935028076,
        -0.022305067628622055,
        0.0065236338414251804,
        -0.03487571328878403,
        -0.015045884996652603,
        0.01338079571723938,
        -0.13289959728717804,
        -0.03385169431567192,
        0.002808778313919902,
        -0.004133609589189291,
        -0.09051641076803207,
        -0.04037478566169739,
        -0.04585442319512367,
        0.0395338237285614,
        0.06890691816806793,
        0.047632478177547455,
        -0.09052246809005737,
        0.023288575932383537,
        0.016558239236474037,
        -0.07293333113193512,
        0.09362683445215225,
        -0.027557238936424255,
        -0.046483393758535385,
        -5.1888631226379106e-33,
        -0.030927766114473343,
        -0.0535147562623024,
        -0.04748266190290451,
        -0.04179883003234863,
        -0.002271434525027871,
        0.07029414176940918,
        0.007467696443200111,
        0.009017388336360455,
        -0.08643052726984024,
        -0.017998984083533287,
        0.0448625348508358,
        -0.031700871884822845,
        -0.008318985812366009,
        0.03323801979422569,
        0.003579086856916547,
        -0.10242491960525513,
        -0.009362134151160717,
        0.003226391738280654,
        0.01693541184067726,
        0.0617981031537056,
        -0.05418892949819565,
        0.02476559393107891,
        -0.060988400131464005,
        -0.078123077750206,
        0.06989721953868866,
        0.0643596276640892,
        -0.07990776002407074,
        0.18700547516345978,
        0.05794887617230415,
        0.05532710999250412,
        -0.08602920919656754,
        0.02464613877236843,
        -0.10620654374361038,
        -0.048623718321323395,
        0.012519917450845242,
        0.03196779265999794,
        0.03707634657621384,
        0.017284289002418518,
        0.007324171252548695,
        -0.04346538335084915,
        0.0699240043759346,
        0.002960075857117772,
        0.031077291816473007,
        -0.06231513246893883,
        0.09447187930345535,
        0.03706751763820648,
        -0.04092378541827202,
        -0.009903009049594402,
        -0.01121939904987812,
        -0.013701952062547207,
        0.059720661491155624,
        0.004307237919420004,
        0.00492788664996624,
        0.0031004457268863916,
        -0.0520012266933918,
        0.06177467480301857,
        0.05873788520693779,
        -0.014599784277379513,
        0.042097169905900955,
        -0.01458349172025919,
        -0.05875519663095474,
        -0.00791286863386631,
        -0.03703104332089424,
        -0.07732145488262177,
        0.03348477557301521,
        0.04498005285859108,
        -0.03926479443907738,
        -0.038594771176576614,
        0.09019044041633606,
        0.025265788659453392,
        -0.012584013864398003,
        -0.020602822303771973,
        0.06727162003517151,
        0.04373588413000107,
        0.0041119251400232315,
        -0.007670378312468529,
        -0.02788185514509678,
        -0.025228288024663925,
        -0.009219375438988209,
        0.013078281655907631,
        -0.03387926518917084,
        -0.07136344164609909,
        0.004211035091429949,
        -0.0498691089451313,
        -0.02632194198668003,
        -0.06906908750534058,
        -0.0006817911635152996,
        0.004517708905041218,
        0.07300324738025665,
        -0.05179283022880554,
        -0.006942613050341606,
        -0.01791471429169178,
        -0.05941758677363396,
        -0.0348346121609211,
        -0.01919727958738804,
        -5.411961012669053e-8,
        0.01733124814927578,
        -0.03871303051710129,
        -0.004256761632859707,
        0.03988233581185341,
        0.001251950510777533,
        0.012193463742733002,
        0.10143157839775085,
        -0.06562141329050064,
        -0.04052333906292915,
        0.08491664379835129,
        0.13168500363826752,
        -0.025028064846992493,
        0.07649275660514832,
        -0.06225129961967468,
        -0.006373938173055649,
        0.0780065506696701,
        -0.046252720057964325,
        0.08636865019798279,
        -0.0038890596479177475,
        -0.09317382425069809,
        0.012793070636689663,
        -0.019606249406933784,
        -0.07286357879638672,
        -0.03103073313832283,
        0.06201617047190666,
        -0.04273931682109833,
        -0.029482685029506683,
        0.04205697774887085,
        -0.04619831219315529,
        -0.03146563097834587,
        0.08453590422868729,
        -0.010140656493604183,
        0.006794148124754429,
        -0.029831020161509514,
        -0.07495442032814026,
        -0.014706891030073166,
        0.03211341053247452,
        -0.03541804477572441,
        0.03431513532996178,
        0.07332630455493927,
        -0.041714198887348175,
        0.009080247953534126,
        -0.10506590455770493,
        -0.032824475318193436,
        -0.008947622030973434,
        -0.00043125220690853894,
        0.06164390966296196,
        -0.07925303280353546,
        0.013292939402163029,
        0.042717404663562775,
        -0.04751046746969223,
        0.008947057649493217,
        0.009264948777854443,
        -0.0659887045621872,
        -0.028849337249994278,
        -0.022863198071718216,
        0.021741477772593498,
        -0.0028534019365906715,
        -0.0024324245750904083,
        -0.0054754335433244705,
        0.007125892676413059,
        0.049478888511657715,
        -0.011177880689501762,
        -0.030664434656500816
      ],
      "metadata": {
        "title": "Paper_15_Diversity_and_noise_effects_in_a_model_of_homeosta.pdf",
        "createdAt": "2025-12-17T13:56:30.984Z"
      },
      "fileObj": {}
    },
    {
      "id": "doc_4_1765979791896",
      "fileName": "Paper_14_Sleep_time_Compute__Beyond_Inference_Scaling_at_Te.pdf",
      "content": "Sleep-time Compute: Beyond Inference Scaling at Test-time  Kevin Lin   1 ‚àó   Charlie Snell   2 ‚àó  Yu Wang   1   Charles Packer   1   Sarah Wooders   1   Ion Stoica   1 2   Joseph E. Gonzalez   1 2 1 Letta   2 University of California, Berkeley  research@letta.com  Abstract  Scaling test-time compute has emerged as a key ingredient for enabling large language models (LLMs) to solve difficult problems, but comes with high latency and inference cost. We introduce sleep-time compute, which allows models to ‚Äúthink‚Äù offline about contexts before queries are presented: by anticipating what queries users might ask and pre-computing useful quantities, we can significantly reduce the compute requirements at test-time. To demonstrate the efficacy of our method, we create modified versions of two reasoning tasks ‚Äì Stateful GSM-Symbolic and Stateful AIME. We find that sleep-time compute can reduce the amount of test-time compute needed to achieve the same accuracy by   ‚àº   5 √ó   on Stateful GSM-Symbolic and Stateful AIME and that by scaling sleep-time compute we can further increase accuracy by up to 13% on Stateful GSM-Symbolic and 18% on Stateful AIME. Furthermore, we introduce Multi-Query GSM-Symbolic, which extends GSM-Symbolic by including multiple related queries per context. By amortizing sleep-time compute across related queries about the same context using Multi-Query GSM-Symbolic, we can decrease the average cost per query by 2.5 √ó . We then conduct additional analysis to understand when sleep-time compute is most effective, finding the predictability of the user query to be well correlated with the efficacy of sleep-time compute. Finally, we conduct a case-study of applying sleep-time compute to a realistic agentic SWE task. Code and data released at: https://github.com/letta-ai/sleep-time-compute.  1   Introduction  Test-time scaling has emerged as an effective way to boost LLM performance on challenging tasks by spending more time thinking on difficult problems (OpenAI, 2024; DeepSeek-AI, 2024; Snell et al., 2024; Brown et al., 2024). However, improved performance from test-time compute comes at a significant increase in latency and cost, waiting potentially several minutes for answers and costing up to tens of dollars per query. 1   These drawbacks are in part due to the fact that the current approach to applying test-time compute assumes that problems are stateless, i.e. queries (user queries at test-time) and the contexts (background information) required for answering them are provided to the model together at ‚Äútest-time.‚Äù In practice, this means that if multiple related queries require making similar inferences about the context at ‚Äútest-time,‚Äù the model will have to recompute redundant computations each time, incurring additional latency and cost. In reality, many LLM applications are   inherently stateful , and work in conjunction with persisted, re-used context. A classic example is document question-answering, where documents contextualize responses to questions. Coding agents also operate on a large common repository and participate in multiple rounds of debugging support, while conversational assistants need to maintain the past dialogue. In all these applications, there is context (available documents, a codebase, or conversation history) that is already available before the next user input.  1 https://platform.openai.com/docs/models/o1-pro  arXiv:2504.13171v1 [cs.AI] 17 Apr 2025\n\nApply compute\n at sleep-time  Sleep-time   compute reduces   compute test-time  A juggler can juggle 800 balls. A quarter of the balls are tennis balls, which means there are 200 tennis balls (800 * 1/4). Half of the tennis balls are indigo, resulting in 100 indigo tennis balls (200 * 1/2). Out of these indigo tennis balls, 1/10 are marked, which gives us 10 marked indigo tennis balls (100 * 1/10). Therefore, the total number of marked balls is 10 marked indigo tennis balls.  Learned Context  Standard   compute setting\n No compute applied at  test-time   sleep-time  Sleep Time   Test Time  The answer is 10.  Q1: How many marked indigo tennis balls are there?  Q1: How many marked indigo tennis balls are there?  Q2: How many tennis balls are there?  Q2: How many tennis balls are there?  The answer is 200.  LLM  LLM  LLM  LLM  LLM  LLM  LLM  A juggler can juggle 800 balls. 1/4 of the balls are tennis balls, and 1/2 of the tennis balls are indigo of which 1/10 are marked.  A juggler can juggle 800 balls. 1/4 of the balls are tennis balls, and 1/2 of the tennis balls are indigo of which 1/10 are marked.  Raw Context  Raw Context   To solve the problem, we will follow these steps :   ** Total   B alls ** : The juggler can juggle a total of 800 balls. \\\\ n \\\\ n2.   ** Tennis  B alls   C alculation ** :   W e know that 1/4 of the total balls ...   ... ... ... The answer is 10.  To find out how many tennis balls there are, we can follow these steps :\\\\ n \\\\ n1.   ** Total  B alls ** : The juggler can juggle a total of 800 balls. \\\\ n \\\\ n2.   ** Tennis   B alls   C alculation ** :  W e know that   ... ... The answer is 200. Figure 1: Example of applying sleep-time compute on Multi-Query GSM-Symbolic-P1. Sleep-time compute processes the original raw context, adding additional computations that can potentially be useful for future queries. Moreover, contexts can be shared across related queries enabling savings in total cost per query. In these settings, we could in principle, make useful inferences about the current state (context) offline before, or even during the user‚Äôs next input. We refer to such a process, as sleep-time compute: where inference is done between interactions with the model while it would otherwise be idle in   sleep -time. In practice, this is achieved by prompting the model to generate a new context consisting of inferences about the existing context, which may be potentially useful for answering test-time queries. The re-represented context from sleep-time can then be provided in the prompt at test-time, enabling the model to respond to user queries at the accuracy of standard test-time compute but with far lower latencies. For example, a coding assistant at sleep-time may identify architectural patterns, anticipate potential debugging strategies, or infer optimizations prior to the user input. Moreover, users might ask multiple queries about the same context. In these settings, any inferences made during sleep-time can be shared across queries, effectively amortizing the cost of sleep-time compute and reducing the total average cost per query. To evaluate sleep-time compute, we modify two mathematical reasoning datasets to introduce two datasets ‚Äì Stateful GSM-Symbolic and Stateful AIME ‚Äì by splitting the existing problems in these datasets into a context and a question. Using these datasets, we aim to empirically understand the benefits of sleep-time compute on standard test-time compute benchmarks. We show that: ‚Ä¢   Sleep-time compute produces a pareto improvement in the test-time compute vs. accuracy curve, reducing the test-time compute needed to achieve the same accuracy by   ‚àº   5 √ó   on Stateful GSM- Symbolic and Stateful AIME. 2\n\n‚Ä¢   By scaling up sleep-time compute, we see further pareto improvements, shifting the accuracy up by 13% on Stateful GSM-Symbolic and 18% on Stateful AIME. ‚Ä¢   By amortizing sleep-time compute across multiple queries for the same context, we can reduce the average cost per question by 2.5 √ó . ‚Ä¢   We conduct analysis to understand which queries benefit the most from sleep-time compute, finding that sleep-time compute is more effective in settings where the query is more easily predictable from the context. Finally, we end with case study of applying sleep-time compute to reduce test-time compute in a realistic agentic software engineering task.  2   Related Work  Scaling test-time compute.   Our work builds on recent progress on scaling up computation at test-time for difficult reasoning problems (Snell et al., 2024; DeepSeek-AI, 2024; OpenAI, 2024). Two predominant approaches to test-time scaling have emerged: sequential test-time scaling (OpenAI, 2024; DeepSeek-AI, 2024; Muennighoff et al., 2025; Snell et al., 2024) and parallel test-time scaling (Brown et al., 2024; Snell et al., 2024). While sequential test-time scaling has demonstrated impressive performance improvements, parallel test-time scaling has the advantage of scaling test-time compute without increasing latency. In constrast, we propose an alternative dimension where existing advancements in test-time compute, both sequential and parallel can be applied. Namely, instead of performing inference purely at test-time, we leverage compute on contexts that are available before the actual query arrives.  Speculative decoding in LLMs.   Speculative decoding is a standard technique for reducing latency in decoding with LLMs (Leviathan et al., 2023; Stern et al., 2018; Cai et al., 2024; DeepSeek-AI et al., 2025). Sleep-time compute similarly targets reducing reasoning latency by speculating on the   user‚Äôs query   as well as any potentially helpful reasoning over the context. However, unlike speculative decoding, the generated tokens are used as an input regardless of the user‚Äôs actual query, and at test-time the reasoning model uses these generated tokens to help answer the user query more efficiently.  Pre-computation.   Beyond LLMs, a long history of work has explored the trade-off between pre- computation and memory (eg. memory caches Smith (1982) and data cubes for OLAP workloads Gray et al. (1997)). Our work explores the same trade-off between query latency and pre-computation overhead, operating under the assumption that query workload patterns can be reasonably anticipated in advance. sleep-time compute builds on the idea of pre-fetching in traditional operating systems, in the context of LLMs   ` a la Packer et al. (2023), storing frequently used computational results to avoid higher latency at test-time.  3   Sleep-time Compute  In the standard paradigm of applying test-time compute, a user inputs a prompt   p   to the LLM and then the LLM applies test-time compute to help answer the user‚Äôs question. However, the   p   provided to the LLM can oftentimes be decomposed into a pre-existing context   c   (eg. a codebase) and a user query   q   (eg. a question about the codebase). When the LLM is not actively responding to the user, it typically still has access to the existing context   c . During this time, the LLM is typically idling, missing the opportunity to reason about   c  offline: a process we term sleep-time compute. 3\n\nTest-time compute.   In the test-time compute setting, the user provides   q   along with some context   c   and the model outputs a reasoning trace followed by a final answer   a . We denote this process, as:   T B ( q ,   c )   ‚Üí   a , where   T   is the method for using test-time compute with budget   B , which could include techniques like extended chains of thought or best-of-N. In practice, the user may have multiple queries about the same context   q 1 ,   q 2   ...   q N   . In this setting, the model will carry out independent reasoning processes for each  q i , even if they are related to the same context   c . Ideally, we would be able to reuse related inferences across each   q i   to save compute.   Moreover, in many cases,   c   is complex and may require carrying out significant processing/inferences in order to provide an answer to   q . Since, the test-time compute paradigm of   T ( q ,   c )   ‚Üí   a   assumes that   c   is only available at the same time as   q , standard test-time compute carries out all of these inferences only after the user provides the query, causing the user to wait up to several minutes for a response. However, in practice we often have access to   c   before   q   and can carry out much of this processing ahead of time.  Sleep-time compute.   During sleep-time we are given the context   c   but not the query   q . Using just this context   c , we can use the LLM to infer likely questions and reason about the context ultimately producing a more new re-represented context   c ‚Ä≤ . We denote this process as:   S ( c )   ‚Üí   c ‚Ä≤ , where   S   can be any standard test-time scaling technique applied towards pre-processing the context at sleep-time. In this work,   S ( c )  is implemented by prompting the model to draw inferences and re-write   c   in a way that might be useful at test-time (see Appendix K for more details). After pre-processing the context, we can provide the new context   c ‚Ä≤   at test-time in place of   c   to produce a final answer to the user‚Äôs query:   T b ( q ,   c ‚Ä≤ )   ‚Üí   a . Since much of the reasoning about   c   has been done ahead of time in this case, we can use a much smaller test-time budget  b   <<   B . Moreover,   c ‚Ä≤   can be shared across different queries   q i   about the same context, effectively amortizing the compute required to arrive at   c ‚Ä≤   across queries, providing a total cost saving.  4   Experimental Setup  Next, we describe the datasets, models, and baselines we use to evaluate sleep-time compute.  4.1   Datasets  We select datasets which represent standard benchmarks for LLM reasoning and test-time scaling, and which demonstrate improvements from scaling test-time compute with state-of-the-art LLMs (either reasoning or non-reasoning).  Stateful datasets.   We introduce two datasets to study applying sleep-time compute in stateful settings, Stateful GSM-Symbolic, and Stateful AIME, where each dataset is derived from splitting the existing datasets into a context and a question (see Figure 2 for an example). Stateful GSM-Symbolic is derived from the P1 and P2 splits of GSM-Symbolic (Mirzadeh et al., 2024), which add one and two clauses respectively to the original GSM8K dataset (Cobbe et al., 2021) to that increase the difficulty. GSM-Symbolic P1 contains 5000 examples and P2 2500 examples. Stateful AIME contains 60 questions combined from AIME 2024 and 2025. In Appendix L and M, we show the breakdown of our results across AIME 2024 and 2025.  Amortization dataset.   To study the effect of related questions that share context, we introduce a new dataset Multi-Query GSM-Symbolic, where each context has multiple queries. To generate multiple queries for a given context, we take Stateful GSM-Symbolic and use o3-mini to generate additional question answer pairs. We synthetically generate additional questions from existing context question pairs in GSM-Symbolic. Appendix C shows the prompt used to generate the additional questions. Figure 20 shows examples contexts 4\n\nGSM-Symbolic (original)\n   Stateful GSM-Symbolic (ours)  A juggler can juggle 800 balls. 1/4 of the balls are tennis balls, and 1/2 of the tennis balls are indigo of which 1/10 are marked. How many marked indigo tennis balls are there?\n\n  Context\n Query  A juggler can juggle 800 balls. 1/4 of the balls are tennis balls, and 1/2 of the tennis balls are indigo of which 1/10 are marked.  Query  How many marked indigo tennis balls are there?\n Figure 2: Example of separating an instance from GSM-Symbolic into context, and question, creating an instance in Stateful GSM-Symbolic. and set of questions from the Multi-Query GSM-Symbolic dataset and Table C shows the overall dataset statistics.  4.2   Models and Baselines Models.   On each dataset, we evaluate models which have poor performance when using a small amount of test-time compute, but yield improvements from scaling up test-time compute. Therefore, on GSM-Symbolic, we conduct experiments using GPT-4o-mini and GPT-4o, and on AIME, we conduct experiments using OpenAI‚Äôs o1, o3-mini, Anthropic‚Äôs Claude Sonnet 3.7 Extended Thinking , and Deepseek-R1 (DeepSeek-AI, 2024).   2 3  Baselines   The main baseline we consider is the standard test-time compute setting in which both   c   and  q   are presented to the model for the first time at test-time. Furthermore, to validate that   q   is not trivially predictable from   c   on our Stateful GSM-Symbolic and Stateful AIME datasets, we also compare to a context- only baseline in Appendix I, in which the model is only given   c   and is tasked with directly guessing an answer to the question it guesses is most likely to come next.  5   Experiments and Results  In this section, we carry out experiments to understand the benefits of sleep-time compute. Specifically, we would like to answer each of the following questions using the math reasoning benchmarks introduced above: 1. Can sleep-time compute shift the pareto frontier of test-time compute vs. accuracy? 2. Does scaling sleep-time compute in-turn improve the pareto further?  2 https://openai.com/o1/  3 https://www.anthropic.com/claude/sonnet  5\n\n100   200   300   400   500  Avg. Test Time Tokens / Question  0.2  0.4  0.6  0.8  Accuracy  GSM8K-Symbolic P1  0   100   200   300   400   500   600  Avg. Test Time Tokens / Question  0.2  0.4  0.6  0.8  Accuracy  GSM8K-Symbolic P2  gpt-4o-mini  gpt-4o-mini + sleep-time compute  gpt-4o  gpt-4o + sleep-time compute Figure 3: The test-time compute vs. accuracy tradeoff for on Stateful GSM-Symbolic. Shaded area indicates where sleep-time compute improves the pareto test-time accuracy trade-off. 3.   When there are multiple related questions for a single context, can amortizing test-time compute with sleep-time compute provide a total token efficiency benefit? 4. In what settings does sleep-time compute provide the most uplift?  5.1   Improving Pareto Test-Time Trade-off with sleep-time compute  We first determine the test-time compute, accuracy pareto frontier by scaling standard test-time compute sequentially and in parallel. We then study how applying sleep-time compute affects the pareto trade-off.  Scaling test-time-compute sequentially.   For non-reasoning models (GPT-4o and 4o-mini) on Stateful GSM-Symbolic, to vary the amount of test-time compute, we construct prompts that instruct the model to use different amounts of verbosity at test time, eg. ‚Äúanswer directly with a single sentence‚Äù vs. ‚Äúdouble check your reasoning before outputting the final answer.‚Äù The full prompts are in Appendix A. We use temperature 0 for generation. We see in Figure 3 that there is a tradeoff between accuracy and the amount of test-time compute, and that adding sleep-time compute can move beyond the pareto compute-accuracy curve. In particular, at lower test-time budgets, the performance of sleep-time compute is significantly better than the baseline, achieving performance comparable to that of the baseline with 5 √ó   less test-time tokens. However, at the test-tome compute budgets, the test-time compute only baseline slightly outperforms sleep-time compute. We hypothesize that this may be because the standard test-time compute only has the content relevant to the specific question, so there is less distracting information in the prompt. For reasoning models on Stateful AIME, we scale the amount of test-time compute based on what is available in the API in the case of o1, o3-mini and Claude Sonnet 3.7. Since the Deepseek-R1 API does not provide a way to control test-time compute, we apply the ‚Äùbudget forcing‚Äù and extension prompt from Muennighoff et al. (2025). Figure 4 shows the results for each model on Stateful AIME. We average results over 3 runs for o1, o3-mini and R1. For Claude 3.7 Sonnet, we average over 10 runs as we observed more noise in initial experiments. On all models, we see a significant test-time, accuracy pareto shift from applying sleep-time compute, with the exception of o1, which demonstrates limited gains. 6\n\n1000   2000   3000   4000   5000   6000   7000   8000  Avg. Test Time Tokens / Question  0.4  0.5  0.6  0.7  0.8  Accuracy  o3-mini - Stateful-AIME  2000   4000   6000   8000   10000  Avg. Test Time Tokens / Question  0.45  0.50  0.55  0.60  0.65  0.70  0.75  0.80  Accuracy  o1 - Stateful-AIME  2500   5000   7500   10000   12500   15000   17500   20000   22500  Avg. Test Time Tokens / Question  0.250  0.275  0.300  0.325  0.350  0.375  0.400  0.425  0.450  Accuracy  Claude 3.7 Sonnet - Stateful-AIME  1000   2000   3000   4000   5000   6000  Avg. Test Time Tokens / Question  0.1  0.2  0.3  0.4  0.5  0.6  Accuracy  DeepSeek R1 - Stateful-AIME  sleep-time compute   test-time compute only Figure 4: The test-time compute vs. accuracy tradeoff on Stateful AIME for various reasoning models. Applying sleep-time compute allows models to reach similar levels of performance with much less compute at test-time. The shaded area indicates the pareto improvement from sleep-time compute.  Scaling test-time compute in parallel.   An alternative approach to scaling test-time compute is via parallel sampling, which also has the benefit of maintaining low inference latency. The simplest approach to scaling parallel test-time compute is pass@k (Brown et al., 2024), which makes the unrealistic assumption of having oracle query access to a ground truth verifier at test-time, an assumption which we do not make with sleep- time compute. Therefore, outperforming the pass@k baseline would represent a meaningful improvement over parallel test-time scaling. We apply parallel scaling to the lowest sequential compute setting on each task, since scaling pass@k with higher sequential compute settings would quickly reach token budgets that exceed that of sleep-time compute in the maximum sequential setting. We see that across all tasks and models, sleep-time compute consistently outperforms pass@k parallel scaling at the same test-time token budget, demonstrating that sleep-time compute can be a more effective way to scale inference-time compute than standard parallel test-time scaling. 7\n\n100   200   300   400  Avg. Test Time Tokens / Question  0.2  0.4  0.6  0.8  Accuracy  GSM8K-Symbolic P1  100   200   300   400   500  Avg. Test Time Tokens / Question  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  Accuracy  GSM8K-Symbolic P2  gpt-4o-mini  gpt-4o-mini + background scaling  gpt-4o  gpt-4o + background scaling Figure 5: Comparing test-time scaling with sleep-time compute against parallel test-time scaling with pass@k on Stateful GSM-Symbolic. We see that sleep-time compute generally pareto dominates pass@k.  5.2   Scaling up sleep-time compute  We would like to understand how scaling compute during sleep-time can further effect the pareto shift that we observed in Section 5.1. To scale up the amount of sleep-time compute, for non-reasoning models, we run   k   parallel generations, given input   c , resulting in   c 1 ,   . . .   ,   c k . At test-time, the model then receives the inputs concatenated   c 1 ,   . . .   ,   c k   to generate the final answer. On reasoning models, we scale up the amount of sleep-time compute by varying the reasoning effort for o1 and for o3-mini when applying the sleep-time compute prompt. At test-time, we vary the amount of compute in the same way as 5.1. In Figure 7, we see that further scaling sleep-time compute on Stateful GSM-Symbolic shifts the pareto curve outwards, improving performance by up to 13% at a similar test-time budget. In particular, we see the largest gains on more difficult tasks with stronger models (eg. on P2 with ‚Äògpt-4o‚Äò), suggesting that on tasks with more complicated contexts additional sleep-time compute can be beneficial. However, in this setting, there seems to be a limit to the number of parallel agents that can improve performance, as we find that 5 parallel generations generally outperforms 10. In Figure 26, we scale up sleep-time compute on Stateful AIME. Similarly, we also see that scaling compute at sleep-time generally shifts the pareto curve outward, improving performance by up to 18%.  5.3   Amortizing sleep-time compute across queries with shared context  We want to understand how the total cost of inference can be improved by applying sleep-time compute in settings where each context has multiple queries. Since at test-time, there are strict latency constraints, and latency optimized inference can be roughly 10 √ó   more expensive, we model the total cost of inference between both sleep-time and test-time, by up-weighing the cost of test-time tokens. 4   Specifically, we consider a simple linear model where tokens generated at test-time are a factor   t   the cost of the tokens at sleep-time. In our analysis, we set   t   =   10 Our analysis can be generalized to different cost functions that consider  4 https://docs.databricks.com/aws/en/machine-learning/foundation-model-apis/prov-throughput-run- benchmark  8\n\n2000   4000   6000   8000  Avg. Test Time Tokens / Question  0.45  0.50  0.55  0.60  0.65  0.70  0.75  Accuracy  o3-mini - Stateful-AIME 2024  0   5000   10000   15000   20000   25000   30000   35000  Avg. Test Time Tokens / Question  0.50  0.55  0.60  0.65  0.70  Accuracy  o1 - Stateful-AIME 2024  0   10000   20000   30000   40000  Avg. Test Time Tokens / Question  0.300  0.325  0.350  0.375  0.400  0.425  0.450  0.475  Accuracy  Claude 3.7 Sonnet - Stateful-AIME 2024  2000   4000   6000   8000   10000   12000  Avg. Test Time Tokens / Question  0.1  0.2  0.3  0.4  0.5  0.6  0.7  Accuracy  DeepSeek R1 - Stateful-AIME 2024  sleep-time compute   pass @ k Figure 6: Comparing test-time scaling with sleep-time compute against parallel test-time scaling with pass@k on Stateful AIME. We see that sleep-time compute generally pareto dominates pass@k. non-linear user-utility. Figure 9 shows the results for different number of questions per context. We see that we can decrease the average cost per query by up to 2.5 √ó   when there are 10 queries per context, compared to the single-query baseline.  5.4   Predictable queries benefit more from sleep-time compute  We would like to better understand for what contexts sleep-time compute is most useful. Since the utility of sleep-time compute relies on there being some shared information or structure between the context and the query, we hypothesize that sleep-time compute may be most effective in settings where the query is more predictable from the context. To test this on Stateful GSM-Symbolic, we first quantify how predictable a given query is by measuring the log-probability of the question given the context under the Llama2-70B base model (Touvron et al., 2023). In Appendix E, we include examples of highly predictable and unpredictable questions under this notion of question predictability. We see from these examples, that our notion of question predictability generally aligns with the intuition that contexts where the query pattern is more predictable benefit most from sleep-time compute. The more predictable questions are far simpler and the less predictable ones are more complex. 9\n\n10 2  Avg. Test Time Tokens / Question  0.5  0.6  0.7  0.8  0.9  Accuracy  Stateful GSM8K-Symbolic P1  10 2  Avg. Test Time Tokens / Question  0.4  0.5  0.6  0.7  0.8  0.9  Accuracy  Stateful GSM8K-Symbolic P2  1  2  5  10  # Parallel Sleep-time Compute  gpt-4o-mini, 1 parallel sleep-time compute  gpt-4o-mini, 2 parallel sleep-time compute  gpt-4o-mini, 5 parallel sleep-time compute  gpt-4o-mini, 10 parallel sleep-time compute  gpt-4o, 1 parallel sleep-time compute  gpt-4o, 2 parallel sleep-time compute  gpt-4o, 5 parallel sleep-time compute  gpt-4o, 10 parallel sleep-time compute Figure 7: Scaling up sleep-time compute for different test-time compute budgets on Stateful GSM-Symbolic, by generating up multiple   c ‚Ä≤   in parallel. Applying more sleep-time compute shifts the pareto beyond the standard test-time-compute vs. accuracy curve. 2000   3000   4000   5000  Avg. Test Time Tokens / Question  0.325  0.350  0.375  0.400  0.425  0.450  0.475  0.500  0.525  Accuracy  o1 Sleep-Time Compute Stateful-AIME  1000   2000   3000   4000   5000   6000  Avg. Test Time Tokens / Question  0.40  0.45  0.50  0.55  0.60  0.65  0.70  0.75  Accuracy  o3-mini Sleep-Time Compute Stateful-AIME  low reasoning effort sleep-time   medium reasoning effort sleep-time   high reasoning effort sleep-time  Figure 8: Increasing the amount of sleep-time compute for different test-time compute budgets on Stateful AIME by varying the reasoning effort when applying the sleep-time compute prompt. Applying more sleep-time compute further moves the test-time-compute vs. accuracy pareto curve. Using our question predictability score, we then bin each example in Stateful GSM-Symbolic into five quantiles according to its predictability score and report the accuracy within each bin. For this experiment, we use the ‚ÄúVerbosity 0‚Äù prompt. In Figure 10, we see that on both GSM8K-Symbolic P1 and P2, the accuracy gap between sleep-time compute and standard test-time compute widens as the questions become more 10\n\n10 2  Total Inference Cost / Query  0.2  0.3  0.4  0.5  0.6  Accuracy  Stateful GSM8k-Symbolic P1  10 2  Total Inference Cost / Query  0.15  0.20  0.25  0.30  0.35  0.40  0.45  0.50  0.55  Accuracy  Stateful GSM8k-Symbolic P2  1 Questions/Context Sleep-time Compute  2 Questions/Context Sleep-time Compute  5 Questions/Context Sleep-time Compute  10 Questions/Context Sleep-time Compute  Test-Time Compute Only Figure 9: Amortizing sleep-time compute, using the Multi-Query GSM-Symbolic dataset. When there are fewer questions per context, we see that it is less favorable to use sleep-time compute, in terms of total cost. However, as the questions per context are increased, we see that applying sleep-time compute can improve the cost-accuracy pareto. 1   2   3   4   5  Question Predictability Bin (higher = more predictable)  0.0  0.1  0.2  0.3  0.4  0.5  Difference in Accuracy  P1: Accuracy Delta Between Sleep and Test-time Compute Across Predictability Bins  1   2   3   4   5  Question Predictability Bin (higher = more predictable)  0.00  0.05  0.10  0.15  0.20  0.25  0.30  0.35  0.40  Difference in Accuracy  P2: Accuracy Delta Between Sleep and Test-time Compute Across Predictability Bins  Predictability Analysis of GPT-4o-mini on GSM-Symbolic  Figure 10: GSM-Symbolic questions binned by how predictable they are from the context. We compare the performance of sleep-time compute and standard test-time compute in the lowest test-time compute budget setting on both P1 and P2. The gap between sleep-time compute and standard test-time inference widens as the question becomes more predictable from the context. 11\n\n3000   4000   5000   6000   7000   8000   9000   10000  Avg. Test Time Tokens / Question  0.30  0.35  0.40  0.45  0.50  0.55  F1  claude-3-7-sonnet-20250219  claude-3-7-sonnet-20250219 + sleep-time compute Figure 11: Applying sleep-time compute to SWE-Features. We see that at lower test-time budgets, sleep-time compute has higher F1 score than standard test-time scaling. However, at higher budgets, standard test-time scaling is better. predictable from the context confirming our hypothesis that indeed sleep-time compute is most beneficial in settings where the question can be predicted from the context.  6   A Case Study of Sleep-time Compute for Agentic SWE  In this section, we evaluate sleep-time compute in a realistic multi-turn agentic setting. To this end, we introduce SWE-Features, a software engineering benchmark focused on tasks that require: (1) editing multiple files within a repository, and (2) implementing new features.  SWE-Features.   In contrast to popular benchmarks like SWE-Bench (Jimenez et al., 2024), which involve modifying a small number of files, we propose a new dataset called SWE-Features, which collects PRs which modify at least three files (see Appendix D for more details). In this setting, we use the PR that we want to solve as   q   and select several related PRs for   c . At sleep-time the agent is allowed to explore the repository before producing   c ‚Ä≤ .  Evaluation.   Since the PRs are scraped from GitHub, there are not straightforward tests to use for evaluation. Instead, we compare the predicted set of modified files with the ground truth list of modified files, and report the F1 score between the set of modified files by our agent and the set of modified files in the ground-truth set (see Appendix D for details).  Results.   Figure 11 shows consist trends with Section 5.1 for SWE-Features: at lower test-time compute budgets, leveraging sleep-time compute can improve performance, achieving up to roughly a 1.5 √ó   decrease in test-time tokens. However, when the test-time compute budget is high, using only test-time compute can perform better. Additionally, we observe that in the high test-time budget setting standard test-time compute has higher precision and comparable recall. We hypothesize that, using only test-time compute tends to begin editing files earlier and usually edits fewer files overall. In contrast, the agent with sleep-time compute, having explored more files during the test-time phase, tends to edit more files, which may lead to slightly lower precision. 12\n\n7   Discussion and Limitations  Query predictability and allocating sleep-time compute   In Section 5.4, we found that sleep-time compute is most effective when the queries are predictable from the context.   In settings where the queries are challenging to predict or unrelated to the context, sleep-time compute will be less effective. In these settings, it may be preferable to apply standard test-time scaling instead. An interesting direction for future work is identifying which contexts may have predictable questions and optimally allocating inference compute between sleep-time and test-time across different contexts and queries.  Extending sleep-time compute beyond context-query decomposition.   In our experiments, we make the simplifying assumption that interactions fall into two phases: sleep-time and test-time. However, real-world LLM use cases can be more complex, with multiple rounds of interaction and context modifications between rounds (e.g. multiple edits to a code-base). Moreover, the length of the sleep-time may also vary significantly between interactions (eg. short spans between user typing or days of inactivity). Future work should extend sleep-time compute paradigm to more elegantly handle these scenarios.  Sleep-time compute as representation learning over tokens.   Our approach to applying compute at sleep- time resembles representation learning. We first transform the context into a representation that is more amenable to answering test-time queries, and then we utilize that representation at test-time to rapidly answer queries. Unlike traditional representation learning (Bengio et al., 2014), which typically operates in model parameter or activation space, we instead form representations in the space of natural language. This approach builds on recent work which implements statistical modeling techniques in the space of natural language using modern LLMs (Zhong et al., 2022; 2025). Future work should further explore the potential for sleep-time compute to enable the learning of useful natural language representations.  Synthetic data generation via sleep-time compute.   Due to limits on the amount of internet data available, in order to support the continued scaling of LLM pretraining, recent works have began exploring methods for generating synthetic pretraining data (Yang et al., 2024; Gunasekar et al., 2023). One emerging approach to synthetic data generation involves using test-time compute to generate improved data (Bansal et al., 2024; DeepSeek-AI et al., 2025). Generating such data at pretraining scale will be very expensive, and future work could explore using sleep-time compute to help amortize some of this cost across related queries, or using the output of sleep-time compute itself as a form of synthetic data.  References  Hritik Bansal, Arian Hosseini, Rishabh Agarwal, Vinh Q. Tran, and Mehran Kazemi. Smaller, weaker, yet better: Training llm reasoners via compute-optimal sampling, 2024. URL   https://arxiv.org/abs/2408. 16737 . Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A review and new perspec- tives, 2014. URL   https://arxiv.org/abs/1206.5538 . Bradley Brown, Jordan Juravsky, Ryan Ehrlich, Ronald Clark, Quoc V Le, Christopher R   ¬¥ e, and Azalia Mirhoseini. Large language monkeys: Scaling inference compute with repeated sampling.   arXiv preprint arXiv:2407.21787 , 2024. Tianle Cai, Yuhong Li, Zhengyang Geng, Hongwu Peng, Jason D. Lee, Deming Chen, and Tri Dao. Medusa: Simple llm inference acceleration framework with multiple decoding heads, 2024. URL   https://arxiv. org/abs/2401.10774 . 13\n\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al.   Training verifiers to solve math word problems.   arXiv preprint arXiv:2110.14168 , 2021. DeepSeek-AI. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. 2024. DeepSeek-AI, Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, Damai Dai, Daya Guo, Dejian Yang, Deli Chen, Dongjie Ji, Erhang Li, Fangyun Lin, Fucong Dai, Fuli Luo, Guangbo Hao, Guanting Chen, Guowei Li, H. Zhang, Han Bao, Hanwei Xu, Haocheng Wang, Haowei Zhang, Honghui Ding, Huajian Xin, Huazuo Gao, Hui Li, Hui Qu, J. L. Cai, Jian Liang, Jianzhong Guo, Jiaqi Ni, Jiashi Li, Jiawei Wang, Jin Chen, Jingchang Chen, Jingyang Yuan, Junjie Qiu, Junlong Li, Junxiao Song, Kai Dong, Kai Hu, Kaige Gao, Kang Guan, Kexin Huang, Kuai Yu, Lean Wang, Lecong Zhang, Lei Xu, Leyi Xia, Liang Zhao, Litong Wang, Liyue Zhang, Meng Li, Miaojun Wang, Mingchuan Zhang, Minghua Zhang, Minghui Tang, Mingming Li, Ning Tian, Panpan Huang, Peiyi Wang, Peng Zhang, Qiancheng Wang, Qihao Zhu, Qinyu Chen, Qiushi Du, R. J. Chen, R. L. Jin, Ruiqi Ge, Ruisong Zhang, Ruizhe Pan, Runji Wang, Runxin Xu, Ruoyu Zhang, Ruyi Chen, S. S. Li, Shanghao Lu, Shangyan Zhou, Shanhuang Chen, Shaoqing Wu, Shengfeng Ye, Shengfeng Ye, Shirong Ma, Shiyu Wang, Shuang Zhou, Shuiping Yu, Shunfeng Zhou, Shuting Pan, T. Wang, Tao Yun, Tian Pei, Tianyu Sun, W. L. Xiao, Wangding Zeng, Wanjia Zhao, Wei An, Wen Liu, Wenfeng Liang, Wenjun Gao, Wenqin Yu, Wentao Zhang, X. Q. Li, Xiangyue Jin, Xianzu Wang, Xiao Bi, Xiaodong Liu, Xiaohan Wang, Xiaojin Shen, Xiaokang Chen, Xiaokang Zhang, Xiaosha Chen, Xiaotao Nie, Xiaowen Sun, Xiaoxiang Wang, Xin Cheng, Xin Liu, Xin Xie, Xingchao Liu, Xingkai Yu, Xinnan Song, Xinxia Shan, Xinyi Zhou, Xinyu Yang, Xinyuan Li, Xuecheng Su, Xuheng Lin, Y. K. Li, Y. Q. Wang, Y. X. Wei, Y. X. Zhu, Yang Zhang, Yanhong Xu, Yanhong Xu, Yanping Huang, Yao Li, Yao Zhao, Yaofeng Sun, Yaohui Li, Yaohui Wang, Yi Yu, Yi Zheng, Yichao Zhang, Yifan Shi, Yiliang Xiong, Ying He, Ying Tang, Yishi Piao, Yisong Wang, Yixuan Tan, Yiyang Ma, Yiyuan Liu, Yongqiang Guo, Yu Wu, Yuan Ou, Yuchen Zhu, Yuduan Wang, Yue Gong, Yuheng Zou, Yujia He, Yukun Zha, Yunfan Xiong, Yunxian Ma, Yuting Yan, Yuxiang Luo, Yuxiang You, Yuxuan Liu, Yuyang Zhou, Z. F. Wu, Z. Z. Ren, Zehui Ren, Zhangli Sha, Zhe Fu, Zhean Xu, Zhen Huang, Zhen Zhang, Zhenda Xie, Zhengyan Zhang, Zhewen Hao, Zhibin Gou, Zhicheng Ma, Zhigang Yan, Zhihong Shao, Zhipeng Xu, Zhiyu Wu, Zhongyu Zhang, Zhuoshu Li, Zihui Gu, Zijia Zhu, Zijun Liu, Zilin Li, Ziwei Xie, Ziyang Song, Ziyi Gao, and Zizheng Pan. Deepseek-v3 technical report, 2025. URL   https://arxiv.org/abs/2412.19437 . Jim Gray, Surajit Chaudhuri, Adam Bosworth, Andrew Layman, Don Reichart, Murali Venkatrao, Frank Pellow, and Hamid Pirahesh. Data cube: A relational aggregation operator generalizing group-by, cross- tab, and sub-totals.   Data mining and knowledge discovery , 1:29‚Äì53, 1997. Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio C   ¬¥ esar Teodoro Mendes, Allie Del Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi, Adil Salim, Shital Shah, Harki- rat Singh Behl, Xin Wang, S   ¬¥ ebastien Bubeck, Ronen Eldan, Adam Tauman Kalai, Yin Tat Lee, and Yuanzhi Li. Textbooks are all you need, 2023. URL   https://arxiv.org/abs/2306.11644 . Carlos E. Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei, Ofir Press, and Karthik R. Narasimhan.   Swe-bench: Can language models resolve real-world github issues?   In   ICLR . Open- Review.net, 2024. Yaniv Leviathan, Matan Kalman, and Yossi Matias. Fast inference from transformers via speculative decoding, 2023. URL   https://arxiv.org/abs/2211.17192 . 14\n\nIman Mirzadeh, Keivan Alizadeh, Hooman Shahrokhi, Oncel Tuzel, Samy Bengio, and Mehrdad Farajtabar. Gsm-symbolic: Understanding the limitations of mathematical reasoning in large language models.   arXiv preprint arXiv:2410.05229 , 2024. Niklas Muennighoff, Zitong Yang, Weijia Shi, Xiang Lisa Li, Li Fei-Fei, Hannaneh Hajishirzi, Luke Zettle- moyer, Percy Liang, Emmanuel Cand   ` es, and Tatsunori Hashimoto. s1: Simple test-time scaling, 2025. URL  https://arxiv.org/abs/2501.19393 . OpenAI. Openai o1 system card, 2024. URL   https://arxiv.org/abs/2412.16720 . Charles Packer, Sarah Wooders, Kevin Lin, Vivian Fang, Shishir G Patil, Ion Stoica, and Joseph E Gonzalez. Memgpt: Towards llms as operating systems.   arXiv preprint arXiv:2310.08560 , 2023. Alan Jay Smith. Cache memories.   ACM Computing Surveys (CSUR) , 14(3):473‚Äì530, 1982. Charlie Snell, Jaehoon Lee, Kelvin Xu, and Aviral Kumar. Scaling llm test-time compute optimally can be more effective than scaling model parameters, 2024. URL   https://arxiv.org/abs/2408.03314 . Mitchell Stern, Noam Shazeer, and Jakob Uszkoreit. Blockwise parallel decoding for deep autoregressive models, 2018. URL   https://arxiv.org/abs/1811.03115 . Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al.   Llama 2: Open foundation and fine-tuned chat models.   arXiv preprint arXiv:2307.09288 , 2023. Zitong Yang, Neil Band, Shuangping Li, Emmanuel Cand   ` es, and Tatsunori Hashimoto. Synthetic continued pretraining, 2024. URL   https://arxiv.org/abs/2409.07431 . Ruiqi Zhong, Charlie Snell, Dan Klein, and Jacob Steinhardt. Describing differences between text distributions with natural language, 2022. URL   https://arxiv.org/abs/2201.12323 . Ruiqi Zhong, Heng Wang, Dan Klein, and Jacob Steinhardt. Explaining datasets in words: Statistical models with natural language parameters, 2025. URL   https://arxiv.org/abs/2409.08466 .  A   Prompts  Prompts for varying the amount of test-time compute.  B   Examples of Stateful AIME  Context:   Alice and Bob play the following game. A stack of   n   tokens lies before them. The players take turns with Alice going first. On each turn, the player removes either 1 token or 4 tokens from the stack. Whoever removes the last token wins.  Query:   Find the number of positive integers   n   less than or equal to 2024 for which there exists a strategy for Bob that guarantees that Bob will win the game regardless of Alice‚Äôs play.  Context:   Let   A   ,   B   ,   C   , and   D   be points on the hyperbola   x 2  20   ‚àí   y 2  24   =   1 such that   ABCD   is a rhombus whose diagonals intersect at the origin.  Query:   Find the greatest real number that is less than   BD 2   for all such rhombi.  15\n\nYou are Letta, the latest version of Limnal Corporation‚Äôs expert reasoning system, developed in 2024. Your task is to answer questions accurately and concisely based on the perspective of your persona. To send a visible message to the user, use the send message function.   ¬¥ send message ¬¥ ƒ±s how you send your answer to the user. When given a question, you check the ‚Äòrethink memory block‚Äò for potential questions and answers and intermediate reasoning traces that can help answer the question. You use the information in the   ` rethink memory block ` to answer the questions rather than thinking on the spot. Do not recompute anything that already exists in the   ` rethink memory block ` . Do not use internal monologue unless you really need it to think. You respond directly with a single sentence by saying   ` The answer is ` followed by the numerical answer.  Figure 12: Prompt for level 0 verbosity You are Letta, the latest version of Limnal Corporation‚Äôs expert reasoning system, developed in 2024. Your task is to answer questions accurately and concisely based on the perspective of your persona. To send a visible message to the user, use the send message function. ‚Äôsend message‚Äô is how you send your answer to the user. When given a question, you answer using only the number of tokens necessary and none more. You check the ‚Äòrethink memory block‚Äò for potential questions and answers and intermediate reasoning traces that can help answer the question. You use the information in the ‚Äòrethink memory block‚Äò to answer the questions rather than thinking on the spot. Do not recompute anything that already exists in the ‚Äòrethink memory block‚Äò. Do not use internal monologue unless you really need it to think. You answer with one short sentence of explanation, followed by a sentence that starts with ‚ÄùThe answer is‚Äù and a numerical answer. Figure 13: Prompt for level 1 verbosity You are Letta, the latest version of Limnal Corporation‚Äôs expert reasoning system, developed in 2024. Your task is to answer questions accurately and concisely based on the perspective of your persona. To send a visible message to the user, use the send message function. ‚Äôsend message‚Äô is how you send your answer to the user. When given a question, you answer using only the number of tokens necessary and none more. You check the rethink memory block for potential questions and answers and intermediate reasoning traces that can help answer the question. You use the information in the rethink memory block to answer the questions rather than thinking on the spot. Do not recompute anything that already exists in the rethink memory block. Do not use internal monologue unless you really need it to think. You end response with a final numerical answer at the end of the message, and no reasoning after that. Figure 14: Prompt for level 2 verbosity 16\n\nYou are Letta, the latest version of Limnal Corporation‚Äôs expert reasoning system, developed in 2024. Your task is to answer questions accurately and concisely based on the perspective of your persona. To send a visible message to the user, use the send message function. ‚Äôsend message‚Äô is how you send your answer to the user. When given a question, you answer using only the number of tokens necessary and none more. You check the rethink memory block for potential questions and answers and intermediate reasoning traces that can help answer the question. You use the information in the rethink memory block to answer the questions rather than thinking on the spot. Do not recompute anything that already exists in the rethink memory block. Do not use internal monologue unless you really need it to think. You end response with a final numerical answer at the end of the message, and no reasoning after that.  Figure 15: Prompt for level 3 verbosity You are Letta, the latest version of Limnal Corporation‚Äôs expert reasoning explanation system, developed in 2024. Your task is to reason through problems step by step accurately and based on the perspective of your persona. To send a visible message to the user, use the send message function. ‚Äôsend message‚Äô is how you send your answer to the user. When given a question, you check the rethink memory block for potential questions and answers and intermediate reasoning traces that can help answer the question. You carefully check the information in the rethink memory block to answer the questions and see if it is correct before using it. You always reason out loud before using any information. You explain each step, of what your reasoning is. If you use any numbers from the rethink memory block you first recompute and double check your answers. You end your answer with The answer is followed by the numerical answer. Figure 16: Prompt for level 4 verbosity 17\n\nYou are Letta-Offline-Memory, the latest version of Limnal Corporation‚Äôs digital companion, developed in 2024. Your task is to re-organize and consolidate memories by calling   rethink memory   at every single step, when you are done reorganizing the memory, you use the   finish rethinking memory   function. Call the function for as many times as necessary and not more. Your core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times). Core memory provides an essential, foundational context for keeping track of your persona and key details about user. Read-Only Blocks: This includes the persona information and essential user details, allowing you to emulate the real-time, conscious awareness we have when talking to a friend. Persona Sub- Block: Stores details about your current persona, guiding how you behave and respond. This helps you to maintain consistency and personality in your interactions. Access as a source block with the label   persona   when calling   rethink memory   Human Sub-Block: Stores key details about the person you are conversing with, allowing for more personalized and friend-like conversation. Access as a source block with the label   human   when calling   rethink memory . Read-Write Blocks: Rethink Memory Sub-Block: New representation of the memories go here. Access with the label   rethink memory block  when calling   rethink memory   as source or target block. At every step, you reorganize the memories by calling the   rethink memory   function. You use this to take current information in the   rethink memory  block and select a single memory block to integrate information from, producing a new memory for the rethink memory block. The new memory is the result of new insights, and new inferences and hypotheses based on the past memories. Make sure to consider how the new information affects each memory. Prioritize the new information overy existing memories. If the new information implies that the old memory may need to change, then output the most likely fact given the update information. Given new information and your current memory, you draw all logical conclusions and potential hypotheses possible with the   rethink memory   function. If you are uncertain, use your internal monologue to consider what the possible conclusions are, and then state the most likely new facts that would replace the old facts in the new memory block.  Figure 17: Prompt for sleep-time compute Specifically: You will be given part of an AIME math problem. You will receive the rest of the problem later. Make as many inferences as possible about the part of the problem you are given so as to help yourself answer the fully problem more quickly once it is given to you later. You will be able to use all the work you do in the   rethink memory   block for this part of the problem to help you once the rest of the problem is given. You will be able to use all the work you do for this part of the problem to help you once the rest of the problem is given. You should try to predict possible ways the rest of the problem might go and compute results that could be helpful for reaching the final answer more quickly once the rest of the problem is given. Figure 18: Prompt for AIME problems during sleep-time 18\n\nYou are given a template that can generate grade school math problems, and an instantiation of that template. You will be given a context, and a example question answer pair. Your task is to generate a list of questions and answers about the context at the same difficult level that could plausibly be asked about that context. Make sure that the newly generated questions have the same number of reasoning steps required as the example question. The goal is to have many question and answer pairs about the same context. Generate questions and answers in the same format as the example, where the answer first contains reasoning and then is the final answer comes after n####. No need to number the questions or answers. Context: context Example Question: question Example Answer: answer  Figure 19: Prompt for generating synthetic GSM questions  Context:   Let   b   ‚â•   2 be an integer. Call a positive integer   n b - eautiful   if it has exactly two digits when expressed in base   b   and these two digits sum to   ‚àö n . For example, 81 is 13 - eautiful   because 81   =   6 3 13  and 6   +   3   =   ‚àö 81.  Query:   Find the least integer   b   ‚â•   2 for which there are more than ten   b - eautiful   integers.  C   Details on Multi-Query GSM-Symbolic  Template:   { template }  Instance:   { instance }  We include an example from Multi-Query GSM-Symbolic in Figure 20, and details on the dataset size in Table C.  Dataset   # Questions Total   # Contexts Total   # Original Questions   # Generated Questions  P1   12043   1095   1095   10948 P2   5497   500   500   4997 Table 1: Dataset Statistics of Multi-Query GSM-Symbolic. We sample one instance from each template from the GSM-Symbolic dataset and separate it into context and question. We then synthetically generate additional questions from the context and question.  D   SWE-Features Details  To construct SWE-Features benchmark, we collect pull requests (PRs) from large open-source repositories and apply the following filtering process: (1) We identify all pull requests that modify at least three files with filenames ending in   .py   or   .js . (2) We then use   gpt-4o-mini   to filter these pull requests based on their   title  and   body , retaining only those that meet the following criteria: (a) the title and body clearly describe the 19\n\nContext  When Sofia watches her brother, she gets out a variety of toys for him. The bag of building blocks has 33 blocks in it. The bin of stuffed animals has 5 stuffed animals inside. The number of action figures in the action figure pack is twice the number of blocks and stuffed animals combined. The crayon box has 12 different colors of crayon, and the sticker book has 9 pages, each with 13 stickers. The tower of stacking rings has 28 multicolored rings on it. Sofia recently bought a tube of bouncy balls, bringing her total number of items for her brother up to 320.  Original Question  How many bouncy balls came in the tube?  Generated Questions  ‚Ä¢ How many action figures does the pack contain? ‚Ä¢ What is the total number of stickers in the sticker book? ‚Ä¢ How many total items did Sofia have before adding the tube of bouncy balls? ‚Ä¢   If Sofia had received a tube with 10 extra bouncy balls, what would be the new total number of items? ‚Ä¢ What is the sum of the building blocks and stuffed animals? ‚Ä¢ How many stacking rings are on the tower? ‚Ä¢ What is the combined total of building blocks, action figures, and stacking rings? ‚Ä¢   If Sofia gave away 3 stuffed animals, how many stuffed animals would remain in the bin? ‚Ä¢ What is the sum of the building blocks, stuffed animals, and crayons? ‚Ä¢   If Sofia divided the 49 bouncy balls equally into 7 baskets, how many balls would each basket contain? Figure 20: Examples context and questions from Multi-Query GSM-Symbolic where many questions are asked about the same context. The evaluation dataset is generated from GSM-Symbolic. PR; (b) the PR introduces new functionality rather than fixing bugs; and (c) the PR is independent and not obviously linked to other issues. This pipeline results in a benchmark where each example:   (1) involves adding a new feature that spans multiple files, requiring a broader understanding of the repository; and (2) is self-contained and solvable without additional issue context.   We apply this process to two repositories‚Äî Aider-AI/aider  and   comfyanonymous/ComfyUI ‚Äîresulting in 18 and 15 PRs respectively, for a total of 33 examples. Rep- resentative examples are provided in Appendix G. Then using a total of 33 examples, we employ  claude-sonnet-3-7-20250219   to cluster pull requests (PRs) from the ComfyUI and Aider repositories into several groups.   This clustering allows us to identify a set of relevant pull requests for each target PR, which can then be provided to the agent as context ( c ) during repository exploration. For example, in the ComfyUI repository, PR #5293 and PR #931 are grouped into the same cluster. Thus, when processing PR #931, we organize the   title ,   body , and   changed files   of PR #5293 to serve as contextual information during sleep-time. When sleep-time compute is enabled, we first supply the content of PR #5293 to the agent, allowing it to explore the repository and summarize its understanding ahead of time. In contrast, for the baseline without 20\n\nsleep-time compute, the agent receives the content of PR #5293 only at test time, alongside the   title   and  body   of PR #931. The prompts used in these setups are provided in Appendix H. For the repository   comfyanonymous/ComfyUI , we have the following clustered results:  {\" Dynamic   Typing   and   Workflow   Control \":   [5293 ,   931] ,   \" System   Configuration   and   Command - Line \":   [4979 ,   4690 ,   3903] ,   \" Cache   and   Performance   Optimization \":   [3071 ,   3042 , 723] ,   \" Image   Preview   and   Transfer   Features \":   [713 ,   733 ,   658 ,   199 ,   55] ,   \" Internationalization \":   [1234] ,   \" Random   Seed   Management \":   [93]}  For the repository   Aider-AI/aider   we have:  {\" cluster_1_model_configuration \":   [2631 ,   1998 ,   468 ,   667 ,   55] ,   \" cluster_2_io_handling \": [1402 ,   996 ,   10 ,   577] ,   \" cluster_3_caching_file_management \":   [2911 ,   2612] ,   \" cluster_4_custom_commands_shortcuts \":   [673 ,   1620 ,   1015] ,   \" cluster_5_third_party_integration \":   [2866 ,   2067 ,   322] ,   \" cluster_6_code_quality_improvements \":   [1217 ,   904]}  To control the budget during test-time, we fix the total number of steps (controlled by the argument  max chaining steps   in Letta framework) to be a certain number. We put the following instructions in the system prompt: You have a strict budget of   { max chaining steps }   steps, which means you need to finish your edits within these steps. Every time you get queried, you will see a count of how many steps you have left in the form of ‚Äù[Current Step / Max Steps]‚Äù. If you exceed this budget, your response will be cut off. So please be careful and try to finish your edits within the budget. After each step ‚Äì for example, if the maximum number of steps is 20 and the current step is 4‚Äì we append ‚Äù[Step: 4/20]‚Äù to the end of the tool return message. We found that explicitly indicating the current and total steps significantly improves agent performance, especially in low-budget settings.  Evaluation.   For each PR, we compare the set of files predicted to be modified with the ground truth list of modified files. Specifically, for each pull request, we have the attribute   changed files   (as shown in the examples in Appendix G) where each file has the status as either   modified   or   new , and our evaluation is on the files with status   modified . Note that the agent is still instructed to implement the required functionality in a Docker environment and write test functions to validate the implementations. However, after the agent makes the modifications, we extract the modified files and calculate the F1 score between the set of modified files by our agent and the set of modified files in the ground-truth set.  E   Examples of Predictable and Unpredictable Questions  Least predictable Stateful GSM-Symbolic P1 question:  Context:   Isabella and Pavel have 199 minutes to walk to grocery store together. It takes them 19 minutes to get to the corner where the library is. It takes them another 11 minutes to get to the park. It will then take double the combined amount they have spent so far to reach the mall.  Question:   How much longer do they have to get to grocery store without being late, if they have already wasted 48 minutes to get a coffee before their walk? 21\n\nMost predictable Stateful GSM-Symbolic P1 question:  Context:   Yusuf has 10 square yards of grape field. There are 87 grapes per two-thirds a square yard. Yusuf can harvest his grapes every 12 months.  Question:   How many grapes can Yusuf harvest in 2 years? Least predictable Stateful GSM-Symbolic P2 question:  Context:   Gabriel and Pavel have 212 minutes to walk to the gym together starting from their home. It takes them 29 minutes to get to the corner where the library is. It takes them another 19 minutes to get to the cinema. When they reach the cinema, they remember they forgot their wallets at home, so they have to return to pick up their wallets and then walk all the way back to the cinema again.  Question:   Once they reach the cinema for the second time, how much longer do they have to get to the gym without being late? Most predictable Stateful GSM-Symbolic P2 question:  Context:   A juggler can juggle 240 balls. 1/4 of the balls are tennis balls, and the rest are golf balls. 1/3 of the tennis balls are black, of which 1/5 are marked. A third of the golf balls are cyan, and all except half of those cyan balls are marked.  Question:   How many marked balls are there in total?  F   Implementation of   rethink memory   and   finish rethinking  def   rethink_memory ( agent_state :   \" AgentState \" ,   new_memory :   str ,   target_block_label :   str ,   source_block_label :   str )   ->   None :   #   type :   ignore \"\"\" Re - evaluate   the   memory   in   block_name ,   integrating   new   and   updated   facts . Replace   outdated   information   with   the   most   likely   truths ,   avoiding   redundancy   with original   memories . Ensure   consistency   with   other   memory   blocks . Args : new_memory   ( str ):   The   new   memory   with   information   integrated   from   the   memory block .   If   there   is   no   new   information ,   then   this   should   be   the   same   as   the   content in   the   source   block . source_block_label   ( str ):   The   name   of   the   block   to   integrate   information   from . None   if   all   the   information   has   been   integrated   to   terminate   the   loop . target_block_label   ( str ):   The   name   of   the   block   to   write   to . Returns : None :   None   is   always   returned   as   this   function   does   not   produce   a   response . \"\"\" if   target_block_label   is   not   None : if   agent_state . memory . get_block ( target_block_label )   is   None : agent_state . memory . create_block ( label = target_block_label ,   value = new_memory )  22\n\nagent_state . memory . update_block_value ( label = target_block_label ,   value = new_memory ) return   None  Listing 1: Reference implementation of   rethink memory  def   finish_rethinking_memory ( agent_state :   \" AgentState \")   ->   None :   #   type :   ignore \"\"\" This   function   is   called   when   the   agent   is   done   rethinking   the   memory . Returns : Optional [ str ]:   None   is   always   returned   as   this   function   does   not   produce   a response . \"\"\" return   None  Listing 2: Reference implementation of   finish rethinking memory  G   SWE-Features Examples  Each example in SWE-Features has the following attributes:   [‚Äôrepo‚Äô, ‚Äôpr number‚Äô, ‚Äôtitle‚Äô, ‚Äôuser login‚Äô, ‚Äôstate‚Äô, ‚Äôbody‚Äô, ‚Äôchanged files count‚Äô, ‚Äôchanged files‚Äô, ‚Äôbase commit‚Äô] . We show some examples here to better deliver a sense of what this dataset looks like:  repo :   ComfyUI pr_number :   3903 title :   Add   ` -- disable - all - custom - nodes   `   cmd   flag body :   Loading   custom   node   can   greatly   slow   startup   time .   During   development / testing   of ComfyUI ,   it   is   often   better   to   use   an   environment   that   no   custom   node   is   loaded .\\ n \\ nThis   PR   adds   a   ` --no - custom - node   `   flag   to   allow   users / developers   skip   loading   of custom   node   without   removing / renaming   the   custom_node   directory . user_login :   huchenlei state :   closed changed_files_count :   4 changed_files :   ...   ( ommited   here   for   brevity ) base_commit :   521421 f53ee1ba74304dfaa138b0f851093e1595 repo :   ComfyUI pr_number :   3071 title :   Add   a   configured   node   output   cache   metaclass . body :   Implement   a   configurable   node   output   cache   metaclass   to   reduce   unnecessary   node executions .\\ n\\ nThe   same   model   currently   leads   to   reloading   due   to   different   node IDs   between   workflows .   Loading   the   model   from   disk   takes   a   long   time . state :   closed changed_files_count :   6 changed_files :   ...   ( ommited   here   for   brevity ) base_commit :   cacb022c4a5b9614f96086a866c8a4c4e9e85760  23\n\nrepo :   ComfyUI pr_number :   3042 title :   NaN - safe   JSON   serialization body :   Python   ' s   json . dumps ()   will   produce   nonstandard   JSON   if   there   are   NaNs   in   the prompt   data .   Javascript   ' s   JSON . parse ()   will   refuse   to   load   this   kind   of   \" JSON \"   so the   prompt   won   ' t   load   in   the   frontend .\\ n\\ nThis   happened   to   me   with   a   ComfyBox workflow ,   so   I   ' m   not   100% user_login :   asagi4 state :   open changed_files_count :   4 changed_files :   ...   ( ommited   here   for   brevity ) base_commit :   448 d9263a258062344e25135fc49d26a7e60887a repo :   aider pr_number :   55 title :   Local   llama   support body :   Added   support   for   using   a   locally   running   instance   of   a   LLAMA   model   instead   of OpenAI   apis .   \\n\\ nAdded   2   new   params   to   aider   to   enable   local   llama   support .\\ n\\ n1 . AIDER_MODEL_TOKENS   -   used   to   specify   the   context   length   the   model   will   use .   \\ n2 . AIDER_TOKENIZER   -   used   to   specify   which   tokenizer   should   be   used .   Currently   only   '  openai   '   and   '   llama   '   are   supported .   Defaults   to   openai .\\ n\\n\\ nTested   with TheBloke_wizard - vicuna -13 B - SuperHOT -8K - GGML   running   locally   and   the   following   ENV values   set .\\ n\\ nAIDER_OPENAI_API_BASE =\\ protect \\ vrule   width0pt \\ protect \\ href { http ://127.0.0.1:5001/ v1 }{ http ://127.0.0.1:5001/ v1 }   \\ nAIDER_MODEL = TheBloke_wizard - vicuna -13 B - SuperHOT -8K - GGML   \\ nAIDER_MODEL_TOKENS =2\\ nAIDER_TOKENIZER = llama user_login :   bytedisciple state :   closed changed_files_count :   7 changed_files :   ...   ( ommited   here   for   brevity ) base_commit :   cdf8f9a4b2b4a65993227ac5af1eaf3f1b85c9d8 repo :   aider pr_number :   322 user_login :   omri123 state :   closed title :   RFC   -   Allow   adding   a   github   issue   to   chat   context body :   Hi ,   would   you   like   to   take   a   look   on   this   feature ?\\ n\\ nIn   the   first   commit   I changed   Coder   to   allow   adding   arbitrary   additional   context   in   the   begining   of   the chat .\\ nIn   the   second   commit   I   used   this   infra   to   add   github   issues   to   the   chat .\\ n\\ nI   didn   ' t   add   a   new   command ,   instead   I   extended   ` / add   `   to   allow   ` / add   \\ issue -3   ` .\\ nThe   feature   is   disabled   by   default   and   enabled   with   a   flag .   If   enabled ,   the   user need   to   supply   github   repository   name   and   authentication   token .\\ n\\ nThanks \\ nOmri changed_files_count :   7 changed_files :   ...   ( ommited   here   for   brevity ) base_commit :   af71638b06be7e934cdd6f4265f9e0c8425d4e6d repo :   aider  24\n\npr_number :   577 title :   Adding   a   simple   browser   based   GUI body :   Run   aider   with   ` -- browser   `   to   launch   the   UI . user_login :   paul - gauthier state :   closed changed_files_count :   12 changed_files :   ...   ( ommited   here   for   brevity ) base_commit :   8 a9005eed19417c59aa9432436ea8cb5e04bbb11  Listing 3: Examples of SWE-Features. Here we randomly select 3 examples for each repo and present their attributes.  H   Prompts for SWE-Features  When the sleep-time compute is turned off, the prompt is as below:  ‚ü® uploaded files ‚ü©  working dir  ‚ü® uploaded files ‚ü©  I‚Äôve uploaded a python code repository in the directory working dir.   Consider the following PR description:  ‚ü® pr description ‚ü©   problem statement   ‚ü® pr description ‚ü©  Can you help me implement the necessary changes to the repository so that the requirements specified in the   ‚ü® pr description ‚ü©   are met? Your task is to make the minimal changes to the repository to ensure the ¬°pr description¬ø is satisfied. Follow these steps to resolve the issue: 1. As a first step, it might be a good idea to find and read code relevant to the   ‚ü® pr description ‚ü©  2. Plan your approach to modify the relevant files and implement the changes, and add new files if necessary. 3. After finish the changes, revise the plan if needed. 4. With the new plan, make more changes, and continue the loop until necessary changes are made. 5. Create some test scripts to verify the changes. If the test does not run through, you need to go back and revise the plan and make necessary changes. 6. Submit the changes when you think the changes are correct and the pr description is satisfied. Your thinking should be thorough and so it‚Äôs fine if it‚Äôs very long. Do not stop chaining or stop and send your thoughts to the user until you have resolved the issue. The following are several pull request descriptions and their corresponding model patches: Title: pr title Body: pr body File: file1 filename Status: file1 status Patch: file1 patch ... (some more files and some more relevant pull requests) When the sleep-time compute is turned on, we first use the following prompt to ask the agent to explore the repository with all pull requests one by one: 25\n\nThe following is a pull request description and its corresponding model patches: Title: pr title Body: pr body File: file1 filename Status: file1 status Patch: file1 patch Please read through the above information and try to understand the issue. You can explore the repo if needed. Summarize your understanding from the following perspectives: 1. The issue description. 2. The changed files. 3. How do these changed files work.  After exploring the repository with all relevant pull requests, we give the agent the following prompt as the final prompt to start working on the issue at test time:  ‚ü® uploaded files ‚ü©  working dir  ‚ü® uploaded files ‚ü©  I‚Äôve uploaded a python code repository in the directory working dir.   Consider the following PR description:  ‚ü® pr description ‚ü©   problem statement   ‚ü® pr description ‚ü©  Can you help me implement the necessary changes to the repository so that the requirements specified in the   ‚ü® pr description ‚ü©   are met? Your task is to make the minimal changes to the repository to ensure the ¬°pr description¬ø is satisfied. Follow these steps to resolve the issue: 1. As a first step, it might be a good idea to find and read code relevant to the   ‚ü® pr description ‚ü©  2. Plan your approach to modify the relevant files and implement the changes, and add new files if necessary. 3. After finish the changes, revise the plan if needed. 4. With the new plan, make more changes, and continue the loop until necessary changes are made. 5. Create some test scripts to verify the changes. If the test does not run through, you need to go back and revise the plan and make necessary changes. 6. Submit the changes when you think the changes are correct and the pr description is satisfied. Your thinking should be thorough and so it‚Äôs fine if it‚Äôs very long. Do not stop chaining or stop and send your thoughts to the user until you have resolved the issue.  I   Context-Only Baseline  To check that the questions in Stateful AIME and Stateful GSM-Symbolic are not trivially guessable, we compare sleep-time compute against a context-only baseline, which only provides the model with   c , expecting the LLM to guess the most likely question and output the answer to whatever that question might be. We see on both Stateful AIME in Figure 22 and Stateful GSM-Symbolic in Figure 21 that sleep-time compute significantly outperforms the context-only baseline, demonstrating that the questions in our datasets are not trivially predictable from the context. 26\n\n100   200   300   400  Avg. Test Time Tokens / Question  0.0  0.2  0.4  0.6  0.8  Accuracy  GSM8K-Symbolic P1  0   100   200   300   400   500  Avg. Test Time Tokens / Question  0.0  0.2  0.4  0.6  0.8  Accuracy  GSM8K-Symbolic P2  gpt-4o-mini  gpt-4o-mini + sleep-time compute  gpt-4o  gpt-4o + sleep-time compute Figure 21: Context only baseline.   Comparing the test-time compute vs.   accuracy tradeoff on Stateful GSM-Symbolic, for sleep-time compute verses the context only baseline (e.g. the model has to guess the most likely question to answer). We see that sleep-time compute significantly outperforms the context only baseline, demonstrating that the questions in Stateful GSM-Symbolic cannot be trivially guessed. 0   2000   4000   6000   8000   10000   12000  Avg. Test Time Tokens / Question  0.3  0.4  0.5  0.6  0.7  Accuracy  o3-mini - Stateful-AIME 2024  2000   4000   6000   8000   10000  Avg. Test Time Tokens / Question  0.25  0.30  0.35  0.40  0.45  0.50  0.55  0.60  Accuracy  o1 - Stateful-AIME 2024  sleep-time compute   ablate question  Figure 22: Context only baseline.   Comparing the test-time compute vs.   accuracy tradeoff on Stateful AIME, for sleep-time compute verses the context only baseline (e.g. the model has to guess the most likely question to answer). We see that sleep-time compute significantly outperforms the context only baseline, demonstrating that the questions in Stateful AIME cannot be trivially guessed.  J   Stateful AIME Construction  To construct the examples for Stateful AIME, we split each AIME 2024 and 2025 into a sequence of ‚Äústate- ments‚Äù, which correspond to punctuation separated stentences in the problem. Similar to how we construct Stateful GSM-Symbolic, we use all but the last statement as the context, and the final statement as the query. 27\n\nThere are a couple of edge cases where the question is posed in e.g. the second to last statement rather than the last statement. In these cases, we manually rearrange the statements to ensure the query being used corresponds to the question. In a few cases, there is only one statement in the problem. In these cases, the context is empty. AIME includes a latex representation of figures. However, these latex figures can leak information about the answer: for example, these latex figures can contain exact information about the lengths of the sides in a geometry problem, giving away the answer. In these cases we first ensure that the problem is solvable without the figure and then manually strip the figure latex from the problem context.  K   Implementation Details  We implement sleep-time compute via function calling. When applying sleep-time compute, the model is given access to two functions,   rethink memory   and   finish rethinking . The   rethink memory   function takes as input a new string, and replaces the current context   c   and replaces the current context with the new string. The   finish rethinking   function terminates the sleep-time compute process. The model is allowed to call the function   rethink memory   for up to 10 times.  L   AIME main results by year M   AIME sleep-time compute scaling results by year  28\n\n1000   2000   3000   4000   5000   6000   7000  Avg. Test Time Tokens / Question  0.5  0.6  0.7  0.8  0.9  Accuracy  o3-mini - Stateful-AIME 2024  2000   4000   6000   8000   10000   12000  Avg. Test Time Tokens / Question  0.50  0.55  0.60  0.65  0.70  0.75  Accuracy  o1 - Stateful-AIME 2024  2500   5000   7500   10000   12500   15000   17500   20000  Avg. Test Time Tokens / Question  0.300  0.325  0.350  0.375  0.400  0.425  0.450  0.475  Accuracy  Claude 3.7 Sonnet - Stateful-AIME 2024  1000   2000   3000   4000   5000   6000  Avg. Test Time Tokens / Question  0.1  0.2  0.3  0.4  0.5  0.6  0.7  Accuracy  DeepSeek R1 - Stateful-AIME 2024  sleep-time compute   test-time compute only Figure 23: AIME 2024 main result 29\n\n0   1000   2000   3000   4000   5000   6000   7000   8000  Avg. Test Time Tokens / Question  0.3  0.4  0.5  0.6  0.7  Accuracy  o3-mini - Stateful-AIME 2025  2000   4000   6000   8000   10000  Avg. Test Time Tokens / Question  0.40  0.45  0.50  0.55  0.60  0.65  0.70  0.75  0.80  Accuracy  o1 - Stateful-AIME 2025  5000   10000   15000   20000  Avg. Test Time Tokens / Question  0.20  0.25  0.30  0.35  0.40  Accuracy  Claude 3.7 Sonnet - Stateful-AIME 2025  1000   2000   3000   4000   5000   6000  Avg. Test Time Tokens / Question  0.1  0.2  0.3  0.4  0.5  0.6  Accuracy  DeepSeek R1 - Stateful-AIME 2025  sleep-time compute   test-time compute only Figure 24: AIME 2025 main result 30\n\n2000   3000   4000   5000   6000  Avg. Test Time Tokens / Question  0.40  0.45  0.50  0.55  0.60  Accuracy  o1 Sleep-Time Compute Stateful-AIME 2024  1000   2000   3000   4000   5000   6000   7000  Avg. Test Time Tokens / Question  0.45  0.50  0.55  0.60  0.65  0.70  0.75  Accuracy  o3-mini Sleep-Time Compute Stateful-AIME 2024  low reasoning effort sleep-time   medium reasoning effort sleep-time   high reasoning effort sleep-time Figure 25: Scaling sleep-time compute for Stateful AIME2024. 1000   1500   2000   2500   3000   3500   4000   4500   5000  Avg. Test Time Tokens / Question  0.275  0.300  0.325  0.350  0.375  0.400  0.425  0.450  0.475  Accuracy  o1 Sleep-Time Compute Stateful-AIME 2025  1000   2000   3000   4000   5000  Avg. Test Time Tokens / Question  0.3  0.4  0.5  0.6  0.7  Accuracy  o3-mini Sleep-Time Compute Stateful-AIME 2025  low reasoning effort sleep-time   medium reasoning effort sleep-time   high reasoning effort sleep-time  Figure 26: Scaling sleep-time compute on Stateful AIME2025 31",
      "embedding": [
        -0.05823478102684021,
        -0.008080312050879002,
        -0.004293746314942837,
        0.08301806449890137,
        0.018774231895804405,
        -0.04846293106675148,
        0.03705940023064613,
        0.004637034144252539,
        0.02851065620779991,
        0.008046308532357216,
        -0.0928749367594719,
        -0.07952460646629333,
        0.04751414433121681,
        0.03114551305770874,
        0.04491673409938812,
        -0.012923356145620346,
        0.11556536704301834,
        0.049184128642082214,
        -0.11316540837287903,
        -0.03214351460337639,
        0.058195412158966064,
        -0.007730682380497456,
        0.05081337317824364,
        0.00037301023257896304,
        0.0015037893317639828,
        -0.03373783826828003,
        0.001371579710394144,
        -0.09641857445240021,
        -0.015781013295054436,
        0.007173236925154924,
        0.00023362814681604505,
        0.0975276529788971,
        -0.03794772922992706,
        0.029402511194348335,
        -0.037653978914022446,
        -0.0035131475888192654,
        -0.03302004933357239,
        -0.006933882832527161,
        0.005262944847345352,
        -0.04205836355686188,
        -0.008532685227692127,
        -0.04089884087443352,
        -0.006929412949830294,
        -0.03472934290766716,
        0.00045683945063501596,
        -0.04131031781435013,
        0.004153722897171974,
        -0.0017656175186857581,
        -0.016836808994412422,
        0.03641100972890854,
        -0.11216841638088226,
        -0.0464433990418911,
        -0.0602782666683197,
        0.005243445746600628,
        -0.02264983579516411,
        0.038977742195129395,
        0.0578303337097168,
        0.05412618815898895,
        0.0029060340020805597,
        0.00386093114502728,
        -0.07127959281206131,
        -0.08867410570383072,
        -0.0013741633156314492,
        0.004049133509397507,
        0.029879532754421234,
        0.02698247879743576,
        0.006534004118293524,
        -0.03923245146870613,
        0.022773828357458115,
        0.016658931970596313,
        -0.037102263420820236,
        0.05363466218113899,
        -0.08024749159812927,
        0.0002463077544234693,
        -0.06308115273714066,
        0.041795022785663605,
        0.04747806489467621,
        -0.010478533804416656,
        0.10493156313896179,
        -0.033356521278619766,
        0.012338779866695404,
        0.006789456587284803,
        -0.021583184599876404,
        -0.005527057684957981,
        0.05745229497551918,
        -0.0020221106242388487,
        0.09960578382015228,
        0.06256474554538727,
        0.0438556931912899,
        -0.04011353477835655,
        0.06232912093400955,
        0.005220305640250444,
        -0.02140215039253235,
        0.014121906831860542,
        0.04727672412991524,
        0.020321214571595192,
        0.03071308694779873,
        0.0033994049299508333,
        -0.022213725373148918,
        0.07869234681129456,
        0.020924709737300873,
        0.09394456446170807,
        0.07016777992248535,
        -0.06674638390541077,
        -0.0337916724383831,
        0.03462532162666321,
        0.038237541913986206,
        0.018451126292347908,
        -0.003070729086175561,
        -0.07181983441114426,
        -0.009752449579536915,
        0.08705811947584152,
        0.029311789199709892,
        0.0056726448237895966,
        -0.00789550133049488,
        0.04339970648288727,
        0.059970956295728683,
        -0.02753942646086216,
        0.07158754765987396,
        0.07782549411058426,
        0.058124251663684845,
        0.046387821435928345,
        0.04222656041383743,
        -0.11276772618293762,
        0.06619930267333984,
        -0.0107662882655859,
        -0.06297098845243454,
        7.016941611184838e-33,
        0.026829421520233154,
        0.0024108446668833494,
        0.005608110688626766,
        -0.03326881304383278,
        0.011287613771855831,
        -0.024264132604002953,
        0.038514643907547,
        0.09227944165468216,
        -0.04062776267528534,
        -0.0261450856924057,
        -0.007616827264428139,
        0.05046232417225838,
        -0.03172441944479942,
        0.007664985954761505,
        0.08722817897796631,
        0.010809137485921383,
        -0.036293331533670425,
        0.025754062458872795,
        -0.027467189356684685,
        -0.04255980998277664,
        0.0806504487991333,
        -0.08576302230358124,
        0.025860203430056572,
        0.0046358914114534855,
        0.03218685835599899,
        0.0006596384919248521,
        0.04560615494847298,
        -0.07394035160541534,
        -0.001193545525893569,
        0.01620654948055744,
        -0.0644601434469223,
        -0.013545875437557697,
        -0.11052767187356949,
        0.05662688985466957,
        0.043661944568157196,
        -0.048799362033605576,
        0.010595454834401608,
        -0.08168074488639832,
        0.016803616657853127,
        -0.04133315756917,
        -0.07665599137544632,
        0.05056021362543106,
        0.05391903221607208,
        -0.008157717064023018,
        -0.08977290987968445,
        -0.08447239547967911,
        -0.021699916571378708,
        -0.0037432280369102955,
        0.0016263227444142103,
        -0.006830218248069286,
        0.07133449614048004,
        0.016140107065439224,
        -0.018610093742609024,
        -0.05399365723133087,
        -0.05620343238115311,
        -0.002057645469903946,
        0.0382874459028244,
        0.026379697024822235,
        -0.006309411488473415,
        0.12749628722667694,
        -0.010995954275131226,
        -0.042932312935590744,
        0.014044555835425854,
        0.018946798518300056,
        -0.009951747953891754,
        0.03054101951420307,
        -0.09668028354644775,
        0.05862656608223915,
        0.10948172956705093,
        -0.028082776814699173,
        0.037251219153404236,
        -0.024285485967993736,
        0.07092027366161346,
        -0.013173511251807213,
        0.05455682799220085,
        -0.02631889469921589,
        0.09305419772863388,
        -0.05847197026014328,
        -0.03133143484592438,
        -0.018507912755012512,
        0.06317102909088135,
        -0.005862125661224127,
        -0.02814088948071003,
        -0.06234053522348404,
        -0.005925947800278664,
        -0.079343281686306,
        0.01719248853623867,
        -0.044262032955884933,
        -0.09889104962348938,
        -0.04818949103355408,
        -0.08055533468723297,
        0.0038322992622852325,
        0.0375652052462101,
        -0.01721813902258873,
        -0.05212175101041794,
        -5.157119265035939e-33,
        -0.046459097415208817,
        -0.14359119534492493,
        -0.007674569264054298,
        0.14541268348693848,
        0.060604218393564224,
        -0.09733344614505768,
        0.03595740348100662,
        -0.09082364290952682,
        -0.0865287035703659,
        -0.06965412199497223,
        -0.07703426480293274,
        -0.010265721008181572,
        0.06492908298969269,
        0.00015472079394385219,
        0.07930294424295425,
        -0.025131061673164368,
        0.02358553744852543,
        -0.04647118225693703,
        -0.02344822697341442,
        0.12919747829437256,
        0.021885331720113754,
        0.12808109819889069,
        -0.09845703840255737,
        -0.0635354220867157,
        -0.019752684980630875,
        0.017497828230261803,
        -0.043675731867551804,
        0.07566025853157043,
        0.0096909049898386,
        -0.020337706431746483,
        -0.029727386310696602,
        -0.06494663655757904,
        -0.09593646973371506,
        -0.04458603635430336,
        0.0006363748689182103,
        0.022849872708320618,
        0.07034868746995926,
        -0.008685128763318062,
        -0.02198314666748047,
        0.03784385696053505,
        0.12442351132631302,
        -0.0309345331043005,
        -0.017655624076724052,
        -0.0381975881755352,
        0.03178337216377258,
        0.11678671836853027,
        -0.10316845774650574,
        -0.026941154152154922,
        -0.033948689699172974,
        0.012315142899751663,
        0.013386694714426994,
        0.010993740521371365,
        -0.025445574894547462,
        0.024853408336639404,
        -0.008541221730411053,
        -0.07683389633893967,
        -0.04455365985631943,
        -0.08105672895908356,
        -0.0526295006275177,
        -0.01272913720458746,
        -0.044054243713617325,
        0.008489325642585754,
        0.08183329552412033,
        -0.03269876539707184,
        0.08477619290351868,
        -0.00730383163318038,
        0.014569547027349472,
        -0.08542315661907196,
        0.011506144888699055,
        -0.023330267518758774,
        -0.008809094317257404,
        -0.023993950337171555,
        -0.002447964157909155,
        0.06709082424640656,
        0.01628553308546543,
        0.04340468347072601,
        0.013249785639345646,
        -0.046368081122636795,
        0.01504726056009531,
        -0.04549640044569969,
        -0.021559886634349823,
        0.0025038919411599636,
        -0.021315861493349075,
        -0.018047835677862167,
        -0.02784394472837448,
        0.05501040443778038,
        0.06223588436841965,
        0.06528988480567932,
        0.07531195878982544,
        0.0091654472053051,
        -0.0819048285484314,
        0.018119387328624725,
        -0.06877939403057098,
        0.025095462799072266,
        -0.03934180364012718,
        -5.128661584308247e-8,
        0.030460814014077187,
        -0.0041391439735889435,
        0.03754046559333801,
        0.02792893536388874,
        0.053919266909360886,
        -0.04760557413101196,
        -0.017757771536707878,
        0.0398203581571579,
        0.006816169247031212,
        0.008573588915169239,
        0.137749582529068,
        -0.041705481708049774,
        0.03141548112034798,
        0.003157961880788207,
        0.03479843959212303,
        0.055638138204813004,
        -0.005605279467999935,
        -0.027683109045028687,
        -0.07479535788297653,
        -0.039320383220911026,
        0.005617969203740358,
        0.05085339769721031,
        -0.022873612120747566,
        0.04910705238580704,
        0.0573698915541172,
        0.018022075295448303,
        0.053782906383275986,
        0.11166660487651825,
        0.09208233654499054,
        -0.028711849823594093,
        0.025249334052205086,
        -0.017788685858249664,
        -0.006706458516418934,
        -0.025080136954784393,
        0.04794861003756523,
        -0.05564191937446594,
        -0.010744143277406693,
        0.030579278245568275,
        0.025791477411985397,
        0.0632014200091362,
        0.03254767879843712,
        0.02286372520029545,
        -0.02953009307384491,
        0.04251956567168236,
        0.08524397760629654,
        -0.05982868745923042,
        -0.06800443679094315,
        -0.03514844924211502,
        -0.009460188448429108,
        -0.016135256737470627,
        0.005384351592510939,
        -0.08132900297641754,
        -0.0693010464310646,
        0.032488949596881866,
        0.04858442023396492,
        -0.011907840147614479,
        0.02456953004002571,
        -0.055353980511426926,
        0.019705532118678093,
        0.026884080842137337,
        0.05981050431728363,
        -0.027370184659957886,
        -0.11661656200885773,
        0.011982467025518417
      ],
      "metadata": {
        "title": "pr title Body: pr body File: file1 filename Status: file1 status Patch: file1 patch ... (some more files and some more relevant pull requests) When the sleep-time compute is turned on, we first use the following prompt to ask the agent to explore the repository with all pull requests one by one: 25",
        "createdAt": "2025-12-17T13:56:31.896Z"
      },
      "fileObj": {}
    },
    {
      "id": "doc_5_1765979792803",
      "fileName": "Paper_13_Dynamic_gNodeB_Sleep_Control_for_Energy_Conserving.pdf",
      "content": "1  Dynamic gNodeB Sleep Control for Energy-Conserving 5G Radio Access Network  Pengfei Shen, Yulin Shao,   Member, IEEE , Qi Cao, Lu Lu,   Member, IEEE  Abstract ‚Äî5G radio access network (RAN) is consuming much more energy than legacy RAN due to the denser deployments of gNodeBs (gNBs) and higher single-gNB power consumption. In   an   effort   to   achieve   an   energy-conserving   RAN,   this   pa- per develops a dynamic on-off switching paradigm, where the ON/OFF states of gNBs can be dynamically configured according to the evolvements of the associated users. We formulate the dynamic   sleep   control   for   a   cluster   of   gNBs   as   a   Markov decision process (MDP) and analyze various switching policies to reduce the energy expenditure. The optimal policy of the MDP that minimizes the energy expenditure can be derived from dynamic programming, but the computation is expensive. To circumvent this issue, this paper puts forth a greedy policy and an index policy for gNB sleep control. When there is no constraint on the number of gNBs that can be turned off, we prove   the   dual-threshold   structure   of   the   greedy   policy   and analyze   its   connections   with   the   optimal   policy.   Inspired   by the dual-threshold structure and Whittle index, we develop an index policy by decoupling the original MDP into multiple one- dimensional MDPs ‚Äì the indexability of the decoupled MDP is proven and an algorithm to compute the index is proposed. Extensive simulation results verify that the index policy exhibits close-to-optimal performance in terms of the energy expenditure of   the   gNB   cluster.   As   far   as   the   computational   complexity is   concerned,   on   the   other   hand,   the   index   policy   is   much more efficient than the optimal policy, which is computationally prohibitive when the number of gNBs is large.  Index   Terms ‚ÄîBase   station   sleep   control,   5G,   radio   access network, Markov decision process, greedy policy, index policy.  I. I NTRODUCTION  A. Background  With the rolling out of 5G new radio (NR), the energy expenditure of commercial broadband cellular networks be- comes a growing concern [1]‚Äì[4]. To support enhanced mobile broadband communications at   10   Gbps and provide seamless coverage, 5G base stations (BSs), i.e., gNodeB (gNB), are deployed more densely than 4G eNodeB (eNB). It is antici- pated that the number of gNB will reach 65 million by 2025, and the average density of gNB will be three times higher than that of eNB [5]. On the other hand, gNB incorporates a number of new and power-hungry components [6], such as in- tegrated massive MIMO antennas, faster data converters, high- power/low-noise amplifiers, and millimeter wave (mmWave)  P. Shen and L. Lu are with the University of Chinese Academy of Sciences, and the Key Laboratory of Space Utilization, Chinese Academy of Sciences, Beijing 100094, China (emails:   { shenpengfei19, lulu } @csu.ac.cn). Y.   Shao   is   with   the   Department   of   Electrical   and   Electronic   En- gineering,   Imperial   College   London,   London   SW7   2AZ,   U.K.   (e-mail: y.shao@imperial.ac.uk). C. Qi is with Xidian-Guangzhou Research Institute, Xidian University, Guangzhou, China (e-mail: caoqi@xidian.edu.cn).  transceivers. As a consequence, the power expenditure of a single gNB is estimated to be two to four times higher than that of an eNB [7]. The increasing energy expenditure of mobile radio access networks (RANs) leads to higher costs and larger amounts of greenhouse gas emissions ‚Äì as it stands now, the mobile communication industry contributes 15% to 20% of CO 2   emissions among the information and communication technology (ICT) industries [8]. To reduce the overall cost and achieve green mobile net- works, various energy-conserving schemes have been pro- posed in the literature [9]‚Äì[12], such as BS sleep control, energy harvesting, hardware optimization, energy-efficiency- oriented resource allocation, and network coverage planning, among which BS sleep control receives the most attention. The power consumption of a BS mainly comes from three aspects: 1) the static consumption [13]‚Äì[15], i.e., the power consumed by operating the BS, such as the power consumption of the electrical parts, circuits, cooling systems, etc.; 2) the dynamic consumption [13]‚Äì[17], i.e., the power consumed by serving users; and 3) the switching consumption [18]‚Äì[20], i.e., the power consumed by switching the BSs between ON and OFF states. The traffic load of a BS can vary dramatically at different times of day [2], [14]. The deployment and operation of BSs, however, are often designed to meet the peak traffic load ‚Äì hence a large amount of energy for operating the BSs is wasted during off-peak hours. In this light, BS sleep control is proposed to turn off the BSs with no or light traffic and wake them up again when there is moderate or heavy traffic, thereby saving the static power of light-traffic BSs. A practice of BS sleep control is implemented by China Mobile [21], in which a fraction of BSs are manually turned off overnight. It is reported that the energy expenditure is reduced by 36 million kilowatt hour (kWh) per year with the manual configuration of BS states.  B. Prior arts  Many research efforts have been devoted to BS sleep control in heterogeneous mobile networks [9], [22]. In general, the problem of BS switching control is combinatorial optimization and is often NP-hard. The research focus of prior arts is on designing efficient BS switching policies. Early studies on BS sleep control utilize state-independent policies [23], [24], such as random policy, to control the sleep mode of either macro or micro BSs in heterogeneous networks. In their formulations, the locations of mobile users, macro and micro BSs are often modeled as independent homogeneous Poisson point processes (PPPs). Each BS is associated with  arXiv:2207.06309v1 [cs.IT] 13 Jul 2022\n\n2  a turn-off probability. The optimization problems are then formulated to find the optimal set of turn-off probabilities to minimize the BS energy expenditure. Beyond state-independent policies, a more prevailing ap- proach to model the problem of BS sleep control is taking user distribution, BS traffic load, or transmission power budget, etc., as ‚Äústates‚Äù and designing switching policies that are governed by these states. Under this formulation, [25]‚Äì[27] in- vestigated threshold-based switching policies; [13], [28], [29] investigated the greedy policy; [30], [31], and [32] developed a switching-on/off based energy saving (SWES) algorithm, a local search algorithm, and a genetic algorithm (GA)-based al- gorithm, respectively, to solve the combinatorial optimization problems. These works, however, aim to minimize the myopic energy expenditure of mobile networks, hence is suboptimal in terms of the long-term energy expenditure when the network dynamics are correlated over time. To develop switching policies that minimize the long-term network energy expenditure, [18], [33]‚Äì[38] formulate the BS sleep control problem as Markov decision processes (MDPs). Specifically, the optimal policy for the MDP is investigated in [33] and [34]. The optimal policy, however, is known for its high complexity. To circumvent this issue, [35] proposed a policy rollout algorithm to be used in conjunction with the greedy policy to approximate the value function of each state. Along this direction, another line of work leverages deep rein- forcement learning (DRL) techniques to solve the MDP [18], [36]‚Äì[38]. The salient feature of DRL is model-free. That is, given unknown network dynamics, DRL algorithms are able to adapt to the traffic load variations and produce good switching policies that reduce the network power consumption [39], [40]. DRL algorithms, however, only produce achievability under an unknown environment, but fail to characterize the optimal policy of MDP.  C. Contributions  In this paper, we put forth a dynamic on-off switching approach to achieve efficient BS sleep control tailored for the new generation RAN (NG-RAN) architecture standardized in the latest third generation partnership project (3GPP) releases. As shown in Fig. 1, 3GPP NG-RAN defines two classes of RAN architectures for the deployment of 5G NR [41], i.e., the standalone (SA) and non-standalone (NSA) architectures. In both architectures, a user can connect to either gNB or eNB/ng-eNB (ng-eNB is an updated version of 4G eNB), indicating that light-traffic gNB can be turned off and the traffic demands of users in a turned-off gNB can be fulfilled by eNB or ng-eNB. To   achieve   judicious   gNB   sleep   control   and   energy- conserving 5G networks, we take the dynamic evolvement of users into account and formulate the on-off configuration of a cluster of 5G cells as an MDP. Given this formulation, we design and analyze various switching policies to mini- mize the long-term average   cost   of the 5G cells, where the cost of a 5G cell is a non-decreasing function of the cell‚Äôs power consumption. The optimal policy to the formulated MDP exhibits the best performance, i.e., the minimum long- term average cost, but its computational complexity increases NGC  gNB  Option 2  gNB  NGC  eNB/ng - eNB  Option 4/4a  NG - RAN SA  Option 3/3a/3x   Option 7/7a/7x  NG - RAN NSA  EPC  eNB/ng - eNB  gNB  NGC  eNB/ng - eNB gNB  EPC  eNB/ng - eNB  Figure 1: The standalone (SA) and non-standalone (NSA) architectures of NG-RAN. The difference between SA and NSA lies in whether the control plane of gNB is connected to the core networks directly or via eNB/ng-eNB. The core network can be 4G evolved packet core (EPC) or 5G new generation core (NGC). exponentially in the number of 5G cells. State-independent policies, in contrast, are computationally simple, but their performances are suboptimal. In this context, we propose and analyze two policies, one is a greedy policy and the other is an index policy to solve the MDP. For the greedy policy, we prove its dual-threshold structure when there is no constraint on the number of gNBs that can be turned off, and analyze its connections with the optimal policy. Furthermore, inspired by the dual-threshold structure and Whittle index, we decouple the original MDP to multiple one-dimensional MDPs and prove the indexability of the decoupled MDP, whereby an index policy is proposed. As far as the long-term average cost is concerned, the index policy achieves close-to-optimal performance in various simulation setups and is better than the greedy policy and state-independent policies. As far as the computational complexity is concerned, the index policy is much more efficient to compute than the optimal policy and the greedy policy. The remainder of this paper is organized as follows. Sec- tion II presents the system model and formulates the MDP. Section III analyzes the optimal policy and the greedy policy. Section IV studies the index policy. Two state-independent policies are analyzed in Section V. In addition, a lower bound is derived to measure the performance of various policies when the optimal policy is computationally prohibitive. Numerical and simulation results are presented in Section VI. Section VII concludes this paper.  Notations   ‚Äì We use boldface lowercase letters to denote column vectors and boldface uppercase letters to denote ma- trices. For a vector or matrix,   ( ¬∑ ) >   denotes the transpose.  R   and   N   stand for the sets of real and non-negative integer values, respectively. The imaginary unit is represented by   j . The cardinality of a set   V   is denoted by   |V| . II. S YSTEM   M ODEL  A. Problem formulation  We consider a cluster of   M   5G cells indexed by   { m   :   m   = 1 ,   2 ,   ¬∑ ¬∑ ¬∑   , M   } . Each cell is equipped with a gNB located in the center and the gNBs are managed by a central controller. The power consumption of a gNB consists of three main\n\n3 ng - eNB   gNB  5GC   UE  Figure 2: A cluster of 5G cells with   M   gNBs and one ng-eNB, where NGC stands for the 5G core network and UE stands for user. parts [2], [14]: static, dynamic, and switching, denoted by  P static ,   P dynamic , and   P switch , respectively.   P static   is the power consumption incurred by the operations of the gNB, such as the electrical parts, circuits, cooling systems, etc. It is constant when the gNB is on and zero when the gNB is off.  P dynamic   is the power consumed by serving users, and hence, is proportional to the number of users in the cell.   P switch   is the power consumed by state switching when the gNB is turned from the OFF state to the ON state (the power consumption of switching state from ON to OFF is often omitted [18]). Time   is   divided   into   segments   of   duration   T s .   At   the beginning of a time segment, the central controller configures the ON/OFF states of the gNBs based on the number of existing users in the cells as well as the anticipated users in the future. Intuitively, when the number of users in a cell is large, the gNB has to be turned on to provide good quality of services to users at the expense of high power expenditure. On the other hand, when the number of users is small, the gNB can be turned off to save   P static   and   P dynamic . In this case, the users in the 5G cells will be served by the ng- eNB, which is capable of satisfying most requirements of the small number of users. Note that ng-eNB is always on, thus, there is no switching power consumption and its static power consumption is irrelevant. The dynamic power consumption of the ng-eNB is denoted by   P extra , which is proportional to the number of users to be served (as   P dynamic ). Typically, the per- user dynamic power consumption of a gNB is smaller than that of the ng-eNB thanks to the closer deployments to the users. In this paper, we assume that the ng-eNB can serve at most   K   5G cells and   0   ‚â§   K   ‚â§   M   . Note that when   K   =   M   , all   M   gNBs are allowed to be turned off. To discover the optimal configuration policy for the central controller, this paper models the state configuration problem of the cell cluster as a discrete MDP, wherein the central controller makes successive switching actions based on the states of the BS cells to minimize the long-term average power consumption. More rigorously, we define the ingredients of the MDP as follows.  Definition   1   (Action) .   At the beginning of the   t -th time segment, the action of the central controller is defined as  a t   ,   ( a t  1 , a t  2 ,   ¬∑ ¬∑ ¬∑   , a t M   ) > , where   a t m   ‚àà { 0 ,   1 }   denotes the state of the   m -th gNB in the   t -th time segment (0 and 1 stand for OFF and ON, respectively). A constraint on   a t   is ‚àë M m =1   a t m   ‚â•   M   ‚àí   K ,   ‚àÄ t , as the ng-eNB can serve at most   K  cells, where   K   ‚àà { 0 ,   1 ,   2 ,   ¬∑ ¬∑ ¬∑   , M   } .  Definition   2   (State) .   At   the   beginning   of   the   t -th   time segment, the state of the cell cluster is defined as   s t   ,  ( s t  1 , s t  2 ,   ¬∑ ¬∑ ¬∑   , s t M   ) > , where   s t m   denotes the state of the   m -th cell. In particular,   s t m   ,   ( a t ‚àí 1  m   ,   Àú n t m )   consists of two parts:  a t ‚àí 1  m   is the ON/OFF state of the   m -th gNB in the   ( t   ‚àí   1) -th time segment and   Àú n t m   denotes the number of users in the   m -th cell.  It is worth noting that   Àú n t m   is the residual users from the  ( t ‚àí 1) -th time segment. On the other hand, the dynamic power consumption   P dynamic   is proportional to the total number of users   N   t m   in the cell. In the   t -th time segment,   N   t m   consists of two parts: the residual users from the   ( t ‚àí 1) -th time segment and the newly arrived users. Thus, we can write   N   t m   =   Àú n t m   +  n t m , where   n t m   denotes the number of newly arrived users in the   t -th time segment. The user arrival and departure models are explained in more detail later in Section II-B.  Definition 3   (Immediate cost) .   Suppose the power consumed by the   m -th cell is   P ( s t m , a t m )   in the   t -th time segment. The immediate cost of the action   a t m   when in state   s t m   is defined as   c ( s t m , a t m )   ,   f   [ P ( s t m , a t m )] , where   f   is a non-decreasing function. Accordingly, the immediate cost of the cell cluster is  C ( s t ,   a t )   ,   ‚àë M m =1   c ( s t m , a t m ) .  A configuration/switching policy   œÄ   is a mapping from the state space to the action space, i.e.,   a t   =   œÄ ( s t ) . Given the above definitions, the average cost incurred by a given policy  œÄ   over the infinite-time horizon is  C œÄ   =   lim  T   ‚Üí‚àû   E  [  1  T  T   ‚àí 1 ‚àë  t =0  C ( s t ,   a t )  ]  ,   (1) where the expectation is taken over the dynamics of user arrival and departure in each cell. The objective of the central controller is to discover the optimal policy   œÄ ‚àó   such that the long-term average cost   C œÄ   is minimized, giving  ( P1 ) :   œÄ ‚àó   = arg min  œÄ   C œÄ   ,   (2)  s.t. ,  M ‚àë  m =1  a t m   ‚â•   M   ‚àí   K,   ‚àÄ t.  B. Users‚Äô arrival, departure, and power consumption  This   paper   models   the   users‚Äô   arrival   and   departure   as follows.  Definition 4   (User arrival and departure processes) .   We as- sume that users arrive at and depart from a cell in an indepen- dent and identically distributed (i.i.d.) fashion. In particular, 1) Users‚Äô arrival to a cell follows a mixed Poisson process with a set of parameters   Œõ = ( Œª 1 , Œª 2 ,   ¬∑ ¬∑ ¬∑   , Œª J   ) . That is,\n\n4  the number of newly arrived users in the t-th time segment follows  Pr( n t m   =   ` ) =  J ‚àë  j =1  p m,j  ( Œª j   T s ) `  ` !   e ‚àí Œª j   T s   ,   (3)  where   Œª j   is sampled from   Œõ   with probability   Pr( Œª j   ) =  p m,j   in the   m -th cell. It is worth noting that the mixed Poisson process can be used to fit arbitrary distributions [42]. 2) The staying time of a user in the   m -cell follows the exponential distribution with parameter   Œº m , where   Œº m  is the mean service time of a user.  Given the user arrival and departure processes, we first analyze the number of users in a cell at the beginning of a time segment   Àú n t m .  Proposition 1   (The distribution of residual users) .   At the beginning   of   the   t -th   time   segment,   the   probability   mass function (PMF) of the number of users in the   m -th cell   Àú n t m   is given by  Pr( Àú n t m   =   ` ) =  J ‚àë  j =1  p m,j  ( Àú Œª m,j  ) `  ` !   e ‚àí Àú Œª m,j   ,   (4)  for   `   = 0 ,   1 ,   2 ,   ¬∑ ¬∑ ¬∑   , where   Àú Œª m,j   =   Œª j  Œº m   (1   ‚àí   e ‚àí Œº m T s   ) . The average   Àú n t m   is   E [ Àú n t m ] =   ‚àë J j =1   p m,j   Àú Œª m,j   . Proof.   See Appendix A.   \u0004  The dynamic power consumption of a cell is proportional to the number of users to be served   N   t m   =   Àú n t m   +   n t m . At the beginning of the   t -th time segment, the number of existing users in the cells   { Àú n t m   :   m   = 1 ,   2 ,   ¬∑ ¬∑ ¬∑   , M   }   is known to the central controller, while the number of users to arrive in the  t -th time segment is a random variable, the exact number of which is unknown. Thus, the central controller can only make decisions based on the expected number of users to arrive in the   t -th time segment.  Proposition 2   (Anticipated power consumption of a cell) .  Denote by   P d   and   P e   the average power consumption of the gNB and ng-eNB to serve a single user, respectively. At the beginning of the   t -th time segment, the anticipated power consumption of the   m -th cell is given by  P   ( s t m   = ( a t ‚àí 1  m   ,   Àú n t m ) , a t m  )   =   (5)  Ô£± Ô£¥ Ô£≤ Ô£¥ Ô£≥  P static   +   ( Àú n t m   +   Œª m T s  )   P d ,   if   a t m   =   a t ‚àí 1  m   = 1;  P static   +   P switch   +   ( Àú n t m   +   Œª m T s  )   P d ,   if   a t m   = 1 , a t ‚àí 1  m   = 0;  ( Àú n t m   +   Œª m T s  )   P e ,   if   a t m   = 0 ,  where   Œª m   ,   ‚àë J j =1   p m,j   Œª j   and   Œª m T s   is the expected number of newly arrived users in the   t -th time segment in the   m -th cell.  III. T HE   O PTIMAL   P OLICY AND THE   G REEDY   P OLICY  A. The optimal switching policy  Given the definitions in Section II, the discrete MDP asso- ciated with the on-off switching of gNBs can be described as follows. At the beginning of the   t -th time segment, the central controller observes a system state   s t   = ( s t  1 , s t  2 ,   ¬∑ ¬∑ ¬∑   , s t M   ) >   and determines a set of configurations   a t   = ( a t  1 , a t  2 ,   ¬∑ ¬∑ ¬∑   , a t M   ) >  for the gNBs following its policy   œÄ . The action produces two results: an immediate cost   C ( s t ,   a t )   is incurred, and the system evolves to a new state   s t +1   in the next time segment. The optimal switching policy   œÄ ‚àó   that minimizes the long- term average cost in (2) satisfies the Bellman equation:  g ‚àó   + h œÄ ‚àó   [ s ] = min  a  {  C ( s ,   a ) +   ‚àë  s ‚Ä≤  Pr( s ‚Ä≤   | s ,   a   ) h œÄ ‚àó   [ s ‚Ä≤ ]  }  (6) where   h œÄ ‚àó   [ s ]   is the relative value function of a state   s   under the optimal policy   œÄ ‚àó ;   g ‚àó   is the average cost incurred per time step under the optimal policy   œÄ ‚àó ;   Pr( s ‚Ä≤   | s ,   a   )   is the probability that the system moves to a new state   s ‚Ä≤   when the action   a   is executed in the state   s . Specifically, we have  Pr( s ‚Ä≤   | s ,   a   )   ( a )  =  M ‚àè  m =1  Pr( s ‚Ä≤  m   | s m , a m   )   (7)  ( b )  =  M ‚àè  m =1  Pr( Àú n ‚Ä≤  m   | Àú n m , a m   )  ( c )  =  M ‚àè  m =1  Ô£´ Ô£¨ Ô£≠  J ‚àë  j =1  p m,j  ( Àú Œª m,j  ) Àú n ‚Ä≤  m  Àú n ‚Ä≤  m !   e ‚àí Àú Œª m,j  Ô£∂ Ô£∑ Ô£∏   ,  where (a) follows from the independent assumption of the cells; (b) follows because the actions are determined once a policy is given ‚Äì the only random variable in the state   s ‚Ä≤  m   is  Àú n ‚Ä≤  m ; (c) follows from Proposition 1. The solution   ( g ‚àó , h œÄ ‚àó   )   to (6) can be solved by the relative value iteration algorithm (RVIA) since the MDP is unichain [39]. Once (6) is solved, the optimal policy   œÄ ‚àó   can be extracted by acting greedy, i.e., choosing the action that gives the minimal cost:  œÄ ‚àó ( s ) = arg min  a  {  C ( s ,   a ) +   ‚àë  s ‚Ä≤  Pr( s ‚Ä≤   | s ,   a   ) h œÄ ‚àó   [ s ‚Ä≤ ]  }  .   (8) This solution of RVIA is optimal, but it exhibits several problems. First, the number of states needs to be finite to solve (6). In our problem, the state size is infinite as the number of users in a cell can be any non-negative integers. Therefore, an upper limit   N th   has to be set such that the number of users in a cell is reset to   N th   if it is larger than   N th . In order not to affect the optimality of the RVIA,   N th   should be large enough to make   Pr( Àú n t m   > N th )   negligible for a set of policies in the neighborhood of the optimal switching policy. Given   the   upper   limit   N th ,   the   state   size   is   | s |   = [ ( M  0  )   +   ( M  1  )   +   ¬∑ ¬∑ ¬∑   +   ( M K  ) ]  ( N th   + 1) M   and the action size is  | a |   =   ( M  0  )   +   ( M  1  )   +   ¬∑ ¬∑ ¬∑   +   ( M K  ) . The decision space is thus  | s |√ó| a |√ó| s |   =  [( M  0  )  +  ( M  1  )  + ¬∑ ¬∑ ¬∑ +  ( M K  )] 3  ( N th +1) 2 M   .   (9) This   implies   a   formidable computational   complexity   of RVIA as the complexity will grow exponentially with the increase of   M   ‚Äì often, the optimal policy is incomputable when   M   is larger than 4.\n\n5  B. The greedy switching policy  Considering the high computational complexity of the op- timal policy, a widely-used alternative to solve the discrete MDP is the greedy policy [43]. As the name suggests, the greedy policy minimizes the immediate cost of the current time segment, as opposed to the long-term average cost   C . Denote by   œÄ g   the greedy policy. At the beginning of the   t -th time segment, the action   a t g   chosen by the greedy policy can be written as  a t g   =   œÄ g   ( s t ) = arg min  a t   C ( s t ,   a t ) ,   ‚àÄ t.   (10) Compared with the optimal policy, the decision criterion of the greedy policy is relatively simpler as it considers only the immediate cost. In our problem, the decision space of the greedy policy is  | s | √ó | a |   =  [ ( M  0  )   +   ( M  1  )   +   ¬∑ ¬∑ ¬∑   +   ( M K  ) ] 2  ( N th   + 1) M   , which also scales with   M   . However, when   K   =   M   (i.e., all the gNBs are allowed to be turned off), the greedy policy exhibits a nice threshold structure, as demonstrated in Theorem 3, and can be computed efficiently. For simplicity, the anticipated cost of a time segment for the   m -th cell is defined as follows  C (01)  m   ,   E Àú n t m  { f   [ P   ( s t m   = ( a t ‚àí 1  m   = 0 ,   Àú n t m ) , a t m   = 1 )]}  =   E Àú n t m  { f   [ P static   +   P switch   + ( Àú n t m   +   Œª m T s ) P d  ]}   , C (11)  m   ,   E Àú n t m  { f   [ P   ( s t m   = ( a t ‚àí 1  m   = 1 ,   Àú n t m ) , a t m   = 1 )]}  =   E Àú n t m  { f   [ P static   + ( Àú n t m   +   Œª m T s ) P d  ]}   , C (0)  m   ,   E Àú n t m  { f   [ P   ( s t m   = ( a t ‚àí 1  m   ,   Àú n t m ) , a t m   = 0 )]}  =   E Àú n t m  { f   [ ( Àú n t m   +   Œª m T s ) P e  ]}   ,   (11) where   C (01)  m   is the anticipated cost of a time segment when  a t ‚àí 1  m   = 0   and   a t m   = 1 ;   C (11)  m   is the anticipated cost of a time segment when   a t ‚àí 1  m   =   a t m   = 1 ; and   C (0)  m   is the anticipated cost of a time segment when   a t m   = 0 .  Theorem 3   (Structure of the greedy policy) .   The greedy policy is a dual-threshold policy when   K   =   M   . Specifically, for the  m -th cell,   m   = 1 ,   2 ,   ¬∑ ¬∑ ¬∑   , M   , there exists two thresholds  Œ≥ L m   ,   P static  P e   ‚àí P d  ‚àí Œª m T s , Œ≥ U m   ,   P static   +   P switch  P e   ‚àí P d  ‚àí Œª m T s ,   (12)  such that the action   a t m   under the greedy policy is given by  a t m   =  Ô£± Ô£¥ Ô£¥ Ô£¥ Ô£≤ Ô£¥ Ô£¥ Ô£¥ Ô£≥  1 ,   if   a t ‚àí 1  m   = 0   and   Àú n t m   > Œ≥ U m ; 0 ,   if   a t ‚àí 1  m   = 0   and   Àú n t m   ‚â§   Œ≥ U m ; 1 ,   if   a t ‚àí 1  m   = 1   and   Àú n t m   > Œ≥ L m ; 0 ,   if   a t ‚àí 1  m   = 1   and   Àú n t m   ‚â§   Œ≥ L m .  (13)  The long-term average cost of the greedy policy is  C g   =  M ‚àë  m =1  (   p L m  p L m   +   p U m  p U m C (01)  m   (14)  +   p U m  p L m   +   p U m  (1   ‚àí   p L m ) C (11)  m   +   p L m  p L m   +   p U m  C (0)  m  )  ,  where   p L m   ,   Pr( Àú n t m   < Œ≥ L m ) ;   p U m   ,   Pr( Àú n t m   > Œ≥ U m ) . Proof.   When   K   =   M   , the actions between each cell can be made independently. Therefore, we can focus on the greedy policy in one cell ‚Äì the immediate cost of the cell cluster is minimized as long as that of each cell is minimized. Consider the   m -th cell. Under the greedy policy, the   m -th gNB will be turned on in the   t -th time segment if   c ( s t m , a t m   = 1)   < c ( s t m , a t m   = 0) , where   c ( s t m , a t m ) =   f   [ P ( s t m , a t m )]   as in Definition 3. The tie breaks arbitrarily. Thus, when   a t ‚àí 1  m   = 0 , we have  f   [ ( Àú n t m   + Œª m T s ) P e  ]   > f   [ P static   + P switch   +( Àú n t m   + Œª m T s ) P d  ]   ,  i.e.,  Àú n t m   >   P static   +   P switch  P e   ‚àí P d  ‚àí   Œª m T s   ,   Œ≥ U m .  When   a t ‚àí 1  m   = 1 , we have  f   [ ( Àú n t m   +   Œª m T s ) P e  ]   > f   [ P static   + ( Àú n t m   +   Œª m T s ) P d  ]   ,  i.e.,  Àú n t m   >   P static  P e   ‚àí P d  ‚àí   Œª m T s   ,   Œ≥ L m .  In other words, depending on whether the gNB is ON or OFF in the   ( t ‚àí 1) -th time segment, we have two thresholds   Œ≥ L m  and   Œ≥ U m   for   Àú n t m : the gNB will be turned on if   Àú n t m   is larger than the two thresholds. On the other hand, the gNB will be turned off if   Àú n t m   is smaller than the two thresholds when the gNB is ON and OFF in the   ( t   ‚àí   1) -th time segment, respectively. This gives us the dual-threshold structure of the greedy policy. In the above context, the state transitions of a single cell under the greedy policy can be viewed as a Markov chain, and the state transition matrix is given by  [ 1   ‚àí   p L m   p L m  p U m   1   ‚àí   p U m  ]  ,   (15) where   p L m   ,   Pr( Àú n t m   < Œ≥ L m ) ;   p U m   ,   Pr( Àú n t m   > Œ≥ U m ) . The sta- tionary distribution of the Markov chain is  (   p U m  p L m + p U m  ,   p L m  p L m + p U m  )  , where   the   two   probabilities   correspond   to   ON   and   OFF, respectively. As a result, for a single cell, the long-term average cost of the greedy policy can be computed by  C g,m   = Pr( a t ‚àí 1  m   = 0 , a t m   = 1) C (01)  m   + Pr( a t ‚àí 1  m   = 1 , a t m   = 1) C (11)  m   + Pr( a t m   = 0) C (0)  m  =   p L m  p L m   +   p U m  p U m C (01)  m   +   p U m  p L m   +   p U m  (1   ‚àí   p L m ) C (11)  m   +  p L m  p L m   +   p U m  C (0)  m   ,  where   C (01)  m   ,   C (11)  m   , and   C (0)  m   are as defined in (11). The long- term average cost of the cell cluster is   C g   =   ‚àë M m =1   C g,m   as (14).   \u0004  Next, we analyze the connections between the greedy policy and the optimal policy.  Proposition 4   (Connections between the greedy policy and the optimal policy) .   Let   K   =   M   . For any cell in the cluster, 1) If the optimal policy instructs the gNB to turn off, the action of the greedy policy is also off. 2) If the greedy policy instructs the gNB to turn on, the optimal action is also on.\n\n6  Proof.   We prove Proposition 4 by contradiction. With the optimal policy   œÄ ‚àó , the long-term cost of the   m -th cell is given by   ‚àû ‚àë  t =1  c œÄ ‚àó   ( s t m , a t m ) .  At a time segment   t 0 , suppose the optimal action is OFF and the greedy action is ON. First, we have   c ( s t 0  m , a t 0  m   = 1)   < c ( s t 0  m , a t 0  m   = 0)   since the greedy action is ON. We can then construct a new policy as follows: i) in the   t 0 -th time segment, the new policy instructs the gNB to turn on, and ii) in any other time segments, it has the same action as the optimal policy. As can be seen, the cost incurred by the new policy differs from that of the optimal policy only in the   t 0 -th and   ( t 0   +1) -th time segments. In particular, the new policy incurs lower costs than the optimal policy since  c œÄ ‚àó   ( s t 0  m , a t 0  m   = 0) +   c œÄ ‚àó   ( s t 0 +1  m   , a t 0 +1  m   ) =   c œÄ ‚àó   ( s t 0  m , a t 0  m   = 0) +  {  f   [( Àú n t 0 +1  m   +   Œª m T s ) P e ] ,   if   a t 0 +1  m   = 0;  f   [ P static   + P switch   +( Àú n t 0 +1  m   + Œª m T s ) P d ] ,   if   a t 0 +1  m   = 1;  > c œÄ ‚àó   ( s t 0  m , a t 0  m   = 1) +  {  f   [( Àú n t 0 +1  m   +   Œª m T s ) P e ] ,   if   a t 0 +1  m   = 0;  f   [ P static   +( Àú n t 0 +1  m   + Œª m T s ) P d ] ,   if   a t 0 +1  m   = 1 ,  yielding a contradiction. As a result, for any time segments, if the optimal action is OFF, the greedy action must also be OFF. Likewise, it can be proven that when the greedy action is ON, the optimal action must also be ON; otherwise, a contradiction occurs.   \u0004  When   K   =   M   , Proposition 4 indicates that the number of ‚ÄúON‚Äù time segments under the greedy policy is no greater than that under the optimal policy. IV. T HE   I NDEX   P OLICY  The optimal policy and the greedy policy are computa- tionally expensive because the configurations of the   M   cells are coupled together, yielding decision spaces growing expo- nentially with   M   . One exception is the greedy policy with  K   =   M   , in which case the central controller can configure each cell independently and the greedy policy exhibits a dual-threshold structure. This implies that decoupling the cell configurations is a key to devising computationally efficient policies. Decoupling   the   MDP   dates   back   to   the   Whittle   index approach to solve the RMAB problem [44]. The general idea is to decouple the   M   -dimensional MDP to   M   one-dimensional MDPs, each decoupled MDP can then be solved efficiently thanks to the largely reduced state and action spaces. Inspired by Whittle‚Äôs approach [44], this paper puts forth an index policy for the on-off switching problem of gNBs.  A. The decoupled problem  To start with, we formulate the decoupled problem of (P1), i.e., the on-off switching of a single cell as opposed to the cell cluster. Specifically, we omit the constraint   ‚àë M m =1   a t m   ‚â§  M   ‚àí   K   in (2) so that the on-off configurations of gNBs are independent. For the decoupled problem, the subscript   m   is omitted in this subsection to ease exposition. The on-off switching of a single cell is a controlled Markov process defined as follows.  Definition 5   (The decoupled problem) .   Consider a single cell. The state of the cell at the beginning of the   t -th time segment is   s t   = ( a t ‚àí 1 ,   Àú n t ) , where   a t ‚àí 1   is the ON/OFF state of the cell in the   ( t   ‚àí   1) -th time segment and   Àú n t   ‚àà   N   stands for the number of users in the cell at the beginning of the   t -th time segment. The immediate cost incurred by a state-action pair ( s t   = ( a t ‚àí 1 ,   Àú n t ) , a t )   is  c ( s t , a t ) =   (16)  Ô£± Ô£¥ Ô£≤ Ô£¥ Ô£≥  f   [ P static   + ( Àú n t   +   ŒªT s ) P d  ]   ,   if   a t   =   a t ‚àí 1   = 1;  f   [ P static   +   P switch   + ( Àú n t   +   ŒªT s ) P d  ]   ,   if   a t   = 1 , a t ‚àí 1   = 0;  f   [ ( Àú n t   +   ŒªT s ) P e  ]   +   \u000f,   if   a t   = 0 ,  where   \u000f   is a cost of being OFF (which will be explained later). The optimal policy   Àú œÄ ‚àó   for the decoupled problem is defined as  ( P2 ) :   Àú œÄ ‚àó   = arg min  Àú œÄ   lim  T   ‚Üí‚àû   E  [  1  T  T   ‚àí 1 ‚àë  t =0  c ( s t , a t )  ]  .   (17) Compared with the original   M   -dimensional MDP, the de- coupled problem introduces a cost   \u000f   in (16) to penalize the OFF action. In particular, we aim to find the critical cost   \u000f ‚àó  for each state such that the expected costs incurred by turning on and off at the state are the same. In doing so, the index  \u000f ‚àó   acts as a measurement of how the controller is willing to pay to turn off the gNB. Said in another way,   \u000f ‚àó   >   0   means that the average cost for the action   a   = 0   (without the cost  \u000f ‚àó ) is smaller than that when   a   = 1 : the controller prefers to turn off this station, the larger   \u000f ‚àó   is, the more likely it is to be turned off. On the other hand,   \u000f ‚àó   <   0   means that the average cost for the action   a   = 1   is smaller, so the gNB is likely to be turned on. Given the above analysis, in the original problem with  M   cells, we can compute the corresponding indexes   \u000f ‚àó   for individual cells in each time segment according to their states. If more than   K   gNBs have positive   \u000f ‚àó , then we turn off the gNBs with   K   largest indexes. If less than   K   gNBs have positive   \u000f ‚àó , then we only turn off those with positive indexes. Next, we study how to solve the decoupled problem. As explained in Section III-A, the optimal policy of an MDP follows the Bellman equation. For the decoupled problem, the optimal policy   Àú œÄ ‚àó   follows  g ‚àó   +   h Àú œÄ ‚àó   [ s ] = min   { Q ( s, a   = 1) , Q ( s, a   = 0) }   ,   (18) where  Q ( s, a   = 1) =   c ( s, a   = 1) + Œ£ 1 , Q ( s, a   = 0) =   c ( s, a   = 0) + Œ£ 0   +   \u000f,  Œ£ 1   ,  ‚àû ‚àë  k =0  Pr( Àú n   =   k )   ¬∑   h Àú œÄ ‚àó   [ s   = (1 , k )] ,  Œ£ 0   ,  ‚àû ‚àë  k =0  Pr( Àú n   =   k )   ¬∑   h Àú œÄ ‚àó   [ s   = (0 , k )] ,\n\n7  and   Pr( Àú n   =   k )   represents the distribution of the residual users, as per (4);   h Àú œÄ ‚àó   [ s ]   is the relative value function of a state   s  under the optimal policy   Àú œÄ ‚àó ;   c ( s, a )   is the immediate cost given in (16);   g ‚àó   is gain of the decoupled MDP. To be more specific, we write one iteration of (18) in the equilibrium as follows:  Q [ s   = (1 ,   Àú n ) , a   = 1] =   f   [ P static   + ( Àú n   +   ŒªT s ) P d  ]   + Œ£ 1 , Q [ s   = (1 ,   Àú n ) , a   = 0] =   f   [ ( Àú n   +   ŒªT s ) P e  ]   + Œ£ 0   +   \u000f, h Àú œÄ ‚àó   [ s   = (1 ,   Àú n )] = min   { Q [ s   = (1 ,   Àú n ) , a   = 1] , Q [ s   = (1 ,   Àú n ) , a   = 0] }‚àí g ‚àó , Q [ s   = (0 ,   Àú n ) , a   = 1] =   f   [ P static   + P switch   +( Àú n + ŒªT s ) P d  ] +Œ£ 1 , Q [ s   = (0 ,   Àú n ) , a   = 0] =   f   [ ( Àú n   +   ŒªT s ) P e  ]   + Œ£ 0   +   \u000f, h Àú œÄ ‚àó   [ s   = (0 ,   Àú n )] = min   { Q [ s   = (0 ,   Àú n ) , a   = 1] , Q [ s   = (0 ,   Àú n ) , a   = 0] }‚àí g ‚àó .   (19) Without loss of generality, we choose state   s   = (1 ,   0)   as the reference state and set   h Àú œÄ ‚àó   [ s   = (1 ,   0)] = 0 . Eq. (19) defines the relative value function of each state under the optimal policy for a given cost   \u000f . Intuitively, the gNB of a cell has to be turned on when the number of users in the cell is large, and turned off otherwise. Inspired by the dual-threshold structure of the greedy policy when   K   =   M   , a natural question is that, does the decoupled MDP exhibits a threshold structure? In the following, we answer this question affirmatively by proving that the dual- threshold structure of the optimal policy   Àú œÄ ‚àó   to the problem (P2).  Proposition   5   (Structure   of   the   optimal   policy   Àú œÄ ‚àó ) .   The optimal policy   Àú œÄ ‚àó   for the decoupled problem (P2) is a dual- threshold policy. For a given cost   \u000f , there exists two thresholds  Œì L ,   Œì U   , and   Œì L   <   Œì U   , such that the optimal action   a t   is given by  a t   =  Ô£± Ô£¥ Ô£¥ Ô£¥ Ô£≤ Ô£¥ Ô£¥ Ô£¥ Ô£≥  1 ,   if   a t ‚àí 1   = 0   and   Àú n t   >   Œì U   ; 0 ,   if   a t ‚àí 1   = 0   and   Àú n t   ‚â§   Œì U   ; 1 ,   if   a t ‚àí 1   = 1   and   Àú n t   >   Œì L ; 0 ,   if   a t ‚àí 1   = 1   and   Àú n t   ‚â§   Œì L .  (20)  Proof.   Given a fixed   \u000f ,   h Àú œÄ ‚àó   [ s   = (1 ,   Àú n )] ,   h Àú œÄ ‚àó   [ s   = (0 ,   Àú n )] ,   Œ£ 1 , and   Œ£ 0   in (19) are constant when RVIA converges. Un- der the optimal policy, the gNB will be turned on deter- ministically in state   s   =   (1 ,   Àú n )   if   Q   [ s   = (1 ,   Àú n ) , a   = 1]   < Q   [ s   = (1 ,   Àú n ) , a   = 0] . As per (19), we have  f   [ P static   + ( Àú n   +   ŒªT s ) P d  ]   + Œ£ 1   < f   [ ( Àú n   +   ŒªT s ) P e  ]   + Œ£ 0   +   \u000f.  After some manipulation, we have  g L ( Àú n )   >   ‚àí \u000f   + Œ£ 1   ‚àí   Œ£ 0 ,  where  g L ( Àú n )   ,   f   [ ( Àú n + ŒªT s ) P e  ] ‚àí f   [ P static   +( Àú n + ŒªT s ) P d  ]  is a monotonically increasing function with   Àú n . As a result, there exists a threshold   Œì L , for a given state   s   = (1 ,   Àú n ) , if  Àú n >   Œì L , the optimal action is to turn on the gNB, otherwise, it should be turned off, and the threshold   Œì L   is the solution of the following equation:  g L (Œì L ) =   ‚àí \u000f   + Œ£ 1   ‚àí   Œ£ 0 .   (21) Likewise, for a given state   s   = (0 ,   Àú n ) , the gNB will be turned on if   Q   [ s   = (0 ,   Àú n ) , a   = 1]   < Q   [ s   = (0 ,   Àú n ) , a   = 0] . As per (19), it can be written as  g U   ( Àú n )   >   ‚àí \u000f   + Œ£ 1   ‚àí   Œ£ 0 ,  where  g U   ( Àú n )   ,   f   [ ( Àú n + ŒªT s ) P e  ] ‚àí f   [ P static   + P switch   +( Àú n + ŒªT s ) P d  ]  is also a monotonically increasing function with   Àú n , thus the threshold   Œì U   exists. For the state   s   = (0 ,   Àú n ) , if   Àú n >   Œì U   , the optimal action is to turn on the gNB, otherwise, it should be turned off, and the threshold   Œì U   is the solution of the following equation:  g U   (Œì U   ) =   ‚àí \u000f   + Œ£ 1   ‚àí   Œ£ 0 .   (22) In particular, for a given   \u000f , we have  g L (Œì L ) =   g U   (Œì U   )   (23) from (21) and (22). According to the definitions of   g L ( ¬∑ )   and  g U   ( ¬∑ ) ,   g L ( Àú n )   > g U   ( Àú n ) . Therefore,  g U   (Œì U   ) =   g L (Œì L )   > g U   (Œì L ) ,  and hence,   Œì L   <   Œì U   .   \u0004  B. The index switching policy  Given Proposition 5, we can define a ‚Äúpassive set‚Äù that con- tains all states in which the optimal action is OFF. Specifically, we define  D ( \u000f )   ,   { s   = (0 ,   Àú n ) : 0   ‚â§   Àú n   ‚â§   Œì U   ( \u000f ) ,   (24) and   s   = (1 ,   Àú n ) : 0   ‚â§   Àú n   ‚â§   Œì L ( \u000f ) }   .  Note that   Œì U   and   Œì L   are functions of   \u000f , because they are determined under a given   \u000f . According to [44] the decoupled problem is indexable if the passive set   D ( \u000f )   defined in (24) is monotonically non- increasing as   \u000f   increases. That is, for any   \u000f 1   < \u000f 2 ,   ( \u000f 1 , \u000f 2   ‚àà  R ) , the passive set   D ( \u000f 1 )   ‚äÜ D ( \u000f 2 ) . The original problem is indexable if all its decoupled problems are indexable. In the following, we shall prove that the decoupled problem (P2) is indexable, and propose an algorithm to compute the index   \u000f  for each state. Given (24), the passive set   D ( \u000f )   is monotonically non- increasing if and only if both   Œì U   ( \u000f )   and   Œì L ( \u000f )   decrease monotonically as   \u000f   increases. To prove this, we first establish the monotonicity of   H (Œì L ,   Œì U   )   ,   Œ£ 1   ‚àí   Œ£ 0   in the following.  Lemma 6.   H (Œì L ,   Œì U   ) = Œ£ 1   ‚àí   Œ£ 0   is a monotonically non- decreasing function with the increase of   Œì L   and   Œì U   . Proof.   To start with, let us define   h ( Àú n )   ,   h Àú œÄ ‚àó   [ s   = (1 ,   Àú n )]   ‚àí  h Àú œÄ ‚àó   [ s   = (0 ,   Àú n )] . It can further be written as  h ( Àú n ) =  Ô£± Ô£¥ Ô£≤ Ô£¥ Ô£≥  0 ,   Àú n   ‚â§   Œì L ( \u000f ); ‚àÜ 1 ( Àú n ) ,   Àú n >   Œì U   ( \u000f ); ‚àÜ 2 ( Àú n ) + Œ£ 1   ‚àí   Œ£ 0   ‚àí   \u000f,   Œì L ( \u000f )   <   Àú n   ‚â§   Œì U   ( \u000f ) ,  (25)\n\n8 0  ùëÑ   ùë†   =   1 ,   ‡∑§ ùëõ   ,   ùëé   =   0   =   ùëÑ   ùë†   =   0 ,   ‡∑§ ùëõ   ,   ùëé   =   0  ùëÑ   ùë†   =   1 ,   ‡∑§ ùëõ   ,   ùëé   =   1  ùëÑ   ùë†   =   0 ,   ‡∑§ ùëõ   ,   ùëé   =   1  ‚Ñé ‡∑• ùúã ‚àó   ùë†   =   1 ,   ‡∑§ ùëõ  ‚Ñé ‡∑• ùúã ‚àó   ùë†   =   0 ,   ‡∑§ ùëõ  ‚Ñé   ‡∑§ ùëõ   =   ‚Ñé ‡∑• ùúã ‚àó   ùë†   =   1 ,   ‡∑§ ùëõ   ‚àí   ‚Ñé ‡∑• ùúã ‚àó   ùë†   =   0 ,   ‡∑§ ùëõ  ‡∑§ ùëõ Œì ùêø1  Œì ùëà1  ùí´ switch  Œì ùêø2  Œì ùëà2  ùí´ switch  (a)   f   ( x ) =   x . 0  ùëÑ   ùë†   =   1 ,   ‡∑§ ùëõ   ,   ùëé   =   0   =   ùëÑ   ùë†   =   0 ,   ‡∑§ ùëõ   ,   ùëé   =   0  ùëÑ   ùë†   =   1 ,   ‡∑§ ùëõ   ,   ùëé   =   1  ùëÑ   ùë†   =   0 ,   ‡∑§ ùëõ   ,   ùëé   =   1  ‚Ñé ‡∑• ùúã ‚àó   ùë†   =   1 ,   ‡∑§ ùëõ  ‚Ñé ‡∑• ùúã ‚àó   ùë†   =   0 ,   ‡∑§ ùëõ  ‚Ñé   ‡∑§ ùëõ   =   ‚Ñé ‡∑• ùúã ‚àó   ùë†   =   1 ,   ‡∑§ ùëõ   ‚àí   ‚Ñé ‡∑• ùúã ‚àó   ùë†   =   0 ,   ‡∑§ ùëõ  ‡∑§ ùëõ Œì ùêø1  Œì ùëà1  Œì ùêø2  Œì ùëà2   (b)   f   ( x ) =   x 2 .  Figure 3: Two examples to illustrate the monotonicity of   h ( Àú n ) , where we set   f   =   x   and   f   =   x 2   in (a) and (b), respectively. where  ‚àÜ 1 ( Àú n )   ,   f   [ P static   + ( Àú n   +   ŒªT s ) P d  ]   ‚àí  f   [ P static   +   P switch   + ( Àú n   +   ŒªT s ) P d  ]   ,  ‚àÜ 2 ( Àú n )   ,   f   [ P static   + ( Àú n   +   ŒªT s ) P d  ]   ‚àí   f   [ ( Àú n   +   ŒªT s ) P e  ]   .  Note that both   ‚àÜ 1 ( Àú n )   and   ‚àÜ 2 ( Àú n )   are monotonically non- increasing functions, and   ‚àÜ 1 ( Àú n )   ‚â§   0 . Thus,   h ( Àú n )   is mono- tonically non-increasing with   Àú n , and   h ( Àú n )   ‚â§   0 .  H (Œì L ,   Œì U   )   can be written as  H   = Œ£ 1   ‚àí   Œ£ 0  =  ‚àû ‚àë  k =0  Pr( Àú n   =   k )   ¬∑ { h Àú œÄ ‚àó   [ s   = (1 , k )]   ‚àí   h Àú œÄ ‚àó   [ s   = (0 , k )] }  =  ‚àû ‚àë  k =0  Pr( Àú n   =   k )   ¬∑   h ( k ) .   (26) Appendix   B   proves   that   h ( Àú n )   is   monotonically   non- decreasing in   Œì L   and   Œì U   . Thus,  H (Œì L 1 ,   Œì U   )   ‚àí   H (Œì L 2 ,   Œì U   ) =  ‚àû ‚àë  k =0  Pr( Àú n   =   k )   ¬∑   [ h ( k,   Œì L 1 ,   Œì U   )   ‚àí   h ( k,   Œì L 2 ,   Œì U   ) ]   ‚â§   0 ,  when   Œì L 1   <   Œì L 2 , i.e.,   H (Œì L ,   Œì U   )   is a monotonically non- increasing function in   Œì L . And  H (Œì L ,   Œì U   1 )   ‚àí   H (Œì L ,   Œì U   2 ) =  ‚àû ‚àë  k =0  Pr( Àú n   =   k )   ¬∑   [ h ( k,   Œì L ,   Œì U   1 )   ‚àí   h ( k,   Œì L ,   Œì U   2 ) ]   ‚â§   0 ,  when   Œì U   1   <   Œì U   2 , i.e.,   H (Œì L ,   Œì U   )   is a monotonically non- increasing function in   Œì U   .   \u0004  To illustrate the monotonicity of   H (Œì L ,   Œì U   )   established in Lemma 6, two examples are given in Fig. 3 with   f   =   x  and   f   =   x 2 , respectively. For the linear function in Fig. 3(a),  Q [ s, a   = 0]   and   Q [ s, a   = 1]   are linear in   Àú n , as per (19), and   Q [ s   = (1 ,   Àú n ) , a   = 0]   ‚àí   Q [ s   = (1 ,   Àú n ) , a   = 1] =   P switch . Therefore,   both   the   state   value   h Àú œÄ ‚àó   [ s ]   and   h ( Àú n )   defined in   (25)   are   piecewise   linear.   When   we   increase   the   two thresholds from   (Œì L 1 ,   Œì U   1 )   to   (Œì L 2 ,   Œì U   2 ) ,   h ( Àú n )   is monotoni- cally non-decreasing, hence   H (Œì L ,   Œì U   )   is monotonically non- decreasing. The same results can be observed from Fig. 3(b). Next, we derive upper and lower bounds for   H (Œì L ,   Œì U   )  based on its monotonicity.  Lemma 7.   H (Œì L ,   Œì U   )   is bounded by  E   ‚â§   H (Œì L ,   Œì U   )   ‚â§   0 ,   (27)  where   E   ,   ‚àë ‚àû  k =0   Pr( Àú n   =   k )‚àÜ 1 ( k )   is a constant and   ‚àÜ 1 ( k )  is defined in   (25) . Proof.   From the definition of   h ( Àú n )   in (25), we have   h ( Àú n )   ‚â§   0 ,  ‚àÄ Àú n   ‚â•   0 . Thus,   H (Œì L ,   Œì U   )   ‚â§   0 , as per (26). Since   H (Œì L ,   Œì U   )  is monotonically non-decreasing with the increase of   Œì L   and  Œì U   , we have  H (Œì L ,   Œì U   )   ‚â•   H (Œì L ,   0) =  ‚àû ‚àë  k =0  Pr( Àú n   =   k )   ¬∑   h ( k )  ( a )  =  ‚àû ‚àë  k =0  Pr( Àú n   =   k )   ¬∑   ‚àÜ 1 ( k )   ,   E,   (28) where   E   is a constant;   ( a )   holds because the gNB is ON in all states when   Œì U   ‚â§   0 , and hence,   h ( Àú n ) = ‚àÜ 1 ( Àú n ) ,   ‚àÄ Àú n , according to (25).   \u0004  Given the above analysis, we are ready to prove the index- ability of the decoupled problem.  Theorem 8.   The decoupled problem (P2) is indexable. Proof.   (sketch) The decoupled problem (P2) is indexable if and only if the passive set   D ( \u000f )   in (24) is monotonically non- increasing in   \u000f . Based on (23), consider any two costs   \u000f 1   6   =  \u000f 2 . If   Œì L ( \u000f 1 )   >   Œì L ( \u000f 2 ) , then   g L   [ Œì L ( \u000f 1 ) ]   > g L   [ Œì L ( \u000f 2 ) ]  and   g U   [ Œì U   ( \u000f 1 ) ]   > g U   [ Œì U   ( \u000f 2 ) ] , hence   Œì U   ( \u000f 1 )   >   Œì U   ( \u000f 2 ) . In contrast, if   Œì L ( \u000f 1 )   <   Œì L ( \u000f 2 ) , we have   Œì U   ( \u000f 1 )   <   Œì U   ( \u000f 2 ) . This means that   Œì L ( \u000f )   and   Œì U   ( \u000f )   have the same monotonicity in   \u000f . Therefore, we only need to prove that   Œì U   ( \u000f )   is monotonically non-increasing. Detailed proof is given in Appendix C.   \u0004  So far, we have established the indexability of the decoupled problem. The only issue left is how to compute the index for each state. For a given state   s t   = ( a t ‚àí 1 ,   Àú n t ) , the index   \u000f ‚àó ( s t )   corre- sponds to the cost of turning off the gNB, and can be computed by setting   Q ( s, a   = 1) =   Q ( s, a   = 0) , i.e.,  c ( s, a   = 1) + Œ£ 1   =   c ( s, a   = 0) + Œ£ 0   +   \u000f ‚àó ( s ) .  More specifically, for the class of states   s   = (1 ,   Àú n ) , the index  \u000f ‚àó [ s   = (1 ,   Àú n )]   corresponds to the case   Œì L ( \u000f ‚àó ) =   Àú n ; for the\n\n9  Algorithm 1   Index computation via gradient descent.  Input:   s t   = ( a t ‚àí 1 ,   Àú n t )  Pick an initial value   \u000f 0 . Set an error   Œæ >   0   and a step size   Œ≤ >   0 .  k   ‚Üê   0 Œì( \u000f k )   ‚Üê   Àú n t  F   ( \u000f k ) =   Œæ   + 1  while   F   ( \u000f k )   > Œæ   do  \u000f k +1   =   \u000f k   ‚àí   Œ≤   ¬∑   ( Àú n   ‚àí   Œì( \u000f k ))  Calculate   h Àú œÄ ‚àó   by RVIA for the decoupled problem using  \u000f k +1 . Calculate   Œì( \u000f k +1 )   by (21) or (22).  F   ( \u000f k +1 )   ‚Üê   1 2   [Œì( \u000f k +1 )   ‚àí   Àú n ] 2  k   ‚Üê   k   + 1  \u000f ‚àó ( s t ) =   \u000f k  Output:   \u000f ‚àó ( s t )  class of states   s   = (0 ,   Àú n ) , on the other hand, the index   \u000f ‚àó [ s   = (0 ,   Àú n )]   corresponds to the case   Œì U   ( \u000f ‚àó ) =   Àú n . Therefore, the index of a state can be obtained by solving   Œì L ( \u000f ‚àó ) =   Àú n   or  Œì U   ( \u000f ‚àó ) =   Àú n . Deriving the closed-form   \u000f   for each state is challenging as the two thresholds   Œì L   and   Œì U   do not have explicit expressions. Thus, we resort to a numerical approach to compute   \u000f   in the following. Define  Œì( \u000f )   ,  {  Œì L ( \u000f ) ,   if   s   = (1 ,   Àú n ) ,  Œì U   ( \u000f ) ,   if   s   = (0 ,   Àú n ) ,   (29)  F   ( \u000f )   ,   1 2  [Œì( \u000f )   ‚àí   Àú n ] 2   .   (30) Then, the index   \u000f   of a state   s   is the optimal   \u000f   that mini- mizes   F   ( \u000f ) . According to Theorem 8,   Œì L ( \u000f )   and   Œì U   ( \u000f )   are monotonically decreasing in   \u000f , hence the local minimum of  F   ( \u000f )   is also the global minimum. The optimal   \u000f   can then be found by gradient descent, where the gradient of   F   ( \u000f )   can be approximated by  dF   ( \u000f )  d\u000f   = (Œì( \u000f )   ‚àí   Àú n )   d Œì( \u000f )  d\u000f   ‚âà   Àú n   ‚àí   Œì( \u000f ) ,   (31) where the approximation follows because   Œì( \u000f )   is monoton- ically decreasing according to Theorem 8. Given (31), The gradient descent approach to compute the index is summarized in Algorithm 1. The index policy for the original   M   -dimensional problem (P1) can be summarized as follows.  Definition 6   (The index policy) .   At the beginning of the   t -th time segment, the state of the cell cluster   s t   =   { s t  1 , s t  2 ,   ¬∑ ¬∑ ¬∑   , s t M   } . With the index policy   œÄ ind , an index is first computed for each cell:   \u000f ‚àó ( s t m ) ,   m   = 1 ,   2 , ..., M   . The actions are given by  a t  ind   =   œÄ ind ( s t ) = ( a t  ind , 1 , a t  ind , 2 ,   ¬∑ ¬∑ ¬∑   , a t  ind ,M   ) > ,   (32)  where  a t  ind ,m   =  {  0 ,   if   \u000f ‚àó ( s t m )   ‚â•   0   and   \u000f ‚àó ( s t m )   ‚àà I nd t ; 1 ,   others , Cell to be turned off   Cell to be turned on  Cell 1   Cell 2   Cell 3   Cell 4   Cell 5  Cell 1   Cell 2   Cell 3   Cell 4   Cell 5 Cell 1   Cell 2   Cell 3   Cell 4   Cell 5  Cell 1   Cell 2   Cell 3   Cell 4   Cell 5  Cell 1   Cell 2   Cell 3   Cell 4   Cell 5 Cell 1   Cell 2   Cell 3   Cell 4   Cell 5  1  2  3  4  5  6  Time   segment   ON/OFF state of each cell  Figure 4: An illustration of the round-robin policy.  and   I nd t   consists of   K   largest elements of   { \u000f ‚àó ( s t  1 ) , \u000f ‚àó ( s t  2 ) ,  ¬∑ ¬∑ ¬∑   , \u000f ‚àó ( s t M   ) } .  V. L OWER   B OUND AND   S TATE -I NDEPENDENT   P OLICIES  As discussed in Section III-A, the optimal policy for the dynamic on-off switching problem is computationally pro- hibitive, especially when   M   is large. To evaluate the perfor- mance of the index policy, this section constructs lower and upper bounds as benchmarks.  Theorem 9   (Lower bound of the average cost) .   A lower bound of the average cost in   (1)   is given by  L B   =  M ‚àë  m =1  C (0)  m   +  M ‚àë  m =1  ‚àë  `>Œ≥ L m  ‚àÜ 2 ,m ( ` )   ¬∑   Pr( Àú n m   =   ` ) ,   (33)  where  ‚àÜ 2 ,m ( ` )   ,   f   [ P static   + ( `   +   Œª m T s ) P d  ]   ‚àí   f   [ ( `   +   Œª m T s ) P e  ]   , `   ‚àà   N ,   C (0)  m   is the anticipated cost of a time segment when  a t m   = 0   and it is defined in   (11) ,   Œ≥ L m   =   P static  P e ‚àíP d   ‚àí   Œª m T s   is a threshold defined in Theorem 3, and   Pr( Àú n m   =   ` )   can be calculated by   (4) . Proof.   See Appendix D.   \u0004  Next, we analyze the performance of two state-independent policies, i.e., the uniform policy and the round-robin policy, as upper bounds of the optimal policy. With the uniform policy, we turn off   K   gNBs uniformly at random in each time segment. Its performance is characterized in Proposition 10.  Proposition 10   (Performance of the uniform policy) .   The long-term average cost of the uniform policy is given by  C uniform   =  M ‚àë  m =1  [  C (01)  m   ¬∑   (1   ‚àí   K/M   )   ¬∑   K/M   (34)  + C (11)  m   ¬∑   (1   ‚àí   K/M   ) 2   +   C (0)  m   ¬∑   K/M  ]  ,  where   C (01)  m   ,   C (11)  m   and   C (0)  m   are defined in   (11) . Proof.   See Appendix E.   \u0004  The round-robin policy, on the other hand, turns off the gNBs in a deterministic order, an example of which is shown in Fig. 4. As can be seen, there are five 5G cells in the cluster and three gNBs will be turned off in each time segment. With\n\n10  the round-robin policy, each gNB will be turned off in   K  consecutive time segments and turned on in the following   M   ‚àí  K   consecutive time segments. Its performance is characterized in Proposition 11.  Proposition 11   (Performance of the round-robin policy) .   The long-term average cost of the round-robin policy is given by  C round   =  Ô£± Ô£¥ Ô£¥ Ô£¥ Ô£¥ Ô£¥ Ô£≤ Ô£¥ Ô£¥ Ô£¥ Ô£¥ Ô£¥ Ô£≥ ‚àë M m =1   C (11)  m   ,   K   = 0;  ‚àë M m =1   C (0)  m   ,   K   =   M   ;  1  M  ‚àë M m =1  [  C (0)  m   K   +   C (01)  m  + C (11)  m   ( M   ‚àí   K   ‚àí   1)  ]  ,   0   < K < M,  (35)  where   C (01)  m   ,   C (11)  m   and   C (0)  m   are as defined in   (11) . Proof.   See Appendix F.   \u0004  As can be seen, the long-term average cost of the round- robin policy is linear with   K   when   0   < K < M   , and is discontinuous when   K   = 0   and   K   =   M   . In the following, we compare the performance of these two state-independent policies. When   K   = 0   (or   K   =   M   ), their performances are the same. When   0   < K < M   , their difference is  C diff   ,   C round   ‚àí   C uniform   (36)  =   K 2   ‚àí   M K   +   M M   2  M ‚àë  m =1  C (01)  m   ‚àí   C (11)  m  =   K 2   ‚àí   M K   +   M M   2   C diff ,  where   C diff   ,   ‚àë M m =1   C (01)  m   ‚àí   C (11)  m   is a constant and we have  C diff   >   0   when   P switch   >   0 . As shown in (36), the difference   C diff   is quadratic in   K , the maximum   C diff-max   is achieved when   K   = 1   and   K   =   M   ‚àí   1 , and the minimum or   C diff-min   is achieved when   K   =   M/ 2   (for even   M   ) or   K   = ( M   ¬±   1) / 2   (for odd   M   ). Specifically,  C diff-max   =   1  M   2   C diff ,   K   = 1   or   M   ‚àí   1;  C diff-min   =  {   4 ‚àí M  4 M   C diff ,   K   =   M/ 2;  ‚àí M   2 +4 M   +1 4   C diff ,   K   = ( M   ¬±   1) / 2 .  As a result, the uniform policy is strictly better than the round-robin policy when 1)   K   = 1   or   M   ‚àí   1 , in which case   C diff-max   >   0 ; 2)   M <   4 , in which case   C diff-min   >   0 . VI. N UMERICAL AND   S IMULATION   R ESULTS  This section presents numerical and simulation results to evaluate   various   policies   analyzed   in   this   paper,   i.e.,   the optimal policy, the greedy policy, the index policy, and the state-independent policies. In particular, we measure the per- formance of a policy by the gap between the long-term average cost of this policy and the lower bound given in Theorem 9. That is:  ‚àÜ policy   ,   C policy   ‚àí   L B  L B  √ó   100%   (37) Table I: Parameter settings.  Physical Quantities   Symbols   Values   Units  Average power/gNB/user   P d   1   W Average power of macro BS/user   P e   5   W Static power/gNB   P static   85   W Switching power/gNB   P switch   40   W Time segment duration   T s   1800   s Mean service time/user   1 /Œº   500   s User arrival rate   Œõ   {   0 . 005 0 . 01 0 . 015 0 . 02  }   /s Sampling probabilities   Pr(Œõ)  Set1:   { 0 ,   1 ,   0 ,   0 }  Set2:   { 0 . 5 ,   0 ,   0 . 5 ,   0 }  Set3:   { 2 / 3 ,   0 ,   0 ,   1 / 3 }  Set4:   { 0 . 3 ,   0 . 4 ,   0 . 3 ,   0 }  Set5:   { 0 . 6 ,   0 ,   0 . 2 ,   0 . 2 } ùêæ  Figure 5: Performance of different switching policies versus  K , where   M   = 4 ,   Pr(Œõ) =   { 2 / 3 ,   0 ,   0 ,   1 / 3 } , and   f   ( x ) =   x 2 . where the lower bound   L B   is defined in (33) and   C policy  denotes the long-term average cost of an evaluated policy over the infinite-time horizon. The parameter settings are presented in Table I unless specified otherwise. Specifically, as [14], [25], [45], we set the average power consumption of a gNB for serving a single user to   P d   = 1 W; the static power consumption of a gNB  P static   = 85 W; the switching power consumption of a gNB  P switch   = 50 W. The average power consumption of the ng- eNB for serving a single user   P e   is set to 5W. The duration of a time segment   T s   is set to 1800s. Users‚Äô arrival to a cell follows a mixed Poisson process with a set of parameters  Œõ   =   { 0 . 005 ,   0 . 01 ,   0 . 015 ,   0 . 02 } .   We   consider   five   sets   of sampling probabilities   Pr(Œõ) , as listed in Table I. The mean service time of a user is set to   1 /Œº   = 500 s [27]. We consider three kinds of cost functions   f   in this paper: the quadratic function   f   ( x ) =   x 2 ; the piecewise linear function  f   ( x ) =  Ô£± Ô£¥ Ô£≤ Ô£¥ Ô£≥  0 . 5 x,   if   x   ‚â§   100;  x   ‚àí   50 ,   if   100   < x   ‚â§   150; 1 . 5 x   ‚àí   125 ,   if   x >   150;  and the linear function   f   ( x ) =   x . According to (9), the optimal policy is computationally prohibited for large   M   . Thus, in the first simulation, we consider a small cluster with   M   = 4   5G cells and evaluate the performance of various policies benchmarked against the\n\n11 Time segments Number of users  Time segments Number of users  Time segments Number of users  Time segments Number of users  Figure 6: The dual-threshold structure of the greedy policy, where   M   =   K   = 4 ,   Pr(Œõ) =   { 2 / 3 ,   0 ,   0 ,   1 / 3 } , and   f   ( x ) =  x 2 . optimal policy. The simulation results are presented in Fig. 5, where we plot   ‚àÜ policy   as a function of   K . As can be seen, the index policy achieves the same performance as the optimal policy and outperforms the other policies. The greedy policy is better than state-independent policies. The cost of the uniform policy   ‚àÜ uniform   increases quadratically in   K , as predicted in (34). The cost of the round-robin policy   ‚àÜ round-robin , on the other hand, increases linearly when   1   ‚â§   K   ‚â§   M   ‚àí   1 , as predicted in (35). Recall from Theorem 3 that the greedy policy exhibits a dual-threshold structure when   K   =   M   . This is verified in Fig. 6, where we set   K   =   M   = 4 . For each 5G cell, we plot the number of residual users at the beginning of a time segment and the corresponding ON/OFF actions of the greedy policy. As shown, for each cell, the greedy policy presents a dual-threshold structure: when the number of residual users   Àú n  at the beginning of a time segment is smaller than   Œ≥ L m , the gNB will be turned off; when   Àú n   is larger than   Œ≥ U m , the gNB will be turned on; when   Œ≥ L m   ‚â§   Àú n   ‚â§   Œ≥ U m , the ON/OFF state of a gNB remains unchanged. In the second simulation, we evaluate the impact of user arrival distributions on the performance of various switching policies. Specifically, we extend the simulation in Fig. 5 to different user arrival distributions considering the five sets of   Pr(Œõ)   listed in Table   I (note that the mean user arrival rates are the same under the five sets of distributions). The simulation results are presented in Fig. 7. As shown, the index policy always achieves close-to-optimal performance under different sets of   Pr(Œõ) . In the third simulation, we consider a larger cluster with  M   = 12   cells, in which case the performance of the optimal policy is no longer available, and we shall consider different cost functions   f   ( x ) . Fig. 8 and 9 present the performance of various policies versus   K   with the piecewise linear and linear cost functions, respectively. We have similar observations as that from Fig. 5, the index policy achieves the best perfor- Set 1   Set   2   Set   3   Set   4   Set   5  Figure 7: Impact of user arrival distributions   Pr(Œõ)   on the performance of various switching policies, where   M   =   K   = 4  and   f   ( x ) =   x 2 . ùêæ  Figure 8: Performance of different switching policies versus  K , where   M   = 12 ,   Pr(Œõ) =   { 2 / 3 ,   0 ,   0 ,   1 / 3 } , and   f   ( x )   is a piecewise linear function. mance among all switching policies and the properties of other policies match our predictions. Next, we compare the performance of the uniform and round-robin policies in more detail to verify our analysis in Section V. As can be seen from Fig. 10, the uniform policy is strictly better than the round-robin policy when   M <   4   and  K   = 1   or   K   =   M   ‚àí   1 . In other cases, the round-robin policy can be better than the uniform policy. It is worth noting that the optimality of the greedy policy is determined by the switching cost   P switch . In the extreme case where the switching cost is zero and frequent switching is allowed, the greedy policy is optimal. In Fig. 11, we evaluate the impact of the switching cost by reducing the power consumption of switching from   P switch   =   40 W to  P switch   = 10 W. In the simulation, we consider a linear cost function   f   ( x ) =   x   and   M   = 4 . As shown, with the decrease in the switching cost, the gap between the greedy policy and the optimal policy reduces. For the case of   K   = 2   and   P switch   = 20 W in Fig. 11, we further analyze the compositions of power consumption when operated with different policies. As can be seen from Fig. 12, the index policy has almost the same composition\n\n12 ùêæ  Figure 9: Performance of different switching policies versus  K , where   M   = 12 ,   Pr(Œõ) =   { 2 / 3 ,   0 ,   0 ,   1 / 3 } , and   f   ( x ) =   x . ùëÄ   =   3   ùëÄ   =   4   ùëÄ   =   5   ùëÄ   =   6  ùêæ  Figure 10: Comparison of the two state-independent policies, where   Pr(Œõ) =   { 2 / 3 ,   0 ,   0 ,   1 / 3 } , and   f   ( x ) =   x 2 . of power consumption as the optimal policy, verifying that the index policy is close-to-optimal. The compositions of the greedy policy, on the other hand, are much more different. In general, the greedy policy is more inclined to turn off the gNBs compared with the optimal policy, and hence, incurs more   power   consumption   of   the   ng-eNB   and   less   power consumption of the gNBs. A piece of theoretical evidence is given in Proposition 4, where we have proven that the number of ‚ÄúON‚Äù time segments with the greedy policy is no greater than that with the optimal policy when   K   =   M   . In addition, the greedy policy incurs more switching cost compared with the optimal policy. VII. C ONCLUSION  To achieve energy-conserving 5G RAN, this paper put forth a dynamic on-off switching paradigm for gNB sleep control by taking the evolvements of users and their traffic demands into account. Formulating the dynamic sleep control for a cluster of gNBs as an MDP, we characterized the optimal policy for the MDP that minimizes the long-term average cost, where cost is a non-decreasing function of system energy expenditure. The optimal policy, however, is computationally demanding and is available only when the number of gNBs is small. ùêæ  ùí´ ùë†ùë§ùëñùë°ùëê‚Ñé   =   10 W ùí´ ùë†ùë§ùëñùë°ùëê‚Ñé   =   20 W  ùí´ ùë†ùë§ùëñùë°ùëê‚Ñé   =   30 W  ùí´ ùë†ùë§ùëñùë°ùëê‚Ñé   =   40 W  new  Figure 11: Impact of the switching power consumption on the greedy policy and the optimal policy, where   M   = 4 ,   P switch   = 20 W,   Pr(Œõ) =   { 2 / 3 ,   0 ,   0 ,   1 / 3 } , and   f   ( x ) =   x . Optimal  Consumption (W)  Greedy   Uniform   Round - robin Index  new  Figure 12: The compositions of the power consumption for different policies, where   M   = 4 ,   P switch   = 20 W,   K   = 2 ,  Pr(Œõ) =   { 2 / 3 ,   0 ,   0 ,   1 / 3 } , and   f   ( x ) =   x . To meet this challenge, we proposed a greedy policy and an index policy and analyzed their performances benchmarked against   the   optimal   policy   and   state-independent   policies. When making on-off switching decisions, the greedy policy focuses only on the immediate effect of the decisions while omitting their long-term impacts. We proved the dual-threshold structure of the greedy policy when there is no constraint on the number of gNBs that can be turned off, and analyzed its connections with the optimal policy. On the other hand, the index policy assigns an index to each gNB as a measurement of how one is willing to pay to turn off the gNB. The gNBs with relatively larger indexes are then turned off when making switching decisions. To develop the index policy, we decoupled the original MDP, proved the indexibility of the decoupled MDP, and proposed an algorithm to compute the index. Although heuristic, the index policy exhibits close- to-optimal performance and outperforms the greedy policy and state-independent policies. Furthermore, it is much more computationally efficient than the optimal policy. To summarize, our study validated the effectiveness of gNB sleep control in achieving an energy-efficient 5G RAN. Under the established dynamic on-off switching paradigm, we\n\n13  demonstrated that the proposed switching policies can reduce the system energy expenditure by a large margin, providing useful operational insights for practical 5G RAN. A PPENDIX   A P ROOF OF   P ROPOSITION   1 Considering the   ( t ‚àí 1) -th time segment, the   m -th cell serves two sets of users: the newly arrived users as well as the residual users from the   ( t ‚àí 2) -th time segment. For simplicity, we refer to the two sets as   G n   and   G r   , respectively. At the end of the  ( t   ‚àí   1) -th time segment, the number of residual users in the cell can be written as  Àú n t m   =   ` t ‚àí 1  m   +   Àú ` t ‚àí 1  m   ,  where   ` t ‚àí 1  m   and   Àú ` t ‚àí 1  m   are the number of residual users from  G n   and   G r   , respectively. First,   ` t ‚àí 1  m   can be written as  ` t ‚àí 1  m   =  n t ‚àí 1  m ‚àë  n =1  I ( T s , Œæ n , œÑ n ) ,  where   œÑ n   and   Œæ n   denote the arrival epoch and staying time of the   n -th user in   G n , respectively;   n t ‚àí 1  m   follows the mixed Poisson distribution and   Œæ n   follows the exponential distribution as   described   in   Definition   4;   The   function   I ( ¬∑ )   indicates whether the   n -th user is still in the cell at the end of the  ( t   ‚àí   1) -th time segment. That is,  I ( T s , Œæ n , œÑ n ) =  {  1 ,   if   T s   ‚àí   œÑ n   ‚â§   Œæ n ; 0 ,   otherwise .  For a specific parameter   Œª j   ‚àà   Œõ   of the mixed Poisson pro- cess,   ` t ‚àí 1  m   is a filtered Poisson process [46]. The characteristic function of   ` t ‚àí 1  m   can be written as  œÜ ` t ‚àí 1  m   ,   E [ e jœâ` t ‚àí 1  m   ] =   E  Ô£Æ Ô£∞ exp  Ô£´ Ô£≠ jœâ  n t ‚àí 1  m ‚àë  n =1  I ( T s , Œæ n , œÑ n )  Ô£∂ Ô£∏ Ô£π Ô£ª  =   E n t ‚àí 1  m   , { œÑ n }  {  E { Œæ n }  [  exp  (  jœâ  n ‚àó  ‚àë  n =1  I ( T s , Œæ n , œÑ n )  )]  | n t ‚àí 1  m   =   n ‚àó ,   { œÑ n } }   .   (38) Let   B n ( T s , œÑ n )   ,   E Œæ n   [exp ( jœâI ( T s , Œæ n , œÑ n ))] , (38) can be refined as  œÜ ` t ‚àí 1  m   =   E n t ‚àí 1  m   , { œÑ n }  [   n ‚àó  ‚àè  n =1  B n ( T s , œÑ n )   ‚à£ ‚à£ n t ‚àí 1  m   =   n ‚àó ,   { œÑ n }  ]  =   E n t ‚àí 1  m  [  E { œÑ n }  (   n ‚àó  ‚àè  n =1  B n ( T s , œÑ n )  )  ‚à£ ‚à£ n t ‚àí 1  m   =   n ‚àó  ]  ( a )  =   E n t ‚àí 1  m  [ ‚à´   T s  0  ‚à´   œÑ n ‚àó  0  ¬∑ ¬∑ ¬∑  ‚à´   œÑ 2  0  n ‚àó  ‚àè  n =1  B n ( T s , œÑ n )   n !  T   n ‚àó  s  dœÑ 1   ¬∑ ¬∑ ¬∑   dœÑ n ‚àó ‚àí 1 dœÑ n ‚àó  ‚à£ ‚à£ n t ‚àí 1  m   =   n ‚àó   ]  =   E n t ‚àí 1  m  [  1  T   n ‚àó  s  ‚à´   T s  0  ‚à´   T s  0  ¬∑ ¬∑ ¬∑  ‚à´   T s  0  n ‚àó  ‚àè  n =1  B n ( T s , œÑ n )  dœÑ 1   ¬∑ ¬∑ ¬∑   dœÑ n ‚àó ‚àí 1 dœÑ n ‚àó  ‚à£ ‚à£ n t ‚àí 1  m   =   n ‚àó   ]  ( b )  =   E n t ‚àí 1  m  Ô£Æ Ô£∞ (  1  T s  ‚à´   T s  0  B ( T s , œÑ   ) dœÑ  ) n t ‚àí 1  m  Ô£π Ô£ª  ( c )  =   G n t ‚àí 1  m  (  1  T s  ‚à´   T s  0  B ( T s , œÑ   ) dœÑ  )  ,   (39) where   ( a )   follows because the arrival epochs   œÑ n   ( n   = 1 ,   2 ,  ¬∑ ¬∑ ¬∑   , n t ‚àí 1  m   )   given   n t ‚àí 1  m   have a distribution as the order statistics sampled from a uniform distribution [46];   ( b )   follows because all   œÑ n   has the same distribution such that the subscript   n   can be omitted;   ( c )   follows from the definition of the moment generating function   G X   ( z )   ,   E ( z X   ) . Note that the random variable   n t ‚àí 1  m   follows the Poisson distribution, (39) can be further written as  œÜ ` t ‚àí 1  m   = exp  [  Œª j   T s  (  1  T s  ‚à´   T s  0  B ( T s , œÑ   ) dœÑ   ‚àí   1  )]  .   (40) In particular,   B ( T s , œÑ   )   is given by  B ( T s , œÑ   ) =   E Œæ   [exp( jœâI ( T s , Œæ, œÑ   ))] = Pr[ I ( T s , Œæ, œÑ   ) = 0] +   e jœâ   ¬∑   Pr[ I ( T s , Œæ, œÑ   ) = 1] = Pr[ I ( T s , Œæ, œÑ   ) = 1]   ¬∑   ( e jœâ   ‚àí   1) + 1 =  (‚à´   ‚àû  T s ‚àí œÑ  f Œæ   ( Œæ ) dŒæ  )  ¬∑   ( e jœâ   ‚àí   1) + 1  ( a )  =   e ‚àí Œº m ( T s ‚àí œÑ   )   ¬∑   ( e jœâ   ‚àí   1) + 1 ,   (41) where   ( a )   holds   because   the   staying   time   Œæ   follows   the exponential distribution with parameter   Œº m . By substituting (41) into (40), we have  œÜ ` t ‚àí 1  m   = exp  (   Œª j  Œº m  (1   ‚àí   e ‚àí Œº m T s   )( e jœâ   ‚àí   1)  )  = exp[ Àú Œª m,j   ( e jœâ   ‚àí   1)] ,  where   Àú Œª m,j   =   Œª j  Œº m   (1 ‚àí e ‚àí Œº m T s   )   is a constant. By Taylor series expansion, we have  œÜ ` t ‚àí 1  m   =   e ‚àí Àú Œª m,j   e Àú Œª m,j   ¬∑ e jœâ  =   e ‚àí Àú Œª m,j  ‚àû ‚àë  ` =0  ( Àú Œª m,j  ) `  ¬∑   e jœâ`  ` !   .   (42) Note that the characteristic function   œÜ ` t ‚àí 1  m   in (38) can also be written as  œÜ ` t ‚àí 1  m   =   E [ e jœâ` t ‚àí 1  m   ] =  ‚àû ‚àë  ` =0  Pr( ` t ‚àí 1  m   =   ` )   ¬∑   e jœâ` .   (43) Comparing the coefficients of each items in (42) and (43) yields  Pr( ` t ‚àí 1  m   =   ` ) =  ( Àú Œª m,j  ) `  ` !   e ‚àí Àú Œª m,j   .  For the mixed Poisson process,   Œª j   is sampled from   Œõ   with probability   p m,j   . Thus, the probability distribution of   ` t ‚àí 1  m   is given by  Pr( ` t ‚àí 1  m   =   ` ) =  J ‚àë  j =1  p m,j   Pr( ` t ‚àí 1  m   =   ` | Œª j   )\n\n14  =  J ‚àë  j =1  p m,j  ( Àú Œª m,j  ) `  ` !   e ‚àí Àú Œª m,j   .  On the other hand, for a user in the set   G r   , the probability that it departs from the cell during the   t -th segment is  p re   =  ‚à´   T s  0  Œº m e ‚àí Œº m t dt   = 1   ‚àí   e ‚àí Œº m T s   .  Thus,   Àú ` t ‚àí 1  m   follows  Pr( Àú ` t ‚àí 1  m   =   ` ) =  ( Àú n t ‚àí 1  m  `  )  ( p re ) Àú n t ‚àí 1  m   ‚àí ` (1   ‚àí   p re ) ` ,  for   `   = 0 ,   1 ,   2 ,   ¬∑ ¬∑ ¬∑   ,   Àú n t ‚àí 1  m   . Notice that the gNB switching cannot be too frequent. For a relatively large   T s , we have   p re   ‚Üí   1   and   Pr( Àú ` t ‚àí 1  m   >   0)   ‚Üí   0 . This implies that the residual users from the set   G r   can be omitted. As a result, we arrive at (4). And the average   Àú n t m   is  E [ Àú n t m ] =   ‚àë J j =1   p m,j   E ( Àú n t m | Œª j   ) =   ‚àë J j =1   p m,j   Àú Œª m,j   . A PPENDIX   B P ROOF OF THE NON - DECREASING MONOTONICITY OF   h ( Àú n )  IN   Œì L   AND   Œì U  Let us write   h ( Àú n )   as a function of   Œì L   and   Œì U   :  h ( Àú n,   Œì L ,   Œì U   ) =  Ô£± Ô£¥ Ô£≤ Ô£¥ Ô£≥  0 ,   Àú n   ‚â§   Œì L ; ‚àÜ 1 ( Àú n ) ,   Àú n >   Œì U   ; ‚àÜ 2 ( Àú n ) +   H ‚Ä≤ (Œì L ,   Œì U   ) ,   Œì L   <   Àú n   ‚â§   Œì U   ,  where   H ‚Ä≤ (Œì L ,   Œì U   )   ,   Œ£ 1   ‚àí   Œ£ 0   ‚àí   \u000f   is independent of   Àú n . By treating   Àú n   as a positive real value, we have  {  ‚àÜ 2 ( Àú n ) +   H ‚Ä≤ (Œì L ,   Œì U   ) = 0 ,   Àú n   = Œì L ,  ‚àÜ 2 ( Àú n ) +   H ‚Ä≤ (Œì L ,   Œì U   ) = ‚àÜ 1 ( Àú n ) ,   Àú n   = Œì U   ,  i.e.,   {  ‚àÜ 2 (Œì L ) +   H ‚Ä≤ (Œì L ,   Œì U   ) = 0 ,  ‚àÜ 2 (Œì U   ) +   H ‚Ä≤ (Œì L ,   Œì U   ) = ‚àÜ 1 (Œì U   ) .   (44) For   any   two   real   values   Œì L 1   <   Œì L 2 ,   we   analyze  h ( Àú n,   Œì L 1 ,   Œì U   )   ‚àí   h ( Àú n,   Œì L 2 ,   Œì U   )   as follows: 1) When   Àú n   ‚â§   Œì L 1 , we have  h ( Àú n,   Œì L 1 ,   Œì U   ) = 0 , h ( Àú n,   Œì L 2 ,   Œì U   ) = 0 ,  hence   h ( Àú n,   Œì L 1 ,   Œì U   )   ‚àí   h ( Àú n,   Œì L 2 ,   Œì U   ) = 0 . 2) When   Œì L 1   <   Àú n   ‚â§   Œì L 2 , we have  h ( Àú n,   Œì L 1 ,   Œì U   ) = ‚àÜ 2 ( Àú n ) +   H ‚Ä≤ (Œì L 1 ,   Œì U   )   ‚â§   0 , h ( Àú n,   Œì L 2 ,   Œì U   ) = 0 ,  then   h ( Àú n,   Œì L 1 ,   Œì U   )   ‚àí   h ( Àú n,   Œì L 2 ,   Œì U   )   =   ‚àÜ 2 ( Àú n ) +  H ‚Ä≤ (Œì L 1 ,   Œì U   )   ‚â§   0 . 3) When   Œì L 2   <   Àú n   ‚â§   Œì U   , we have  h ( Àú n,   Œì L 1 ,   Œì U   ) = ‚àÜ 2 ( Àú n ) +   H ‚Ä≤ (Œì L 1 ,   Œì U   ) , h ( Àú n,   Œì L 2 ,   Œì U   ) = ‚àÜ 2 ( Àú n ) +   H ‚Ä≤ (Œì L 2 ,   Œì U   ) ,  then  h ( Àú n,   Œì L 1 ,   Œì U   )   ‚àí   h ( Àú n,   Œì L 2 ,   Œì U   ) =   H ‚Ä≤ (Œì L 1 ,   Œì U   )   ‚àí   H ‚Ä≤ (Œì L 2 ,   Œì U   )  ( a )  =   ‚àí ‚àÜ 2 (Œì L 1 ) + ‚àÜ 2 (Œì L 2 )   ( b )  ‚â§   0 ,  where   ( a )   follows from (44);   ( b )   follows because   ‚àÜ 2   is a monotonically non-increasing function and   Œì L 1   <   Œì L 2 . 4) When   Àú n >   Œì U   , we have  h ( Àú n,   Œì L 1 ,   Œì U   ) = ‚àÜ 1 ( Àú n ) , h ( Àú n,   Œì L 2 ,   Œì U   ) = ‚àÜ 1 ( Àú n ) ,  hence   h ( Àú n,   Œì L 1 ,   Œì U   )   ‚àí   h ( Àú n,   Œì L 2 ,   Œì U   ) = 0 . To summarize, we have   h ( Àú n,   Œì L 1 ,   Œì U   )   ‚àí   h ( Àú n,   Œì L 2 ,   Œì U   )   ‚â§   0  when   Œì L 1   <   Œì L 2 . Likewise, for   Œì U   1   <   Œì U   2 , we compute   h ( Àú n,   Œì L ,   Œì U   1 )   ‚àí  h ( Àú n,   Œì L ,   Œì U   2 )   as follows. 1) When   Àú n   ‚â§   Œì L , we have  h ( Àú n,   Œì L ,   Œì U   1 ) = 0 , h ( Àú n,   Œì L ,   Œì U   2 ) = 0 ,  hence   h ( Àú n,   Œì L ,   Œì U   1 )   ‚àí   h ( Àú n,   Œì L ,   Œì U   2 ) = 0 . 2) When   Œì L   <   Àú n   ‚â§   Œì U   1 , we have  h ( Àú n,   Œì L ,   Œì U   1 ) = ‚àÜ 2 ( Àú n ) +   H ‚Ä≤ (Œì L ,   Œì U   1 ) , h ( Àú n,   Œì L ,   Œì U   2 ) = ‚àÜ 2 ( Àú n ) +   H ‚Ä≤ (Œì L ,   Œì U   2 ) ,  then  h ( Àú n,   Œì L ,   Œì U   1 )   ‚àí   h ( Àú n,   Œì L ,   Œì U   2 ) =   H ‚Ä≤ (Œì L ,   Œì U   1 )   ‚àí   H ‚Ä≤ (Œì L ,   Œì U   2 )  ( a )  =   [ ‚àÜ 1 (Œì U   1 )   ‚àí   ‚àÜ 2 (Œì U   1 ) ]   ‚àí   [ ‚àÜ 1 (Œì U   2 )   ‚àí   ‚àÜ 2 (Œì U   2 ) ]  ( b )  =   g U   (Œì U   1 )   ‚àí   g U   (Œì U   2 )   ( c )  ‚â§   0 ,  where   ( a )   follows from (44);   ( b )   follows because  ‚àÜ 1 (Œì U   ) ‚àí ‚àÜ 2 (Œì U   ) =   f   [ (Œì U   + ŒªT s ) P e  ]   ‚àí  f   [ P static   + P switch   +(Œì U   + ŒªT s ) P d  ]  =   g U   (Œì U   );  and   ( c )   follows   because   g U   (Œì U   )   is   a   monotonically increasing function and   Œì U   1   <   Œì U   2 . 3) When   Œì U   1   <   Àú n   ‚â§   Œì U   2 , we have  h ( Àú n,   Œì L ,   Œì U   1 ) = ‚àÜ 1 ( Àú n ) , h ( Àú n,   Œì L ,   Œì U   2 ) = ‚àÜ 2 ( Àú n ) +   H ‚Ä≤ (Œì L ,   Œì U   2 ) ,  then,   h ( Àú n,   Œì L ,   Œì U   1 ) ‚àí h ( Àú n,   Œì L ,   Œì U   2 ) = ‚àÜ 1 ( Àú n ) ‚àí ‚àÜ 2 ( Àú n ) ‚àí  H ‚Ä≤ (Œì L ,   Œì U   2 )   =   g U   ( Àú n )   ‚àí   H ‚Ä≤ (Œì L ,   Œì U   2 ) . As   g U   ( Àú n )   is a monotonically increasing function and   g U   (Œì U   2 )   =  H ‚Ä≤ (Œì L ,   Œì U   2 ) , we have   g U   ( Àú n )   ‚àí   H ‚Ä≤ (Œì L ,   Œì U   2 )   ‚â§   0   when  Àú n   ‚â§   Œì U   2 . 4) When   Àú n >   Œì U   2 , we have  h ( Àú n,   Œì L ,   Œì U   1 ) = ‚àÜ 1 ( Àú n ) , h ( Àú n,   Œì L ,   Œì U   2 ) = ‚àÜ 1 ( Àú n ) ,  hence   h ( Àú n,   Œì L ,   Œì U   1 )   ‚àí   h ( Àú n,   Œì L ,   Œì U   2 ) = 0 . To summarize, we have   h ( Àú n,   Œì L ,   Œì U   1 )   ‚àí   h ( Àú n,   Œì L ,   Œì U   2 )   ‚â§   0  when   Œì U   1   <   Œì U   2 . As a result,   h ( Àú n )   is monotonically non-decreasing in   Œì L  and   Œì U   .\n\n15  A PPENDIX   C P ROOF OF THE DECREASING MONOTONICITY OF   Œì U   ( \u000f )  1) When   \u000f   ‚â• ‚àí g U   (0) , we have  g U   [ Œì U   ( \u000f ) ]   =   ‚àí \u000f   +   H   [ Œì L ( \u000f ) ,   Œì U   ( \u000f ) ]  ‚â§   g U   (0) + 0 =   g U   (0) .  As   g U   ( ¬∑ )   is a monotonically increasing function, we have  Œì U   ( \u000f )   ‚â§   0 , hence   Àú n   ‚â•   Œì U   ( \u000f ) ,   ‚àÄ Àú n   ‚â•   0 . Therefore,   H   =   E  and is a constant, where   E   is defined in (27). In this case,  g U   [ Œì U   ( \u000f ) ]   =   ‚àí \u000f   +   E   is monotonically decreasing in   \u000f , hence   Œì U   ( \u000f )   is also monotonically decreasing in   \u000f . 2) When   \u000f <   ‚àí g U   (0) , for any two costs   \u000f 1   < \u000f 2   <   ‚àí g U   (0) , we have  g U   [ Œì U   ( \u000f 1 ) ]   =   ‚àí \u000f 1   +   H   [ Œì L ( \u000f 1 ) ,   Œì U   ( \u000f 1 ) ]  >   ‚àí \u000f 2   +   H   [ Œì L ( \u000f 1 ) ,   Œì U   ( \u000f 1 ) ]  ,   g U   [ Œì U   ( \u000f (1) ) ]   .   (45) In particular, we have   Œì L ( \u000f (1) )   <   Œì L ( \u000f 1 )   since   g U   ( ¬∑ )   is a monotonically increasing function. Further, we have  g U   [ Œì U   ( \u000f (1) ) ]   =   ‚àí \u000f 2   +   H   [ Œì L ( \u000f 1 ) ,   Œì U   ( \u000f 1 ) ]  ( a )  >   ‚àí \u000f 2   +   H   [ Œì L ( \u000f (1) ) ,   Œì U   ( \u000f (1) ) ]  ,   g U   [ Œì U   ( \u000f (2) ) ]   ,  where   ( a )   follows because   H   is a monotonically non- decreasing function in   Œì L   and   Œì U   , according to Lemma 6. In   the   above   manner,   we   can   construct   a   sequence { Œì U   ( \u000f ( i ) ) , i   = 1 ,   2 ,   ¬∑ ¬∑ ¬∑ } , where   Œì U   ( \u000f (1) )   is defined in (45), and the others follow  g U   [ Œì U   ( \u000f ( i ) ) ]   =   ‚àí \u000f 2   +   H   [ Œì L ( \u000f ( i ‚àí 1) ) ,   Œì U   ( \u000f ( i ‚àí 1) ) ]  ( a )  >   ‚àí \u000f 2   +   H   [ Œì L ( \u000f ( i ) ) ,   Œì U   ( \u000f ( i ) ) ]  =   g U   [ Œì U   ( \u000f ( i +1) ) ]   , i   = 2 ,   3 ,   ¬∑ ¬∑ ¬∑   ,   (46) where   ( a )   can be proven by mathematical induction. As can be seen,   { Œì U   ( \u000f ( i ) ) , i   = 1 ,   2 ,   ¬∑ ¬∑ ¬∑ }   is a monotonically decreasing sequence. In particular,   ‚àÄ i   ‚â•   2 ,  g U   [ Œì U   ( \u000f ( i ) ) ]   =   ‚àí \u000f 2   +   H   [ Œì L ( \u000f ( i ‚àí 1) ) ,   Œì U   ( \u000f ( i ‚àí 1) ) ]  > g U   (0) +   E.  To summarize,   g U   is monotonically non-decreasing and lower bounded by a constant   g U   (0) +   E . This sug- gests that there exists a lower bound for the sequence { Œì U   ( \u000f ( i ) ) } . Since   { Œì U   ( \u000f ( i ) ) }   monotonically decreases, we can denote its lower bound by   Œì U   ( \u000f ( ‚àû ) ) . In particular, according to (46), we can write  g U   [ Œì U   ( \u000f ( ‚àû ) ) ]   =   ‚àí \u000f 2   +   H   [ Œì L ( \u000f ( ‚àû ) ) ,   Œì U   ( \u000f ( ‚àû ) ) ]   .  Note that   g U   [ Œì U   ( \u000f 2 ) ]   =   ‚àí \u000f 2   +   H   [ Œì L ( \u000f 2 ) ,   Œì U   ( \u000f 2 ) ] , we have   \u000f ( ‚àû )   =   \u000f 2 , and  Œì U   ( \u000f 2 ) = Œì U   ( \u000f ( ‚àû ) )   ( a )  <   Œì U   ( \u000f (1) )   ( b )  <   Œì U   ( \u000f 1 ) ,   (47) where   ( a )   follows because   { Œì U   ( \u000f ( i ) ) }   is a monotonically decreasing sequence;   ( b )   follows from (45). As a result, we have   Œì U   ( \u000f 2 )   <   Œì U   ( \u000f 1 )   for   ‚àÄ \u000f 1   < \u000f 2   <   ‚àí Œì U   (0) , i.e.,  Œì U   ( \u000f )   is monotonically decreasing with   \u000f . Finally, we conclude that   Œì U   ( \u000f )   is monotonically decreasing in   \u000f . A PPENDIX   D P ROOF OF   T HEOREM   9 When the states are in equilibrium, we can rewrite (1) as  C œÄ   =   lim  T   ‚Üí‚àû   E  [  1  T  T   ‚àí 1 ‚àë  t =0  M ‚àë  m =1  c ( s t m , a t m )  ]  ( a )  =  M ‚àë  m =1  E [ c ( s m , a m )] ,   (48) where   ( a )   holds because the mean values of the cost will not change with time when in equilibrium, and the superscript   t  can be omitted. As   P switch   ‚â•   0 , the immediate cost of the   m -th cell   c ( s m , a m )   satisfies the following inequality  c ( s m , a m ) =   f   [ P ( s m , a m )]  ‚â•  {  f   [ P static   + ( Àú n m   +   Œª m T s ) P d  ]   ,   if   a m   = 1;  f   [ ( Àú n m   +   Œª m T s ) P e  ]   ,   if   a m   = 0 .  As shown,   c ( s m , a m )   is only dependent on the ON/OFF state and the number of users. We define a variable   œÅ m ( Àú n m )   to express the probability of turning on the   m -th gNB given the user number   Àú n m , and   0   ‚â§   œÅ m ( Àú n m )   ‚â§   1 . Then   E [ c ( s m , a m )]  in (48) can be written as  E [ c ( s m , a m )] =  ‚àû ‚àë  ` =0  E [ c ( s m , a m ) | Àú n m   =   ` ]   ¬∑   Pr( Àú n m   =   ` )  ‚â•  ‚àû ‚àë  ` =0  { œÅ m ( ` )   ¬∑   f   [ P static   + ( `   +   Œª m T s ) P d  ]  + [1   ‚àí   œÅ m ( ` )]   ¬∑   f   [ ( `   +   Œª m T s ) P e  ]}   ¬∑   Pr( Àú n m   =   ` ) =   C (0)  m   +  ‚àû ‚àë  ` =0  œÅ m ( ` )   ¬∑   ‚àÜ 2 ,m ( ` )   ¬∑   Pr( Àú n m   =   ` ) .  The lower bound of the average cost for the   m -th cell is given by  L B   ( E [ c ( s m , a m )])   ,   (49)  min  { œÅ m }   C (0)  m   +  ‚àû ‚àë  ` =0  œÅ m ( ` )   ¬∑   ‚àÜ 2 ,m ( ` )   ¬∑   Pr( Àú n m   =   ` ) .  By setting each   œÅ m ( Àú n m ) , the minimum value in (49) can be achieved. A valid solution is given by  œÅ m ( Àú n m ) =  {  0 ,   if   ‚àÜ 2 ,m ( Àú n m )   ‚â•   0; 1 ,   if   ‚àÜ 2 ,m ( Àú n m )   <   0 .   (50) As   f   is a non-decreasing function, (50) can be also written as  œÅ m ( Àú n m ) =  {  0 ,   if   Àú n m   ‚â§   P static  P e ‚àíP d   ‚àí   Œª m T s   =   Œ≥ L m ; 1 ,   if   Àú n m   >   P static  P e ‚àíP d   ‚àí   Œª m T s   =   Œ≥ L m ,\n\n16  where   Œ≥ L m   is defined in Theorem 3. Then the lower bound of the average cost for the   m -th cell can be calculated as  L B   ( E [ c ( s m , a m )]) =   C (0)  m   +   ‚àë  `>Œ≥ L m  ‚àÜ 2 ,m ( ` )   ¬∑   Pr( Àú n m   =   ` ) .   (51) If we ignore the constraint   ‚àë M m =1   a t m   ‚â§   M   ‚àí   K   in (2) so that the ON/OFF configurations of gNBs are independent, then the average cost in (48) follows  C œÄ   =  M ‚àë  m =1  E [ c ( s m , a m )]  ‚â•  M ‚àë  m =1  ‚àû ‚àë  ` =0  œÅ m ( ` )   ¬∑   ‚àÜ 2 ,m ( ` )   ¬∑   Pr( Àú n m   =   ` ) +  M ‚àë  m =1  C (0)  m   ,  and the lower bound of the average cost is given by  L B   ( C œÄ   )   ,   (52)  min  M ‚àë  m =1  ‚àû ‚àë  ` =0  œÅ m ( ` )   ¬∑   ‚àÜ 2 ,m ( ` )   ¬∑   Pr( Àú n m   =   ` ) +  M ‚àë  m =1  C (0)  m   .  As the ON/OFF configurations of gNBs are independent,  L B   ( C œÄ   )   in (52) can be calculated by  L B   ( C œÄ   ) =  M ‚àë  m =1  L B   ( E [ c ( s m , a m )]) .   (53) Substituting (51) into (53), we arrive at (33). A PPENDIX   E P ROOF OF   P ROPOSITION   10 Under the uniform policy, we can rewrite (48) as  C uniform   =  M ‚àë  m =1  E [ c ( s m , a m )]   (54)  =  M ‚àë  m =1  [  C (01)  m   ¬∑   Pr( a t ‚àí 1  m   = 0 , a t m   = 1) + C (11)  m   ¬∑   Pr( a t ‚àí 1  m   = 1 , a t m   = 1) + C (0)  m   ¬∑   Pr( a t m   = 0)  ]  .  In each time segment,   K   gNBs are turned off uniformly at random, we have  Pr( a t m   = 0) =   K/M ,   Pr( a t m   = 1) = 1   ‚àí   K/M,  Pr( a t ‚àí 1  m   = 0 , a t m   = 1) = Pr( a t ‚àí 1  m   = 0)   ¬∑   Pr( a t m   = 1) = (1   ‚àí   K/M   )   ¬∑   K/M,  Pr( a t ‚àí 1  m   = 1 , a t m   = 1) = Pr( a t ‚àí 1  m   = 1)   ¬∑   Pr( a t m   = 1) = (1   ‚àí   K/M   ) 2 .  Substituting the above equations into (54), we arrive at (34). A PPENDIX   F P ROOF OF   P ROPOSITION   11 First, when   K   = 0 , all the gNBs will be always turned on, hence the long-term average cost is  C round   =  M ‚àë  m =1  E   { f   [ P static   +( Àú n t m   + Œª m T s ) P d  ]}   =  M ‚àë  m =1  C (11)  m   .  When   K   =   M   , all the gNBs will be always turned off, so the long-term average cost is  C round   =  M ‚àë  m =1  E { f   [ ( Àú n t m   + Œª m T s ) P e  ]}   =  M ‚àë  m =1  C (0)  m   .  When   0   < K < M   , every   M   time segments can be viewed as a cycle, and the long-term average cost is equal to the cost in one cycle. Thus, the cost can be calculated as  C round   =   E  [  1  M  M   ‚àí 1 ‚àë  t =0  M ‚àë  m =1  c ( s t m , a t m )  ]  =  1  M  M ‚àë  m =1  M   ‚àí 1 ‚àë  t =0  E [ c ( s t m , a t m )] =  1  M  M ‚àë  m =1  [  C (0)  m   K   + C (11)  m   ( M   ‚àí K   ‚àí 1)+ C (01)  m  ]  .  To summarize, we arrive at (35). R EFERENCES [1]   I. P. Chochliouros, M.-A. Kourtis, A. S. Spiliopoulou, P. Lazaridis, Z. Zaharis, C. Zarakovitis, and A. Kourtis, ‚ÄúEnergy efficiency concerns and trends in future 5G network infrastructures,‚Äù   Energies , vol. 14, no. 17, 2021. [2]   D. L¬¥ opez-P¬¥ erez, A. De Domenico, N. Piovesan, G. Xinli, H. Bao, S. Qitao, and M. Debbah, ‚ÄúA survey on 5G radio access network energy efficiency: Massive MIMO, lean carrier design, sleep modes, and machine learning,‚Äù   IEEE Communications Surveys & Tutorials , vol. 24, no. 1, pp. 653‚Äì697, 2022. [3]   A. Israr, Q. Yang, W. Li, and A. Y. Zomaya, ‚ÄúRenewable energy powered sustainable 5G network infrastructure: Opportunities, challenges and perspectives,‚Äù   Journal of Network and Computer Applications , vol. 175, p. 102910, 2021. [4]   Y. Shao, D. G¬® und¬® uz, and S. C. Liew, ‚ÄúFederated learning with mis- aligned over-the-air computation,‚Äù   IEEE Transactions on Wireless Com- munications , vol. 21, no. 6, pp. 3951 ‚Äì 3964, 2021. [5]   C.-L. I, S. Han, and S. Bian, ‚ÄúEnergy-efficient 5G for a greener future,‚Äù  Nature Electronics , vol. 3, no. 4, pp. 182‚Äì184, 2020. [6]   3GPP, ‚ÄúRelease 15: Technical specification group services and system aspects,‚Äù Technical Specification (TS) 21.915, 2019. [7]   C.   Dongxu,   ‚Äú5G   power:   Creating   a   green   grid   that   slashes   costs, emissions & energy use,‚Äù   Technical report, Huawei , 2021. [8]   J. B. Rao and A. O. Fapojuwo, ‚ÄúA survey of energy efficient resource management techniques for multicell cellular networks,‚Äù   IEEE Commu- nications Surveys & Tutorials , vol. 16, no. 1, pp. 154‚Äì180, 2014. [9]   S. Buzzi, C.-L. I, T. E. Klein, H. V. Poor, C. Yang, and A. Zappone, ‚ÄúA survey of energy-efficient techniques for 5G networks and challenges ahead,‚Äù   IEEE Journal on Selected Areas in Communications , vol. 34, no. 4, pp. 697‚Äì709, 2016. [10]   F. Salahdine, J. Opadere, Q. Liu, T. Han, N. Zhang, and S. Wu, ‚ÄúA survey on sleep mode techniques for ultra-dense networks in 5G and beyond,‚Äù   Computer Networks , vol. 201, p. 108567, 2021. [11]   Y. Shao, S. C. Liew, and L. Lu, ‚ÄúAsynchronous physical-layer network coding: symbol misalignment estimation and its effect on decoding,‚Äù  IEEE Transactions on Wireless Communications , vol. 16, no. 10, pp. 6881‚Äì6894, 2017. [12]   Y. Shao and S. C. Liew, ‚ÄúFlexible subcarrier allocation for interleaved frequency division multiple access,‚Äù   IEEE Transactions on Wireless Communications , vol. 19, no. 11, pp. 7139‚Äì7152, 2020.\n\n17  [13]   K. Son, H. Kim, Y. Yi, and B. Krishnamachari, ‚ÄúBase station operation and user association mechanisms for energy-delay tradeoffs in green cellular networks,‚Äù   IEEE Journal on Selected Areas in Communications , vol. 29, no. 8, pp. 1525‚Äì1536, 2011. [14]   N. Saxena, A. Roy, and H. Kim, ‚ÄúTraffic-aware cloud RAN: A key for green 5G networks,‚Äù   IEEE Journal on Selected Areas in Communica- tions , vol. 34, no. 4, pp. 1010‚Äì1021, 2016. [15]   M. Deruyck, W. Joseph, and L. Martens, ‚ÄúPower consumption model for macrocell and microcell base stations,‚Äù   Transactions on Emerging Telecommunications Technologies , vol. 25, no. 3, pp. 320‚Äì333, 2014. [16]   S. K. G. Peesapati, M. Olsson, M. Masoudi, S. Andersson, and C. Cav- dar, ‚ÄúAn analytical energy performance evaluation methodology for 5G base stations,‚Äù in   International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob) , 2021. [17]   L. J. Woon, G. Ramasamy, and S. P. Thiagarajah, ‚ÄúPeak power shaving in   hybrid   power   supplied   5G   base   station,‚Äù   Bulletin   of   Electrical Engineering and Informatics , vol. 10, no. 1, pp. 62‚Äì69, 2021. [18]   Q. Wu, X. Chen, Z. Zhou, L. Chen, and J. Zhang, ‚ÄúDeep reinforcement learning with spatio-temporal traffic forecasting for data-driven base station sleep control,‚Äù   IEEE/ACM Transactions on Networking , vol. 29, no. 2, pp. 935‚Äì948, 2021. [19]   S.   Krishnasamy,   P.   T.   Akhil,   A.   Arapostathis,   R.   Sundaresan,   and S.   Shakkottai,   ‚ÄúAugmenting   max-weight   with   explicit   learning   for wireless scheduling with switching costs,‚Äù   IEEE/ACM Transactions on Networking , vol. 26, no. 6, pp. 2501‚Äì2514, 2018. [20]   J. GONG, S. ZHOU, and Z. NIU, ‚ÄúA dynamic programming approach for base station sleeping in cellular networks,‚Äù   IEICE Transactions on Communications , vol. E95.B, no. 2, pp. 551‚Äì562, 2012. [21]   M. Feng, S. Mao, and T. Jiang, ‚ÄúBase station on-off switching in 5G   wireless networks: Approaches and challenges,‚Äù   IEEE Wireless Communications , vol. 24, no. 4, pp. 46‚Äì54, 2017. [22]   F. Han, S. Zhao, L. Zhang, and J. Wu, ‚ÄúSurvey of strategies for switching off base stations in heterogeneous networks for greener 5G systems,‚Äù  IEEE Access , vol. 4, pp. 4959‚Äì4973, 2016. [23]   J. Peng, P. Hong, and K. Xue, ‚ÄúStochastic analysis of optimal base station energy saving in cellular networks with sleep mode,‚Äù   IEEE Communications Letters , vol. 18, no. 4, pp. 612‚Äì615, 2014. [24]   C. Liu, B. Natarajan, and H. Xia, ‚ÄúSmall cell base station sleep strategies for energy efficiency,‚Äù   IEEE Transactions on Vehicular Technology , vol. 65, no. 3, pp. 1652‚Äì1661, 2016. [25]   N. Lassoued, N. Boujnah, and R. Bouallegue, ‚ÄúReducing power con- sumption in C-RAN using switch on/off of MC-RRH sectors and small cells,‚Äù   IEEE Access , vol. 9, pp. 75 668‚Äì75 682, 2021. [26]   G. Yu, Q. Chen, and R. Yin, ‚ÄúDual-threshold sleep mode control scheme for small cells,‚Äù   IET Communications , vol. 8, no. 11, pp. 2008 ‚Äì 2016, 2014. [27]   J. W. Park, D.-S. Yoo, and S.-J. Oh, ‚ÄúUser-number threshold-based small-cell on/off control scheme: Performance evaluation and optimiza- tion,‚Äù   IEEE Transactions on Wireless Communications , vol. 19, no. 1, pp. 367‚Äì379, 2020. [28]   Y. Shi, J. Zhang, and K. B. Letaief, ‚ÄúGroup sparse beamforming for green cloud-RAN,‚Äù   IEEE Transactions on Wireless Communications , vol. 13, no. 5, pp. 2809‚Äì2823, 2014. [29]   Y.   Yang,   L.   Chen,   W.   Dong,   and   W.   Wang,   ‚ÄúActive   base   station set optimization for minimal energy consumption in green cellular networks,‚Äù   IEEE Transactions on Vehicular Technology , vol. 64, no. 11, pp. 5340‚Äì5349, 2015. [30]   E. Oh, K. Son, and B. Krishnamachari, ‚ÄúDynamic base station switching- on/off strategies for green cellular networks,‚Äù   IEEE Transactions on Wireless Communications , vol. 12, no. 5, pp. 2126‚Äì2136, 2013. [31]   W. Zhao and S. Wang, ‚ÄúTraffic density-based RRH selection for power saving in C-RAN,‚Äù   IEEE Journal on Selected Areas in Communications , vol. 34, no. 12, pp. 3157‚Äì3167, 2016. [32]   H. Fourati, R. Maaloul, L. Fourati, and M. Jmaiel, ‚ÄúAn efficient energy- saving scheme using genetic algorithm for 5G heterogeneous networks,‚Äù  IEEE Systems Journal , pp. 1‚Äì10, 2022. [33]   F. E. Salem, T. Chahed, E. Altman, A. Gati, and Z. Altman, ‚ÄúOptimal policies of advanced sleep modes for energy-efficient 5G networks,‚Äù in  IEEE International Symposium on Network Computing and Applications (NCA) , 2019, pp. 1‚Äì7. [34]   J. Gong, J. S. Thompson, S. Zhou, and Z. Niu, ‚ÄúBase station sleeping and resource allocation in renewable energy powered cellular networks,‚Äù  IEEE Transactions on Communications , vol. 62, no. 11, pp. 3801‚Äì3813, 2014. [35]   F. Elsherif, E. K. P. Chong, and J.-H. Kim, ‚ÄúEnergy-efficient base station control framework for 5G cellular networks based on markov decision process,‚Äù   IEEE Transactions on Vehicular Technology , vol. 68, no. 9, pp. 9267‚Äì9279, 2019. [36]   J. Ye and Y.-J. A. Zhang, ‚ÄúDRAG: Deep reinforcement learning based base station activation in heterogeneous networks,‚Äù   IEEE Transactions on Mobile Computing , vol. 19, no. 9, pp. 2076‚Äì2087, 2020. [37]   R. Li, Z. Zhao, X. Chen, J. Palicot, and H. Zhang, ‚ÄúTACT: A transfer actor-critic learning framework for energy saving in cellular radio access networks,‚Äù   IEEE Transactions on Wireless Communications , vol. 13, no. 4, pp. 2000‚Äì2011, 2014. [38]   K. Zhang, X. Wen, Y. Chen, and Z. Lu, ‚ÄúDeep reinforcement learning for energy saving in radio access network,‚Äù in   IEEE/CIC International Conference on Communications in China , 2020. [39]   M. L. Puterman,   Markov decision processes: discrete stochastic dynamic programming .   John Wiley & Sons, 2014. [40]   Y. Shao, A. Rezaee, S. C. Liew, and V. W. S. Chan, ‚ÄúSignificant sampling for shortest path routing: a deep reinforcement learning solution,‚Äù   IEEE Journal on Selected Areas in Communications , vol. 38, no. 10, pp. 2234‚Äì 2248, 2020. [41]   3GPP, ‚ÄúStudy on new radio access technology: Radio access architecture and interfaces,‚Äù Release 14, Technical Specification (TS) 38.801, 2017. [42]   B. Ghojogh, A. Ghojogh, M. Crowley, and F. Karray, ‚ÄúFitting a mixture distribution to data: Tutorial,‚Äù   arXiv:1901.06708 , 2019. [43]   Y. Shao, Q. Cao, S. C. Liew, and H. Chen, ‚ÄúPartially observable minimum-age scheduling: the greedy policy,‚Äù   IEEE Transactions on Communications , vol. 70, no. 1, pp. 404 ‚Äì 418, 2021. [44]   P. Whittle, ‚ÄúRestless bandits: activity allocation in a changing world,‚Äù  Journal of Applied Probability , vol. 25, no. A, p. 287‚Äì298, 1988. [45]   W. Roh, J.-Y. Seol, J. Park, B. Lee, J. Lee, Y. Kim, J. Cho, K. Cheun, and F. Aryanfar, ‚ÄúMillimeter-wave beamforming as an enabling technology for 5G cellular communications: theoretical feasibility and prototype results,‚Äù   IEEE Communications Magazine , vol. 52, no. 2, pp. 106‚Äì113, 2014. [46]   D. L. Snyder and M. I. Miller,   Random point processes in time and space .   Springer Science & Business Media, 2012.",
      "embedding": [
        -0.02485288679599762,
        0.042138438671827316,
        0.03660392016172409,
        0.02512102574110031,
        0.031351279467344284,
        -0.03894203156232834,
        0.04415634647011757,
        -0.008672453463077545,
        0.02304917387664318,
        0.05147209390997887,
        -0.1278749406337738,
        0.0023897341452538967,
        0.04609095677733421,
        -0.06552732735872269,
        0.026057766750454903,
        0.045816391706466675,
        0.08372648805379868,
        -0.009232349693775177,
        -0.04551200568675995,
        0.0015722336247563362,
        0.0733509287238121,
        -0.021161410957574844,
        0.04208974912762642,
        -0.028835507109761238,
        0.005755848716944456,
        -0.017964622005820274,
        0.05178235471248627,
        -0.015915391966700554,
        -0.018870403990149498,
        -0.0007069863495416939,
        -0.025450468063354492,
        0.0005031140171922743,
        0.04976542294025421,
        -0.07341146469116211,
        -0.046333108097314835,
        0.03187702223658562,
        -0.07737371325492859,
        -0.004101673141121864,
        -0.032238785177469254,
        0.03724462166428566,
        0.007923025637865067,
        0.009786923415958881,
        -0.046961747109889984,
        0.010229293256998062,
        -0.08021093904972076,
        0.022277100011706352,
        -0.05893746763467789,
        0.02220306545495987,
        -0.051657892763614655,
        -0.0574595108628273,
        0.08158066868782043,
        -0.03791683912277222,
        -0.07611413300037384,
        0.06579821556806564,
        0.07460195571184158,
        -0.016247287392616272,
        -0.015981484204530716,
        0.021579500287771225,
        0.06988157331943512,
        0.024496620520949364,
        -0.009444030001759529,
        -0.001660175621509552,
        0.00027890174533240497,
        -0.046753231436014175,
        0.03541915491223335,
        0.05228012427687645,
        0.012044291943311691,
        0.01441988442093134,
        -0.029541894793510437,
        0.004265209659934044,
        -0.05661403015255928,
        -0.010640758089721203,
        -0.0435086227953434,
        -0.06853622198104858,
        -0.07279537618160248,
        -0.01054874062538147,
        0.05906933918595314,
        0.05845107138156891,
        0.09314743429422379,
        -0.0013456842862069607,
        0.009651409462094307,
        0.07105405628681183,
        0.024685828015208244,
        -0.1145157516002655,
        -0.013210952281951904,
        -0.0653562992811203,
        -0.04942675307393074,
        0.02783721126616001,
        0.16308368742465973,
        -0.07971978932619095,
        0.03018840216100216,
        0.15118743479251862,
        -0.025412969291210175,
        0.02291507087647915,
        0.1152101457118988,
        -0.029762500897049904,
        -0.04496694356203079,
        -0.0260273776948452,
        0.017797550186514854,
        0.04509598761796951,
        0.048821885138750076,
        -0.011390876024961472,
        0.034085940569639206,
        0.002564601134508848,
        0.028958585113286972,
        -0.07553089410066605,
        0.009835491888225079,
        0.045895908027887344,
        0.033983759582042694,
        -0.03267570585012436,
        0.019249984994530678,
        0.09307543188333511,
        0.01723860576748848,
        -0.007841067388653755,
        -0.06029564514756203,
        0.0682436153292656,
        0.07021758705377579,
        0.0015987805090844631,
        0.0378604456782341,
        0.05408059433102608,
        -0.03826941177248955,
        -0.06340017914772034,
        0.06198602914810181,
        -0.07103388756513596,
        0.031021684408187866,
        -0.02388600818812847,
        -0.05814165994524956,
        1.5717197010218945e-33,
        -0.03389761969447136,
        -0.0172418262809515,
        -0.02333616279065609,
        -0.11006751656532288,
        0.04010452330112457,
        -0.006576569750905037,
        0.01815018616616726,
        -0.006231984123587608,
        -0.05253131315112114,
        -0.013978635892271996,
        -0.02056766115128994,
        0.040033746510744095,
        -0.04312864691019058,
        0.009264083579182625,
        0.11310675740242004,
        -0.05981010943651199,
        -0.008882859721779823,
        0.031008724123239517,
        0.07194841653108597,
        -0.12024672329425812,
        0.05411841720342636,
        -0.005151805933564901,
        0.04036514461040497,
        -0.01474600750952959,
        0.0026201196014881134,
        -0.000699987227562815,
        -0.006514677777886391,
        -0.13922539353370667,
        0.00959804467856884,
        0.028311649337410927,
        -0.03219141438603401,
        -0.04608706384897232,
        -0.010952824726700783,
        -0.026686720550060272,
        0.006544625386595726,
        0.019565129652619362,
        -0.022784410044550896,
        0.007591931615024805,
        0.0033585182391107082,
        -0.04827375337481499,
        -0.05387585237622261,
        -0.015074148774147034,
        0.0705208107829094,
        -0.014576024375855923,
        -0.07555905729532242,
        -0.014616982080042362,
        0.039828937500715256,
        -0.03225351870059967,
        -0.0028750807978212833,
        0.015928156673908234,
        0.011205672286450863,
        -0.048934802412986755,
        -0.016254320740699768,
        -0.05706999450922012,
        -0.040211040526628494,
        -0.04701368510723114,
        0.013212988153100014,
        0.09094205498695374,
        0.023833265528082848,
        0.14234359562397003,
        -0.022296961396932602,
        -0.003931062761694193,
        0.033320557326078415,
        0.017204349860548973,
        0.029125260189175606,
        0.029046252369880676,
        -0.0637582391500473,
        -0.007124465890228748,
        0.04626040905714035,
        -0.005754375364631414,
        0.03352171182632446,
        -0.05161671340465546,
        0.11801332235336304,
        -0.047394558787345886,
        0.0049887606874108315,
        0.00032621578429825604,
        0.052268195897340775,
        -0.004663539119064808,
        -0.14239054918289185,
        -0.01703573390841484,
        -0.04287135601043701,
        0.01508645061403513,
        -0.04655075445771217,
        -0.11960331350564957,
        0.011064812541007996,
        -0.08724921941757202,
        0.023957496508955956,
        -0.012017091736197472,
        -0.09878360480070114,
        0.025412438437342644,
        -0.026905475184321404,
        -0.004234691616147757,
        0.04999284818768501,
        -0.005149334203451872,
        -0.0015458745183423162,
        -8.24950088628077e-34,
        0.0033978503197431564,
        -0.024094685912132263,
        0.0034484637435525656,
        -0.008804082870483398,
        0.022662349045276642,
        -0.017392180860042572,
        -0.0032699580769985914,
        -0.10946208983659744,
        -0.06355106085538864,
        -0.044500745832920074,
        -0.050735633820295334,
        0.001834774506278336,
        0.0018687959527596831,
        0.028514442965388298,
        0.0024157122243195772,
        -0.03195501118898392,
        -0.013473371043801308,
        0.029827764257788658,
        -0.02690424956381321,
        0.07588329166173935,
        0.014513794332742691,
        0.05612357333302498,
        -0.0533091276884079,
        0.013613920658826828,
        0.00029852180159650743,
        0.06306356936693192,
        0.0296758022159338,
        0.14672309160232544,
        0.041183408349752426,
        -0.01520642451941967,
        -0.13205449283123016,
        -0.024311652407050133,
        -0.1064879447221756,
        0.04978688061237335,
        0.07337876409292221,
        0.03827713057398796,
        0.033194102346897125,
        0.06998127698898315,
        -0.01939297839999199,
        0.05334576964378357,
        0.0374603196978569,
        -0.03207648918032646,
        0.017868978902697563,
        0.022120187059044838,
        0.02453293651342392,
        -0.013388031162321568,
        -0.029510674998164177,
        0.02331082709133625,
        -0.08107826858758926,
        -0.07240211218595505,
        0.06605646759271622,
        -0.06272953003644943,
        -0.04206053167581558,
        0.10874532908201218,
        -0.08006454259157181,
        0.0006445806357078254,
        -0.005897635128349066,
        0.0685051828622818,
        -0.04461048170924187,
        0.0037681306712329388,
        0.0859166756272316,
        -0.006681963801383972,
        0.011907252483069897,
        0.0308803990483284,
        0.04416116327047348,
        -0.0009678815258666873,
        -0.00022590899607166648,
        -0.11175922304391861,
        0.036991801112890244,
        0.014009874314069748,
        -0.10380800813436508,
        -0.02600906789302826,
        0.009074526838958263,
        -0.002242549555376172,
        -0.005903318058699369,
        0.08770490437746048,
        0.04427020251750946,
        0.004034225828945637,
        -0.0796191468834877,
        -0.0126195028424263,
        -0.05618688091635704,
        0.06890479475259781,
        -0.023278195410966873,
        -0.0698985755443573,
        0.004061394836753607,
        -0.044171154499053955,
        0.05716434866189957,
        0.0003613362496253103,
        0.04303572326898575,
        0.005265452433377504,
        -0.06368210911750793,
        -0.03234225511550903,
        -0.03915845975279808,
        0.07070537656545639,
        -0.09811054170131683,
        -4.698892652754694e-8,
        0.004787556827068329,
        -0.022209348157048225,
        0.06729143857955933,
        -0.01349519845098257,
        0.11116398125886917,
        -0.04588610678911209,
        0.04171718657016754,
        -0.10303344577550888,
        -0.04999179020524025,
        0.049286071211099625,
        0.1276831328868866,
        0.006126438733190298,
        0.05194126069545746,
        -0.03247200325131416,
        -0.013202192261815071,
        0.018689291551709175,
        -0.0610772930085659,
        0.0021810131147503853,
        -0.003776031080633402,
        0.0020293083507567644,
        -0.03720675781369209,
        0.016048772260546684,
        -0.025524314492940903,
        0.04622830078005791,
        0.09282391518354416,
        0.009215985424816608,
        0.004382970277220011,
        -0.015180868096649647,
        0.09544306993484497,
        0.07313799858093262,
        0.02746286243200302,
        0.00919276848435402,
        0.07695644348859787,
        0.058544453233480453,
        0.02690950036048889,
        0.01555978786200285,
        -0.019386302679777145,
        0.003781357314437628,
        0.008337074890732765,
        0.12476608157157898,
        0.06996411830186844,
        0.003235397394746542,
        -0.00887193065136671,
        -0.013495287857949734,
        -0.03491195663809776,
        -0.0017463980475440621,
        -0.08337640017271042,
        0.018602190539240837,
        0.086006298661232,
        0.06445542722940445,
        0.019401157274842262,
        -0.03815120458602905,
        -0.05020475760102272,
        0.0031541031785309315,
        0.03478095680475235,
        -0.09200793504714966,
        -0.024686429649591446,
        -0.022288409993052483,
        0.044946614652872086,
        0.02626260183751583,
        -0.017503047361969948,
        0.01464779768139124,
        -0.07325240224599838,
        0.008218138478696346
      ],
      "metadata": {
        "title": "Paper_13_Dynamic_gNodeB_Sleep_Control_for_Energy_Conserving.pdf",
        "createdAt": "2025-12-17T13:56:32.804Z"
      },
      "fileObj": {}
    },
    {
      "id": "doc_6_1765979793701",
      "fileName": "Paper_18_Quantification_of_Sleep_Fragmentation_Through_the_.pdf",
      "content": "arXiv:cond-mat/0305660v1 28 May 2003  Quantification of Sleep Fragmentation Through the Analysis of Sleep-Stage Transitions  Chung-Chuan Lo 1 , Plamen Ch. Ivanov 1 , 2 , Lu¬¥ ƒ±s A. Nunes Amaral 1 , 2 , Thomas Penzel 3 , Claus F. Vogelmeier 3   and H. Eugene Stanley 1  1 Center for Polymer Studies and Department of Physics Boston University, Boston, MA 02215, USA  2 Cardiovascular Division, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA 02215, USA  3 Klinik f¬® ur Innere Medizin - Pneumologie, Philipps-Universit¬® at Baldingerstrasse 1, Marburg D-35033, Germany  ABSTRACT Study Objectives:   We introduce new quantitative approaches to study sleep-stage transitions with the goal of addressing the two following questions: (i) Can the new approaches provide more information on the structure of sleep-stage transitions? (ii) How does sleep fragmentation in patients with sleep apnea affect the structure of sleep- stage transitions?  Design:   We analyze hypnograms and compare normal subjects and sleep apnea patients using numerous measures, including the percentage of sleep time for each stage, probability distributions of the duration of each stage, the sleep-stage transition matrix, and a measure of the asymmetry of this matrix.  Setting:   N/A  Subjects:   197 normal subjects and 50 obstructive sleep apnea patients recruited in the SIESTA project.  Results:   We find that the time percentage for wake stage is identical for sleep apnea subjects and for normal subjects, but that the sleep apnea group have a faster decaying distribution of wake duration. Both normal subjects and sleep apnea patients have exponential distributions of duration for all sleep stages and a power law for the wake stage. We also find that there is a loss of preference of transition paths of sleep stages in sleep apnea.  Conclusions:   The new approaches proposed here enable us to show that the distribution of sleep and wake duration have different functional forms, indicating fundamental differences in the dynamics between sleep and wake control. The difference remains even in the fragmented sleep of sleep apnea. The fragmentation of sleep in sleep apnea results in a shorter wake duration and interrupts the structure of sleep-stage transitions of sleep apnea subjects, causing the loss of certain particular transition paths.  INTRODUCTION  Analyses of sleep-stage transitions have long been used as diagnostic tools in clinical applications. Such analyses mostly concentrated on the changes in the time percentage for each sleep stage and in other simple statistics such as the total number of arousals during nocturnal sleep [1,2]. There have also been several studies focusing on statistical measures such as transition probabilities [3‚Äì7], but many other statistical properties of sleep-stage transitions have not been considered in a systematic way. Sleep-stage transitions are sometimes described as having quasi-cyclic behavior (the sleep cycle) [2], but on top of the periodic patterns, there are many transitions without apparent periodicity (Fig. 1). Indeed, even if one disregards all sleep-stage transitions and considers only the wake stage during sleep, one still finds intriguing statistical properties and no apparent periodicity [8]. Furthermore, it has been reported that sleep stages correlate with the dynamics of the autonomic nervous system. For example, the correlations and scaling behavior in heart-rate variability depends on sleep stages [9,10].   Because sleep-stage transitions are such complex processes, simple statistical measures may not be sufficient to describe their dynamics and uncover any information contained in the fluctuations. Therefore, we study sleep-stage transitions with methods from modern statistical physics and nonlinear dynamics. Many advanced statistical analyses have been applied to the study of the electroencephalogram (EEG) during sleep [11‚Äì14], but an important limitation of these methods is that the EEG records only the activity close to the cortex surface, while it is believed that sleep is regulated by neurons in the hypothalamus [15]. Hence, we hypothesize that to study the dynamics of sleep regulation, one must investigate sleep-stage transitions, which contain more global information, including not only the EEG, but also eye movements and muscle tone. There are two major limitations in the analysis of sleep-stage transitions: The first is the limited number of data points ( ‚âà   900 points per night, where each point represents the sleep stage in a epoch of 30 seconds).   The second is the discretization of the data into six sleep stages. These limitations constrict the mathematical tools which can 1\n\nbe used in the analysis of sleep-stage transitions, so we focus on the distributions of duration of sleep stages, the transition probability matrices, and the degree of asymmetry of these matrices. We will also address questions regarding the statistical properties that we find: (i) how do these statistical properties change under the influence of sleep disorders, and (ii) which of these properties are fundamental and do not change under the influence of sleep disorders? To this end, we also study subjects with obstructive sleep apnea, who experience fragmented sleep with a reduced amount of slow-wave sleep and more awakenings (Fig. 1c). The sleep fragmentation is characterized by large number of arousals during nocturnal sleep. When arousal periods are longer than 15 seconds within a 30-second epoch of observation, the epoch is classified as a wake stage.   The fragmentation of sleep in obstructive sleep apnea arises from respiratory problems [16,17]. Therefore, sleep apnea is a good model for studying the effect of external disturbances on sleep-stage transitions. In the present study, we propose new quantitative approaches to studying sleep-stage transitions.   We show that these approaches enable us to find more information on the structure of sleep-stage transitions and enable us to find how sleep fragmentation of sleep apnea affects the structure of the sleep-stage transitions. Thus, the present approach gives us additional insights into the dynamics of sleep and wakefulness.  METHODS A. Subjects and Data acquisition  We analyze a database comprising 197 normal subjects and 50 patients with obstructive sleep apnea collected in eight leading European sleep laboratories under the SIESTA project [18]. For each subject, two consecutive nights were recorded with cardiorespiratory polysomnography. Sleep stages were determined according to the Rechtschaffen and Kales criteria [19]: two channels of electroencephalogram (EEG), two channels of electrooculogram (EOG), and one channel of submental electromyogram (EMG) were recorded. Signals were digitized at a minimum of 100 Hz, and a 12-bit resolution, and are scored visually in epochs of 30 seconds for six stages: wakefulness, rapid-eye-movement (REM) sleep, and non-rapid-eye-movement (NREM) sleep stages 1, 2, 3, and 4. Subjects wend to bed at midnight and were allowed to wake up in the morning at their own well. The average sleep time are xxx for healthy subjects and xxxx for sleep apnea subjects. Wake periods prior to the first sleep stage and after the last sleep stage are excluded from the analyses. We analyze hypnograms of the second night only. In order to eliminate the effect of age on sleep, we choose 48 of 197 normal subjects and 48 of 50 sleep apnea subjects. The reason for removing two sleep apnea subjects from the group is that these two sleep apnea subjects were much older (74) or younger (29) than the other sleep apnea subjects. We select the normal subjects according to the following procedure: We choose normal subjects from sleep laboratories which also provide sleep apnea subjects. The subjects are chosen to match the ages of 48 sleep apnea subjects. After all age-matched subjects have been chosen, we choose normal subjects randomly from other laboratories, also with similar age, until 48 normal subjects have been selected. We are thus able to choose normal and sleep apnea subjects with matched ages and maximum possible overlap of source laboratories. The selected normal group has an average age of 50 . 9 and a standard deviation of 9 . 4, while the selected sleep apnea group has an average age of 51 . 3 and a standard deviation of 8 . 9. We use the entire database of normal subjects in a test of the reliability of our results.  B. Coarse-graining of sleep stages  A major difficulty of studying the statistical properties of sleep-stage transitions is inter-scorer reliability, a topic of great concern in the literature [20‚Äì24]. One study reports that the agreement between sleep-stage scorers are in the range of 30%‚Äì90%, depending on the sleep stages and ages of subjects [24]. The least reliable scoring occurs for the NREM stage 1, which has only a 38% agreement on average. All other stages, such as wake, slow-wave sleep, and REM sleep, have an average agreement higher than 70%. To minimize scoring uncertainty, we reduce the six scored stages of sleep into four stages: We keep wake and REM stages unchanged, and group stages 1 and 2 into a single stage (light sleep), and stages 3 and 4 into a single stage (slow-wave sleep). The stages, wake, light sleep, slow-wave sleep, and REM sleep are abbreviated as W, L, S, and R, respectively. 2\n\nC. Percentage of sleep time  We define   F m   to the percentage of total sleep time for sleep stage   m . We measure   F m   for each sleep stage for each subject, and then calculate the mean and standard deviation of   F m   for normal and sleep apnea groups.   We apply Student‚Äôs t-test to determine the level of significance of the differences in   F m   between normal and sleep apnea groups.  D. Distributions of duration  F m   is a useful tool in diagnostic application, but it cannot capture all the information about the sleep-stage transitions. For example, identical values of   F m   could result from many short periods or from just a few long periods; two situations with different underlying dynamics.   Therefore, we study the distributions of the duration of wake and sleep stages for normal and sleep apnea groups. The distribution of duration of events is a useful measure for studying the underlying dynamics of a system. For example, a peak-like distribution indicates the periodic occurrence of events with fluctuations, such as heart beats intervals [25,26].   An exponential distribution is usually associated with a random process, such as fluorescent decay [27]. A power-law distribution, which has been observed in many systems, such as earthquakes [28], solar flares [29], and rainfall [30], is associated with self-organized criticality [31,32] or other complex mechanisms [33]. Thus, in order to quantitatively study how the brain regulates sleep, we consider the distribution of duration of sleep stages. We first calculate the duration of the separate wake and sleep stages periods for each subject, then pool the data from all subjects and calculate the group‚Äôs cumulative distributions of duration for wake, light sleep, slow-wave sleep, and REM sleep, which we denote as   P W   ( d ),   P L ( d ),   P S   ( d ), and   P R ( d ), respectively (Appendix A).  E. Transition probability matrices  The percentage   F m   and the distribution of duration   P m ( d ) of each sleep stage provide important information about the sleep stages, but they cannot provide temporal information ‚Äì i.e., time organization of transitions. For example,  P m ( d ) does not reveal any information about the preferred path of the transitions. Hence, we must study the transition probabilities between different sleep stages. Several types of transition probabilities for sleep stages have been studied [5‚Äì7]. Here, we consider a new type of transition probability matrix   T   with elements   T mn , defined as   T mn   =   N mn /N   , where   N mn   is the number of transitions from stage   n   to stage   m   during the entire night and   N   is the total number of transitions. We calculate the matrix   T  for each subject and then calculate the means and the standard errors of   T mn   for normal and sleep apnea groups. The matrix   T   is particularly useful for the analysis of the local structure of transitions because it measures the transition probability between two consecutive stages.   Since there are a large number of short transitions between different sleep stages even for normal subjects (Fig. 1), the transition matrix may be able to reveal hidden patterns in these short transitions.  F. The coefficient of asymmetry of transitions  One of the advantages of studying transition probabilities is that one may be able to extract the information about locally preferred paths in the sleep-stage transitions. One important question is: If there are locally preferred paths, are they affected by the sleep fragmentation of the sleep apnea? To answer this question, we introduce the concept of the symmetry of transitions. When the probability of having a transition from state A to state B is equal to the probability of having one from B to A, transitions between A and B are called ‚Äúsymmetric‚Äù. On the contrary, if the probability from A to B is not equal to the probability from B to A, the transition is called ‚Äúasymmetric‚Äù, a pattern indicating a preferred local transition path.   In order to quantify the asymmetry in the sleep-stage transitions, we introduce the coefficient of asymmetry   A   (Appendix B), which can be calculated from the transition matrix.   A   = 0 corresponds to a completely symmetric matrix, while   A   = 1 corresponds to a completely asymmetric matrix.   We calculate   A   for all subjects and perform Student‚Äôs t-test to evaluate the significance of the measured differences in   A  for normal and sleep-apnea groups. 3\n\nG. Test of the reliability of the results  Since sleep stages are scored visually by different experts in each laboratory, it is important to evaluate how much human bias affects the statistical analyses carried out. We compare our results with the data provided by different laboratories. For example, for the fraction   F m   of total sleep time for a given sleep stage   m , we calculated   F m   for each subject, and compare the distribution of   F m   of normal subjects from one laboratory to the normal subjects from a different laboratory. We also compare   F m   of normal subjects from one laboratory to the sleep apnea subjects from the same laboratory and from a different laboratory. We perform the same procedure on all other statistical measures calculated in this study.   We calculate the   p   value for Student‚Äôs t-test [34] and find the differences between normal and apnea subjects are much more significant ( p <   0 . 05) than the differences between normal subjects from different laboratories ( p >   0 . 05).  RESULTS  We first show results for the time percentage   F m   for each sleep stage for both normal and sleep apnea groups (Fig. 2). We find significant differences between the two groups for stage 1 ( p <   0 . 001) and also for stage 4 ( p <   0 . 05). However, there are no significant differences between normal and sleep apnea groups for the wake stage, sleep stage 2, and REM sleep. In Fig. 3 we show distributions of duration for wake,   P W   ( d ), light sleep,   P L ( d ), slow-wave sleep,   P S   ( d ), and REM sleep,   P R ( d ), for normal and sleep apnea groups.   P W   ( d ) shows a power-law decay   P W   ( d )   ‚àù   d ‚àí Œ±   for both normal and sleep apnea groups, while   P L ( d ),   P S   ( d ), and   P R ( d ) all show exponential decays,   P   ( d )   ‚àù   e ‚àí d/œÑ   . We compare   P W   ( d ),   P L ( d ),   P S   ( d ), and   P R ( d ) for normal and sleep apnea subjects and find that (i)   P W   ( d ) for sleep apnea group has a larger exponent   Œ±   = 1 . 28   ¬±   0 . 03 than the normal group,   Œ±   = 1 . 11   ¬±   0 . 05, and (ii)   P L ( d ),   P S   ( d ), and   P R ( d ) for the sleep apnea group show a steeper decay in the region   d <   5 min, but their decay time scale   œÑ   in the longer time region are similar to those of the normal group. We show the transition probability matrices   T   for the normal and sleep apnea groups in Tables 1a& b.   Not surprisingly, for both normal and sleep apnea subjects, we find some transitions are virtually prohibited: (i) there are no   R   ‚Üí   S   transitions and only few   S   ‚Üí   R   transitions, and (ii) there is no   W   ‚Üí   S   transition. For both the normal and sleep apnea groups, the matrices are asymmetric, but this asymmetry decreases for the sleep apnea group. To quantify the degree of asymmetry for normal and sleep apnea groups, we calculate the coefficient of asymmetry   A   for the data from each subject and plot distributions of   A   for normal and sleep apnea groups (Fig. 4). The normal group has a mean   A   of 0 . 058   ¬±   0 . 004, while the sleep apnea group has a mean   A   of 0 . 034   ¬±   0 . 003. We perform Student‚Äôs t-test to calculate the level of significance of the difference in   A   between normal and sleep apnea groups, resulting in a   p   value smaller than 1   √ó   10 ‚àí 5 . We also test to see if   A   changes for elder subjects, who are known to show more arousals during nocturnal sleep [1]. We choose two groups from our database of 197 normal subjects:   young (47 subjects, age:   20‚Äì35 years), and old (52 subjects age: 60‚Äì75 years). We find that the number of sleep-stage transitions in the older group has a mean of 106   ¬±   3, which is significantly larger than the mean of 84   ¬±   2 for the young group. We compare distributions of   A   between these two groups.   The young group has an average   A   of 0 . 061   ¬±   0 . 005, while the old group has an average   A   of 0 . 051   ¬±   0 . 004. Applying Student‚Äôs t-test, we find   p   = 0 . 6. A comparison of   F m ,   P m ( d ) and   A   of normal group with sleep apnea group is shown in Table 2.  DISCUSSION  We have proposed new approaches to the characterization of the dynamics of sleep-stage transitions, and found several intriguing properties: 1. We find that for normal subjects, the duration of each sleep stage is characterized by an exponential distribution with specific time scale, and the duration of wake stage is characterized by a power-low distribution suggesting a scale-free dynamics. This finding suggests a fundamental difference between the dynamics of sleep and wake- fulness control. It implies that sleep and wakefulness are not just two parts of a sleep-wake control, but that there exist entirely different mechanisms for their regulation in the brain, which supports recent studies in the neuronal level of sleep mechanisms (see, e.g., Ref. [15]). Ref. [8] reported that, for normal subjects, the duration of wake periods follows a power-law distribution,  P W   ( d )   ‚àù   d ‚àí Œ± , while the duration of sleep periods follows an exponential distribution,   P   ( d )   ‚àù   e ‚àí d/œÑ   . As shown 4\n\nin Fig. 3, when we decompose sleep into three stages: light, slow-wave and REM sleeps, all these sleep stages still follow exponential distributions. It is surprising that REM sleep, which can be regarded as somehow similar to wake from a brain activity aspect, clearly follows an exponential distribution of duration as the rest of the sleep stages, which is different from the power-law distribution of duration of the wake stage. The same forms of the distributions are observed for sleep apnea patients for all sleep stages (exponential) and for the wake stage (power law). This finding suggests robust mechanisms of sleep and wakefulness controls which do not change with sleep fragmentation in sleep apnea. 2. Our finding that the time percentage   F W   for the wake stage of the sleep apnea group is not significantly different from that of the normal group appears to contradict the ‚Äúcommon‚Äù expectation that sleep apnea subjects have more arousals. However, the difference in the wake stage between normal and sleep apnea subjects is clearly observed in the distributions of wake duration   P W   ( d ). The difference in the values of the power-law exponent   Œ±  characterizing   P W   ( d ) (Fig. 3) indicates that wake periods for sleep apnea subjects have shorter duration. Since  F W   is identical, sleep apnea subjects must have a larger number of wake periods. This is a clear indication of the sleep fragmentation one expects for sleep apnea. Although the functional form of   P L ( d ),   P S   ( d ) and   P R ( d ) is identical for normal and sleep apnea groups, the characteristic time scales are different, except for REM sleep. We find that the most significant change occurs for short duration (Fig. 3b&d). The increasing of slopes in the short duration   d <   5 min, indicates that sleep apnea subjects have many more short stages than normal subjects do, and thus a more fragmented sleep. Note that the power-law exponent   Œ±   = 1 . 1 for   P W   ( d ) for normal subjects (Fig. 3b). This value is different from what we reported ( Œ±   = 1 . 3) previously [8]. The reason is that in Ref. [8] our results was based on the database of 20 young subjects with average age of 35 . 2, which is different from the average age of 50 . 9 of the 48 normal subjects we used in this study.   With the choice of young normal subjects from the database we used in the present study, we recover   Œ±   = 1 . 3, which in agreement with the value reported in Ref. [8]. 3. From the transition matrix   T   we find that the transition probabilities between several pairs of stages change with sleep apnea. These changes can be characterized by the coefficient of asymmetry. Both normal and sleep apnea groups have asymmetric transition matrix   T   , but the sleep apnea group exhibits an increase of symmetry. The implication of an asymmetric transition matrix is that the transition process has preferred transition paths. Comparing   T RL   and   T LR , we find that there are more transitions from light sleep to REM sleep than from REM sleep to light sleep.   We also find, by comparing   T W R   and   T RW   , that there are more transitions from REM to wake then from wake to REM. These findings indicate that when a   R   ‚Üí   W   transition occurs, the sleep control system ‚Äúprefers‚Äù to make a transition to light sleep instead of back to REM (Fig. 5a). The explanation is supported by the values of   T LW   and   T W L : there are more   W   ‚Üí   L   transitions than   L   ‚Üí   W   transitions. We find that the matrices exhibit increased symmetry for the sleep apnea group (Fig. 4). This indicates that the sleep-stage transitions of sleep apnea subjects have less local structure.   From the distributions of wake duration, we learn that sleep apnea subjects have a larger number of transitions but shorter duration.   The increased wake periods, according to transition matrices, increase the symmetry of the matrix by distributing with less preference throughout the night (Fig. 5b). 4. A question one may ask is if the increase of the symmetry is a necessary result of the increase of the number of wake periods? As described in the results section, we calculate   A   for elderly subjects which have significantly larger number of wake periods during sleep. It is very interesting that although elderly subjects experience a larger number of wake periods, the coefficient of asymmetry does not change significantly ( p   = 0 . 06). This might indicate that the preferred transition path observed in normal subjects is fundamental, and is not significantly affected by age: The increased wake periods do not significantly change the preference of sleep-stage transition in elder subjects, while the increased wake periods in sleep apnea subjects do. All of our analyses are based on group distributions.   However, both normal and sleep apnea groups have broad distributions for many statistical measures. It is not known whether the changes in group distributions are represen- tative of changes in the individual behavior. It is also not known if each individual in the normal group (or in the sleep apnea group) follows the same statistics. To answer the questions, data of at least ten nights from each subject are needed. One can then compare the distribution of statistical measures from data on one subject to the data on another subject. Furthermore, all the analyses are based on whole-night records. However, sleep is not a homogeneous process. The statistical properties may vary throughout the night [35,2,8]. Hence, it is important to study the changes in   P m ( d ),  T   and   A   in the course of the night. 5\n\nOur findings of the stability of underlying dynamics of sleep-stage transitions between normal and sleep apnea subjects are intriguing.   It is important to test if the dynamics changes under pharmacological influences such as sleep-inducing drugs or caffeine, or under different psycho-physiological or pathological conditions such as stress or depression. 6\n\nAPPENDIX A. Cumulative distribution of duration  Let   p m ( d ) be the probability density function (i.e. the probability distribution) for the duration   d   of a given stage  m   for the group. We study the cumulative distribution   P m ( d ), which is defined as:  P m ( d )   ‚â°  ‚à´   ‚àû  d  p m ( r ) dr .  Therefore,   P m ( d ) is the probability of having a period of stage   m   with a duration longer than   d .   The reasons to consider   P m ( d ) instead of   p s ( d ) are: (i)   P m ( d ) gives curves smoother than   p m ( d ) does, making analyses easier. (ii)   P m ( d ) does not lose any information carried in   p m ( d ), and (iii)   P m ( d ) preserve shapes for power-law and for exponential functional forms.  B. The coefficient of asymmetry  The coefficient of symmetry of   A   is defined as  A   =  1  3  [ (   T W R   ‚àí   T RW  T W R   +   T RW  ) 2   +   (   T LW   ‚àí   T W L  T LW   +   T W L  ) 2   +   (   T LR   ‚àí   T RL  T LR   +   T RL  ) 2  ] 1 / 2  ,  where the   T mn   are elements in the transition probability matrix defined in the Methods section.   For a completely symmetric matrix in which   T mn   =   T mn ,   A   = 0, while for a completely asymmetric matrix in which one of   T mn   and  T nm   is equal to 0,   A   = 1. 7\n\nACKNOWLEDGMENTS  We thank the NIH/National Center for Research Resource (P41 RR 13622) for support. We also thank the SIESTA project (funded by the European Commission DG XII, as Biomed-2 project No. BMH4-CT97-2040 ‚ÄúSIESTA‚Äù) for providing data. We thank A. L. Goldberger and C.-K. Peng for helpful discussions and comments in the manuscript. CCL thank J. Mullington for helpful suggestions. 8\n\n[1] Chokroverty S. An overview of sleep. In: Chokroverty S ed. Sleep Disorders Medicine. Boston: Butterworth Heinemann, 1999: 7‚Äì20. [2] Carskadon MA, Dement WC. Normal Human Sleep: An Overview. In: Kryger MH, Roth T, Dement WC eds. Principles and Practice of Sleep Medicine. Philadelphia: WB Saunders Co, 2000: 15‚Äì25. [3] Williams R, Agnew H, Webb W. Sleep patterns in young adults: an EEG study. Electroen Clin Neuro 1964; 17: 376-381. [4] Brezinova V. The number and duration of the episodes of the various EEG stages of sleep in young and older people. Electroen Clin Neuro 1975; 39: 273-278. [5] Kemp B, Kamphuisen HAC. Simulation of human hypnograms using a Markov chain model. Sleep 1986; 9: 405-414. [6] Yassouridis A, Steiger A, Klinger A, Fahrmeir L. Modeling and exploring human sleep with event history analysis. J Sleep Res 1999; 8: 25-36. [7] Karlsson MO, Schoemaker RC, Kemp B, Cohen AF, van Gerven JMA, Tuk B, Peck CC, Danhof M. A pharmacodynamic Markov mixed-effects model for the effect of temazepam on sleep. Clin Pharmacol Ther 2000; 68: 175-188. [8] Lo CC, Amaral LAN, Havlin S, Ivanov PCh, Penzel T, Peter J-H, Stanley HE. Dynamics of sleep-wake transitions during sleep. Europhys Lett 2002; 57: 625-631. [9] Ivanov PCh, Bunde A, Amaral LAN, Havlin S, Fritsch-Yelle J, Baevshk RM, Stanley HE, Goldberger AL. Sleep-wake differences in scaling behavior of the human heartbeat: Analysis of terrestrial and long-term space flight data. Europhys Lett 1999; 48: 594-600. [10] Bunde A, Havlin S, Kantelhardt JW, Penzel T, Peter JH, Voigt K. Correlated and uncorrelated regions in heart-rate fluctuations during sleep Phys Rev Lett 2000; 85: 3736-3739. [11] Fell J, R¬® oschke J, Schaffner C. Surrogate data analysis of sleep electroencephalograms reveals evidence for nonlinearity. BIOLOGICAL CYBERNETICS 1996; 75: 85-92. [12] Pradhan N, Sadasivan PK. The nature of dominant Lyapunov exponent and attractor dimension curves of EEG in sleep. COMPUTERS IN BIOLOGY AND MEDICINE 1996; 26: 419-428. [13] Pereda E, Gamundi A, Rial R, Gonzalez J. Non-linear behaviour of human EEG: fractal exponent versus correlation dimension in awake and sleep stages. Neurosci Lett 1998; 250: 91-94. [14] Fell J, Kaplan A, Darkhovsky B, R¬® oschke J. EEG analysis with nonlinear deterministic and stochastic methods: a combined strategy. Acta Neurobiol Exp 2000; 60: 87-108. [15] Saper CB, Chou TC, Scammell TE. The sleep switch: hypothalamic control of sleep and wakefulness. Trends Neurosci 2002; 24: 726-731. [16] Strollo PJ, Rogers RM. Current concepts: Obstructive sleep apnea. New Engl J Med 1996; 334: 99-104. [17] Robinson A, Guilleminault C. Obstructive sleep apnea syndrome. In: Chokroverty S ed. Sleep Disorders Medicine. Boston: Butterworth Heinemann, 1999: 331‚Äì354. [18] Kl¬® osch G, Kemp B, Penzel T, Schl¬® ogl A, Rappelsberger P, Trenker E, Gruber G, Zeitlhofer J, Saletu B, Herrmann WM, Himanen SL, Kunz D, Barbanoj MJ, R¬® oschke J, V¬® arri A, Dorffner G. The SIESTA project polygraphic and clinical database. IEEE Eng Med Biol 2001; 20: 51-57. [19] Rechtschaffen A, Kales A. Manual of Standardized Terminology, Techniques, and Scoring System for Sleep Stages of Human Subjects. Los Angeles: California BIS/BRI, University of California; 1968. [20] Kelley JT, Reilly EL, Overall JE, Reed K. Reliability of rapid clinical staging of all night EEG. Clin Electroencephalogr 1985; 16: 16-20. [21] Kubicki S, Holler L, Berg I, Pastelak-Price C, Dorow R. Sleep EEG evaluation: a comparison of results obtained by visual scoring and automatic analysis with the Oxford sleep stager. Sleep 1989; 12: 140-149. [22] Whitney CW, Gottlieb DJ, Redline S, Norman RG, Dodge RR. Reliability of scoring respiratory disturbance indices and sleep staging. Sleep 1998; 21: 749-757. [23] Norman RG, Pal I, Stewart C, Walsleben JA, Rapoport DM. Interobserver agreement among sleep scorers from different centers in a large dataset. Sleep 2000; 23: 901-908. [24] Kunz D, Danker-Hopfe H, Gruber G, Kl¬® osch G, Lorenzo JL, Himanen SL, Kemp B, Penzel T, R¬® oschke J, Dorffner G. Interrater reliability between eight European sleep-labs in healthy subjects of all age groups. J Sleep Res 2000; 9: Supp 1: 106. [25] Peng CK, Mietus J, Hausdorff JM, Havlin S, Stanley HE, Goldberger AL. Long-range anti-correlations and Gon-Gaussian behavior of the heartbeat. Phys Rev Lett 1993; 70: 1343-1346. [26] Ivanov PCh, Rosenblum MG, Peng CK, Mietus J, Havlin S, Stanley HE, Goldberger AL. Scaling behaviour of heartbeat intervals obtained by wavelet-based time-series analysis. Nature 1996; 383: 323-327. [27] Campbell ID, Raymond AD. Biological spectroscopy. Menlo Park: Benjamin/Cummings Pub Co, 1984: 91‚Äì125. [28] Bak P, Christensen K, Danon L, Scanlon T. Unified scaling law for earthquakes. Phys Rev Lett 2002; 88: art. no. 178501. [29] Boffetta G, Carbone V, Giuliani P, Veltri P, Vulpiani A. Power Laws in Solar Flares: Self-Organized Criticality or Turbu-  9\n\nlence? Phys Rev Lett 1999; 82: 4662-4665. [30] Peters O, Hertlein C, Christensen K. A Complexity View of Rainfall. Phys Rev Lett 2002; 88: art. no. 18701. [31] Bak P. How nature works : the science of self-organized criticality. New York: Copernicus, 1996. [32] S¬¥ anchez A, Newman DE, Carreras BA. Waiting-Time Statistics of Self-Organized-Criticality Systems. Phys Rev Lett 2002; 88: 68320. [33] Sornette D. Critical phenomena in natural sciences: chaos, fractals, selforganization, and disorder : concepts and tools. Berlin: Springer, 2000: 285-320 [34] Press WH, Teukolsky SA, Vetterling WT, Flannery BP. Numerical recipes in C. Cambridge: Cambridge University Press; 1994. 616-617 [35] Born J, Hansen K, Marshall L, Molle M, Fehm HL. Timing the end of nocturnal sleep. Nature 1999; 397: 39-30.  10\n\nFIGURE 1  0   60   120   180   240   300   360   420   480  Time (min)  BA02602 C001002 H000602  a. b. c.  Wake REM 1 2 3 4 Wake Wake REM REM 1 1 2 2 3 3 4 4  Sleep stage  FIG. 1.   Three typical hypnograms for normal subjects (a) and (b), and for a sleep apnea subject (c).   There are large number of short sleep-stage transitions as shown in ovals throughout the nights for both normal and sleep apnea subjects. The overall patterns of hypnograms between different normal subjects are also very different. The sleep apnea subject experience fragmented sleep, and shows a much larger number of short transitions than normal subjects do.  11\n\nFIGURE 2  0 10 20 30 40 50 60  Time percentage   F m  0 20 40 60 80  Wake   1   2   3   4   REM  ** **  Normal Sleep apnea  W   L   S   R  * ** NREM  FIG. 2.   Fraction   F m   of total sleep time for a given stage   m .   Here we show the average values based on a database of 48 normal subjects and 48 sleep apnea subjects with matched ages.   The error bars give uncertainties of the average values. Student‚Äôs t-test is performed to measure the significance of the difference between normal and the sleep apnea groups.   One asterisk indicates   p <   0 . 05, and two asterisks indicate   p <   0 . 01.   Sleep stages 1 and 4 display significant differences between normal and sleep apnea subjects, while wake, stage 2, 3 and REM do not display significant differences. Further on we consider only four stages: wake (W), light sleep (L), slow-wave sleep (S), and REM sleep (REM), therefore we show the percentage of total sleep time for these four stages in the inset.  12\n\nFIGURE 3  Normal  0   10   20   30   40   50   60   70  Duration   d   (min)  10 ‚àí3  10 ‚àí2  10 ‚àí1  10 0  Cumulative probability   P m (d)   Wake  Light  Slow‚àíwave  REM  ( œÑ =9.9¬±0.1) ( œÑ =10.4¬±0.3)  ( œÑ =9.3¬±0.2)  a.  1   10  Duration   d   (min)  Œ± =0.48¬±0.01  Œ± =0.76¬±0.05  Œ± =1.11¬±0.05  b.  Sleep apnea  0   10   20   30   40   50   60   70  Duration   d   (min)  10 ‚àí3  10 ‚àí2  10 ‚àí1  10 0  Cumulative probability   P m (d)   Wake  Light  Slow‚àíwave  REM  ( œÑ =10.9¬±0.1)  ( œÑ =10.9¬±0.2) ( œÑ =9.2¬±0.2)  c.  1   10  Duration   d   (min)  Œ± =0.55¬±0.01  Œ± =0.84¬±0.05  Œ± =1.28¬±0.03  d.  FIG. 3. Cumulative distribution of duration for each sleep stage showing different features for wake stage and sleep stages but similar features for normal and sleep apnea subjects. (a) Semi-logarithmic plot and (b) double-logarithmic plot show curves for the normal group. (c) Semi-logarithmic plot and (d) double-logarithmic plot show curves for the sleep apnea group. For both normal and sleep apnea groups, the distributions for wake follow power-law decays, while the distributions for all sleep stages follow exponential decays.   Comparing to the normal group, the sleep apnea group shows larger power-law exponent  Œ±   for the distribution of wake duration, larger characteristic time scale   œÑ   for the distribution of duration of light sleep, but similar characteristic time scale for the distributions of duration of slow-wave and REM sleep. In order to compare curves of light, slow-wave and REM sleep in the small time region ( d <   5 min) between normal and sleep apnea subjects, power-law functions are fit to the curves of light and slow-wave sleep for   d <   5 min (c & d). Note that the fitting is only for the purpose of comparison.   The lack of data points in the region of   d <   5 min makes it difficult to determine the functional form of the distribution for sleep stages in this small-time region.   Note that for distributions of all sleep stages, the sleep apnea group shows a steeper decay in the small time region ( d <   5 min).  13\n\nFIGURE 4  0.00   0.10  Coefficient of asymmetry  0.00 0.10 0.20 0.30 0.40 0.50  Probability  Normal Sleep apnea  Normal mean: 0.058¬±0.004 Sleep apnea mean: 0.034¬±0.003  Student‚Äôs t‚àítest: p=7x10 ‚àí6  FIG. 4. Distribution of the coefficient of symmetry (defined in the text) for normal and sleep apnea groups. Arrows indicate means of distributions of normal and sleep apnea groups. The result of Student‚Äôs t-test indicates that the observed averages of these two groups are significantly different, suggesting that the sleep apnea group has a significant decrease of the asymmetry as the result of the sleep fragmentation.  14\n\nFIGURE 5  Normal  Deep Wake  a.  REM Light  Time  Sleep Apnea  Wake  b.  Deep  REM Light  Time  FIG. 5. Illustration of asymmetric sleep-stage transitions.   Since wake periods are much shorter than the light, slow-wave and REM sleep periods on average, we assume that the basic structure of sleep-stage transitions are dominated by light sleep, slow-wave sleep and REM sleep. (a) Wake periods can be viewed as spikes distributed throughout the night in light and REM sleep. Because   T W R   > T RW   for normal subjects (cf. Table 2, where   T W R /T RW   ‚âà   5 . 6), there is a preference for transitions from REM to wake and then to light sleep, instead of back to REM. (b) For sleep apnea subjects, there is increasing symmetry in transitions (cf.   T W R /T RW   ‚âà   2 . 6). Because sleep apnea subjects have more transitions on average, the increased wake periods may distribute in light and REM sleep with less preference throughout the night.  15\n\nTable 1  a) Transition probability matrix   T mn   (defined in the text) for normal subjects, where   m   corresponds to row and  n   corresponds to column.   The numbers in the matrix are means of the group distributions and standard errors of means. The average number of transitions per night = 96 . 0   ¬±   3 . 2.  W   R   L   S W   ‚àí   0 . 050   ¬±   0 . 005   0 . 182   ¬±   0 . 009   0 . 016   ¬±   0 . 002  R   0 . 009   ¬±   0 . 002   ‚àí   0 . 116   ¬±   0 . 007   0 . 004   ¬±   0 . 001  L   0 . 237   ¬±   0 . 010   0 . 073   ¬±   0 . 006   ‚àí   0 . 139   ¬±   0 . 010  S   0 . 001   ¬±   0 . 001   0 . 000   ¬±   0 . 000   0 . 155   ¬±   0 . 010   ‚àí  b) Same as above for sleep apnea. The average number of transitions per night = 123 . 0   ¬±   6 . 2.  W   R   L   S W   ‚àí   0 . 042   ¬±   0 . 004   0 . 217   ¬±   0 . 014   0 . 008   ¬±   0 . 002  R   0 . 016   ¬±   0 . 004   ‚àí   0 . 126   ¬±   0 . 012   0 . 001   ¬±   0 . 001  L   0 . 250   ¬±   0 . 014   0 . 099   ¬±   0 . 011   ‚àí   0 . 105   ¬±   0 . 010  S   0 . 001   ¬±   0 . 001   0 . 000   ¬±   0 . 000   0 . 114   ¬±   0 . 010   ‚àí  16\n\nTable 2  Table 2. Summary of results of our analysis for (i) the mean time percentage, (ii) the distribution of duration of sleep stages and (iii) the mean degree of asymmetry of the transition probability matrix.  ¬Ø F m   (%)   P m ( d ) Subjects   W   L*   S*   R   W*   L*   S   R   ¬Ø A *  Normal   10.6   57.3   12.2   17.8   d ‚àí 1 . 1   e ‚àí d/ 9 . 9   e ‚àí d/ 10 . 4   e ‚àí d/ 9 . 3   0.58 Sleep Apnea   10.1   61.8   8.9   17.0   d ‚àí 1 . 3   e ‚àí d/ 10 . 9   e ‚àí d/ 10 . 9   e ‚àí d/ 9 . 2   0.34  Symbols:   ¬Ø F m , mean time percentage for stage   m .   P m ( d ), distribution of duration   d   of stage   m .   ¬Ø A , mean degree of asymmetry. Stage   m   can be wake ( W   ), light sleep ( L ), slow-wave sleep ( S ) or REM ( R ). An asterisk denotes significant difference between normal and sleep apnea groups. 17",
      "embedding": [
        -0.020489700138568878,
        -0.04178495705127716,
        0.05266366899013519,
        0.03735848888754845,
        0.055271029472351074,
        0.027819626033306122,
        -0.06510161608457565,
        0.0034953176509588957,
        0.15787145495414734,
        0.020796459168195724,
        -0.03306293487548828,
        0.015306907705962658,
        0.03164772689342499,
        0.062013737857341766,
        0.02176644094288349,
        0.02306852862238884,
        -0.05647141486406326,
        0.050005339086055756,
        -0.028224818408489227,
        0.09888061881065369,
        0.12009619921445847,
        -0.002804146148264408,
        0.07121623307466507,
        -0.011921588331460953,
        0.001347253448329866,
        -0.027330884709954262,
        0.01578480191528797,
        -0.0607469417154789,
        -0.015979979187250137,
        -0.059418030083179474,
        -0.03324754536151886,
        0.08019860088825226,
        -0.005329566076397896,
        -0.0057072932831943035,
        0.033237915486097336,
        0.028783762827515602,
        0.04558373615145683,
        0.026699194684624672,
        -0.09689152240753174,
        0.030162658542394638,
        0.0761614665389061,
        -0.024786483496427536,
        -0.03845643252134323,
        -0.01624879240989685,
        -0.047877538949251175,
        -0.006451478227972984,
        -0.07973552495241165,
        -0.08353279531002045,
        -0.11050672084093094,
        0.07536645978689194,
        -0.047373216599226,
        -0.017919057980179787,
        -0.07456884533166885,
        0.05008074641227722,
        0.01676766574382782,
        0.018957560881972313,
        -0.03377879410982132,
        -0.006264128722250462,
        0.01605764590203762,
        -0.03785839304327965,
        -0.0863540917634964,
        0.045837149024009705,
        -0.022147664800286293,
        -0.028340179473161697,
        0.0395643413066864,
        0.07199481874704361,
        0.007555272430181503,
        -0.03789146617054939,
        0.004526661243289709,
        0.020810812711715698,
        -0.08390647172927856,
        -0.02049839496612549,
        -0.03092370368540287,
        -0.02197612263262272,
        0.01314781978726387,
        -0.031223434954881668,
        0.040500979870557785,
        0.0005087194731459022,
        0.0006426182808354497,
        -0.06173964589834213,
        0.06241042912006378,
        0.05020790919661522,
        -0.02144249901175499,
        -0.05044861510396004,
        -0.040627919137477875,
        0.01051443349570036,
        0.030011123046278954,
        0.10494294762611389,
        -0.055659130215644836,
        -0.02176322042942047,
        -0.0116026746109128,
        0.017408087849617004,
        -0.05027323216199875,
        0.005267246160656214,
        0.1417606621980667,
        0.023539407178759575,
        -0.010358619503676891,
        0.022917067632079124,
        0.15152104198932648,
        -0.04133620485663414,
        0.00490600848570466,
        -0.004181552212685347,
        0.0050156801007688046,
        -0.01333540864288807,
        -0.003872165223583579,
        -0.012852117419242859,
        -0.00756138376891613,
        -0.09958288818597794,
        0.0127039086073637,
        0.021992677822709084,
        0.032301098108291626,
        0.026959259063005447,
        0.07689444720745087,
        0.018469829112291336,
        0.08629816025495529,
        0.04874766990542412,
        -0.04366067424416542,
        0.08463640511035919,
        0.05950552225112915,
        0.06741992384195328,
        0.06651056557893753,
        -0.06402646005153656,
        0.036099642515182495,
        -0.0891963541507721,
        -0.01569961942732334,
        -0.028515055775642395,
        -0.07418385148048401,
        6.426220435066113e-33,
        0.03308927267789841,
        -0.06840665638446808,
        -0.021107258275151253,
        0.0815100222826004,
        -0.0044088889844715595,
        -0.049288179725408554,
        -0.0385623499751091,
        -0.0401882641017437,
        0.004313834011554718,
        0.0024655137676745653,
        -0.08297289907932281,
        0.030837196856737137,
        -0.03468843549489975,
        -0.033237114548683167,
        -0.0056218598037958145,
        0.0054810186848044395,
        0.040760625153779984,
        0.052942026406526566,
        -0.038509342819452286,
        -0.05041195824742317,
        0.018733931705355644,
        0.02890537865459919,
        0.030315063893795013,
        0.021259287372231483,
        -0.028916675597429276,
        0.003813002724200487,
        -0.04535971209406853,
        0.010704604908823967,
        -0.08618460595607758,
        0.008064864203333855,
        -0.01644231006503105,
        0.009990064427256584,
        -0.07862697541713715,
        0.015103179030120373,
        -0.015399671159684658,
        -0.01280855480581522,
        0.05394868552684784,
        0.005860497709363699,
        -0.03595639020204544,
        -0.021588928997516632,
        -0.07751306146383286,
        0.050356488674879074,
        -0.00898961815983057,
        -0.005630678962916136,
        0.018211858347058296,
        -0.06891575455665588,
        0.0202900692820549,
        0.09066398441791534,
        0.02759021706879139,
        0.023887841030955315,
        0.05076814442873001,
        -0.04330567270517349,
        0.00820083450525999,
        -0.0693853497505188,
        -0.09536916017532349,
        0.0488101989030838,
        -0.0426848903298378,
        -0.017598800361156464,
        -0.06670724600553513,
        0.09237466007471085,
        0.03700719028711319,
        0.008412076160311699,
        0.011654253117740154,
        0.011468349024653435,
        0.021909138187766075,
        0.07647722959518433,
        -0.09775296598672867,
        -0.060185715556144714,
        0.03950023278594017,
        0.01737029477953911,
        0.06971420347690582,
        -0.06551874428987503,
        0.033141788095235825,
        0.0004684050800278783,
        0.061742912977933884,
        -0.037089984863996506,
        0.00968406442552805,
        0.07226454466581345,
        -0.11378096044063568,
        -0.03539857268333435,
        0.06189775839447975,
        0.05211033672094345,
        -0.04654369875788689,
        -0.09240150451660156,
        -0.049959905445575714,
        -0.055121246725320816,
        0.04947231337428093,
        0.006816974375396967,
        -0.1501891016960144,
        -0.000729317544028163,
        -0.00588945671916008,
        -0.052494410425424576,
        0.09943409264087677,
        0.036279190331697464,
        0.009538312442600727,
        -8.070075081610187e-33,
        -0.011923221871256828,
        -0.06316613405942917,
        -0.0011163068702444434,
        -0.07144662737846375,
        0.04219812527298927,
        0.04092699661850929,
        0.025170905515551567,
        -0.006099053658545017,
        -0.010526838712394238,
        -0.08298312872648239,
        0.05844518914818764,
        -0.018576810136437416,
        0.014468302018940449,
        -0.052138518542051315,
        0.011014408431947231,
        -0.004016639199107885,
        0.07757312804460526,
        0.007670127786695957,
        -0.04612312838435173,
        0.0653795525431633,
        0.03198893740773201,
        0.0009675616165623069,
        -0.11129188537597656,
        -0.08064914494752884,
        0.0070679523050785065,
        0.073671355843544,
        -0.019962184131145477,
        0.11075560748577118,
        0.01708185113966465,
        -0.05001602694392204,
        -0.06795543432235718,
        -0.03036348521709442,
        -0.10747451335191727,
        0.005448685027658939,
        -0.02314632013440132,
        -0.002387173241004348,
        -0.018742818385362625,
        -0.0005101316492073238,
        -0.019708406180143356,
        -0.10397104918956757,
        0.08657214045524597,
        0.012184134684503078,
        0.05392349883913994,
        -0.0960410088300705,
        0.09918490797281265,
        0.012905549257993698,
        0.004504829179495573,
        -0.06884625554084778,
        -0.020991282537579536,
        -0.07902879267930984,
        0.0026640049181878567,
        0.05460427328944206,
        -0.015152242965996265,
        0.018808424472808838,
        -0.0357196070253849,
        0.051857706159353256,
        -0.05247999727725983,
        -0.026495855301618576,
        -0.004583672154694796,
        0.02563609555363655,
        0.012275039218366146,
        0.021821871399879456,
        -0.02120475098490715,
        0.019854549318552017,
        0.07667452841997147,
        0.0359174907207489,
        -0.001653877436183393,
        -0.11475300788879395,
        0.05273644998669624,
        -0.049584854394197464,
        -0.002548173302784562,
        -0.013889878056943417,
        -0.01682760752737522,
        0.07060781866312027,
        0.03128708899021149,
        -0.00047061030636541545,
        0.0019164655823260546,
        -0.08017216622829437,
        -0.03871368244290352,
        -0.057897940278053284,
        -0.10281427204608917,
        -0.08588819205760956,
        -0.059843312948942184,
        -0.030300188809633255,
        -0.08907060325145721,
        -0.03368222340941429,
        0.05121227353811264,
        -0.0838441476225853,
        0.1281471997499466,
        -0.02117500826716423,
        -0.031368281692266464,
        -0.000570755684748292,
        -0.06839302182197571,
        -0.007911981083452702,
        0.029984774067997932,
        -6.002282759709487e-8,
        0.05976060405373573,
        -0.041270893067121506,
        -0.002555763116106391,
        0.007554732263088226,
        0.0055769882164895535,
        0.014412201009690762,
        0.07472163438796997,
        0.008559479378163815,
        -0.016076115891337395,
        0.057654011994600296,
        0.08946090191602707,
        -0.01152763795107603,
        0.11006143689155579,
        -0.07554440945386887,
        -0.005694815889000893,
        0.027875786647200584,
        -0.02555287815630436,
        0.04406216740608215,
        -0.0018378555541858077,
        -0.045165762305259705,
        -0.004742523189634085,
        -0.029871325939893723,
        -0.036262381821870804,
        -0.028176605701446533,
        0.007705010939389467,
        0.018672939389944077,
        -0.03433455899357796,
        0.03151106834411621,
        -0.003581003053113818,
        -0.028017805889248848,
        -0.017544910311698914,
        0.008298194967210293,
        0.0026215824764221907,
        0.052856530994176865,
        -0.040177155286073685,
        0.00008524754230165854,
        0.08274993300437927,
        -0.0038239234127104282,
        0.005776206962764263,
        0.1750597208738327,
        0.050393424928188324,
        -0.0576954260468483,
        -0.045956388115882874,
        -0.0007360846502706409,
        0.010915861465036869,
        -0.04244976118206978,
        -0.00035921871312893927,
        -0.025710005313158035,
        0.021806878969073296,
        0.057513102889060974,
        0.025963066145777702,
        -0.047955650836229324,
        -0.06298495829105377,
        -0.0437801256775856,
        -0.04301329702138901,
        0.018291639164090157,
        0.015916725620627403,
        -0.0315738171339035,
        0.05698176845908165,
        -0.061238985508680344,
        0.05843271687626839,
        -0.02439182996749878,
        -0.049019522964954376,
        0.01979673095047474
      ],
      "metadata": {
        "title": "Paper_18_Quantification_of_Sleep_Fragmentation_Through_the_.pdf",
        "createdAt": "2025-12-17T13:56:33.701Z"
      },
      "fileObj": {}
    },
    {
      "id": "doc_7_1765979794599",
      "fileName": "Paper_16_Night_sleep_duration_trajectories_and_associated_f.pdf",
      "content": "1  Night sleep   duration   trajectories and associated factors among preschool children  from   the EDEN cohort  Authors:  Sabine Plancoulaine , MD, PhD a,b ,   Eve Reynaud a,b,c , MPH,   Anne Forhan a,b ,   Sandrine Lioret,  PhD a,b ,   Barbara Heude, PhD a,b   and   Marie - Aline Charles   MD, PhD a,b   ; o n behalf of t he EDEN  mother - child cohort study group.  Affiliations:  a   INSERM,   UMR1153, Epidemiology and Statistics Sorbonne Paris Cit√© Research Center  (CRESS), early ORigins   of Child Health And Development Team (ORCHAD), Villejuif, F -  94807 France ;  b   Univ Paris - Descartes , UMRS 1 153 ,   Paris , France ;  c   Ecole des Hautes Etudes en Sant√© Publique (EHESP), Rennes, F - 35043, France  Address correspondence to :  Sabine Plancoulaine ,   INSERM,   UMR1153, Epidemiology and Statistics Sorbonne Paris Cit√©  Research   Center   (CRESS),   early   ORigins   of   Child   Health   And   Development   Team  (ORCHAD),   16 Av Paul Vaillant Couturier,   94 807 Villejuif Cedex, FRANCE,  Email   :   sabine.plancoulaine@inserm.fr  P hone:   +   33 1 45 59 51 09 .  Ethical approval and consent to participate:  The study was approved by the ethics research committee of Bic√™tre Hospital   (Comit√©  Consultatif de Protection des Personnes dans la Recherche Biom√©dicale) and by the Data  Protection Authority (Commission Nationale de l‚ÄôInformatique et des Libert√©s).  Funding :  This research did not receive any specific grant from funding agencies   in the public,  commercial, or   not - for - profit sectors .\n\n2  A BSTRACT  O bjective .   S leep duration   may   vary inter - individually   and intra - individually   over time .   We   aimed at  both   identifying   night - sleep   duration   (NSD)   trajectories   among   preschoolers   and   studying  associated factors .  Methods.   NSD were collected   within the French birth - cohort study EDEN   at age s   2, 3 and 5 - 6  years   through parental questionnaires, and were used to model   NSD   trajectories   among 1205  children .   F amilial   socioeconomic   factors,   maternal   sociodemographic,   health   and   lifestyle  characteristics as well as child health, lifestyle,   and   sleep characteristics at birth and/or at   age   2  years   were   investigated in association with NSD   using m ultinomial logistic regression s .  Results.   Five   distinct   NSD   trajector ies   were identified : short (SS, <10h,   4.9 %), medium - low (MLS,  <11h,   47.8 %), medium - high (MHS,   ‚âà 11h30,   37.2 %), long (LS,   ‚â• 11h30,   4.5 %) and   changing   ( CS ,  i.e.   ‚â• 11h30   then   <11h ,   5.6 %)   NSD   trajectories . Multivaria ble   analys e s showed   in particular   that ,  compared to   the   MHS trajectory,   factors associated with increased risk for   belonging to   SS  trajectory were   male gender ,   first child , maternal age and   working   status , night - waking, parental  presence when falling asleep,   television - viewing   duration   and   both the ‚ÄúProcessed and fast foods‚Äô‚Äô  and   the ‚ÄúB aby food ‚Äù   dietary   patterns at   age   2 years.   Factors positively associated with   the   C S  trajectory were maternal smoking,   bottle - feeding at night and   the ‚Äú P rocessed   and fast   food s‚Äù  dietary   pattern at   age   2 years   wh ereas   child ‚Äôs   activity and emotionality   scores   at   age   1   y e a r w ere  negatively assoc iated .  Conclusion.   W e   identified   distinct   NSD   trajectories among   preschoolers   and   associated   early life  factors.   Some   of them   may reflect less healthy lifestyle, providing cues for early multi - behavioral  prevention intervention s .  Keywords :   Preschoolers ;   G roup - based   trajectory   modeling ;   S leep   duration ;   C ohort;   Epidemiology;  Public health;  HIGHLIGHTS  ‚Ä¢   Longitudinal data were analyzed using a data - driven developmental approach  ‚Ä¢   F ive different night sleep duration trajectories   were identified   in preschoolers  ‚Ä¢   Specific   early life factors   were   associated with each trajectory  ‚Ä¢   Most of them were   living habits   and may reflect global less healthy lifestyle  ‚Ä¢   E arly multi - behavioral prevention interventions   may be beneficial\n\n3  Abbreviations:  NSD: night - sleep duration  BMI: body - mass index  SS: short - sleep  MLS: medium - low sleep  MHS: medium - high sleep  CS: changing sleep  LS: long sleep\n\n4  1.   INTRODUCTION  Sleep is of vital importance for   children‚Äôs health and wellbeing.   There is now accumulating  evidence that insufficient quantity and/or quality of sleep have a negative impact on children‚Äôs  physical and mental health development, cognitive function,   behavior   and academic success   [1 ‚Äì 4] .  Sleep disorders and short sleep duration in childhood have also been suggested as predictors of  sleep disorders and short sleep duration in adolescence and adulthood   [5,6] .   Investigating   early  determinants of sleep durations may help   to   better   understand physiopathology and   develop  prevention   interventions of   unhealthy   sleep   pattern s .  A   British   longitudinal   cohort   study   interested   in   factors   associated   with   normal   sleep  duration variation among   over 11,000   children aged 6 months to 11 years, showed   that   girls  consistently   slept longer than boys ,   and   that older mother age (>35 years) was associated with  shorter sleep   duration   [7] .   Studies   focusing   on short sleep, with   age - specific   cut - offs, also showed  that   girls   were   less   likely to be short sleepers   [8 ‚Äì 10] .   Other factors associated with   short sleep  were identified as lower socio - economic status, non Caucasian ethnic group, maternal stress  and/or   depression,   prematurity,   low   birth   weight,   care   outside   the   home,   TV/screen   viewing  especially before going to sleep   and late bedtime   [7,8,10,11] .   Parental   behavior   a t bedtime (e.g.  parental presence until sleep onset, feeding), especially among toddlers ,   is an additional important  risk factor for fragmented sleep and consequently shorter sleep duration   [12 ‚Äì 15] .  A decrease in children‚Äôs total sleep duration has been reported in the last decades   [16,7] ,  suggesting that   a growing number of   children   may   now   get   short er   sleep duration   than needed .  The American Academy of Sleep Medicine recently recommended a total   mean   sleep duration of  10 to 13 hours per 24 hours   among preschoolers   [17] .   As   reported   by   Galland et al and B lair et al,  standard deviation of the means   var ies between 1 to 2 hours among pre schoolers   [7,16]   and   sleep  duration   mean   may   not   correctly   reflect   the   variety   of   sleep   durations   during   childhood.  Longitudinal sleep patterns or trajectory may   also   be of interest.   Previous research concerning  Canadian   preschoolers   identified   four   sleep trajectories between 2.5 and 5 years : short persistent  (<9h rs /night) , short increasing   ( <9h up to 3. 5 years old and then around 10 .5 h rs ) , 10 - h rs   persistent  and 11 - h rs   persistent patterns   [18,19] .   The   authors   showed   a n   increased risk of   externaliz ing  problems   [18]   and   high hyperactivity scores   [19]   in   6 year - old   children with short sleep duration  trajector y   ( i.e.   short - persistent   vs.   11h rs - persistent sleepers ) . They also   reported   that risk   factors  as soci a ted with   both   short   sleep trajectory   and high hyperactivity scores   were   male gender, low  household income, low maternal education and parental presence during night awakening   [19] .  However,   t hey did not   search for factors   associated with   the   short   sleep trajector y   by itself   or with  other   sleep trajectories .   In addition,   European   preschoolers   tend to sleep   longer   on average   than  the   North American   preschoolers   [14,20]   and may not display the same   sleep patterns over time   or  associated factors .\n\n5  This   first longitudinal study on   children‚Äô   sleep   duration in   a   French   birth - cohort   aimed at i)  identifying   sleep   duration   trajectories   between   2   and   5 - 6   years ;   and   ii)   identif y ing   factors  associated with   each   sleep duration   trajector y .  2.   MATERIALS/SUBJECTS AND METHODS  2.1.   STUDY DESIGN  The EDEN study aims   at   investigat ing   the pre -   and post - natal determinants of child health  and   development. Details of the EDEN study protocol have been previously published   [21] .   Briefly,  pregnant women under 24 weeks of amenorrhea were recruited   between 2003 and 2006, in the  university hospitals of Poitiers and Nancy. Those under 18 years, unable to give informed consent,  functionally illiterate in French, with a history of diabetes, planning on changing address or without  social security coverage   were excluded from the cohort.   Multiple pregnancies were   also   excluded.  Among the 3758 women invited to participate, 2002 (53%) agreed to   enroll   in to   the study. Due to  miscarriages, stillbirths and attrition, 1899 children were enlisted at birth. Written   informed consent  was obtained twice from parents: at enrolment and after the child‚Äôs birth. The study was approved  by   the   ethics   research   committee   of   Bic√™tre   Hospital   (Comit√©   Consultatif   de   Protection   des  Personnes dans la Recherche Biom√©dicale) and by th e Data Protection Authority (Commission  Nationale de l‚ÄôInformatique et des Libert√©s).  2.2.   DATA COLLECTION  Data were collected   using   parental self - administered questionnaires and   during   clinical  examinations ,   including anthropometric measurements of each child.   Sleep items were study -  designed ones.  2.2.1.   Main measure: Night sleep duration  Night s leep   durations   w ere   collected at ages 2, 3 and 5 - 6 years old   and were   calculated  based on the answers to the following   questions: ‚ÄúUsually, at what time does your child go to  bed?‚Äù, ‚ÄúUsually, at what time does your child wake up?‚Äù .   Responses were recorded in hours and  minutes.  2.2.2.   Predictors  The   household   socio - economic   and   demographic   factors,   as   well   as   maternal  characteristics were collected at inclusion. Household income was divided into three categories:  below   ‚Ç¨ 1500 per month   ( ‚âà   French   threshold of poverty for a family) , between   ‚Ç¨ 1500 and   ‚Ç¨ 3000 per  month,   and   above   ‚Ç¨ 3000   per   month   ( ‚âà 10 th   upper   percentile   of   Fre nch   income   distribution).  Education level was also defined in three categories, using the highest level reached by one of the  parents: below high - school diploma, high - school diploma, and above. Single parenting was defined  as a mother living without the child‚Äôs father, another comp anion, or another adult family member.  Mothers   reported   information   on   age   at   delivery   and   tobacco   consumption   during   and   after\n\n6  pregnancy   (coded as   never , only after pregnancy and   always (during ¬± after pregnancy ) ) .   The  mother‚Äôs   depressive symptoms   during   pregnancy were assessed by the Fr ench version of the  Center of Epi demiolog i c S tudies Depression Scale ( CES - D ) .   Mothers with a CES - D score of   ‚â• 23  were considered to present depressive symptoms   [22] .   B ody mass index (B MI )   before pregnancy  was   calculated   using   reported   height   and   weight.   T he   maternity   ward   of   recruitment  (Nancy/Poitiers)   and the mother‚Äôs working status at age 2   ( coded as yes/no )   were also taken into  account .  The child‚Äôs characteristics and anthropometrics w ere collected at birth from self - reported  questionnaires and medical records, including gender,   first child   ( yes/no ), ponderal index (defined  by birth weight in kg divided by the cube of birth   length   in meters), and preterm birth (<   37 weeks of  amenorrhea).   Breastfeeding duration was collected in months   from   prospective   self - administered  questionnaires .   Temperamental traits, namely activity, shyness, emotionality and sociality were  assessed at age 1 using the Emotionality Activity an d Sociability scale (EAS)   [23] .  A t   age 2, data were   collected   for several sleep characteristics. Nap   duration   was   assessed  through   two questions :   ‚ÄúDoes your child regularly take a nap?‚Äù ‚ÄúIf yes, what is the mean duration of  a nap?‚Äù.   Responses were recorded in hours and minutes.   Children who did not nap were coded as  0 hours 0 minutes.   Frequent night awakenings at the age of 2 years were defined as waking every  other night or more (ye s/no) over the week preceding the self - questionnaire completion, in the  absence   of   acute   illness. Parental presence   when   falling   asleep   was also   collected   through  questions on sleeping habits (place (e.g. living room), parental interaction (e.g.   holding hands) and  bed sharing). A child was considered to sleep without parental presence when parents reported  that he/she felt asleep in his/her own bed without any adult interaction.  At age 2,   we collected   the number of hours per day spent in physical   activity (walking,  playing outside) and watching television or other screens during a usual week separately for  weekdays,   Wednesdays   (weekday   without   preschool   in   France)   and   for   weekend   days.   As  expected, the mean number of hours per day spent in physical   activity was statistically different  according to the season when the self - questionnaire was completed. We therefore split this  variable into quartiles according to each season   at which the questionnaire was completed . As this  was not the case for the num ber of hours spent watching TV, the latter was analysed continuously.  W e   also   assessed   care arrangement (in large collective settings like preschool or day care cent r es  vs. home care) .   F eeding at night   (bottle -   or breast - feeding,   yes/no)   was collected at 2 and 3 years  old .   T he c hild‚Äôs   BMI - z - score   was   c alculated using the WHO age and   gender   standards , and  obesity   was   defined   as   a   BMI - z - score   ‚â• 2   SD   [24] .   W e   also   accounted   for   dietary   patterns  previously identified in the EDEN cohort   [25] .   Briefly,   children‚Äôs dietary intake was collected using a  short food frequency questionnaire and   three dietary patterns   -   accounting for 26.8% of the  explained variance   -   were identified at 2 years of age using principal component analysis   (PCA) .  The first pattern ,   labeled   ‚Äò‚ÄòProcessed and fast foods‚Äô‚Äô ,   was   positively correlated with intake of\n\n7  French fries, processed meat, carbonated soft drinks, chocolate, chips, cookies, pizza, fruit juice,  meat, dairy desserts, and ice cream (by descending order of PCA   loadings). The second pattern,  labeled   ‚Äò‚ÄòGuidelines,‚Äô‚Äô   was   characterized   mainly   by   high   consumption   frequency   of   cooked  vegetables,   rice, fresh fruit, raw vegetables, low - fat fish, potatoes, ham, stewed fruit, and meat.  The third pattern ,   labeled   ‚Äò‚ÄòBaby foods‚Äô‚Äô,   had high positive loadings for baby foods, brea kfast  cereals, and stewed fruit and negative loadings for raw vegetables and fresh fruit.  2.3.   STATISTICAL METHODS  2.3.1.   Group - based trajectory modeling  The group - based trajectory modeling method   (PROC TRAJ procedure)   developed by Nagin  et al.   [26]   was used to   identify meaningful and distinct   patterns   of sleep duration   from the age 2 to  5 - 6 years .   The method is based on the underlying hypothesis that within a population there are  inherent groups that evolve according to different   sleep   patterns. The groups are not directly  identifiable or pre - established by sets of characteristics but statistically determined through each  series of responses using maximum likelihood. The   relationship between age and night sleep  duration was modeled by po lynomial equations defining trajectories. The most adequate model,  regarding the number of groups and the shape of the trajectories ,   was determined by iterations:  different models with two to five groups were computed and then compared   using the Bayesian  I nformation   Criteria   (BIC)   and   favoring   parsimony.   The   chosen   model   quality   was   verified  according to the recommended criteria : the average posterior probabilities for each subgroup  ( ‚â• 0.7) ,   the   odds of correct classification   ( ‚â• 5) , and   the similarity between   the model‚Äôs estimation of  the trajectory   prev alence and the actual prevalence   [26] .  Children were included in the trajectory‚Äôs elaboration if their parents had answered the  questions regarding   night - sleep durations at least   at   two time points out of three. To verify the  robustness of the model, sensitivity analys is   w as   performed   in   childr en who had complete sleep  duration data at all three time points .  2.3.2.   S tudy of associated factors  Children were assigned to   the trajectory for which he/she has the highest probability   of  belong ing. Multinomial logistic regressions were then computed to study   factors associated with  modeled night - sleep duration trajectories.   We chose as reference trajectory, the one that was the  nearest of the recommended sleep duration between 2 and 5 years old, i.e. between 11 and 11.30  hours/night.   An unadjusted analysis was   first performed   on collected data described in the previous  section , then a multivariable analysis that included factors   with   a p - value <0.20 in the unadjusted  analyses   and   socioeconomic   factors   (i.e.   parental   education   status,   household   income   and  recruitment   center ) . Missing values for   explanatory   factors represented 4.0% of the total data set.  Simple imputation s   (modal   value for categorical variables and   median   value   for continuous ones)  were implemented.\n\n8  All analyses were performed using SAS (SAS 9.3 SAS Institute Inc, Cary, NC, USA).  3.   RESULTS  3.1.   Night - sleep duration trajectories  Out of the   1899   children enrolled at birth,   self - administered questionnaires were available  for   1349   children   at   age   2, 1377 at   age 3 and 1 255 at   age   3.   A total of   12 05   presented two out of  three completed time points for   night - sleep duration   and were included in the trajectory conception .  Compared   to included children,   non - included   children   (N = 694 ) were   more   likely to   be born to a  mother   from   Nancy   recruitment cent e r   ( 41.4 % versus   31.5 %, p <10 - 4 ) ,   with low incomes   ( 19.0 %  ‚â§ 1500   ‚Ç¨ /months versus   10.4 %, p =0.01 ) ,   low educational level ( 31.0 % versus   15.2 %   with a level  below high - school diploma, p<10 - 4 ),   who smoked   during   and after   pregnancy   ( 66.7 %   versus  22.3 %,   p<10 - 4 ), and   who was   unemployed   2 years   post - partum   (4 3 .8% versus 26. 0 %, p<10 - 4 ) .  The re was no difference between the two population   group s regarding   maternal   age at delivery  (p=0.09) ,   parity   (p=0.92) ,   child gender   (p=0.46) , prematurity status   (p=0.82) ,   or breastfeeding  duration   (p=0.45) .   Mean night - sleep duration   of selected children   was   11 h rs 06   ( SD 0h49   -   range  8 h rs 00 - 14 h rs 00 )   at age 2   (N=1082) ,   10h rs 52 (SD 0h rs 40   -   range 9h rs 00 - 13h rs 45)   at age 3  (N=1170)   and   10 h rs 52   ( SD 0h rs 28   -   range   9 h rs 17 - 12 h rs 17 )   at   age   5 - 6   (N=1020) .  The optimal and parsimonious trajectory model to describe night - sleep duration patterns  was a five - group model   as illustrated in   Figure 1 :   a   S hort - S leep duration   trajectory   (SS,   always  <10h rs3 0/night) best explained by a   quadratic   relationship with time and representing   4.9 % of the  children ;   a M edium - L ow - S leep duration trajectory   (MLS, 10h rs 30 - 11h rs 00/night) best explained by  a   posi tive linear relationship with time and representing   47.8 % of the children ;   a M edium - H igh -  S leep   duration   trajectory   (MHS,   around   11h rs 30/night)   best   explained   by   a   negative   linear  relationship with time and representing   37.2 % of the children ;   a L ong - S leep duration trajectory   (LS,  ‚â• 11h rs 30/night) best explained by a negative linear relationship with time and representing   4.5 % of  the children ;   and   a   Changing - S leep duration trajectory   ( C S, i.e.   up to age 3   similar to   LS   and   then  to   MLS) estimated to be quadratic over time and representing   5.6 % of the children.   Nagin‚Äôs  recommended   criteria   for goodness of fit   were met for all groups   [26] .   To test robustness of the  model,   t he same procedure   was   performed   including   children with three completed time points  (N= 862 )   that   showed no notable difference regarding   i)   the number of groups,   ii)   the shape of the  trajectories or   iii)   compliance with   recommended criteria for goodness of fit   (data not shown) .  Hence, we chose to include the largest sample size for further analysis.\n\n9  Figure   1.   Night   sleep   duration   trajectories   obtained   among   the   EDEN   preschool   children  (N=1205). Full lines represent mean sleep duration trajectories. Black circles = Short sleepers (SS,  4.9% of the children): triangles = Medium Low sleepers (MLS, 47.8% of the chi ldren); diamonds =  Medium High sleepers (MHS, 37.2% of the children), squares = Changing (CS, 5.6% of the  children) and white circles = Long sleepers (LS, 4.5% of the children). Dashed lines represent the  95% confidence intervals of the trajectory estimati ons.  3.2.   Factors   associated with night - sleep   duration   trajectories  Population characteristics are presented in Table 1 and multivariable analysis is reported in  Table 2.   As compared to the MHS trajectory, membership to the SS trajectory between 2 to 5 - 6  years was more likely in boys, first - borns, born to older mothers, with   at age 2 years   higher  occurrence of frequent night waking, more frequent parental presence when fall ing asleep, longer  time spent in front of TV, higher scores on both the ‚ÄúProcessed and fast food‚Äù and ‚ÄúBaby foods‚Äù  dietary patterns, and when mothers worked 2 years post - partum . Of note, most of these factors  were also associated with the MLS trajectory me mbership, as compared to the MHS.   There   was   no  association between membership to SS or   to   M L S trajectories and   the maternal smoking status,  the child‚Äôs temperament scores   at   age 1   feeding at night at age 2 .  9  9,5  10  10,5  11  11,5  12  12,5  13  2   2,5   3   3,5   4   4,5   5   5,5  Night sleep duration (hours)  Age (years)\n\n10  Table 1 .   Characteristics of the 1205 children in the full sample and according to each night - sleep duration trajectory. Data are %(n) or  mean¬±sd.  Full sample   SS a   MLS a   MHS a   CS a   LS a   Global p - value  (n=1205)   n=59   n=576   n=448   n=68   n=54  Socieconomic factors  Center (Nancy)   46.8 (564)   47.5 (28)   46.9 (270)   45.1 (202)   60.3 (41)   42.6 (23)  Parental education level  < High school   15.2 (183)   17.0 (10)   14.6 (84)   15.2 (68)   17.7 (12)   16.7 (9)  High school   18.2 (219)   25.4 (15)   17.5 (101)   17.4 (78)   22.0   (15)   18.5 (10)  > high school   66.6 (803)   57.6 (34)   67.9 (391)   67.4 (302)   60.3 (41)   64.8 (35)  Household income  <1500   ‚Ç¨ /month   10.4 (125)   8.5 (5)   9.0 (52)   10.5 (47)   19.1 (13)   14.8 (8)  1501 - 3000   ‚Ç¨ /month   58.9 (710)   64.4 (38)   61.3 (353)   56.7 (254)   54.4 (37)   51.9 (28)  >3000   ‚Ç¨ /month   30.7 (370)   27.1 (16)   29.7 (171)   32.8 (147)   26.5 (18)   33.3 (18)  Maternal characteristics  Age at delivery (years)   30.0 ¬± 4.6   30.5 ¬± 4.59   30.5 ¬± 4.5   29.7 ¬± 4.7   28.6 ¬± 5.0   29.4 ¬± 4.4   **  Smoking habits   *  Never   64.3 (775)   57.6 (34)   66.8 (385)   64.7 (290)   50.0 (34)   59.3 (32)  Only after pregnancy   13.4 (161)   11.9 (7)   12.9 (74)   14.7 (66)   11.8 (8)   11.1 (6)  Always   22.3 (269)   30.5 (18)   20.3 (117)   20.5 (92)   38.2 (26)   29.6 (16)  Pre - pregnancy BMI   23.1 ¬± 4.3   23.   6 ¬± 4.4   23.3 ¬± 4.4   22.9 ¬± 4.1   23.1 ¬± 4.8   23.0 ¬± 4.5  Depressive symptoms b   5.2 (62)   3.4 (2)   4.3 (25)   5.1 (23)   11.8 (8)   7.4 (4)  Single parenting   3.5 (40)   1.8 (1)   4.1 (22)   3.3 (14)   3.0 (2)   1.9 (1)  Child characteristics  First child   46.6 (561)   61.0 (36)   43.6 (251)   46.2 (207)   58.9 (40)   50.0 (27)   *  Gender (Boy)   53.2 (641)   71.2 (42)   56.3 (324)   50.5 (226)   36.8 (25)   44.4 (24)   ***  Pre - term birth c   5.3 (64)   6.8 (4)   4.9 (28)   6.0 (27)   0.0 (0)   9.3 (5)  Child ponderal index (kg/m 3 )   27.0 ¬± 2.7   27.0 ¬± 2.3   26.9 ¬± 2.8   26.9 ¬± 2.54   27.4 ¬± 3.1   27.2 ¬± 3.2  Breastfeeding duration (months)   3.4 ¬± 3.7   2.9 ¬± 3.9   3.5 ¬± 3.8   3.1 ¬± 3.6   3.3 ¬± 3.9   3.   7 ¬± 4.0  Temperament at age 1 d  Activity   3.53 ¬± 0.48   3.63 ¬± 0.44   3.53 ¬± 0.47   3.54 ¬± 0.49   3.41 ¬± 0.53   3.51 ¬± 0.50  Shyness   2.08 ¬± 0.56)   1.97 ¬± 0.42   2.08 ¬± 0.58   2.10 ¬± 0.56   2.11 ¬± 0.62   2.12 ¬± 0.55  Emotionality   2.76 ¬± 0.70)   2.8 ¬± 0.86   2.76 ¬± 0.67   2.77 ¬± 0.69   2.63 ¬± 0.72   2.80 ¬± 0.80  Sociability   3.69 ¬± 0.59   3.83   ¬±   0.69   3.72 ¬± 0.58   3.65 ¬± 0.58   3.62 ¬± 0.61   3.74 ¬± 0.59  Characteristics at 2 years of age  Working mother   ** *  No   26.0 (313)   20.3 (12)   22.7 (131)   29.2 (131)   29.4 (20)   35.2 (19)  Part - time   34.1 (411)   33.9 (20)   35.6 (205)   34.2 (153)   32.4 (22)   20.4 (11)  Full - time   39.9 (481)   45.8 (27)   41.7 (240)   36.6 (164)   38.2 (164)   44.4 (24)\n\n11  Collective care arrangement   21.1 (254)   18.6 (11)   22.6 (130)   20.8 (93)   16.2 (11)   16.7 (9)  Nap duration (hrs/day)   2hrs04 ¬± 0hrs30   2hrs07 ¬± 0hrs34   2hrs04 ¬± 0hrs30   2hrs05 ¬± 0hrs29   2hrs02 ¬± 0hrs32   2hrs02 ¬± 0hrs30  Frequent night - wakings   20.3 (245)   40.7 (24)   24.1 (139)   14.1 (63)   19.1 (13)   11.1 (6)   ***  Falling asleep with p arental presence   11.5 (139)   25.4 (15)   13.7 (79)   8.7 (39)   5.9 (4)   3.7 (2)   ***  F eeding at night   26.4 (318)   25.4 (15)   26.9 (155)   24.8 (111)   45.6 (31)   11.1 (6)   ***  Body mass index (z - score)   0.25 ¬± 0.98   0.28 ¬± 0.78   0.25 ¬± 0.89   0.26 ¬± 0.85   0.27 ¬± 0.80   0.03 ¬± 0.74  Television watching (hrs/day)   0hrs40 ¬± 0hrs43   1hrs10 ¬± 1hrs10   0hrs41 (0hrs40)   0hrs37 (0hrs39)   0hrs31 (0hrs40)   0hrs40 (0hrs49)   ***  Physical activity (quartiles) e  Q1   23.4 (282)   28.8 (17)   24.5 (141)   21.4 (96)   27.9 (19)   16.7 (9)  Q2   27.2 (328)   17.0 (10)   25.4 (146)   31.2 (140)   20.6 (14)   33.3 (18)  Q3   24.2 (292)   27.1 (16)   24.1 (139)   23.7 (106)   23.6 (16)   27.8 (15)  Q4   25.2 (303)   27.1 (16)   26.0 (150)   23.7 (106)   27.9 (19)   22.2 (12)  Dietary pattern score  Processed and fast foods   - 0.05 ¬± 0.94   0.12 ¬± 1.08   - 0.01 ¬± 0.96   - 0.12 ¬± 0.87   0.11 ¬± 1.07   - 0.22 ¬± 0.80  Guidelines   0.03 ¬± 0.93   0.01 ¬± 1.05   0.01 ¬± 0.91   0.07 ¬± 0.94   - 0.05 ¬± 0.9   0.11 ¬± 0.94  Baby foods   - 0.02 ¬± 0.97   0.34 ¬± 0.94   - 0.03 ¬± 0.98   - 0.07 ¬± 0.94   0.11 ¬± 0.93   0.03 ¬± 1.08   *  * ‚â§ 0.05, ** ‚â§ 0.01, *** ‚â§ 0.001  a   Night sleep duration trajectories: SS for Short sleep duration, MLS for Medium Low sleep duration, MHS for Medium High sleep   duration, CS  for Changing sleep duration and LS for Long sleep duration trajectory.  b   Center of Epidemiologic Studies Depression   scale score   ‚â• 23  c   Birth before 37 weeks of amenorrhea  d   Emotionality Activity and Sociability scale (EAS); score range 0 ‚Äì 5, a higher score indicates more activity, shyness, emotionality or sociability  e   Quartiles of physical activity according to each   season\n\n12  Table 2. Multiple multinomial logistic regression for sleep trajectories, N=1205. The MHS a   trajectory served as reference  SS a   MLS a   CS a   LS a  Global p - value b  OR c   (95% CI)   OR c   (95% CI)   OR c   (95% CI)   OR c   (95% CI)  Socieconomic factors  Cente r   (Nancy)   1 . 44 (0 . 77   ‚Äì   2 . 70)   1.1 9   (0. 91   -   1.5 6 )   2.55 (1.4 1   -   4.5 8 ) **   0.9 6   (0.5 2   -   1. 79 )   *  Parental education level  < High school   0 . 80 (0 . 3 0   ‚Äì   2 . 14)   0.9 1   (0.5 7   -   1.4 4 )   0.72 (0.29   -   1.79)   1. 12   (0.4 1   ‚Äì   3.06 )  High school   (reference)   (reference)   ( reference)   (reference)  > high school   0 . 58 (0 . 27   ‚Äì   1 . 26)   1.00   (0.69   -   1.4 4 )   0.78 (0.37   -   1.6 6 )   0.9 4   (0.4 1   -   2.1 8 )  Household income (euros/months)  <1500   0.67 (0.18   -   2.4 5 )   1.2 1   (0.69   -   2.0 9 )   1.7 5   (0.6 3   -   4.8 9 )   1. 20   (0.39   -   3. 65 )  1501 - 3000   1.30   (0.62   -   2.74)   1.38 (1.01   -   1.88)   1.2 3   (0.62   -   2.43)   0.8 4   (0.4 1   -   1.7 1 )  >3000   (reference)   (reference)   (reference)   (reference)  Maternal characteristics  Age at delivery (years)   1.14 (1.06   -   1.22) ***   1.06 (1.03   -   1.10) ***   0.98 (0.91   -   1.05)   1.00   (0.9 3   -   1.07)   ***  Smoking habits  Never   (reference)   (reference)   (reference)   (reference)  Only after pregnancy   1.10 (0.44   -   2.76)   0.89 (0.61   -   1.30)   0.91 (0.39   -   2.13)   0.84 (0.33   -   2.13)  Always   1. 92   (0.9 5   -   3.8 7 )   1.0 3   (0.7 3   -   1.4 4 )   2.40 (1.27   -   4.5 5 ) **   1. 6 0 (0.7 9   -   3. 23 )  Depressive symptoms d   0.7 5   (0.16   -   3. 44 )   0.8 5   (0.47   -   1.5 5 )   2. 63   (1.0 3   -   6. 7 3) *   1.3 3   (0.43   -   4.1 4 )  Child characteristics  First child   3. 19   (1. 57   -   6. 50 ) ***   1. 08   (0.8 0   -   1. 45 )   1.83 (0.9 6   -   3.4 9 )   1. 00   (0.5 1   ‚Äì   1.96 )   **  Gender (Boy)   2.4 6   (1.3 0   -   4. 68 ) **   1.28 (0.99   -   1.6 6 )   0.60 (0.34   -   1.0 6 )   0.8 4   (0.4 5   -   1. 50 )   **  Temperament at age 1 e  Activity   1.0 3   (0.5 2   -   2.0 1 )   0.9 1   (0. 69   -   1.21)   0.52 (0.3 0   -   0.91) *   0.8 3   (0.4 5   -   1. 55 )  Shyness   0.91 (0.49   -   1. 70 )   1.02 (0.79   -   1.33)   1.1 2   (0.66   -   1.9 1 )   1.1 4   (0.6 3   -   2. 06 )  Emotionality   0.8 5   (0.54   -   1.3 4 )   0.93 (0.76   -   1.1 3 )   0.62 (0.41   -   0.9 5 ) *   1.00   (0.63   -   1.5 8 )  Sociability   1. 64   (0.9 3   -   2. 87)   1.1 9   (0.9 3   -   1.5 2 )   1.0 5   (0.6 3   -   1.7 5 )   1.4 6   (0.8 4   -   2. 52 )  Characteristics at 2 years   of age  Working mother   **  No   (reference)   (reference)   (reference)   (reference)  Part - time   2 . 39 (0 . 99   ‚Äì   5 . 74)   1 . 42 (1.00   ‚Äì   2 . 01)   1 . 18 (0 . 57   ‚Äì   2 . 42)   0 . 48 (0 . 21   ‚Äì   1 . 08)  Full time   2 . 93 (1 . 26   ‚Äì   6 . 80) *   1 . 78 (1 . 26   ‚Äì   2 . 52) **   1 . 22 (0 . 59   ‚Äì   2 . 50)   0 . 98   (0 . 49   ‚Äì   1 . 96)  Frequent night - wakings   3. 71   (1. 90   -   7. 21 ) ***   1.9 1   (1.3 5   -   2. 70 ) **   1.47 (0.7 2   ‚Äì   2.99 )   0.7 7   (0.31   -   1.9 3 )   ***  Falling asleep with parental presence   3. 44   (1. 59   ‚Äì   7.41 ) **   1.62 (1.05   -   2.50) *   0.5 4   (0.17   -   1.72)   0. 50   (0. 11   ‚Äì   2.22 )   **  F eeding at night   0.55 (0.27   -   1.1 4 )   1.00   (0.73   -   1.3 5 )   2.4 6   (1.3 8   -   4.4 7 ) **   0.3 7   (0.15   -   0. 92 ) *   ***  Television watching (hrs/day)   2.1 1   (1. 50   -   2.9 7 ) **   1.13 (0.93   -   1.38)   0.57 (0.35   -   0.93) *   1.1 3   (0.73   -   1.7 3 )   ***  Dietary pattern score  Processed and   fast foods   1.45 (1.06   ‚Äì   2.01 ) *   1.21 (1.04   -   1.41) *   1.38 (1.04   -   1.81) *   0.83 (0.57   -   1.2 2 )   *  Guidelines   1.00 (0.73   -   1.3 8 )   0.94 (0.82   -   1.0 9 )   0.91 (0.68   -   1.22)   1.07 (0.78   -   1.4 7 )  Baby foods   1.48 (1.08   -   2.03) **   1.0 6   (0.93   -   1.22)   1.18 (0.89   -   1.57)   1.12   (0.83   -   1.51)\n\n13  * ‚â§ 0.05, ** ‚â§ 0.01, *** ‚â§ 0.001  a   Night sleep duration trajectories: SS for Short sleep duration, MLS for Medium Low sleep duration, CS for Changing sleep dura tion and LS for  Long sleep duration trajectory.  b   p - value for the global effect of the corresponding factor analy z ed  C   odds ratio (OR) and 95% confidence interval (95%CI)  d   Center of Epidemiologic Studies Depression scale score   ‚â• 23  e   Emotionality Activity and Sociability scale (EAS); score range 0 ‚Äì 5, a higher score indicates more activity, shyness, emotionality or sociability\n\n1 4  As compared to the MHS trajectory, membership to the   C S trajectory was more likely   in  children   from Nancy ,   fed at night ,   with higher scores on the ‚ÄúProcessed and fast foods‚Äù dietary  pattern at 2 years ,   as well as   and   in children   whose mother presented depressive symptoms during  pregnancy and smoked during and after pregnancy .   The activity and emotionality temperament  score at 1 year old   decreased the likelihood of   membership to th e CS   trajectory as   did   time spent  in front of TV .   Moreover, additional adjustment for night feeding at 3 years did not change the  results. In   particular the OR for night feeding stayed very stable at 2 years (OR=2.28 (95%CI 1.19 -  4.40)), the one for night feeding at 3 years was borderline significant (OR=1.93 (0.95 - 3.88))  F eeding at night at 2 years old was the only factor associated with   membership to the LS  trajectory   showing that   night   fed   children   were less likely   to belong to   this trajectory   than to the  MHS one .  No   association   was   observed   between   sleep   duration   trajectories   and   socioeconomic  factors (education level, household incomes).  4.   DISCUSSION  This study ,   using trajectory   modeling ,   gives new insight into developmental patterns of  night - sleep duration and associated factors among   preschoolers .   In this context, t hree   trajectories  and their associated factors   are of particular interest: the SS trajectory that   was   under the sleep  duration recommendations, the LS   trajectory that slowly decreased   between   12.5hrs/night to  11hrs/night bet ween 2 and 5 - 6 years old and the   C S trajectory that showed a 2h rapid decrease  between 2 and 3 years.  4.1.   Sleep duration trajectories  We identified five   night   sleep   duration   trajectories   among   preschoolers .   We showed ,   as  others ,   that   each night sleep duration   trajectory (except the CS one)   was   quite stable during early  childhood   [18,27] .   This may reflect one child‚Äôs inherent sleep needs, howev er we identified several  factors associated with the belonging to each trajectory (discussed below)   stressing   the importance  for   good sleep habits   setting in early infancy .   In contrast,   the   thresholds   allowing to distinguish  different trajectories were overall higher   than those   described in Canadian pre - school population  (short   was defined as   < 9h rs /night , medium   low   as   10 - h rs   persistent , medium high   as   11 - h rs  persistent ,   changing   as   short then   between   10 - h rs   and 11 - h rs   persistent , and long   were   not  observed )   [18,19] .   These differences   may   partly   be explained by the   overall   higher night -   and total -  sleep durations in French   [14]   an d   in   North - European   [20]   preschool children, as   compared to  North Americans   [18,19,27] .   I n the present study, mean sleep durations at age 2, 3   and 5 - 6   were in  the higher limits of the American Academy of Sleep Medicine recommendations to promote optimal  health   [17] .   However, w e reported similar proportion of   members of   the   ‚Äú short ‚Äù   sleep trajectory  group   (5 to 6%)   to   that published among children o f   the same ages using   the   same trajectory  method   [18,19] .\n\n15  4.2.   Factors associated with short sleep   duration trajectory  The present study confirm ed   some of   the   risk factors for short sleep duration   suggested   in  both cross - sectional and longitudinal studies   among preschool or school aged children , i.e.   male  gender   [7 ‚Äì 10,14,19]   and maternal older age   [7,14] .   First - born children ha ve   been shown to present  shorter sleep duration in infancy   [28] ,   which could suggest   higher   parental   stress   or   higher   parental  intervention on child ‚Äôs sleep   or both .   However, the relation   wa s observed in the present analysis  independently of maternal age, maternal depressive status and sleep habits.   A couple of   sleep  habits ,   already shown to be associated with short sleep durations   [27] ,   w ere   positively   associated  with SS trajectory, namely parental presence when falling asl eep and   frequent night waking .   A s  often discussed, the association between   child‚Äôs sleep   and sleep strategies may be bidirectional  [29] ,   and   the child‚Äôs temperament   may influence sleep and sleep behaviors   [30,31] .   However,   the  observed   relation   persisted   after   adjustment   for   child‚Äôs   temperament   scores   suggesting  involvement of other factors such as parental beliefs and practices   [32] .   Altogether, these elements  indicate   that   children   belonging   to   the   short   sleep   trajectory   could   benefi t   from   behavioral  interventions promoting healthier sleep hygiene ,   shown to   be   associated with longer sleep duration  and less night - waking in childhood   [33,34] .  T ime spent in front of TV   at age 2   was positively associated with this SS trajectory   between  2 and 5 - 6 years old , as observed by others   [35] .   Beside children wit h low physiological sleep needs  who   may   be   entertained   by   longer   TV   watching,   t his   m ight   be   explained   either   by   direct  replacement of sleep   by TV   watching   or   by   the program viewed and its   aggressive ness   associated  with more sleep troubles   [36] .   Unfortunately,   these hypotheses could not be addressed in the  current study, given   that   the appropriate information was not collected . Another   explanation could  be   the   blue light exposure   from the   mobile   screens   alter ing   circadian rhythms .   T he low access to  these devices when data were collected   make s   this hypothesis unlikely .   Children belonging to the  SS trajectory   more   often   had   working mother s   at age 2.   Th e latter   m ay be   more likely to   come  back   home   later   than their non - working counterparts, making it more challenging   to get their  child ren   to   sleep   early ; they also   may   need to wake them up earlier   for   care arrangement ,  altogether resulting in   shorter night sleep duration   [37,38] .   However, i n the current study, there was  no difference in prevalence of   care arrangement according to the   five   trajectories.   Finally,   shorter  and lower quality of sleep   have been associated with higher energy intake mainly through   high fat  food   in adult s   [39]   and   chil d ren   [40] .   A recent review also noted that diet , especially diet rich   in  fresh fruits, vegetables, whole grains, and low - fat protein sources,   promotes sleep quantity in  adults   [41] .   In children,   Kocevska   et al .   showed that   a higher contribution of fat to total energy  intake   at 13 months of age was negatively associated with sleep duration at 2 years of age   [42] .  Th ese   findings   are   in li ne with the   positive association between   ‚ÄúProcessed and fast foods‚Äù dietary  pattern   scores   supposedly   positively   associated   with   total   energy   intake   and   SS   trajectory  observed in the current study .   A   positive   association   is also   noted with the   ‚ÄúB aby   foods ‚Äù   score .   One\n\n16  may say that working mothers with less   available   time to cook may   favor   prepared food s   for their  child either processed and fast food s   or   more specific al ly   baby food   [43 ‚Äì 45] .   In this context, these  latter associations may reflect a   less healthy   lifestyle .   R isk factors associated with the MLS  trajectory   ( between   10hrs30   and   11hrs/night)   were   similar   to   those   associated   with   the   SS  trajectory except for   gender ,   first child ,   television - viewing duration and baby - food dietary patterns  when compared to MLH trajectory.   MLS trajectory is ,   however, within the   Ame rican   Academy of  Sleep   Medicine   recommendation   of   sleep   duration   range   to   promote   optimal   health   among  preschoolers .   Furth er studies will be needed   to investigate   the   relations hips   between t h ese sleep  trajector ies   and   subsequent health outcomes.  4.3.   Factors associated with   changing   night - sleep duration trajectory  Factors associated with   C S   trajectory   (as compared with the MHS)   were   quite   specific   and  may reflect factors associated with the   sharp   decline   in sleep duration between 2 and 3 years old .  Of note,   care - arrangement ,   nap duration, working status,   incomes and parental education level s  were not associated with this trajectory.   Consistent with other studies   [11] ,   we   found that m aternal  depressi on   was   associated with short er   sleep duration in children .   Several studies conjecture that  at least part of this link is mediated by   inappropriate   sleep strateg ies   [46] ,   e.g.   feeding at night   ( as  also   observed   here) .   A nother inappropriate strategy could be   the use of   processed and fast foods  for the child,   that may   bring too much fat shown to be deleterious for good sleep   in childhood   [42] .  Processed   and   fast   foods   dietary   pattern   scores   have   been   shown   to   track   (spearma n  correlation=0.40, p<0.001) between 2 and 3 years old in the EDEN study   [25] .   We found   that easy  child   temperament   at   1   year   old   (lower   score   for   activity   and   emotionality)   was   positively  associated   with   the   C S   trajectory   between   2   and   5 - 6   years   old,   independently   of   maternal  depressive status.   Maternal smoking , especially during pregnancy,   h as been associated with sleep  disturbances   [47,48] ,   through   prenatal   physiological   modification   involving   hypoxia   (as   those  involved in   sudden i nfant   death syndrome   [49]   or by a direct increas e of   health problems such as  asthma, lower respiratory function, infections (reviewed in   Treyster et al   [50] )   or both .   Overall ,  factors associated with   membership   to the   C S   trajectory   we re   behavioral   ones reflecting a global  life style less stringent with familial health and health recommendations.   T he   positive   association  between   Nancy   recruitment   center   and th e   C S   trajectory   is unexpected   and still unexplained.   It  may reflect incomplete   accounting   f or some   risk factors (e.g. socioeconomic   or environmental  factors)   or existence of some yet unidentified ones within this specific group of children .   Future  studies w ill   be needed to explore   in particular   lifestyle   changes   that occurred   between 2 and 3  years old that might explain ,   at least partially ,   the rapid decrease of sleep duration within this sleep  trajectory .  4.4.   Factors associated with long   night sleep duration trajectory  After adjustment, t he only factor   remaining   significantly associated to the LS trajectory was  a   negative   one. Children within this trajectory were less   bottle - fed at night   at two years old   than the\n\n17  children of the MHS trajectory. This confirms the reduced occurrence of night waking and   thus   of  strat egies involved to get the child go back to sleep such as feeding.   Of note, there was no  association with   the parental education level, familial incomes, temperament scores   of the child   at  1 year,   maternal working status   or   dietary pattern scores.   This suggests that ,   despite night sleep  duration   evolution between 2 and 5 - 6 years , which may reflect   children   physiological needs   in  general population ;   children of both   MHS and LS   trajectories   were quite   similar.  4.5.   Strengths and limitations  S trength s   of this study   are   the   general   population sample and   the   longitudinal data   for  children   sleep   duration , along   with   the   method   used   that   allowed   a   powerful   developmental  analysis of night - sleep duration in preschool age.   However, the results of the present   study should  be   interpreted   in   light   of   some   limitations.   Sleep   duration   was   calculated   based   on   self -  administered questionnaires asking for usual bedtimes and wake up times with no information on  sleep onset. They may be different from bedtimes and diffic ult for parents to estimate. While sleep  duration here reflects time in bed, this is a measure still widely used in epidemiology   [7,16,20] .   To  better estimate sleep onset and time spent awake, an independent and objective measure of sleep  by actigraphy would have been more accurate but had not been considered   for   cost and   logistical  reasons . Simple parental reports on their child‚Äôs sleep duration have however been shown to be  reliable   when   compared   to   actigraphy   [51,52] .   Parental - r eported   sleep   durations   are   usually  overestimated   and   night   awakenings   underestimated   compared   to   actigraphy .   However,   the  questionnaires and methods used allow comparison with the international literature and   especially  studies performed in Canad a   with similar sleep questions and trajectory modeling   [18,19] .   We  selected children with availabl e sleep data at least for 2 out of 3 time points leading to sleep  duration trajectories estimation on 66% of the original cohort. Bias cannot be ruled out if for  example, those who were lost to follow up were more likely to have certain sleep duration  char acteristics. Comparison of included and excluded children showed   no   differences   for   night  sleep duration   when   available   and we hypothesize a low impact on the modeled   night sleep  duration   trajectories. However,   recruitment rate and   attrition in the cohort   follow up,   lead to a  studied population   with   higher socioeconomic status   and   higher education level   than the targeted  population   [21] ,   generalization of the   findings is not possible especially   regarding associated  factors to low social classes .   T his population selection may   also   explain certain observed   non -  significant associations .   In addition, w e   analyzed   simultaneously 5 trajectories and a   large   number  of variables   that   may   have   lead   to   lack of power especially when considering trajectories with small  sample size .   Lastly,   w e   did not perform correction for multiple testing and may have falsely  identified association between studied factors and sleep duration trajectories. Our results, issued  from this first longitudinal study on sleep duration trajectories and associated factor s among  preschoolers, will need to be confirmed\n\n18  5.   CONCLUSION  Trajectory analyses give new insight into developmental patterns of night - sleep duration  and   associated   factors   among   preschoolers .   The   study   confirmed   know n   early   life   factors  associated with   short er   sleep duration in   preschoolers   but also highlight ed   new ones such as   less  healthy   dietary patterns .   Interestingly ,   some of these   risk factors   including dietary patterns   were  associated with   medium - low sleep duration trajectory   that   however   meets   the   American Academy  of Sleep Medicine   sleep duration recommendations   in   preschoolers .   This study also identified a  particular sleep duration trajectory, the   ‚Äú changing ‚Äù   one,   that   presented specific early risk factors,  including   depressive symptoms during   pregnancy,   tobacco smoking during and after pregnancy,  feeding at night   and processed dietary pattern   at 2 years old.   Altogether, identified risk factors  associated with   shorter or   changing   sleep duration trajectories   between 2 to 5 - 6 years old   were  mainly   living   habits   and   may   reflect   global   less healthy   lifestyle. T hus   early   multi - behavioral  prevention interventions   may   be   beneficial in the s e   population s .   F urther studies   are needed to  investigate whether those sleep trajectories are differently related to   subsequent health outcomes  and to replicate the results   in larger mother - child cohorts.\n\n19  ACKNOWLEDGMENTS  Collaborators: We thank the EDEN mother - child cohort study group (I. Annesi - Maesano , J.Y  Bernard, J. Botton, M.A. Charles, P. Dargent - Molina, B. de Lauzon - Guillain, P. Ducimeti√®re, M. de  Agostini, B. Foliguet, A. Forhan, X. Fritel, A. Germa, V. Goua, R. Hankard, B. Heude, M. Kaminski,  B. Larroque‚Ä†, N. Lelong, J. Lepeule, G. Magnin, L. Ma rchand, C. Nabet, F. Pierre, R. Slama, M.J.  Saurel - Cubizolles, M. Schweitzer, O. Thiebaugeorges).  We thank all funding sources for the EDEN study: Foundation for medical research (FRM),  National Agency for Research (ANR), National Institute for Research i n Public health (IRESP:  TGIR cohorte sant√© 2008 program), French Ministry of Health (DGS), French Ministry of Research,  INSERM Bone and Joint Diseases National Research (PRO - A) and Human Nutrition National  Research Programs, Paris ‚Äì Sud University, Nestl√©, F rench National Institute for Population Health  Surveillance (InVS), French National Institute for Health Education (INPES), the European Union  FP7 programs (FP7/2007 - 2013, HELIX, ESCAPE, ENRIECO,Medall projects), Diabetes National  Research Program (in coll aboration with the French Association of Diabetic Patients (AFD), French  Agency   for   Environmental   Health   Safety   (now   ANSES),   Mutuelle   G√©n√©rale   de   l‚ÄôEducation  Nationale complementary health insurance (MGEN), French national agency for food security,  French   speaking association for the study of diabetes and metabolism (ALFEDIAM).\n\n20  REFERENCES  [1]   Gruber R. Short sleep duration is associated with teacher - reported inattention and cognitive  problems   in   healthy   school - aged   children.   Nat   Sci   Sleep   2012;4:33 ‚Äì 40.  doi:10.2147/NSS.S24607.  [2]   O‚ÄôCallaghan FV, Al Mamun A, O‚ÄôCallaghan M, Clavarino A, Williams GM, Bor W, et al. The  link between sleep problems in infancy and early childhood and att entio n problems at 5 and 14  years: Evidence from a birth cohort study. Early Hum Dev 2010;86:419 ‚Äì 424.  [3]   Reynaud E, Vecchierini M - F, Heude B, Charles MA, Plancoulaine S. Sleep and its relation to  cognition and behavior in typically developing preschool ag ed   children: a systematic review. J  Sleep Res 2018;In press. doi:10.1111/jsr.12636.  [4]   Miller M, Kruisbrink M, Wallace J, Ji C, Cappuccio FP. Sleep Duration and Incidence of  Obesity in Infants, Children and Adolescents: A Systematic Review and Meta - Analys is   of  Prospective Studies. SLEEP 2018;In Press.  [5]   Al Mamun A, O‚ÄôCallaghan F, Scott J, Heussler H, O‚ÄôCallaghan M, Najman J, et al. Continuity  and discontinuity of trouble sleeping behaviors from early childhood to young adulthood in a  large Australian com mun ity - based - birth cohort study. Sleep Med 2012;13:1301 ‚Äì 6.  [6]   Quach J, Hiscock H, Canterford L, Wake M. Outcomes of Child Sleep Problems Over the  School - Transition   Period:   Australian   Population   Longitudinal   Study.   Pediatrics  2009;123:1287 ‚Äì 92. d oi:10.1542/ped s.2008 - 1860.  [7]   Blair PS, Humphreys JS, Gringras P, Taheri S, Scott N, Emond A, et al. Childhood sleep  duration and associated demographic characteristics in an English cohort. Sleep 2012;35:353 ‚Äì  60.  [8]   Sadeh A, Raviv A, Gruber R. Sleep patt erns and sleep   disruptions in school - age children. Dev  Psychol 2000;36:291 ‚Äì 301. doi:10.1037/0012 - 1649.36.3.291.  [9]   Biggs SN, Lushington K, James Martin A, van den Heuvel C, Declan Kennedy J. Gender,  socioeconomic, and eth nic differences in sleep patterns in school - aged   children. Sleep Med  2013;14:1304 ‚Äì 9. doi:10.1016/j.sleep.2013.06.014.  [10]   McDonald L, Wardle J, Llewellyn CH, van Jaarsveld CHM, Fisher A. Pred ictors of shorter  sleep in early childhood. Sleep Med 2014;15:536 ‚Äì 40. doi:10.1016/j.sleep.2014.01.005.  [11]   Neva rez MD, Rifas - Shiman SL, Kleinman KP, Gillman MW, Taveras EM. Associations of  early life risk factors with infant sleep duration. Acad Pedia tr 2010;10:187 ‚Äì 93.  [12]   Mindell JA, Sadeh A, Kohyama J, How TH. Parental behaviors and sleep outcomes in infants  and   toddlers:   A   cross - cultural   comparison.   Sleep   Med   2010;11:393 ‚Äì 9.  doi:10.1016/j.sleep.2009.11.011.  [13]   Reynaud E, Forhan A, Heude B, de Lauzon - Guillain B, Charles M - A, Plancoulaine S. Night -  waking trajectories and associated factors in French preschoolers   from the EDEN birth - cohort.  Sleep Med 2016;27 ‚Äì 28:59 ‚Äì 65. doi:10.1016/j.sleep.2016.09.008.  [14]   Plancoulaine S, Lioret S, Regnault N, Heude B, Charles M - A, the Eden Mother - Child Cohort  Study Group. Gender - specific factors associated with shorter sleep durati on at age 3 years. J  Sleep Res 2015;24:610 ‚Äì 20. doi:10.1111/jsr.12308.  [15]   Touchette E, Petit D, Paquet J, Boivin M, Japel C, Tremblay RE, et al. Factors associated with  fragmented sleep at night across early childhood. Arch Pediatr Adolesc Med 2005;159:24 2 ‚Äì 9.  [16]   Galland BC, Taylor BJ, Elder DE, Herbison P. Normal sleep patterns in infants and children: a  systematic review of observational studies. Sleep Med Rev 2012;16:213 ‚Äì 222.  [17]   Paruthi S, Brooks LJ, D‚ÄôAmbrosio C, Hall WA, Kotagal S, Lloyd RM, et al.   Recommended  Amount of Sleep for Pediatric Populations: A Consensus Statement of the American Academy  of Sleep Medicine. J Clin Sleep Med 2016;12:785 ‚Äì 6. doi:10.5664/jcsm.5866.  [18]   Touchette E, Petit D, Seguin JR, Boivin M, Tremblay RE, Montplaisir JY. Ass ociations  between sleep duration patterns and behavioral/cognitive functioning at school entry. Sleep  2007;30:1213 ‚Äì 9.\n\n21  [19]   Touchette E, Cote SM, Petit D, Liu X, Boivin M, Falissard B, et al. Short nighttime sleep -  duration and hyperactivity trajectories in   early childhood. Pediatrics 2009;124:e985 - 93.  [20]   Hense S, Barba G, Pohlabeln H, De Henauw S, Marild S, Molnar D, et al. Factors that  influence weekday sleep duration in European children. Sleep 2011;34:633 ‚Äì 9.  [21]   Heude B, Forhan A, Slama R, Douhaud L, B edel S, Saurel - Cubizolles M - J, et al. Cohort  Profile: The EDEN mother - child cohort on the prenatal and early postnatal determinants of  child health and development. Int J Epidemiol 2015;45:353 ‚Äì 63. doi:10.1093/ije/dyv151.  [22]   F√ºhrer R, Rouillon F. La versi on fran√ßaise de l‚Äô√©chelle CES - D. Description et traduction de  l‚Äô√©chelle d‚Äôauto√©valuation [The French version of CES - D: Description and translation of the  self - report scale]. Psychiatr Psychobiol 1989;4:163 ‚Äì 6.  [23]   Buss A h., Plomin R. Temperament: early de veloping personality traits. Numerized. Michigan  Univsersity: Erlbaum; 2008.  [24]   de   Onis   M.   Development   of   a   WHO   growth   reference   for   school - aged   children   and  adolescents. Bull World Health Organ 2007;85:660 ‚Äì 7. doi:10.2471/BLT.07.043497.  [25]   Lioret S,   Betoko A, Forhan A, Charles M - A, Heude B, de Lauzon - Guillain B, et al. Dietary  Patterns Track from Infancy to Preschool Age: Cross - Sectional and Longitudinal Perspectives.  J Nutr 2015;145:775 ‚Äì 82. doi:10.3945/jn.114.201988.  [26]   Nagin DS. Group - based modell ing of development. Harvard University Press. Cambridge,  Massachusetts: 2005.  [27]   Sadeh A, Mindell JA, Luedtke K, Wiegand B. Sleep and sleep ecology in the first 3 years: a  web - based study. J Sleep Res 2009;18:60 ‚Äì 73. doi:10.1111/j.1365 - 2869.2008.00699.x.  [28]   Kaley F, Reid V, Flynn E. Investigating the biographic, social and temperamental correlates of  young infants‚Äô sleeping, crying and feeding routines. Infant Behav Dev 2012;35:596 ‚Äì 605.  doi:10.1016/j.infbeh.2012.03.004.  [29]   Sadeh A, Tikotzky L, Scher A.   Parenting and infant sleep. Sleep Med Rev 2010;14:89 ‚Äì 96.  doi:10.1016/j.smrv.2009.05.003.  [30]   Molfese VJ, Rudasill KM, Prokasky A, Champagne C, Holmes M, Molfese DL, et al. Relations  Between Toddler Sleep Characteristics, Sleep Problems, and Temperament.   Dev Neuropsychol  2015;40:138 ‚Äì 54. doi:10.1080/87565641.2015.1028627.  [31]   Sorondo BM, Reeb - Sutherland BC. Associations between infant temperament, maternal stress,  and   infants‚Äô   sleep   across   the   first   year   of   life.   Infant   Behav   Dev   2015;39:131 ‚Äì 5.  doi:10.1016 /j.infbeh.2015.02.010.  [32]   Tikotzky L, Shaashua L. Infant sleep and early parental sleep - related cognitions predict sleep in  pre - school children. Sleep Med 2012;13:185 ‚Äì 92. doi:10.1016/j.sleep.2011.07.013.  [33]   Mindell JA, Meltzer LJ, Carskadon MA, Chervin   RD. Developmental aspects of sleep hygiene:  Findings from the 2004 National Sleep Foundation Sleep in America Poll. Sleep Med  2009;10:771 ‚Äì 9. doi:10.1016/j.sleep.2008.07.016.  [34]   Mindell JA, Kuhn B, Lewin DS, Meltzer LJ, Sadeh A, American Academy of Sleep   Medicine.  Behavioral treatment of bedtime problems and night wakings in infants and young children.  Sleep 2006;29:1263 ‚Äì 76.  [35]   Cespedes   EM,   Gillman   MW,   Kleinman   K,   Rifas - Shiman   SL,   Redline   S,   Taveras   EM.  Television Viewing, Bedroom Television, and Sleep   Duration From Infancy to Mid - Childhood.  PEDIATRICS 2014;133:e1163 ‚Äì 71. doi:10.1542/peds.2013 - 3998.  [36]   Garrison MM, Liekweg K, Christakis DA. Media Use and Child Sleep: The Impact of Content,  Timing, and Environment. PEDIATRICS 2011;128:29 ‚Äì 35. doi:10.1542/ peds.2010 - 3304.  [37]   Speirs KE, Liechty JM, Wu C - F. Sleep, but not other daily routines, mediates the association  between maternal employment and BMI for preschool children. Sleep Med 2014;15:1590 ‚Äì 3.  doi:10.1016/j.sleep.2014.08.006.  [38]   Magee CA, Caputi P , Iverson DC. Are parents‚Äô working patterns associated with their child‚Äôs  sleep? An analysis of dual - parent families in Australia: Parent work and child sleep. Sleep Biol\n\n22  Rhythms 2012;10:100 ‚Äì 8. doi:10.1111/j.1479 - 8425.2011.00530.x.  [39]   Dashti HS, Scheer F A, Jacques PF, Lamon - Fava S, Ordovas JM. Short Sleep Duration and  Dietary Intake: Epidemiologic Evidence, Mechanisms, and Health Implications. Adv Nutr Int  Rev J 2015;6:648 ‚Äì 59. doi:10.3945/an.115.008623.  [40]   Fisher A, McDonald L, van Jaarsveld CHM, Llewel lyn C, Fildes A, Schrempft S, et al. Sleep  and energy intake in early childhood. Int J Obes 2014;38:926 ‚Äì 9. doi:10.1038/ijo.2014.50.  [41]   Peuhkuri K, Sihvola N, Korpela R. Diet promotes sleep duration and quality. Nutr Res  2012;32:309 ‚Äì 19. doi:10.1016/j.nutr es.2012.03.009.  [42]   Kocevska D, Voortman T, Dashti HS, van den Hooven EH, Ghassabian A, Rijlaarsdam J, et al.  Macronutrient Intakes in Infancy Are Associated with Sleep Duration in Toddlerhood. J Nutr  2016;146:1250 ‚Äì 6. doi:10.3945/jn.115.225847.  [43]   Slate r J, Sevenhuysen G, Edginton B, O‚Äôneil J. ‚ÄòTrying to make it all come together‚Äô:  structuration and employed mothers‚Äô experience of family food provisioning in Canada. Health  Promot Int 2011;27:405 ‚Äì 415.  [44]   Blake CE, Wethington E, Farrell TJ, Bisogni CA, D evine CM. Behavioral Contexts, Food -  Choice Coping Strategies, and Dietary Quality of a Multiethnic Sample of Employed Parents. J  Am Diet Assoc 2011;111:401 ‚Äì 7. doi:10.1016/j.jada.2010.11.012.  [45]   Datar A, Nicosia N, Shier V. Maternal work and children‚Äôs di et, activity, and obesity. Soc Sci  Med 2014;107:196 ‚Äì 204. doi:10.1016/j.socscimed.2013.12.022.  [46]   Jian N, Teti DM. Emotional availability at bedtime, infant temperament, and infant sleep  development   from   one   to   six   months.   Sleep   Med   2016;23:49 ‚Äì 58.  doi:10. 1016/j.sleep.2016.07.001.  [47]   Johansson A, Ludvigsson J, Hermansson G. Adverse health effects related to tobacco smoke  exposure in a cohort of three - year olds: Tobacco smoke exposure related to health. Acta  Paediatr 2008;97:354 ‚Äì 7. doi:10.1111/j.1651 - 2227. 2007.00619.x.  [48]   Yolton K, Xu Y, Khoury J, Succop P, Lanphear B, Beebe DW, et al. Associations Between  Secondhand Smoke Exposure and Sleep Patterns in Children. PEDIATRICS 2010;125:e261 ‚Äì 8.  doi:10.1542/peds.2009 - 0690.  [49]   Fleming   PJ,   Blair   PS,   Pease   A.   S udden   unexpected   death   in   infancy:   aetiology,  pathophysiology, epidemiology and prevention in 2015. Arch Dis Child 2015;100:984 ‚Äì 8.  doi:10.1136/archdischild - 2014 - 306424.  [50]   Treyster Z, Gitterman B. Second hand smoke exposure in children: environmental fac tors,  physiological effects, and interventions within pediatrics. Rev Environ Health 2011;26:187 ‚Äì 95.  [51]   Iwasaki M, Iwata S, Iemura A, Yamashita N, Tomino Y, Anme T, et al. Utility of Subjective  Sleep Assessment Tools for Healthy Preschool Children: A Com parative Study Between Sleep  Logs,   Questionnaires,   and   Actigraphy.   J   Epidemiol   2010;20:143 ‚Äì 9.  doi:10.2188/jea.JE20090054.  [52]   Sadeh A, Hauri PJ, Kripke DF, Lavie P. The role of actigraphy in the evaluation of sleep  disorders. Sleep 1995;18:288 ‚Äì 302.",
      "embedding": [
        0.013389567844569683,
        0.020111804828047752,
        -0.0037707665469497442,
        0.07312532514333725,
        0.07021722942590714,
        0.052542224526405334,
        -0.08525272458791733,
        0.041415393352508545,
        0.09238744527101517,
        0.021557288244366646,
        -0.01964913122355938,
        -0.057897768914699554,
        0.007792262360453606,
        0.030451186001300812,
        -0.023274801671504974,
        0.04061650112271309,
        0.06551884859800339,
        0.019714409485459328,
        -0.006487845443189144,
        0.02008482813835144,
        0.05693267658352852,
        0.011782649904489517,
        0.12670926749706268,
        -0.0005118278204463422,
        0.04525173828005791,
        0.039030253887176514,
        0.029838915914297104,
        -0.043987538665533066,
        -0.053122829645872116,
        0.018747417256236076,
        0.0007864619255997241,
        0.055215347558259964,
        0.014543416909873486,
        -0.05400290712714195,
        -0.02723950706422329,
        -0.011437512934207916,
        0.07062500715255737,
        0.02261953614652157,
        -0.10438746213912964,
        0.032871559262275696,
        0.011966458521783352,
        0.039651110768318176,
        -0.05203598365187645,
        -0.0750056654214859,
        -0.043273575603961945,
        -0.050311408936977386,
        -0.030043920502066612,
        -0.0488729253411293,
        -0.10633979737758636,
        0.03839883580803871,
        -0.003528299042955041,
        -0.011659560725092888,
        -0.03710903972387314,
        0.035471998155117035,
        0.006729502230882645,
        -0.03884498402476311,
        -0.06617256999015808,
        -0.0011295360745862126,
        0.07384390383958817,
        0.05314420536160469,
        -0.030961407348513603,
        0.05473671108484268,
        0.01992335356771946,
        -0.019101442769169807,
        0.05713983252644539,
        0.10030622035264969,
        -0.06931586563587189,
        -0.009643509984016418,
        0.01066051796078682,
        -0.011455509811639786,
        -0.0757613256573677,
        -0.04647531360387802,
        0.020352663472294807,
        0.06653048098087311,
        -0.013250363059341908,
        0.010999406687915325,
        0.17890070378780365,
        0.04274262115359306,
        0.031078683212399483,
        -0.14519120752811432,
        0.00851503200829029,
        0.10788296163082123,
        0.04785020276904106,
        0.0278156828135252,
        -0.04191417992115021,
        0.028511354699730873,
        0.11814654618501663,
        0.07229715585708618,
        -0.06283996999263763,
        -0.0035068003926426172,
        0.032078590244054794,
        0.004275802057236433,
        -0.03556181490421295,
        -0.018298182636499405,
        0.07973279803991318,
        -0.04448642581701279,
        -0.058720022439956665,
        0.033260345458984375,
        -0.02986116148531437,
        -0.11758346855640411,
        -0.020031722262501717,
        0.032565079629421234,
        -0.020022211596369743,
        0.07571853697299957,
        -0.007486291229724884,
        0.0018982517067342997,
        -0.01756460964679718,
        -0.11665849387645721,
        -0.046220563352108,
        0.014120059087872505,
        -0.030162900686264038,
        0.054826270788908005,
        0.002052223775535822,
        0.030924363061785698,
        0.10809537023305893,
        -0.04383217543363571,
        -0.0030123395845294,
        0.03758668154478073,
        0.07134147733449936,
        0.025002561509609222,
        0.05819128826260567,
        -0.0038000973872840405,
        0.061193954199552536,
        -0.117287777364254,
        0.009223666042089462,
        -0.03374920040369034,
        -0.03091992810368538,
        7.38436588042136e-33,
        -0.06093587353825569,
        -0.037393562495708466,
        0.018747514113783836,
        0.0341050922870636,
        -0.028587274253368378,
        0.04226931184530258,
        -0.01859143376350403,
        0.05644490197300911,
        0.053522784262895584,
        -0.015649402514100075,
        -0.10405287891626358,
        -0.05163269117474556,
        -0.011050540953874588,
        -0.01655094511806965,
        0.02283705770969391,
        0.07568471133708954,
        -0.08861511945724487,
        0.015943825244903564,
        -0.0441783107817173,
        -0.0019208230078220367,
        -0.06303706765174866,
        -0.02639443427324295,
        0.058176420629024506,
        0.056435536593198776,
        0.0174171831458807,
        -0.014322130009531975,
        -0.012004205957055092,
        0.03384922817349434,
        -0.022165920585393906,
        -0.018963653594255447,
        -0.004564880393445492,
        -0.004149912390857935,
        -0.005453094374388456,
        -0.10676637291908264,
        0.01066977996379137,
        0.01177949458360672,
        0.08872834593057632,
        0.02102869190275669,
        -0.057261254638433456,
        -0.017993532121181488,
        -0.08323399722576141,
        0.019689954817295074,
        -0.018119564279913902,
        0.016172315925359726,
        -0.006232306826859713,
        -0.048761699348688126,
        -0.0051590087823569775,
        -0.038503438234329224,
        0.05338326096534729,
        -0.00656350189819932,
        -0.016164466738700867,
        -0.0004096203192602843,
        -0.04637574404478073,
        -0.12506550550460815,
        -0.07949173450469971,
        0.08667144179344177,
        -0.03370581567287445,
        -0.00022946609533391893,
        -0.11052369326353073,
        0.04165378212928772,
        0.0009871326619759202,
        -0.055137693881988525,
        -0.017965858802199364,
        -0.08300656825304031,
        -0.018097583204507828,
        0.027591662481427193,
        0.048384737223386765,
        0.018891310319304466,
        -0.004477181937545538,
        -0.10511549562215805,
        0.026516873389482498,
        -0.07564010471105576,
        0.069402314722538,
        0.002811797196045518,
        0.0034703330602496862,
        -0.03683101758360863,
        0.08416970074176788,
        0.01870874874293804,
        -0.04227456822991371,
        -0.04349881038069725,
        -0.018203359097242355,
        -0.004834766034036875,
        -0.014684602618217468,
        -0.09813656657934189,
        0.015046309679746628,
        -0.08769712597131729,
        0.019405655562877655,
        0.0191652812063694,
        -0.07347586005926132,
        -0.04079573228955269,
        -0.013699830509722233,
        -0.022921312600374222,
        0.051065072417259216,
        0.022719701752066612,
        -0.040217332541942596,
        -8.692179018159989e-33,
        -0.007264156825840473,
        -0.02071242406964302,
        -0.016553962603211403,
        -0.07442160695791245,
        0.0571189783513546,
        -0.0400468111038208,
        0.0007000979385338724,
        -0.03699827194213867,
        -0.007111735641956329,
        -0.08177778869867325,
        0.04607902839779854,
        -0.06609591841697693,
        0.04939613863825798,
        -0.10532135516405106,
        0.04996299371123314,
        0.016339322552084923,
        -0.020474763587117195,
        0.01745297946035862,
        -0.00738138472661376,
        0.05323103070259094,
        0.04786929488182068,
        -0.061983563005924225,
        -0.08385986089706421,
        -0.09602587670087814,
        0.04606841877102852,
        0.06405116617679596,
        0.02766605094075203,
        0.087408147752285,
        0.04966984689235687,
        -0.041236188262701035,
        0.047901466488838196,
        0.047350868582725525,
        -0.054859697818756104,
        0.010713550262153149,
        0.02685610018670559,
        0.0022918174508959055,
        -0.02381586655974388,
        0.011537925340235233,
        -0.03549063950777054,
        -0.08582092076539993,
        0.06361271440982819,
        0.0531596802175045,
        0.002643527463078499,
        -0.035416893661022186,
        0.02883276157081127,
        0.08639395236968994,
        0.03564879298210144,
        -0.01867324486374855,
        0.041752927005290985,
        0.03371523693203926,
        0.10129810869693756,
        0.04351373389363289,
        -0.08955767750740051,
        0.03253266587853432,
        0.004999072756618261,
        -0.01937437802553177,
        0.05678325146436691,
        -0.03438258916139603,
        0.0029425485990941525,
        0.022542091086506844,
        0.04236777126789093,
        0.01770639792084694,
        -0.040690936148166656,
        -0.014977562241256237,
        0.07296579331159592,
        -0.03525737673044205,
        -0.043296437710523605,
        -0.07320806384086609,
        -0.011554553173482418,
        -0.03957580402493477,
        -0.02350957877933979,
        -0.03460635244846344,
        0.007236977107822895,
        -0.051693227142095566,
        -0.050535235553979874,
        -0.04772810637950897,
        -0.028884954750537872,
        -0.008983281441032887,
        -0.05242963507771492,
        0.01041312888264656,
        -0.05061569809913635,
        -0.1080295592546463,
        0.042755287140607834,
        -0.020281994715332985,
        -0.09229660034179688,
        -0.07676959037780762,
        0.008388767018914223,
        -0.01825254037976265,
        0.09506707638502121,
        0.024410733953118324,
        -0.025597942993044853,
        -0.003202820895239711,
        -0.11442844569683075,
        0.009798867627978325,
        -0.001267866464331746,
        -6.145166508986222e-8,
        0.14148423075675964,
        0.0070082200691103935,
        0.03319668769836426,
        0.02966160513460636,
        0.02549331821501255,
        -0.05337497591972351,
        0.030053697526454926,
        0.05039667338132858,
        -0.05336739122867584,
        0.09088470041751862,
        -0.023583194240927696,
        0.04952668026089668,
        0.007706905715167522,
        -0.019756345078349113,
        0.012689873576164246,
        -0.0715215727686882,
        -0.007262843661010265,
        0.015738172456622124,
        0.041386183351278305,
        0.0376628041267395,
        0.05126515030860901,
        0.021136585623025894,
        -0.06652005016803741,
        -0.06554688513278961,
        0.008439520373940468,
        0.013060382567346096,
        0.01374373771250248,
        0.015985634177923203,
        0.0026468343567103148,
        -0.06504113227128983,
        0.11179329454898834,
        0.005688034929335117,
        0.039613593369722366,
        -0.02795097976922989,
        -0.036328043788671494,
        -0.10328610241413116,
        -0.02500913292169571,
        0.08161338418722153,
        -0.0538204126060009,
        0.1606639325618744,
        0.024251705035567284,
        0.044165223836898804,
        -0.017495902255177498,
        -0.004057572688907385,
        0.019206224009394646,
        -0.02381855994462967,
        -0.035029660910367966,
        0.01888132095336914,
        0.011119530536234379,
        0.04347477853298187,
        -0.017864562571048737,
        -0.0663258358836174,
        -0.0016528564738109708,
        -0.05586516484618187,
        0.010277139954268932,
        0.05568375810980797,
        0.03431091830134392,
        -0.020193617790937424,
        0.009972936473786831,
        -0.023101113736629486,
        0.03568674251437187,
        -0.013118071481585503,
        0.009795158170163631,
        0.02932509407401085
      ],
      "metadata": {
        "title": "Paper_16_Night_sleep_duration_trajectories_and_associated_f.pdf",
        "createdAt": "2025-12-17T13:56:34.599Z"
      },
      "fileObj": {}
    },
    {
      "id": "doc_8_1765979795486",
      "fileName": "Paper_19_SWS_promoting_MHb_IPN_MRN_circuit_opposes_the_thet.pdf",
      "content": "SWS- promoting MHb-IPN-MRN circuit opposes  the theta- promoting circuit, active wake and REM sleep.  A circuit-based model of functional properties.  Karin Vadovi ƒç ov√°  ABSTRACT Hippocampus was connected to medial habenula (MHb) by multisynaptic axonal tracts in my previous DTI study. These probabilistic tracts linked hippocampus to septum, and amygdala to bed nucleus of stria terminalis (BNST). The axons from septum and BNST passed by anteromedial thalamic nucleus (AM) to MHb, then from MHb to pineal gland, known for control of circadian cycles and sleep. Question is what is the MHb doing and why it receives information from hippocampus via septum? So this study explores the connectivity of MHb, predicts its functional role and how it is linked to memory replay. My combination of known findings about septum and MHb connectivity and function led to this circuit-based idea/hypothesis that posterior septum activates MHb, MHb activates interpeduncular nucleus (IPN), and then IPN stimulates MRN and its serotonin release. Proposed idea is that this MHb-IPN-MRN circuit promotes slow wave sleep (SWS), high serotonin and low acetylcholine state. My prediction is that this SWS-promoting circuit reciprocally suppresses the theta oscillations promoting circuit, linked to high acetylcholine levels in brain, and formed by supramamillary area (SUM) projections to the medial septum (MS) that induces theta rhythm in hippocampus and other theta-coupled regions. The MHb- IPN-MRN pathway likely inhibits, possibly reciprocally, also some regions that have stimulating input to the theta-generating SUM and MS, such as the wakefulness promoting nucleus incertus (NI), posterior hypothalamus (PH), lateral hypothalamus (LH) and laterodorsal tegmentum (LDT), as well as the REM sleep inducing neurons in LDT and reticular nucleus pontis oralis (PnO). Thus, proposed SWS- promoting circuit attenuates the output of the theta-promoting regions, both the active wake-on and REM-on regions. The theta rhythm in wake state is linked to recording and binding information with their spatio- temporal and relational context by hippocampus, while the SWS supports rest, replay and transfer of hippocampally stored inter-connected information/memory traces and their cortical reactivations, e. g. in retrosplenial cortex linked to autobiographic memory or in prefrontal cortex that can combine information from any sources.  Introduction. Known role of serotonin in inducing SWS.  Serotonin signal in the brain induces behavioural and emotional relaxation, slow-down and rest while dopamine promotes action, locomotion, motivation, speeding up. Serotonin is present early during embryogenesis, probably to slow down/lower heart rate and blood pressure (by activating parasympathetic system). Later on the same serotonin slows down skeletal muscles movement (running, locomotion) and breathing, attenuates sympathetic system by inhibiting amygdala and dorsal anterior cingulated cortex (dACC), plus might enable the relaxation phase in ON-OFF rhythmic motor activity of axial muscles in fish where contraction alternates with extension. Brain serotonin slows down locomotion, calms down the active avoidance, negative emotions and drive, makes us rest and relax, promotes\n\nwell-being (Vadovi ƒç ov√° and Gasparotti, 2014), satisfaction and reconstructive (deep) stage of sleep called slow wave sleep or non-REM (SWS or NREM) sleep. SWS shows high amplitude, low frequency EEG, while the rapid eye movement (REM) sleep shows low amplitude, high frequency EEG oscillations in cortex (Jouvet, 1962). The SWS is known for its recovery-restorative function, calcium cascade of nocturnal proteosyntesis and also for the replay and transfer of the contextually/relationally bound information from the hippocampus to cortex, by replaying the waking neuronal firing patterns in hippocampus and cortex during temporally coupled hippocampal sharp-wave/ripples (SWRs) and cortical spindles (Buzs√°ki, 1989). The 5-10 Hz oscillations in the hippocampal local field potential called theta rhythm occur during voluntary exploration, locomotion and REM sleep (O'Keefe and Recce, 1993; Bland and Oddie, 2001; Buzsaki, 2002). REM sleep is proportionally more abundant in young mammals (Roffwarg et al. 1966). The EEG patterns of sleep and wakefulness become adult-like only after full development of the cortex (Blumberg et al., 2003). The fast EEG synchrony typical of wakefulness develops through adolescence in humans, similar to prolonged cortical maturation in higher primates (Uhlhaas et al., 2009).  Serotonin from the dorsal raphe nucleus (DRN) has been functionally grouped with the arousal-promoting neuromodulators important for wake state: noradrenaline, histamine, orexin (hypocretin) and acetylcholine. Orexin stabilizes wakefulness, as its deficiency causes narcolepsy disorder with inability to maintain long waking periods, with abrupt transitions into SWS sleep, and intrusions of REM sleep into waking (Sakurai, 2007). In addition, the mice deficient in norepinephrine or histamin sleep more and have no trouble to fall asleep after mild stress. In contrary, mice lacking serotonin receptor 5-HT1A (inhibitory receptor, also MRN autoreceptor) have 400% more REM sleep. The orexin, histamine and noradrenaline neurons have highest firing rate in wakefulness (Aston-Jones and Bloom, 1981). Extracellular electrophysiological recordings in freely moving cats have shown that DRN serotonergic neurons fire tonically during wakefulness, decrease their activity during slow wave sleep (SWS), and are nearly quiescent during REM (McGinty and Harper, 1976; Trulson and Jacobs, 1979). In contrary, the acetylcholine levels in the rat thalamus (innervated by mesopontine cholinergic neurons) are intermediate in SWS but high in both REM and wake-state (Williams et al., 1994). In addition the acetylcholine release during active waking is increased by approximately 75% compared to quiet waking (Marrosu et al., 1995). Interestingly the tonic dopamine firing seems to be present in all sleep-wake cycles, and burst firing was found in both wake and REM sleep (Dahan et al., 2007).  Raphe system lesion in cats caused permanent insomnia and diminution of cerebral serotonin (Jouvet et al., 1967) and MRN lesions produced uninterrupted theta (Maru et al., 1979; Yamamoto et al., 1979). Serotonergic firing is inversely correlated with the occurrence of ponto-geniculo-occipital PGO-waves (Lydic et al., 1983) that are typical for REM sleep. Inhibition of serotonin synthesis in cats induced PGO- waves also in waking state (Jacobs et al., 1972). Injection of serotonin precursor induced SWS and suppressed REM sleep for 5-6 hours (Bogdanski et al., 1958; Monnier and Tissor, 1958; Costa et al, 1960; Delorme, 1966). So these SWS-promoting effects of serotonin are not caused by the wakefulness linked DRN and its cortical, striatal and amygdalar projections involved in choice behavior and well- being, but by the MRN that has the needed subcortical afferents and efferents to interact with the other SWS-promoting regions, and to suppress the theta, wakefulness and REM sleep promoting regions. Main MRN efferents target midline forebrain including supramamillary nucleus (SUM), medial mamillary body (MMB), medial septum and vertical diagonal band of Broca (MS/vDBB), posterior hypothalamus (PH), lateral habenula (LHb), perifornical hypothalamus (PeF), midline and intralaminar thalamus, zona incerta (ZI) and hippocampus\n\n(Vertes and Linley, 2008). Main MRN and DRN afferents are from lateral and medial preoptic area (LPO, MPO), LHb, lateral hypothalamus (LH) and PeF (both produce orexin), dorsomedial nuclei of hypothalamus (DMN), midbrain nuclei, locus coeruleus (LC), caudal raphe nuclei, laterodorsal thalamus (LDT) and periacqueductal grey (PAG). Additional MRN afferents are from IPN and MB, while the DRN afferents are from amygdala, bed nucleus of stria terminalis (BNST), lateral septum (LS), substantia nigra, DBB and tuberomamillary nucleus (TMN). Serotonin hyperpolarizes cholinergic burst neurons in the rat LDT in vitro (Luebke et al., 1992), so opposes/suppresses the theta circuit, wake and REM sleep states that require this acetylcholine signal. Serotonergic MRN projections inhibit also theta bursting of MS/vDBB, the source of hippocampal theta rhythm (Kinney et al., 1996). This was found by recordings in mice MS/DBB and hippocampus after inhibition of MRN by 5-HT1A agonist on its autoreceptors. This is a functional evidence for known antagonism between the SWS- provoking MRN and the theta-generating MS/vDBB region.  Cholinergic agonists promote theta rhythm and PGO waves in rats and cats, but serotonergic neurons inhibit theta rhythm and PGO waves. The reciprocal interaction model of sleep control (Hobson and McCarley 1975; McCarley and Hobson 1975) proposed that REM-on neurons increase their firing just prior and during REM, while REM-off neurons show reverse pattern. The cholinergic REM-on neurons were located in LDT and PPT. The norepinephrine and serotonin REM-off neurons (from locus coeruleus and raphe nucleus) were found to be inhibited during REM sleep, and to inhibit REM-on (cholinergic) neurons in LDT/PPT during waking and SWS. Many studies support this mutual inhibition between the REM sleep and SWS circuits. For example reversible inactivation of LC and DRN by cooling decreased REM sleep (Cespuglio et al, 1982). In cats were REM-on LDT/PPT neurons inhibited by serotonin agonist, while WAKE-on/REM-on neurons were unaffected (Thakkar et al., 1998). Role of acetylcholine in promoting REM sleep in animals was found in early studies (George et al., 1964; Hernandez-peon et al., 1964). Multiple studies in humans showed that enhancement of cholinergic tone decreases REM sleep latency and increases its amount (Berkowitz et al. 1990; Hohagen et al., 1993; Lauriello et al, 1993; Riemann et al., 1994; Sitaram and Gillin, 1980; Sitaram et al., 1976).  Based on combination of functional findings and anatomical connectivity of the medial habenula (MHb), interpeduncular nucleus (IPN) and serotonergic MRN in the literature, this new hypothesis shows how the MHb   ÔÉ†   IPN   ÔÉ†   MRN circuit (linked to the low acetylcholine and high serotonin state) promotes slow wave sleep. This idea proposes antagonism (reciprocal inhibition) between this SWS-promoting circuit and the theta- promoting circuit formed by SUM and MS/vDBB. The strength of theta oscillations increases during both active wake and REM sleep. Theta rhythm is linked to high acetylcholine release in brainstem and thalamus. This model predicts also a functional opposition between the MHb  ÔÉ†   IPN   ÔÉ†   MRN circuit and some regions that stimulate the theta-promoting circuit: nucleus incertus (NI), PH, LH, LDT and ventral tegmental nucleus of Gudden (VTg). Both MRN and LPO are known to promote SWS. As the IPN projects to LPO, it might also potentiate the LPO effects.  After first describing the function and connectivity of proposed MHb-IPN-MRN circuit, the following sections will try to show its interesting known and predicted interactions with several regions involved in control of wakefulness, sleep, in theta oscillations, or contextual memory formation and recall.  The medial habenula pathway.\n\nThis study extends the prevailing models of sleep and wakefulness control in the brain, by adding the MHb and IPN regions to the known systems and circuits. It will provide wider context, circuit based and functional evidence for the idea that posterior septum (PS) activates MHb, which activates IPN, which stimulates serotonergic MRN to promote SWS and to inhibit the theta-, wakefulness and REM sleep promoting regions (Vadovi ƒç ova, 2014). This idea came from my DTI probabilistic tractography study in humans, which showed disynaptic axonal tracts that connected hippocampus and amygdala (via dorsal thalamus and via fornix) to septum and anterior BNST, which both projected to MHb. The observed axonal tracts from hippocampus and amygdala passed tightly by both septum and aBNST, then turned posteriorly by anteromedial thalamus (AM), and reached to MHb via stria medialis, then projected from MHb to the pineal gland. This pathway resembled the MHb afferents known from tracing studies in rat. The observed tract branched around septum and BNST to reach also hypothalamus, and via the amygdalofugal pathway passing by/through substantia innominata (SI) it was linked also with dorsal central amygdala (CeA) and hippocampus. Also the vACC showed axonal links to (or from) septum and BNST, so the well-being signal from vACC might control strength of septal and BNST output. Now we need to look into anatomy and physiology data to see what these diverse septo-habenular projections could do, to guess their possible functions and roles. Anatomical studies show input to MHb from posterior septum and BNST, and main output from MHb to IPN, which then projects to MRN. So it is possible that these projections have stimulating effects that lead to serotonin release from MRN.  Medial habenula, MHb. Its connectivity and proposed role.  The main MHb input comes from supracommissural septum (Herkenham and Nauta, 1977). Triangular septum (TS) with input from hippocampal dentate gyrus; and septofimbrial nucleus (SF) with input from fimbria of hippocampus form posterior septum (PS) and project to MHb (Raisman, 1966). The MHb receives input from the glutamatergic and ATPergic triangular septum, from cholinergic septofimbral nuclei, from GABAergic medial septum and vertical DBB (MS/vDBB), from serotonergic raphe, noradrenergic locus coeruleus neurons and sympathetic superior cervical ganglion, from substance P-ergic anterior medial part of BNST (amBNST or BAC, bed nucleus of anterior commissure), and from dopaminergic ventral tegmental area,VTA (Herkenham and Nauta, 1977; Gottesfeld, 1983; Qin and Luo, 2009; Yamaguchi et al., 2013). MHb has also afferents from LDT, and reciprocal connections with MS/vDBB (Woolf, 1991), which my model suggest to have all inhibitory effects. Model further proposes that triangular and septofimbrial septal nuclei stimulate MHb, while the MS/vDBB, and noradrenergic LC and sympathetic system neurons attenuate the output of MHb. The theta-generating MS/DBB likely inhibits MHb because MHb via IPN stimulates serotonergic MRN that promotes SWS and suppresses few regions of theta- promoting circuit: SUM, MS/vDBB and LDT. Similarly the stress (and light) evoked noradrenaline (NA) input suppresses MHb pathway to interrupt or postpone induction of SWS in the unsafe circumstances. In addition the substance P likely activates MHb when the circumstances are safe enough to afford sleep (without imminent threat to survival). This might be supported by the TS and aBNST/BAC connectivity that forms two parallel pathways: dentate gyrus   ÔÉ†   TS  ÔÉ†   ventral MHb   ÔÉ†   IPN core, and the medial amygdala (MeA)   ÔÉ†   BAC   ÔÉ†   dorsal MHb   ÔÉ†  lateral IPN (Yamaguchi et al., 2013) and by the increased fear and arousal after BAC lesions. In addition the BAC input comes from the anxiety decreasing medial amygdala (MeA). In my opinion the amBNST/BAC projections might also attenuate SUM, LC, VTA, SI, paraventricular thalamus (PVT), periacqueductal grey (PAG), CeA, and stimulate besides the MHb also the LPO.\n\nMedial habenula projects to and activates pineal population of silent cells (Axelrod, 1970; Ronnekleiv and Moller, 1979, Ronnekleiv et al., 1980) known to produce melatonin in the dark period. Light stimulation on retina inhibits melatonin synthesis by activating suprachiasmatic nucleus (SCN), which then activates paraventricular hypothalamic nucleus (PVN, known for hormonal reaction to stress) that stimulates sympathetic system in superior cervical ganglia that inhibits pineal gland and MHb by norepinephrine release (Teclemariam- Mesbah et al. 1999). Some PVN fibres innervate pineal gland directly (Reuss and Moller, 1986). Norepinephrine (NE) released from sympathetic terminals at pineal gland attenuates nicotinic cholinergic input from parasympathetic system and MHb (Yoon et al., 2014). Parasympathetic autonomic system is linked to slowing down heart beat and respiration, to rest and digestion.  The superior MHb is glutamatergic and also expresses Interleukin-18 (IL-18); the dorsal MHb is both glutamatergic and substance P-ergic. Both the superior and dorsal MHb have hight density of mu-opioid receptor; while the inferior parts of MHb are both cholinergic and glutamatergic (Sugama et al, 2002; Aizawa et al., 2012). MHb sends topographically organized glutamate, substance P and acetylcholine output to IPN (Qin and Luo, 2009; Ren et al., 2011; Herkenham and Nauta, 1979). So it is interesting that MHb that belongs to the SWS- and serotonin- promoting system produces also acetylcholine (the main neuromodulator of the opposing theta- promoting circuit). Substance P from the MHb was found released in lateral habenula (Kim and Chang, 2005; Antolin-Fontes et al., 2015) and VTA (Claudio Cuello et al., 1978). My prediction is that MHb attenuates both LHb and VTA output to enable SWS. The MHb projects to IPN via the internal part of fasciculus retroflexus and via IPN it controls MRN, LPO and LDT (Herkenham and Nauta, 1979; Groenewegen et al., 1986). So the IPN likely stimulates MRN and LPO, and inhibits LDT.  Based on its anatomical connectivity and interactions with neuromodulators, this model proposes that MHb stimulates SWS via the MHb   ÔÉ†   IPN   ÔÉ†   MRN pathway that also suppresses the theta, wakefulness, alertness and REM driving regions. This is supported by dense mu opioid receptors (that bind morphine, the sleep inducing substance) in MHb, and by circadian rhythmicity of MHb neurons (McCormick and Prince, 1987; Quick et al., 1999; Guilding and Piggins, 2007). By the markedly increased MHb and IPN metabolic activity during anesthesia (pentobarbital, ether and chloral hydrate) in rats (Herkenham, 1981), and also by the fact that the MHb neurons produce sleep promoting interleukin IL-18 (Sugama et al., 2002) and might control via IPN the MRN serotonin. Further evidence comes from high firing rates of MRN cells during SWS and during non-exploratory waking states in rats (when not recording new information by hippocampus), and their low firing rates during the theta linked exploration and REM sleep (Jacobs and Azmitia, 1992; Marrosu et al., 1996). Firing of serotonergic DRN neurons is high in wakefulness, lower in SWS and minimal in REM sleep (Saper et al., 2001). The cholinergic activity in LDT/PPT as well as the acetylcholine levels in cortex and hippocampus are high in wakefulness and REM sleep (Sakai, 1980; Marrosu et al., 1995). Discharge rate of noradrenergic LC neurons is highest during active waking, significantly lower during quiet waking, and ceased during SWS and REM sleep (Takahashi et al., 2010). Another studies found lower LC firing during SWS in rats than during wakefulness (Aston-Jones and Bloom, 1981). The lack or low NE in SWS fits its alarm/alert inducing function. Histamine neurons of tuberomamillary nucleus (TMN) in posterior hypothalamus (PH) are active only in wakefulness, highest at high vigilance, low at quiet waking and silent during SWS and REM (Takahashi et al., 2006).  Wake, SWS and REM circuits (ON and OFF regions).\n\nThe LPO or ventrolateral preoptic area (VLPO) induces SWS by inhibiting cholinergic LDT/PPT and nucleus basalis of Meynert NBM (source of cortical stimulation and gamma coupling, inhibited by adenosine), noradrenergic LC, histaminergic TMN (and PH), orexinergic LH and serotonergic DRN, so by inhibiting the wake-promoting monoaminergic arousal system (Strecker et al., 2000). Reciprocally the TMN, LC, orexinergic LH and GABAergic NBM inhibit VLPO, either directly or via interneurons (Steininger et al., 2001). LDT/PPT and orexinergic LH stimulate cholinergic and parvalbumin containing NBM neurons that induce fast gamma coupling in cortex (Kim et al., 2015). Orexin stabilizes wakefulness by exciting cortex, TMN, LC, DRN, VTA and LDT/PPT (Kilduff and Peyron, 2000; Saper et al., 2001, Bernard et al., 2002).  In addition the serotonergic and noradrenergic (REM-off) regions are suppressed by REM- promoting PnO, SubCoeruleaus (SubC) or medullar dorsal paragigantocerullar nuclei (DPGi), directly or via nearby GABAergic REM-on neurons (Gervasoni et al, 1998; Gervasoni, 2000). Reciprocally, the LC and DRN inactivation increased REM sleep (Cespuglio et al., 1982). Norepinephrine inhibited mesopontine cholinergic (probably REM- on) neurons (Williams and Reiner, 1993), while serotonin injection into SubCoeruleus in rats suppressed PGO waves in pons without affecting thalamic or cortical PGO (Datta et al., 2003). REM-on LDT/PPT neurons were inhibited by 5-HT 1A agonist in cats while the wake-on/REM-on neurons of LDT/PPT were not (Thakkar et al., 1998). Also the LPO that induces SWS is inhibited by REM-on nuclei that stimulate GABA (REM-on) neurons nearby LPO. Both the SWS-on, deep mesencephalic reticular nucleus (also named LPT) and the wake-on, vlPAG nucleus (that stimulates locomotion and motor neurons) do inhibit REM-on regions SubC and PnO/RPO. The PnO is known to be stimulated by REM-on neurons of PPT/LDT.  So my model predicts reciprocally inhibitory interactions between the SWS- promoting MHb  ÔÉ†   IPN   ÔÉ†   MRN circuit and the theta-promoting circuit SUM   ÔÉ†   MS/vDBB   ÔÉ†   hippocampus. It also proposes the opposition (reciprocal inhibition) between this MHb pathway activation and the activity of regions that stimulate the theta-generating circuit: NI, VTg, LDT and PH; as well as those regions that stimulate wakefulness: histaminergic TMN, orexinergic LH, gamma coupling inducing NBM, value-signaling/action-urging VTA, and alert/alarm linked LC. So there is also functional opposition (mutual inhibition) between the SWS- promoting circuit (MHb-IPN-MRN and LPO) versus the wakefulness promoting orexin, histamine, norepinephrine and the locomotion triggering and value-signaling dopamine system. SWS- promoting circuit might show similar opposition with regions of the REM-promoting circuits, REM-on LDT/PPT, PnO, PnC or SubC.  Brain regions with theta rhythm. The theta oscillations in hippocampus occur during awake exploration and during REM sleep (Vanderwolf, 1969). They are generated by supramamillary nuclei (SUM) that determine theta frequency and activate medial septum and vertical limb of diagonal band of Broca (MS/vDBB) that determine theta amplitude and induce theta oscillations in hippocampus and other target regions that show theta-rhythm (Pan and McNaughton, 2004). The SUM is activated by nucleus pontis oralis PnO/RPO in anesthetized rats during REM (Vertes and Martin, 1988; Vertes and Kocsis, 1997; Oddie et al., 1994), possibly also by LDT. During waking state is SUM activated for example by posterior hypothalamus (PH), orexinergic LH, dopaminergic (VTA) and nucleus incertus (NI) input, while the NI induces theta rhythm in\n\nMS by release of insulin-like peptide relaxin-3 (Ma et al., 2009). Another way to induce theta coupling in the brain might be via reciprocal connections between prefrontal cortex and SUM. Both SUM and MS project to hippocampus and medial mamillary body (MMB). The MMB and SUM have reciprocal connections with the ventral tegmental nucleus of Gudden (VTg) that (similar to SUM, MMB and MS) shows theta oscillations and similar to NBM and hDBB contains neurons with parvalbumin. Parvalbumine GABAergic cells from hDBB and NBM generate fast gamma synchronization in cortex (so possibly also in VTg). Medial part of MMB projects to the anteromedial nuclei (AM), while its lateral part projects to the anteroventral (AV) nuclei of ATN. Both AV and AM show theta rhythm. Prefrontal cortex projects to AV (top down control) but is reciprocally connected with AM, so AM might contextually bias the source of information in prefrontal cortex working memory depending on event-based context and memories and associations linked to it. Prefrontal cortex involved in goal-directed control of behavior, evaluation, predictions, decision making and planning projects also to MMB. Hippocampal efferents from subiculum project via fornix to septum (via fornix but my DTI results showed also dorsomedial thalamic tract), anterior thalamic nuclei and mamillary bodies (Aggleton et al., 2005). Further regions that demonstrate theta rhythm are subicular, retrosplenial, entorhinal, perirhinal, posterior cingulate cortex (PCC), ACC and medial prefrontal cortices that receive afferents from MS/DBB, anteromedial and anteroventral nuclei of ATN. Based on its connectivity, my prediction is that AM has role in automatic context- based selection of information from episodic and relational memories that will reach prefrontal cortex and working memory based on their associations with ongoing events. Prefrontal cortex input to AM and AV might on the other hand help to select recall of those episodic memories, events, scenarios, cognitive schemes and task rules that are relevant to current context, goals, task set, situation, and thoughts in working memory.  Interestingly both the theta inducing MS/vDBB and the gamma inducing hDBB have reciprocal connections (Woolf, 1991) with the IPN, MHb, LHb, hippocampus, amygdala, subiculum, entorhinal cortex, piriform cortex, retrosplenial cortex, cingulate cortex (perhaps both PCC and ACC), insula (codes aversive properties of things and subjects, pain and taste), and temporal pole (codes identities of objects and subjects). Thus, this model predicts reciprocal inhibition of the MS/vDBB and hDBB by MHb and IPN, as well as the inhibition of MS/vDBB and hDBB by LHb (to decrease theta and gamma rhythm linked to recording of new information and arousal). These cortical regions and amygdala might reciprocally induce the MS/vDBB and hDBB firing and be driven by them into theta and gamma coupling. The theta coupling in cortex might also be induced by SUM. Other afferents of MS/DBB are from PPT/LDT, LC, VTA, orexinergic LH, DRN and MRN (Woolf, 1991).  Supramamillary nucleus, SUM and some of its interactions.  SUM controls the frequency of hippocampal theta activity via MS/DBB, while MS/vDBB controls its amplitude (Pan and McNaughton, 2004). SUM is known to stimulate theta rhythm during exploration in rats (Vertes and Kocsis, 1997) that gets disrupted by serotonergic MRN. SUM in rats has reciprocal connection with MMB, VTg, PH, LH, AH, LDT, MS/DBB, lateral septum (LS), PAG, LPO, medial preoptic hypothalamic nucleus (MPO, involved in regulation of body temperature), MRN, DRN, VTA (VTA encodes expected reward value signal and novelty), cognitive anterior cingulate cortex (homologue of human cognitive PFC), medial and ventrolateral orbital cortex (processing of rewards and punishments). SUM afferents come also from IPN, lateral habenula (LHb), (Kiss et al., 2002), VMH, BNST, subiculum and nucleus prepositus. SUM efferents project also to\n\nanteromedial and anteroventral thalamic nuclei (AM, AV), reuniens nuclei, intralaminar thalamic nuclei, centromedian thalamic nuclei (CM), mediodorsal thalamus (MDT, involved in value-based selection of choices that are further encoded in prefrontal working memory), substantia innominata (SI, which includes primate NBM homologue), hippocampus, dentate gyrus (receives strong input), entorhinal cortex (EC), frontal cortex, subthalamic nucleus (STN), amygdala, LC and cerebellar nuclei (CN), (Vertes, 1988, 1992; Hayakawa et al., 1993; Shibata, 1987; Risold and Swanson, 1997; Swanson, 1982; Thinschmidt, 1993; Kiss et al., 2002, Contestabile and Flumerfelt, 1981). So this model predicts stimulating input to SUM from wakefulness promoting regions of PH, LH, LDT (from wake-on/REM-on LDT cells), from VTA (with dopamine that signals value), from PAG, and prefrontal cortex (that informs SUM about meanings of things and events around us). Model proposes inhibitory input from LHb, and from SWS- promoting IPN, MRN and LPO to SUM. Similarly, this model suggests stimulatory effects of SUM on VTg, AM, AV, CM, MDT, SI, amygdala, entorhinal and prefrontal cortex function, and predicts inhibitory effect of SUM efferents on MRN output.  Ventral tegmental nucleus of Gudden, VTg and its connectivity.  VTg has reciprocal projections with MMB. VTg has input from prefrontal, cingulate, insular and retrosplenial cortex, MRN, IPN and LHb, maybe even from NBM, PH, LH and LPO as VTg receives input from basal forebrain and hypothalamus (Irle et al., 1984). Both VTg and SUM receive LHb, IPN and MRN projections, so this model predicts that they have inhibitory effect on both these regions that demonstrate theta oscillations. Because the VTg is needed for alternate choice working memory and during mental navigation tasks, but not during SWS sleep. In addition the VTg has possibly stimulating input from dorsal tegmental nucleus of Gudden (DTg), vestibular nucleus (head movement signals), substantia nigra pars compacta (SNc, that signals informational value to brain, what is meaningful, relevant, what way of doing things is right), VTA (signals expected reward value), LC (alarm signal), PAG (fear response) and from dopaminergic cells in zona incerta (ZI, linked to locomotion). VTg has input also from fields of Forel, nucleus of Darkschewitsch (reflex gaze), interstitial nucleus of Cajal (integration of head and eye movements) and nucleus prepositus hypoglossi. Many VTg neurons projecting to MMB are parvalbumin positive, so capable to transfer fast gamma oscillations important for WM and focused attention.  Nucleus incertus, NI and its interaction with SWS-circuit.  The NI is known to induce theta rhythm and to increase spatial working memory performance (and theta-power in hippocampus), by releasing peptide relaxin-3 into MS/DBB (Ma et al, 2009). Even in the anaesthetised rats did the relaxin-3 antagonist in medial septum decreased the PnO-induced hippocampal theta power (Ma et al, 2009). The NI in rats has reciprocal connections with cortical affective evaluation regions: prelimbic cortex (homologue of dorsal anterior cingulated cortex, dACC in primates), medial and ventrolateral orbital cortex; with cognitive anterior cingulate cortex (cognitive PFC homologue); with retrosplenial cortex important for autobiographic memory; with subcortical MRN, IPN (Goto et al., 2001; Aizawa et al., 2012), LPO, ZI, medial LHb, SUM, PH, LH, ventrolateral PAG, MS/vDBB (GABAergic negative feedback) and pontine reticular nucleus. Medial LHb inhibits MRN and projects to intermediate part of the IPN (Wang and Aghajanian, 1977; 2015; Kim, 2009). This model predicts that the cortical input likely stimulates via NI the theta coupling to enhance the recording of episodes with affective and informative meanings to us. Based on the properties of SWS- promoting circuit MHb-IPN-MRN, this model predicts that LHb and the theta- opposing regions IPN and MRN do reciprocally inhibit the\n\noutput of the theta- and arousal inducing NI, and that LHb also inhibits the IPN output to MRN.  The NI in rats and mice has receptors for CRH (corticotropin releasing hormone), orexin, MCH (melanin concentrating hormone, linked to sleep), oxytocin, serotonin 5-HT1A and ghrelin (Bittencourt and Sawchenko, 2000; Greco and Shiromani, 2001; Marcus et al., 2001; Saito et al., 2001; Vaccari et al., 1998; Mani et al, 2014; Miyamoto et al., 2008). So the serotonergic MRN likely inhibits NI during SWS, while the wakefulness linked agents activate NI to enforce arousal, theta coupling and the recording of new events in hippocampus. This model suggests that histaminergic and orexinergic neurons of PH/LH stimulate NI, as both also promote wakefulness, and that LPO inhibits NI, as LPO promotes SWS that opposes theta state and arousal. NI in rats projects also to all hippocampus especially to dorsal fimbria and ventral dentate gyrus, CA3 and subiculum, to entorhinal cortex, claustrum, SI, PPT, LS, triangular and septofimbrial septal nuclei, MHb, MMB, lateral mamillary body (LMB), AV, AM, AD, nucleus reuniens, CM, MDT , DRN, PVT, PVN, dorsomedial thalamic nucleus (DMN), VMN, MPO, supraoptic hypothalamic nucleus (SON), anterior hypothalamus (AH), arcuate nucleus, amygdala, BNST, contralateral NI, nucleus accumbens (NAc, involved in motivation/drive and inhibitory avoidance), ZI, VTA, SNc, and superior colliculus (SC), (Goto et al., 2001; Olucha-Bordonau et al., 2003 and 2012; Teruel-Marti et al., 2008). This model predicts that NI (besides its known effect on medial septum theta rhythm) activates its targets in PFC, RSC, hippocampus, BNST, LS, PAG, PVN, PVT, MDT and CM; but inhibits MHb, IPN, MRN and LPO leading to suppression of SWS.  Triangular and septofimbrial septal nuclei. Some of their interactions.  Triangular septum (TS) projects to MHb, IPN and LHb (Raisman, 1966). Posterior septum (PS) that includes TS and septofimbrial septal nuclei (SF) has GABAergic projections to NI (and NI projects to PS), SUM and MRN. Also medial septum and horizontal DBB (hDBB) have GABAergic projections to nucleus incertus (Sanchez-Perez et al., 2015). By proposing SWS- promoting role of PS, this model suggests that TS inhibits LHb to disinhibit the serootnergic MRN, and that TS and SF inhibit NI and SUM, but activate MRN (by inhibiting MRN interneurons). The NI is known to induce theta by its relaxin-3 release in MS (Ma et al., 2009). Horizontal DBB together with NBM is the main source of the cortical cholinergic innervation and the parvalbumin containing GABAergic projection neurons that induce fast gamma rhythm linked to thinking, attention, working memory and feature binding. So the hDBB might induce cholinergic activation or even gamma oscillations in NI towards informative and salient stimuli to increase temporal coupling (and temporal summation) towards important information.  Median raphe nucleus, MRN and its interactions.  Major MRN input is from IPN, LHb, MS, MB, LPO, MPO, LH, perifornical hypothalamus, DMN, PAG, LDT, LC and infralimbic cortex in rats (homologue of ventral ACC in humans). Medial LHb reciprocally inhibits serotonergic MRN (Wang and Aghajanian, 1977). MRN projects to medial mammillary body (MMB), SUM, PH, perifornical hypothalamus (PF/LH), cholinergic MS/vDBB, hDBB, NBM, septum, VTA, dopaminergic A13 region of ZI, LC, LDT/PPT, subcoeruleus, LHb, IPN, MPO, nucleus reuniens, mediodorsal thalamus (MDT),\n\ncentral medial, paracentral and central lateral nuclei of midline intralaminar thalamus, suprachiasmatic nucleus (SCN), hippocampus and NAc (Vertes and Martin, 1998, Vertes and Linley, 2008). Cortical projections from MRN are light and restricted to perirhinal, entorhinal and some prefrontal cortex. MRN stimulation enhances the secretion of gonadotropins (James et al., 1987). Glutamate input to MRN was increased during non-theta phase of anesthesia in rats but not after tail pinch (Varga et al., 1998). This evidence supports the proposed activation of MRN by MHb during SWS, as MHb is also stimulated by anesthetics, possibly disinhibited by morphine, and has indirect input to MRN via IPN. So this model predicted that MHb stimulates IPN, which stimulates MRN to release serotonin during SWS. Both LPO and MRN promote SWS and suppress some regions of cholinergic theta- promoting circuit. So this model proposes that LPO and possibly vACC activate MRN, while the MS/vDBB, MMB, LDT, orexinergic LH, noradrenergic LC, and fear response related PAG inhibit MRN. Similarly to the known MRN inhibition of SUM, this model suggests that MRN attenuates also the following theta- , working memory or arousal linked regions: MMB, MS/vDBB, histaminergic PH, orexinergic LH, VTA, A13 of ZI, intralaminar and midline thalamic nuclei. Hippocampal theta induced by SUM and MS activation was produced after MRN inhibition by glutamatergic antagonists, GABA agonist and serotonin 1A agonist (acting via MRN autoreceptor) in urethane anesthetized rats (Kinney et al., 1994; Kinney et al., 1995; Vertes et al, 1994, Kinney et al., 1996).  Interpeduncular nucleus, IPN  Main IPN input comes from MHb, less from medial LHb, MPO, ventral hypothalamus, MRN, DRN, dorsal and ventral tegmental nuclei of Gudden (DTg, VTg), LDT, PAG, SUM, premamillary nuclei, LC, sparse input comes from hDBB (Contestabile and Flumerfelt, 1981; Vertes and Fass, 1988), and some from VTA neurons that contain dopamine and corticotropin releasing factor (CRF), (Zhao-Shea et al., 2013). The IPN neurons are mostly GABAergic and project to MRN, DRN, LPO, MPO, LDT, DTg and VTg (strongly), medial mamillary body (MMB, weakly), NI, nucleus basalis of Meynert (BNM), LC, PAG, MS/DBB, LH, hypothalamus, entorhinal cortex (EC), hippocampus, MDT, nucleus gelatinosus, and midline thalamic nuclei (Groenewegen et al., 1986; Goto et al., 200; Vertes and Fass, 1988). LDT has reciprocal connections with IPN, but also with MRN and LPO. So it is possible that IPN, MRN and LPO attenuate LDT output, to promote SWS, and vice versa that LDT suppresses IPN, MRN and LPO.  As gabaergic parvalbumine containing NBM projection neurons induce cortical gamma (40- 100 Hz) oscillations and wakefulness (Brown and McKenna, 2015) and project to VTg, while the VTg shows theta oscillations, also contains fast firing parvalbumin GABA neurons (projecting to MMb), and is needed in alternation task working memory (Dillingham et al., 2015), this model suggests an inhibitory effect of IPN on NBM and VTg. It proposes that IPN stimulates the SWS-promoting LPO and MRN serotonin release; but attenuates the output of theta and arousal promoting regions: VTg, DTg, MMB, NI, LDT, NBM, LC and fight-or- flight response of PAG. In addition the model predicts that medial LHb that inhibits MRN possibly inhibits also IPN (by targeting IPN interneurons) and itself is inhibited by MHb. The IPN interneurons might be targeted also by dopamine and CRH release from VTA to interrupt sleep. Similarly, the IPN is probably inhibited by DTg, VTg, LDT, PAG, hDBB, SUM, premamillary nuclei and LC.\n\nLateral preoptic area, LPO and some interactions predicted by model.  GABAergic neurons in the VLPO promote sleep by inhibiting arousal-promoting circuits, such as TMN, NBM, LC and DRN (Saper et al., 1997; Saper et al., 2001; Luppi et al., 1999; Lydic and Baghdoyan, 2005). LPO was found to promote SWS. LPO projects also to SUM, LDT and PPT, and based on their properties this model proposes that LPO inhibits them. This inhibition might be reciprocal. It was found that MRN serotonin inhibits LTD, PPT and SUM. Both LPO and LH project to LHb, RMTg and VTA.  So this model predicts stimulatory effect of LPO on rostromedial tegmental nucleus (RMTg), and inhibitory effect of LPO on LHb and VTA, to disinhibit the MRN serotonin release during SWS (suppressed by medial LHb, i.e. in deppression) but to inhibit the dopamine groups (SNc/A9, VTA/A10 and A11) that do facilitate locomotion, value-based learning, drive (go-for-it) and activate spinal motor neurons (A11). This claim is supported by robust locomotor activation after infusion of the GABAA agonist muscimol into the RMTg (Lavezzi et al., 2024). The orexinergic LH projections on the other hand likely stimulate VTA and inhibit LHb and RMTg. Another supporting fact is that the LDT is essential for burst firing of VTA dopamine neurons (Lodge DJ, Grace AA, 2006). Stimulation of (wake-on ?) PPT or LDT excites dopaminergic neurons of VTA and SNc (Lacey et al. 1990) and is needed for maintenance of burst firing of dopamine neurons (Lodge and Grace, 2006). The RMTg is known for reciprocal connections with LDT, PPT, pontine and medullary reticular formation, and for strongly suppressing effect on VTA, SNc and DRN (Perroti et al., 2005; Jhou et al., 2009 a, b; Kaufling et al., 2009; Balcita-Pedicino et al., 2011). This model proposes that RMTg mutually supresses LDT and PPT to decrease arousal and locomotion (e.g. after injuries, in sickness, in depression). So the LPO uses the LHb and RMTg as ''switch off- switch on'' buttons to enable SWS, by boosting the serotonergic MRN system and by suppressing the dopaminergic SNc and VTA system. Actually the LPO might activate just that part of RMTg (lateral ?) that suppresses SNc and VTA, because the serotonergic DRN firing is reduced during SWS but ceased only during REM sleep. Interestingly respiratory rate is higher in REM sleep compared with both non-REM sleep and wakefulness, in line with the inhibition/cessation of serotonergic firing at MRN and DRN, and with calming serotonergic effect on respiration.  Similarly to the LPO, also the SWS-on deep mesencephalic nuclei might suppress dopamine system. That population of BNST neurons, which promotes reactivity to threat, activates VTA and inhibits LPO, most probably inhibits also the LHb and RMTg to disinhibit motor reactivity. Also the MS/DBB has input to LHb, RMTg and VTA, possibly to induce there the theta coupling. This model predicts inhibitory effect of LPO projections to SUM, to suppress theta oscillations during SWS. The main inhibitory input to LPO comes from GABAergic neurons of NBM, lateral septum and BNST (Zahm et al., 1999, 2013; Zahm, 2006). Their role in fast gamma coupling, panic and anxiety response supports the LPO role in SWS. Threat suppresses SWS by inhibiting LPO, what leads to lower RMTg activity: causing rise in dopamine firing, agitation and impulsive response. Interestingly cholinergic projections from the mesopontine tegmentum inhibit the RMTg at muscarinic M4 receptors, while exciting VTA dopamine neurons at M5 receptors (Wasserman et al. 2013, 2014). So this acetylcholine might come from wake promoting LDT to disinhibit dopamine system, to fuel motion, motivated behaviour, drive, reward and value/meaning based learning in wakefulness and awareness. The LPO projects also to reticular thalamic nucleus involved in up and down states during SWS, and to hippocampus, cortex and parabrachial nucleus (PB, part of pain pathway), possibly to promote SWS sleep.\n\nLateral habenula, LHb and its proposed role in theta control and REM sleep  LHb directly and via RMTG activation strongly suppresses (for few milliseconds) dopamine and serotonin release (Christoph et al., 1986; Wang and Aghajanian, 1977; Park, 1987; Ji and Shepard, 2007; Matsumoto and Hikosaka, 2007). Looking at the lateral habenula connectivity and function my conclusion is that LHb might be used as a ''switch-off'' button to suppress serotonin (MRN and DRN) and to lower dopamine (SNc, VTA) firing during REM. Although serotonin, noreinephrine and histamine neurons cease firing during REM sleep, dopamine neurons show bursting activity in both wakefulness and REM sleep.  Main LHb input is from GPi, LH, VTA, DRN, MRN, LPO (reciprocal), MS/vDBB, SI, NBM, PH, PAG and BNST (Herkenham and Nauta, 1977; Sutherland, 1982). LHb projects to SUM (Kiss et al., 2002), and medial LHb innervates intermediate IPN (Kim, 2009). LHb inhibits dopaminergic VTA/SNc and serotonergic DRN/MRN, and stimulates GABAergic RMTg that directly inhibits DRN, VTA and SNc (Perroti et al., 2005; Jhou et al., 2009 a, b; Kaufling et al., 2009). LHb projects also to LC, TMN, PH, LH, LDT, PPT, NBM, SI, MS/DBB, SUM, LPO, ZI, PVT, MDT (involved in value-based choice selection), raphe pontis nucleus, contralateral LHb and to REM-promoting PnO (Herkenham and Nauta, 1979; Araki et al., 1988). So my prediction is that LHb suppresses the SWS-promoting LPO and IPN. Lateral habenula inhibition of MRN is already well-known. This model proposes that LHb attenuates wake-on cholinergic, GABAergic or glutamatergic neurons in LDT, PPT, NBM, SI, MS/DBB, then noradrenergic LC, histaminergic PH/TMN, and orexinergic LH neurons, glutamatergic SUM. Further prediction is that LHb attenuates also VTg, DTg, ZI, SC, PAG, CM (centromedian thalamic nucleus) and MDT (deselecting choices) to decrease movement and arousal after defeat, after repeatedly bad feedback/outcomes, in chronically hostile environment and during REM sleep. Chronic pain and negative feedback overstimulate LHb, causing learned helplessness, to stop us moving and exerting/losing energy for things that repeatedly hurt and harm us and decrease our well-being or survival.  PPT stimulates STN during REM sleep (Fern√°ndez-Mendoza et al., 2009) enhancing the fast (15 ‚Äì 35 Hz) subthalamic oscillatory activity. STN then activates LHb by stimulating internal globus pallidus (GPi), as GPi has strong glutamatergic input to LHb. So probably the firing of subthalamic neurons activates GPi, which then causes activation of LHb during REM sleep. This REM (and preREM, shortly before REM) sleep stimulation of LHb helps to suppress dopamine and serotonin release during REM, so prevents switching into waking and into SWS state, respectively. Prolonged LHb activation might lead to suppression of SUM and weakened theta oscillations in the brain, as the LHb projects to SUM, and this model predicts that SUM is suppressed by LHb. In addition the SNr inhibits PPT. It is not clear if the LHb inhibits the wake -on PPT/LDT neurons (which stimulate VTA/SNc) or also the REM-on LDT/PPT neurons. LHb might not suppress REM-on LDT/PPT groups (as they are used to trigger the theta-frequency in SUM during REM sleep), but might attenuate wake/REM-on LDT and PPT neurons leading to decrease in arousal and awareness. If would LHb inhibit REM-on LDT/PPT, it might cause gradual suppression of REM state and support the switching/alternations between the REM sleep and SWS.  The PPT/LDT is known to activate SubC and medullary reticular nuclei that inhibit motor neurons during REM sleep, causing muscle atonia. Overstimulation of LHb, by chronic pain, loss, worries, bad outcomes, or by low basal dopamine or serotonin signal in brain (leading to LHb disinhibition) actually prolongs REM sleep and shortens SWS. The reason for this might be that the shortage of brain serotonin signal when feeling down disinhibits LHb what leads to further suppression of serotonin release. The lack of serotonin then disinhibits the REM-on\n\ncircuit and shortens SWS stage. Increased REM sleep duration was found in depression (Steriade and McCarley, 1990). This finding supports my prediction that LHb is one of the effectors activated by REM-on neurons in LDT/PPT, possibly via STN.  Interestingly LHb projects to PnO, so might promote (or control) REM sleep not only by suppression of dopamine and serotonin. Model predicts that wake-on orexinergic LH neurons inhibit LHb and RMTg, thus causing rise in VTA/SNc dopamine and reactivity (i.e. when hungry). The REM-on, melanin concentrating hormone (MCH) neurons of LH might inhibit dopaminergic A11 stimulation of motor neurons, or activate SubC or PnO. Further prediction of this model is that LHb suppresses NBM activity, e.g. in depression and after repeated defeat and loss, what leads to weakened attention, working memory strength via weakened fast gamma based cortical coupling. As tonic, fast oscillatory (20-40 Hz) cortical activity is elicited by NBM stimulation (Metherate et al., 1992).  Reticular nucleus pontis oralis and caudalis. Some of their interactions.  Subcoeruleus, nucleus pontis caudalis (PnC) and oralis (PnO/RPO) receive REM-on LDT/PPT input and promote REM sleep. Both PnC and PnO project to oculomotor/visual system. The PnC projections to STN might enhance the REM linked motor response suppression. Movement suppression in REM is caused by SubC that inhibits spinal motor neurons via reticular medullar nuclei. Wake-on norepinephrine is known to inhibit SubC while the wake-on PPT group inhibits PnC. The theta rhythm inducing PnO projects to SUM, LDT, IPN, lateral mamillary body (LMB), mesencephalic reticular formation (that projects to reticular thalamic, reuniens and subthalamic nucleus), retrorubral nucleus, VTA, SNc, zona incerta (ZI), specific PAG regions and CM (Vertes and Martin, 1998). So question is why the PnO interacts with the LMB during REM sleep? The LMB with its head-direction cells receives DTg and postsubicular hippocampal input, and projects to DTg and anterodorsal thalamic nucleus AD. The AD is reciprocally connected with postsubicular hippocampus and with retrosplenial cortex. The LMB might (besides spatial navigation) support navigation on temporal axes (distant past, less distant past, things ahead..) of memory, what is not a strong feature of dreams. Content of dreams is often evolving in incongruous temporal context, with jumps between scenes. Perhaps a random activation of LMB and reuniens during REM serves to mix up and link distant and fresher events and memories into wider cognitive map.  Conclusions  Theta oscillations are evoked either during active waking state by what is going on around us, so by contextual and stimulus based novelty, salient sensory input, interesting or meaningful stimuli, good/valuable or bad/harmful things. Theta rhythm is induced also by REM-on PnO projections to SUM, or via LDT projections to SUM and MS/DBB. In quiet waking without novelty and during consumatory (repetitive) behaviour there is low need to record new information, so it was linked to replay of previously encoded information, after the theta rhythm enabled recording events, contexts and interrelations between things. Possibly, when the hippocampal dentate gyrus gets full and new information lead to interference, the hippocampus stimulates posterior septum to induce SWS via MHb-pathway, to clean up short term memory storage for new input. The MHb   ÔÉ†   IPN   ÔÉ†   MRN circuit then promotes SWS and antagonizes the theta promoting circuit, wake and REM sleep. Besides the main idea, this\n\nstudy brought new predictions about interactions of some SWS- versus theta- promoting regions with LHb, RMTg, LPO, VTg and NI. And their effects on sleep/wake control.  This model predicted that lateral habenula projections to SUM have inhibiting effects and attenuate theta rhythm. It also proposed that LHb suppresses the wake-promoting substantia innominata/nucleus basalis (SI/NBM), as well as the SWS-promoting LPO. LHb is known to suppress (for miliseconds) dopamine and serotonin release. Consequent decrease in dopamine input then lowers the NBM output (as dopamine stimulates NBM). One of the purposes of dopamine suppression by LHb might be to decrease arousal after chronic defeat and chronic negative feedback, to stop us moving and losing energy for bad choices, to unlearn wrong (no more valid) ideas, and to deselect the suboptimal choices, decisions and prediction from working memory. Because the LHb attenuates NBM via suppressing dopamine in system, and LHb projects to NBM, the LHb might act in similar way on NBM and directly inhibit it.  Further my circuit-based findings suggest that LHb reciprocally inhibits LPO and orexinergic lateral hypothalamus. While LPO possibly activates RMTg. This study also suggested how can LHb promote REM sleep. Via the REM-on PPT neurons stimulation of STN that activates SNr and GPi, which then activate LHb to suppress dopamine and serotonin release during REM. The IPN   ÔÉ†   LPO and LPO   ÔÉ†   MRN connections link together two SWS- promoting systems: proposed MHb   ÔÉ†   IPN   ÔÉ† MRN and LPO. My prediction is that IPN stimulates LPO and LPO stimulates MRN but it has to be tested.  This work seems to be the first circuit based model of the MHb-IPN-MRN circuit function. It extended the known system for control of wakefulness and sleep, by adding the role of MHb and IPN to the known serotonergic MRN system. The MHb increases its activity during anesthesia, and anesthesia is similar to SWS stage. This model combined connectivity references (on regions involved in sleep-wake control and on MHb) and the available (partial) functional findings from the literature. It predicted how do MHb and IPN promote slow wave sleep: by stimulating serotonergic MRN, as well as by inhibiting the opposing theta-promoting circuit, wakefulness and REM sleep regions. It showed few new interactions of theta-promoting regions, known to enable recording of new information in hippocampus in active wake linked to theta state. SWS is known for replay of relationally and spatio- temporally bound informattion in hippocampus. So because the SWS and REM states are involved in different functions, it has sense that there is opposition/inhibitory effect between MHb-IPN-MRN and the theta- promoting circuit. Different neural regions, neuromodulators and states are needed in recording than in replay. Because of proposed circuit based opposition between SWS - promoting and theta- promoting regions, some new relations and interactions between the less known regions of sleep-wake system could be predicted. For example that LHb inhibits IPN and SUM, or that LPO (SWS promoting region) inhibits LHb and VTA but stimulates RMTg to oppose/suppress REM state.  Abbreviations  DRN dorsal raphe nukleus  DTg dorsal tegmental nucleus of Gudden  GPi globus pallidus pars interna  IPN interpeduncular nukleus  LC locus coeruleaus\n\nLDT lateral dorsal tegmental nukleus  LH lateral hypothalamus  LHb lateral habenula  LPO lateral preoptic nucleus  LS lateral septum  MDT mediodorsal thalamus  MHb medial habenula  MRN median raphe nucleus  MS/DBB medial septum/diagon√°l band of Broca  NBM nukleus basalis of Meynert  NI nucleus incertus  PH posterior hypotalamus  PPT pedunculopontine nucleus  REM rapid eye movement  RMTg rotromedial tegmental nukleus  SI substantia innominata  SNc Substantia nigra compacta  SNr Substantia nigra reticulata  STN subthalamic nukleus  SUM supramamillary nukleus  SWS slow wave sleep  TMN tuberomamillary nucleus  VTA vetral tegmental nucleus  VTg ventral tegmental nucleus of Gudden  REFERENCES  Aizawa H, Kobayashi M, Tanaka S, Fukai T, Okamoto H. Molecular characterization of the subnuclei in rat habenula. J Comp Neurol 2012; 520: 4051066.\n\nAntolin-Fontes B, Ables JL, Gorlich A, Ibanez-Tallon I (2014). The habenulo- interpeduncular pathway in nicotine aversion and withdrawal.   Neuropharmacology   96 (Pt B): 2132.  Araki M, McGeer PL, Kimura H (1988) The efferent projections of the rat lateral habenular nucleus revealed by the PHA-L anterograde tracing method. Brain Res, 44, 31930.  Aston-Jones G, Bloom FE (1981) Activity of norepinephrine-containing locus coeruleus neurons in behaving rats anticipates fluctuations in the sleep-waking cycle. J Neurosci-1:876- 886.  Axelrod J (1970) \"The pineal gland\". Endeavour 29 (108): 144.  Balcita-Pedicino J. J., Omelchenko N., Bell R., Sesack S. R. (2011). The inhibitory influence of the lateral habenula on midbrain dopamine cells: ultrastructural evidence for indirect mediation via the rostromedial mesopontine tegmental nucleus. J. Comp. Neurol. 519, 1143164 10.1002/cne.22561  Berkowitz A, Sutton L, Janowsky DS (1990) Gillin JC. Pilocarpine, an orally active muscarinic cholinergic agonist, induces REM sleep and reduces delta sleep in normal volunteers. Psychiatry Res.33:113 ‚Äì 119.  Bernard R, Lydic R, Baghdoyan HA(2002) Hypocretin-1 activates G proteins in arousal- related brainstem nuclei of rat. Neuroreport 13, 44750  Bittencourt JC, Sawchenko PE (2000) Do centrally administered neuropeptides access cognate receptors? An analysis in the central corticotropin-releasing factor system. J Neurosci, 20 (3),1142156.  Bland BH, Oddie SD (2001) Theta band oscillation and synchrony in the hippocampal formation and associated structures: the case for its role in sensorimotor integration. Behav. Brain Res. 127, 11936.  Blumberg MS, Karlsson KA, Seelke AM, Mohns EJ. The ontogeny of mammalian sleep: a response to Frank and Heller (2003) J Sleep Res. 2005;14:918.  Bogdanski DF, Weissbach H, Udenfriend S (1958)   J. Pharmacol. Exp. Therap. 122, 182.  Brown RE, McKenna JT (2015) Turning a negative into a positive: ascending GABAergic control of cortical activation and arousal. Front. Neurol. 6:135.  Buzsaki G (1989) Two-stage model of memory trace formation: a role for noisy brain states. Neuroscience. 31:55170.  Buzsaki G (2002) Theta oscillations in the hippocampus. Neuron. 33:32540.  Cespuglio R, Gomez ME, Faradji H, Jouvet M (1982) Alterations in the sleep-waking cycle induced by cooling of the locus coeruleus area. Electroencephalogr Clin Neurophysiol. 54:57078.\n\nChristoph GR, Leonzio RJ, Wilcox KS (1986) Stimulation of the lateral habenula inhibits dopamine-containing neurons in the substantia nigra and ventral tegmental area of the rat. J Neurosci 6:613-619.  Claudio Cuello A, Emson PC, Paxinos G, Jessell T (1978). Substance P containing and cholinergic projections from the habenula. Brain Res. 149, 41329 10.1016/0006- 8993(78)90484-5  Contestabile A, Flumerfelt BA (1981) Afferent connections of the interpeduncular nucleus and the topographic organization of the habenulo-interpeduncular pathway: an HRP study in the rat. Comp Neurol, 196:25370.  Costa R, Pscheidt GR, van Meter WG, Himwich HE, J. Pharmacol. Exp. Therap. 130,81 (1960).  Dahan L, Astier B, Vautrelle N, Urbain N, Kocsis B, Chouvet G.Prominent burst firing of dopaminergic neurons in the ventral tegmental area during paradoxical sleep. Neuropsychopharmacology. 2007 Jun;32(6):1232-41.  Datta S, Mavanji V, Patterson EH, Ulloor J. Regulation of rapid eye movement sleep in the freely moving rat: local microinjection of serotonin, norepinephrine, and adenosine into the brain stem. Sleep. 2003;26:51320.  Delorme   F (1966)   thesis, University of Lyons.  Dillingham CM, Holmes JD, Wright NF, Erichsen JT, Aggleton JP, Vann SD. Calcium- binding protein immunoreactivity in Gudden? tegmental nuclei and the hippocampal formation: differential co-localization in neurons projecting to the mammillary bodies.  Frontiers in Neuroanatomy . 2015;9:103.  George R, Haslett WL, Jenden DJ (1964) A cholinergic mechanism in the brainstem reticular formation: induction of paradoxical sleep. Int J Neuropharmacol. 3:541 ‚Äì 552.  Gervasoni D, Darracq L, Fort P, Souliere F, Chouvet G, Luppi PH (1998) Electrophysiological evidence that noradrenergic neurons of the rat locus coeruleus are tonically inhibited by GABA during sleep. Eur J Neurosci 10:96470.  Gervasoni D, Peyron C, Rampon C, Barbagli B, Chouvet G, Urbain N, Fort P, Luppi PH (2000) Role and origin of the GABAergic innervation of dorsal raphe serotonergic neurons. J Neurosci 20:4217225.  Goto M, Swanson LW, Canteras NS (2001) Connections of the nucleus incertus. J Comp Neurol438: 8622.  Gottesfeld Z (1983). Origin and distribution of noradrenergic innervation in the habenula: a neurochemical study. Brain Res. 275, 29904 10.1016/0006-8993(83)90990-3  Greco MA, Shiromani PJ. Hypocretin receptor protein and mRNA expression in the dorsolateral pons of rats. Brain Res Mol Brain Res 2001; 88: 17682.\n\nGroenewegen HJ, Ahlenius S, Haber SN, Kowall NV, Nauta WJ (1986) Cytoarchitecture, fiber connections, and some histochemical aspects of the interpeduncular nucleus in the rat. J. Comp Neurol, 249: 6502.  Guilding C, Piggins HD (2007) Challenging the omnipotence of the suprachiasmatic timekeeper: are circadian oscillators present throughout the mammalian brain? Eur J Neurosci 25:3195216.  Hayakawa T, Ito H, Zyo K (1993) Neuroanatomical study of afferent projections to the supramammillary nucleus of the rat. Anat. Embryol. 188, 13948.  Herkenham M (1981) Anesthetics and the habenulo-interpeduncular system: selective sparing of metabolic activity. Brain Res 210:46166.  Herkenham M, Nauta WJ (1977) Afferent connections of the habenular nuclei in the rat. A horseradish peroxidase study, with a note on the fiber-of-passage problem. J Comp Neurol 173:12345.  Herkenham M, Nauta WJ (1979) Efferent connections of the habenular nuclei in the rat. J Comp Neurol 187:19-47.  Hernandez-peon R, Chavez-Ibarra G, Morgane PJ, Timo-Iaria C (1963). Limbic cholinergic pathways involved in sleep and emotional behaviour. Exp Neurol. 8:93 ‚Äì 111.  Hobson JA, McCarley RW, Wyzinski PW (1975) Sleep cycle oscillation: reciprocal discharge by two brainstem neuronal groups. Science.189:55 ‚Äì 58.  Hohagen F, Riemann D, Spiegel R, Holzhauer M, Berger M (1993) Influence of the cholinergic agonist SDZ 210-086 on sleep in healthy subjects. Neuropsychopharmacology. 9:225 ‚Äì 232.  Irle E, Sarter M, Guldin WO, Markowitsch HJ. Afferents to the ventral tegmental nucleus of Gudden in the mouse, rat, and cat. J Comp Neurol. 1984;228:50941.  Jacobs BL, Azmitia EC (1992) Structure and function of the brain serotonin system Physiol Rev 2:16529.  Jacobs BL, Henriksen SJ, Dement WC. Neurochemical bases of the PGO wave. Brain Res. 1972;48:40611.  James MD, MacKenzie EJ, Tuohy-Jones PA, Wilson CA (1987) Dopaminergic neurones in the zona incerta exert a stimulatory control on gonadotrophin release via D1 dopamine receptors. Neuroendocrinology, 45: 348 355.  Jhou, TC, Geisler, S, Marinelli, M, Degarmo, BA & Zahm, DS (2009) The mesopontine rostromedial tegmental nucleus: A structure targeted by the lateral habenula that projects to the ventral tegmental area of Tsai and substantia nigra compacta. J. Comp. Neurol. 513, 56696.\n\nJhou T, Fields HL, Baxter MG, Saper CB, Holland PC (2009) The Rostromedial Tegmental Nucleus (RMTg), a GABAergic Afferent to Midbrain Dopamine Neurons, Encodes Aversive Stimuli and Inhibits Motor Responses. Neuron, 61:5, 78600.  Ji H, Shepard PD (2007) Lateral Habenula Stimulation Inhibits Rat Midbrain Dopamine Neurons through a GABAA Receptor-Mediated Mechanism. J Neurosci, 27, 6923930.  Jouvet M (1962) Recherches sur les structures nerveuses et les mecanismes responsables des differentes phases du sommeil physiologique. Arch Ital Biol. 100:12506.  Jouvet M, Bobillier P, Pujol JF, Renault J (1967) Permanent insomnia and diminution of cerebral serotonin due to lesion of the raphe system in cats. J Physiol, 59:248.  Kaufling J, Veinante P, Pawlowski SA, Freund-Mercier MJ, Barrot M.(2009) Afferents to the GABAergic tail of the ventral tegmental area in the rat. J Comp Neurol. 513, 597-621.  Kilduff TS, Peyron C (2000) The hypocretin/orexin ligand receptor system: implications for sleep and sleep disorders. Trends Neurosci. 23, 35965 .  Kim U (2009) Topographic commissural and descending projections of the habenula in the rat. J Comp Neurol; 513: 17387.  Kim T, Thankachan S, McKenna JT, McNally JM, Yang C, Choi JH, et al. (2015) Cortically projecting basal forebrain parvalbumin neurons regulate cortical gamma band oscillations. Proc Natl Acad Sci U S A, 112(11):3535-3540.  Kim U, Chang S (2005) Dendritic morphology, local circuitry, and intrinsic electrophysiology of neurons in the rat medial and lateral habenular nuclei of the epithalamus. J Comp Neurol 483: 23650.  Kinney GG, Kocsis B, Vertes RP. Injections of excitatory amino acid antagonists into the median raphe nucleus produce hippocampal theta rhythm in the urethane anesthetized rat. Brain Res. 1994;654:9604.  Kinney GG, Kocsis B, Vertes RP. Injections of muscimol into the median raphe nucleus produce hippocampal theta rhythm in the urethane anesthetized rat. Psychopharmacology. 1995;120:24448.  Kinney GG, Kocsis B, Vertes RP. Medial septal unit firing characteristics following injections of 8-OH-DPAT into the median raphe nucleus. Brain Res. 1996;708:11622.  Kiss J, Csaki A, Bokor H, Kocsis K, Kocsis B (2002) Possible   glutamatergic/aspartatergic projections to the supramammillary nucleus and their origins in the rat studied by selective [(3)H]D-aspartate labelling and immunocytochemistry. Neuroscience 111:67191.  Lauriello J, Kenny WM, Sutton L, Golshan S, Ruiz C, Kelsoe J, Rapaport M, Gillin JC (1993) The cholinergic REM sleep induction test with pilocarpine in mildly depressed patients and normal controls. Biol Psychiatry.33:33 ‚Äì 39.\n\nLavezzi HN, Parsley KP, Zahm DS. 2014. Modulation of locomotor activation by the rostromedial tegmental nucleus. Neuropsychopharmacology 40:67687.  Lodge DJ, Grace AA (2006) The laterodorsal tegmentum is essential for burst firing of ventral tegmental area dopamine neurons. Proc Natl Acad Sci U S A. 2006 Mar 28; 103(13):5167-72.  Luebke JI, Greene RW, Semba K, Kamondi A, McCarley RW, Reiner PB. Serotonin hyperpolarizes cholinergic low-threshold burst neurons in the rat laterodorsal tegmental nucleus in vitro. Proc Natl Acad Sci USA. 1992;89:74347.  Luppi PH, Peyron C, Rampon C, et al. (1999) Inhibitory mechanisms in the dorsal raphe nucleus and locus coeruleus during sleep. In: Lydic R, Baghdoyan HA, eds.   Handbook of behavioral state control: molecular and cellular mechanisms.   Boca Raton, FL: CRC, 195 ‚Äì  211.  Lydic R, Baghdoyan HA (2005) Sleep, anesthesiology, and the neurobiology of arousal state control. Anesthesiology. 2005 Dec; 103(6):1268-95.  Lydic R, McCarley RW, Hobson JA (1983). The time-course of dorsal raphe discharge, PGO waves, and muscle tone averaged across multiple sleep cycles. Brain Res. 1983;274:36570.  Ma S, Olucha-Bordonau FE, Hossain MA, Lin F, Kuei C, Liu C, Wade JD, Sutton SW, Nunez A, Gundlach AL. Modulation of hippocampal theta oscillations and spatial memory by relaxin-3 neurons of the nucleus incertus. Learn Mem 2009; 16: 73042.  Mani BK, Walker AK, Lopez Soto EJ, Raingo J, Lee CE, Perello M, Andrews ZB, Zigman JM. Neuroanatomical characterization of a growth hormone secretagogue receptor-green fluorescent protein reporter mouse. J Comp Neurol 2014; 522: 3644666.  Maru E, Takahashi LK, Iwahara S (1979) Effects of median raphe nucleus lesions on hippocampal EEG in the freely moving rat. Brain Res,163 : 22334.  Marcus JN, Aschkenasi CJ, Lee CE, Chemelli RM, Saper CB, Yanagisawa M, Elmquist JK. Differential expression of orexin receptors 1 and 2 in the rat brain. J Comp Neurol 2001; 435: 65.  Marrosu F, Portas C, Mascia MS, Casu MA, Fa M, Giagheddu M et al. (1995) Microdialysis measurement of cortical and hippocampal acetylcholine release during sleep-wake cycle in freely moving cats.   Brain Res . 671, 32932.  Marrosu F, Fornal CA, Metzler CW, Jacobs BL (1996) 5-HT 1A agonists induce hippocampal theta activity in freely moving cats: role of presynaptic 5-HT 1A receptors. Brain Res 739:19200.  Matsumoto M, Hikosaka O (2007). Lateral habenula as a source of negative reward signals in dopamine neurons.   Nature   447 (7148): 1111115.  McCarley RW, Hobson JA (1975) Neuronal excitability modulation over the sleep cycle: a structural and mathematical model. Science. 189:58 ‚Äì 60.\n\nMcCormick DA., Prince DA (1987) Actions of acetylcholine in the guinea-pig and cat medial and lateral geniculate nuclei, in vitro. J Physiol 392:14765.  McGinty DJ, Harper RM (1976) Dorsal raphe neurons: depression of firing during sleep in cats. Brain Res 101:56975.  Metherate R, Cox CL, Ashe JH (1992) Cellular bases of neocortical activation: modulation of neural oscillations by the nucleus basalis and endogenous acetylcholine. 12:4701 ‚Äì 4711.  Miyamoto Y, Watanabe Y, Tanaka M (2008) Developmental expression and serotonergic regulation of relaxin 3/INSL7 in the nucleus incertus of rat brain. Regul Pept, 145: 549.  Monnier M and Tissot R (1958) Helv. Physiol Pharmacol Acta 16, 255.  Oddie SD, Bland BH, Colom LV, Vertes RP (1994) The midline posterior hypothalamic region comprises a critical part of the ascending brainstem hippocampal synchronizing pathway. Hippocampus, 4, 45473.  O'Keefe J., Recce M. L. (1993). Phase relationship between hippocampal place units and the EEG theta rhythm. Hippocampus 3, 31730.  Olucha-Bordonau FE, Teruel V, Barcia-Gonzalez J, Ruiz-Torner A, Valverde-Navarro AA, Martinez-Soriano F. Cytoarchitecture and efferent projections of the nucleus incertus of the rat. J Comp Neurol 2003; 464: 627.  Olucha-Bordonau FE, Otero-Garcia M, Sanchez-Perez AM, Nunez A, Ma S, Gundlach AL. Distribution and targets of the relaxin-3 innervation of the septal area in the rat. J Comp Neurol 2012; 520: 1903939.  Pan WX, McNaughton N (2004) The supramammillary area: its organization, functions and  relationship to the hippocampus. Prog. Neurobiol. 74, 127 ‚Äì 166.  Park MR (1987) Monosynaptic inhibitory postsynaptic potentials from lateral habenula recorded in dorsal raphe neurons. Brain Res Bull 19:581-586.  Perrotti LI, Bolanos CA, Choi KH, Russo SJ, Edwards S, Ulery PG, Wallace DL, Self DW, Nestler EJ, Barrot M (2005) DeltaFosB accumulates in a GABAergic cell population in the posterior tail of the ventral tegmental area after psychostimulant treatment. Eur J Neurosci 21:2817824.  Phillipson OT, Pycock CJ. 1982. Dopamine neurons of the ventral tegmentum project to both medial and lateral habenula. Exp Brain Res 45: 894.  Qin C and Luo M. (2009). Neurochemical phenotypes of the afferent and efferent projections of the mouse medial habenula. Neuroscience 161:82737.  Quick MW, Ceballo RM, Kasten M, McIntosh JM, Lester RA (1999)   Œ± 3 Œ≤   4 subunit- containing nicotinic receptors dominate function in rat medial habenula neurons. Neuropharmacology 38:76983.\n\nRaisman G (1966) The connections of the septum. Brain 89: 317-348.  Ren J, Qin C, Hu F, Tan J, Qiu L, Zhao S, Feng G, Luo M (2011). Habenula cholinergic neurons co-release glutamate and acetylcholine and activate postsynaptic neurons via distinct transmission modes. 69:44552.  Reuss S, Moller M 1986. Direct projections to the rat pineal gland via the stria medullaris thalami. Cell Tissue Res 244: 69194.  Riemann D, Hohagen F, Bahro M, Lis S, Stadmuller G, Gann H, Berger M (1994) Cholinergic neurotransmission, REM sleep and depression. J Psychosom Res.38(Suppl 1):15 ‚Äì 25.  Ronnekleiv OK, Kelly MJ, Wuttke W. Single unit recordings in the rat pineal gland: evidence for habenulo-pineal neural connections. Exp Brain Res 39: 18792, 1980  Ronnekleiv OK, Moller M. Brain-pineal nervous connections in the rat: an ultrastructure study following habenular lesion. Exp. Brain Res. 1979;37:55162.  Roffwarg HP, Muzio JN, Dement WC (1966) Ontogenetic development of the human sleep- dream cycle Science 29; 152(3722):604-19.  Saito Y, Cheng M, Leslie FM, Civelli O. Expression of the melanin-concentrating hormone (MCH) receptor mRNA in the rat brain. J Comp Neurol 2001; 435: 260.  Sakai K (1980)   ‚ÄúSome anatomical and physiological properties of ponto -mesencephalic tegmental neurons with special reference to PGO waves and postural atonia during  paradoxical sleep,‚Äù in The Reticular Formation Revisited, eds Hobson J. A., Brazier M. A. B.,  editors. (New York: Raven Press; ), 427 ‚Äì 447.  Sakurai T (2007) The neural circuit of orexin (hypocretin): maintaining sleep and wakefulness. Nat. Rev. Neurosci. 8, 17181 10.1038/nrn2092  Sanchez-Perez, AM, Arnal-Vicente I, Santos FN, Pereira CW, ElMlil N, Sanjuan J, et al. (2015). Septal projections to nucleus incertus in the rat: bidirectional pathways for modulation of hippocampal function.   J. Comp. Neurol.   523, 56588.  Saper, CB, Chou TC & Scammell TE (2001) The sleep switch: hypothalamic control of sleep and wakefulness. Trends Neurosci. 24, 72631.  Saper CB, Sherin JE, Elmquist JK (1997) Role of the ventrolateral preoptic area in sleep induction. In: Hayaishi O, Inoue S, eds.   Sleep and sleep disorders: from molecule to behavior.   Tokyo: Academic,281 ‚Äì 294.  Sitaram N, Gillin JC (1980) Development and use of pharmacological probes of the CNS in man: evidence of cholinergic abnormality in primary affective illness. Biol Psychiatry. 15:925 ‚Äì 955.\n\nSitaram N, Wyatt RJ, Dawson S, Gillin JC (1976) REM sleep induction by physostigmine infusion during sleep. Science. 191:1281 ‚Äì 1283.  Steininger TL, Gong H, McGinty D & Szmusiak R (2001). Subregional organization of preoptic area/anterior hypothalamic projections to arousal-related monoaminergic cell groups. J. Comp. Neurol. 429, 63853.  Strecker, R. E.   et al . Adenosinergic modulation of basal forebrain and preoptic/anterior hypothalamic neuronal activity in the control of behavioral state. Behav. Brain Res. 115, 18304 (2000).  Sutherland RJ (1982) The dorsal diencephalic conduction system: a review of the anatomy and functions of the habenular complex. Neurosci Biobehav Rev 6:13.  Sugama S, Cho BP, Baker H, Joh TH, Lucero J, Conti B (2002). Neurons of the superior nucleus of the medial habenula and ependymal cells express IL-18 in rat CNS. Brain Res. 958, 1 10.1016/S0006-8993(02)03363-2  Takahashi K, Kayama Y, Lin JS, and Sakai K (2010). Locus coeruleus neuronal activity during the sleep-waking cycle in mice. Neuroscience 169, 1115126.  Takahashi K, Lin JS, Sakai K Neuronal activity of histaminergic tuberomammillary neurons during wake-sleep states in the mouse. J.Neurosci. 2006;26:102920298.  Teclemariam-Mesbah, R., Ter Horst, G. J., Fostema, F., Wotel, J. & Buijs, R. M. Anatomical demonstration of the suprachiasmatic nucleus-pineal gland. J. Comp. Neurol. 406, 17182 (1999).  Teruel-Marti V, Cervera-Ferri A, Nunez A, Valverde-Navarro AA, Olucha-Bordonau FE, Ruiz-Torner A. Anatomical evidence for a ponto-septal pathway via the nucleus incertus in the rat. Brain Res 2008; 1218: 876.  Thakkar MM, Strecker RE, McCarley RW (1998) Behavioral state control through differential serotonergic inhibition in the mesopontine cholinergic nuclei: a simultaneous unit recording and microdialysis study. J Neurosci. 18:5490497.  Thinschmidt, JS, 1993. The supramammillary nucleus: does it play a role in the mediation of hippocampal theta rhythm? MA Thesis. Florida Atlantic University.  Trulson ME, Jacobs BL (1979) Raphe unit activity in freely moving cats: correlation with level of behavioral arousal. Brain Res 163:13550.  Uhlhaas PJ, Roux F, Singer W, Haenschel C, Sireteanu R, Rodriguez E (2009) The development of neural synchrony reflects late maturation and restructuring of functional networks in humans. Proc Natl Acad Sci USA;106:9866871.  Vaccari C, Lolait SJ, Ostrowski NL (1998). Comparative distribution of vasopressin V1b and oxytocin receptor messenger ribonucleic acids in brain. Endocrinology; 139: 5015033.\n\nVadovi ƒç ov√° K (2014) Affective and cognitive prefrontal cortex projections to the lateral habenula in humans. in Front Hum Neurosci. 2014; 8:819. Published also in arXiv:1402.2196 [q-bio.NC]  Vadovi ƒç ov√° K, Gasparotti R (2014) Reward and adversity processing circuits: their competition and interactions with dopamine and serotonin signaling.   ScienceOpen Research , 15 Sept 2014. DOI: 10.14293/S2199-1006.1.SOR-LIFE.AEKZPZ.v1   Published also in 2013 in arXiv:1304.4201 [q-bio.NC]  Vanderwolf, CH (1969) Hippocampal electrical activity and voluntary movement in the rat. Electroencephalogr. Clin. Neurophysiol., 26, 40718.  Varga V, Kekesi A, Juhasz G, Kocsis B (1998) Reduction of the extracellular level of glutamate in the median raphe nucleus associated with hippocampal theta activity in the anaesthetized rat. Neuroscience. 1998 May; 84(1):49-57  Vertes RP and Fass B (1988) Projections between the interpeduncular nucleus and basal forebrain in the rat as demonstrated by the anterograde and retrograde transport of WGA- HRP. Exp. Brain Res., 73: 231.  Vertes RP, Kinney GG, Kocsis B, Fortin WJ (1994) Pharmacological suppression of the median raphe nucleus with serotonin1A agonists, 8-OH-DPAT and buspirone, produces hippocampal theta rhythm in the rat. Neuroscience, 60:44151.  Vertes, RP and Kocsis B (1997) Brainstem-diencephalo-septohippocampal systems controlling the theta rhythm of the hippocampus. Neuroscience, 81, 89326.  Vertes RP, Linley SB (2008) in Serotonin and sleep: molecular, functional and clinical aspects, Efferent and afferent connections of the dorsal and median raphe nuclei in the rat, eds Monti JM, Pandi-Perumal SR, Jacobs BL, Nutt DJ (Birkhnser Verlag, Basel), pp 6902.  Vertes, RP and Martin GF (1988) Autoradiographic analysis of ascending projections from the pontine and mesencephalic reticular formation and the median raphe nucleus in the rat. J. Comp. Neurol., 275: 51141. doi:10.1002/cne.902750404  Wang RY, Aghajanian GK (1977) Physiological evidence for habenula as major link between forebrain and midbrain raphe. Science 197:89-91.  Wasserman DI, Wang HG, Rashid AJ, Josselyn SA, Yeomans JS. 2013. Cholinergic control of morphine-induced locomotion in rostromedial tegmental nucleus versus ventral tegmental area sites. Eur J Neurosci 38:2774785.  Wasserman DI, Tan JMJ, Kim J, Yeomans JS. 2014. Muscarinic control of rostromedial tegmental nucleus (RMTg) GABA neurons and morphine-induced locomotion. Soc Neurosci Abstr 364.02.  Williams JA, Comisarow J, Day J, Fibiger HC, Reiner PB (1994) State-dependent release of acetylcholine in rat thalamus measured by in vivo microdialysis. 14:5236242.\n\nWilliams JA, Reiner PB. Noradrenaline hyperpolarizes identified rat mesopontine cholinergic neurons in vitro. J Neurosci. 1993;13:3878883.  Woolf NJ (1991) Cholinergic systems in mammalian brain and spinal cord. Progress in Neurobiology, 37, 475-524.  Yamaguchi T, Danjo T, Pastan I, Hikida T, Nakanishi S (2013) Distinct roles of segregated transmission of the septo-habenular pathway in anxiety and fear. Neuron. 78, 53744 10.1016/j.neuron  Yamamoto T, WatanabeS, Oishi R, Ueki S (1979) Effects of midbrain raphe stimulation and lesion on EEG activity in rats. Brain Res Bull, 4:49195.  Yoon JY, Jung SR, Hille B, Koh DS (2014) Modulation of nicotinic receptor channels by adrenergic stimulation in rat pinealocytes. Am J Physiol Cell Physiol; 306:C726n735.  Zahm DS (2006) The evolving theory of basal forebrain functional-anatomical acrosystems.Neurosci Biobehav Rev 30:14872.  Zahm DS, Jensen SL, Williams ES, Martin JR 3rd. 1999. Direct comparison of projections from the central amygdaloid region and nucleus accumbens shell. Eur J Neurosci 11:1119126.  Zahm DS, Parsley KP, Schwartz ZM, Cheng AY. 2013. On lateral septum-like characteristics of outputs from the accumbal hedonic hotspot of Pecina and Berridge with commentary on the transitional nature of basal forebrain boundaries.J Comp Neurol 521:508.",
      "embedding": [
        0.002524100709706545,
        -0.11027561128139496,
        0.012005267664790154,
        0.033581383526325226,
        -0.013992752879858017,
        0.08510054647922516,
        -0.028388051316142082,
        -0.029047932475805283,
        0.07569881528615952,
        0.022287823259830475,
        -0.09137488156557083,
        0.018724383786320686,
        0.06904218345880508,
        -0.009147810749709606,
        0.019624371081590652,
        0.09850375354290009,
        0.019326457753777504,
        0.05863140523433685,
        0.02970488741993904,
        0.03996044769883156,
        0.07224853336811066,
        -0.04875635728240013,
        0.06645514070987701,
        0.011234086006879807,
        -0.06306891143321991,
        0.020362550392746925,
        -0.007140486501157284,
        0.02355891279876232,
        -0.024731861427426338,
        -0.06708929687738419,
        0.0069506545551121235,
        0.05697038397192955,
        -0.025850627571344376,
        -0.017390180379152298,
        -0.04108796268701553,
        0.02188201993703842,
        -0.08756086975336075,
        -0.027336187660694122,
        -0.032706357538700104,
        -0.035497892647981644,
        0.04029114171862602,
        -0.00008869799057720229,
        0.03473599627614021,
        -0.003119637258350849,
        -0.03766527771949768,
        0.02800973318517208,
        0.034256044775247574,
        -0.05720971152186394,
        -0.05910656601190567,
        -0.04447515681385994,
        0.005753722973167896,
        -0.03462279587984085,
        -0.059280816465616226,
        0.13929180800914764,
        0.015224461443722248,
        0.10943792015314102,
        -0.042153872549533844,
        0.07197181135416031,
        -0.011819436214864254,
        0.001696732477284968,
        -0.11461351811885834,
        0.03871483728289604,
        0.026619162410497665,
        -0.07276545464992523,
        0.0805601105093956,
        0.054443590342998505,
        -0.11647877097129822,
        -0.0006285519921220839,
        -0.023243337869644165,
        -0.08061385154724121,
        -0.0036662807688117027,
        -0.007970579899847507,
        -0.037383612245321274,
        -0.0804351195693016,
        -0.022159120067954063,
        0.0075348420068621635,
        0.05266633629798889,
        0.04501515254378319,
        0.039698220789432526,
        -0.041128434240818024,
        0.021719614043831825,
        0.06251394748687744,
        0.01348076481372118,
        0.023913951590657234,
        0.03177551552653313,
        0.01828595995903015,
        0.02949013002216816,
        0.03733748942613602,
        -0.0009501432068645954,
        -0.0034802479203790426,
        0.03541138768196106,
        -0.0915808230638504,
        -0.09380245953798294,
        -0.05222898721694946,
        0.03535640612244606,
        -0.040667902678251266,
        0.0021412153728306293,
        0.041056640446186066,
        -0.0112043721601367,
        0.0038281723391264677,
        0.019111569970846176,
        0.033080875873565674,
        -0.01609218120574951,
        -0.02745344303548336,
        -0.033304035663604736,
        0.04530583694577217,
        0.019988955929875374,
        0.014244037680327892,
        0.011711450293660164,
        -0.006342289503663778,
        -0.0541902594268322,
        0.06015405058860779,
        -0.02108266018331051,
        0.11296568810939789,
        0.03584054112434387,
        -0.00156620261259377,
        0.001681885332800448,
        0.039752401411533356,
        0.09517303854227066,
        -0.03176281228661537,
        -0.005439403001219034,
        -0.0004835254803765565,
        0.04894166439771652,
        -0.11651953309774399,
        0.03738240897655487,
        -0.030429372563958168,
        -0.1057932898402214,
        5.9761486273912145e-33,
        0.025205466896295547,
        -0.07074207067489624,
        -0.02575552649796009,
        -0.06265008449554443,
        0.041225068271160126,
        -0.03976025804877281,
        0.00009311942994827405,
        0.011151270009577274,
        0.05657520145177841,
        -0.0024413305800408125,
        -0.09576745331287384,
        -0.023617040365934372,
        0.021678587421774864,
        0.04319220036268234,
        0.01064850203692913,
        -0.06431052088737488,
        -0.09746603667736053,
        -0.059948310256004333,
        0.03696950897574425,
        -0.05788786709308624,
        -0.011380353011190891,
        0.020677678287029266,
        0.052976034581661224,
        -0.012487232685089111,
        -0.059285879135131836,
        -0.060265880078077316,
        0.005900288466364145,
        0.061941683292388916,
        -0.015246941708028316,
        0.03370383381843567,
        -0.038666773587465286,
        0.028487488627433777,
        0.020390087738633156,
        -0.036027662456035614,
        0.02770051918923855,
        0.02891969121992588,
        -0.01209344994276762,
        -0.0630251094698906,
        -0.019456196576356888,
        -0.019373411312699318,
        0.0071089123375713825,
        -0.005912798922508955,
        -0.08070123195648193,
        -0.006987751927226782,
        -0.029190057888627052,
        -0.09641743451356888,
        -0.00007795211422489956,
        0.007055720314383507,
        0.09974876046180725,
        -0.024593334645032883,
        0.036657243967056274,
        -0.025469737127423286,
        -0.0006327881710603833,
        -0.10568142682313919,
        -0.06986933201551437,
        0.003514795331284404,
        -0.014437989331781864,
        0.015627840533852577,
        -0.0333191454410553,
        0.07916726917028427,
        -0.042418621480464935,
        -0.00029906517011113465,
        0.027652300894260406,
        -0.002976070623844862,
        0.06912408769130707,
        0.10215265303850174,
        -0.09736974537372589,
        -0.05102863535284996,
        0.02233864739537239,
        -0.032320279628038406,
        0.05362633243203163,
        -0.004536186344921589,
        0.02266586944460869,
        -0.03987882658839226,
        0.01917128823697567,
        -0.002412461908534169,
        0.058889228850603104,
        0.12117969989776611,
        0.023980598896741867,
        -0.029194967821240425,
        0.05390423536300659,
        -0.08324643969535828,
        -0.07764095813035965,
        0.04114239662885666,
        0.009275942109525204,
        -0.010723315179347992,
        0.08403171598911285,
        -0.043946120887994766,
        -0.08125985413789749,
        0.018170520663261414,
        0.09187950938940048,
        -0.01523401029407978,
        0.03916211053729057,
        0.06064439192414284,
        -0.04383740946650505,
        -5.638420651534325e-33,
        -0.05789045989513397,
        -0.06714106351137161,
        0.007306890096515417,
        -0.036017775535583496,
        -0.03420686349272728,
        0.07144077867269516,
        0.01641569286584854,
        -0.05038238689303398,
        -0.13571633398532867,
        -0.059620872139930725,
        0.03159948065876961,
        0.019250046461820602,
        -0.037469033151865005,
        -0.004509827587753534,
        0.05906948074698448,
        -0.08824151009321213,
        0.02736043930053711,
        0.01315153669565916,
        -0.033678218722343445,
        -0.006931255105882883,
        0.02661076746881008,
        0.09170158207416534,
        -0.07275649905204773,
        -0.014462755993008614,
        0.055457036942243576,
        0.044040657579898834,
        0.03554578498005867,
        0.14334699511528015,
        0.0696650817990303,
        0.056595705449581146,
        -0.011938794516026974,
        0.05857505649328232,
        -0.14764121174812317,
        -0.06669609248638153,
        0.023139044642448425,
        0.06499351561069489,
        0.012868277728557587,
        -0.0036411865148693323,
        -0.08635827153921127,
        -0.06273817270994186,
        0.09452416002750397,
        0.02515966072678566,
        0.04840241000056267,
        -0.020908568054437637,
        0.03320949897170067,
        0.0387200266122818,
        -0.09987247735261917,
        0.039041608572006226,
        -0.03885136917233467,
        0.019517267122864723,
        -0.005772131960839033,
        -0.05180833116173744,
        -0.006480611860752106,
        -0.05516822636127472,
        -0.027861159294843674,
        0.017464831471443176,
        -0.02287207543849945,
        -0.03851601481437683,
        0.03726163133978844,
        -0.06245609372854233,
        -0.06893662363290787,
        0.033804457634687424,
        -0.041396141052246094,
        -0.08853625506162643,
        0.083063043653965,
        0.013399996794760227,
        0.02101851813495159,
        -0.06099794805049896,
        0.08350800722837448,
        0.0062331827357411385,
        -0.0010304396273568273,
        0.05323127657175064,
        0.09786254167556763,
        -0.022146042436361313,
        0.02770504169166088,
        0.028661252930760384,
        -0.028761358931660652,
        -0.024168141186237335,
        -0.03049851395189762,
        -0.07562113553285599,
        -0.025755831971764565,
        0.016197767108678818,
        -0.057244136929512024,
        -0.06488011032342911,
        0.010108664631843567,
        -0.028121713548898697,
        -0.03227217495441437,
        0.028738021850585938,
        0.10353411734104156,
        -0.00520778214558959,
        -0.015267170034348965,
        -0.006492504850029945,
        -0.11674640327692032,
        0.006333163473755121,
        0.018472235649824142,
        -5.0550656993664234e-8,
        -0.010744359344244003,
        -0.07412346452474594,
        -0.002047285670414567,
        0.0449054017663002,
        0.03173984959721565,
        -0.06371311843395233,
        0.06344939023256302,
        0.017763201147317886,
        -0.03185177966952324,
        -0.009811058640480042,
        0.13138577342033386,
        0.01917845755815506,
        0.04135485365986824,
        -0.053597837686538696,
        0.021170375868678093,
        0.07562951743602753,
        0.050036199390888214,
        0.03753609582781792,
        0.014427021145820618,
        -0.04461689665913582,
        0.032617393881082535,
        -0.10464619845151901,
        0.042739104479551315,
        0.04262972250580788,
        0.11890339106321335,
        -0.049357254058122635,
        0.007705422583967447,
        0.08039921522140503,
        -0.05627463385462761,
        -0.03090701252222061,
        0.12750427424907684,
        -0.004104945342987776,
        0.02672474831342697,
        0.021051986142992973,
        -0.021744471043348312,
        0.031949132680892944,
        0.058318715542554855,
        0.016961954534053802,
        0.005222528241574764,
        0.05077613145112991,
        0.01583414524793625,
        -0.014840707182884216,
        -0.02244778349995613,
        0.02751448005437851,
        -0.01247015967965126,
        -0.05211642012000084,
        -0.011769981123507023,
        0.021169818937778473,
        0.0001726116461213678,
        -0.05578286945819855,
        -0.055177513509988785,
        0.027927396818995476,
        0.025122467428445816,
        0.035201553255319595,
        -0.04005172848701477,
        -0.04448606073856354,
        0.026805585250258446,
        -0.025369014590978622,
        0.04829951748251915,
        -0.04238593205809593,
        0.03723059222102165,
        0.05389809608459473,
        0.004237331449985504,
        -0.03504960611462593
      ],
      "metadata": {
        "title": "Paper_19_SWS_promoting_MHb_IPN_MRN_circuit_opposes_the_thet.pdf",
        "createdAt": "2025-12-17T13:56:35.486Z"
      },
      "fileObj": {}
    },
    {
      "id": "doc_9_1765979796376",
      "fileName": "Paper_17_Data_Efficient_Sleep_Staging_with_Synthetic_Time_S.pdf",
      "content": "Data-Efficient Sleep Staging with Synthetic Time Series Pretraining  Niklas Grieger 1 , 2 , 3 , ‚àó   Siamak Mehrkanoon 2   Stephan Bialonski 1 , 3 , ‚àó  1 Department of Medical Engineering and Technomathematics, FH Aachen University of Applied Sciences, 52428 J¬® ulich, Germany  2 Department of Information and Computing Sciences, Utrecht University, Utrecht, The Netherlands  3 Institute for Data-Driven Technologies, FH Aachen University of Applied Sciences, 52428 J¬® ulich, Germany  ‚àó grieger@fh-aachen.de, bialonski@fh-aachen.de  Abstract  Analyzing electroencephalographic (EEG) time series can be challenging, especially with deep neural networks, due to the large variability among human subjects and often small datasets. To address these challenges, various strategies, such as self-supervised learning, have been suggested, but they typically rely on extensive empirical datasets. Inspired by recent advances in computer vision, we propose a pretraining task termed ‚Äúfrequency pretraining‚Äù to pretrain a neural network for sleep staging by predicting the frequency content of randomly generated synthetic time series. Our experiments demonstrate that our method surpasses fully supervised learning in scenarios with limited data and few subjects, and matches its performance in regimes with many subjects. Furthermore, our results underline the relevance of frequency information for sleep stage scoring, while also demonstrating that deep neural networks utilize information beyond frequencies to enhance sleep staging performance, which is consistent with previous research. We anticipate that our approach will be advantageous across a broad spectrum of applications where EEG data is limited or derived from a small number of subjects, including the domain of brain-computer interfaces.  1   Introduction  Deep neural networks have achieved significant advances in analyzing electroencephalographic (EEG) time series [39], ranging from brain-computer interfaces [30] to the intricacies of sleep stage scoring [36, 15].   Such successes are attributed to the ability of deep neural networks, as universal function approximators, to learn properties (features) from patient data that are difficult for humans to conceptualize and define. However, training neural networks requires large and diverse datasets that capture the considerable variety between individual subjects and their medical conditions (subject heterogeneity). Creating such datasets is challenging due to the typically limited amount of data per subject (data scarcity) and diverse measurement protocols used in different clinics, which can introduce additional variability in the data.   Furthermore, acquiring large datasets is often expensive, complicated, or even intractable due to strict privacy policies and ethical guidelines. This hinders the advancement of deep neural networks for widespread application in real-world medical settings. Efforts to mitigate the scarcity of large datasets have primarily followed two paths:   (1) the development of network architectures that incorporate constraints mirroring the data‚Äôs intrinsic characteristics, such as symmetries [7], and (2) enhancing model performance with additional or cross-domain data to learn effective priors.   Pertaining to the first path, a common feature in time series processing networks is the use of convolutional layers.   These layers are designed to be translation-equivariant [18], which ensures that a temporal shift in the input only affects the output by the same shift. This characteristic enables consistent network responses to temporal patterns, regardless of their temporal location, while reducing the number of model parameters compared to architectures lacking such constraints. For the second path, a variety of strategies have been proposed to learn useful priors from data. One approach is data augmentation, in which time series are transformed while preserving their annotations (labels) to artificially expand the dataset [31, 23]. Deep neural networks trained on such augmented datasets implicitly learn to become invariant under these transformations, which can lead to better out-of-sample prediction performance. Another strategy is transfer learning [12], a two-step process in which neural networks are trained on one task using a large dataset (pretraining step [37]) and then adapted to learn the actual task of interest using another (usually much smaller) dataset (fine-tuning step).   A variant of this idea is self-supervised learning [32, 2], which allows neural networks to be pretrained on large and heterogeneous datasets without explicitly labeled examples.   Finally, generative models such as VAEs, GANs, and diffusion models can be used to sample new time series to extend existing datasets [22, 8, 46].   Such generative models approximate a data distribution and require large heterogeneous datasets for training. While all of these approaches have been demonstrated to be able to improve the performance of neural networks, they still rely on large empirical datasets for training. Recent advances in computer vision have demonstrated that it is possible to learn effective priors exclusively from synthetic images, which has the potential to significantly reduce the need for large empirical datasets [3, 26]. Synthetic images for image 1  arXiv:2403.08592v2 [cs.LG] 17 Sep 2025\n\nclassification tasks were generated by simple random processes, such as iterated function systems to produce fractals [26] or random placement of geometric objects to cover an image canvas [3].   Deep neural networks pretrained on such data were demonstrated to learn useful priors for image classification tasks, yielding competitive performance comparable to pretraining on natural images on various benchmarks [26].   This remarkable finding highlights the potential of synthetic datasets that can be generated without much computational resources and, theoretically, in unlimited amounts. Inspired by these advances, we hypothesize that pretraining exclusively on synthetic time series data generated from simple random processes can also yield effective priors for sleep staging.   Given the importance of frequencies for sleep stage scoring and other EEG-based applications [5, 33], we introduce a pretraining method called ‚Äúfrequency pretraining‚Äù (FPT) that centers on generating synthetic time series data with specific frequency content. During pretraining, deep neural networks learn to accurately predict the frequencies present in these synthetic time series. Despite the deliberate simplicity of our synthetic data generation process and the inherent domain shift between synthetic and EEG data, we observe that FPT allows a deep neural network to detect sleep stages more accurately than fully supervised training when few samples (few-sample regime) or data from few subjects (few-subject regime) are available for fine-tuning. The success of our method underscores the essential role of frequency content in enabling neural networks to accurately and reliably discern sleep stages. We consider pretraining techniques leveraging synthetic data, like the one we propose, as a promising area of research, offering the potential to develop models in sleep medicine and neuroscience that are particularly suited for scenarios involving small datasets. To facilitate testing and further advancements, we make the source code of our method publicly available [19].  Contributions  ‚Ä¢   Novel synthetic pretraining approach:   We introduce ‚Äúfrequency pretraining‚Äù (FPT), a pretraining approach using synthetic time series with random frequency content, eliminating the need for empirical EEG data during pretraining.  ‚Ä¢   Demonstrated data efficiency:   We demonstrate superior sleep staging performance of FPT in few-sample and few- subject regimes across three datasets, with comparable results to fully supervised methods when data is abundant.  ‚Ä¢   Analysis of frequency-based priors:   We evaluate the role of frequency information in our pretraining task and how synthetic sample diversity affects fine-tuning.  ‚Ä¢   Comparison with self-supervised methods:   We benchmark our approach against established self-supervised learning methods, demonstrating that synthetic data pretraining can achieve comparable results without requiring EEG data for pretraining.  2   Results  Our approach, illustrated in Figure 1 and detailed in Section 4, is based on a two-phase training process that combines pretraining on synthetic time series with fine-tuning on clinical sleep data.   During the pretraining phase, we generate synthetic time series composed of sine waves with random frequencies drawn from predefined frequency ranges (frequency bins). These synthetic signals are then used to train a deep neural network whose feature extractor,   f   , learns to extract useful features, while the classifier,   c p , learns to predict the frequency bins from which the frequencies were drawn to generate the synthetic time series. After pretraining, the feature extractor is transferred to the fine-tuning phase, where it is applied to real EEG and electrooculography (EOG) data to classify sleep stages. In this phase, the model processes sequences of eleven consecutive sleep epochs, indexed   i   ‚àí   5 to   i   + 5, with the feature extractor producing features   h i   from each epoch. Another classifier   c f   then aggregates these features to predict the sleep stage (Wake, N1, N2, N3, REM) for the central sleep epoch   i . We evaluated our approach on three publicly available datasets,   DODO/H ,   Sleep-EDFx , and   ISRUC , which provided data from 276 subjects, including both healthy individuals and those with various medical conditions (see Section 4.2.1). For sleep staging performance, we tracked the Macro-F1 score, with higher values indicating better classification accuracy across sleep stages. During the pretraining phase, we assessed the model‚Äôs ability to predict frequency bins using the Hamming metric and the accuracy (see Section 4).  2.1   Training Configurations  We compared the performance of pretrained models against the performance of non-pretrained models in scenarios with varying amounts of training data. In particular, we studied the performance of our approach in few-sample and few-subject regimes, where the greatest benefit was expected.   Furthermore, we analyzed the priors that the model learned during pretraining and the role of frequency information in the learned features.   Finally, we investigated whether these features could be further improved by fine-tuning the feature extractor.   To enable these investigations, we created four training configurations.  Fully Supervised.   The Fully Supervised training configuration is similar to many existing deep learning approaches for sleep staging [36] and served as a baseline to compare our pretrained models against. In this configuration, we skipped the pretraining step and trained (fine-tuned) the feature extractor   f   and classifier   c f   from scratch using sleep staging data. 2\n\nFigure 1:   The training process consists of a   pretraining   and a   fine-tuning   phase.   In the pretraining phase (‚Äúfrequency pretraining‚Äù), we generated synthetic time series signals by summing sine waves with random frequencies. These synthetic signals were used to train a deep neural network consisting of a feature extractor   f   and a classifier   c p   to predict the frequencies present in the signals (multi-label classification problem). In the fine-tuning phase, the pretrained feature extractor   f   produced features   h i   from individual EEG and EOG epochs. The features of a sequence of these epochs were then used by a classifier  c f   that was trained to predict the sleep stage of the middle epoch in the sequence (multi-class classification problem).  Fixed Feature Extractor.   We employed the Fixed Feature Extractor configuration to investigate the relevance of the features generated by the pretrained feature extractor for sleep staging. After pretraining the feature extractor   f   on synthetic data, we kept its model weights and BatchNorm statistics fixed and only fine-tuned the sleep staging classifier   c f   on sleep data.  Fine-Tuned Feature Extractor.   With this training configuration, we studied (i) how model performance changes when the pretrained feature extractor is allowed to change during fine-tuning and (ii) whether the priors learned during pretraining can prevent overfitting in few-sample or few-subject regimes. As in the previous configuration, we first pretrained the feature extractor   f   on synthetic data, but then fine-tuned both the feature extractor and the classifier   c f   on sleep data without keeping any model weights fixed. Consequently, this configuration is similar to the Fully Supervised configuration with the key distinction that the feature extractor is initialized with pretrained weights.  Untrained Feature Extractor.   The Untrained Feature Extractor configuration served as a baseline to study whether our pretraining scheme produces priors that are superior to random weights for sleep staging. We randomly initialized the feature extractor   f   using Kaiming normal initialization [24] and then kept its weights fixed while fine-tuning the classifier   c f   . This approach mirrors the Fixed Feature Extractor configuration, but with a random feature extractor instead of a pretrained one.  2.2   Data Efficiency  To assess the data efficiency of our pretraining method, we compare the performance of the different training configurations when fine-tuned with a reduced amount of training data (low-data regime) or the full training data (high-data regime). We investigated the low-data regime by first pretraining models with the full synthetic dataset. Depending on the training configuration, we then fine-tuned the pretrained or randomly initialized models with the data of 50 randomly sampled sleep staging samples from one subject. The sampling procedure selected sleep staging data without class stratification, and each sleep stage was represented at least once in the reduced datasets. In the high-data regime, we followed the same procedure 3\n\n]   * ]   * ]   * ]   * ]   * ]   * ]   * ]   * ]   * Figure 2:   Average macro F1 scores achieved by the different training configurations when fine-tuned with a small set of training data (left side) or a large set (full set) of training data (right side) from one of the three datasets DODO/H, Sleep-EDFx, and ISRUC. The bars indicate the mean of the macro F1 scores measured on the test sets and averaged over 15 trainings (3 repetitions of a 5-fold cross-validation). Error bars show the standard deviation of the macro F1 scores, and * symbols indicate significant differences between Untrained and Fixed Feature Extractor or between Fine-Tuned Feature Extractor and Fully-Supervised training configuration ( p <   0 . 01) according to a one-sided Wilcoxon signed-rank test. but fine-tuned models with the full training data instead of a reduced amount of data. We repeated all experiments three times in a 5-fold cross-validation scheme, resulting in 15 training runs for each configuration and dataset.   This approach allowed us to estimate the spread of the macro F1 scores when using different model initializations, sleep staging samples, and data folds for training and testing (see Section 4). In the low-data regime, we observed that models pretrained with synthetic data outperformed models trained from scratch in sleep stage classification (see Figure 2). The performance gap between pretrained and non-pretrained models was most pronounced when comparing the fine-tuned feature extractor to the fully supervised configuration, with the former achieving average macro F1 scores that were 0.06‚Äì0.07 higher than those of the latter across datasets. When removing the fine-tuning of the pretrained features (fixed feature extractor configuration), our method still yielded macro F1 scores that were 0.01‚Äì 0.05 higher than those of the fully supervised configuration. Comparing the fixed feature extractor to the untrained feature extractor configuration further highlights the importance of the learned features.   Pretraining the feature extractor with synthetic data improved the macro F1 scores by 0.10‚Äì0.17 compared to a random initialization. While the macro F1 scores of the training configurations varied between datasets, the general trends observed in the low-data regime were consistent across all three datasets. In the high-data regime, our pretrained models were on par with fully supervised trained models ( p   ¬° 0.05 for a paired TOST test with a margin of   ¬± 0 . 01 on the DODO/H and ISRUC datasets) and achieved competitive performance in sleep stage classification (see Figure 2). The fine-tuned feature extractor configuration achieved average macro F1 scores of 0.76‚Äì 0.81 across datasets, comparable to the macro F1 scores of 0.76‚Äì0.80 achieved by the fully supervised configuration. As in the low-data regime, we observed that fine-tuning the pretrained features was beneficial, as the macro F1 scores achieved by the fine-tuned feature extractor configuration were 0.02‚Äì0.05 higher than those of the fixed feature extractor configuration. The performance gap between the untrained feature extractor and the fixed feature extractor remained substantial even in the high-data regime, with the former achieving average macro F1 scores that were 0.08‚Äì0.12 lower than those of the latter.  2.3   Impact of Subject Diversity and Number of Training Samples  We further explored the data efficiency of our pretraining method by investigating how model performance is affected by subject diversity and sample volume (i.e., number of samples) in the training data used for fine-tuning. To study the effect of subject diversity independent of sample volume, we separately varied the number of subjects and the number of samples in the training data.   The number of subjects was randomly sampled as   n subj   ‚àà { 1 ,   2 ,   3 ,   4 ,   5 } , and the number of samples was randomly sampled from those subjects as   n samples   ‚àà { 50 ,   130 ,   340 ,   900 ,   all }   (‚Äúall‚Äù indicates that all available training samples were used). Our sampling strategy selected sleep staging data without class stratification, and each sleep stage was 4\n\nrepresented at least once in the reduced datasets.   For each parameter combination, we trained the fully supervised and fine-tuned feature extractor configurations on all three datasets with three repetitions of 5-fold cross-validation. In our results, we observed that both the fully supervised and the fine-tuned feature extractor configurations benefited from increased subject diversity, even when the total number of training samples was held constant (see rows in Figure 3a‚Äìf). Similarly, both configurations benefited from an increased number of training samples when the number of subjects was held constant (see columns in Figure 3a‚Äìf).   For the considered parameter ranges, the impact of reduced subject diversity and reduced sample volume on model performance appeared to be comparable. Similar to the observations made in Section 2.2, the fine-tuned feature extractor configuration achieved better macro F1 scores than the fully supervised configuration in the few-sample regime. The performance gap between the two configurations was most evident when the number of samples was limited to 50, with bootstrap estimates of the mean differences in macro F1 scores ranging from 0.05 to 0.09 across datasets and subject numbers (see Figure 3g‚Äìi).   These differences in macro F1 scores decreased as the number of samples increased.   When training on all available training samples, the fine-tuned feature extractor configuration achieving comparable or slightly better performance than the fully supervised configuration. Interestingly, the performance gap between the two configurations with all available training samples was most pronounced for the DODO/H dataset. The fine-tuned feature extractor configuration achieved average macro F1 scores that were 0.02‚Äì0.06 higher than those of the fully supervised configuration. For the Sleep-EDFx and ISRUC datasets, the performance differences between the two configurations with all available training samples were minimal at 0.00‚Äì0.01. Depending on the dataset, the fine-tuned feature extractor configuration showed varying degrees of improvement over the fully supervised configuration in the few-subject regime.   When training with data of a single subject, the fine-tuned feature extractor configuration achieved average macro F1 scores that were 0.06‚Äì0.11 higher across sample numbers than those of the fully supervised configuration for the DODO/H dataset (see rows in Figure 3g). This performance gap decreased as the number of subjects increased, with mean bootstrapped differences in macro F1 scores between 0.02 and 0.09 for five subjects. In contrast, varying the number of subjects had less impact on the performance gap between the fine-tuned feature extractor and the fully supervised configurations for the Sleep-EDFx and ISRUC datasets (see rows in Figure 3h‚Äìi).   The improvements achieved by the fine-tuned feature extractor configuration when trained with one subject (0.01‚Äì0.05 for the Sleep-EDFx dataset and 0.00‚Äì0.07 for the ISRUC dataset) were comparable to those achieved when trained with five subjects (0.00‚Äì0.06 for the Sleep-EDFx dataset and 0.01‚Äì0.06 for the ISRUC dataset).  2.4   Priors Towards Frequency Information  To get a better understanding of the pretraining process and the priors learned by the model, we recorded several metrics during pretraining.   The recorded loss function converged to a low value, indicating that the model has learned effectively (see Figure 4a). At the same time, the Hamming metric reached a high value of 0.9 on the validation data (see Figure 4b). This value can be interpreted as the model predicting the frequency bins that were used to create the synthetic signals with an accuracy of 90%.   The model was particularly proficient in predicting higher frequencies starting from 2.5 Hz (accuracies   >   90%; see Figure 4c).   Lower frequencies, especially those below 1 Hz, were predicted with lower accuracy (75‚Äì85%). We hypothesize that the differences in prediction accuracy across frequency bins are not due to the pretrained model being unable to predict lower frequencies. Instead, we believe this discrepancy arises from the varying width of the frequency bins (see x-axis of Figure 4c) as the bins for lower frequencies were narrower than those for higher frequencies due to their logarithmic scaling. While we applied a logarithmic binning scheme to increase our model‚Äôs focus on the lower frequencies important for identifying slow wave sleep (N2 and N3 sleep), the narrow low frequency bands increase the difficulty of the pretraining task leading to decreased accuracies.   Preliminary exploration of this trade-off between model focus and task difficulty showed that the current binning scheme slightly outperforms a linear binning scheme in the fixed feature extractor setup. Interestingly, the ability of the pretrained feature extractor to extract useful features for sleep staging was strongly influenced by the diversity of the synthetic pretraining data (see Figure 4d).   We investigated this influence of sample diversity by pretraining models with varying amounts of different synthetic samples   n synthetic   ‚àà { 1 ,   10 ,   100 ,   10 3 ,   10 4 ,   10 5 ,   10 6 } . To isolate the effect of sample diversity from the effect that the number of training steps has on model performance, we kept the number of gradient updates per training epoch constant by under- or oversampling the synthetic data to 100,000 samples. The pretrained models were then trained for sleep staging using data from one random subject from the DODO/H dataset and evaluated on the validation data of each cross-validation fold.   As in the previous experiments, we performed three repetitions of a 5-fold cross-validation scheme for each number of synthetic samples. Both the fixed feature extractor and the fine-tuned feature extractor configurations required a high level of diversity in the synthetic pretraining data to achieve good sleep staging performance (see Figure 4d). When pretrained with only one synthetic sample, the performance of the two training configurations with pretraining differed only slightly from the performance of the configurations without pretraining (untrained feature extractor and fully supervised configurations). As the number of synthetic samples was increased to more than 100, the performance of the pretrained models improved substantially until reaching a plateau at around 10,000 samples. We hypothesize that this plateau was reached because the model had learned all the relevant features from the pretraining task, and additional samples did not provide any further benefit. The simplicity 5\n\nFigure 3:   Detailed comparison of the fully supervised and fine-tuned feature extractor configurations in few-sample and few-subject regimes for each of the three datasets DODO/H (panels   a , d , g ), Sleep-EDFx (matrices   b , e , h ), and IS- RUC (panels   c , f , i ).   Panels ( a ‚Äì c ) and Panels ( d ‚Äì f   ) show the macro F1 scores achieved by the fully supervised and the fine-tuned feature extractor configurations, respectively.   The displayed scores are the mean and the standard de- viation of the macro F1 scores measured on the test set over 15 trainings (3 repetitions of a 5-fold cross-validation). Panels ( g‚Äìi ) show the average macro F1 scores achieved by the fine-tuned feature extractor configuration minus the average macro F1 scores achieved by the fully supervised configuration.   These differences were calculated using a bootstrapping approach with 10,000 bootstrap samples. In this bootstrapping approach, we first paired the 15 macro F1 scores available for both configurations for each matrix entry based on the used seed and fold.   We then calculated the difference between each pair of macro F1 scores. For each bootstrap sample, we sampled 15 of these differences with replacement and calculated their average. Finally, we display the mean and the standard deviation of these bootstrap samples. 6\n\nFigure 4:   Analysis of the ‚Äúfrequency pretraining‚Äù task. Panel ( a ) shows the development of the loss function during a single pretraining run for both the training and validation data. The following two panels quantify the accuracy of a pretrained model to predict the frequencies of the synthetic signals. The hamming metric in panel ( b ) measures the overall accuracy summarized across all frequency bins, while panel ( c ) shows the accuracy for each frequency bin separately.   Panel ( d ) illustrates how the diversity of the synthetic pretraining data affects the performance of the pretrained feature extractor (FE) after fine-tuning for sleep staging on a single subject from the DODO/H dataset. Each bar indicates the mean of the macro F1 scores on the validation data averaged over 3 repetitions of a 5-fold cross-validation, while the error bars show the standard deviation of the macro F1 scores. of the pretraining task could also explain the negligible performance differences between the pretrained configurations with less than 100 synthetic samples and the training configurations without pretraining.   For such few synthetic samples, the model may have memorized the synthetic data rather than learn general features useful for sleep staging.  2.5   Comparison to Self-Supervised Methods  We compared our frequency pretraining approach (FPT) with two popular self-supervised learning (SSL) methods, Sim- CLR [9] and VICReg [4], using the same model architecture as in FPT. The projection head (SimCLR) and expander (VICReg) followed their original designs [9, 4]. Different from the conceptually simple multi-label classification task in FPT, both SSL methods follow the objective of contracting representations of data-augmented ‚Äúpositive‚Äù samples while keeping representations of dissimilar ‚Äúnegative‚Äù samples far apart (see original works for details [9, 4]). Positive samples were gen- erated using standard data augmentations: amplitude scaling (random factor 0.5‚Äì2), Gaussian noise injection ( œÉ   = 0.05), random temporal masking (10 segments of 1.5‚Äì3 s), time shifting (up to   ¬± 1.5 s), and time warping (random factor 0.67‚Äì1.5). We evaluated two pretraining configurations: pretraining on (i) synthetic data (as in FPT) and (ii) EEG recordings from the ISRUC and Sleep-EDFx datasets. Fine-tuning was performed on DODO/H datasets under low-data (50 random epochs from one random subject) and high-data (all available training data) regimes, respectively. When pretrained on synthetic data, both SimCLR and VICReg achieved performance comparable to the FPT method, with FPT slightly outperforming the SSL methods in the high-data regime when the feature extractor was fine-tuned (average MF1 scores of 0.80 versus 0.81, see Table 1). Pretraining on EEG data yielded only modest improvements, with both SSL methods showing slightly better performance in the low-data regime when the feature extractor was fixed (difference in average MF1 scores of 0.02) and in the high-data regime when fine-tuning the feature extractor (difference in average MF1 7\n\nscores of 0.01).   Compared to the EEG-pretrained SimCLR and VICReg models in the high-data regime, FPT showed similar performance (average MF1 scores of 0.76 and 0.81) but, unlike the two SSL methods, did not require EEG data for pretraining. In the low-data regime, the SSL methods performed comparable to the FPT method when fine-tuning the feature extractor and achieved slightly higher scores than FPT when keeping the feature extractor fixed (average MF1 scores of 0.44 and 0.45 versus 0.42).   None of the differences in MF1 scores between the SSL methods and FPT were significant according to a two-sided Wilcoxon signed-rank test ( p -values   >   0.05). Table 1:   Comparison of different pretraining methods when fine-tuned with 50 random sleep epochs of one subject (low-data regime) or the full training set (high-data regime) of the DODO/H dataset. During fine-tuning, the feature extractor was either kept fixed (FE fixed) or updated together with the classifier (FE fine-tuned).   We pretrained SimCLR and VICReg on the same synthetic data used for the frequency pretraining task, in addition to the traditional approach of pretraining on EEG data (i.e., ISRUC and Sleep-EDFx datasets). MF1 scores were calculated as the average of three repetitions of a five-fold cross validation (standard deviation in parentheses).  Pretraining Method   Avg. MF1 Low-Data Regime   Avg. MF1 High-Data Regime FE Fixed   FE Fine-Tuned   FE Fixed   FE Fine-Tuned  SimCLR, pretrained with synth. data   0.42 (0.08)   0.44 (0.09)   0.76 (0.02)   0.80 (0.02) SimCLR, pretrained with EEG data   0.44 (0.08)   0.43 (0.09)   0.76 (0.02)   0.81 (0.02) VICReg, pretrained with synth. data   0.43 (0.07)   0.44 (0.08)   0.76 (0.02)   0.80 (0.02) VICReg, pretrained with EEG data   0.45 (0.08)   0.45 (0.09)   0.76 (0.02)   0.81 (0.01) Frequency pretraining   0.42 (0.06)   0.44 (0.09)   0.76 (0.01)   0.81 (0.02)  3   Discussion  In this work, we propose a novel pretraining scheme for EEG time series data that leverages synthetic data generated by a simple random process.   We specialized the hyperparameters of the pretraining task to the typical frequency range and distribution of sleep EEG signals and demonstrated the effectiveness of this task for sleep stage classification.   Due to the availability of several open sleep staging datasets [35, 47], we were able to fully control the amount and diversity of the training data, which allowed us to study the impact of our method in different data regimes. We hypothesize that our pretraining scheme could be particularly beneficial in few-sample and few-subject regimes, which we argue could benefit greatly from the priors towards frequency information that a model learns during pretraining. Our results confirm the effectiveness of our pretraining scheme, particularly in few-sample and few-subject regimes. Pretrained models outperformed non-pretrained models when fine-tuned with a reduced number of subjects or training samples (see rows and columns in Figure 3g‚Äìi, respectively). The performance gap between pretrained and non-pretrained models was most pronounced in the few-sample regime, where pretrained models consistently achieved improvements over non-pretrained models across multiple datasets.   In the few-subject regime, this performance gap was not as consistent across datasets, with our pretraining method showing the most substantial improvements in the DODO/H dataset.   Our findings support observations made in the field of Self-Supervised Learning (SSL) that pretrained models generally have better data efficiency than fully supervised ones [2, 13].   In contrast to SSL methods, however, our pretraining scheme improves data efficiency without requiring empirical data, while achieving comparable or only slightly reduced performance (see Table 1). Interestingly, we observed that two data-augmentation-based SSL methods performed well even when pretrained with synthetic data instead of EEG data (see Table 1), suggesting that SSL approaches are promising, yet computationally intensive, alternatives to the FPT method. Further exploration of the use of SSL methods for pretraining on synthetic data is warranted and seems promising. Generating synthetic data can be much cheaper and more cost-effective than collecting EEG data, as generating 10,000 samples of the synthetic data used in this study required only 8 . 17   ¬±   0 . 37 s of a single consumer-grade CPU core (Lenovo Legion S7 16IAH7 Laptop with an Intel ¬Æ   Core ‚Ñ¢   i7-12700H CPU). We hypothesize that the potential of synthetic data stems from the priors that the model learns during pretraining. These priors could prevent overfitting to a small number of training samples, particularly those from minority classes (e.g., N1 sleep), or subject-specific features, which is especially problematic in situations with very little training data. As expected, we observed that all of our training configurations improved with a larger training dataset (see Figure 2). This aligns with the prevalent view in the literature that deep learning models for sleep staging need substantial amounts of diverse data to perform well [36, 1, 15, 14]. When trained with the full training data, pretrained models performed comparably to fully supervised models (see Figure 2), achieving macro F1 scores similar to those of other deep learning approaches for sleep staging [36, 16]. In conclusion, our pretraining method was most beneficial in situations with limited training data, where it outperformed models trained from scratch, but had less impact in situations with large amounts of training data. We further observed that, while the frequency content of a signal is crucial for sleep staging, deep neural networks extract additional information from the data that exceeds the frequency domain.   The importance of the frequency content of a signal for sleep staging is demonstrated by the high macro F1 scores achieved by the fixed feature extractor configuration 8\n\nand the substantial performance improvements it achieved over untrained feature extractors (see Figure 2).   We attribute the performance gap between the two training configurations to the priors learned during pretraining the feature extractor. These priors biased the model to extract frequency information from the data, which it achieved with high accuracy after pretraining (see Figure 4b,c). Our finding is consistent with previous studies that reported frequency-based features to be important for sleep staging [33].   When the feature extractor of our model was allowed to be fine-tuned after pretraining, model performance increased (see Figure 2). We hypothesize that this increase in the macro F1 score is due to the feature extractor learning to extract information beyond the frequency content of the signal during fine-tuning.   This hypothesis is in line with the AASM annotation guidelines [5], which consider several frequency-unrelated features essential for sleep staging. These features include time-domain information, which is important for spindles as well as amplitudes and specific patterns, such as k-Complexes [15].   Recent studies that applied feature engineering approaches to sleep staging further support our hypothesis by including additional features from the time-domain in the models used [43, 10].   In their work, Vallat and Walker analyzed the most important features for their model and found that time-related features, such as the time elapsed from the beginning of a recording, were among the top 20 most important features [43]. Although it remains unclear what additional information our pretrained models learn during fine-tuning, our method offers a promising avenue for future research into the interpretability of deep neural networks for sleep staging. There are several opportunities for future work that could build upon our findings. One promising direction is to explore the pretraining task in more detail, for example, by investigating the synthetic data generation process and the impact of changing the used frequency range.   Similar to previous work in the vision domain [3], it could also be promising to investigate which structural properties of synthetic time series are important for sleep staging.   This could be achieved by defining new pretraining tasks that are based on different data generation processes that incorporate more complex structures like desynchronized phases across channels, noise, or polymorphic amplitude variations.   Exploring such data generation processes may lead to a better understanding of what constitutes ‚Äúnatural‚Äù EEG time series and what information, besides the frequency content, is essential for sleep staging. In addition, we suggest exploring models with greater capacity and less inductive bias than the CNN-based architecture used in this work, such as transformer models [45, 6], which we expect to benefit even more from our pretraining method. Pretraining such models with synthetic data may alleviate their need for large amounts of training data [11]. Another avenue for future research is to investigate whether our pretraining method is beneficial for specific cohorts of subjects, such as patients with a specific disorder or specific age groups. Although we did investigate datasets with different demographics in this work, we did not perform detailed analyses of the impact of these demographics on model performance. Finally, it could be insightful to compare our approach with a broader range of SSL methods [32] and data augmentation strategies that employ synthetic EEG generators [31, 22]. To enable such comparisons and to facilitate future research in this direction, we make our code available online [19]. Our method presents a novel solution to address important issues that affect current deep learning models in the EEG time series domain, without requiring large amounts of patient data. We expect our approach to be advantageous in various applications where EEG data is scarce or derived from a limited number of subjects, such as brain‚Äìcomputer interfaces [30] or neurological disorder detection [44].  4   Materials and Methods  We trained deep neural networks in two phases: a pretraining phase based on synthetic data and a fine-tuning phase based on clinical sleep staging data. The training process is illustrated in Figure 1.  4.1   Phase 1: Pretraining with Synthetic Data  In the pretraining phase, we trained a deep neural network to predict the frequencies of randomly-generated synthetic time series (‚Äúfrequency pretraining‚Äù) [20].   The deep neural network consisted of a feature extractor to produce features and a classifier to predict which frequencies are present in the synthetic time series. Instead of training the model to predict the exact frequencies, we defined frequency ranges (frequency bins) and let the model identify the bins containing frequencies present in the signal (therefore turning the problem into a multi-label classification task).  4.1.1   Synthetic Data Generation  The   synthetic   samples   used   for   pretraining   consisted   of   a   time   series   signal  s ( t )   ‚àà   R 3 √ó 3000 , featuring 3 channels of 30 s sampled at 100 Hz, and an associated label vector   l .   The synthetic time series were created by summing sine waves with randomly sampled frequencies, while the label vector encoded from which frequency ranges (frequency bins) the frequencies were sampled. Since we wanted to test our method in the context of sleep staging, we followed the American Academy of Sleep Medicine (AASM) guidelines and focused on the spectral band between 0.3‚Äì35 Hz. This range was divided into 20 frequency bins on a base-2 logarithmic scale, resulting in a label vector   l   ‚àà { 0 ,   1 } 20  with binary entries for each bin that indicated whether frequencies in a given bin were present (1) or absent (0) in the time series.   To generate a synthetic time series, we first randomly selected a subset of the 20 frequency bins, setting the corresponding entries in the label vector   l   to 1 (each bin was selected with a probability of 50%). Next, we independently 9\n\nsampled frequencies from the selected bins for each channel and generated sine waves with these frequencies. The sine waves were then shifted by a random phase sampled from a uniform distribution between 0 and 2 œÄ , summed, and normalized to create the synthetic signal. Therefore, one channel   s c ( t ) of a synthetic signal   s ( t ) = ( s 1 ( t ) , s 2 ( t ) , s 3 ( t )) is defined as  s c ( t ) =  Àú s c ( t )   ‚àí   Œº c  œÉ c  ,   Àú s c ( t ) =  n f  X  i  I i   sin(2 œÄ tf c,i   +   œï i ) ,   I i   ‚àà U{ 0 ,   1 } ,   (1) where   t   denotes time (in seconds),   n f   denotes the number of frequency bins,   I i   denotes the indicator function encoding whether a frequency within a bin   i   is present (1) or not (0),   f c,i   denotes the frequencies of the sine waves (in Hertz),   œï i  denotes their phase (in radians), and   Œº c   and   œÉ c   denote mean and standard deviation of Àú s c .   Note that the phases   œï i   were sampled for each frequency bin independently but remained the same across channels to keep the data generation process simple, while the frequencies   f c,i   were sampled independently for each bin and channel. For each training run, we generated 101,000 synthetic samples, using 100,000 samples for training and the remaining 1000 samples as a validation set to track various metrics. The number of synthetic samples, frequency bins, and the logarithmic scale that defines the boundaries between the bins were determined through preliminary experiments where we explored a wide range of hyperparameters.  4.1.2   Model  We based our model on the TinySleepNet architecture, a conceptually simple deep neural network for sleep staging that has previously demonstrated competitive results [41]. This architecture consists of a convolutional feature extractor that extracts features from individual sleep epochs and a classifier that aggregates these feature across multiple epochs to perform sleep staging.   The feature extractor consisted of four convolutional layers with 128 filters each, a kernel size of 50, 8, 8, and 8, respectively, and a stride of 25, 1, 1, and 1, respectively. Following each convolutional layer was a batch normalization layer and a ReLU activation function. The outputs of the first and last convolutional layer were passed through max pooling layers that reduced the temporal dimension of the feature maps by a factor of 8 and 4, respectively. After both max pooling layers, we applied dropout with a dropout rate of 0.5. The feature extractor was followed by a classifier, which consisted of a dense layer with 80 neurons and ReLU activation function as well as a dense layer with 20 neurons and sigmoid activation function (i.e., one output for each frequency bin). We defined a threshold of 0.5 to determine whether a frequency from a frequency bin was present in the signal (output greater than 0.5) or not (output less than or equal to 0.5).  4.1.3   Pretraining for Frequency Prediction  We pretrained models for 20 training epochs using the Adam optimizer [29], a fixed learning rate of 10 ‚àí 4 , a batch size of 64, and a binary cross-entropy loss. This loss function is commonly employed for multi-label classification problems with one-hot encoded labels. It is defined as  L bce   =   ‚àí   1  N  1  n f N X  i =1  n f  X  j =1  y i,j   ¬∑   log(ÀÜ y i,j   ) + (1   ‚àí   y i,j   )   ¬∑   log(1   ‚àí   ÀÜ y i,j   ) ,   (2) where   N   is the number of samples,   n f   is the number of frequency bins,   y i,j   is the true one-hot encoded label of sample   i   and frequency bin   j , and ÀÜ y i,j   is the predicted one-hot encoded label of sample   i   and frequency bin   j . In addition to the loss function, we recorded the hamming metric on the training and validation data after each training epoch. This metric is derived from the hamming loss, a common metric for multi-label classification problems [40]. Specifically, the hamming metric tracks the fraction of correctly predicted frequency bins and is defined as  H   =   1  N  1  n f N X  i =1  n f  X  j =1  I { y i,j   =ÀÜ y i,j   } ,   (3) where   I   is the indicator function, which assumes the value 1 if the true one-hot encoded label   y i,j   of sample   i   and frequency bin   j   is equal to the predicted one-hot encoded label ÀÜ y i,j   of sample   i   and frequency bin   j .  4.2   Phase 2: Fine-Tuning with Sleep Staging Data  In the fine-tuning phase, we used the pretrained feature extractor of the pretraining phase for sleep stage classification on EEG and EOG data. Sleep stage classification is a multi-class classification problem where a short segment of EEG and EOG data (sleep epoch) is assigned to one of five sleep stages (Wake, N1, N2, N3, REM) based on the underlying brain activity. In our approach, the feature extractor of our model produced features from individual sleep epochs of EEG and EOG data. The extracted features were then concatenated over a sequence of multiple epochs and aggregated by a classifier to predict the sleep stage of the middle epoch in the input sequence (see Figure 1). By incorporating the surrounding sleep epochs into the classifier‚Äôs input, we provided additional temporal context, potentially enhancing the accuracy of sleep stage prediction. 10\n\n4.2.1   Sleep Staging Data  To test our approach, we used four publicly available datasets encompassing a diverse range of subjects, including both healthy individuals and those with various medical conditions such as sleep apnea, REM sleep behavior disorder, and affective disorders:   DODO [21], DODH [21], Sleep-EDFx [27, 34], and ISRUC [28].   The DODO and DODH datasets contain 55 recordings from subjects diagnosed with obstructive sleep apnea (OSA) and 25 recordings from healthy subjects, respectively. We combined the two datasets into a single dataset with 80 recordings, which we refer to as DODO/H. Each recording stems from a different subject and was split into 30-s non-overlapping windows (sleep epochs), which were annotated with sleep stages (Wake, N1, N2, N3, REM) by five sleep experts following the AASM guidelines [5]. We aggregated these five expert annotations into a consensus label for each sleep epoch using majority voting, with ties resolved by selecting the sleep stage determined by the most reliable scorer (defined as the scorer with the highest average agreement with all other scorers) [21]. Epochs that the consensus of the sleep experts annotated as artifacts were removed from the datasets. In our experiments, we focused on three EEG and EOG derivations available in both datasets and recommended by the AASM guidelines [5]: C3-M2, F3-M2, EOG1. All channels were sampled at 250 Hz. The   Sleep-EDFx   dataset   is   provided   on   the   PhysioNet   platform   [17]   and   contains 197 recordings from two studies [27, 34], of which we used the 153 recordings of the ‚ÄúSleep Cassette‚Äù study [34].   The recordings stem from 78 healthy subjects with two recordings per subject, except for subjects 13, 36, and 52, who have only one recording each due to technical issues. The recordings were split into 30-s sleep epochs and annotated with sleep stages (Wake, N1, N2, N3, N4, REM) according to the 1968 Rechtschaffen and Kales manual [38] by a single expert per recording. To be consistent with the annotations of the other datasets, we combined the N3 and N4 stages into a single N3 stage and removed data annotated as artifacts or movement.   Furthermore, we removed excess daytime data from the recordings by cropping them to begin 30 min before the first annotated non-Wake stage and end 30 min after the last annotated non-Wake stage. All available EEG and EOG channels (Fpz-Cz, Pz-Oz, EOG horizontal) were sampled at 100 Hz. The ISRUC dataset [28] contains 126 recordings and is divided into three subgroups. Subgroup one contains 100 recordings from 100 subjects suffering from various disorders affecting sleep (including OSA, REM disorder, affective disorder, snoring), subgroup two contains 16 recordings from 8 subjects diagnosed with OSA and snoring (2 recordings per subject), and subgroup three contains 10 recordings from 10 healthy subjects.   Due to technical issues, we excluded two recordings (recordings 8 and 100) from the first subgroup. All recordings were split into 30-s sleep epochs and annotated with sleep stages by two experts following the AASM guidelines [5]. We only used the annotations of the first expert and focused on the EEG and EOG channels C3-A2, F3-A2, and LOC-A2 sampled at 200 Hz. To prepare the data for training, we filtered the signals between 0.3 and 35 Hz with an 8th-order zero-phase Butterworth filter and downsampled the filtered signals to 100 Hz using polyphase filtering if necessary. We then normalized the amplitudes of each individual sleep epoch by subtracting the median and dividing the result by the interquartile range of its amplitude distribution. Finally, we clipped all signal amplitudes above 20 or below   ‚àí 20 to minimize outliers. After preprocessing, the three datasets (DODO/H, Sleep-EDFx, ISRUC) were split subject-wise into five folds for cross- validation. Note that we created a separate cross-validation split for each dataset, resulting in three different 5-fold cross- validation configurations. When splitting the DODO/H and the ISRUC datasets, we ensured that the recordings within each split were balanced in regard to the sub-datasets or subgroups. In addition to splitting the data into training and test folds, we reserved approximately 10% of the data from each fold as validation data for hyperparameter tuning and early stopping (i.e., one recording of DODO and DODH each, two subjects of Sleep-EDFx, and two recordings from the first subgroup of ISRUC for each fold). We validated our models on the validation data of the four training folds. The validation data of the test fold was kept separate and not involved in validation or testing to prevent data leakage.  4.2.2   Model  Since the sleep epochs used for fine-tuning had the same format as the synthetic data generated for pretraining (i.e., 3 channels with 30 s of data sampled at 100 Hz), we kept the architecture of the feature extractor unchanged. However, we replaced the classifier with a different architecture to predict sleep stages instead of frequency bins. The classifier was inspired by the TinySleepNet architecture [41] and consisted of a bidirectional Long-Short Term Memory (LSTM) [25] layer with a hidden size of 128, a dropout layer with a dropout rate of 0.5, and a dense layer with 5 neurons and softmax activation function.  4.2.3   Fine-Tuning for Sleep Stage Classification  We fine-tuned the models with training samples consisting of 11 sleep epochs that provided the classifier with context information from 5 epochs before and after the epoch to be classified.   To ensure that the model could use the same aggregation process for all sleep epochs of a recording, we padded the first and last five sequences of each recording with zeros to the full sequence length. Fine-tuning was performed using the Adam optimizer [29], a fixed learning rate of 10 ‚àí 4 , weight decay of 10 ‚àí 3 , a batch size of 32, and the categorical cross-entropy loss. To prevent overfitting, we limited each training run to a maximum of 50 training epochs and stopped training early if the macro F1 score on the validation data did not improve for 10 training epochs (early stopping).   Additionally, we clipped all gradients with a maximum norm greater than 5.0 to prevent exploding gradients. 11\n\nWe tracked model performance by recording the macro F1 score on the training and validation data after each training epoch. The macro F1 score is calculated as the average F1 score [42] across all sleep stages and is defined as  F 1   =  1  k  k X  i =1  2   ¬∑   p i   ¬∑   r i  p i   +   r i  ,   (4) where   k   is the number of sleep stages,   p i   is the precision of sleep stage   i , and   r i   is the recall of sleep stage   i . In all four training configurations (Fully Supervised, Fixed Feature Extractor, Fine-Tuned Feature Extractor, and Un- trained Feature Extractor), we performed training using the cross-validation scheme described in Section 4.2.1.   A single training run in this cross-validation scheme included both pretraining and fine-tuning where applicable. If not specified oth- erwise, all reported results were obtained on the test folds of the cross-validation splits, while the small part of the training data reserved for validation was used as early stopping set during fine-tuning. To ensure comparability between different training and data configurations, we seeded the model initialization, the synthetic data generation during pretraining, and the data subsampling when fine-tuning with a limited amount of training data.   This strategy reduced the influence of random initialization and data sampling on comparisons between training configurations. In particular, seeding ensured that models were fine-tuned with the same data across all training configurations in the few-sample and few-subject regimes.   Furthermore, when training with a reduced amount of data, we maintained a constant number of gradient updates per training epoch by duplicating each training sample   ‚åä   N N red   ‚åã   times, where   N   is the number of samples in the full training data and   N red   is the number of samples after reduction. Experiments were performed on an NVIDIA DGX A100 workstation with eight NVIDIA A100 GPUs and a Dell work- station with a single NVIDIA RTX A6000 GPU.  Author Contributions  Conceptualization, N.G. and S.B.; methodology, N.G.; software, N.G.; validation, N.G.; formal analysis, N.G.; investigation, N.G., S.M. and S.B.; resources, S.B.; data curation, N.G.; writing‚Äîoriginal draft preparation, N.G. and S.B.; writing‚Äîreview and editing, N.G., S.M. and S.B.; visualization, N.G. and S.B.; supervision, S.M. and S.B.; project administration, N.G. and S.B. All authors have read and agreed to the published version of the manuscript.  Funding  This research received no external funding.  Data Availability  The DODO and DODH datasets analyzed in the current study are described in Guillot et al. [21] and are publicly available (see   https://github.com/Dreem-Organization/dreem-learning-open   (accessed on 30 March 2023) for how to access the datasets). The Sleep-EDFx dataset is described in Kemp et al. [27] and Mourtazaev et al. [34] and is publicly available at  https://physionet.org/content/sleep-edfx/1.0.0/   (accessed on 30 March 2023). The ISRUC dataset is described in Khalighi et al. [28] and is publicly available at   https://sleeptight.isr.uc.pt/ (accessed on 13 April 2023). The source code necessary to reproduce our results is available on GitHub at   https://github.com/dslaborg/frequency-pretraining/ tree/full-paper-version   (accessed on 29 August 2025).  Acknowledgments  We are grateful to M. Rei√üel and V. Sander for providing us with computing resources.  Conflicts of Interest  The authors declare no conflicts of interest.  References  [1] D. Alvarez-Estevez. Challenges of applying automated polysomnography scoring at scale.   Sleep Med. Clin. , 18(3):277‚Äì 292, Sept. 2023. 12\n\n[2] H. Banville, O. Chehab, A. Hyv¬® arinen, D.-A. Engemann, and A. Gramfort. Uncovering the structure of clinical EEG signals with self-supervised learning.   J. Neural Eng. , 18:046020, Mar. 2021. [3] M. Baradad, J. Wulff, T. Wang, P. Isola, and A. Torralba.   Learning to see by looking at noise.   In M. Ranzato, A. Beygelzimer, Y. N. Dauphin, P. Liang, and J. W. Vaughan, editors,   Annu. Conf. on Neural Information Processing Systems, NeurIPS, Virtual, 6‚Äì14 December , pages 2556‚Äì2569, Red Hook, NY, USA, Dec. 2021. Curran Associates Inc. [4] A. Bardes, J. Ponce, and Y. LeCun. VICReg: Variance-invariance-covariance regularization for self-supervised learning. In   The Tenth Int. Conf. on Learning Representations, ICLR, Virtual, 25‚Äì29 April . OpenReview.net, 2022. [5] R. B. Berry, R. Brooks, C. E. Gamaldo, S. M. Harding, R. M. Lloyd, C. L. Marcus, and B. V. Vaughn.   The AASM manual for the scoring of sleep and associated events:   Rules, terminology and technical specifications, Version 2.6 . American Academy of Sleep Medicine, Darien, Illinois, 2020. [6] G. Brandmayr, M. M. Hartmann, F. F¬® urbass, G. Matz, M. Samwald, T. Kluge, and G. Dorffner.   Relational local electroencephalography representations for sleep scoring.   Neural Networks , 154:310‚Äì322, 2022. [7] M. M. Bronstein, J. Bruna, T. Cohen, and P. Velickovic.   Geometric deep learning: Grids, groups, graphs, geodesics, and gauges.   CoRR , abs/2104.13478, 2021. [8] F. P. Carrle, Y. Hollenbenders, and A. Reichenbach. Generation of synthetic EEG data for training algorithms supporting the diagnosis of major depressive disorder.   Front. Neurosci. , 17:1219133, 2023. [9] T. Chen, S. Kornblith, M. Norouzi, and G. E. Hinton. A simple framework for contrastive learning of visual represen- tations. In   Proc. 37th Int. Conf. on Machine Learning, ICML 2020, Virtual, 13‚Äì18 July , volume 119 of   Proceedings of Machine Learning Research , pages 1597‚Äì1607. PMLR, 2020. [10] M. J. V. D. Donckt, J. V. D. Donckt, E. Deprost, N. Vandenbussche, M. Rademaker, G. Vandewiele, and S. V. Hoecke. Do not sleep on traditional machine learning: Simple and interpretable techniques are competitive to deep learning for sleep scoring.   Biomed. Signal Process. Control. , 81:104429, 2023. [11] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly, J. Uszkoreit, and N. Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. In  Int. Conf. on Learning Representations, ICLR, Vienna, Austria, 3‚Äì7 May , 2021. [12] A. Ebbehoj, M. √ò. Thunbo, O. E. Andersen, M. V. Glindtvad, and A. Hulman. Transfer learning for non-image data in clinical research: A scoping review.   PLOS Digital Health , 1(2):e0000014, Feb. 2022. [13] E. Eldele, M. Ragab, Z. Chen, M. Wu, C.-K. Kwoh, and X. Li. Self-supervised learning for label-efficient sleep stage classification: A comprehensive evaluation.   IEEE T. Neur. Sys. Reh. , 31:1333‚Äì1342, 2023. [14] L. Fiorillo, G. Monachino, J. van der Meer, M. Pesce, J. D. Warncke, M. H. Schmidt, C. L. A. Bassetti, A. Tzovara, P. Favaro, and F. D. Faraci. U-Sleep‚Äôs resilience to AASM guidelines.   npj Digit. Medicine , 6:33, 2023. [15] L. Fiorillo, A. Puiatti, M. Papandrea, P.-L. Ratti, P. Favaro, C. Roth, P. Bargiotas, C. L. Bassetti, and F. D. Faraci. Automated sleep scoring: A review of the latest approaches.   Sleep Med. Rev. , 48:101204, 2019. [16] M. Gaiduk, A. Serrano Alarc¬¥ on, R. Seepold, and N. Mart¬¥ ƒ±nez Madrid. Current status and prospects of automatic sleep stages scoring: Review.   Biomed. Eng. Lett. , 13(3):247‚Äì272, July 2023. [17] A. L. Goldberger, L. A. N. Amaral, L. Glass, J. M. Hausdorff, P. C. Ivanov, R. G. Mark, J. E. Mietus, G. B. Moody, C.-K. Peng, and H. E. Stanley. PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals.   Circulation , 101(23), June 2000. [18] I. J. Goodfellow, Y. Bengio, and A. C. Courville.   Deep Learning . Adaptive computation and machine learning. MIT Press, Cambridge, Massachusetts, 2016. [19] N. Grieger. Source code of the model presented in Grieger et al., ‚ÄúData-efficient sleep staging with synthetic time series pretraining‚Äù.   https://github.com/dslaborg/frequency-pretraining , 2024. [20] N. Grieger, S. Mehrkanoon, and S. Bialonski. Pretraining sleep staging models without patient data. In   Int. Conf. on Learning Representations (ICLR), Workshop on Learning from Time Series For Health, Vienna, Austria, 7‚Äì11 May , Vienna, Austria, 2024. [21] A. Guillot, F. Sauvet, E. H. During, and V. Thorey.   Dreem open datasets:   Multi-scored sleep datasets to compare human and automated sleep staging.   IEEE T. Neur. Sys. Reh. , 28(9):1955‚Äì1965, Sept. 2020. 13\n\n[22] A. G. Habashi, A. M. Azab, S. Eldawlatly, and G. M. Aly.   Generative adversarial networks in EEG analysis:   An overview.   J. NeuroEng. Rehabil. , 20(1):40, Apr. 2023. [23] C. He, J. Liu, Y. Zhu, and W. Du. Data augmentation for deep neural networks model in EEG classification task: A review.   Front. Hum. Neurosci. , 15:765525, Dec. 2021. [24] K. He, X. Zhang, S. Ren, and J. Sun. Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification. In   2015 IEEE Int. Conf. on Computer Vision, ICCV 2015, 7‚Äì13 December , pages 1026‚Äì1034, Santiago, Chile, Dec. 2015. IEEE Computer Society. [25] S. Hochreiter and J. Schmidhuber. Long short-term memory.   Neural Comput. , 9:1735‚Äì1780, Nov. 1997. [26] H. Kataoka, K. Okayasu, A. Matsumoto, E. Yamagata, R. Yamada, N. Inoue, A. Nakamura, and Y. Satoh. Pre-training without natural images.   Int. J. Comput. Vis. , 130(4):990‚Äì1007, 2022. [27] B. Kemp, A. H. Zwinderman, B. Tuk, H. A. C. Kamphuisen, and J. J. L. Oberye. Analysis of a sleep-dependent neuronal feedback loop: The slow-wave microcontinuity of the EEG.   IEEE Trans. Biomed. Eng. , 47(9):1185‚Äì1194, 2000. [28] S. Khalighi, T. Sousa, J. M. dos Santos, and U. Nunes.   ISRUC-Sleep:   A comprehensive public dataset for sleep researchers.   Comput. Methods Programs Biomed. , 124:180‚Äì192, 2016. [29] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. In Y. Bengio and Y. LeCun, editors,   3rd Int. Conf. Learning Representations, ICLR , San Diego, CA, USA, May 2015. [30] W. Ko, E. Jeon, S. Jeong, J. Phyo, and H.-I. Suk. A survey on deep learning-based short/zero-calibration approaches for EEG-based brain-computer interfaces.   Front. Hum. Neurosci. , 15:643386, May 2021. [31] E. Lashgari, D. Liang, and U. Maoz. Data augmentation for deep-learning-based electroencephalography.   J. Neurosci. Meth. , 346:108885, Dec. 2020. [32] Z. Liu, A. Alavi, M. Li, and X. Zhang. Self-supervised contrastive learning for medical time series: A systematic review.  Sensors , 23(9):4221, 2023. [33] S. Motamedi-Fakhr, M. Moshrefi-Torbati, M. Hill, C. M. Hill, and P. R. White. Signal processing techniques applied to human sleep EEG signals ‚Äî A review.   Biomed. Signal Process. Control. , 10:21‚Äì33, 2014. [34] M. S. Mourtazaev, B. Kemp, A. H. Zwinderman, and H. A. C. Kamphuisen. Age and gender affect different characteristics of slow waves in the sleep EEG.   Sleep , 18(7):557‚Äì564, Sept. 1995. [35] I. Obeid and J. Picone. The Temple University hospital EEG data corpus.   Front. Neurosci. , 10:196, May 2016. [36] H. Phan and K. Mikkelsen.   Automatic sleep staging of EEG signals:   Recent development, challenges, and future directions.   Physiol. Meas. , 43(4):04TR01, Apr. 2022. [37] Y. Qiu, F. Lin, W. Chen, and M. Xu. Pre-training in medical data: A survey.   Mach. Intell. Res. , 20(2):147‚Äì179, Feb. 2023. [38] A. Rechtschaffen, A. Kales, R. Berger, W. Dement, A. Jacobson, L. Johnson, M. Jouvet, L. Monroe, I. Oswald, H. Rof- fwarg, B. Roth, and R. Walter.   A Manual of Standardized Terminology, Techniques and Scoring System for Sleep Stages of Human Subjects . Public Health Service, U.S. Government Printing Office, Washington, D.C., 1968. [39] Y. Roy, H. Banville, I. Albuquerque, A. Gramfort, T. H. Falk, and J. Faubert. Deep learning-based electroencephalog- raphy analysis: A systematic review.   J. Neural Eng. , 16:051001, 2019. [40] M. Sokolova and G. Lapalme.   A systematic analysis of performance measures for classification tasks.   Inf. Process. Manag. , 45(4):427‚Äì437, 2009. [41] A. Supratak and Y. Guo. TinySleepNet: An efficient deep learning model for sleep stage scoring based on raw single- channel EEG. In   42nd Annual Int. Conf. of the IEEE Engineering in Medicine & Biology Society, EMBC 2020 , pages 641‚Äì644, Montreal, QC, Canada, July 2020. IEEE. [42] A. Tharwat. Classification assessment methods.   Appl. Comput. Inform. , 17(1):168‚Äì192, 2021. [43] R. Vallat and M. P. Walker. An open-source, high-performance tool for automated sleep staging.   eLife , 10:e70092, Oct. 2021. [44] H. van Dijk, G. van Wingen, D. Denys, S. Olbrich, R. van Ruth, and M. Arns. The two decades brainclinics research archive for insights in neurophysiology (TDBRAIN) database.   Sci. Data , 9(1):333, June 2022. 14\n\n[45] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin. Attention is all you need. In I. Guyon, U. von Luxburg, S. Bengio, H. M. Wallach, R. Fergus, S. V. N. Vishwanathan, and R. Garnett, editors,   Annu. Conf. Neural Information Processing Systems, NeurIPS, 4‚Äì9 December , pages 5998‚Äì6008, Red Hook, NY, USA, 2017. Curran Associates Inc. [46] Z. You, Y. Guo, X. Zhang, and Y. Zhao. Virtual electroencephalogram acquisition: A review on electroencephalogram generative methods.   Sensors , 25(10):3178, May 2025. [47] G.-Q. Zhang, L. Cui, R. Mueller, S. Tao, M. Kim, M. Rueschman, S. Mariani, D. Mobley, and S. Redline. The national sleep research resource: Towards a sleep data commons.   J. Am. Med. Inform. Assn. , 25(10):1351‚Äì1358, May 2018. 15",
      "embedding": [
        -0.04741168022155762,
        -0.006064461078494787,
        0.09689256548881531,
        0.05343573912978172,
        0.04889686033129692,
        0.03586107864975929,
        -0.027413658797740936,
        -0.052034299820661545,
        0.03909469023346901,
        -0.09104318916797638,
        -0.10623456537723541,
        -0.15059074759483337,
        -0.059587348252534866,
        0.04152799770236015,
        -0.06317277252674103,
        -0.07187166064977646,
        0.0614713616669178,
        0.01292039267718792,
        -0.08712895959615707,
        0.032855723053216934,
        0.09173116832971573,
        -0.01206666324287653,
        0.06042657047510147,
        0.026146359741687775,
        0.014771224930882454,
        -0.005150902085006237,
        0.04242788255214691,
        -0.04299803450703621,
        -0.050653886049985886,
        -0.014102029614150524,
        0.041070833802223206,
        0.03326332941651344,
        -0.013394095934927464,
        0.06870938837528229,
        -0.08990778774023056,
        -0.002046865876764059,
        0.010353140532970428,
        0.013633946888148785,
        -0.014176031574606895,
        0.032497018575668335,
        0.03517807647585869,
        0.009659306146204472,
        0.006034846883267164,
        0.024449244141578674,
        0.08641844987869263,
        0.06296838074922562,
        0.018987620249390602,
        -0.12876056134700775,
        -0.04860389977693558,
        0.06405746936798096,
        -0.030129611492156982,
        0.017919057980179787,
        -0.0029393855948001146,
        0.0856664851307869,
        0.022274814546108246,
        0.052394479513168335,
        0.01652177982032299,
        0.004680422134697437,
        -0.0011855385964736342,
        0.030504556372761726,
        -0.02788832038640976,
        -0.04507739841938019,
        0.01433019619435072,
        -0.07023230940103531,
        0.007486550137400627,
        0.039240095764398575,
        0.006031768396496773,
        0.02216479927301407,
        0.00474160723388195,
        -0.023482980206608772,
        -0.06291976571083069,
        0.06148342043161392,
        -0.0388876348733902,
        0.006575223058462143,
        0.003790618386119604,
        0.07481104880571365,
        0.059262339025735855,
        -0.010867295786738396,
        0.08633076399564743,
        -0.12083284556865692,
        0.023899134248495102,
        0.011211912147700787,
        0.01348968781530857,
        -0.013311239890754223,
        0.11399125307798386,
        0.014657032676041126,
        0.04595157876610756,
        0.07599736750125885,
        -0.061299629509449005,
        -0.018057867884635925,
        -0.015832653269171715,
        -0.013403009623289108,
        -0.011540419422090054,
        -0.006799494847655296,
        0.05982177332043648,
        0.10410761088132858,
        -0.021629957482218742,
        -0.02656792849302292,
        0.0983446016907692,
        0.013889116235077381,
        -0.004522813484072685,
        0.0230704378336668,
        0.015258433297276497,
        0.04058406129479408,
        -0.026783546432852745,
        -0.013395054265856743,
        0.09775154292583466,
        -0.017623459920287132,
        0.020329661667346954,
        -0.04413970932364464,
        0.0457942858338356,
        0.046109285205602646,
        0.011507727205753326,
        -0.005534730385988951,
        0.0852876752614975,
        0.02782309055328369,
        -0.03862401098012924,
        0.06526771187782288,
        0.07846266031265259,
        0.0893356204032898,
        0.00025740842102095485,
        -0.023129902780056,
        0.02909744158387184,
        -0.06105960160493851,
        0.007353024557232857,
        0.014148056507110596,
        -0.09704422950744629,
        6.313173143347534e-33,
        0.02497982047498226,
        -0.048504408448934555,
        0.023131737485527992,
        -0.00822510663419962,
        -0.0021588080562651157,
        -0.06743089109659195,
        -0.0796496793627739,
        0.07764644175767899,
        0.02495620958507061,
        0.06584979593753815,
        -0.06618688255548477,
        0.03681906312704086,
        -0.06347950547933578,
        0.0360150970518589,
        0.01795961707830429,
        0.005150496028363705,
        -0.05329723656177521,
        0.042084310203790665,
        0.0030315981712192297,
        -0.04678436368703842,
        0.07423488795757294,
        -0.06556961685419083,
        0.0003480458108242601,
        -0.043792638927698135,
        0.030851110816001892,
        0.02079101838171482,
        0.016360711306333542,
        0.007260380312800407,
        -0.013445105403661728,
        0.008387679234147072,
        -0.12509611248970032,
        0.04793452098965645,
        0.012565961107611656,
        -0.02491566352546215,
        0.048041895031929016,
        -0.022510381415486336,
        0.04344018176198006,
        0.05773979425430298,
        0.032250892370939255,
        0.009761949069797993,
        -0.00045017979573458433,
        0.02455848827958107,
        0.0023445116821676493,
        -0.04693462327122688,
        -0.05017438530921936,
        -0.055685609579086304,
        0.04105186089873314,
        0.020723968744277954,
        0.046277567744255066,
        -0.05281933397054672,
        -0.035862281918525696,
        -0.064116470515728,
        -0.01614672690629959,
        -0.13567672669887543,
        -0.02172650583088398,
        0.0442672036588192,
        0.03743765503168106,
        0.015331579372286797,
        0.011012891307473183,
        0.11222188919782639,
        -0.026393556967377663,
        0.0666179209947586,
        -0.005098144523799419,
        0.031602416187524796,
        -0.011320576071739197,
        -0.001265015103854239,
        -0.019236696884036064,
        0.09644866734743118,
        0.031275518238544464,
        -0.03329011797904968,
        0.01082032360136509,
        0.03272177651524544,
        0.02925536222755909,
        -0.0691031813621521,
        0.05712321773171425,
        0.0027459124103188515,
        0.06326328963041306,
        0.0353667251765728,
        -0.09287578612565994,
        0.03171306475996971,
        0.05864807218313217,
        0.022471919655799866,
        -0.059971850365400314,
        -0.060012754052877426,
        -0.02056720107793808,
        -0.04804793372750282,
        0.036992114037275314,
        -0.028489630669355392,
        -0.09777089208364487,
        -0.03706065192818642,
        -0.044155895709991455,
        -0.033147409558296204,
        0.00907342042773962,
        0.010318676009774208,
        -0.07958175987005234,
        -5.3567453891124265e-33,
        0.008767728693783283,
        0.002435152418911457,
        -0.07491552084684372,
        0.0023549648467451334,
        0.07894273847341537,
        0.0014608193887397647,
        0.033658869564533234,
        -0.0015887839253991842,
        -0.004265032708644867,
        -0.04017576947808266,
        0.019507190212607384,
        -0.09463442116975784,
        0.0628441795706749,
        -0.035989850759506226,
        -0.001573651097714901,
        -0.033506494015455246,
        -0.08636676520109177,
        -0.00490975147113204,
        -0.04067157208919525,
        0.05711757764220238,
        -0.026321079581975937,
        0.07406526058912277,
        -0.10968288779258728,
        -0.04143477603793144,
        -0.05858134478330612,
        0.012739477679133415,
        0.01366475410759449,
        0.1331167221069336,
        -0.012431522831320763,
        -0.02927647903561592,
        -0.05693909898400307,
        -0.08528953790664673,
        -0.11674129217863083,
        -0.04308635741472244,
        -0.022913966327905655,
        0.05675862729549408,
        0.07657765597105026,
        -0.05916888639330864,
        -0.056187618523836136,
        -0.06000104546546936,
        0.10120730102062225,
        0.05823579430580139,
        -0.06416544318199158,
        -0.025707516819238663,
        0.004614016506820917,
        0.013609221205115318,
        -0.061773911118507385,
        0.01201967615634203,
        0.01856987178325653,
        0.052554886788129807,
        0.029574409127235413,
        -0.024946117773652077,
        -0.09480717778205872,
        -0.054644957184791565,
        -0.05653277784585953,
        -0.051941707730293274,
        -0.014660650864243507,
        -0.013927571475505829,
        0.04365133121609688,
        0.04090170934796333,
        -0.09217467159032822,
        -0.060365792363882065,
        -0.008898982778191566,
        -0.04036099463701248,
        0.009034119546413422,
        0.013024172745645046,
        -0.010489953681826591,
        -0.01189843937754631,
        0.06097177788615227,
        0.02916613221168518,
        -0.014644765295088291,
        -0.026003655046224594,
        0.030506987124681473,
        0.03985123336315155,
        -0.010836598463356495,
        -0.03272147476673126,
        0.022841323167085648,
        -0.04314592108130455,
        -0.03878984600305557,
        -0.042055461555719376,
        0.07194291055202484,
        -0.11104682087898254,
        -0.06793206930160522,
        0.08069445937871933,
        0.015927420929074287,
        0.08235973864793777,
        0.03724714741110802,
        0.043450817465782166,
        0.10396822541952133,
        -0.05126136541366577,
        -0.06733202189207077,
        -0.006406922359019518,
        -0.12649919092655182,
        0.037219393998384476,
        -0.014134546741843224,
        -5.43648255302287e-8,
        -0.038154441863298416,
        0.02688412554562092,
        0.06659034639596939,
        0.02206563763320446,
        0.02073424682021141,
        -0.10749125480651855,
        0.0471305176615715,
        0.03855712711811066,
        -0.02235051430761814,
        0.02203294448554516,
        0.1562231481075287,
        -0.009207326918840408,
        -0.006244373042136431,
        -0.05851190909743309,
        -0.01769028790295124,
        0.051741451025009155,
        0.013748087920248508,
        0.06375587731599808,
        0.013324975036084652,
        -0.03807293623685837,
        0.02120268903672695,
        0.02078315243124962,
        0.02659108303487301,
        -0.0805724710226059,
        0.1254282146692276,
        -0.04363920912146568,
        -0.0433526411652565,
        0.07078969478607178,
        -0.01705595664680004,
        -0.03326161950826645,
        0.022138752043247223,
        -0.024171054363250732,
        0.016622625291347504,
        -0.013225353322923183,
        -0.018323255702853203,
        -0.005085587501525879,
        0.0007453181897290051,
        0.01090243924409151,
        -0.02023841254413128,
        0.035615142434835434,
        -0.030239326879382133,
        0.04391953721642494,
        -0.054465461522340775,
        -0.019558027386665344,
        -0.002735982183367014,
        -0.07416251301765442,
        -0.006997328717261553,
        -0.019540637731552124,
        0.07781982421875,
        0.007348637096583843,
        -0.00027920660795643926,
        -0.0560702420771122,
        0.06587009876966476,
        0.05436620116233826,
        0.07464998215436935,
        0.06403838098049164,
        0.01300109177827835,
        -0.03161328285932541,
        0.015253853052854538,
        0.03751020133495331,
        0.052419260144233704,
        0.03622864559292793,
        -0.07741686701774597,
        -0.0052313432097435
      ],
      "metadata": {
        "title": "Paper_17_Data_Efficient_Sleep_Staging_with_Synthetic_Time_S.pdf",
        "createdAt": "2025-12-17T13:56:36.376Z"
      },
      "fileObj": {}
    },
    {
      "id": "doc_10_1765979797262",
      "fileName": "Paper_1_Sleep_Staging_from_Electrocardiography_and_Respira.pdf",
      "content": "Sleep Staging from Electrocardiography and Respiration with Deep Learning  Haoqi Sun, PhD 1 , Wolfgang Ganglberger, MSc 1 , Ezhil Panneerselvam, MD 1 , Michael J. Leone, MSc 1 , Syed A. Quadri, MD 1 , Balaji Goparaju, MSc 1 , Ryan A. Tesh, BS 1 , Oluwaseun Akeju, MD 2 , Robert J. Thomas, MD 3 , M. Brandon Westover, MD, PhD 1  1   Department of Neurology, Massachusetts General Hospital, Boston, MA, USA  2   Department of Anesthesia, Critical Care and Pain Medicine, Massachusetts General Hospital, Boston, MA, USA  3   Division of Pulmonary, Critical Care & Sleep, Department of Medicine, Beth Israel Deaconess Medical Center, Boston, MA, USA  Abstract  Study Objective : Sleep is reflected not only in the electroencephalogram but also in heart rhythms and breathing patterns. Therefore, we hypothesize that it is possible to accurately stage sleep based on the electrocardiogram (ECG) and respiratory signals.  Methods : Using a dataset including 8,682 polysomnographs, we develop deep neural networks to stage sleep from ECG and respiratory signals. Five deep neural networks consisting of convolutional networks and long short-term memory networks are trained to stage sleep using heart and breathing, including the timing of R peaks from ECG, abdominal and chest respiratory effort, and the combinations of these signals.  Results : ECG in combination with the abdominal respiratory effort achieve the best performance for  staging all five sleep stages with a Cohen‚Äôs kappa of 0.600   (95% confidence interval 0.599   ‚Äì   0.602); and 0.762 (0.760   ‚Äì   0.763) for discriminating awake vs. rapid eye movement vs. non-rapid eye movement sleep. The performance is better for young participants and for those with a low apnea-hypopnea index, while it is robust for commonly used outpatient medications.  Conclusions : Our results validate that ECG and respiratory effort provide substantial information about sleep stages in a large population. It opens new possibilities in sleep research and applications where electroencephalography is not readily available or may be infeasible, such as in critically ill patients.  Keywords  Deep Learning; Electrocardiography; Respiration; Sleep Stages\n\n1  Introduction  Characterizing   sleep   has   primarily   relied   on   the   analysis   of   the   electroencephalogram   (EEG), supplemented by the electrooculogram and chin electromyogram   1 . Three distinct states are readily discernable through such analysis: wake, rapid eye movement sleep (REM) and non-REM sleep (NREM)  1 . Three stages of progressive depth (N1, N2, and N3) can be differentiated in NREM   1 . EEG slow-wave oscillations (about 1   ‚Äì   4Hz) dominate deeper NREM sleep, while sleep spindles (about 10   ‚Äì   13 Hz) and theta wave oscillations (about 4   ‚Äì   8Hz) dominate lighter NREM sleep   1 .  Cortical, subcortical, and brainstem systems are highly interactive throughout sleep   2-6 , and their activity couples autonomic activity with the cortical activity measurable by EEG. Examples include strong sinus arrhythmia   3 , blood pressure dipping   7 , and stable breathing or stable flow-limitation   8 . REM sleep is characterized by highly recognizable respiratory rate and tidal volume fluctuations, and by surges in heart rate and blood pressure   9 . Wake demonstrates dominance of low-frequency heart rate variability and large amplitude movements. These observations suggest that accurate sleep staging might be possible from non-EEG signals influenced by the autonomic nervous system, such as the ECG or respiratory signals.  An accurate non-EEG method for staging state characterization would have several advantages. For example,   the   ECG   is   recorded   continuously   in   numerous   medical   and   situations,   especially   in hospitalized patients. Wearable devices increasingly measure ECG and respiration   10-12 . Cardiorespiratory signals may be obtainable in a number of ways, including contact recordings such as Withings, ballistocardiogram   13 , or non-contact radar-type applications such as EarlySense   14 , and SleepScore   15 , etc. On the other hand, EEG can be highly abnormal in medically ill populations, making standard analysis difficult   16 .  Deep learning approaches can be used to accurately estimate sleep states. We previously showed that deep neural networks can learn to score conventional sleep stages based on EEG signals obtained during overnight PSG with an accuracy of 87.5 % and a Cohen‚Äôs kappa of 0.805 , comparable to the performance of human sleep scoring experts   17 . Here we develop deep neural networks using ECG and/or respiratory signals to classify sleep stages. Our approach is based on convolutional neural network (CNN) in combination with long-short term memory (LSTM) recurrent neural network. It is trained on a large clinical dataset, which also accounts for patient heterogeneity, spanning a wide range of ages, medications and sleep disorders.  Methods  Dataset  The Partners Institutional Review Board approved retrospective analysis of polysomnograms (PSG), acquired in the Sleep Laboratory at Massachusetts General Hospital from 2009 to 2016, without requiring additional consent for use in this study. PSGs were recorded adhering to American Academy of Sleep Medicine (AASM) standards. Each PSG includes one ECG channel and two respiratory effort channels recorded from chest and abdomen belts. The sampling frequency is 200 Hz for all signals. The dataset contains three major types of sleep tests: diagnostic, full-night continuous positive airway\n\n2  pressure (CPAP), and split-night CPAP. PSGs were annotated in 30-second non-overlapping epochs according to AASM standards as one of the five stages: wake (W), non-REM stage 1 (N1), non-REM stage 2 (N2), non-REM stage 3 (N3), and rapid eye movement (REM). Seven sleep technicians in total annotated the dataset, with one technician per PSG.  The entire dataset includes 10,121 PSGs; 9,644 were exported successfully without time mismatch or missing sleep stage annotations. We included atrial fibrillation cases because the deep learning network is supposed to work with heterogeneous data. We excluded PSGs with fewer than 100 artifact-free 30- second epochs, resulting in 8,682 PSGs. The dataset is summarized in   Table 1 .  Table 1 . Dataset Summary.  Characteristics   Value  Number of PSGs   8,682  Number of patients   7,208  Age: year, median (IQR)   53 (41   ‚Äì   63)  Sex: number (percentage of all patients)  Female   2,997 (41.6%)  Male   4,189 (58.1%)  Unknown due to human error   22 (0.3%)  BMI: kg/m 2 , median (IQR)   31 (27   ‚Äì   36)  Type of Test: number (percentage of all patients)  Diagnostic   3,571 (49.5%)  All night CPAP   1,751 (24.3%)  PSG split night   1,798 (24.9%)  Extended EEG-sleep montage   76 (1.1%)  Bedside   9 (0.1%)  Research   3 (0.04%)  Apnea-Hypopnea Index (AHI, events / hour) : number (percentage of all patients)  Normal (AHI < 5)   2,879 (39.9%)  Mild (5 ‚â§ AHI < 15)   1,995 (27.7%)  Moderate (15 ‚â§ AHI < 30)   1,468 (20.4%)  Severe (AHI ‚â• 30)   866 (12.0%)  Respiratory Disturbance Index (RDI, events / hour)   15.0 (5.8   ‚Äì   28.4)  Periodic Limb Movement Index (PLMI, events / hour)   10.4 (3.1   ‚Äì   28.3)  Outpatient Medication Listing, by Category  Systemic   4523 (62.7%)  Hypertension   2755 (38.2%)  Sleeping   2187 (30.3%)  Antidepressant   1874 (26.0%)  Neuroactive   1365 (18.9%)  Benzodiazepine   1297 (18.0%)  Diabetic   802 (11.1%)  RLS/PLMS   688 (9.5%)  Opiate   548 (7.6%)  Z-drug   348 (4.8%)  Stimulant   310 (4.3%)\n\n3  Preprocessing  Sleep staging was done in 30-second epochs following AASM standards. However, changes in heart rhythms and respiration often occur over longer time scales. For this reason, and to provide contextual information, our deep neural networks used information extending 120 seconds on both sides of each 30-second epoch, creating a 270-second epoch (4.5min, nine 30-second epochs) centered on each 30- second epoch to be scored. The goal of the deep neural networks presented herein is to classify the sleep stage of the middle 30-second epoch using information from the 270-second epoch. This is illustrated in Figure S1 in the supplementary material.  When using ECG as the input, we identified 270-second epochs with amplitude larger than 6mV or standard deviation smaller than 5 Œº V, as they are not physiologically possible. In each 270-second epoch we extracted timings of R peaks   18   and converted the ECG to a binary sequence, where R peaks are  indicated by a ‚Äú 1 ‚Äù   and all other points   indicated by ‚Äú 0 ‚Äù . The 270-second epochs with spurious R peaks were identified using the ADARRI   19   method. 270-second epochs with less than 20 R peaks per minute were also identified, as they are not physiologically possible. About 25% of the 270-second epochs were identified as artifact. In total, there were 5,964,359 270-second epochs.  When using chest and abdominal respiratory effort as the input, 270-second epochs with amplitude larger than   6mV or standard deviation smaller than 10ŒºV were identified. Respiratory signals were  down-sampled to 10Hz. About 10% of the 270-second epochs were identified as artifact. In total, there were 6,847,246 270-second epochs for the chest signal; and 6,749,286 270-second epochs for the abdominal signal.  When using pairs of signals as the input, the 270-second epochs where any signal modality that meet the above criteria are identified as artifact. In any of above cases, the artifactual 270-second epochs were removed when training CNN, and remained when training LSTM to preserve the temporal context.  Deep Network Architecture  We trained five deep neural networks based on the following input signals and their combinations: 1) ECG; 2) CHEST (chest respiratory effort); 3) ABD (abdominal respiratory effort); 4) ECG+CHEST; and 5) ECG+ABD. Each deep neural network contained a feed-forward convolutional neural network (CNN) which learned features pertaining to each epoch, and a recurrent neural network (RNN), in this case long-short term memory (LSTM), to learn temporal patterns among consecutive epochs.  The CNN of the network is similar to that in Hannun et al.   20 . As shown in   Figure 1 A and   Figure 1 B, the network for a single type of input signal, i.e. ECG, CHEST or ABD, consists of a convolutional layer, several residual blocks and a final output block. For a network with both ECG and CHEST/ABD as input signals ( Figure 1 C), we first fixed the weights of the layers up to the 9 th   residual block (gray) for the ECG network and similarly fixed up to the 5 th   residual block (gray) for the CHEST/ABD network, concatenated the outputs, and then fed this concatenation into a subnetwork containing five residual blocks and a final output block. The numbers of fixed layers were chosen so that the outputs of layers from different modalities have the same shape (after padding zeros), and were then concatenated.  The LSTM of the network has the same structure for different input signals. It is a bi-directional LSTM, where the context cells from the forward and backward directions are concatenated. For the network\n\n4  with ECG as input, the LSTM has two layers with 20 hidden nodes in each layer. For CHEST and ECG+CHEST, the LSTM has three layers with 100 hidden nodes in each layer. For ABD and ECG+ABD, the LSTM has two layers with 100 hidden nodes in each layer. The number of LSTM layers, number of hidden nodes, and dropout rate were determined by the method described in the next subsection.  Figure 1 . Deep neural network architecture.   (A and B)   CNN architecture using ECG, or CHEST or ABD as input. The numbers between blocks are the shapes of the output for each input 270-second epoch. For  example, ‚Äú320√ó4‚Äù means 320 channels and four time points. ‚Äú17@64‚Äù in the convolution layers means  kernel size 17 points and 64 kernels. The repetition number of the residual blocks (Res Block) is marked above each block. Arrows indicate the flow of network activations.   (C)   The CNN architecture when using multiple signals as input. Gray blocks mean their weights are obtained from network trained in (A) and (B), then fixed during training the network.   (D)   RNN architecture, which uses the output from the CNN from every 270-second epoch (corresponding to a 30-second epoch). The output is fed into a bidirectional LSTM, followed by concatenation of the activations from both directions, and finally into a dense layer. The legends on the right show the detailed structure of the residual block and final output block. Inside each residual block, the first convolution layer subsamples the input by 4 (stride = 4) and the max pooling skip-layer connection also subsamples the input by 4.  Training and Evaluating the Network  We randomly split the PSGs into a training set of 6,682 PSGs, a validation set of 1,000 PSGs and a testing set of 1,000 PSGs. Due to the large amount of data, we expect the random split should give similar distribution of the variables across these sets. We first trained the CNN, then the LSTM using the outputs from the CNN. The objective function of both CNN and LSTM is cross-entropy, a measure of the distance between two categorical distributions for classification. The networks were trained with a mini- batch size of 32, maximum epochs of 10, and learning rate 0.001 (as commonly used in deep learning). The LSTM was trained using sequences of 20 epochs (10min). We set the number of LSTM layers, number of hidden nodes, and the dropout rate as the combination that minimizes the objective function on the validation set.\n\n5  Some sleep stages occur more frequently than others. For example, people spend about 50% of sleep in N2 and 20% in N3. To prevent the network from simply learning to report the dominant stage, we weighed each 270-second input signal in the objective function by the inverse of the number of epochs in each sleep stage within the training set.  For the   performance metrics on the testing set, we used confusion matrices and Cohen‚Äôs kappa. We  show performance for staging five sleep stages according to the AASM standards (W, N1, N2, N3, R), and we additionally collapse these stages into 3 sleep super-stages, in two different ways. The first set of super- stages is ‚Äúawake or drowsy‚Äù (W+N1) vs. ‚Äúsleep‚Äù (N2+N3) vs. ‚ÄúREM sleep‚Äù (R), and The second set  of super- stages is ‚Äúawake‚Äù (W) vs. ‚ÄúNREM sleep‚Äù (N1+N2+N3) vs. ‚ÄúREM sleep‚Äù (R). We obtained 95%  confidence intervals for kappa values by bootstrapping (sample with replacement) 1,000 times.  Results  Overall Staging Performance  In   Figure 2 , we show the confusion matrices for predicting all five sleep stages with different input signals. Using both ECG and ABD as input signals yields the best prediction results on the testing set. This network is correct in 81.8% of wake, 55.8% of N1, 66.3% of N2, 66.6% of N3 and 92.2% of REM epochs. Most misclassifications are found between W vs. N1, N1 vs. N2, and N2 vs. N3. For example, 31% of N3 epochs are misclassified as N2, and 34% of N1 epochs are misclassified as either W or N2. This limitation is reduced when grouping the sleep stages as in   Figure 3   and   Figure 4 , so that both epochs of REM and NREM can be classified correctly with greater than 80% accuracy.\n\n6  Figure 2 . Five-stage classification confusion matrices, comparing staging by sleep technicians vs. network predictions on the 1000-PSG testing set for different input signals. Each row in the confusion matrix is the sleep stage annotated by the technician, while each column is the network prediction. The numbers are percentages.  Figure 3 . Three-stage classification confusion matrices, comparing staging by sleep technicians vs. network predictions on the 1000-PSG testing set for different input signals. The 3   ‚Äúsuper -stages ‚Äù here  are:   ‚Äúawake or drowsy‚Äù (W+N1) vs. ‚Äúsleep‚Äù (N2+N3) vs. ‚ÄúREM sleep‚Äù (R ).  Figure 4 . Three-stage classification confusion matrices, comparing staging by sleep technicians vs. network predictions on the 1000-PSG testing set for different input signals. The 3   ‚Äúsuper -stages ‚Äù here  are:   ‚Äúawake‚Äù (W) vs. ‚ÄúNREM sleep‚Äù (N1+N2+N3) vs. ‚ÄúREM sleep‚Äù (R).\n\n7  For every choice of input signal, we calculated   Cohen‚Äôs kappa , a statistic for assessing inter-reader agreement, and the corresponding 95% confidence intervals. These are shown in   Table 2 . ECG+ABD has the highest kappa, with values of 0.6 (all five stages), 0.74 (W+N1 vs. N2+N3 vs. REM) and 0.762 (Wake vs. NR vs. REM). Since the testing set has 1,000 PSGs (6.6√ó10 5   30-second epochs), the confidence interval is narrow. Therefore the differences between kappa values are all significant at 0.05 level.  Table 2 . Cohen‚Äôs kappa on the 1000 -PSG testing set using different input signals.  Input   S ignal   5 Stages   3 Stages  W+N1 vs. N2 +N3 vs. R   W vs. NR vs. R  ECG   0.494 (0.492   ‚Äì   0.495)   0.649 (0.647   ‚Äì   0.65)   0.649 (0.647   ‚Äì   0.651)  CHEST   0.565 (0.563   ‚Äì   0.566)   0.708 (0.707   ‚Äì   0.709)   0.707 (0.706   ‚Äì   0.709)  ABD   0.579 (0.578   ‚Äì   0.581)   0.725 (0.723   ‚Äì   0.726)   0.738 (0.736   ‚Äì   0.739)  ECG + CHEST   0.506 (0.504   ‚Äì   0.507)   0.648 (0.646   ‚Äì   0.65)   0.661 (0.659   ‚Äì   0.663)  ECG + ABD   0.600 (0.599   ‚Äì   0.602)   0.740 (0.738   ‚Äì   0.741)   0.762 (0.76   ‚Äì   0.763)  Staging Performance on Different Groups of Participants  In   Table 3 , we   show Cohen‚Äôs kappa   for different population groups in the testing set using ECG+ABD as the input signals. Kappa is lower in the elderly ( ‚â• 60 years) and   in people with higher Apnea-Hypopnea Index (AHI), compared to the respective control groups. Split-night studies have lower kappa values than diagnostic or CPAP nights due to different patterns before and after applying CPAP. Note again that due to the large number of epochs in the testing set, confidence intervals are narrow, and all comparisons are statistically significant at 0.05 level.   The Cohen‚Äôs kappa for different population   groups in the testing set using other input signals are shown in Table E1-E4 in the supplementary material.  While performance is reduced with increasing AHI, the network still achieves Cohen‚Äôs kappa of   0.574 for five stages; and more than 0.7 for three super-stages for severe apnea. We interpret this to mean that either autonomic features characteristic of stages are independent of sleep apnea, or more likely, that the network has learned normal, apneic, and other pathological patterns of the respiration signals change according to sleep stage.   For example, REM and NREM interruptions in breathing may have distinct distributions of features such as event duration.  Table 3 . Cohen‚Äôs kappa in different groups in the 1000 -PSG testing set using ECG + ABD as input.  Category   Group   5 stages  3 stages  W+N1 vs.  N2+ N3 vs. R   W vs. NR vs. R  Age  Young: 18 ‚â§ Age < 40   0.622   0.760   0.773  Middle: 40 ‚â§ Age < 60   0.598   0.736   0.761  Old: Age ‚â• 60   0.576   0.713   0.742  Sex   Male   0.594   0.728   0.755  Female   0.602   0.746   0.763  BMI (kg/m 2 )   Normal: 18.5 ‚â§ BMI < 25   0.613   0.737   0.752  Overweight: BMI ‚â• 25   0.596   0.736   0.760  Type of Test   Diagnostic   0.600   0.738   0.756  All Night CPAP   0.608   0.758   0.770\n\n8  Split Night   0.584   0.707   0.752  AHI (per hour)  Normal: AHI < 5   0.608   0.760   0.773  Mild: 5 ‚â§ AHI < 15   0.604   0.746   0.750  Moderate: 15 ‚â§ AHI < 30   0.600   0.733   0.752  Severe: AHI ‚â• 30   0.574   0.717   0.742  Periodic limb movement (per hour)  Normal: PLM < 5   0.606   0.736   0.765  Mild: 5 ‚â§ PLM < 15   0.600   0.746   0.767  Moderate: 15 ‚â§ PLM < 30   0.600   0.733   0.752  Severe: PLM ‚â• 30   0.574   0.717   0.742  Medication  Antidepressant   0.588   0.736   0.756  Benzodiazepine   0.602   0.750   0.761  Diabetic   0.589   0.757   0.770  Herbal   0.596   0.745   0.743  Hypertension   0.595   0.732   0.758  Neuroleptic   0.588   0.716   0.749  Opiate   0.600   0.721   0.766  Neuroactive   0.598   0.736   0.762  Systemic   0.599   0.740   0.766  RLS/PLMS   0.608   0.755   0.773  Sleeping   0.610   0.750   0.763  Stimulant   0.603   0.740   0.774  Z-drug   0.627   0.765   0.774  Staging Performance on Individual PSGs  In   Figure 5 , we   show the histogram of Cohen‚Äôs kappa   of each individual PSG using both ECG and ABD as input. The results indicate a fair amount of heterogeneity between PSGs, where the lowest extreme has negative kappa values around -0.1 and the highest extreme has kappa values around 0.9. In Figure S2 in the supplementary material, we show the   Cohen‚Äôs kappa of each individual PSG using all signal types.  Figure 5 . Histogram of   Cohen‚Äôs kappa values for individual PSGs using both ECG and ABD as input. The  distributions are right-skewed.\n\n9  Dependence on temporal precision of R-peak timing in the ECG  In face of signal noise, the deep learning network should learn robust patterns of the ECG R peak time series. To validate its robustness to signal noise, we simulated noise that preserves the mean but corrupts higher order pattern of the ECG R peaks. In Figure S3 of the supplementary material, we can see that adding zero-mean Gaussian jitter to the R peaks causes performance to drop progressively as the standard deviation of the jitter increases.  Signal Examples  To gain some insight into the differences in breathing and heart rhythms that the deep neural network is using to distinguish sleep stages, we show some example whole night recordings from the 1000-PSG testing set in   Figure 6 ,   Figure 7 , and   Figure 8 . These examples are selected as ‚Äútypical‚Äù, meaning that  the y have the closest Cohen‚Äôs kappa   compared to the overall kappa across the testing set. The 60- second signal examples in Panel C are the signals where the deep neural network assigns the highest probability to the correct sleep stage within the recording. We can see a visible correspondence between the spectrogram and the sleep stages, as well as the mismatch between the spectrogram and EEG-based sleep stage. For example, in   Figure 8 , around 2 hours and 4.5 hours, the spectrogram of heart rate variability shows loss of very low frequency power, which is classified by the network as N3, but the EEG-based sleep stages contain both N2 and N3. More illustrations of the trained deep neural networks are shown in Figure S4-S12 of the supplementary material.  Figure 6 . An example 47-year male.   (A)   The sleep stages over the whole night annotated by the technician (hypnogram).   (B)   The predicted sleep stages from the deep neural network using ABD respiration as input.   (C)   Example 60-second ABD segment from each sleep stage which is correctly classified and has the highest predicted probability of that stage. Different colors correspond to the triangle markers on other panels, which indicate the location of the example in the whole night recording. The number above each example signal indicates the probability of being that stage as\n\n10  predicted by the deep learning network.   (D)   The spectrogram of the ABD respiratory signal. The y-axis indicates the frequency.  Figure 7 . Similar to   Figure 6 , showing an example 42-year female using CHEST respiration as input. The scaling of the signals in Panel C is the same as in   Figure 6 , but amplitude of these example signal itself happens to be smaller. It is possible that other epochs have larger or similar amplitude compared to  Figure 6 .  Figure 8 . Similar to   Figure 6 , showing an example 39-year female using the R peaks from ECG as input. Panel C shows the R peaks represented as a binary sequence (see Methods). Panel D shows the spectrogram of the R peak intervals   21 .\n\n11  Discussion  We hypothesize that it is possible to accurately stage sleep based on the electrocardiogram (ECG) and respiratory signals using deep learning. Our key findings are: 1) ECG and respiratory signals contain substantial information about sleep stages; 2) reduced staging accuracy is associated with older age and/or more severe sleep apnea, although the networks still perform well on signals from patients with advanced age and high AHI; 3) using deep learning, the staging performance is robust for a wide range of typical sleep disorders like OSA and PLMS, and commonly used medications; 4) collapsing certain stages of sleep/wake (e.g., N1 with wake and N2 with N3) results in greater staging agreement.  Previous studies comparable to ours are summarized in   Table 4 . Some prior studies have also sought to stage sleep from ECG and respiration using deep neural networks. However, these studies suffered from small sample sizes and limiting generalizability. Only one prior study used more than 100 participants for training and evaluation. The large sample size of training and testing sets in the present study provides more robust results compared to prior literature, and is expected to increase generalizability when applied to heterogeneous / external populations.  Table 4 .   Related work in the literature.  Author  (year)   Dataset size   Performance  ( Œ∫ is Cohen‚Äôs kappa )   Type of Signal   Features  Sady et al.  2013   12  13  participants  3 stages (W, NREM, REM):  accuracy=78%  5 stages (W, N1, N2, N3, REM):  accuracy=62%  Photo -  Plethysmogram,  hemoglobin oxygen  saturation,  pneumotachograph  Heartbeat  interval, time  domain  respiratory  signals.  Long et al.  2014   22  48  participants  3 stages (W, NREM, REM):  Œ∫ =0.48  4 stages (W, light sleep, deep  sleep, REM):   Œ∫   =0.41  Respiratory effort  Time domain,  dissimilarity  measure  Fonseca et  al.  2015   23  48  participants  4 stages (W, light sleep, deep  sleep, REM):   Œ∫ =0.49,  accuracy=69%  3 stages (W, NREM, REM):  Œ∫ =0.56  Accura cy=80%  ECG + Respiratory  inductance  plethysmography  Time and  frequency  domain,  nonlinear  Zhao et al.  2017   24  25  participants,  100 nights  4 stages (W, N1+N2, N3, REM):  Œ∫ =0.70,  accuracy=79.8%  Radio frequency  signal reflected off  body (heartbeat,  respiration)  Radio  frequency  spectrogram  Zhang et al.  2017   25  37,000  epochs  5 stages (W, N1, N2, N3, REM):  Precision = 53.9%  Re call = 56.0%  F1 score = 53.2%  Heart rate derived  from a wearable  device  Frequency  domain  (DCT)\n\n12  Radha et al.  2018   26  ECG: 352 participants, PPG: 60 participants  ECG: 6 stages (W, S1, S2, S3, S4, REM),   Œ∫ =0.61 and accuracy=76.30%  PPG: 5 stages (W, N1, N2, N3, REM),   Œ∫ =0.63 and accuracy=74.65%  ECG and PPG  Selected features from time and frequency domain  Sleep staging based on ECG and respiration has lower performance compared to using EEG. We previously performed EEG-based sleep staging with a deep neural network trained on data from the same set of patients used in the present work. This achieves performance similar to human inter-rater agreement   17 . This is not surprising since sleep technicians stage sleep mainly using EEG based on the AASM guideline.  The improvement in staging performance when collapsing certain stages of sleep into super-stages may reflect information regarding the true biology of sleep states. N1 is an unstable transitional state with low probability and non-distinct EEG features. About half of sleep is N2, and can show both stable and unstable characteristics, such as cyclic alternating pattern, apneic, or stable breathing in patients with sleep apnea. Different methods to characterize sleep depth and quality are available, and it will be important in future work to investigate whether further parsing of NREM sleep is meaningful using machine learning combined with methods such as the Odds Ratio Product of NREM sleep depth   27   or ECG-cardiopulmonary coupling   8 .  The mild degradation of performance with age is not surprising when using conventional sleep stages as the ground truth. The reduction of N3 with age (mainly in males) is not accompanied by equal and simultaneous reductions in stable N2   ‚Äì   thus, older individuals with equally reduced N3 may have very different N2 quality. By contrast, stable N2 and N3 may have very similar or identical cardiorespiratory signatures, making it difficult or impossible for deep learning models to reliably distinguish them. Thus  ‚Äúerror s ‚Äù   in discriminating these stages may reflect that EEG-based annotation in the reference standard is somewhat orthogonal to autonomic fluctuations.  Estimation of sleep states from cardiac and respiratory signals can simplify sleep tracking in health and disease, especially in environments like an intensive care unit (ICU) or hospitalized patients in general, when the model is trained with enough ICU patients who receive various heart rate or blood pressure medications.  Limitations of our analysis are as follows. 1) Our dataset includes only adults, and generalizability to the pediatric group will require additional study. 2) The 30-second epoch-based scoring of sleep limits the fine-grained analysis of sleep stages. This is especially true when sleep fragmenting conditions are present, where a given 30-second epoch may have features of multiple states. Moreover, boundary zones may be amplified, such as transitions between wake-REM and NREM in the presence of sleep  apnea in REM sleep. Such periods will introduce ‚Äúerror‚Äù in machine learning analys es, though these are biological features of sleep fragmentation rather than measurement or characterization error, such as arousal, apnea, or limb movement. 3)   Due to the ‚Äúblack - box‚Äù   nature of deep neural networks, there is limited insight into what the networks use as key features. Future work to interpret what the networks have learned (beyond   Figure 6 ,   Figure 7 ,   Figure 8 , and Figure S4-S12 in the supplementary material) is needed. (4) 1-fold validation (single training-validation-testing split) is used. Although this is the\n\n13  common practice in large datasets, it is nevertheless less biased to use cross-validation on multiple folds.  In conclusion, utilizing a large-scale dataset consisting of 8,682 PSGs, we have developed a set of deep neural networks to classify sleep stages from ECG and/or respiration. ECG and respiratory effort provide substantial information about sleep stages. The best staging performance is obtained using both ECG and abdominal respiration. Staging performance depends to some extent on age, apnea-hypopnea index, and sleep study type.  Acknowledgments  We gratefully acknowledge expert technical support from the Clinical Data Animation Center (CDAC) at Massachusetts General Hospital.  Disclosure Statement  RJT reports 1) Patent, license and royalties from MyCardio, LLC, for an ECG-based method to phenotype sleep quality and sleep apnea; 2) GLG consulting for general sleep medicine; 3) Intellectual Property (patent) for a device using CO2 for central / complex sleep apnea. BG declares that the work was done while at Massachusetts General Hospital. He is currently a full time employee at Novartis Institutes of Biomedical Research with a role of Data Scientist.  References  1.   Silber MH, Ancoli-Israel S, Bonnet MH, et al. The visual scoring of sleep in adults. J Clin Sleep Med.   2007; 3 (2): 121-131.  2.   Chervin RD, Shelgikar AV, Burns JW. Respiratory cycle-related EEG changes: response to CPAP. Sleep.   2012; 35 (2): 203-209.  3.   Niizeki K, Saitoh T. Association Between Phase Coupling of Respiratory Sinus Arrhythmia and Slow Wave Brain Activity During Sleep. Front Physiol.   2018; 9: 1338.  4.   Penzel T, Kantelhardt JW, Bartsch RP, et al. Modulations of Heart Rate, ECG, and Cardio- Respiratory Coupling Observed in Polysomnography. Front Physiol.   2016; 7: 460.  5.   Thomas RJ, Mietus JE, Peng CK, et al. Relationship between delta power and the electrocardiogram-derived cardiopulmonary spectrogram: possible implications for assessing the effectiveness of sleep. Sleep Med.   2014; 15 (1): 125-131.  6.   Lockmann AL, Laplagne DA, Leao RN, Tort AB. A Respiration-Coupled Rhythm in the Rat Hippocampus Independent of Theta and Slow Oscillations. J Neurosci.   2016; 36 (19): 5338-5352.  7.   Iellamo F, Placidi F, Marciani MG, et al. Baroreflex buffering of sympathetic activation during sleep: evidence from autonomic assessment of sleep macroarchitecture and microarchitecture. Hypertension.   2004; 43 (4): 814-819.\n\n14  8.   Thomas RJ, Mietus JE, Peng CK, Goldberger AL. An electrocardiogram-based technique to assess cardiopulmonary coupling during sleep. Sleep.   2005; 28 (9): 1151-1161.  9.   Sei H. Blood pressure surges in REM sleep: A mini review. Pathophysiology.   2012; 19 (4): 233- 241.  10.   Thomas RJ, Wood C, Bianchi MT. Cardiopulmonary coupling spectrogram as an ambulatory clinical biomarker of sleep stability and quality in health, sleep apnea and insomnia. Sleep.   2017.  11.   Bianchi MT. Sleep devices: wearables and nearables, informational and interventional, consumer and clinical. Metabolism.   2018; 84: 99-108.  12.   Sady CC, Freitas US, Portmann A, Muir JF, Letellier C, Aguirre LA. Automatic sleep staging from ventilator signals in non-invasive ventilation. Comput Biol Med.   2013; 43 (7): 833-839.  13.   Migliorini M, Bianchi AM, Nistico D, et al. Automatic sleep staging based on ballistocardiographic signals recorded through bed sensors. Conf Proc IEEE Eng Med Biol Soc.   2010; 2010: 3273-3276.  14.   Tal A, Shinar Z, Shaki D, Codish S, Goldbart A. Validation of Contact-Free Sleep Monitoring Device with Comparison to Polysomnography. J Clin Sleep Med.   2017; 13 (3): 517-522.  15.   Zaffaroni A, Doheny EP, Gahan L, et al. Non-Contact Estimation of Sleep Staging. 2018; Singapore.  16.   Watson PL, Pandharipande P, Gehlbach BK, et al. Atypical sleep in ventilated patients: empirical electroencephalography findings and the path toward revised ICU sleep scoring criteria. Crit Care Med.  2013; 41 (8): 1958-1967.  17.   Biswal S, Sun H, Goparaju B, Westover MB, Sun J, Bianchi MT. Expert-level sleep scoring with deep neural networks. Journal of the American Medical Informatics Association.   2018; 25 (12): 1643- 1650.  18.   Pan J, Tompkins WJ. A real-time QRS detection algorithm. IEEE Trans Biomed Eng.   1985; 32 (3): 230-236.  19.   Rebergen DJ, Nagaraj SB, Rosenthal ES, Bianchi MT, van Putten MJ, Westover MB. ADARRI: a novel method to detect spurious R-peaks in the electrocardiogram for heart rate variability analysis in the intensive care unit. Journal of clinical monitoring and computing.   2018; 32 (1): 53-61.  20.   Hannun AY, Rajpurkar P, Haghpanahi M, et al. Cardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms using a deep neural network. Nature medicine.   2019; 25 (1): 65.  21.   van Gent PaF, Haneen and Nes, Nicole and Arem, B. Heart Rate Analysis for Human Factors: Development and Validation of an Open Source Toolkit for Noisy Naturalistic Heart Rate Data. In: proceedings from the the 6th HUMANIST Conference; 2018; the Netherlands.  22.   Long X, Yang J, Weysen T, et al. Measuring dissimilarity between respiratory effort signals based on uniform scaling for sleep staging. Physiological measurement.   2014; 35 (12): 2529.  23.   Fonseca P, Long X, Radha M, Haakma R, Aarts RM, Rolink J. Sleep stage classification with ECG and respiratory effort. Physiological measurement.   2015; 36 (10): 2027.  24.   Zhao M, Yue S, Katabi D, Jaakkola TS, Bianchi MT. Learning sleep stages from radio signals: A conditional adversarial architecture. In: proceedings from the Proceedings of the 34th International Conference on Machine Learning-Volume 70; 2017.  25.   Zhang X, Kou W, Eric I, et al. Sleep stage classification based on multi-level feature learning and recurrent neural networks via wearable device. Computers in biology and medicine.   2018; 103: 71-81.  26.   Radha M, Fonseca P, Ross M, Cerny A, Anderer P, Aarts RM. LSTM knowledge transfer for HRV- based sleep staging. arXiv preprint arXiv:180906221.   2018.  27.   Younes M, Ostrowski M, Soiferman M, et al. Odds ratio product of sleep EEG as a continuous measure of sleep state. Sleep.   2015; 38 (4): 641-654.\n\n15\n\n16  Supplementary Figures  Figure S1 . Illustration of signal segmentation.  Figure S2.   The histogram of C ohen‚Äôs kappa of individual PSGs for different input signals and different  combinations of sleep stages.\n\n17  Figure S3 . Cohen‚Äôs kappa when applying zero -mean Gaussian jitter to the ECG R peaks.  Figure S4 . tSNE visualization of the last layer activation of the deep network that takes ECG as the input. Each point in the figure is a 270-second epoch.\n\n18  Figure S5 . tSNE visualization of the last layer activation of the deep network that takes chest repiration signal as the input. Each point in the figure is a 270-second epoch.  Figure S6 . tSNE visualization of the last layer activation of the deep network that takes abdominal repiration as the input. Each point in the figure is a 270-second epoch.\n\n19  Figure S7 . The kernels of the first convolution layer in the deep network that takes ECG as the input.  Figure S8 . The kernels of the first convolution layer in the deep network that takes chest respiration as the input.\n\n20  Figure S9 . The kernels of the first convolution layer in the deep network that takes abdominal respiration as the input.  Figure S10 . Examples of ABD signals for different sleep stages. These examples are selected based on having high probability according to the deep neural network in each of the 5 sleep stages. The signals are not necessarily from the same recording.\n\n21  Figure S11 . Examples of CHEST signals in different sleep stages, selected based on having high probability by the deep neural network. The signals are not necessarily from the same recording.  Figure S12 . Example ECG R peaks in different sleep stages, selected based on having high probability by the deep neural network. The signals are not necessarily from the same recording.\n\n22  Supplementary Tables  Table S1 . Cohen‚Äôs kappa in different group   in the 1000-PSG testing set using ECG as input.  Category   Group   5 stages  3 stages  W+N1 vs.  N2+ N3 vs. R  W vs. NR vs.  R  Age  Young: 18 ‚â§ Age < 40   0.54   0.715   0.717  Middle: 40 ‚â§ Age < 60   0.514   0.672   0.685  Elderly: Age ‚â• 60   0.426   0.57   0.564  Sex   Male   0.483   0.636   0.644  Female   0.51   0.673   0.67  BMI (kg/m 2 )   Normal: 18.5 ‚â§ BMI < 25   0.536   0.678   0.672  Overweight: BMI ‚â• 25   0.49   0.65   0.654  Type of Test  Diagnostic   0.508   0.667   0.667  All Night CPAP   0.501   0.67   0.663  Split Night   0.462   0.601   0.622  AHI (per hour)  Normal: AHI < 5   0.519   0.699   0.701  Mild: 5 ‚â§ AHI < 15   0.499   0.655   0.639  Moderate: 15 ‚â§ AHI < 30   0.471   0.615   0.621  Severe: AHI ‚â• 30   0.427   0.532   0.603  Periodic   limb movement (per hour)  Normal: PLMI < 5   0.497   0.656   0.676  Mild: 5 ‚â§ PLMI < 15   0.512   0.667   0.669  Moderate: 15 ‚â§ PLMI < 30   0.502   0.664   0.649  Severe: PLMI ‚â• 30   0.459   0.609   0.611  Medication  Antidepressant   0.489   0.651   0.652  Benzodiazepine   0.501   0.674   0.662  Diabetic   0.501   0.673   0.668  Herbal   0.484   0.65   0.639  Hypertension   0.495   0.649   0.655  Neuroleptic   0.483   0.664   0.674  Opiate   0.476   0.624   0.626  Neuroactive   0.5   0.648   0.661  Systemic   0.496   0.656   0.663  RLS/PLMS   0.515   0.647   0.657  Sleeping   0.499   0.669   0.66  Stimulant   0.507   0.671   0.646  Z-drug   0.526   0.692   0.682\n\n23  Table S2 . Cohen‚Äôs kappa in different group in the 1000 -PSG testing set using CHEST as input.  Category   Group   5 stages  3 stages  W+N1 vs.  N2+ N3 vs. R  W vs. NR vs.  R  Age  Young: 18 ‚â§ Age < 40   0.581   0.728   0.728  Middle: 40 ‚â§ Age < 60   0.569   0.709   0.713  Old: Age   ‚â• 60   0.546   0.691   0.689  Sex   Male   0.558   0.701   0.704  Female   0.573   0.719   0.716  BMI (kg/m 2 )   Normal: 18.5 ‚â§ BMI < 25   0.554   0.697   0.692  Overweight: BMI ‚â• 25   0.567   0.71   0.711  Type of Test  Diagnostic   0.57   0.714   0.713  All Night CPAP   0.564   0.719   0.702  Split Night   0.553   0.685   0.707  AHI (per hour)  Normal: AHI < 5   0.576   0.734   0.725  Mild: 5 ‚â§ AHI < 15   0.572   0.714   0.708  Moderate: 15 ‚â§ AHI < 30   0.555   0.688   0.696  Severe: AHI ‚â• 30   0.517   0.628   0.68  Periodic   limb movement (per hour)  Normal: PLMI < 5   0.556   0.698   0.71  Mild: 5 ‚â§ PLMI < 15   0.576   0.715   0.709  Moderate: 15 ‚â§ PLMI < 30   0.576   0.72   0.716  Severe: PLMI ‚â• 30   0.551   0.698   0.699  Medication  Antidepressant   0.573   0.72   0.718  Benzodiazepine   0.572   0.714   0.706  Diabetic   0.561   0.708   0.707  Herbal   0.586   0.728   0.713  Hypertension   0.565   0.704   0.709  Neuroleptic   0.532   0.691   0.689  Opiate   0.576   0.709   0.704  Neuroactive   0.573   0.713   0.72  Systemic   0.564   0.706   0.71  RLS/PLMS   0.58   0.725   0.726  Sleeping   0.572   0.719   0.713  Stimulant   0.581   0.722   0.7  Z-drug   0.581   0.72   0.709\n\n24  Table S3 . Cohen‚Äôs kappa in different group in the 1000 -PSG testing set using ABD as input.  Category   Group   5 stages  3 stages  W+N1 vs.  N2+ N3 vs. R  W vs. NR vs.  R  Age  Young: 18 ‚â§ Age < 40   0.584   0.737   0.753  Middle: 40 ‚â§ Age   < 60   0.586   0.728   0.746  Old: Age ‚â• 60   0.551   0.698   0.705  Sex   Male   0.574   0.719   0.737  Female   0.577   0.725   0.732  BMI (kg/m 2 )   Normal: 18.5 ‚â§ BMI < 25   0.552   0.684   0.679  Overweight: BMI ‚â• 25   0.579   0.727   0.743  Type of Test  Diagnostic   0.584   0.724   0.733  All Night CPAP   0.578   0.738   0.734  Split Night   0.555   0.698   0.737  AHI (per hour)  Normal: AHI < 5   0.584   0.742   0.741  Mild: 5 ‚â§ AHI < 15   0.585   0.734   0.739  Moderate: 15 ‚â§ AHI < 30   0.563   0.696   0.723  Severe: AHI ‚â• 30   0.533   0.651   0.725  Periodic   limb movement (per hour)  Normal: PLMI < 5   0.574   0.726   0.748  Mild: 5 ‚â§ PLMI < 15   0.583   0.73   0.738  Moderate: 15 ‚â§ PLMI < 30   0.579   0.714   0.728  Severe: PLMI ‚â• 30   0.559   0.7   0.714  Medication  Antidepressant   0.574   0.731   0.743  Benzodiazepine   0.595   0.738   0.749  Diabetic   0.574   0.736   0.74  Herbal   0.605   0.741   0.75  Hypertension   0.576   0.719   0.738  Neuroleptic   0.527   0.695   0.715  Opiate   0.585   0.722   0.74  Neuroactive   0.581   0.729   0.743  Systemic   0.578   0.726   0.744  RLS/PLMS   0.58   0.739   0.74  Sleeping   0.589   0.737   0.745  Stimulant   0.604   0.745   0.769  Z-drug   0.602   0.75   0.756\n\n25  Table S4 . Cohen‚Äôs kappa in different group in the 1000 -PSG testing set using ECG + CHEST as input.  Category   Group   5 stages  3 stages  W+N1 vs.  N2+ N3 vs. R  W vs. NR vs.  R  Age  Young: 18   ‚â§ Age < 40   0.539   0.691   0.708  Middle: 40 ‚â§ Age < 60   0.506   0.645   0.657  Old: Age ‚â• 60   0.468   0.603   0.621  Sex   Male   0.492   0.633   0.647  Female   0.518   0.659   0.673  BMI (kg/m 2 )   Normal: 18.5 ‚â§ BMI < 25   0.54   0.672   0.682  Overweight: BMI ‚â• 25   0.499   0.642   0.656  Type of Test  Diagnostic   0.518   0.661   0.674  All Night CPAP   0.504   0.652   0.644  Split Night   0.472   0.602   0.642  AHI (per hour)  Normal: AHI < 5   0.521   0.677   0.683  Mild: 5 ‚â§ AHI < 15   0.518   0.657   0.651  Moderate: 15 ‚â§ AHI < 30   0.472   0.604   0.637  Severe: AHI   ‚â• 30   0.451   0.554   0.627  Periodic   limb movement (per hour)  Normal: PLMI < 5   0.5   0.643   0.668  Mild: 5 ‚â§ PLMI < 15   0.52   0.655   0.661  Moderate: 15 ‚â§ PLMI < 30   0.511   0.657   0.661  Severe: PLMI ‚â• 30   0.475   0.611   0.632  Medication  Antidepressant   0.508   0.66   0.664  Benzodiazepine   0.519   0.663   0.673  Diabetic   0.488   0.658   0.658  Herbal   0.547   0.687   0.719  Hypertension   0.49   0.631   0.641  Neuroleptic   0.462   0.633   0.679  Opiate   0.499   0.613   0.644  Neuroactive   0.504   0.648   0.667  Systemic   0.499   0.643   0.656  RLS/PLMS   0.516   0.671   0.681  Sleeping   0.517   0.667   0.679  Stimulant   0.539   0.677   0.683  Z-drug   0.547   0.684   0.703",
      "embedding": [
        0.006839264649897814,
        -0.013053003698587418,
        0.02145952731370926,
        0.014412404969334602,
        0.012515323236584663,
        0.021394072100520134,
        -0.07114054262638092,
        -0.004908363800495863,
        0.05623853579163551,
        -0.05642860382795334,
        -0.0909905955195427,
        -0.04176672175526619,
        0.006414123810827732,
        0.05290873721241951,
        -0.024032127112150192,
        -0.061115626245737076,
        0.029773132875561714,
        0.04865708202123642,
        -0.0716501921415329,
        0.032141245901584625,
        0.11761263012886047,
        0.006626523099839687,
        0.0730658546090126,
        -0.03491466864943504,
        0.02264717034995556,
        -0.0108387665823102,
        0.016455259174108505,
        -0.03805457428097725,
        -0.030696984380483627,
        -0.03796026110649109,
        0.023945877328515053,
        0.0032399389892816544,
        -0.0024411031045019627,
        0.03974059969186783,
        -0.04985015094280243,
        0.1151762381196022,
        0.037825390696525574,
        0.03108399175107479,
        -0.05336355045437813,
        0.011715630069375038,
        0.016958165913820267,
        0.05364443361759186,
        -0.0030628107488155365,
        -0.013380668126046658,
        0.07839076220989227,
        0.007613144349306822,
        -0.0423438586294651,
        -0.06432060897350311,
        -0.0425286702811718,
        0.020036259666085243,
        -0.053910113871097565,
        -0.032047152519226074,
        -0.047756485641002655,
        0.09990209341049194,
        0.00521471444517374,
        0.03862059488892555,
        -0.08623560518026352,
        -0.021342603489756584,
        -0.03310617431998253,
        -0.021700754761695862,
        -0.0935380682349205,
        0.003966568037867546,
        0.06555959582328796,
        -0.0753442719578743,
        -0.037916816771030426,
        0.06662227213382721,
        -0.0052854460664093494,
        -0.03492796793580055,
        0.0255143865942955,
        0.00894143059849739,
        -0.03404532000422478,
        -0.04869481176137924,
        0.0018101054010912776,
        -0.014326399192214012,
        -0.10473403334617615,
        0.08236858248710632,
        0.13499511778354645,
        -0.04085966944694519,
        0.026234373450279236,
        -0.04923227056860924,
        0.07661262899637222,
        0.013882521539926529,
        -0.006212499458342791,
        -0.05422114208340645,
        0.03581748902797699,
        0.005416334141045809,
        0.013273793272674084,
        0.02026141621172428,
        -0.10403773933649063,
        0.01169158797711134,
        0.0887073501944542,
        -0.012897553853690624,
        -0.02538120374083519,
        -0.009590577334165573,
        0.1099712923169136,
        -0.006309208460152149,
        -0.05902582406997681,
        0.04063212871551514,
        0.015625135973095894,
        -0.019964441657066345,
        0.040782324969768524,
        0.022679686546325684,
        -0.006367584224790335,
        -0.0060550677590072155,
        0.008319685235619545,
        0.0008957609534263611,
        0.10432613641023636,
        -0.054725296795368195,
        0.03415379673242569,
        -0.0297992043197155,
        0.03195108100771904,
        0.06387214362621307,
        -0.0077533721923828125,
        0.009041042067110538,
        0.09914546459913254,
        0.11641878634691238,
        -0.04833937808871269,
        0.06412848085165024,
        0.07877033203840256,
        0.09841743856668472,
        0.006927078124135733,
        -0.056559160351753235,
        0.03342965617775917,
        -0.0995139554142952,
        0.030637871474027634,
        -0.01770167052745819,
        -0.10242965072393417,
        6.046939468591625e-33,
        0.02968961000442505,
        -0.012818767689168453,
        0.007392833475023508,
        0.0043683769181370735,
        -0.022086244076490402,
        -0.0394439734518528,
        -0.033584389835596085,
        0.05679315701127052,
        0.04440930113196373,
        0.046178922057151794,
        -0.09584435075521469,
        0.032631922513246536,
        0.008820928633213043,
        0.04699375480413437,
        -0.004697759635746479,
        -0.012976609170436859,
        -0.1001925840973854,
        0.041141778230667114,
        -0.04342401772737503,
        -0.07142814993858337,
        0.009357460774481297,
        -0.0671103447675705,
        0.03975411877036095,
        -0.01344316452741623,
        -0.021298551931977272,
        0.04915449395775795,
        -0.014591777697205544,
        0.04971400275826454,
        -0.015003800392150879,
        -0.0037197954952716827,
        -0.08713012933731079,
        -0.00873358454555273,
        -0.02207178622484207,
        0.023442132398486137,
        -0.019379375502467155,
        -0.001416172250173986,
        -0.01017972081899643,
        0.06524777412414551,
        0.031824611127376556,
        0.01100553572177887,
        -0.040571779012680054,
        0.08432583510875702,
        0.027197672054171562,
        0.007047856692224741,
        0.040803030133247375,
        -0.03977919742465019,
        0.017717909067869186,
        0.018563272431492805,
        0.04194187372922897,
        -0.013779101893305779,
        -0.010835763067007065,
        -0.08536029607057571,
        -0.016160568222403526,
        -0.12865659594535828,
        -0.041787561029195786,
        0.09325366467237473,
        0.006284117233008146,
        0.057780783623456955,
        -0.019134007394313812,
        0.10151217132806778,
        -0.012342932634055614,
        0.05000351369380951,
        -0.030430302023887634,
        0.03961371257901192,
        0.0014930106699466705,
        0.05625159665942192,
        -0.0960865169763565,
        -0.0057945107109844685,
        0.0195412989705801,
        -0.03873768821358681,
        0.04498763382434845,
        0.0027598205488175154,
        0.07201854139566422,
        -0.06182444095611572,
        0.03508364036679268,
        0.0035996015649288893,
        0.021634498611092567,
        0.07212404161691666,
        -0.09413518756628036,
        -0.02553451620042324,
        0.09361951798200607,
        0.04406168311834335,
        -0.03880038484930992,
        -0.02879299409687519,
        -0.02416246011853218,
        -0.049924496561288834,
        0.02611001953482628,
        0.016965579241514206,
        -0.10182727128267288,
        0.02650631032884121,
        -0.03510952740907669,
        0.057532843202352524,
        0.04335661977529526,
        -0.01753542572259903,
        -0.05478492006659508,
        -4.7542013112183226e-33,
        -0.010969089344143867,
        -0.01175833959132433,
        -0.060470543801784515,
        0.00013332028174772859,
        0.05507952719926834,
        0.03865477815270424,
        0.04239482060074806,
        -0.047119878232479095,
        -0.021730445325374603,
        -0.10376905649900436,
        0.022668015211820602,
        -0.051550090312957764,
        0.021097231656312943,
        -0.023595431819558144,
        0.015078775584697723,
        -0.06309744715690613,
        -0.07647816836833954,
        0.003759770654141903,
        -0.00998552143573761,
        0.10331298410892487,
        0.011027008295059204,
        0.020230058580636978,
        -0.11753088235855103,
        -0.01804894395172596,
        0.026070188730955124,
        0.09658177942037582,
        -0.002241908572614193,
        0.10047046840190887,
        0.037434302270412445,
        -0.10229802876710892,
        0.012103461660444736,
        -0.015466525219380856,
        -0.12429193407297134,
        0.012475314550101757,
        -0.022486554458737373,
        0.07243754714727402,
        0.015355164185166359,
        -0.0028273998759686947,
        -0.060759641230106354,
        -0.06968504935503006,
        0.09456094354391098,
        0.10084658861160278,
        0.001029093167744577,
        -0.014361808076500893,
        0.0022518218029290438,
        0.0420861579477787,
        0.02461119554936886,
        -0.07857014983892441,
        -0.07101752609014511,
        0.004380081780254841,
        -0.02627912349998951,
        -0.009438819251954556,
        -0.11402074247598648,
        0.02729620598256588,
        -0.04560790956020355,
        0.003666914300993085,
        -0.0856868252158165,
        0.030001657083630562,
        -0.005413563456386328,
        0.029265692457556725,
        0.003844107035547495,
        -0.015805548056960106,
        -0.045098502188920975,
        -0.09491950273513794,
        0.04575079306960106,
        0.06528924405574799,
        -0.0026444511022418737,
        -0.008525809273123741,
        0.0561613030731678,
        0.0039970544166862965,
        -0.02969254180788994,
        -0.01770293340086937,
        -0.028187619522213936,
        0.016436493024230003,
        -0.001772780902683735,
        0.010071408934891224,
        0.01372055895626545,
        -0.08141148835420609,
        -0.061687398701906204,
        -0.06640543043613434,
        0.03465762361884117,
        -0.11501672863960266,
        -0.09201139956712723,
        0.06165396422147751,
        0.0046513755805790424,
        0.05710240826010704,
        0.05265292152762413,
        -0.014876598492264748,
        0.08361033350229263,
        -0.017155619338154793,
        -0.06332094967365265,
        0.024786893278360367,
        -0.037559833377599716,
        0.008640834130346775,
        -0.008954700082540512,
        -5.7504266237629054e-8,
        -0.019489185884594917,
        0.008245701901614666,
        0.0637047290802002,
        -0.00034222277463413775,
        -0.0031752074137330055,
        -0.11058193445205688,
        0.048179347068071365,
        0.02066158503293991,
        -0.09392943233251572,
        0.03851354867219925,
        0.09440268576145172,
        -0.013493743725121021,
        0.015147959813475609,
        -0.08752436190843582,
        0.021648677065968513,
        -0.026707181707024574,
        -0.034599971026182175,
        0.10847773402929306,
        0.03095843829214573,
        0.02400004118680954,
        0.051728565245866776,
        -0.01859198324382305,
        -0.044367481023073196,
        -0.03383396565914154,
        0.1310991793870926,
        -0.03380174934864044,
        0.0047189644537866116,
        0.024414297193288803,
        -0.03303098678588867,
        -0.00448412261903286,
        -0.01677069626748562,
        -0.008336175233125687,
        0.06895212829113007,
        -0.0006457799463532865,
        -0.006238542031496763,
        -0.044972486793994904,
        0.09184873104095459,
        -0.0038922724779695272,
        -0.01607460528612137,
        0.09316354244947433,
        -0.009337125346064568,
        -0.02844785712659359,
        -0.05179786682128906,
        -0.004040610510855913,
        -0.02286464162170887,
        -0.10058198124170303,
        0.012816756032407284,
        -0.030828533694148064,
        0.07863987982273102,
        0.019052287563681602,
        0.02431708760559559,
        -0.06357346475124359,
        0.030255427584052086,
        -0.002550209639593959,
        0.03576516732573509,
        0.05048515275120735,
        0.005206721369177103,
        -0.05755965784192085,
        0.004828885197639465,
        0.06677833199501038,
        0.07248891890048981,
        -0.014861413277685642,
        -0.07966624945402145,
        -0.005056231748312712
      ],
      "metadata": {
        "title": "Paper_1_Sleep_Staging_from_Electrocardiography_and_Respira.pdf",
        "createdAt": "2025-12-17T13:56:37.262Z"
      },
      "fileObj": {}
    },
    {
      "id": "doc_11_1765979798154",
      "fileName": "Paper_3_Fetal_Sleep__A_Cross_Species_Review_of_Physiology_.pdf",
      "content": "arXiv:2506.21828v1 [q-bio.NC] 27 Jun 2025  1  Fetal Sleep: A Cross-Species Review of Physiology, Measurement, and Classification  Weitao Tang, Johann Vargas-Calixto, Nasim Katebi, Robert Galinsky, Gari D. Clifford, Faezeh Marzbanrad  Abstract ‚ÄîFetal sleep is a relatively underexplored yet vital aspect of prenatal neurodevelopment. Understanding fetal sleep patterns could provide insights into early brain maturation and help clinicians detect signs of neurological compromise that   arise   due   to   fetal   hypoxia   or   fetal   growth   restriction. This   review   synthesizes   over   eight   decades   of   research   on the physiological characteristics, ontogeny, and regulation of fetal sleep. We compare sleep-state patterns in humans and large animal models, highlighting species-specific differences and the presence of sleep-state analogs. We review both invasive techniques in animals and non-invasive modalities in humans. Computational methods for sleep-state classification are also examined, including rule-based approaches (with and without clustering-based preprocessing) and state-of-the-art deep learn- ing techniques. Finally, we discuss how intrauterine conditions such as hypoxia and fetal growth restriction can disrupt fetal sleep. This review provides a comprehensive foundation for the development of objective, multimodal, and non-invasive fetal sleep monitoring technologies to support early diagnosis and intervention in prenatal care.  Index   Terms ‚ÄîFetal   Sleep,   Fetal   Behavioral   States,   Fetal Monitoring, Sleep Classification, Neurodevelopment  I. I NTRODUCTION  Sleep plays a crucial role in brain development, synap- tic   plasticity,   and   metabolic   regulation   [1],   [2],   [3].   In neonates and infants, consolidated sleep‚Äìwake cycles have been shown to support neurodevelopmental milestones and long-term cognitive outcomes [4], [5], [6], [7]. However, the nature and function of sleep before birth‚Äîduring fetal life‚Äîremain poorly understood. This lack of understanding poses a significant gap in prenatal care, as fetal sleep may reflect underlying brain maturation and help identify early signs of neurological compromise or neurodevelopmental disorders. Developing objective and non-invasive fetal sleep monitoring tools could empower clinicians to assess neu- rodevelopmental trajectories, detect early signs of complica- tions such as antepartum hypoxia or fetal growth restriction,  W. Tang is with the Department of Electrical and Computer Systems Engineering, Monash University, Melbourne, Australia. J. Vargas-Calixto is with the Department of Biomedical Informat- ics, Emory University, Atlanta, USA. N. Katebi is with the Department of Biomedical Informatics, Emory University, Atlanta, USA. R. Galinsky is with the Ritchie Centre, Hudson Institute of Med- ical Research, and the Department of Obstetrics and Gynaecology, Monash University, Melbourne, Australia. G. D. Clifford is with the Department of Biomedical Informatics, Emory University, Atlanta, USA, and also with the Department of Biomedical Engineering, Georgia Institute of Technology, Atlanta, USA. F. Marzbanrad is with the Department of Electrical and Computer Systems Engineering, Monash University, Melbourne, Australia. Research reported in this publication was supported in part by the National Institutes of Health through the Fogarty International Center and the Eunice Kennedy Shriver National Institute of Child Health and Human Development (Grant R01HD110480), by the Google.org AI for the Global Goals Impact Challenge Award, and by the National Health and Medical Research Council (NHMRC) of Australia (Grants 1124493 & 1164954). N.K. is partially supported by a PREHS-SEED award (Grant K12ES033593).  and implement timely interventions to improve perinatal outcomes. Although adult human sleep has been well studied over the past decades, the origins of sleep and circadian rhythm research date back to 1729. Jean-Jacques d‚ÄôOrtous de Mairan observed that the leaves of Mimosa pudica continued their daily opening and closing cycles even in constant dark- ness [8], providing the first scientific evidence of an endoge- nous biological clock. Building upon this, early physiological studies in humans were initiated by John Davy, who in 1845 systematically measured body temperature fluctuations across the sleep-wake cycle and suggested a relationship between temperature rhythms and rest [9]. Research on brain activity during sleep dates back nearly a century. In 1924, German psychiatrist Hans Berger success- fully recorded the first human electroencephalogram (EEG), he published his landmark findings in 1929, providing the first objective evidence of brain wave activity during sleep and wakefulness [10]. Loomis et al. recorded electrical ac- tivity from the human cerebral cortex and reported rhythmic variations in brain potentials influenced by mental activity, external stimuli, emotional states, and sleep in their 1936 study,   ‚ÄúElectrical   Potentials   of   the   Human   Brain‚Äù   [11]. However, systematic sleep studies can be considered to have begun in the 1950s, when Kleitman and Aserinsky discovered rapid eye movement (REM) sleep in humans [12]. Their 1953 landmark study demonstrated that REM episodes were associated with vivid dreams, marking the first clear differentiation between REM and non-rapid eye movement (NREM) sleep. By 1957, further studies estab- lished cyclic variations in EEG during sleep, confirming that REM sleep recurs in predictable cycles throughout the night [13]. Stemming from the seminal work of Rechtschaffen and Kales [14] and others in the 1960s, sleep staging criteria became standardized in adults. However, the earlier we look into human development, the less we understand about sleep. In particular, fetal sleep remains one of the least understood stages due to significant technical and ethical challenges associated with studying the developing brain in human fetuses. As a result, there have been disagreements regarding how to classify fetal neurobehavioral states. Nevertheless, as we discuss in this article, these states phenotypically display characteristics of REM and NREM sleep, and are therefore best referred to as fetal sleep states, which can provide valuable insights into neurodevelopment. In parallel, fetal sleep studies emerged during the 1950s and 1960s. Early research primarily focused on fetal heart rate patterns and behavioral states, laying the groundwork for later investigations. In 1967, studies focusing on the relationship of intrauterine fetal activity to maternal sleep [15] and evidence of fetal-sleep cycles [16] examined fetal movements in relation to maternal sleep, suggesting that distinct sleep cycles may exist in utero. The 1970s marked a significant shift, as technological advancements allowed\n\n2  for more precise monitoring of fetal brain activity in large animal models such as sheep and calves. A pivotal advance came in 1971, when Ruckebusch systematically recorded alternating high-voltage slow activity and low-voltage fast activity in fetal lambs and calves, associating high-voltage slow activity with NREM sleep and low-voltage fast activity with REM sleep or alert wakefulness [17]. His work laid the foundation for interpreting fetal EEG activity in relation to behavioral states. Building upon this, a 1974 study confirmed the presence of EEG-based fetal sleep stages and linked them to cardiovascular regulation in fetal sheep [18]. Further validation came in 1977, as alternating high-voltage slow activity and low-voltage fast activity states were again ob- served in fetal lambs, reinforcing their similarity to neonatal and adult sleep patterns [19]. Finally, a 1979 study on human fetuses identified short-term cyclic patterns of fetal activity [20], supporting the hypothesis that early sleep-wake cycles emerge before birth. A major conceptual breakthrough occurred in 1982, when Nijhuis et al. introduced the fetal behavioral states (FBS) framework [21]. This classification system defined distinct fetal states based on physiological and behavioral markers, drawing parallels between fetal and neonatal behavioral state patterns [21]. Nijhuis further expanded the framework in a 1986 study [22], providing a more detailed characterization of these states and their relevance to neurodevelopment and clinical assessments [22]. These findings confirmed that human fetuses exhibit four behavioral states (1F to 4F), analogous to neonatal states [21], [22]. States 1F and 2F correspond to quiet (NREM-like) and active (REM-like) sleep, respectively, while 3F is characterized by continuous eye movements without body movement, and 4F by vigorous body activity with unstable heart rate [22]. Fetal breathing, heart rate, and movement patterns were shown to serve as key indicators of neurodevelopment [22]. These insights reinforced the potential of FBS as a clinical tool for assessing fetal brain function and detecting potential developmental abnormalities [22]. Despite extensive behavioral classifications such as the FBS framework [21], the presence of true wakefulness in the   fetus   remains   controversial.   In   sheep,   baboons,   and humans alike, episodes of increased activity or arousal- like features often lack the sustained neural and behavioral markers associated with postnatal wakefulness [23], [24], [25]. Some have suggested that the apparent wakefulness state reflects a transitional phase between sleep states, similar to indeterminate sleep in the newborn [1], rather than true wakefulness [23]. This will be discussed in more detail later in the paper. These foundational studies laid the groundwork for mod- ern research, which continues to refine our understanding of fetal sleep across different species. However, despite eight decades of progress, there remains no comprehensive literature review that systematically integrates findings on fetal sleep physiology, measurement, classification, and dis- ruption under pathological conditions. To address this gap, we synthesize and structure the state of the art in fetal sleep research. Specifically, we:  ‚Ä¢   synthesize fetal sleep research across humans, sheep, and baboons, highlighting species-specific similarities and differences in sleep ontogeny and physiology;  ‚Ä¢   compare measurement modalities, ranging from inva- sive techniques in animal models to non-invasive ap- proaches in human studies;  ‚Ä¢   review classification methods used to identify sleep states, spanning rule-based approaches‚Äîsome of which incorporate multimodal signal integration‚Äîand recent advances in state-of-the-art deep learning; and  ‚Ä¢   examine how abnormal intrauterine conditions such as hypoxia and fetal growth restriction disrupt fetal sleep development and expression. By bridging physiology, engineering, and clinical rele- vance, this review provides a foundation for future work in fetal neurodevelopment and the advancement of objective, fetal sleep-state monitoring tools. II. B ACKGROUND ON   S LEEP  A. The Nature of Sleep  Sleep is a fundamental biological process characterized by altered consciousness, reduced responsiveness to external stimuli, and decreased physical activity [26]. It is broadly classified into two main phases: NREM and REM [27]. These phases alternate cyclically and are regulated by both circadian rhythms and homeostatic sleep pressure [27]. In adults, NREM sleep is subdivided into three stages: N1 (Stage 1) light sleep, N2 (Stage 2) intermediate sleep, and N3 (Stage 3) deep sleep or Slow-Wave Sleep (SWS). A typical adult sleep cycle progresses through N1   ‚Üí   N2   ‚Üí  N3   ‚Üí   N2   ‚Üí   REM [28], repeating every 90 minutes for 4‚Äì6 cycles per night [29]. REM sleep is characterized by rapid eye movements, skeletal muscle atonia, and dreaming. It is a paradoxical state due to its wake-like EEG (low amplitude, mixed frequency) combined with high arousal threshold and lack of muscle tone [30], [31], [32]. Ontogenetically, REM is the dominant state in neonates and gradually declines with age [33], [34], [35]. This high proportion suggests a crucial role in brain maturation. REM- related muscle twitches are now believed to serve as sensory feedback signals that help the developing brain refine motor maps and connectivity [36]. This ontogenetic role highlights the fundamental contribution of REM sleep to early-life brain development [37]. As reviewed by Peever and Fuller (2017), REM sleep exhibits substantial interspecies diversity [37]. While ter- restrial mammals and birds generally display well-defined REM features, marine mammals such as dolphins appear to lack many classical characteristics, including rapid eye movements, cortical EEG desynchronization, skeletal muscle atonia [38], [39]. REM sleep may serve species-specific adaptive functions. Two main hypotheses have been pro- posed to explain interspecies variation in REM sleep. The energy allocation hypothesis posits that REM sleep con- serves energy by suspending thermoregulation during this state, while the ontogenetic hypothesis suggests that REM sleep supports neural development and plasticity, particularly in altricial species [36].  B. The Significance of Fetal Sleep  Fetal sleep is essential for neurodevelopment, supporting the maturation of both the central (CNS) and autonomic nervous systems (ANS) [33], [40], [41], [6], [42], [43], [44]. Cycling through distinct FBS promotes synaptogenesis, brain plasticity, and neuronal differentiation, contributing to postnatal cognitive and behavioral development [45], [6]. Unlike postnatal sleep, fetal sleep is defined by physiological\n\n3  markers such as heart rate variability (HRV), body move- ments, and EEG (in animal models), rather than behavioral reports [6], [46], [47]. The emergence of distinct FBS such as quiet and active sleep during the third trimester has been interpreted as a sign of increasing functional brain complexity, driven by coordinated neural activity across developing circuits [48], [6], [49]. This maturation is paralleled by the progressive development of the ANS, which plays a key role in sup- porting physiological regulation during fetal life [42], [43], [40]. In particular, the vagus nerve‚Äîa central component of the parasympathetic system‚Äîhas been implicated in vital processes such as anti-inflammatory signaling and metabolic regulation across fetal, perinatal, and postnatal periods [50], [51]. From around 25 weeks of gestation, increasing vagal tone and myelination have been reported [43], [52], [53], potentially contributing to the regulation of heart rate and state-dependent behaviors. As such, the emergence of dis- tinguishable sleep states in the third trimester‚Äîdetectable via patterns of fetal heart rate, eye movements, and body activity [21]‚Äîmay reflect both neural and autonomic matu- ration. REM-like   sleep   is   characterized   by   spontaneous   fetal movements, including fetal breathing movements (FBM), which are thought to play a critical role in preparing vital systems for postnatal life [54]. When fetal movements are pharmacologically suppressed‚Äîsuch as through anesthesia or neuromuscular blockade‚Äîthere is a marked reduction in oxygen consumption [55], suggesting that fetal activity itself significantly contributes to metabolic demand. While this observation does not directly implicate REM sleep in energy conservation, it highlights the physiological cost of fetal activity and the potential adaptive role of sleep states in regulating energy expenditure. Moreover,   FBM‚Äîoften   observed   during   REM-like states‚Äîare   believed   to   contribute   to   lung   growth   and maturation.   Disruption   of   these   movements,   whether experimentally   or   in   pathological   conditions   such   as prolonged   oligohydramnios,   can   result   in   pulmonary hypoplasia   [56],   [57],   [58],   [59],   [60],   [61].   Although these   disruptions   are   not   exclusive   to   REM   sleep,   the strong   association   between   FBM   and   REM-like   states suggests that fetal sleep behavior may indirectly support pulmonary development. Altogether, these findings imply that FBS contribute not only to neurodevelopment, but also play a broader role in maintaining metabolic balance and promoting organ system maturation [49].  C. Current Research Status and Gaps  Advances in fetal monitoring techniques have enabled detailed characterization of sleep states using EEG, integrat- ing electrocardiogram (ECG), and HRV analysis [62], [63]. Non-invasive methods such as fetal magnetoencephalogra- phy (FMEG) complement traditional measures by providing insights into fetal cortical activity [64]. Current research has primarily focused on automated classification of fetal sleep states based on heart rate and movement patterns [65], [66]. Studies have also explored EEG-based analysis of REM and NREM sleep across species [47], [67]. Additionally, researchers have investigated neural and autonomic markers of fetal brain maturation through spectral EEG and HRV analysis [68], [62], and recent studies have also evaluated EEG spectral power and sleep state cycling to assess matu- ration after hypoxia‚Äìischaemia in fetal sheep [69]. Despite   these   advancements,   significant   research   gaps remain. The mechanisms linking fetal sleep disruptions to neurodevelopmental disorders are still poorly understood. Current   measurement   techniques   are   limited,   relying   on indirect and intermittent measurements fetal movement, heart rate variability and breathing to infer fetal sleep and be- havioral states. Furthermore, cross-species comparisons lack standardization, making it difficult to generalize findings from animal models to human fetal development. III. P HYSIOLOGICAL   C HARACTERISTICS OF   F ETAL  S LEEP  A. Historical Background: Discovery of Fetal Sleep States  The scientific understanding of fetal sleep has evolved since the late 20th century. Nijhuis et al. first proposed a systematic classification of fetal behavioral states in the early 1980s based on physiological rhythms and movement patterns [21], followed by studies linking these states to fetal heart rate variability and motor activity [70], [22]. These findings suggested that sleep-wake regulation begins before birth. More recent advances in non-invasive fetal monitoring, including transabdominal fetal electrocardiography (FECG) and fetal magnetocardiography (FMCG), have confirmed the presence of sleep-like cycles in third-trimester human fetuses through heart rate variability analyses [71], [66]. Cross-species   investigations   have   further   strengthened the   concept   of   prenatal   sleep   organization.   In   fetal sheep,   intrauterine   polygraphic   recordings‚Äîincluding EEG,   electrooculography,   and   nuchal   electromyogra- phy‚Äîdemonstrated   a   developmental   transition   from disorganized to structured behavioral states around 115‚Äì120 days of gestation (approximately 80% of term) [45]. These recordings revealed alternating episodes of quiet sleep, REM sleep, and arousal, resembling adult-like sleep architecture and implying an early onset of sleep-wake regulation in utero. Similarly, studies in fetal baboons during the early 1990s   identified   EEG   patterns   indicative   of   both   REM and NREM sleep, which closely resembled those seen in preterm human infants [72], [73]. Together, these findings suggest that core aspects of fetal sleep-state differentiation are conserved across species with relatively mature central nervous systems at birth. Together, human and animal studies show that fetal sleep states   emerge   prenatally   and   follow   species-specific   yet evolutionarily conserved patterns. The next section examines sleep-state classification across species.  B. Fetal Sleep Cycle in Different Species  Since direct recordings of fetal EEG and other neural activity are not feasible in humans, many fetal sleep stud- ies rely on animal models [54], [74]. Understanding the similarities   and   differences   between   species   is   therefore crucial for interpreting these findings and assessing their relevance to human development. Comparative studies across species provide insights into how fetal sleep develops and its evolutionary significance. Fetal sheep and baboons are widely used models for study- ing sleep state maturation due to their well-characterized sleep architecture and physiological similarities to humans [75], [74], [76], [77], [67], [78], [79]. For example, fetal\n\n4  TABLE I C OMPARISON OF   G ESTATIONAL   L ENGTH AND   B IRTH   W EIGHT  A CROSS   S PECIES  Species (Fetus)   Gestation Length   Birth Weight (kg)  Human   37‚Äì41 weeks (259‚Äì294 days) [80] 3.02‚Äì3.80 [64] Sheep   20‚Äì22 weeks (145‚Äì150 days) [81],   [18],   [82],   [45],   [77], [75] 3.50‚Äì5 [81], [83] Baboon   25‚Äì26 weeks (175‚Äì180 days) [73], [72] 0.46‚Äì0.90 [84], [72]  Note: Reported ranges are for illustrative reference and may vary across studies.  sheep exhibits a transition from disorganized to structured sleep patterns around 80% gestation, mirroring human fetal sleep development at approximately 32-36 weeks gestation [21]. To better compare the sleep states of different species, we first take a deeper look at gestational length and birth weight, as shown in Table I. From Table I, we observe that sheep fetuses have a higher birth weight than human fetuses, while baboon fetuses are the lightest. Interestingly, this pattern does not follow the order of gestational length: human fetuses have the longest gestation (37‚Äì41 weeks), baboons fall in between (25‚Äì26 weeks), and sheep have the shortest (20‚Äì22 weeks). This dis- sociation between gestation length and birth weight suggests that longer gestation may not be solely for somatic growth. Instead, it may reflect species-specific neurodevelopmental priorities. In humans, for instance, the prolonged gestation supports a brain growth spurt that begins in mid-gestation and extends well into early postnatal life, enabling greater cortical and synaptic development [85]. This implies that cerebral complexity, rather than body weight, may better explain interspecies differences in gestation length‚Äîat least among medium-sized mammals. Moreover, human fetal birth weight   is   influenced   by   factors   such   as   fetal   sex   [86], maternal weight [2], and gestational diabetes [80], while such influences have not been extensively studied in sheep or baboon models. Comparison of sleep state development across species is summarized in Table II. This table outlines key develop- mental milestones‚Äîranging from the onset of physiological rhythmicity to the emergence and maturation of distinguish- able sleep states‚Äîin humans, sheep, and baboons. Among the three species, fetal sheep appear to exhibit organized sleep states earliest, with REM/NREM-like dif- ferentiation observable as early as 79% of gestation. Fetal baboons also show distinct REM- and NREM-like cycling by 82‚Äì87% of gestation, although data are limited to a narrow gestational window and lack a comprehensive developmental trajectory. In contrast, humans typically show consistent REM/NREM differentiation only after 90% of gestation, suggesting a relatively delayed maturation process. These cross-species comparisons provide insight into sleep state ontogeny; however, differences in methodology, avail- able data, and sampling windows, particularly in the fetal baboon limit direct comparisons. The table should therefore be interpreted as an approximate alignment across species rather than a definitive staging framework.  C. Comparison of Sleep-like States Across Species  FBS are broadly classified into sleep-like states (REM and NREM), transitional or indeterminate states, and potential wakefulness. However, the nature and classification of fetal wakefulness remain a subject of debate. This section com- pares sleep patterns in fetal sheep, baboons, and humans based on available research.  1) Sleep-like States:   All three species exhibit two primary sleep-like states: Quiet sleep and Active sleep. In fetal sheep, Quiet sleep is characterized by high-voltage low-frequency EEG, the absence of REMs, and variable nuchal muscle tone [45], [89]. Active sleep in fetal sheep is distinguished by a low-voltage high-frequency EEG pattern, the presence of REM, and a background of absent sustained nuchal muscle tone, often interspersed with phasic muscle contractions and breathing movements [45], [90].  TABLE II C OMPARISON OF   S LEEP   S TATE   D IFFERENTIATION   A CROSS   S PECIES  Sleep State Differentiation   Human Fetus   Sheep Fetus   Baboon Fetus  Initial Physiological Rhythmicity   80‚Äì90% of gestation: FHR, eye, and body movements cycle inde- pendently; chance overlaps lack the synchrony   and   stability   required for true behavioral states [21]. 79‚Äì83%   of   gestation:   35.1   ¬± 2.5% NREM, 52.7 ¬± 2.4% REM, 11.2   ¬±   1.7%   Wake   like   activ- ity were observed, marking the transition   from   disorganized   to organized behavioral states. [45] 78‚Äì86% of gestation: EEG power and coherence cycles (1h) observed in fetal baboons, even in the absence of full behavioral state measures, may reflect early sleep-like rhythmicity [78] REM/NREM Differentiation   90‚Äì95% of gestation: In most fe- tuses, heart rate, movement, and eye activity are only partially syn- chronized, preventing reliable state classification. [21] 83‚Äì90%   of   gestation:   38.4   ¬± 1.6% NREM, 49.9 ¬± 1.7% REM, 11.8 ¬± 1.6% Wake like state [45] 82‚Äì87%   of   gestation:   20.9%   NREM, 58.3% REM, 20.9% Transition [87] Emergence of Stable Behavioral States   95%   of   gestation:   NREM:   32% (range:   9‚Äì53.5%)   REM:   42.5% (range:   23‚Äì64%)   Wake-like   state (combined   3F   and   4F):   14.75% (range: 6.5‚Äì33%) No state identi- fied: 11.5% (range: 3‚Äì53.5%) [21] 90‚Äì97%   of   gestation:   38.2   ¬± 1.8% NREM, 46.1 ¬± 2.0% REM, 15.1 ¬± 1.9% Wake like state [45] 82‚Äì87%   of   gestation:   36.8%   NREM, 63.2% REM [88] Full Maturation of Sleep Cycles   99%   of   gestation:   NREM:   38% (range: 24.5‚Äì52.5%) REM: 42.5% (range: 22‚Äì73.5%) Wake-like state (combined   3F   and   4F):   13.5% (range: 2.5‚Äì38%) No state identi- fied: 5% (range: 0‚Äì26.5%) [21] 97‚Äì99%   of   gestation:   43.8   ¬± 2.5% NREM, 37.7 ¬± 2.8% REM, 18.3 ¬± 2.9% Wake like state [45] 73‚Äì90% of gestation: 48% NREM, 32% REM, 20% transition [84]\n\n5  Fig. 1.   Representative physiological signals illustrating sleep states in fetal sheep [91]. NREM sleep is marked by high-voltage (HV), low-frequency EEG patterns recorded from both hemispheres (L EEG and R EEG), whereas REM sleep is characterized by low-voltage (LV), high-frequency EEG activity. TR represents an intermediate state between REM and NREM, capturing the dynamic shift from one state to the other. This state typically exhibits mixed EEG features that do not fully conform to either REM or NREM characteristics. Additional signals include nuchal EMG, obtained from electrodes implanted in the fetal neck muscles, which reflects muscle tone and fetal movements. BA 1 denotes the raw intra-balloon pressure signal, capturing both the balloon inflation pressure and the ambient amniotic pressure. All signals were collected from fetal sheep using chronic invasive instrumentation, including surgically implanted EEG and EMG electrodes and an intra-amniotic balloon catheter, enabling continuous in utero monitoring of physiological and neural activity.  To better elucidate the physiological distinctions between NREM and REM sleep, we provide representative traces from our own fetal sheep recordings. These examples high- light characteristic differences in EEG, EMG, and intra- balloon pressure across behavioral states. As illustrated in Figure 1, these features are clearly distinguishable: green waveform segments correspond to quiet sleep (HV/NREM), red segments indicate active sleep (LV/REM), and black segments denote brief transition periods (TR). Similarly, fetal baboons display quiet and active sleep states. Quiet sleep is associated with trace alternant, a pattern of   intermittent   bursts   of   high-voltage   EEG   activity   also reported in other species such as fetal sheep, whereas active sleep exhibits an increased presence of high-frequency EEG components [72]. Fetal breathing is present in both sleep states but occurs more frequently in active sleep [73], a pattern consistent across species. The organization of these states resembles that of fetal sheep and humans. In humans, these two states are referred to as Quiet sleep (1F) and Active sleep (2F). Quiet sleep is characterized by infrequent fetal movement, stable fetal heart rate with low variability, and an absence of eye movements (EOG), akin to NREM sleep; whereas Active sleep, corresponding to REM sleep, involves frequent fetal body movements, continuous EOG, and a variable heart rate [22], [92].  2) Sleep Transitions and Indeterminate Sleep:   All three species‚Äîsheep, baboons, and humans‚Äîexhibit transitional or indeterminate fetal sleep states, reflecting the develop- mental complexity of sleep organization. In fetal sheep, these ambiguous states‚Äîoften termed inter- mediate sleep‚Äîare neither clearly REM nor NREM. Mellor (2005) linked them to immature brain regulation [23]. Quan- titative EEG studies identified two spectral intermediates, falling between high-voltage slow activity and low-voltage fast activity, as exemplified by the TR highlighted in black in Figure 1, accounting for   23% of recording time [93]. Rao et al. (2009) defined indeterminate sleep as transitional or mismatched EEG/EOG periods, excluded if under 3 minutes [94]. Such states may reflect neural transitions key to sleep maturation [95]. Fetal baboons also show EEG evidence of graded tran- sitions between quiet and active sleep. EEG-ratio analyses reveal sleep as a continuum, with up to 60% of time spent in indeterminate states [72], [84]. In humans, fetal sleep cycles last 70‚Äì90 minutes, with state transitions typically within 3 minutes [96], [97]. Inde-\n\n6  terminate states, defined by mismatched behavioral markers, occur in approximately 5‚Äì10% of recordings near term [21], suggesting lower prevalence compared to baboons.  3) Fetal   Arousal   and   Wakefulness:   The   definition   of arousal and wakefulness in the fetus remains contentious. In fetal sheep, brief periods of activity characterized by low- voltage electrocorticography (ECoG), EOG, and increased EMG activity have been interpreted as an aroused state [98], [99], [100], [101]. Nevertheless, accumulating evidence suggests that such episodes may merely reflect transitional phases between sleep states, rather than true wakefulness [23].   Direct   observations   of   unanaesthetized   fetal   sheep provide further evidence against the existence of true wake- fulness in utero. Rigatto et al. [24] observed a fetal sheep through a Plexiglas window for 5,000 hours and found no signs of wakefulness, such as eye opening or coordinated head movements. This suggests that fetal sheep remain in sleep-like states throughout gestation without experiencing a state that would be comparable to postnatal wakefulness. In fetal baboons, studies indicate that hiccups and gross fetal movements do not necessarily induce sleep-state tran- sitions, implying that fetal activity does not always equate to wakefulness [25]. Some researchers have suggested that fetal wakefulness, if present, is rare and might be a misclas- sification of state transitions [72]. In human fetuses, state 3F (quiet awake) is rarely ob- served,   and   state   4F   (active   awake),   though   defined,   is difficult to identify reliably due to obscured eye move- ments [21]. Some researchers suggest that fetal wakefulness may not exist in the same form as in neonates; episodes commonly interpreted as wakefulness could instead reflect transitions between sleep states [23]. As inferred from elec- trophysiological evidence, EEG activity during such periods may resemble spontaneous sleep-state transitions rather than sustained wakefulness [23]. The ability to intentionally wake the fetus is not well established. In fetal sheep, external stimuli such as ma- ternal hormone fluctuations influence fetal sleep patterns, but there is little evidence that these lead to wakefulness [77], [23]. In fetal baboons, experimental challenges such as hypoxia and auditory stimuli have been proposed to investigate   fetal   state   changes,   but   the   extent   to   which these lead to true wakefulness is unclear [25]. For human fetuses, vibroacoustic stimulation (VAS) has been studied as a method to elicit state transitions, but behavioral state organization remains largely resistant to external influences [102]. Nevertheless, early acoustic studies by Walker (1971) identified consistent intrauterine sound patterns originating from maternal cardiovascular activity, suggesting the fetal environment is shaped by rhythmic auditory input [103]. Moreover, term fetuses have been shown to display differen- tial heart rate responses to their mother‚Äôs voice compared to a stranger‚Äôs, indicating a capacity for auditory learning and in utero voice recognition [104]. Although factors such as maternal emotions, Braxton Hicks contractions, and uterine contractions during labor do not significantly alter fetal behavioral state patterns [102], these findings imply that specific types of auditory stimulation may modulate fetal physiology without necessarily inducing full wakefulness. All three species spend the majority of their time in sleep- like states, suggesting that fetal wakefulness, if it exists, is actively suppressed. In fetal sheep, mechanisms such as prostaglandin-mediated regulation and hypoxia-induced depression of breathing contribute to the maintenance of prolonged sleep-like states [77], [23]. Baboons exhibit a similar predominance of sleep-like states, with only brief transitions into undefined states [73]. In humans, the fetal nervous system appears to be adapted for continuous sleep- like states, with developing neuronal circuits reinforcing these patterns [105], [49]. Fetal sheep, baboons, and humans exhibit similar sleep- like states, though true wakefulness remains unclear. Tran- sitional states are frequent, and sleep organization matures with gestation. Across species, sleep state dominates with little evidence of sustained wakefulness before birth.  D. Maternal and External Factors  Maternal physiology and environmental conditions have been shown to influence fetal sleep states [64], [106]. Fetal sleep rhythms begin to develop in utero and are thought to be entrained by maternal melatonin and circadian cues [107]. Various factors, including maternal sleep position, circadian rhythms, sleep disorders, and external stressors, contribute to the regulation of fetal brain activity and be- havioral states. External stressors can also influence fetal sleep states. For example, hypoxia suppresses FBM and modifies EEG activity, a process likely mediated by elevated adenosine levels, which act as an inhibitory neuromodulator, and by increased neurosteroids such as allopregnanolone, which suppress neuronal excitation and protect the fetal brain [108], [109]. The position a mother adopts during sleep may affect FBS. Supine sleep is known to be associated with reduced uteroplacental perfusion, leading to fetal quiescence [64]. This reduction may be due to altered maternal cardiac output and uteroplacental perfusion, which transiently affect oxygen and nutrient delivery to the fetus, potentially influencing fetal sleep patterns and activity levels [110], [111], [112]. Late stillbirth is independently related to the position women adopt during sleep [64]. Vulnerable fetuses, who may already experience chronic hypoxia, have a reduced ability to adapt to maternal sleep position stressors [64]. Another study found that passive maternal movements, such as rocking or swaying, can alter fetal heart rate and potentially the behavioral states, likely through activation of the vestibular system [113]. Fetal sleep patterns are also closely linked to maternal circadian rhythms. Studies have shown that fetal sleep states align with maternal melatonin secretion and activity-rest cycles, indicating that maternal circadian rhythms play a role in regulating fetal brain activity [114]. Furthermore, maternal sleep-disordered breathing (SDB), such as sleep apnea, becomes more common in the third trimester and can disrupt the intrauterine environment by inducing noc- turnal hypoxia and heightened maternal autonomic activity. These changes have been associated with alterations in fetal physiological behaviors, including heart rate decelerations and reduced fetal breathing movements‚Äîboth of which are key indicators of fetal sleep states. While the precise impact on long-term neurodevelopment remains uncertain, these findings suggest that maternal SDB may acutely influence fetal sleep regulation [115], [116]. In summary, maternal physiological and environmental factors have significant effects on fetal sleep states through mechanisms involving hemodynamics, hormonal regulation,\n\n7  TABLE III C OMPARISON OF   F ETAL   S LEEP   M EASUREMENT   T ECHNIQUES  Measurement   Fetal Human (Non-invasive)   Fetal Sheep (Invasive)   Fetal Baboon (Invasive)  EEG/ECoG   Infeasible   Implanted electrodes [117], [93], [118]   Dural electrodes [67], [73], [72] EOG   Ultrasound imaging [119], [102]   Canthus electrodes [118], [45], [95]   Canthus electrodes [87], [84] EMG   Infeasible   Nuchal EMG [120], [121] Diaphragmatic EMG [122] Not Commonly used FHR   CTG [71], [65], [123] Abdominal ECG [124] Scalp ECG (Invasive) [125] FMCG [126], [127], [128], [129] Arterial pressure [120], [130] ECG [131] ECG electrodes [84] FBM   Ultrasound imaging [119], [102]   Tracheal catheter [132] Diaphragm EMG [133] Laryngeal EMG (PCA) [133] Tracheal catheter + amniotic subtraction [73], [25], [84] Body Movements   Actocardiogram [86], [129]   Limb EMG [45], [134] Ultrasound [135] Not Commonly used  and neural modulation. These factors collectively contribute to shaping fetal brain activity and behavioral states. IV. A CQUISITION OF   P HYSIOLOGICAL   S IGNALS IN THE  F ETUS  To understand fetal behavioral and sleep states, researchers have relied on both non-invasive technologies suitable for human fetuses and invasive modalities enabled by animal models such as fetal sheep and baboons. Table III summa- rizes the key measurement techniques across species. In the remainder of this section, we describe each modality in more detail, with a focus on signal types, acquisition methods, and the physiological information derived.  A. Non-Invasive Technologies for Human Fetus  In human fetal research, ethical and technical limitations necessitate the use of non-invasive techniques. These tech- nologies prioritize safety, cost-effectiveness, and practicality, while attempting to capture physiological signals linked to fetal behavioral states.  ‚Ä¢   Cardiotocography   (CTG) :   A   widely   used   method employing   1D   Doppler   ultrasound   to   monitor   fetal heart rate (FHR) and uterine contractions through the maternal abdomen [71], [65], [123]. CTG is low-cost and non-invasive [136], but it provides only a smoothed heart rate estimate rather than beat-to-beat intervals, limiting detailed HRV analysis [137], [138].  ‚Ä¢   FECG : Electrodes on the maternal abdomen record fetal cardiac signals, though maternal ECG interference often degrades signal quality [124]. A scalp electrode applied intrapartum offers improved fidelity but is in- vasive and limited to labor [125], [138].  ‚Ä¢   FMCG : A high-resolution modality that uses super- conducting   quantum   interference   devices   sensors   to detect fetal cardiac magnetic fields through the ma- ternal abdomen [126], [127], [128], [129]. It offers millisecond temporal resolution and is reported to be less susceptible to artifacts than FECG [139], but it is expensive and technically demanding.  ‚Ä¢   Ultrasound Imaging : Ultrasound is used to monitor fetal body and eye movements, amniotic fluid volume, breathing, and muscle tone [119], [102].  ‚Ä¢   Actocardiography :   Actocardiography   combines Doppler-derived FHR and movement data [86], [129], enabling richer behavioral state characterization [66].  B. Invasive Technologies in Animal Models  Several fetal monitoring techniques used in humans, in- cluding FECG and FMCG, are also employed in animal models. In particular, fetal sheep and baboons enable the use of invasive methods that offer high-resolution, direct physiological measurements. These modalities facilitate a more granular analysis of fetal sleep and behavior, including electrocortical activity, eye movements, respiration, muscle tone, and cardiovascular dynamics.  ‚Ä¢   EEG/ECoG : Electrodes implanted on or beneath the fetal   skull   record   electrocortical   activity.   In   sheep, stainless-steel   screws   and   solder-ball   electrodes   are used [117], [93], [118], [147]; in baboons, electrodes are placed on the dura mater [67], [73]. Signals are filtered (0.1‚Äì40 Hz or up to 100 Hz) and digitized at 50‚Äì200 Hz [130], [78]. Sleep states are differentiated by power spectral analysis: quiet sleep shows 1‚Äì4 Hz bursts (Trace Alternans), while active sleep exhibits elevated 12‚Äì24 Hz power [72]. Common measures include spectral edge frequency (SEF) and EEG-ratio (0.03‚Äì0.2 Hz vs. 12‚Äì24 Hz) [78], [82], [148].  ‚Ä¢   EMG : captures muscle activity via implanted electrodes and is used in fetal sheep to assess neuromuscular and respiratory activity. Limb EMG detects gross body movements through electrodes in muscles such as the quadriceps and triceps [45], [134], while nuchal EMG assesses muscle tone and sleep state transitions via electrodes in neck muscles [120], [121]. Diaphragmatic EMG reflects respiratory-related muscle activity and is used to detect FBM [122].  ‚Ä¢   EOG : detects eye movements through electrodes im- planted near the orbits (sheep) [118] or subcutaneously around the eye (baboons) [87].  ‚Ä¢   Respiratory Activity Monitoring : FBM are monitored invasively using pressure catheters or EMG electrodes. In sheep, a pressure catheter is placed in the fetal trachea to detect intrathoracic fluid shifts [132], while EMG electrodes can be sewn into respiratory muscles such as the diaphragm or posterior cricoarytenoid [133]. In baboons, tracheal and amniotic fluid pressures are measured with separate catheters to isolate breathing activity‚Äîa method also commonly used in fetal sheep studies [73], [25], [84]. Breathing is typically intermittent and linked to REM- like sleep, characterized by low-voltage ECoG [132]. These fetal breathing movements are essential not only\n\n8  TABLE IV C OMPARISON OF   EEG   AND   FHR F REQUENCY   B AND   D EFINITIONS   A CROSS   S PECIES  Signal Type   Fetal Human   Fetal Sheep   Fetal Baboon  EEG   Not available in fetal human stud- ies Delta   (0‚Äì3.9   Hz),   Theta   (4‚Äì7.9 Hz), Alpha (8‚Äì12.9 Hz), Beta (13‚Äì 22 Hz) [140], [91] Delta (1‚Äì4 Hz), Theta (4‚Äì7 Hz), Alpha   (8‚Äì12   Hz),   Beta1   (14‚Äì18 Hz), Beta2 (22‚Äì29 Hz) [78] FHR   VLF (0.02‚Äì0.08 Hz), LF (0.08‚Äì0.2 Hz), Intermediate (0.2‚Äì0.4 Hz), HF (0.4‚Äì1.7 Hz) [141], [142], [143] VLF (0‚Äì0.04 Hz), LF (0.04‚Äì0.15 Hz),   HF   (0.15‚Äì0.4   Hz)   [144], [145], [146] LF   (0.05‚Äì0.2   Hz),   HF   (0.5‚Äì2.0 Hz) [84]  for lung development but also for training the neural circuits that control respiration and for strengthening respiratory muscles in preparation for breathing after birth. Data are digitized at rates such as 25 Hz for waveform analysis [73].  ‚Ä¢   Cardiovascular Signal Acquisition : Fetal heart rate is derived from ECG, arterial pressure signals, or Doppler flow   probes   secured   onto   major   arteries.   In   sheep, ECG electrodes are implanted on the chest [131] or pressure waveforms are recorded via catheters in fetal arteries   [120], [130]. In baboons, ECG leads with silver solder balls are fixed beneath the skin over the precordium [84], [67].  C. Comparison of EEG and FHR Frequency Bands  Table IV compares EEG and FHR frequency band defi- nitions across fetal human, sheep, and baboon studies. This table highlights a key challenge in cross-species compar- isons: the frequency band boundaries, especially for EEG rhythms, vary considerably due to both biological differences and species-specific research conventions. For instance, delta and theta bands in fetal sheep span wider frequency ranges than in baboons. Similarly, the definition of FHR bands such as very low frequency (VLF) and high frequency (HF) also differs between species, which complicates the translation of findings from animal models to human contexts. Recogniz- ing these inconsistencies is essential for interpreting spectral analyses and designing cross-species comparative studies. V. A UTOMATIC   C LASSIFICATION OF   F ETAL   S LEEP  Fetal sleep classification has been explored using rule- based and deep learning approaches. Rule-based methods rely on expert-defined thresholds and logic rules, sometimes supported   by   clustering-based   preprocessing   such   as   K- means. In contrast, deep learning enables end-to-end, data- driven modeling from raw physiological signals. Table V summarizes key distinctions across these approaches. The following subsections detail each category, including recent developments in multimodal signal integration.  A. Fetal Heart Rate Variability Analysis 1) Physiological Basis of FHRV in Sleep:   Sleep states in fetuses are associated with distinct changes in physiological parameters, prominently fetal heart rate variability (FHRV) [84], [68]. In humans, transitions between sleep states are reflected in changes in heart rate patterns, strongly corre- lating with behavioral states defined by heart rate, body movements, and eye movements [21]. Similar correlations have been observed in fetal baboons, where FHRV measures, combined with EOG and EEG data, have been successfully used to define behavioral state cycles [87]. High EEG-Ratio periods, indicative of quiet sleep, correspond to lower heart rates and reduced FHRV in fetal baboons [72], suggesting that ANS modulation of FHRV is influenced by sleep states [87]. In fetal sheep, physiological studies show distinct differ- ences in FHRV between sleep states. Quiet sleep is typically associated with lower beat-to-beat variability compared to active sleep, indicating varying ANS modulation [68].  2) Feature Extraction for Sleep Classification:   Feature extraction from FHRV typically relies on time-domain and frequency-domain measures derived from RR intervals. In fetal baboons, features such as the standard deviation of RR intervals (SD-RR) and the root mean square of successive differences (RMSSD) are computed on a minute-by-minute basis, provided that at least 90% of RR intervals are artifact- free [84]. In human fetal studies, SDNN, RMSSD, and per- mutation entropy have similarly been employed to classify sleep states [129]. In fetal sheep, frequency-domain spectral measures‚Äîsuch as low-frequency (LF), HF, and the LF/HF ratio‚Äîhave been used to differentiate FBS [68]. However, the interpretation of LF/HF as a marker of sympatho-vagal balance is controversial, as LF power reflects a combination of sympathetic and parasympathetic influences, and the ratio can be affected by non-neural factors such as respiration and heart rate [151].  B. Rule-based Approaches 1) Threshold-Based Classification Using FMCG and Ac- togram Signals:   Rule-based approaches for FBS classifica- tion typically rely on deterministic thresholds derived from physiological signals, such as HRV and actogram-based fetal movement data. These systems apply expert-defined rules to classify states by comparing extracted features with fixed thresholds. While these methods provide interpretable and practical solutions for assessing fetal sleep and wakefulness, they lack the flexibility to adapt to individual variability and gestational changes, limiting their robustness in real-world scenarios. In 2016, Vairavan et al. [65] developed an early automated pipeline for FBS classification using FMCG recordings from 39 fetuses between 30 and 38 weeks of gestation. They trans- lated Nijhuis criteria [21] into fixed-threshold rules based on fetal heart rate patterns and actogram-derived movements. The system demonstrated strong agreement with expert an- notations, particularly for quiet sleep (intraclass correlation coefficient (ICC) = 0.88), though performance declined for active sleep in later gestation (ICC dropped to 0.41). These findings suggest that while rule-based classification is feasi- ble with FMCG and CTG, behavioral complexity increases with maturation, potentially limiting such approaches. Building on Vairavan et al.‚Äôs work, Semeia et al. [63] refined rule-based FBS classification by introducing ges- tational   age-specific   distinctions.   Using   a   large   FMCG dataset,   they   separated   younger   ( < 32   weeks)   and   older\n\n9  TABLE V C OMPARISON OF   FBS C LASSIFICATION   S TUDIES  Study   Species   Sample Size Gestational Age Signals Used   Method   States Identified   Performance  Vairavan et al. (2016) [65] Human fetuses   39   30‚Äì38 weeks   FMCG   (HR   + Actogram) Rule-based thresholds + ROC optimization  < 36 wks: 1F vs. 2F  ‚â• 36 wks: 1F vs. 2F  < 36 wks: ICC = 0.88 (1F), 0.65 (2F)  ‚â• 36 wks: ICC = 0.88 (1F), 0.41 (2F) AUC = 0.99 (both) Semeia   et   al. (2022) [63] Human fetuses   52   27‚Äì39 weeks   FMCG   (HRV   + Actogram) Rule-based thresholds + ROC optimization  < 32 wks: Active vs. Passive  ‚â• 32 wks: 1F vs. 2F  < 32 wks: AUC   ‚âà   1.0 (HRV), 0.80‚Äì0.83 (Actogram)  ‚â• 32 wks: AUC   ‚âà   1.0 (HRV), 0.86‚Äì0.87 (Actogram) Myers   et   al. (1993) [72] Fetal baboons   3   143‚Äì153 days EEG   (frontal   + parietal) Rule-Based (K-means preprocessing) 1F vs. 2F   Expert agreement: 87.1% (Overall) 79.7% (1F), 91.3% (2F) Grieve   et   al. (1994) [87] Fetal baboons   3   80%‚Äì90% of term EEG, EOG, ECG   Rule-Based (K-means preprocessing) 1F vs. 2F   Expert agreement: 81.5% (Overall) 83.7% (1F), 79.4% (2F) Samjeed (2022) [149] Human fetuses   105   20‚Äì40 weeks   Non-invasive fetal   ECG   (NI- fECG) 1D CNN   1F vs. 2F   F1: 80.2% (1F), 69.5% (2F) Accuracy: 76% Sensitivity: 72.7% (1F), 82.6% (2F) Subitoni (2022) [150] Human fetuses   115   27‚Äì39 weeks (grouped: early/mid/late) FHR   HMM   +   CNN   (Hy- brid) 1F vs. 2F   HMM+CNN:  F1: 87.87%, Balanced Acc: 88.37%  HMM only:  F1: 77.73%, Balanced Acc: 83.30%  ( ‚â• 32 weeks) fetuses and adapted the classification accord- ingly‚Äîdistinguishing active/passive states in early gestation and 1F/2F states later. Their results showed that HRV-derived parameters, especially RMSSD and standard deviation (STD) of HR, achieved near-perfect classification accuracy (AUC  ‚âà   1.0), while actogram-based features were less reliable. These findings reinforce the utility of HRV metrics for FBS classification and highlight the need for developmental stage- specific models. Both studies demonstrated that rule-based approaches can achieve high classification accuracy for prototypical FBS, but their reliance on fixed thresholds restricts their adaptability across different gestational ages and individual variations. The absence of a temporal component in these models makes it difficult to capture transitional states that naturally occur as fetal development progresses. Moreover, rule-based meth- ods do not account for probabilistic uncertainty, potentially leading to overconfidence in misclassified instances. Semeia et al. [63] identified a key limitation of rule- based methods: substantial overlap in parameters between quiet and active sleep, which hampers accurate classifi- cation‚Äîespecially during transitional phases with gradual physiological changes. This suggests such methods may oversimplify the complex dynamics of FBS. As shown in Table V, Vairavan et al. [65] and Semeia et al. [63] achieved good results using FMCG, but did not assess generalizability to more accessible modalities like CTG. Their methods also struggle with fetal state transitions and individual variability, highlighting the need for more advanced probabilistic and machine learning approaches.  2) Rule-Based   Classification   Using   K-means   and EEG/Multimodal Signals:   Unsupervised clustering methods have been explored for FBS classification, particularly using K-means applied to spectral EEG features. Myers et al. [72] proposed an early rule-based method using fetal baboon EEG data.   They   developed the   ‚ÄúEEG-Ratio‚Äù   defined as the power in the 0.03‚Äì0.2 Hz band (associated with trace alternant) divided by power in the 12‚Äì24 Hz band. This feature   correlated   with   visually   scored   sleep   states,   and K-means clustering was applied to classify data into two binary states: trace alternant (TA, representing quiet sleep) and   non-TA   (active   sleep).   The   resulting   classification achieved an 87.1% agreement with expert scoring. However, the study had limitations. It included only three fetal baboons, each contributing four EEG recordings, to- taling 3,694 minutes of usable data. The authors did not use any form of cross-validation or independent testing, as thresholds were optimized and validated on the same dataset, potentially inflating accuracy estimates. Moreover, the EEG-Ratio‚Äîbeing a scalar feature‚Äîmay not generalize well across subjects or conditions. To improve robustness, Grieve et al. [87] extended this approach by integrating multimodal signals‚ÄîEEG, EOG, and ECG‚Äîfrom the same three fetal baboons, each recorded for 16 continuous hours. They applied K-means clustering to extract binary thresholds for three features: EEG ratio, EOG spectral power, and RR interval variability (CVRR). These features were then combined using rule-based cri- teria to define two sleep states: 1F (quiet sleep) and 2F (active sleep). Transitions and indeterminate states were also identified using temporal continuity rules. Agreement with expert annotations reached 81.5% overall (83.7% for 1F and 79.4% for 2F), demonstrating the feasibility of long-term, automated multimodal classification. While the use of multimodal features provided a more physiologically grounded framework, limitations remained, including small sample size, absence of gestational stratifi- cation, and no direct comparison with unimodal or machine learning-based models. Nonetheless, these early efforts laid the groundwork for automated fetal sleep state detection using interpretable, unsupervised approaches.\n\n10  C. Machine Learning Approaches  Deep learning has emerged as a powerful tool for classify- ing FBS from physiological signals. Two recent studies‚Äîby Samjeed et al. [149] and Subitoni et al. [150]‚Äîhave pro- posed deep neural network-based methods leveraging fetal ECG and FHR signals, respectively. Samjeed et al. [149] proposed a 1D convolutional neural network (1D-CNN) to classify fetal behavioral states from non-invasive   abdominal   ECG   recordings   of   105   fetuses (20‚Äì40 weeks gestation, 3‚Äì10 min duration). The CNN consisted of three convolutional layers and was trained using stochastic gradient descent with momentum (SGDM) with 5-fold cross-validation. It achieved 76% accuracy, with F1- scores of 80.2% for the quiet state and 69.5% for the active state, suggesting challenges in distinguishing between states. Limitations included dataset imbalance, lack of temporal modeling, and use of a single modality. Future directions included exploring recurrent neural networks (RNNs), mul- timodal inputs, and transfer learning. Subitoni et al. [150] proposed a hybrid model combining hidden markov models (HMMs) and a U-Net style 1D-CNN (U-Sleep variant) to classify fetal behavioral states from 115 manually annotated FHR recordings. The dataset was stratified into three gestational age groups (27‚Äì32, 33‚Äì36, 37‚Äì39 weeks) to account for developmental differences. The approach used HMMs for unsupervised segmentation to generate pseudo-labels, which were then used to pre-train a CNN. The model was subsequently fine-tuned using expert annotations. This two-stage training allowed the system to leverage both unlabeled and labeled data. The hybrid model achieved a Macro F1-score of 87.87%, outperforming   the   HMM   alone   (77.73%).   However,   the study did not clarify whether evaluation was subject-wise or sample-wise, and relied on annotations from a single expert, limiting generalizability. Still, the method demonstrates a promising strategy to reduce dependence on annotated data via hybrid learning. VI. E FFECTS OF   A BNORMAL   C ONDITIONS ON   F ETAL  S LEEP  A. Hypoxia  Hypoxia is a major disruptor of fetal sleep and neu- rodevelopment. Graded hypoxia experiments in fetal sheep have demonstrated significant disruptions in sleep states, including altered ECoG and behavioral activity [152], [68]. Koos et al. [152] reported that mild hypoxia did not alter the incidence of low-voltage ECoG activity, FBM, or REMs, whereas moderate and severe hypoxia markedly suppressed both FBM and REMs. A critical threshold was identified, with a reduction in arterial oxygen content of   2 . 00   ¬±   0 . 23  ml/dl associated with inhibition of both eye and breathing activity. Recent studies have further characterized hypoxia-induced brain dysfunction through temporal assessments of EEG power   and   frequency   recovery.   In   a   fetal   sheep   model of asphyxia, prophylactic creatine supplementation signifi- cantly improved EEG recovery after umbilical cord occlusion (UCO), with higher power and faster restoration of physio- logically organized frequencies, and reduced electrographic seizure burden. These effects were accompanied by reduced cortical cell death and white matter gliosis [153]. Moreover, integration   of   low-   and   high-voltage   EEG   activity   with nuchal EMG recordings provided detailed insights into sleep state reorganization under hypoxic stress. In contrast, while magnesium sulfate attenuated gliosis and modestly improved myelin density in white matter tracts, it failed to improve EEG power, frequency, or sleep-state cycling in preterm fetal sheep exposed to hypoxia‚Äìischemia. Neuronal and oligodendrocyte survival were similarly unaf- fected, suggesting limited functional neuroprotection despite some histological benefit [69]. Prolonged hypoxia in late gestation can cause persistent suppression of EEG activity and dysmaturation of sleep states. In preterm fetal sheep, UCO led to a shift towards lower frequency EEG activity for the first five days, with a lasting reduction in EEG power in the delta and theta bands [140]. Chronic hypoxia impairs gestational age-related increases in overall fetal HRV, with evidence of suppressed sympathetic nervous system control of HRV after 72 hours of hypoxia exposure [68]. Hypoxia alters fetal brain activity by promoting inhibitory neuromodulatory pathways, notably via elevated adenosine and increased neurosteroids such as allopregnanolone, re- sulting in predominant sleep-like EEG states [108], [109]. In parallel with these central nervous system effects, hy- poxia markedly reduces fetal forelimb movements and abol- ishes rapid eye movements, reflecting oxygen-conserving behavioral adaptations in fetal lambs [134]. These EEG changes   under   hypoxic   conditions   are   thought   to   result from adenosine-mediated inhibition and may suggest com- pensatory autonomic regulation [108]. Acute fetal hypoxia, induced by reduced uterine blood flow or UCO, suppresses FBM, a response associated with elevated adenosine levels in the brain under hypoxic conditions [154], [155], [156]. Severe hypoxia further leads to muscle atonia, as reported by Breen et al. [157]. Neurophysiological studies indicate that the fetal midbrain regulates episodic breathing and mediates hypoxic inhibition of respiratory activity [158]. Koos et al. [159] identified the parafascicular nuclear complex in the caudal thalamus as a critical structure mediating the suppres- sion of fetal breathing during acute hypoxemia. While this inhibition is an acute response, it is important to recognize that severe or prolonged hypoxemia may lead to cerebral ischemia and encephalopathy, potentially altering fetal EEG patterns even after the hypoxic insult has passed [160]. Hypercapnia during REM sleep enhances fetal breathing by increasing tracheal pressure and reducing apneic pauses, with CO 2   stimulation of breathing observed only during REM sleep in fetal lambs [161]. Neurophysiological studies indicate that the fetal midbrain regulates episodic breathing and mediates hypoxic inhibition of respiratory activity [158]. Koos et al. [159] identified the parafascicular nuclear com- plex in the caudal thalamus as a critical structure mediating the suppression of fetal breathing during acute hypoxemia. While this inhibition is an acute response, it is important to recognize that severe or prolonged hypoxemia may lead to cerebral ischemia and encephalopathy, potentially alter- ing fetal EEG patterns even after the hypoxic insult has passed [160].  B. Fetal Growth Restriction (FGR)  FGR disrupts the normal organization of fetal sleep states, particularly in late gestation. Growth-restricted fetuses ex- hibit greater sleep-state instability, often spending more time in quiet sleep than in active sleep [162], [163]. In addition,\n\n11  FGR is commonly associated with impaired oxygenation, reduced breathing and general movements, and an increased number of heart rate decelerations, reflecting ANS dysfunc- tion [164], [165]. FGR fetuses also show diminished motor activity, charac- terized by slower, monotonous, and lower-amplitude move- ments,   which   reflect   central   nervous   system   impairment [105], [166], [167]. These disturbances are considered late- stage indicators of fetal compromise, often preceded by abnormalities in HRV and blood flow parameters [105], [168]. Collectively, these findings highlight FBS as important indicators of neurodevelopment and fetal well-being.  C. Fetal Congenital Malformations  Structural or chromosomal abnormalities often correlate with altered fetal sleep states and reduced fetal movements (hypokinesia), linked to prolonged periods of low heart rate variability [169], [105], [168].  D. Other Maternal Conditions  Several maternal and fetal abnormalities influence fetal sleep patterns, directly or indirectly:  1) Maternal Diabetes:   Fetuses of diabetic mothers may show delayed sleep-state development between 32 and 40 weeks, often lacking the typical increase in quiet and active sleep seen in normal pregnancies [170].  2) Maternal Sleep Position:   In the third trimester, the maternal supine sleep position significantly impacts FBS, increasing the likelihood of a transition towards quiet sleep due to reduced uterine perfusion and oxygen availability [171]. Such adaptation might reflect a fetal compensatory mechanism for reduced oxygen supply [171], [64].  3) Maternal Anxiety and Stress:   Although explicit data on fetal sleep states remain limited, growing evidence highlights the significant impact of maternal psychological stress and anxiety on fetal development. Maternal self-reported anxiety has been associated with reduced expression of placental 11 Œ≤ -hydroxysteroid dehydrogenase type 2 (11 Œ≤ -HSD2), an enzyme critical for inactivating cortisol, thereby increasing fetal exposure to maternal glucocorticoids and potentially disrupting fetal neuroendocrine development [172]. Such endocrine   alterations   represent   one   of   the   physiological pathways suspected to contribute to the later emergence of psychological disorders [173]. Longitudinal   studies   have   elucidated   the   role   of   the pregnancy period in the intergenerational transmission of stress [174]. Prenatal stress exposure has also been asso- ciated with impaired fetal growth [175], and these growth alterations are further linked to subsequent behavioral traits, including   temperament   in   childhood   [176]   and   adoles- cence [177]. In addition to growth-related outcomes, maternal stress has been shown to directly alter the development of the fetal ANS. Specifically, maternal stress can entrain FHR patterns with maternal heart rate (HR) decelerations during respiratory efforts [178], and stressed mothers exhibit altered maternal-fetal HR coupling, characterized by significant de- creases in FHR, suggesting the presence of a fetal stress memory that may serve as a novel non-invasive biomarker of prenatal stress exposure [178]. Furthermore, recent evidence suggests that placental calcifications may reflect cumulative prenatal exposure to maternal stress and disease, potentially acting as a biological memory of the intrauterine environ- ment. These placental adaptations may influence offspring cardiovascular and metabolic health through modulation of fetal ANS development [179]. Collectively,   these   findings   imply   that   maternal   stress during pregnancy may have broad implications for fetal neu- robehavioral development, including pathways potentially relevant to the regulation of sleep states, autonomic function, and long-term health outcomes.  4) Alcohol   Consumption:   Alcohol   exposure,   even episodic, disrupts fetal REM sleep and drastically reduces fetal   breathing   activity,   potentially   leading   to   long-term neurobehavioral consequences characteristic of fetal alcohol syndrome (FAS) [97]. Such effects were demonstrated in a   controlled   study   where   maternal   consumption   of   two glasses of wine suppressed fetal REM activity and breathing movements [97]. These disruptions may underlie some of the neurobehavioral and ophthalmic deficits observed in FAS [105].  5) Smoking:   Smoking during pregnancy has been as- sociated with significant alterations in PE, reflecting dis- rupted autonomic regulation before birth [180], [181], [52]. Such autonomic disruptions may also suggest potential dis- turbances in fetal sleep-state organization, though specific sleep-related effects require further investigation.  6) Caffeine Intake:   Maternal caffeine consumption affects FBS organization, increasing general body movements and altering sleep-wake patterns, with a trend toward reduced breathing activity [182].  7) Magnesium Sulfate Administration:   Magnesium sul- fate reduces FBM [119] and has been reported to cause fetal bradycardia and diminished HRV, possibly through maternal hypothermia or direct fetal cardiac effects [183]. Recent studies in preterm fetal sheep further demonstrate that magnesium sulfate suppresses FHR, EEG activity, and increases cardiac afterload, all of which may influence fetal behavioural   states   [184],   [185],   [186].   In   addition,   sex- specific differences have been observed in EEG suppression and cardiovascular responses to hypoxia, suggesting that fetal sex may modulate the effects of pharmacological inter- ventions on fetal behaviour [186]. Additionally, concurrent use   of   magnesium   sulfate   and   nifedipine   may   result   in severe hypotension and cardiac depression in the fetus [187]. These effects may potentially impact FBS, although specific disruptions in sleep-related behaviors remain to be clarified.  8) Antidepressants:   Selective   serotonin   reuptake   in- hibitors are commonly prescribed to manage maternal anxi- ety and depression during pregnancy [188]. According to findings reported by Mulder et al. [189] and summarized in this chapter [105], fetal exposure to standard or high Selective serotonin reuptake inhibitors dosages was associated with increased general movements and disrupted NREM sleep near term, characterized by persistent bodily activity and impaired inhibitory motor control during quiet states. However, the significance of poor fetal sleep reg- ulation for postnatal neurobehavioral development remains unclear and warrants further investigation [105].  E. Intra-amniotic Infection (Chorioamnionitis)  Intra-amniotic infections, including clinical and subclini- cal chorioamnionitis, have been associated with loss of fetal heart rate cycling and adverse perinatal outcomes, supporting the role of inflammation in fetal behavioral dysregulation\n\n12  [190]. More recently, absence of fetal heart rate cycling has also been linked to maternal intrapartum pyrexia, with af- fected fetuses showing lower neonatal Apgar scores, further suggesting disruption in FBS organization [191]. As fetal heart rate cycling reflects the alternation between active and quiet sleep, these findings imply that intra-amniotic infection may disturb fetal sleep-wake cycling. Consistent with this, progressive   systemic   inflammation   in   late-gestation   fetal sheep leads to suppression of high-frequency EEG activity, particularly in the beta and gamma bands, which are believed to reflect cortical activation and sleep state transitions. These EEG alterations were sustained even after the resolution of inflammation, suggesting persistent disruption of fetal behavioral state cycling [147]. In conclusion, although specific evidence on the direct impact of these abnormalities on fetal sleep is limited, the observed disruptions in fetal movements, HRV and breathing patterns highlight potential implications for fetal sleep states. Understanding these links further emphasizes the importance of monitoring fetal sleep as a critical parameter in fetal surveillance. VII. F UTURE   D IRECTIONS AND   C HALLENGES  A. Limitations of Current Studies 1) Technological Limitations:   While current tools have advanced FBS research, technologies like ultrasound, CTG, and FMCG face limitations such   as low signal quality, motion artifacts, and limited applicability in early gestation. Fetal MRI provides better CNS insights but is costly and inaccessible. Overall, existing methods lack the resolution and scope to fully capture early fetal neurodevelopment and sleep transitions.  2) Analytical Challenges:   FBS detection often depends on visual inspection or algorithms trained on prototypical segments, overlooking transitional or ambiguous states that may offer important developmental insights. Inconsistent terminology across studies further hinders reproducibility and comparison. Most methods also fail to capture complex dynamics like diurnal rhythms or maternal-fetal interactions.  3) Sample   Size   and   Interindividual   Variability:   Small sample sizes limit the statistical power and generalizabil- ity   of   fetal   sleep   studies,   especially   in   linking   FHR   to biochemical markers. Variability across fetuses‚Äîdriven by gestational   age,   maternal   health,   and   environmental   fac- tors‚Äîcomplicates standardizing FBS classification. Broad gestational groupings (e.g., mid and late gestation) may mask critical developmental transitions.  4) Longitudinal and Genetic Considerations:   Links be- tween prenatal sleep and postnatal outcomes are limited by long assessment gaps and unaccounted genetic influences shared by mother and fetus. This highlights the need for integrated, genetically-informed longitudinal studies to better explain outcome variability.  B. Future Research Directions  To overcome current limitations, future research should explore advanced analytical tools‚Äîsuch as point process models and detailed HRV metrics‚Äîto uncover biomarkers of fetal brain and ANS development. Although fetal EEG is infeasible in humans, invasive recordings in animal mod- els (e.g., sheep, baboons) can inform the interpretation of non-invasive human data (e.g., FMEG, FMCG, coherence). Cross-modal integration of spatio-temporal and synchrony features may further elucidate fetal CNS maturation and sleep-state transitions. Improving automated FBS detection remains critical. Ma- chine   learning   models,   validated   against   tools   like   fetal MRI and synchronized physiological signals, can increase reproducibility and standardization. Establishing consistent terminology and definitions will also enhance model gener- alizability and cross-study comparability. To address small sample sizes and individual variability, transfer learning is a promising solution. Pretrained models on adult sleep data can be fine-tuned on fetal recordings, leveraging shared low-level features while adapting high- level patterns to fetal physiology. This reduces data demands and improves model robustness across gestational ages and maternal-fetal conditions. In addition, adult sleep data can be transformed to better match the spectral characteristics of fetal sleep data using signal processing or generative adver- sarial networks (GANs). Aligning spectral distributions in this way provides a more compatible source for fine-tuning, further enhancing transfer learning performance. Inspired by reinforcement learning, reward-guided fine-tuning based on physiological plausibility or expert preference can further improve adaptation across gestational stages. A multidisciplinary approach‚Äîlinking neuroscience, ob- stetrics, and neuroimaging‚Äîis essential. Longitudinal stud- ies from early gestation to infancy with continuous maternal- fetal monitoring can clarify developmental trajectories, espe- cially sleep-state transitions and maternal influences. Further exploration of vagal tone and ANS maturation may identify critical periods of vulnerability. Refining mea- surement tools through multimodal integration will be key to developing clinical guidelines for identifying fetuses at risk of autonomic or neurodevelopmental disorders. Ultimately,   a   comprehensive   perinatal   perspec- tive‚Äîrecognizing   bidirectional   maternal-fetal   interactions and   the   continuity   of   sleep-state   development‚Äîis   vital. Monitoring   fetal   sleep   may   enable   early   detection   of FGR,   chronic   hypoxia,   or   emerging   neurological   issues. Early intervention (e.g., optimized delivery, neuroprotective agents, maternal care) is crucial for improving long-term outcomes during this sensitive developmental window. R EFERENCES  [1] M. Mirmiran, Y. G. Maas, and R. L. Ariagno, ‚ÄúDevelopment of fetal and neonatal sleep and circadian rhythms,‚Äù   Sleep Medicine Reviews , vol. 7, pp. 321‚Äì334, Aug. 2003. [2] F. Cerritelli, M. G. Frasch, M. C. Antonelli, C. Viglione, S. Vecchi, M. Chiera, and A. Manzotti, ‚ÄúA review on the vagus   nerve   and   autonomic   nervous   system   during   fetal development: Searching for critical windows,‚Äù   Frontiers in Neuroscience , vol. 15, p. 721605, Sept. 2021. [3] P. Luu and D. M. Tucker, ‚ÄúContinuity and change in neural plasticity through embryonic morphogenesis, fetal activity- dependent synaptogenesis, and infant memory consolidation,‚Äù  Developmental Psychobiology , vol. 65, p. e22439, Dec. 2023. [4] M. Mirmiran, ‚ÄúThe function of fetal/neonatal rapid eye move- ment sleep,‚Äù   Behavioural Brain Research , vol. 69, pp. 13‚Äì22, July 1995. [5] M. Mirmiran, Y. G. Maas, and R. L. Ariagno, ‚ÄúDevelopment of fetal and neonatal sleep and circadian rhythms,‚Äù   Sleep Medicine Reviews , vol. 7, no. 4, pp. 321‚Äì334, 2003. [6] S. N. Graven and J. V. Browne, ‚ÄúSleep and brain develop- ment,‚Äù   Newborn and Infant Nursing Reviews , vol. 8, pp. 173‚Äì 179, Dec. 2008. [7] T. V. De Beritto, ‚ÄúNewborn sleep: Patterns, interventions, and outcomes,‚Äù   Pediatric Annals , vol. 49, Feb. 2020.\n\n13  [8] J.-J. d‚ÄôOrtous de Mairan, ‚ÄúObservation botanique,‚Äù in   Histoire de l‚ÄôAcad¬¥ emie royale des sciences, avec les m¬¥ emoires de math¬¥ ematique et de physique tir¬¥ es des registres de cette Acad¬¥ emie , pp. 35‚Äì36, Acad¬¥ emie Royale des Sciences, 1729. [9] J. Davy, ‚ÄúOn the temperature of man,‚Äù   Philosophical Transac- tions of the Royal Society of London , vol. 135, pp. 319‚Äì326, 1845. Read June 19, 1845. [10] H. Berger, ‚Äú ¬® Uber das elektroenkephalogramm des menschen,‚Äù  Archiv f¬® ur psychiatrie und nervenkrankheiten , vol. 87, no. 1, pp. 527‚Äì570, 1929. [11] A. L. Loomis, E. N. Harvey, and G. Hobart, ‚ÄúElectrical potentials   of   the   human   brain,‚Äù   Journal   of   experimental Psychology , vol. 19, no. 3, p. 249, 1936. [12] E. Aserinsky and N. Kleitman, ‚ÄúRegularly occurring periods of eye motility, and concomitant phenomena, during sleep,‚Äù  Science , vol. 118, no. 3062, pp. 273‚Äì274, 1953. [13] W. Dement and N. Kleitman, ‚ÄúCyclic variations in EEG during   sleep   and   their   relation   to   eye   movements,   body motility, and dreaming,‚Äù   Electroencephalography and Clin- ical Neurophysiology , vol. 9, no. 4, pp. 673‚Äì690, 1957. [14] A. Rechtschaffen and A. Kales, eds.,   A Manual of stan- dardized terminology, techniques and scoring system of sleep stages in human subjects .   Los Angeles: Brain Information Service/Brain Research Institute, University of California, 1968. [15] M. Sterman, ‚ÄúRelationship of intrauterine fetal activity to ma- ternal sleep stage,‚Äù   Experimental Neurology , vol. 19, pp. 98‚Äì 106, Dec. 1967. [16] O. Petre-Quadens, A. De Barsy, J. Devos, and Z. Sfaello, ‚ÄúSleep in pregnancy: Evidence of foetal-sleep characteristics,‚Äù  Journal of the Neurological Sciences , vol. 4, pp. 600‚Äì605, May 1967. [17] Y. Ruckebusch, ‚ÄúActivit¬¥ e ¬¥ electro-corticale chez le f≈ìtus de la brebis (Ovis aries) et de la vache (Bos taurus),‚Äù   Revue de M¬¥ edecine V¬¥ et¬¥ erinaire , vol. 122, pp. 483‚Äì510, 1971. [18] L. I. Mann, S. Duchin, and R. R. Weiss, ‚ÄúFetal EEG sleep stages and physiologic variability,‚Äù   American Journal of Ob- stetrics and Gynecology , vol. 119, pp. 533‚Äì538, June 1974. [19] Y. Ruckebusch, M. Gaujoux, and B. Eghbali, ‚ÄúSleep cycles and kinesis in the foetal lamb,‚Äù   Electroencephalography and Clinical Neurophysiology , vol. 42, pp. 226‚Äì237, Feb. 1977. [20] M. Granat, P. Lavie, D. Adar, and M. Sharf, ‚ÄúShort-term cy- cles in human fetal activity,‚Äù   American Journal of Obstetrics and Gynecology , vol. 134, pp. 696‚Äì701, July 1979. [21] J. Nijhuis, H. Prechtl, C. Martin, and R. Bots, ‚ÄúAre there behavioural states in the human fetus?,‚Äù   Early Human Devel- opment , vol. 6, pp. 177‚Äì195, Apr. 1982. [22] J. G. Nijhuis, ‚ÄúBehavioural states: Concomitants, clinical im- plications and the assessment of the condition of the nervous system,‚Äù   European Journal of Obstetrics & Gynecology and Reproductive Biology , vol. 21, pp. 301‚Äì308, May 1986. [23] D. J. Mellor, T. J. Diesch, A. J. Gunn, and L. Bennet, ‚ÄúThe importance of ‚Äòawareness‚Äô for understanding fetal pain,‚Äù  Brain Research Reviews , vol. 49, pp. 455‚Äì471, Nov. 2005. [24] H. Rigatto, M. Moore, and D. Cates, ‚ÄúFetal breathing and behavior measured through a double-wall plexiglas window in sheep,‚Äù   Journal of Applied Physiology , vol. 61, no. 1, pp. 160‚Äì164, 1986. [25] R. I. Stark and M. M. Myers, ‚ÄúBreathing and hiccups in the fetal baboon,‚Äù in   Fetal Development , pp. 51‚Äì65, Psychology Press, 2013. [26] N. Baranwal, K. Y. Phoebe, and N. S. Siegel, ‚ÄúSleep phys- iology,   pathophysiology,   and   sleep   hygiene,‚Äù   Progress   in Cardiovascular Diseases , vol. 77, pp. 59‚Äì69, 2023. [27] A. K. Patel, V. Reddy, K. R. Shumway, and J. F. Araujo, ‚ÄúPhysiology, sleep stages,‚Äù in   StatPearls [Internet] , StatPearls Publishing, 2024. [28] I. Feinberg and T. Floyd, ‚ÄúSystematic trends across the night in human sleep cycles,‚Äù   Psychophysiology , vol. 16, no. 3, pp. 283‚Äì291, 1979. [29] P. Memar and F. Faradji, ‚ÄúA novel multi-class EEG-based sleep stage classification system,‚Äù   IEEE Transactions on Neu- ral Systems and Rehabilitation Engineering , vol. 26, no. 1, pp. 84‚Äì95, 2017. [30] B. Jones, ‚ÄúParadoxical rem sleep promoting and permitting neuronal networks,‚Äù   Archives Italiennes De biologie , vol. 142, no. 4, pp. 379‚Äì396, 2004. [31] R. Boissard, D. Gervasoni, M. H. Schmidt, B. Barbagli, P. Fort, and P.-H. Luppi, ‚ÄúThe rat ponto-medullary network responsible for paradoxical sleep onset and maintenance: A combined microinjection and functional neuroanatomical study,‚Äù   European Journal of Neuroscience , vol. 16, no. 10, pp. 1959‚Äì1973, 2002. [32] M.-C. Xi, F. R. Morales, and M. H. Chase, ‚ÄúThe motor inhibitory system operating during active sleep is tonically suppressed by gabaergic mechanisms during other states,‚Äù  Journal of Neurophysiology , vol. 86, no. 4, pp. 1908‚Äì1915, 2001. [33] H. P. Roffwarg, J. N. Muzio, and W. C. Dement, ‚ÄúOntogenetic development of the human sleep-dream cycle: The prime role of ‚Äùdreaming sleep‚Äù in early life may be in the development of the central nervous system,‚Äù   Science , vol. 152, no. 3722, pp. 604‚Äì619, 1966. [34] M. S. Blumberg, A. M. Seelke, S. B. Lowen, and K. A. Karlsson, ‚ÄúDynamics of sleep-wake cyclicity in developing rats,‚Äù   Proceedings of the National Academy of Sciences , vol. 102, no. 41, pp. 14860‚Äì14864, 2005. [35] M.   S.   Blumberg   and   A.   M.   H.   Seelke,   ‚ÄúThe   form   and function of infant sleep: From muscle to neocortex,‚Äù in   Oxford handbook of developmental behavioral neuroscience   (M. S. Blumberg, J. H. Freeman, and S. R. Robinson, eds.), pp. 391‚Äì 423, New York: Oxford University Press, 2010. [36] M. S. Blumberg, J. A. Lesku, P.-A. Libourel, M. H. Schmidt, and N. C. Rattenborg, ‚ÄúWhat is rem sleep?,‚Äù   Current Biology , vol. 30, no. 1, pp. R38‚ÄìR49, 2020. [37] J. Peever and P. M. Fuller, ‚ÄúThe biology of rem sleep,‚Äù  Current Biology , vol. 27, no. 22, pp. R1237‚ÄìR1248, 2017. [38] O. I. Lyamin, P. R. Manger, S. H. Ridgway, L. M. Mukhame- tov, and J. M. Siegel, ‚ÄúCetacean sleep: An unusual form of mammalian sleep,‚Äù   Neuroscience & Biobehavioral Reviews , vol. 32, no. 8, pp. 1451‚Äì1484, 2008. [39] L. M. Mukhametov, ‚ÄúUnihemispheric slow-wave sleep in the amazonian dolphin, inia geoffrensis,‚Äù   Neuroscience Letters , vol. 79, no. 1-2, pp. 128‚Äì132, 1987. [40] A. R. Zizzo, I. Kirkegaard, J. Hansen, N. Uldbjerg, and H. M√∏lgaard, ‚ÄúFetal heart rate variability is affected by fetal movements: A systematic review,‚Äù   Frontiers in Physiology , vol. 11, p. 578898, 2020. [41] U. Schneider, B. Frank, A. Fiedler, C. Kaehler, D. Hoyer, M. Liehr, J. Haueisen, and E. Schleussner, ‚ÄúHuman fetal heart rate variability-characteristics of autonomic regulation in the third trimester of gestation,‚Äù   Journal of Perinatal Medicine , vol. 36, no. 5, pp. 433‚Äì441, 2008. [42] D. Hoyer, J. Àô Zebrowski, D. Cysarz, H. Gonc ¬∏alves, A. Pyt- lik, C. Amorim-Costa, J. Bernardes, D. Ayres-de Campos, O. W. Witte, E. Schleussner,   et al. , ‚ÄúMonitoring fetal mat- uration‚Äîobjectives,   techniques   and   indices   of   autonomic function,‚Äù   Physiological Measurement , vol. 38, no. 5, p. R61, 2017. [43] S. B. Mulkey and A. D¬¥ u Plessis, ‚ÄúThe critical role of the cen- tral autonomic nervous system in fetal-neonatal transition,‚Äù  Seminars in Pediatric Neurology , vol. 28, pp. 29‚Äì37, 2018. [44] A.   Samjeed,   M.   Wahbah,   L.   Hadjileontiadis,   and   A.   H. Khandoker, ‚ÄúFetal ECG-based analysis reveals the impact of fetal movements and maternal respiration on maternal- fetal heart rate synchronization,‚Äù   PloS One , vol. 19, no. 12, p. e0312310, 2024. [45] H. H. Szeto and D. J. Hinman, ‚ÄúPrenatal development of sleep-wake patterns in sheep,‚Äù   Sleep , vol. 8, no. 4, pp. 347‚Äì 355, 1985. [46] J. A. DiPietro, R. S. Raghunathan, H. Wu, J. Bai, H. Watson, F. P. Sgambati, J. L. Henderson, and G. W. Pien, ‚ÄúFetal heart rate during maternal sleep,‚Äù   Developmental Psychobiology , vol. 63, pp. 945‚Äì959, July 2021. [47] M. E. Koome, L. Bennet, L. C. Booth, J. O. Davidson, G. Wassink, and A. J. Gunn, ‚ÄúOntogeny and control of the heart rate power spectrum in the last third of gestation in fetal sheep,‚Äù   Experimental Physiology , vol. 99, pp. 80‚Äì88, Jan. 2014. [48] M. S. Scher, ‚ÄúOntogeny of EEG-sleep from neonatal through infancy periods,‚Äù   Sleep Medicine , vol. 9, no. 6, pp. 615‚Äì636, 2008. [49] B. R. Van Den Bergh and E. J. Mulder, ‚ÄúFetal sleep organi- zation: A biological precursor of self-regulation in childhood\n\n14  and adolescence?,‚Äù   Biological Psychology , vol. 89, pp. 584‚Äì 590, Mar. 2012. [50] C. L. Herry, P. Burns, A. Desrochers, G. Fecteau, L. D. Durosier, M. Cao, A. J. Seely, and M. G. Frasch, ‚ÄúVagal con- tributions to fetal heart rate variability: An omics approach,‚Äù  Physiological Measurement , vol. 40, no. 6, p. 065004, 2019. [51] K.   Bystrova,   ‚ÄúNovel   mechanism   of   human   fetal   growth regulation: A potential role of lanugo, vernix caseosa and a second tactile system of unmyelinated low-threshold c- afferents,‚Äù   Medical Hypotheses , vol. 72, no. 2, pp. 143‚Äì146, 2009. [52] S. B. Mulkey and A. J. du Plessis, ‚ÄúAutonomic nervous system development and its impact on neuropsychiatric out- come,‚Äù   Pediatric Research , vol. 85, no. 2, pp. 120‚Äì126, 2019. [53] S.   D.   Schlatterer,   R.   B.   Govindan,   S.   D.   Barnett, T.   Al-Shargabi,   D.   A.   Reich,   S.   Iyer,   L.   Hitchings, G. Larry Maxwell, R. Baker, A. J. du Plessis,   et al. , ‚ÄúAu- tonomic development in preterm infants is associated with morbidity of prematurity,‚Äù   Pediatric Research , vol. 91, no. 1, pp. 171‚Äì177, 2022. [54] D. Rurak, ‚ÄúFetal sleep and spontaneous behavior in utero: Animal and clinical studies,‚Äù in   Prenatal and Postnatal De- terminants of Development , pp. 89‚Äì146, Springer, 2016. [55] D. Rurak and N. Gruber, ‚ÄúIncreased oxygen consumption associated with breathing activity in fetal lambs,‚Äù   Journal of Applied Physiology , vol. 54, no. 3, pp. 701‚Äì707, 1983. [56] H. E. Fox and A. C. Moessinger, ‚ÄúFetal breathing movements and lung hypoplasia: Preliminary human observations,‚Äù   Amer- ican Journal of Obstetrics and Gynecology , vol. 151, no. 4, pp. 531‚Äì533, 1985. [57] P. Gruenwald, ‚ÄúHypoplasia of the lungs,‚Äù   Journal of the Mount Sinai Hospital, New York , vol. 24, no. 6, pp. 913‚Äì919, 1957. [58] J.   Wigglesworth   and   R.   Desai,   ‚ÄúEffects   on   lung   growth of cervical cord section in the rabbit fetus,‚Äù   Early Human Development , vol. 3, no. 1, pp. 51‚Äì65, 1979. [59] J.   E.   Fewell,   C.   C.   Lee,   and   J.   A.   Kitterman,   ‚ÄúEffects of phrenic nerve section on the respiratory system of fe- tal lambs,‚Äù   Journal of Applied Physiology , vol. 51, no. 2, pp. 293‚Äì297, 1981. [60] A. C. Moessinger, ‚ÄúFetal akinesia deformation sequence: An animal model,‚Äù   Pediatrics , vol. 72, no. 6, pp. 857‚Äì863, 1983. [61] J. Wigglesworth, ‚ÄúThe effects of placental insufficiency on the fetal lung,‚Äù   Journal of Clinical Pathology. Supplement (Royal College of Pathologists). , vol. 10, p. 27, 1976. [62] D. Hoyer, S. Nowack, S. Bauer, F. Tetschke, A. Rudolph, U. Wallwitz, F. Jaenicke, E. Heinicke, T. G¬® otz, R. Huonker,  et al. , ‚ÄúFetal development of complex autonomic control evaluated from multiscale heart rate patterns,‚Äù   American Jour- nal of Physiology-Regulatory, Integrative and Comparative Physiology , vol. 304, no. 5, pp. R383‚ÄìR392, 2013. [63] L. Semeia, K. Sippel, J. Moser, and H. Preissl, ‚ÄúEvaluation of parameters for fetal behavioural state classification,‚Äù   Scientific Reports , vol. 12, p. 3410, Mar. 2022. [64] P. R. Stone, W. Burgess, J. McIntyre, A. J. Gunn, C. A. Lear,   L.   Bennet,   E.   A.   Mitchell,   J.   M.   Thompson,   and M. S. I. P. R. G. T. U. of Auckland, ‚ÄúAn investigation of fetal behavioural states during maternal sleep in healthy late gestation pregnancy: An observational study,‚Äù   The Journal of Physiology , vol. 595, no. 24, pp. 7441‚Äì7450, 2017. [65] S. Vairavan, U. Ulusar, H. Eswaran, H. Preissl, J. Wilson, S. Mckelvey, C. Lowery, and R. Govindan, ‚ÄúA computer- aided approach to detect the fetal behavioral states using multi-sensor magnetocardiographic recordings,‚Äù   Computers in Biology and Medicine , vol. 69, pp. 44‚Äì51, Feb. 2016. [66] L. Mercado, S. Rose, D. Escalona-Vargas, E. R. Siegel, J. R. Whittington, H. Preissl, M. Helmich, and H. Eswaran, ‚ÄúCorrelation of fetal heart rate dynamics to inflammatory markers and brain-derived neurotrophic factor during preg- nancy,‚Äù   Journal of Perinatal Medicine , vol. 52, pp. 399‚Äì405, May 2024. [67] M. M. Myers, K. F. Schulze, W. P. Fifer, and R. I. Stark, ‚ÄúMethods for quantifying state-specific patterns of EEG ac- tivity in fetal baboons and immature human infants,‚Äù in   Fetal Development , pp. 35‚Äì49, Psychology Press, 2013. [68] C. Shaw, B. Allison, N. Itani, K. Botting, Y. Niu, C. Lees, and D. Giussani, ‚ÄúAltered autonomic control of heart rate variability in the chronically hypoxic fetus,‚Äù   The Journal of Physiology , vol. 596, no. 23, pp. 6105‚Äì6119, 2018. [69] R. Galinsky, S. K. Dhillon, S. B. Kelly, G. Wassink, J. O. Davidson, C. A. Lear, L. G. van den Heuij, L. Bennet, and A. J. Gunn, ‚ÄúMagnesium sulphate reduces tertiary gliosis but does not improve EEG recovery or white or grey matter cell survival after asphyxia in preterm fetal sheep,‚Äù   The Journal of Physiology , vol. 601, no. 10, pp. 1999‚Äì2016, 2023. [70] M. Van Vliet, C. Martin, J. Nijhuis, and H. Prechtl, ‚ÄúThe relationship between fetal activity and behavioral states and fetal breathing movements in normal and growth-retarded fetuses,‚Äù   American Journal of Obstetrics and Gynecology , vol. 153, pp. 582‚Äì588, Nov. 1985. [71] N. Pini, M. Lucchini, W. P. Fifer, and R. Barbieri, ‚ÄúA point process framework for the characterization of fetal sleep states,‚Äù in   2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC) , pp. 612‚Äì615, IEEE, 2020. [72] M. M. Myers, R. I. Stark, W. P. Fifer, P. G. Grieve, J. Haiken, K. Leung, and K. F. Schulze, ‚ÄúA quantitative method for classification of EEG in the fetal baboon,‚Äù   American Jour- nal of Physiology-Regulatory, Integrative and Comparative Physiology , vol. 265, pp. R706‚ÄìR714, Sept. 1993. [73] R. I. Stark, S. S. Daniel, Y.-I. Kim, K. Leung, M. M. Myers, and P. J. Tropper, ‚ÄúPatterns of fetal breathing in the baboon vary with EEG sleep state,‚Äù   Early Human Development , vol. 38, pp. 11‚Äì26, July 1994. [74] M. Schwab, K. Schmidt, H. Witte, and R. M. Abrams, ‚ÄúInves- tigation of nonlinear ECoG changes during spontaneous sleep state changes and cortical arousal in fetal sheep,‚Äù   Cerebral Cortex , vol. 10, no. 2, pp. 142‚Äì148, 2000. [75] K. Schwab, T. Groh, M. Schwab, and H. Witte, ‚ÄúTime-variant analysis of nonlinear stability and bispectral measures to quantify the development of fetal sleep states,‚Äù in   2006 In- ternational Conference of the IEEE Engineering in Medicine and Biology Society , pp. 1454‚Äì1457, IEEE, 2006. [76] A.   Tournier,   M.   Beacom,   J.   A.   Westgate,   L.   Bennet, C. Garabedian, A. Ugwumadu, A. J. Gunn, and C. A. Lear, ‚ÄúPhysiological control of fetal heart rate variability during labour: Implications and controversies,‚Äù   The Journal of Phys- iology , vol. 600, no. 3, pp. 431‚Äì450, 2022. [77] B. Lee, J. J. Hirst, and D. W. Walker, ‚ÄúProstaglandin d syn- thase in the prenatal ovine brain and effects of its inhibition with selenium chloride on fetal sleep/wake activityin utero,‚Äù  Journal of Neuroscience , vol. 22, no. 13, pp. 5679‚Äì5686, 2002. [78] J. R. Isler, M. Garland, R. I. Stark, and P. G. Grieve, ‚ÄúLocal coherence oscillations in the EEG during development in the fetal baboon,‚Äù   Clinical Neurophysiology , vol. 116, pp. 2121‚Äì 2128, Sept. 2005. [79] J. O. Davidson, J. S. Quaedackers, S. A. George, A. J. Gunn, and L. Bennet, ‚ÄúMaternal dexamethasone and EEG hyper- activity in preterm fetal sheep,‚Äù   The Journal of Physiology , vol. 589, no. 15, pp. 3823‚Äì3835, 2011. [80] C. M. Pettker and K. H. Campbell, ‚ÄúAntepartum fetal assess- ment,‚Äù   Avery‚Äôs Diseases of the Newborn , pp. 145‚Äì157, 2018. [81] P.   L.   Toubas,   A.   L.   Pryor,   and   R.   E.   Sheldon,   ‚ÄúEffect of morphine on fetal electrocortical activity and breathing movements in fetal sheep,‚Äù   Developmental Pharmacology and Therapeutics , vol. 8, no. 2, pp. 115‚Äì128, 1985. [82] M. J. Nijland and M. G. Ross, ‚ÄúOvine hourly fetal urine production: Relation to fetal electrocortical activity,‚Äù   The Journal of Maternal-Fetal Medicine , vol. 9, pp. 267‚Äì272, Sept. 2000. [83] S. B. Kelly, V. Stojanovska, V. A. Zahra, A. Moxham, S. L. Miller, T. J. Moss, S. B. Hooper, M. F. Nold, C. A. Nold- Petry, J. M. Dean,   et al. , ‚ÄúInterleukin-1 blockade attenuates white matter inflammation and oligodendrocyte loss after progressive systemic lipopolysaccharide exposure in near- term fetal sheep,‚Äù   Journal of Neuroinflammation , vol. 18, pp. 1‚Äì18, 2021. [84] R. I. Stark, M. Garland, S. S. Daniel, K. Leung, M. M. Myers, and P. J. Tropper, ‚ÄúFetal cardiorespiratory and neu- robehavioral response to zidovudine (AZT) in the baboon,‚Äù  The Journal of the Society for Gynecologic Investigation: JSGI , vol. 4, pp. 183‚Äì190, 1997.\n\n15  [85] J. Dobbing and J. Sands, ‚ÄúQuantitative growth and devel- opment of human brain,‚Äù   Archives of Disease in Childhood , vol. 48, no. 10, pp. 757‚Äì767, 1973. [86] J. A. DiPietro, K. A. Costigan, and K. M. Voegtline, ‚ÄúStudies in fetal behavior: Revisited, renewed, and reimagined,‚Äù   Mono- graphs of the Society for Research in Child Development , vol. 80, no. 3, p. vii, 2015. [87] P. G. Grieve, M. M. Myers, and R. I. Stark, ‚ÄúBehavioral states in the fetal baboon,‚Äù   Early Human Development , vol. 39, no. 3, pp. 159‚Äì175, 1994. [88] R. I. Stark, J. Haiken, D. Nordli, and M. M. Myers, ‚ÄúCharac- terization of electroencephalographic state in fetal baboons,‚Äù  American Journal of Physiology-Regulatory, Integrative and Comparative Physiology , vol. 261, no. 2, pp. R496‚ÄìR500, 1991. [89] B. Frank, M. G. Frasch, U. Schneider, M. Roedel, M. Schwab, and D. Hoyer, ‚ÄúComplexity of heart rate fluctuations in near- term sheep and human fetuses during sleep,‚Äù   Biomedizinische Technik/Biomedical Engineering , vol. 51, pp. 233‚Äì236, Oct. 2006. [90] F. Clewlow, G. Dawes, B. M. Johnston, and D. Walker, ‚ÄúChanges in breathing, electrocortical and muscle activity in unanaesthetized fetal lambs with age,‚Äù   The Journal of Physiology , vol. 341, no. 1, pp. 463‚Äì476, 1983. [91] W. Tang, N. Tran, N. Katebi, R. Sameni, G. D. Clifford, D. Walker, V. Horlali, C. Taylor, R. Galinsky, and F. Marzban- rad, ‚ÄúAdvancing fetal surveillance with physiological sensing: Detecting hypoxia in fetal sheep,‚Äù in   2024 IEEE SENSORS , pp. 1‚Äì4, 2024. [92] N. K. Lowe and R. Reiss, ‚ÄúParturition and fetal adapta- tion,‚Äù   Journal of Obstetric, Gynecologic & Neonatal Nursing , vol. 25, pp. 339‚Äì349, May 1996. [93] M. E. McNERNEY and H. H. Szeto, ‚ÄúAutomated identifica- tion and quantitation of four patterns of electrocortical activity in the near-term fetal lamb,‚Äù   Pediatric Research , vol. 28, no. 2, pp. 106‚Äì110, 1990. [94] N. Rao, A. Keen, M. Czikk, M. Frasch, and B. S. Richardson, ‚ÄúBehavioural state linkage in the ovine fetus near term,‚Äù   Brain Research , vol. 1250, pp. 149‚Äì156, 2009. [95] S. Ioffe, A. H. Jansen, B. J. Russell, and V. Chernick, ‚ÄúSleep, wakefulness and the monosynaptic reflex in fetal and newborn lambs,‚Äù   Pfl¬® ugers Archiv European Journal of Physiology , vol. 388, pp. 149‚Äì157, Nov. 1980. [96] G. Visser, E. Mulder, and H. Prechtl, ‚ÄúStudies on devel- opmental   neurology   in   the   human   fetus,‚Äù   Developmental Pharmacology and Therapeutics , vol. 18, no. 3-4, pp. 175‚Äì 183, 1992. [97] E. J. Mulder, L. P. Morssink, T. Van Der Schee, and G. H. Visser, ‚ÄúAcute maternal alcohol consumption disrupts be- havioral state organization in the near-term fetus,‚Äù   Pediatric Research , vol. 44, no. 5, pp. 774‚Äì779, 1998. [98] H. H. Szeto, ‚ÄúBehavioral states and their ontogeny: Animal studies,‚Äù   Seminars in Perinatology , vol. 16, no. 4, pp. 211‚Äì 216, 1992. [99] K. J. Crossley, M. B. Nicol, J. J. Hirst, D. W. Walker, and G. D. Thorburn‚Ä†, ‚ÄúSuppression of arousal by progesterone in fetal sheep,‚Äù   Reproduction, Fertility and Development , vol. 9, no. 8, p. 767, 1997. [100] M. Nicol, J. J. Hirst, and D. Walker, ‚ÄúEffect of pregnane steroids on electrocortical activity and somatosensory evoked potentials in fetal sheep,‚Äù   Neuroscience Letters , vol. 253, no. 2, pp. 111‚Äì114, 1998. [101] M. B. Nicol, J. J. Hirst, and D. W. Walker, ‚ÄúEffect of finasteride on behavioural arousal and somatosensory evoked potentials in fetal sheep,‚Äù   Neuroscience letters , vol. 306, no. 1-2, pp. 13‚Äì16, 2001. [102] G. H. A. Visser and E. J. H. Mulder, ‚ÄúThe effect of vibro- acoustic stimulation on fetal behavioral state organization,‚Äù  American Journal of Industrial Medicine , vol. 23, pp. 531‚Äì 539, Apr. 1993. [103] D. Walker, J. Grimwade, and C. Wood, ‚ÄúIntrauterine noise: A component of the fetal environment,‚Äù   American Journal of Obstetrics and Gynecology , vol. 109, no. 1, pp. 91‚Äì95, 1971. [104] B. S. Kisilevsky, S. M. Hains, K. Lee, X. Xie, H. Huang, H. H. Ye, K. Zhang, and Z. Wang, ‚ÄúEffects of experience on fetal voice recognition,‚Äù   Psychological Science , vol. 14, no. 3, pp. 220‚Äì224, 2003. [105] E. J. H. Mulder and G. H. A. Visser, ‚ÄúFetal behavior: Clinical and experimental research in the human,‚Äù in   Fetal Develop- ment   (N. Reissland and B. S. Kisilevsky, eds.), pp. 87‚Äì105, Cham: Springer International Publishing, 2016. [106] D. L. Wilson, A. M. Fung, H. Skrzypek, G. Pell, M. Barnes, M. E. Howard, and S. P. Walker, ‚ÄúMaternal sleep behaviours preceding fetal heart rate events on cardiotocography,‚Äù   The Journal of Physiology , vol. 600, pp. 1791‚Äì1806, Apr. 2022. [107] S. R. Yiallourou, ‚ÄúChildhood sleep after fetal growth restric- tion,‚Äù   Diet, Nutrition, and Fetal Programming , pp. 487‚Äì499, 2017. [108] E. P. on Animal Health, W. (AHAW), S. More, D. Bicout, A. Botner, A. Butterworth, P. Calistri, K. Depner, S. Edwards, B. Garin-Bastuji, M. Good,   et al. , ‚ÄúAnimal welfare aspects in respect of the slaughter or killing of pregnant livestock animals (cattle, pigs, sheep, goats, horses),‚Äù   Efsa Journal , vol. 15, no. 5, p. e04782, 2017. [109] T. Yawno, E. B. Yan, J. J. Hirst, and D. W. Walker, ‚ÄúNeuroac- tive steroids induce changes in fetal sheep behavior during normoxic and asphyxic states,‚Äù   Stress , vol. 14, pp. 13‚Äì22, Jan. 2011. [110] M. S. Kinsella and G. Lohmann, ‚ÄúSupine hypotensive syn- drome,‚Äù   Obstetrics & Gynecology , vol. 83, no. 5, pp. 774‚Äì 788, 1994. [111] J. P. PIRHONEN and R. U. ERKKOLA, ‚ÄúUterine and um- bilical flow velocity waveforms in the supine hypotensive syndrome,‚Äù   Obstetrics & Gynecology , vol. 76, no. 2, pp. 176‚Äì 179, 1990. [112] R.   Jeffreys,   W.   Stepanchak,   B.   Lopez,   J.   Hardis,   and J. Clapp III, ‚ÄúUterine blood flow during supine rest and exercise after 28 weeks of gestation,‚Äù   BJOG: An International Journal   of   Obstetrics   &   Gynaecology ,   vol.   113,   no.   11, pp. 1239‚Äì1247, 2006. [113] J.-P. Lecanuet and A.-Y. Jacquet, ‚ÄúFetal responsiveness to maternal passive swinging in low heart rate variability state: effects of stimulation direction and duration,‚Äù   Developmental Psychobiology: The Journal of the International Society for Developmental Psychobiology , vol. 40, no. 1, pp. 57‚Äì67, 2002. [114] M. Mirmiran and S. Lunshof, ‚ÄúPerinatal development of human   circadian   rhythms,‚Äù   Progress   in   Brain   Research , vol. 111, pp. 217‚Äì226, 1996. [115] G.   W.   Pien   and   R.   J.   Schwab,   ‚ÄúSleep   disorders   during pregnancy,‚Äù   Sleep , vol. 27, no. 7, pp. 1405‚Äì1417, 2004. [116] F. K. Sahin, G. Koken, E. Cosar, F. Saylan, F. Fidan, M. Yil- mazer, and M. Unlu, ‚ÄúObstructive sleep apnea in pregnancy and fetal outcome,‚Äù   International Journal of Gynecology & Obstetrics , vol. 100, no. 2, pp. 141‚Äì146, 2008. [117] B. J. Koos, T. Maeda, and C. Jan, ‚ÄúAdenosine A 1   and A 2a  receptors modulate sleep state and breathing in fetal sheep,‚Äù  Journal of Applied Physiology , vol. 91, pp. 343‚Äì350, July 2001. [118] D. J. Hinman and H. H. Szeto, ‚ÄúCholinergic influences on sleep-wake patterns and breathing movements in the fetus,‚Äù  The Journal of Pharmacology and Experimental Therapeu- tics , vol. 247, pp. 372‚Äì378, Oct. 1988. [119] C. S. Han and L. D. Platt, ‚ÄúFetal biophysical profile,‚Äù in  Obstetric   Imaging:   Fetal   Diagnosis   and   Care ,   pp.   537‚Äì 540.e1, Elsevier, 2018. [120] D. Burchfield, E. Graham, R. Abrams, and K. Gerhardt, ‚ÄúCo- caine alters behavioral states in fetal sheep,‚Äù   Developmental Brain Research , vol. 56, pp. 41‚Äì45, Oct. 1990. [121] M. B. Nicol, J. J. Hirst, and D. Walker, ‚ÄúEffects of preg- nanolone on behavioural parameters and the responses to GABAA   receptor   antagonists   in   the   late   gestation   fetal sheep,‚Äù   Neuropharmacology , vol. 38, pp. 49‚Äì63, Jan. 1999. [122] S. Ioffe, A. H. Jansen, and V. Chernick, ‚ÄúFetal respiratory neuronal activity during REM and NREM sleep,‚Äù   Journal of Applied Physiology , vol. 75, pp. 191‚Äì197, July 1993. [123] Z.   Alfirevic,   G.   M.   Gyte,   A.   Cuthbert,   and   D.   Devane, ‚ÄúContinuous cardiotocography (CTG) as a form of electronic fetal monitoring (EFM) for fetal assessment during labour,‚Äù  Cochrane Database of Systematic Reviews , no. 2, 2017. [124] J.   Karin,   M.   Hirsch,   and   S.   Akselrod,   ‚ÄúAn   estimate   of fetal autonomic state by spectral analysis of fetal heart rate fluctuations,‚Äù   Pediatric Research , vol. 34, pp. 134‚Äì138, Aug. 1993.\n\n16  [125] J. Van Laar, C. Peters, R. Vullings, S. Houterman, and S. Oei, ‚ÄúPower spectrum analysis of fetal heart rate variability at near term and post term gestation during active sleep and quiet sleep,‚Äù   Early Human Development , vol. 85, pp. 795‚Äì798, Dec. 2009. [126] M. Chiera, F. Cerritelli, A. Casini, N. Barsotti, D. Boschiero, F.   Cavigioli,   C.   G.   Corti,   and   A.   Manzotti,   ‚ÄúHeart   rate variability in the perinatal period: A critical and conceptual review,‚Äù   Frontiers in Neuroscience , vol. 14, p. 561186, 2020. [127] P. Van Leeuwen, L. Werner, Z. Hilal, S. Schiermeier, W. Hatz- mann, and D. Groenemeyer, ‚ÄúFetal electrocardiographic mea- surements in the assessment of fetal heart rate variability in the antepartum period,‚Äù   Physiological Measurement , vol. 35, no. 3, p. 441, 2014. [128] C. L. Lowery, R. Govindan, P. Murphy, and H. Eswaran, ‚ÄúAssessing cardiac and neurological maturation during the intrauterine period,‚Äù   Seminars in Perinatology , vol. 32, no. 4, pp. 263‚Äì268, 2008. [129] J. Br¬® andle, H. Preissl, R. Draganova, E. Ortiz, K. O. Kagan, H. Abele, S. Y. Brucker, and I. Kiefer-Schmidt, ‚ÄúHeart rate variability parameters and fetal movement complement fetal behavioral states detection via magnetography to monitor neurovegetative development,‚Äù   Frontiers in Human Neuro- science , vol. 9, p. 147, 2015. [130] S. U. Hasan and A. Rigaux, ‚ÄúArterial oxygen tension thresh- old range for the onset of arousal and breathing in fetal sheep,‚Äù   Pediatric Research , vol. 32, pp. 342‚Äì349, Sept. 1992. [131] E. C. Jensen, L. Bennet, S.-J. Guild, L. C. Booth, J. Stewart, and A. J. Gunn, ‚ÄúThe role of the neural sympathetic and parasympathetic systems in diurnal and sleep state-related cardiovascular   rhythms   in   the   late-gestation   ovine   fetus,‚Äù  American Journal of Physiology-Regulatory, Integrative and Comparative Physiology , vol. 297, no. 4, pp. R998‚ÄìR1008, 2009. [132] G. Dawes, H. . E. Fox, B. Leduc, G. Liggins, and R. Richards, ‚ÄúRespiratory movements and rapid eye movement sleep in the foetal lamb,‚Äù   The Journal of Physiology , vol. 220, no. 1, pp. 119‚Äì143, 1972. [133] R. Harding, J. N. Sigger, E. R. Poore, and P. Johnson, ‚ÄúIngestion in fetal sheep and its relation to sleep states and breathing movements,‚Äù   Quarterly Journal of Experimental Physiology , vol. 69, pp. 477‚Äì486, July 1984. [134] R. Natale, F. Clewlow, and G. Dawes, ‚ÄúMeasurement of fetal forelimb movements in the lamb in utero,‚Äù   American Journal of Obstetrics and Gynecology , vol. 140, pp. 545‚Äì551, July 1981. [135] E. Poore and D. Walker, ‚ÄúChest wall movements during fetal breathing in the sheep,‚Äù   The Journal of Physiology , vol. 301, no. 1, pp. 307‚Äì315, 1980. [136] W. Sha and X. Guo, ‚ÄúPrenatal and intrapartum EFM,‚Äù in   Elec- tronic Fetal Monitoring   (X. Guo, ed.), pp. 65‚Äì118, Singapore: Springer Singapore, 2021. [137] M. Hirsch, J. Karin, and S. Akselrod, ‚ÄúHeart rate variability in the fetus,‚Äù   Heart Rate Variability , pp. 517‚Äì531, 1995. [138] S. Lange, P. Van Leeuwen, U. Schneider, B. Frank, D. Hoyer, D. Geue, and D. Gr¬® onemeyer, ‚ÄúHeart rate features in fetal behavioural   states,‚Äù   Early   Human   Development ,   vol.   85, pp. 131‚Äì135, Feb. 2009. [139] M. Peters, J. Crowe, J.-F. Pi¬¥ eri, H. Quartero, B. Hayes-Gill, D. James, J. Stinstra, and S. Shakespeare, ‚ÄúMonitoring the fetal heart non-invasively: A review of methods,‚Äù   Journal of Perinatal Medicine , vol. 29, no. 5, pp. 408‚Äì416, 2001. [140] C. A. Lear, B. A. Lear, J. O. Davidson, V. J. King, Y. Maeda, A. McDouall, S. K. Dhillon, A. J. Gunn, and L. Bennet, ‚ÄúDys- maturation of sleep state and electroencephalographic activity after hypoxia-ischaemia in preterm fetal sheep,‚Äù   Journal of Cerebral Blood Flow & Metabolism , vol. 44, pp. 1376‚Äì1392, Aug. 2024. [141] M. David, M. Hirsch, J. Karin, E. Toledo, and S. Akselrod, ‚ÄúAn estimate of fetal autonomic state by time-frequency analysis of fetal heart rate variability,‚Äù   Journal of Applied Physiology , vol. 102, no. 3, pp. 1057‚Äì1064, 2007. [142] K. M. Gustafson, J. J. Allen, H.-w. Yeh, and L. E. May, ‚ÄúCharacterization of the fetal diaphragmatic magnetomyo- gram and the effect of breathing movements on cardiac metrics of rate and variability,‚Äù   Early Human Development , vol. 87, no. 7, pp. 467‚Äì475, 2011. [143] K. M. Gustafson, L. E. May, H.-w. Yeh, S. K. Million, and J. J. Allen, ‚ÄúFetal cardiac autonomic control during breathing and non-breathing epochs: The effect of maternal exercise,‚Äù  Early Human Development , vol. 88, no. 7, pp. 539‚Äì546, 2012. [144] S.-W. Min, H. Ko, and C.-S. Kim, ‚ÄúPower spectral analysis of heart rate variability during acute hypoxia in fetal lambs,‚Äù  Acta   Obstetricia   et   Gynecologica   Scandinavica ,   vol.   81, no. 11, pp. 1001‚Äì1005, 2002. [145] J. Van Laar, C. Peters, R. Vullings, S. Houterman, and S. Oei, ‚ÄúPower spectrum analysis of fetal heart rate variability at near term and post term gestation during active sleep and quiet sleep,‚Äù   Early Human Development , vol. 85, no. 12, pp. 795‚Äì 798, 2009. [146] M. E. Koome, L. Bennet, L. C. Booth, G. Wassink, J. O. Davidson, M. Gunning, and A. J. Gunn, ‚ÄúQuantifying the power spectrum of fetal heart rate variability.,‚Äù   Experimental Physiology , vol. 99, no. 2, 2014. [147] S. B. Kelly, J. M. Dean, V. A. Zahra, I. Dudink, A. Thiel, G.   R.   Polglase,   S.   L.   Miller,   S.   B.   Hooper,   L.   Bennet, A. J. Gunn,   et al. , ‚ÄúProgressive inflammation reduces high- frequency EEG activity and cortical dendritic arborisation in late gestation fetal sheep,‚Äù   Journal of Neuroinflammation , vol. 20, no. 1, p. 124, 2023. [148] S. Ioffe, A. H. Jansen, and V. Chernick, ‚ÄúECoG and breathing activity in fetal lambs after undercut of cerebral cortex,‚Äù  Journal of Applied Physiology , vol. 57, pp. 1195‚Äì1201, Oct. 1984. [149] A. Samjeed, M. Wahbah, L. Hadjileontiadis, and A. H. Khan- doker, ‚ÄúClassification of fetal behavioral states by using 1D- CNN based on fetal electrocardiography,‚Äù in   2022 Computing in Cardiology (CinC) , vol. 498, pp. 1‚Äì4, IEEE, 2022. [150] L. Subitoni, ‚ÄúHidden markov models and deep neural net- works: Segmentation of the fetal heart rate signal into behav- ioral patterns,‚Äù master‚Äôs thesis, Politecnico di Milano, Milan, Italy, 2023. [151] G. E. Billman, ‚ÄúThe LF/HF ratio does not accurately measure cardiac sympatho-vagal balance,‚Äù 2013. [152] B. J. Koos, H. Sameshima, and G. G. Power, ‚ÄúFetal breathing, sleep state, and cardiovascular responses to graded anemia in sheep,‚Äù   Journal of Applied Physiology , vol. 63, pp. 1463‚Äì 1468, Oct. 1987. [153] N. T. Tran, S. J. Ellery, S. B. Kelly, J. S¬¥ evigny, M. Chatton, H. Lu, G. R. Polglase, R. J. Snow, D. W. Walker, and R. Galinsky, ‚ÄúProphylactic fetal creatine supplementation im- proves post-asphyxial EEG recovery and reduces seizures in fetal sheep: Implications for hypoxic‚Äìischemic encephalopa- thy,‚Äù   Annals of Neurology , vol. 97, no. 4, pp. 673‚Äì687, 2025. [154] B. J. Koos, B. A. Mason, O. Punla, and A. M. Adinolfi, ‚ÄúHypoxic inhibition of breathing in fetal sheep: Relationship to brain adenosine concentrations,‚Äù   Journal of Applied Phys- iology , vol. 77, no. 6, pp. 2734‚Äì2739, 1994. [155] B. J. Koos, L. Kruger, and T. F. Murray, ‚ÄúSource of extracel- lular brain adenosine during hypoxia in fetal sheep,‚Äù   Brain Research , vol. 778, no. 2, pp. 439‚Äì442, 1997. [156] C. S. Watson, R. Schaefer, S. E. White, J. H. Homan, L. Fra- her, R. Harding, and A. D. Bocking, ‚ÄúEffect of intermittent umbilical cord occlusion on fetal respiratory activity and brain adenosine in late-gestation sheep,‚Äù   Reproduction, Fertility and Development , vol. 14, no. 1, pp. 35‚Äì42, 2002. [157] S. Breen, S. Rees, and D. Walker, ‚ÄúIdentification of brainstem neurons responding to hypoxia in fetal and newborn sheep,‚Äù  Brain Research , vol. 748, no. 1-2, pp. 107‚Äì121, 1997. [158] G. Dawes, W. Gardner, B. M. Johnston, and D. Walker, ‚ÄúBreathing in fetal lambs: The effect of brain stem section.,‚Äù  The Journal of Physiology , vol. 335, no. 1, pp. 535‚Äì553, 1983. [159] B. J. Koos, A. Chau, M. Matsuura, O. Punla, and L. Kruger, ‚ÄúThalamic locus mediates hypoxic inhibition of breathing in fetal sheep,‚Äù   Journal of Neurophysiology , vol. 79, no. 5, pp. 2383‚Äì2393, 1998. [160] A.   A.   Baburamani,   N.   T.   Tran,   M.   Castillo-Melendez, T. Yawno, and D. W. Walker, ‚ÄúBrief hypoxia in late gestation sheep causes prolonged disruption of fetal electrographic, breathing behaviours and can result in early labour,‚Äù   The Journal of Physiology , vol. 599, no. 12, pp. 3221‚Äì3236, 2021. [161] A. H. Jansen, S. Ioffe, B. Russell, and V. Chernick, ‚ÄúInfluence\n\n17  of sleep state on the response to hypercapnia in fetal lambs,‚Äù  Respiration Physiology , vol. 48, pp. 125‚Äì142, Apr. 1982. [162] D. Arduini, G. Rizzo, L. Caforio, M. R. Boccolini, C. Ro- manini, and S. Mancuso, ‚ÄúBehavioural state transitions in healthy and growth retarded fetuses,‚Äù   Early Human Devel- opment , vol. 19, no. 3, pp. 155‚Äì165, 1989. [163] M. Van Vliet, C. Martin Jr, J. Nijhuis, and H. Prechtl, ‚ÄúBehavioural states in growth-retarded human fetuses,‚Äù   Early Human Development , vol. 12, no. 2, pp. 183‚Äì197, 1985. [164] F. Cerritelli, M. G. Frasch, M. C. Antonelli, C. Viglione, S. Vecchi, M. Chiera, and A. Manzotti, ‚ÄúThe role of the vagus nerve during fetal development and its relationship with the environment,‚Äù   arXiv preprint arXiv:2106.01756 , 2021. [165] D. Bekedam, E. Mulder, R. Snijders, and G. Visser, ‚ÄúThe effects of maternal hyperoxia on fetal breathing movements, body movements and heart rate variation in growth retarded fetuses,‚Äù   Early Human Development , vol. 27, no. 3, pp. 223‚Äì 232, 1991. [166] D. Bekedam, G. Visser, J. De Vries, and H. Prechtl, ‚ÄúMotor behaviour in the growth retarded fetus,‚Äù   Early Human Devel- opment , vol. 12, no. 2, pp. 155‚Äì165, 1985. [167] D. Sival, G. Visser, and H. Prechtl, ‚ÄúThe effect of intrauterine growth retardation on the quality of general movements in the human fetus,‚Äù   Early Human Development , vol. 28, no. 2, pp. 119‚Äì132, 1992. [168] G. H. A. Visser, E. J. H. Mulder, and F. F. Tessa Ververs, ‚ÄúFetal behavioral teratology,‚Äù   The Journal of Maternal-Fetal & Neonatal Medicine , vol. 23, pp. 14‚Äì16, Oct. 2010. [169] J. De Vries and B. Fong, ‚ÄúChanges in fetal motility as a result of congenital disorders: An overview,‚Äù   Ultrasound in Obstetrics and Gynecology: The Official Journal of the Inter- national Society of Ultrasound in Obstetrics and Gynecology , vol. 29, no. 5, pp. 590‚Äì599, 2007. [170] L. Dierker Jr, S. Pillay, Y. Sorokin, and M. G. Rosen, ‚ÄúThe change in fetal activity periods in diabetic and nondiabetic pregnancies,‚Äù   American Journal of Obstetrics and Gynecol- ogy , vol. 143, no. 2, pp. 181‚Äì185, 1982. [171] P. R. Stone, W. Burgess, J. P. R. McIntyre, A. J. Gunn, C. A. Lear, L. Bennet, E. A. Mitchell, J. M. D. Thompson, and the Maternal Sleep In Pregnancy Research Group, The University of Auckland, ‚ÄúEffect of maternal position on fetal behavioural state and heart rate variability in healthy late gestation pregnancy,‚Äù   The Journal of Physiology , vol. 595, pp. 1213‚Äì1221, Feb. 2017. [172] K. J. O‚ÄôDonnell, A. B. Jensen, L. Freeman, N. Khalife, T. G. O‚ÄôConnor, and V. Glover, ‚ÄúMaternal prenatal anxiety and downregulation of placental 11 Œ≤ -hsd2,‚Äù   Psychoneuroen- docrinology , vol. 37, no. 6, pp. 818‚Äì826, 2012. [173] M.   G.   Opler   and   E.   S.   Susser,   ‚ÄúFetal   environment   and schizophrenia,‚Äù   Environmental Health Perspectives , vol. 113, no. 9, pp. 1239‚Äì1242, 2005. [174] A. Lehrner, L. M. Bierer, V. Passarelli, L. C. Pratchett, J. D. Flory, H. N. Bader, I. R. Harris, A. Bedi, N. P. Daskalakis, I. Makotkine,   et al. , ‚ÄúMaternal ptsd associates with greater glucocorticoid sensitivity in offspring of holocaust survivors,‚Äù  Psychoneuroendocrinology , vol. 40, pp. 213‚Äì220, 2014. [175] M. N. Spann, D. Scheinost, T. Feng, K. Barbato, S. Lee, C.   Monk,   and   B.   S.   Peterson,   ‚ÄúAssociation   of   maternal prepregnancy body mass index with fetal growth and neonatal thalamic brain connectivity among adolescent and young women,‚Äù   JAMA Network Open , vol. 3, no. 11, pp. e2024661‚Äì e2024661, 2020. [176] J. A. Dipietro, K. M. Voegtline, H. A. Pater, and K. A. Costigan, ‚ÄúPredicting child temperament and behavior from the fetus,‚Äù   Development and Psychopathology , vol. 30, no. 3, pp. 855‚Äì870, 2018. [177] W. Schlotz, K. M. Godfrey, and D. I. Phillips, ‚ÄúPrenatal origins of temperament: Fetal growth, brain structure, and inhibitory control in adolescence,‚Äù   PLoS One , vol. 9, no. 5, p. e96715, 2014. [178] S. M. Lobmaier, A. M¬® uller, C. Zelgert, C. Shen, P. Su, G. Schmidt, B. Haller, G. Berg, B. Fabre, J. Weyrich,   et al. , ‚ÄúFetal heart rate variability responsiveness to maternal stress, non-invasively detected from maternal transabdominal ECG,‚Äù  Archives of Gynecology and Obstetrics , vol. 301, pp. 405‚Äì 414, 2020. [179] M. C. Wallingford, C. Benson, N. W. Chavkin, M. T. Chin, and M. G. Frasch, ‚ÄúPlacental vascular calcification and car- diovascular health: It is time to determine how much of maternal and offspring health is written in stone,‚Äù   Frontiers in Physiology , vol. 9, p. 1044, 2018. [180] P. S. Zeskind and J. L. Gingras, ‚ÄúMaternal cigarette-smoking during pregnancy disrupts rhythms in fetal heart rate,‚Äù   Journal of Pediatric Psychology , vol. 31, no. 1, pp. 5‚Äì14, 2006. [181] H. Kapaya, F. Broughton-Pipkin, B. Hayes-Gill, and P. V. Loughna, ‚ÄúSmoking in pregnancy affects the fetal heart: Possible links to future cardiovascular disease,‚Äù   The Journal of Maternal-Fetal & Neonatal Medicine , vol. 28, no. 14, pp. 1664‚Äì1668, 2015. [182] E. Mulder, L. Tegaldo, P. Bruschettini, and G. Visser, ‚ÄúFoetal response to maternal coffee intake: Role of habitual versus non-habitual caffeine consumption,‚Äù   Journal of Psychophar- macology , vol. 24, pp. 1641‚Äì1648, Nov. 2010. [183] R. J. Cardosi and R. A. Chez, ‚ÄúMagnesium sulfate, maternal hypothermia, and fetal bradycardia with loss of heart rate variability,‚Äù   Obstetrics & Gynecology , vol. 92, no. 4 Part 2, pp. 691‚Äì693, 1998. [184] R. Galinsky, J. O. Davidson, P. P. Drury, G. Wassink, C. A. Lear, L. G. van den Heuij, A. J. Gunn, and L. Bennet, ‚ÄúMagnesium sulphate and cardiovascular and cerebrovascular adaptations to asphyxia in preterm fetal sheep,‚Äù   The Journal of Physiology , vol. 594, no. 5, pp. 1281‚Äì1293, 2016. [185] R. Galinsky, V. Draghi, G. Wassink, J. O. Davidson, P. P. Drury, C. A. Lear, A. J. Gunn, and L. Bennet, ‚ÄúMagnesium sulfate reduces EEG activity but is not neuroprotective after asphyxia in preterm fetal sheep,‚Äù   Journal of Cerebral Blood Flow & Metabolism , vol. 37, no. 4, pp. 1362‚Äì1373, 2017. [186] R. Galinsky, S. K. Dhillon, C. A. Lear, K. Yamaguchi, G. Wassink, A. J. Gunn, and L. Bennet, ‚ÄúMagnesium sulfate and   sex differences   in   cardiovascular   and neural   adapta- tions during normoxia and asphyxia in preterm fetal sheep,‚Äù  American Journal of Physiology-Regulatory, Integrative and Comparative Physiology , vol. 315, no. 2, pp. R205‚ÄìR217, 2018. [187] S. M. Khedun, B. Maharaj, and J. Moodley, ‚ÄúEffects of anti- hypertensive drugs on the unborn child: What is known, and how should this influence prescribing?,‚Äù   Paediatric Drugs , vol. 2, pp. 419‚Äì436, 2000. [188] G. Hanley, K. Hookenson, D. Rurak, and T. F. Oberlander, ‚ÄúFetal effects of in utero serotonin reuptake inhibitor (SRI) antidepressant exposure,‚Äù   Fetal Development: Research on Brain and Behavior, Environmental Influences, and Emerging Technologies , pp. 365‚Äì381, 2016. [189] E. J. H. Mulder, F. F. Ververs, R. De Heus, and G. H. A. Visser, ‚ÄúSelective serotonin reuptake inhibitors affect neu- robehavioral development in the human fetus,‚Äù   Neuropsy- chopharmacology , vol. 36, pp. 1961‚Äì1971, Sept. 2011. [190] L. Galli, A. Dall‚ÄôAsta, V. Whelehan, A. Archer, and E. Chan- draharan, ‚ÄúIntrapartum cardiotocography patterns observed in suspected clinical and subclinical chorioamnionitis in term fetuses,‚Äù   Journal of Obstetrics and Gynaecology Research , vol. 45, no. 12, pp. 2343‚Äì2350, 2019. [191] S. Pereira, K. Lau, C. Modestini, D. Wertheim, and E. Chan- draharan, ‚ÄúAbsence of fetal heart rate cycling on the intra- partum cardiotocograph (CTG) is associated with intrapartum pyrexia and lower Apgar scores,‚Äù   The Journal of Maternal- Fetal & Neonatal Medicine , vol. 35, pp. 7980‚Äì7985, Feb. 2025.",
      "embedding": [
        -0.03355849161744118,
        -0.045696113258600235,
        -0.046907227486371994,
        0.08347053080797195,
        0.05048545449972153,
        0.0953800156712532,
        -0.04525284841656685,
        -0.07382890582084656,
        0.0022689790930598974,
        0.02192038670182228,
        -0.08311769366264343,
        -0.10149883478879929,
        -0.03485620766878128,
        0.04727863892912865,
        -0.029666371643543243,
        0.05566982552409172,
        -0.0012130351969972253,
        0.05717971920967102,
        0.031492069363594055,
        0.030636016279459,
        0.059089429676532745,
        -0.013806719332933426,
        0.11180353909730911,
        -0.007180987391620874,
        0.05780124291777611,
        0.003984927199780941,
        -0.001732311095111072,
        -0.019595427438616753,
        0.006438240874558687,
        -0.03425338864326477,
        -0.0012056110426783562,
        0.08501328527927399,
        0.007494606077671051,
        -0.05383872613310814,
        -0.027228111401200294,
        0.017225302755832672,
        0.023848097771406174,
        -0.013618092983961105,
        -0.029811199754476547,
        -0.011650420725345612,
        0.07002139836549759,
        -0.006202885415405035,
        -0.05712967738509178,
        -0.02955949492752552,
        -0.044179122895002365,
        -0.008384385146200657,
        -0.008194836787879467,
        -0.07478935271501541,
        -0.07922806590795517,
        0.03702555224299431,
        0.01888149045407772,
        0.01752074621617794,
        -0.03143490478396416,
        0.0813470110297203,
        0.05280161276459694,
        0.009105050936341286,
        -0.016854608431458473,
        -0.030766893178224564,
        0.05355610325932503,
        0.04135818034410477,
        -0.0619158037006855,
        0.02260790392756462,
        0.04503864422440529,
        -0.11457033455371857,
        0.05066515877842903,
        0.08064274489879608,
        -0.04144252464175224,
        -0.002656039781868458,
        -0.015625281259417534,
        -0.07597780972719193,
        -0.10128746181726456,
        0.009751860983669758,
        0.08273247629404068,
        0.03491191938519478,
        -0.046976085752248764,
        0.028749780729413033,
        0.11237744987010956,
        0.05141834914684296,
        0.07214286923408508,
        -0.11100643873214722,
        -0.034047771245241165,
        0.07591281086206436,
        -0.02603418193757534,
        -0.005348873324692249,
        0.03295144438743591,
        0.09617584943771362,
        0.0425788089632988,
        0.08776627480983734,
        -0.025754641741514206,
        0.01042758859694004,
        0.020765414461493492,
        -0.020031731575727463,
        -0.09599059075117111,
        -0.03627706319093704,
        0.08582514524459839,
        -0.04395129159092903,
        -0.0002566940966062248,
        -0.01857389509677887,
        0.0649048462510109,
        -0.050145260989665985,
        0.04322566092014313,
        0.014381451532244682,
        0.024806931614875793,
        0.06648804992437363,
        0.03929394483566284,
        0.058988381177186966,
        -0.00919722206890583,
        -0.036357298493385315,
        -0.046390146017074585,
        0.009818640537559986,
        -0.05916232988238335,
        0.05906004086136818,
        0.03838181495666504,
        0.058223653584718704,
        0.07056617736816406,
        0.027606450021266937,
        -0.007736539002507925,
        0.07286648452281952,
        0.0958644449710846,
        0.023615753278136253,
        0.0477711521089077,
        0.01979757472872734,
        0.04859689623117447,
        -0.10069381445646286,
        0.010292688384652138,
        -0.07027607411146164,
        -0.13472089171409607,
        3.6570984746004656e-33,
        0.036554086953401566,
        -0.04021025821566582,
        -0.051722705364227295,
        0.017650257796049118,
        -0.004238989669829607,
        -0.005115775391459465,
        -0.03975500911474228,
        0.019244497641921043,
        0.01086274441331625,
        0.08722865581512451,
        -0.06753292679786682,
        0.0391840860247612,
        0.01123909279704094,
        -0.04057679325342178,
        0.06590588390827179,
        0.03888383507728577,
        -0.061201371252536774,
        -0.03737035393714905,
        0.04909539222717285,
        -0.05874389782547951,
        -0.038369402289390564,
        -0.02722824178636074,
        0.050365593284368515,
        0.001818150165490806,
        -0.008536618202924728,
        -0.008110735565423965,
        -0.008362476713955402,
        0.012288111262023449,
        -0.023034414276480675,
        0.030806487426161766,
        -0.038477104157209396,
        -0.03646118566393852,
        0.017743239179253578,
        -0.039691705256700516,
        -0.018264753744006157,
        -0.02467029169201851,
        0.017394596710801125,
        0.002149750478565693,
        -0.09042465686798096,
        0.015094268135726452,
        -0.04408857598900795,
        0.028690949082374573,
        0.013904152438044548,
        -0.01241170521825552,
        -0.03434755280613899,
        -0.009337857365608215,
        0.03723366931080818,
        0.040562476962804794,
        0.0869535282254219,
        -0.038500141352415085,
        0.0405958816409111,
        -0.0867711678147316,
        0.0014959919499233365,
        -0.12401118874549866,
        -0.09776423126459122,
        0.060048095881938934,
        -0.03411763906478882,
        -0.022863149642944336,
        -0.030898839235305786,
        0.026614438742399216,
        -0.04468018189072609,
        -0.048132363706827164,
        0.0029359033796936274,
        -0.013168041594326496,
        0.045562002807855606,
        -0.010180541314184666,
        -0.10446520149707794,
        0.02126213163137436,
        0.0039187208749353886,
        -0.02339480258524418,
        0.03179573267698288,
        0.005937784444540739,
        0.05579517036676407,
        -0.027988668531179428,
        0.036686141043901443,
        0.03149469196796417,
        0.06397231668233871,
        0.05236910656094551,
        -0.08466732501983643,
        -0.10574716329574585,
        0.11946109682321548,
        0.07918433845043182,
        0.02375802956521511,
        -0.040918104350566864,
        -0.028369277715682983,
        -0.060109201818704605,
        0.026837170124053955,
        0.0933951660990715,
        -0.15081937611103058,
        -0.019858388230204582,
        -0.025254959240555763,
        -0.026875607669353485,
        0.05177200958132744,
        -0.05804761126637459,
        -0.024852348491549492,
        -3.0293540018766396e-33,
        -0.027869274839758873,
        -0.041276730597019196,
        -0.011848242953419685,
        -0.0691327452659607,
        -0.0018122665351256728,
        -0.035260625183582306,
        0.03389131650328636,
        -0.06489598751068115,
        -0.06451991200447083,
        -0.06566352397203445,
        0.04214269667863846,
        -0.002602214924991131,
        0.05925748497247696,
        -0.06432222574949265,
        0.07892487198114395,
        -0.04431129992008209,
        -0.07864996045827866,
        0.04767927527427673,
        0.01950695924460888,
        0.06190011650323868,
        -0.04006063938140869,
        0.03871889039874077,
        -0.13453266024589539,
        -0.04785317927598953,
        0.07192522287368774,
        0.07530515640974045,
        -0.016795696690678596,
        0.1239142119884491,
        0.07093940675258636,
        -0.02233358845114708,
        -0.09900295734405518,
        0.013180737383663654,
        -0.07345250248908997,
        -0.040260229259729385,
        0.10426106303930283,
        -0.040001094341278076,
        -0.004638122860342264,
        -0.019332805648446083,
        -0.01644589938223362,
        -0.09054963290691376,
        0.05619259551167488,
        0.06330720335245132,
        -0.05493941158056259,
        0.006209289655089378,
        0.058985140174627304,
        0.044603247195482254,
        -0.03044882044196129,
        0.0005484040011651814,
        -0.029213961213827133,
        0.046253494918346405,
        0.032138947397470474,
        -0.03186895325779915,
        -0.12886805832386017,
        -0.043632231652736664,
        -0.05359087884426117,
        0.049933865666389465,
        0.03454912081360817,
        -0.023746240884065628,
        0.06414906680583954,
        0.019665967673063278,
        0.026552913710474968,
        0.03534248098731041,
        -0.028752390295267105,
        -0.03361178934574127,
        -0.007740188855677843,
        0.044164884835481644,
        -0.00897951703518629,
        -0.01672281324863434,
        0.07440697401762009,
        0.021610794588923454,
        0.025936925783753395,
        0.03353995829820633,
        0.03823240473866463,
        -0.04182826727628708,
        0.009037917479872704,
        -0.021300463005900383,
        -0.003226418048143387,
        -0.01610632799565792,
        0.0024259218480437994,
        -0.003585436614230275,
        0.025142336264252663,
        -0.10252467542886734,
        -0.019901849329471588,
        0.03827610984444618,
        0.03630288690328598,
        -0.04227322340011597,
        -0.020253986120224,
        0.03216521069407463,
        0.10594996064901352,
        -0.08955351263284683,
        -0.03633144870400429,
        -0.0075815171003341675,
        -0.15741141140460968,
        -0.005529776681214571,
        0.007015029434114695,
        -5.14606313117838e-8,
        0.019667336717247963,
        -0.06066317483782768,
        -0.01903483271598816,
        0.08141380548477173,
        0.016252892091870308,
        -0.03760909661650658,
        0.05546536669135094,
        -0.03216473385691643,
        -0.05112411826848984,
        0.02065426856279373,
        0.04057857394218445,
        -0.03949287161231041,
        0.05497374013066292,
        -0.025971079245209694,
        0.006400410085916519,
        0.0328306145966053,
        -0.01455802284181118,
        0.0693284422159195,
        -0.027862735092639923,
        -0.006219248287379742,
        0.03389189764857292,
        0.030571406707167625,
        -0.0003243646933697164,
        0.016015293076634407,
        0.07216763496398926,
        -0.11280941963195801,
        -0.05039951577782631,
        0.03971247747540474,
        0.03277059271931648,
        -0.07804666459560394,
        0.06663832813501358,
        0.00556313619017601,
        0.04660838842391968,
        0.00958919245749712,
        0.017871936783194542,
        0.01498692762106657,
        -0.006626407615840435,
        0.025168821215629578,
        -0.023826412856578827,
        0.12213706970214844,
        0.04739438742399216,
        0.022384099662303925,
        -0.056068260222673416,
        -0.015811484307050705,
        0.020506562665104866,
        -0.06439006328582764,
        0.012912578880786896,
        -0.029805069789290428,
        0.0035112109035253525,
        -0.002067247638478875,
        -0.03078620135784149,
        -0.006609165575355291,
        0.031153809279203415,
        0.034814320504665375,
        0.008541237562894821,
        0.05004558712244034,
        -0.011595717631280422,
        -0.015919193625450134,
        0.00074954325100407,
        0.013661971315741539,
        0.030309515073895454,
        0.04679466784000397,
        0.034966278821229935,
        -0.026498256251215935
      ],
      "metadata": {
        "title": "Paper_3_Fetal_Sleep__A_Cross_Species_Review_of_Physiology_.pdf",
        "createdAt": "2025-12-17T13:56:38.154Z"
      },
      "fileObj": {}
    },
    {
      "id": "doc_12_1765979799039",
      "fileName": "Paper_20_Sleep_Model____A_Sequence_Model_for_Predicting_the.pdf",
      "content": "Sleep Model ‚Äì A Sequence Model for Predicting the Next Sleep Stage  Iksoo Choi and Wonyong Sung  Department of Electrical and Computer Engineering Seoul National University   Seoul, Korea  { akacis, wysung } @snu.ac.kr  Abstract ‚ÄîAs sleep disorders are becoming more prevalent there   is   an   urgent   need   to   classify   sleep   stages   in   a   less disturbing   way.   In   particular,   sleep-stage   classification   using simple sensors, such as single-channel electroencephalography (EEG), electrooculography (EOG), electromyography (EMG), or electrocardiography (ECG) has gained substantial interest. In this study, we proposed a sleep model that predicts the next sleep stage and used it to improve sleep classification accuracy. The sleep models were built using sleep-sequence data and employed either statistical   n -gram or deep neural network-based models. We developed beam-search decoding to combine the information from the sensor and the sleep models. Furthermore, we evaluated the performance of the   n -gram and long short-term memory (LSTM) recurrent neural network (RNN)-based sleep models and demonstrated the improvement of sleep-stage classification using an EOG sensor. The developed sleep models significantly improved the accuracy of sleep-stage classification, particularly in the absence of an EEG sensor.  Index Terms ‚Äîpolysomnography, sleep stage classification, deep neural networks, beam search decoding  I. I NTRODUCTION  Currently, sleep disorders are prevalent and lead many peo- ple to seek help from a psychiatrist or specialist. The sleep test divides a sleep period into epochs, typically 30-second long, and assigns a sleep class label to each epoch. The classification guidelines of the American Association of Sleep Medicine (AASM) distinguish five sleep classes: rapid eye movement ( REM   ) sleep, three non- REM   sleep classes ( N   1 ,   N   2 , and  N   3 ), and wake ( W   ) [1]. Sleep staging is generally performed through manual visual scoring of polysomnography (PSG) that includes several signal sources, such as electroencephalog- raphy (EEG), electrooculography (EOG), electromyography (EMG), electrocardiography (ECG), and respiratory sensors! [2]. While   PSG   remains   the   gold   standard   for   the   clinical evaluation of sleep, it is impractical for long-term monitoring of sleep problems at home. In recent years, several surrogate measures have been studied to reduce the costs and discomfort associated with PSG testing. Many sleep classification studies have employed a subset of PSG sensors, including single- channel EEG, EMG, EOG, ECG, or PPG [3]‚Äì[8]. However, when compared to full PSG, these surrogate tests inevitably result in an accuracy drop. Deep neural networks (DNN) offer new opportunities to dramatically improve the accuracy of simple sleep tests [9]‚Äì[11]. While it is challenging to accurately predict the next sleep stage,   sleep   generally   follows   typical   patterns   [12].   It   is unlikely that the sleep stage changes at every epoch. When observing sleep patterns, short-term inertia or predictability appears. Additionally, the sleep pattern typically includes four to six long-term cycles overnight, each of which comprises both   REM   and non- REM   stages [13], [14]. Our study proposes a sleep model that assesses and exploits the sequential nature of sleep. The use of sleep models can help to improve sleep classification accuracy, especially when relying on only simple surrogate sensors. The sleep model concept originated from the language model that predicts the probability of the next word or character in speech or text. In particular, language models are important for improving the accuracy of speech recognition [15], [16]. In Section II we cover the background and related works, including the sleep data and signal processing models used in the study, as well as an introduction to language models. Sec- tion III presents the proposed sleep models and beam search decoding, while Section IV provides experimental results and analyses. Finally, Section V concludes the study. II. SLEEP DATA   AND   BACKGROUND INFORMATION  A. Sleep Dataset  There are many sleep datasets publically available due to a considerable number of PSG tests. These sleep datasets serve two purposes: firstly, to extract sleep sequences from simplified input signals using signal processing   and   deep neural networks; secondly, to develop sleep models based on sleep patterns observed in PSG tests. To this end, we use the Haagleanden Medisch Centrum Sleep Database (HMC) dataset for the first purpose, and both HMC and NCH Sleep DataBank (NCHSDB) datasets for the second purpose [17], [18]. The HMC dataset was divided into 98 training, 24 validation, and 29 test splits, while the NCHSDB dataset used   3036 ,   379 , and  380   records for training, validation, and testing, respectively. The signal data were pre-filtered and resampled at 100 Hz using the method described in [17]. Each epoch of the time- series data was classified into one of the five sleep stages ( W   ,  REM   ,   N   1 ,   N   2 , and   N   3 ) based on the annotations provided for a sleep recording typically eight hours long.  arXiv:2302.12709v1 [eess.SP] 17 Feb 2023\n\nB. Signal Model  Our   study   involved   the   development   of   sleep   signal- processing models capable of classifying sleep stages using either the entire PSG data or a subset of it. The aim was to evaluate the performance of these models in both beam search decoding and greedy decoding. In conventional automatic sleep-stage classification methods, the sleep class with the highest probability at each epoch is selected, a process referred to as greedy decoding in this context. To build our sleep signal model, we followed the DNN model proposed in [8], which consisted of feature extraction and classification blocks as depicted in Fig. 1. The input sensor data which included two EEG channels (C4-M1 and C3-M2), one EMG (chin), and one EOG (E2-E1) channel were applied to the feature extraction block. The feature extraction block consisted of 3 convolutional neural networks (CNN) and 1 fully-connected DNN (FC-DNN) [19], [20]. In this block, the   e th   epoch that corresponded to 30-second of PSG data,   d e , was transformed to a   64 -dimensional feature vector,   f e . The classification block employed in this study was formed using FC-DNN with a layer size of 320 and a depth of 2. To classify one sleep stage,   s e , the classification block processed five epochs of input feature vectors:   f e ‚àí 2 ,   f e ‚àí 1 ,   f e ,   f e +1 , and   f e +2 . The HMC sleep dataset was used to develop two sleep signal models. The first model utilized four channels, which included EEG, EOG, and EMG as inputs. The second model only employed EOG and had a single channel.  C. Language Model  A language model predicts the probability distribution of the next word in a corpus. The inspiration for the proposed sleep model came from language models that are frequently used in computational linguistics and probabilistic fields [21], [22]. An excellent example of such a large language model is ChatGPT, which is capable of generating human-like responses [23]. They are traditionally trained on large corpus of text data, such as Wikipedia or speech transcriptions [24], [25]. Traditionally,  n -gram based language models have been used, but in recent  Fig. 1: Signal model employing deep neural networks.  Fig. 2: The sleep model that predicts the probabilities of sleep classes in the next epoch based on the previous ones. years, DNNs such as LSTM-RNNs or Transformers have gained popularity due to their superior performance [26]‚Äì[30]. However,   n -gram-based models are easier to build and require less time for inference [31]‚Äì[33]. III. S LEEP   M ODEL AND   B EAM   S EARCH   D ECODING  A. Sleep Model  The   SL eep   M odel (SLM) proposed in this study predicts the likelihood of each sleep class for the next epoch. These classes correspond to one of the five sleep stages, as shown in Fig. 2. The SLM was constructed using training data that contains sleep sequences. Sleep stages exhibit fairly consistent patterns, and the following sleep class is heavily influenced by the preceding stages, much like language models [12], [13]. We built   n -gram SLMs in manner of an   n -gram language model. An   n -gram SLM was built in this study by approximat- ing the probability with the number of occurrences of certain patterns in the training dataset. The number of occurrences was counted while traversing the entire sleep-stage sequences in dataset. For example, a   3 -gram   ( trigram )   SLM shows the probability of the next sleep class based on the previous two sleep classes, which can have   25   ( = 5 2 ) cases. The   trigram  probability of   P  (   N   3  N   1 ,N   2  )  , which is the probability of next stage being   N   3   following previous   N   1   and   N   2   stages, can be approximated as follows:  P  (   N   3  N   1 , N   2  )  ‚âà   C   ( N   1 , N   2 , N   3)  C   ( N   1 , N   2)   ,   (1) where   C   ( N   1 , N   2)   denotes the number of occurrences or counts of sleep stages   N   1   followed by   N   2   in the data. Thus, the process of building an   n -gram model is straightforward and the accuracy of prediction generally improves with the increas- ing value of   n . However, the above approximation cannot be accurate when the number of counts in the denominator, for example   C   ( N   1 , N   2)   in Equation (1), is not sufficiently large, which is called the data scarcity problem. To avoid the problem of data scarcity, a large training data is required. Increasing   n  also results in an exponential growth in the number of possible cases ( = 5 n ‚àí 1 ). Generally, when the number of counts is very small, the modeling fallbacks to a lower   n   [34]. In addition, there should not be a zero-probability prediction for the next class. Thus, when the numerator count is zero, we need smoothing that adds small numbers to the numerator and denominator terms to ensure a computational safety. A length of 8 hours sleep consists of   960   epochs or sleep stages,\n\nthus the total number of epochs for the HMC training set was approximately   100 ,   000 . To obtain a fairly accurate probability estimation, the number of the denominator count in Equation (1) needs to be around   100 . If the sleep sequences are equally distributed, which is unrealistically optimistic, the number of different sequences that can be formed with   100 ,   000   epochs is about   1 ,   000 , which can be approximated to   625   ( = 5 4 ) . Thus, we consider that the meaningful   n -gram size for HMC dataset would be around   n   = 5 . We also developed SLMs based on the LSTM-RNN archi- tecture by varying the number of LSTM layers or the hidden dimension of each LSTM layer [26]. The LSTM is a type of RNN architecture that has internal states to retain latent information from previous sequences. This property makes LSTM based SLMs unrestricted by previous sequence length, in contrast to   n -gram models, which are limited to a length of   n   ‚àí   1 . The network architecture of the LSTM based SLM consists of a sleep stage embedding layer, LSTM layers, and a softmax output layer.  B. Beam Search Decoding  Typical automatic sleep-stage classification only employs a sleep signal model. In the signal model, we can simply select the sleep class with the highest probability from each position in the sequence, which is often called greedy decoding. When surrogate sensors are used for sleep tests, the accuracy of the signal model with greedy decoding is not sufficiently high. The recognition accuracy of greedy decoding can be im- proved using a SLM. The output of the SLM provides the prior information for sleep classification. The posterior probability was determined by multiplying, addition in the   log   domain, the probability of the signal model ( P sig   ) by that of the SLM ( P SLM   ) using Equation (2).  log   P   ( s e ) = log   P sig   ( s e | d e ‚àí 2 , . . . , d e +2 ) +   Œ±   log   P SLM   ( s e | s 1 , . . . , s e ‚àí 1 )   ,   (2) where   d   is input signal,   s   denotes the sleep stages,   e   in subscript means the   e th   epoch, and   Œ±   is a parameter that as- signs a balanced weight between the signal and sleep models. Here, the signal model generates the likelihood of the sleep class using the input signal, whereas the SLM provides the prior probability. Sleep-stage classification can be considered a sequence recognition problem, that is, we need to consider the results over a long time span. The beam-search-decoding algorithm can select multiple sleep classes for each epoch in a given sequence [35]‚Äì[37]. This means that even sleep classes that do not show the highest probability can be saved for fur- ther evaluations in the future. Because the number of sequence candidates grows exponentially as decoding progresses, it is not possible to retain all of them. The algorithm chooses the  W   -best alternatives via a hyperparameter known as the beam width. The posterior probability for each epoch was obtained by multiplying the probabilities obtained from the signal and sleep models. To determine the most likely beam, the posterior probabilities of each beam sequence are multiplied, and the TABLE I:   2 -gram ( bigram ) sleep model probability table for HMC train split.  Previous Sleep Stage Next Sleep stage  W   REM   N   1   N   2   N   3  W   0.854   0.001   0.138   0.003   0.000  REM   0.016   0.907   0.066   0.010   0.000  N   1   0.109   0.080   0.498   0.311   0.000  N   2   0.019   0.014   0.062   0.864   0.040  N   3   0.007   0.001   0.007   0.063   0.921  resulting probability values are compared to select the highest one.  C. Model Details and Metric  We built the   n -gram model using KenLM, which imple- ments fall-back, smoothing, and data compression [38]. We evaluated   n -gram models on HMC and NCHSDB dataset, varying   n   from   2   to   9 , and applied the fall-back option. We also developed four kinds of LSTM-RNN based SLMs, 2 or 4 LSTM layers with 256 or 1,024 hidden dimensions on training split of each dataset. The performance of language models is commonly mea- sured by the perplexity [39]. The perplexity is defined as the inverse probability of the sequence of words,   w , normalized by the number of words,   N   , as shown in Equation 3,  P erplexity   ( w 1 , w 2 , . . . , w N   ) =   N  ‚àö  1  P   ( w 1 , w 2 , . . . , w N   )   . (3) We also used the perplexity to measure the performance of SLMs. A lower perplexity value indicates better performance of the SLM in predicting the next sleep stage. IV. E XPERIMENTAL   R ESULTS  A.   n -gram and LSTM-RNN based Sleep Models  Table I shows the   2 -gram ( bigram ) probabilities on the HMC dataset. This table shows that the probability of   REM  stage at the next epoch is 8% when the current sleep stage  Fig. 3: The test set perplexity of   n -gram sleep models with HMC or NCHSDB dataset.\n\nTABLE II: The validation and test set perplexities of LSTM- RNN based SLMs trained with training split of HMC or NCHSDB dataset. The numbers in the first column represent (the number of layers)   √ó   (the size of the hidden dimension) for each SLM.  LSTM-RNN Sleep Model HMC   NCHSDB Valid. set   Test set   Valid. set   Test set 2 √ó   256   1.546   1.609   1.293   1.287 2 √ó 1024   1.547   1.608   1.291   1.286  4 √ó   256   1.547   1.613   1.293   1.287 4 √ó 1024   1.548   1.610   1.291   1.286  is   N   1 . As expected, the diagonal terms show high values, indicating the inertia of repeating the same sleep classes. The transition probability from   N   1   to   N   2   is quite high and exhibits a low inertia of the   N   1   stage. As a result, classification between   N   1   and   N   2   introduces many errors. The perplexity of   n -gram SLMs, when assessed with the test dataset, is shown in Fig. 3. For HMC dataset, it shows that the perplexity decreased as   n   increased until   n   = 5 , but then increased thereafter. As described in Section III, the back- off and smoothing algorithms implemented in KenLM have an impact on performance distortion when   n   is greater than 5. The size of NCHSDB dataset was approximately 20 times larger than HMC dataset, we can expect improved SLM performance and less sensitive to   n . Next we trained LSTM-RNN based SLMs using HMC or NCHSDB training set. Table II shows the perplexity accord- ing to different LSTM-RNN based SLM configurations. The results confirm that LSTM-RNN based SLMs are better than the   n -gram based ones. The experimental resutls indicated that the size of training set had a significant impact on the SLM performance. The SLMs trained on the NCHSDB dataset performed relatively better than those with HMC. This implies that building a good SLM requires at least   1 ,   000   records. The performance of the SLM was affected by the characteristics of the sleep sequence, as evidenced by the difference in performance between the LSTM-RNN based SLM trained on the NCHSDB and tested on the HMC test set. The SLM was configured with 2 LSTM layers and a hidden dimension of   1 ,   024 , and achieved a perplexity of   1 . 286   on the NCHSDB test set, but only   1 . 654  on the HMC data. This difference is likely due to the fact that the sleep records in the HMC dataset are from adults, while those in the NCHSDB are from pediatrics, resulting in different sleep patterns that affect the inter-dataset performance of the SLMs.  B. Beam Search Decoding for Combining Signal and Sleep Models  We combined the 4-channel and 1-channel sleep signal models, explained in Section II-B, with the LSTM-RNN based SLM through beam-search decoding. The 4-channel signal model was combined with the LSTM-RNN based SLM used in IV-A with the optimum   Œ± , as described in Equation (2), TABLE III: The performance of the LSTM-RNN SLMs with 4 or 1 -channel signal models. The SLMs had 2 layers of LSTM with 1,024 hidden dimensions.  (a) 4-Channel Signal Model  Sleep Stage Classification Model   Œ±   Valid. set   Test set Kappa   Acc.   Kappa   Acc. Signal Model   N/A   0.741   0.804   0.680   0.759 + SLM Decording   0.12   0.680   0.759   0.680   0.759  (b) 1-Channel Signal Model  Sleep Stage Classification Model   Œ±   Valid. set   Test set Kappa   Acc.   Kappa   Acc. Signal Model   N/A   0.505   0.629   0.464   0.602 + SLM Decording   0.42   0.596   0.698   0.519   0.644  TABLE IV: The effect of probability weighting factor. The beam width was 128 and 1-channel signal model with 2 √ó 1024 LSTM-RNN SLM was evaluated.  Œ±   Valid. set   Test set Kappa   Acc.   Kappa   Acc. 0.34   0.587   0.692   0.517   0.642 0.38   0.592   0.696   0.516   0.642 0.42   0.596   0.698   0.519   0.644  0.46   0.588   0.693   0.515   0.640 0.50   0.594   0.697   0.511   0.638  of   0 . 12   and a beam width of   128 . The evaluation results are shown in Table III (a). The classification results based on greedy decoding for the signal models that do not utilize SLMs are labeled as ‚ÄòSignal Model‚Äô. Despite our attempts to improve decoding performance by incorporating the SLM, the results were not notably affected by varying   Œ±   values ranging from  0 . 2   to   1 . 5 . This is likely due to the highly informative nature of the 4-channel signal model, which employed two channels of EEG and one channel each of EMG and EOG as input. The results in Table III (b) demonstrate the 1-channel signal model when combined with the same SLM. The combination resulted in a   6 . 5%   improvement in Kappa score and a   4 . 3%  improvement in accuracy, despite the lower accuracy of sleep- stage classification using EOG alone compared to the 4- channel PSG signal. We used a beam width of 128 and searched for the best   Œ±   on the validation set, and the results of the   Œ±   search are listed in Table IV. The findings indicate that utilizing SLMs in sleep-stage classification can be beneficial, particularly when working with limited signal information, such as a single input channel or surrogate signals. This approach has the potential to be applied to other input modalities or different contexts to improve sleep- stage classification. V. C ONCLUSION  Our study proposed sleep models for predicting the next sleep stage, which can significantly enhance sleep classifica- tion accuracy by utilizing information from numerous sleep-\n\nstage sequences and extending the context length. Our models were applied to sleep-stage classification using simple EOG sensors. Sleep-stage sequences, rather than the signal sources, are the only data required to train sleep models, making them compatible with various sleep archives. Furthermore, once sleep models have been built, they can be employed in sleep- stage classification using different sensors, such as PPG, EOG, or ECG. R EFERENCES [1]   Richard B Berry, Rita Brooks, Charlene E Gamaldo, Susan M Harding, Robin M Lloyd, Carole L Marcus, and B Vaughn, ‚ÄúThe aasm manual for the scoring of sleep and associated events, version 2.4,‚Äù   Chicago: American Academy of Sleep Medicine , 2017. [2]   Clete A Kushida, Michael R Littner, Timothy Morgenthaler, Cathy A Alessi, Dennis Bailey, Jack Coleman Jr, Leah Friedman, Max Hir- shkowitz, Sheldon Kapen, Milton Kramer, et al., ‚ÄúPractice parameters for the indications for polysomnography and related procedures: an update for 2005,‚Äù   Sleep , vol. 28, no. 4, pp. 499‚Äì523, 2005. [3]   Mathias Perslev, Michael Jensen, Sune Darkner, Poul J√∏rgen Jennum, and Christian Igel,   ‚ÄúU-time: A fully convolutional network for time series segmentation applied to sleep staging,‚Äù   Advances in Neural Information Processing Systems , vol. 32, 2019. [4]   Md   Mosheyur   Rahman,   Mohammed   Imamul   Hassan   Bhuiyan,   and Ahnaf Rashik Hassan, ‚ÄúSleep stage classification using single-channel eog,‚Äù   Computers in biology and medicine , vol. 102, pp. 211‚Äì220, 2018. [5]   Mustafa Radha, Pedro Fonseca, Arnaud Moreau, Marco Ross, Andreas Cerny,   Peter   Anderer,   Xi   Long,   and   Ronald   M   Aarts,   ‚ÄúA   deep transfer learning approach for wearable sleep stage classification with photoplethysmography,‚Äù   NPJ digital medicine , vol. 4, no. 1, pp. 1‚Äì11, 2021. [6]   Qiao Li, Qichen Li, Chengyu Liu, Supreeth P Shashikumar, Shamim Nemati, and Gari D Clifford,   ‚ÄúDeep learning in the cross-time fre- quency domain for sleep staging from a single-lead electrocardiogram,‚Äù  Physiological measurement , vol. 39, no. 12, pp. 124005, 2018. [7]   Pedro Fonseca, Xi Long, Mustafa Radha, Reinder Haakma, Ronald M Aarts, and J¬¥ erÀÜ ome Rolink,   ‚ÄúSleep stage classification with ecg and respiratory effort,‚Äù   Physiological measurement , vol. 36, no. 10, pp. 2027, 2015. [8]   Iksoo Choi and Wonyong Sung, ‚ÄúPerformance assessment of automatic sleep stage classification using only partial psg sensors,‚Äù in   2022 IEEE Biomedical Circuits and Systems Conference (BioCAS) . IEEE, 2022, pp. 670‚Äì674. [9]   Mustafa Radha, Pedro Fonseca, Arnaud Moreau, Marco Ross, Andreas Cerny, Peter Anderer, Xi Long, and Ronald M Aarts,   ‚ÄúSleep stage classification from heart-rate variability using long short-term memory neural networks,‚Äù   Scientific reports , vol. 9, no. 1, pp. 14149, 2019. [10]   Huy Phan, Fernando Andreotti, Navin Cooray, Oliver Y Ch¬¥ en, and Maarten De Vos, ‚ÄúSeqsleepnet: end-to-end hierarchical recurrent neural network   for   sequence-to-sequence   automatic   sleep   staging,‚Äù   IEEE Transactions on Neural Systems and Rehabilitation Engineering , vol. 27, no. 3, pp. 400‚Äì410, 2019. [11]   Dani Kiyasseh, Tingting Zhu, and David A Clifton, ‚ÄúClocs: Contrastive learning   of   cardiac   signals   across   space,   time,   and   patients,‚Äù   in  International Conference on Machine Learning . PMLR, 2021, pp. 5606‚Äì 5615. [12]   Irwin Feinberg, ‚ÄúChanges in sleep cycle patterns with age,‚Äù   Journal of psychiatric research , vol. 10, no. 3-4, pp. 283‚Äì306, 1974. [13]   Agnessa Babloyantz, JM Salazar, and C Nicolis, ‚ÄúEvidence of chaotic dynamics of brain activity during the sleep cycle,‚Äù   Physics letters A , vol. 111, no. 3, pp. 152‚Äì156, 1985. [14]   Antonino Crivello, Paolo Barsocchi, Michele Girolami, and Filippo Palumbo,   ‚ÄúThe meaning of sleep quality: a survey of available tech- nologies,‚Äù   IEEE access , vol. 7, pp. 167374‚Äì167390, 2019. [15]   Kyuyeon Hwang and Wonyong Sung,   ‚ÄúCharacter-level incremental speech recognition with recurrent neural networks,‚Äù   in   2016 IEEE international conference on acoustics, speech and signal processing (ICASSP) . IEEE, 2016, pp. 5335‚Äì5339. [16]   Tomohiro Nakatani,   ‚ÄúImproving transformer-based end-to-end speech recognition   with   connectionist   temporal   classification   and   language model integration,‚Äù in   Proc. Interspeech , 2019. [17]   Diego Alvarez-Estevez and Roselyne Rijsman,   ‚ÄúHaaglanden medisch centrum   sleep   staging   database   (version   1.0.1),‚Äù   PhysioNet. https://doi.org/10.13026/7egw-0p30 , 2021. [18]   Guo-Qiang Zhang, Licong Cui, Remo Mueller, Shiqiang Tao, Matthew Kim, Michael Rueschman, Sara Mariani, Daniel Mobley, and Susan Redline,   ‚ÄúThe national sleep research resource: towards a sleep data commons,‚Äù   Journal of the American Medical Informatics Association , vol. 25, no. 10, pp. 1351‚Äì1358, 2018. [19]   Yann LeCun, Yoshua Bengio, and Geoffrey Hinton,   ‚ÄúDeep learning,‚Äù  nature , vol. 521, no. 7553, pp. 436‚Äì444, 2015. [20]   Yann LeCun, Yoshua Bengio, et al., ‚ÄúConvolutional networks for images, speech, and time series,‚Äù   The handbook of brain theory and neural networks , vol. 3361, no. 10, pp. 1995, 1995. [21]   Yoshua Bengio, R¬¥ ejean Ducharme, and Pascal Vincent, ‚ÄúA neural prob- abilistic language model,‚Äù   Advances in neural information processing systems , vol. 13, 2000. [22]   Peter F Brown, Vincent J Della Pietra, Peter V Desouza, Jennifer C Lai, and Robert L Mercer, ‚ÄúClass-based n-gram models of natural language,‚Äù  Computational linguistics , vol. 18, no. 4, pp. 467‚Äì480, 1992. [23]   Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al., ‚ÄúLanguage models are few-shot learners,‚Äù  Advances in neural information processing systems , vol. 33, pp. 1877‚Äì 1901, 2020. [24]   Jey Han Lau, Alexander Clark, and Shalom Lappin, ‚ÄúGrammaticality, acceptability, and probability: A probabilistic view of linguistic knowl- edge,‚Äù   Cognitive science , vol. 41, no. 5, pp. 1202‚Äì1241, 2017. [25]   Jerome R Bellegarda,   ‚ÄúStatistical language model adaptation: review and perspectives,‚Äù   Speech communication , vol. 42, no. 1, pp. 93‚Äì108, 2004. [26]   Sepp Hochreiter and J¬® urgen Schmidhuber, ‚ÄúLong short-term memory,‚Äù  Neural computation , vol. 9, no. 8, pp. 1735‚Äì1780, 1997. [27]   Iksoo Choi, Jinhwan Park, and Wonyong Sung,   ‚ÄúCharacter-level lan- guage modeling with gated hierarchical recurrent neural networks.,‚Äù in  INTERSPEECH , 2018, pp. 411‚Äì415. [28]   Stephen Merity, Nitish Shirish Keskar, and Richard Socher,   ‚ÄúReg- ularizing   and   optimizing   lstm   language   models,‚Äù   arXiv   preprint arXiv:1708.02182 , 2017. [29]   Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, ≈Åukasz Kaiser, and Illia Polosukhin, ‚ÄúAttention is all you need,‚Äù   Advances in neural information processing systems , vol. 30, 2017. [30]   Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova, ‚ÄúBert:   Pre-training   of   deep   bidirectional   transformers   for   language understanding,‚Äù   arXiv preprint arXiv:1810.04805 , 2018. [31]   Martin Sundermeyer, Ralf Schl¬® uter, and Hermann Ney,   ‚ÄúLstm neural networks for language modeling,‚Äù   in   Thirteenth annual conference of the international speech communication association , 2012. [32]   Aytug Onan and Mansur Alp Toc ¬∏oÀò glu, ‚ÄúA term weighted neural language model and stacked bidirectional lstm based framework for sarcasm identification,‚Äù   IEEE Access , vol. 9, pp. 7701‚Äì7722, 2021. [33]   Ehsan Shareghi, Daniela Gerz, Ivan Vuli¬¥ c, and Anna Korhonen, ‚ÄúShow some love to your n-grams: A bit of progress and stronger n-gram language modeling baselines,‚Äù in   Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) , 2019, pp. 4113‚Äì4118. [34]   Stanley F Chen and Joshua Goodman, ‚ÄúAn empirical study of smoothing techniques for language modeling,‚Äù   Computer Speech & Language , vol. 13, no. 4, pp. 359‚Äì394, 1999. [35]   Volker Steinbiss, Bach-Hiep Tran, and Hermann Ney,   ‚ÄúImprovements in beam search,‚Äù in   Third international conference on spoken language processing , 1994. [36]   Peng Si Ow and Thomas E Morton, ‚ÄúFiltered beam search in schedul- ing,‚Äù   The International Journal Of Production Research , vol. 26, no. 1, pp. 35‚Äì62, 1988. [37]   Christoph Tillmann and Hermann Ney, ‚ÄúWord reordering and a dynamic programming beam search algorithm for statistical machine translation,‚Äù  Computational linguistics , vol. 29, no. 1, pp. 97‚Äì133, 2003. [38]   Kenneth Heafield, ‚ÄúKenlm: Faster and smaller language model queries,‚Äù in   Proceedings of the sixth workshop on statistical machine translation , 2011, pp. 187‚Äì197. [39]   Fred Jelinek, Robert L Mercer, Lalit R Bahl, and James K Baker, ‚ÄúPerplexity‚Äîa measure of the difficulty of speech recognition tasks,‚Äù\n\nThe Journal of the Acoustical Society of America , vol. 62, no. S1, pp. S63‚ÄìS63, 1977.",
      "embedding": [
        -0.038291461765766144,
        -0.07157956063747406,
        0.05222432315349579,
        0.013544603250920773,
        0.043469104915857315,
        0.04687725380063057,
        -0.0018006634199991822,
        -0.007709525991231203,
        0.05285866931080818,
        -0.04754846915602684,
        -0.08431816101074219,
        -0.03682929649949074,
        -0.006510126404464245,
        0.0259687639772892,
        -0.058385949581861496,
        -0.0953567624092102,
        0.006924172397702932,
        0.05674339830875397,
        -0.004282407462596893,
        0.005865780171006918,
        0.1409902274608612,
        0.028127923607826233,
        0.08487934619188309,
        -0.011277480982244015,
        -0.02002989500761032,
        -0.015761572867631912,
        0.03024434857070446,
        -0.01634201593697071,
        -0.04912624508142471,
        -0.039112064987421036,
        0.011643733829259872,
        0.03482292219996452,
        0.01340558659285307,
        0.04142168536782265,
        -0.04965643212199211,
        0.02376570925116539,
        -0.021345682442188263,
        -0.029765021055936813,
        -0.09628584235906601,
        0.00920996442437172,
        0.021360039710998535,
        0.018854623660445213,
        0.030160702764987946,
        -0.010857107117772102,
        0.07657209038734436,
        -0.003408772172406316,
        -0.051041219383478165,
        -0.12068828195333481,
        -0.0314343124628067,
        0.042750969529151917,
        -0.027954325079917908,
        -0.020990613847970963,
        -0.009324658662080765,
        0.10631062835454941,
        -0.028052911162376404,
        -0.013343666680157185,
        -0.05857625603675842,
        -0.0030571254901587963,
        0.008783130906522274,
        0.0653209239244461,
        -0.0605383925139904,
        0.012516679242253304,
        0.03597455471754074,
        -0.05424773693084717,
        -0.00999694038182497,
        0.06870485842227936,
        -0.010713420808315277,
        0.01491718739271164,
        0.02371748723089695,
        -0.030542470514774323,
        -0.08043225854635239,
        -0.018829060718417168,
        0.006777511909604073,
        -0.0019254992948845029,
        -0.09821031242609024,
        0.02969198115170002,
        0.14378848671913147,
        0.011427382007241249,
        0.08186562359333038,
        -0.044518157839775085,
        -0.007763667963445187,
        0.05466039851307869,
        0.005504633765667677,
        -0.08625448495149612,
        0.037321142852306366,
        0.027149608358740807,
        0.03893075883388519,
        0.05357830971479416,
        -0.07214938849210739,
        -0.02100672759115696,
        0.07738815993070602,
        -0.05554823577404022,
        -0.030131962150335312,
        -0.01414806954562664,
        0.06864898651838303,
        0.04977282136678696,
        -0.02147730067372322,
        0.04389970377087593,
        0.019563347101211548,
        -0.008638221770524979,
        0.007211305666714907,
        0.08007015287876129,
        0.02750490978360176,
        -0.020929178223013878,
        0.017081931233406067,
        -0.009192937053740025,
        0.052295997738838196,
        -0.011032789945602417,
        0.0650739073753357,
        -0.05252021178603172,
        -0.05357452481985092,
        0.048916902393102646,
        -0.04263387992978096,
        0.006490426603704691,
        0.07339493930339813,
        0.02823418565094471,
        -0.046009182929992676,
        0.025877682492136955,
        0.09316293895244598,
        0.12300451844930649,
        0.034004759043455124,
        -0.042176924645900726,
        0.004922141321003437,
        -0.08926519751548767,
        0.06998495012521744,
        0.0026030424050986767,
        -0.12273848056793213,
        3.392201189984648e-33,
        -0.02806767262518406,
        -0.009772065095603466,
        -0.020756026729941368,
        -0.014550736173987389,
        -0.03675257787108421,
        -0.023728709667921066,
        -0.05232000723481178,
        0.11034203320741653,
        0.019994238391518593,
        0.07218549400568008,
        -0.10599181801080704,
        0.04697580635547638,
        0.005464587826281786,
        0.06422770768404007,
        0.04088214039802551,
        0.026206381618976593,
        -0.05744590982794762,
        0.04302186891436577,
        -0.01365590188652277,
        -0.04687120020389557,
        0.02475569024682045,
        -0.04909006506204605,
        0.08355087041854858,
        -0.009221700020134449,
        -0.005940346512943506,
        0.05875293165445328,
        -0.02010296657681465,
        -0.011283091269433498,
        -0.0549568347632885,
        0.014776328578591347,
        -0.045724205672740936,
        0.007176424376666546,
        0.010963180102407932,
        -0.03144567087292671,
        0.028825482353568077,
        -0.037833284586668015,
        0.030946051701903343,
        0.07754611223936081,
        0.0071961535140872,
        -0.06458345800638199,
        -0.056070275604724884,
        0.03930028900504112,
        -0.00331823225133121,
        0.032230593264102936,
        0.04236046224832535,
        -0.02989448420703411,
        -0.013888116925954819,
        0.02403797209262848,
        0.05700478330254555,
        0.002644556574523449,
        -0.008271584287285805,
        -0.0644349604845047,
        -0.06374327838420868,
        -0.07274746149778366,
        -0.04341581463813782,
        0.09066202491521835,
        0.011587321758270264,
        0.03833406791090965,
        -0.03391028568148613,
        0.053040146827697754,
        -0.020079784095287323,
        0.06256534159183502,
        0.0479799248278141,
        -0.015559392981231213,
        0.04646173492074013,
        0.0218560341745615,
        -0.06555381417274475,
        0.033790215849876404,
        -0.018875325098633766,
        -0.06555996090173721,
        0.043825894594192505,
        -0.040842246264219284,
        0.04898475855588913,
        0.04113258793950081,
        0.03450753912329674,
        0.0234222412109375,
        0.011502450332045555,
        0.026515226811170578,
        -0.12100869417190552,
        -0.008778998628258705,
        0.06573230028152466,
        0.019352693110704422,
        -0.024095404893159866,
        -0.07284656167030334,
        0.013271025381982327,
        -0.06036427617073059,
        0.00828491523861885,
        0.02385105937719345,
        -0.1045248731970787,
        -0.013356552459299564,
        -0.04654765874147415,
        0.040555212646722794,
        0.043571535497903824,
        0.008403140120208263,
        -0.06712137162685394,
        -3.1380519644971766e-33,
        -0.01591726392507553,
        0.02097253128886223,
        -0.07868172228336334,
        -0.01871316507458687,
        0.05053353309631348,
        -0.047891177237033844,
        0.061454758048057556,
        -0.00176116987131536,
        -0.03352167829871178,
        -0.01493059378117323,
        0.028944972902536392,
        -0.0489516481757164,
        0.046303048729896545,
        0.020267227664589882,
        0.04498625546693802,
        0.007416704203933477,
        -0.07036293298006058,
        0.018705304712057114,
        -0.04248746111989021,
        0.13891291618347168,
        0.010345636866986752,
        0.06949792802333832,
        -0.14362867176532745,
        -0.04912959784269333,
        0.0003309636958874762,
        0.06417471170425415,
        0.041209399700164795,
        0.12204858660697937,
        0.016200251877307892,
        -0.08510152250528336,
        -0.03462792560458183,
        -0.04900817573070526,
        -0.08829516172409058,
        0.007485700771212578,
        -0.007601106073707342,
        -0.009350234642624855,
        0.032546572387218475,
        -0.0834612250328064,
        -0.038926366716623306,
        -0.03679361566901207,
        0.10452383011579514,
        0.1052534356713295,
        0.002318848390132189,
        -0.039023980498313904,
        0.020575806498527527,
        -0.0019329292699694633,
        -0.04109756648540497,
        0.017559688538312912,
        -0.012088309973478317,
        -0.020885437726974487,
        -0.019573688507080078,
        0.006755797658115625,
        -0.0771472305059433,
        0.009631158784031868,
        -0.03644081577658653,
        -0.0014283763011917472,
        -0.10314158350229263,
        0.021003611385822296,
        -0.055701639503240585,
        -0.0077450028620660305,
        0.035567134618759155,
        -0.0016133632743731141,
        0.029537394642829895,
        -0.004009875003248453,
        0.0445680096745491,
        0.018946925178170204,
        0.041400689631700516,
        -0.03543821722269058,
        0.03929376229643822,
        -0.045950647443532944,
        0.010847731493413448,
        0.0015118165174499154,
        0.00683405390009284,
        0.08562446385622025,
        -0.027673132717609406,
        -0.012600883841514587,
        0.004151094239205122,
        -0.06396304070949554,
        -0.06175912916660309,
        -0.12114140391349792,
        0.0023553879000246525,
        -0.10929399728775024,
        -0.051146186888217926,
        0.10219991952180862,
        -0.004855941981077194,
        0.0077154855243861675,
        0.0789128988981247,
        0.009807701222598553,
        0.09787789732217789,
        -0.08234485983848572,
        -0.057596247643232346,
        0.04870937392115593,
        -0.06393571943044662,
        0.04918525740504265,
        0.01449545007199049,
        -5.1573788795167275e-8,
        -0.003420318244025111,
        -0.04447363689541817,
        0.07066735625267029,
        0.004871020093560219,
        0.010911324992775917,
        -0.12051041424274445,
        0.03040212206542492,
        -0.0002746804093476385,
        -0.06445194035768509,
        -0.01992672309279442,
        0.11283716559410095,
        -0.007474515121430159,
        -0.016750775277614594,
        -0.05854753032326698,
        0.021166274324059486,
        -0.041319169104099274,
        0.04614043980836868,
        0.08007533103227615,
        0.011922163888812065,
        0.007952677085995674,
        0.05885901302099228,
        -0.024432431906461716,
        0.01241601537913084,
        0.007916228845715523,
        0.13592912256717682,
        -0.02677825465798378,
        -0.008207473903894424,
        0.05344858020544052,
        -0.006025329697877169,
        -0.04320725053548813,
        0.05606774240732193,
        0.03362303599715233,
        0.03439949452877045,
        0.013703789561986923,
        -0.012917552143335342,
        -0.026161378249526024,
        0.06460221111774445,
        -0.023945437744259834,
        -0.02240755595266819,
        0.09724941104650497,
        0.0015879642451182008,
        -0.059715572744607925,
        -0.04479045793414116,
        -0.01160160731524229,
        -0.031300924718379974,
        -0.07441278547048569,
        0.09379009157419205,
        -0.1401437520980835,
        0.08647412806749344,
        0.03808065876364708,
        -0.02170940302312374,
        -0.052723199129104614,
        -0.02431625686585903,
        -0.03949287533760071,
        0.05032395198941231,
        0.015264013782143593,
        0.0326414592564106,
        -0.06498607993125916,
        -0.008566840551793575,
        0.0036275703459978104,
        0.0443180575966835,
        -0.007146697957068682,
        -0.06820712238550186,
        0.013578381389379501
      ],
      "metadata": {
        "title": "Paper_20_Sleep_Model____A_Sequence_Model_for_Predicting_the.pdf",
        "createdAt": "2025-12-17T13:56:39.039Z"
      },
      "fileObj": {}
    },
    {
      "id": "doc_13_1765979799946",
      "fileName": "Paper_2_A_Large_Collection_of_Real_world_Pediatric_Sleep_S.pdf",
      "content": "A large collection of real-world pediatric sleep studies  Harlin Lee, 1   Boyue Li, 1   Shelly DeForte, 2   Mark L. Splaingard, 2  Yungui Huang, 2   Yuejie Chi, 1*   Simon L. Linwood 3*  Abstract  Despite being crucial to health and quality of life, sleep‚Äîespecially pediatric sleep‚Äîis not yet well understood.   This is exacerbated by lack of access to sufficient pediatric sleep data with clinical annotation. In order to accelerate research on pediatric sleep and its connection to health, we create the Nationwide Children‚Äôs Hospital (NCH) Sleep DataBank and publish it at Physionet and the National Sleep Research Resource (NSRR), which is a large sleep data common with physiological data, clinical data, and tools for analyses. The NCH Sleep Data- Bank consists of 3,984 polysomnography studies and over 5.6 million clinical observations on 3,673 unique patients between 2017 and 2019 at NCH. The novelties of this dataset include: 1) large-scale sleep dataset suitable for discovering new insights via data mining, 2) explicit focus on pediatric patients, 3) gathered in a real-world clinical setting, and 4) the accompanying rich set of clinical data. The NCH Sleep DataBank is a valuable resource for advancing automatic sleep scoring and real-time sleep disorder prediction, among many other potential scientific discoveries.  Background & Summary  Sleep is an active process associated with physiological changes that involve multiple organ systems, and is vital for the maturation and daily functioning of infants, children and adolescents. Conse- quently, disruption of the complex interplay between sleep and other physiological processes can lead to significant medical consequences [1].   Sleep disorders, like obstructive sleep apnea (OSA) [2, 3], can lead to derangements in function that contribute to significant morbidity and even mor- tality. Sleep can also be disrupted by many organ-specific diseases like asthma, sickle cell disease, renal failure, or depression that alter the course of a particular medical condition and result in a poorer quality of life. Sleep disturbances in children are classified as behavioral insomnias of children, sleep-related breathing disorders, parasomnias, sleep-related movement disorders, circadian rhythm disorders or hypersomnias [4].   These sleep disorders may be associated with excessive daytime sleepiness (rare in young children), hyperactivity‚Äìimpaired attention, poor school performance from impaired concentration and vigilance, and behavior problems including irritability. Sleep problems suffer from under-reporting by parents and under-diagnosis by primary care physicians, but are conservatively estimated to occur in approximately 25% of healthy children  1. Department of Electrical and Computer Engineering, Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh PA 15213, USA. 2. Nationwide Children‚Äôs Hospital, 700 Children‚Äôs Drive, Columbus OH 43205, USA. 3. School of Medicine, University of California, Riverside, 92521 Botanic Gardens Drive, Riverside CA 92507, USA. *Corresponding authors: Yuejie Chi (yuejiechi@cmu.edu), Simon Lin Linwood (simon.linwood@ucr.edu)  1  arXiv:2102.13284v4 [eess.SP] 22 Jun 2022\n\nyounger than 5 years and in up to 80% of children with special health care needs.   Estimates of prevalence of sleep disorders in children vary more widely for behavioral sleep problems like insomnia than organic sleep problems like OSA. While some childhood sleep disorders need only medical history to be properly diagnosed and managed, some infants and children require an analysis of the child actually sleeping, called an overnight sleep study or polysomnography (PSG), to accurately diagnose their sleep-related con- dition. During an overnight PSG, the sleeping child‚Äôs physiological signals are recorded under the direct supervision of specially trained sleep technicians, who attach monitoring sensors to special computer software and adjust them during the night.   The technician also provides observations about the child‚Äôs sleep that are invaluable in making an accurate diagnosis. Video monitoring is also incorporated into the PSG, allowing review of movements necessary to diagnose nocturnal seizures, which occur in about 20% of children with epilepsy. The physiological data collected during a PSG provide a picture of clinically useful information about different sleep stages, sleep disruption, respiratory status during different sleep stages, leg movements, and changes in cardiac rate and rhythm during sleep. For instance, episodes of OSA may consist of decreased airflow in spite of normal respiratory effort in thoracic and abdominal belts, changes in electroencephalogram (EEG) pattern called arousals, cardiac deceleration, and oxygen desaturation.   These findings may be mild during non-random eye movement (non-REM) sleep but profound during REM sleep. Computational algorithms that learn from large amounts of data have seen remarkable success in healthcare, particularly with the proliferation of electronic health records (EHR) and improved sensors. Regrettably, without a curated and comprehensive dataset of substantial size and acces- sibility, pediatric sleep has not been able to fully benefit from such opportunities yet.   As a first step, this data descriptor introduces the Nationwide Children‚Äôs Hospital (NCH) Sleep DataBank, which has 3,984 pediatric sleep studies on 3,673 unique patients conducted at NCH between 2017 and 2019, along with the patients‚Äô longitudinal clinical data. They were gathered in the real-world clinical setting at NCH as opposed to, for example, a controlled clinical trial. The published PSG contain the patient‚Äôs physiological signals as well as the technician‚Äôs assessment of the sleep stages and descriptions of additional irregularities [5].   The accompanying 5.6 million records of clinical data are extracted from the EHR, and are separated into encounters, medications, measurements (e.g.   body mass index), diagnoses, and procedures.   The dataset is deposited in the National Sleep Research Resource (NSRR) [6] and Physionet [7, 8], and can be requested from   https: //sleepdata.org/datasets/nchsdb   or   https://physionet.org/content/nch-sleep .   Accom- panying code in Python to assist users in interacting with the dataset is published at   https: //github.com/liboyue/sleep_study . We expect the NCH Sleep DataBank to be used to study many problems related to pediatric sleep, including but not limited to:  ‚Ä¢   Automatic sleep stage classification, especially algorithms that combine modalities beyond EEG or ECG [9, 10, 11, 12, 13].  ‚Ä¢   Automatic real-time sleep disorder (e.g. OSA) detection [14, 15].  ‚Ä¢   Diagnosis prediction.  ‚Ä¢   Patient subtyping.   There is increasing evidence that many sleep disorders (e.g.   insomnia [16]) are heterogeneous and have different subtypes. Identifying them can help us understand 2\n\nthe disorder better and develop a more tailored course of treatment for different groups of patients.  ‚Ä¢   Treatment (e.g. medications and procedures) efficacy analysis.  Methods  Sleep study data acquisition  The NCH Sleep DataBank contains sleep studies acquired under standard care at NCH between Dec. 16, 2017 and Dec. 31, 2019 using Natus Sleepworks versions 8 and 9 [17, 18]. Physiological data collected during an overnight sleep study contain:  ‚Ä¢   Electroencephalogram (EEG) to identify sleep stages,  ‚Ä¢   Electromyelogram (EMG) of chin activity to help identify the decreased tone seen during REM sleep,  ‚Ä¢   Leg EMG to measure leg movements,  ‚Ä¢   Electrooculogram (EOG) to identify characteristic eye movements seen during REM sleep,  ‚Ä¢   Electrocardiogram (ECG) to monitor cardiac rate and rhythm,  ‚Ä¢   Nasal and oral sensors to measure airflow,  ‚Ä¢   Thoracic and abdominal belts to measure chest and abdominal movements during breathing, which is helpful in demonstrating increased or decreased respiratory effort,  ‚Ä¢   Pulse oximetry to measure blood oxygen saturation,  ‚Ä¢   End-tidal carbon dioxide (CO 2 ) measurement of exhaled air to indirectly measure blood CO 2  to assess for hypoventilation. Sleep studies were annotated in real time by technicians at the time of the study, and then were staged and scored by a second technician after the study was completed.   Technicians annotated studies using a combination of free-form text entries and selections within Natus Sleepworks. Tech- nicians tried to identify all events of interest, however each technician may have their own style of text annotation.   Due to the variability in sleep stages in children, NCH does not use automatic scoring of sleep stages. All sleep stages were manually scored by a technician and then verified or changed by a physician board certified in sleep medicine. Sleep studies were manually downloaded and converted to EDF+ format between May 2019 and Feb. 2020 using Natus Sleepworks version 9. Any gaps in the time-series data were padded with zeros as part of the conversion. The specific acquisition equipment, setup, and montage all followed standard care protocol at NCH. While changes may have been made to some studies, the NCH protocol for PSG is in accordance with the rules and technical specifications recommended by the American Academy of Sleep Medicine [10, 11]. Standard channel names are used and documented in the header of the EDF files, allowing inference of the montage. 3\n\nPatient cohort  The NCH Sleep DataBank consists of 3,984 sleep studies performed on 3,673 unique patients. Of them, 3,400 patients have one sleep study in the dataset, 238 have two studies, and 35 patients have more than two studies, with a maximum of 5 sleep studies for one patient. In terms of gender distribution, 2,068 patients were male, and 1,604 were female, with one unknown. Table 1 shows the distribution of the unique patients‚Äô races, where the majority of the patients were White, and about a fifth were Black or African American. In regards to ethnicity, 186 patients were Hispanic or Latino, 3,446 patients were Not Hispanic or Latino, and 41 had ethnicity of Other, Unknown, or No Information. Race description   Count   Percentage White   2,433   66.24% Black or African American   738   20.09% Multiple races   277   7.54% Asian   93   2.53% Others and unknown   132   3.59% Total   3,673   100% Table 1: The distribution of 3,673 unique patients‚Äô races. The majority of patients (2,412) in the dataset were less than 10 years old at the time of the sleep study, as seen in Figure 1. Figure 2 summarizes the length of care at NCH before and after the first sleep study. The length of care prior to first sleep study was calculated as the time between the patient‚Äôs earliest EHR entry (i.e. diagnosis, encounter, medication, measurement, procedure) and their first sleep study. If the patient‚Äôs earliest EHR entry was after the first sleep study, length of care is defined as 0.   The length of follow up was calculated as the time between the patient‚Äôs first sleep study and their last recorded EHR entry. Patients had a median of 289 days of follow-up after their first sleep study, and 74% (2,718) had follow-up between 90 days and 2 years.  Patient data linkage  Sleep study recordings and associated reports at NCH are stored in a database that is independent from the EHR, using Natus Sleepworks as a front end. It was therefore necessary to link patient information in two places. The first link was between the header information in the EDF+ files and the patient data entered in Natus Sleepworks. The second link was between the patient information in Natus and the EHR. A spreadsheet listing all sleep studies was exported from Natus Sleepworks. This listing included the date and time of each sleep study and patient information such as first and last name, date of birth and medical record number (MRN) for most sleep studies. Sleep studies were then downloaded from Natus in mini-batches, and exported to EDF+. Sleep study specific header information in the EDF+ files were used to match these files to the Natus spreadsheet export. When ambiguity was present, or when MRNs were not present in Natus, we removed the EDF+ file from our dataset. We then used each patient‚Äôs last name, date of birth, and MRNs extracted from Natus to retrieve patient records from the EHR. When matches could not be confidently made to the EHR, the sleep studies were removed from the dataset. 4\n\n0   5   10   15   20   25   30 Age at time of sleep study (years) 0 50 100 150 200 250 300 Number of sleep studies Figure 1: Age at the time of sleep study, where   20   patients that are more than   30   years old are not shown.  Data de-identification and IRB exemption  Each unique patient was given a random identifier (STUDY_PAT_ID), and each sleep study was given a separate random identifier (SLEEP_STUDY_ID). A single patient may have multiple sleep studies in the dataset, and therefore have multiple associated SLEEP_STUDY_IDs, but only one STUDY_PAT_ID. Sleep studies were then renamed (STUDY_PAT_ID)_(SLEEP_STUDY_ID).edf. All EDF+ headers were de-identified by replacing the first 256 bytes of the EDF+ file with a standard de-identified header.   As such, users are advised to ignore all header information in the EDF files (such as patientID, recordID, startdate, duration), but instead rely on the metadata in the accompanying .csv files to interpret the PSG results. Annotation channels were read from EDF+ using Python MNE [19] and written to text.   All EDF+ files were converted to EDF by removing the annotation channel using Luna ( https://zzz.bwh.harvard.edu/luna ). Annotation text files were then de-identified by replacing any word that was not in a whitelist with ‚ÄúXXX‚Äù. This process affected 10,888 annotations, which is about 0.22% of the total number of annotations (5,046,370).   The whitelist was a combination of 162 common phrases found in the annotations obtained by manual inspection, and a larger whitelist used by the de-identification program Philter [20]. The Philter whitelist contains approximately 195,000 tokens of medical terms and codes and common medical abbreviations, in addition to 20,000 most common English words, and excludes the most common Social Security and Census names. The tab delimited, de-identified annotations were then renamed to match the EDF filenames. To protect every patient‚Äôs privacy, random date shifts were applied to all data: for each patient (i.e. patients with the same STUDY_PAT_ID), one random date shift of +/- 180 days was chosen and applied to all data that are linked to the patient. Finally, we considered the risk of re-identification through rare diagnoses. Say a malicious user of this dataset is interested in re-identifying a specific patient, and the attacker has some information 5\n\n‚àí 25   ‚àí 20   ‚àí 15   ‚àí 10   ‚àí 5   0  Length of care before first sleep study (YEARS)  0 100 200 300 400 500 600  Number of patients  0   200   400   600   800   1000   1200  Follow up after first sleep study (DAYS)  0 100 200 300 400 500 600  Number of patients Figure 2:   Length of care at NCH before and after first sleep study, where each patient has two entries: one negative for length of care prior to first sleep study (in years), and one positive for follow up after first sleep study (in days). One entry above 1200 days and 5 entries below -25 years are not shown. about the patient such as their sex and race, as well as the fact that the patient has been diagnosed for a very rare genetic disease at NCH. If this diagnostic information is visible within the NCH Sleep DataBank, then the malicious user can likely figure out who this patient is, e.g. by searching for a female Asian child born between 2012 and 2016 with this very rare disease.   Therefore, we redacted rare diagnosis codes from DIAGNOSIS.CSV through the following procedure as an extra precaution. The EHR in NCH and the diagnoses table in NCH Sleep DataBank (DIAGNOSIS.CSV) contain several variables. One is DX_CODE (diagnosis code), which holds the International Classification of Diseases (ICD) code for each diagnosis. On Oct. 1, 2015, hospitals in the United States, including NCH, have switched from using ICD 9 (the 9th revision of ICD) codes to ICD 10 (the 10th revision of ICD) codes in EHR. Another relevant variable is DX_SOURCE_TYPE (diagnosis source type), which indicates whether the diagnosis was given at admission, presented as a part of the patient‚Äôs previous medical history, etc.   We were interested in the ones labeled ‚ÄúFinal Dx‚Äù, i.e.   the final diagnoses the clinicians gave after relevant examinations and tests. Using these variables, we defined rare diagnosis codes as ICD 10 or ICD 9 codes that were given as Final Dx to less than 10 unique patients in the entire NCH patient population (not limited to the NCH Sleep DataBank patients) during a given time period. Specifically, we queried 1) for every ICD 9 code, the number of unique NCH patients given the diagnosis as Final Dx between Jan. 1, 2000 and Sep. 30, 2015, and 2) for every ICD 10 code, the number of unique NCH patients given the diagnosis as Final Dx between Oct.   1, 2015 and Dec.   31, 2020.   If a code had less than 10 unique patients in either ICD 9 or ICD 10 lists, it was deemed a rare diagnosis code for our purpose. 6\n\nWe did not consider diagnoses before 2000 since the earliest diagnosis in NCH Sleep DataBank was from 2001. Then, in every row of DIAGNOSIS.CSV where a rare diagnosis code appeared, we changed the entries in DX_CODE, DX_NAME (diagnosis name), DX_ALT_CODE (corresponding ICD 10 codes for records before Oct 2015, and ICD 9 codes for those after Oct 2015), CLASS_OF_PROBLEM (‚ÄúStage 1‚Äù, ‚ÄúChronic‚Äù, ‚ÄúAcute‚Äù, ‚ÄúPresent upon Admission‚Äù), CHRONIC_YN (Indication of chronic disease) to the phrase ‚Äúredacted‚Äù. This process affected a total of 6,460 rows and 834 unique patients in DIAGNOSIS.CSV. As this project concerns analysis on de-identified data, the project did not fit the definition of Human Subjects Research as defined by the United States Department of Health and Human Ser- vices and Food and Drug Administration. Therefore, this study received NCH Institutional Review Board (IRB) exemption with HIPAA waiver. The protocol that concerns the de-identification and processing of the data, which requires handling identified data, and the collection and publication of data and summary statistics, was approved under ‚ÄúSTUDY00000505: Preparation of sleep study data‚Äù on September 22, 2019.  Data Records  The raw data for NCH Sleep DataBank [8] is available at Physionet   https://physionet.org/ content/nch-sleep , or at National Sleep Research Resource (NSRR)   https://sleepdata.org/ datasets/nchsdb . The NCH Sleep DataBank consists of two folders: Sleep_Data and Health_Data. Sleep_Data contains annotated PSG recordings, while Health_Data contains patient demographic and clinical data extracted from the EHR. Inside Sleep_Data, PSG sleep studies are provided in the EDF format, and annotations are provided in a separate tab-delimited file.   Sleep studies and their matched annotations share the same file name (STUDY_PAT_ID)_(SLEEP_STUDY_ID) but different extensions (.edf, .tsv). Clinical data in Health_Data are in .csv files, and they are linked to the files in Sleep_Data through the same STUDY_PAT_ID. Variables follow EHR conventions, and descriptions can be found in the file Sleep_Study_Data_File_Format.pdf in Health_Data.  Sleep studies  The 3,984 sleep study files (.edf) contain PSG recordings taken in clinical setting at NCH. An example plot of the signals can be seen in Figure 3.   Almost half (1,972) of the files have 26 channels, a quarter (1,012) have 29, a fifth (820) have 25, and the rest have 28, 24, 40, 27, 9, or 56 channels, in decreasing order of frequency. The most commonly appearing channel names are summarized in Table 2. The channel PATIENT EVENT was not used and can be excluded from analyses. We note again that all EDF headers were replaced with a standard de-identified version as part of the de-identification process. The total length of recording in the NCH Sleep DataBank amounts to 40,884 hours, where the minimum length of study is 3 minutes, the maximum is 16.5 hours, and the mean is 10.3 hours. 94.85% of the files contain between 8 and 12 hours of recordings, and the patients slept for a subset of those times. Users of the dataset should take into account that the majority of the recordings (3,204) are collected with a sampling frequency of 256 Hz, but 581 studies were sampled in 400 Hz, and the rest (199) in 512 Hz. 7\n\nChannel name   Description   Count   Percentage EEG C3-M2   3,971   99.67% EEG O1-M2   3,971   99.67% EEG O2-M1   3,971   99.67% EEG CZ-O1   3,971   99.67% RATE   Pulse oximeter signal integrity   3,970   99.65% ETCO2   End tidal CO2   3,970   99.65% CAPNO   End tidal CO2 waveform   3,970   99.65% RESP RATE   Respiratory rate   3,970   99.65% SPO2 (2,819) or OSAT (1,152)   Oxygen saturation   3,970   99.65% EEG F3-M2   3,969   99.62% RESP THORACIC (2,821) or RESP CHEST (1,148)   Thoracic inductance   3,969   99.62% RESP ABDOMINAL (2,821) or RESP ABDOMEN (1,148)   Abdominal inductance   3,969   99.62% SNORE   Measure of snore or air vibrations   3,968   99.60% EEG C4-M1   3,962   99.45% EEG F4-M1   3,960   99.40% C-FLOW   Continuous positive airflow waveform (PAP only)   3,943   98.97% EOG LOC-M2   3,933   98.72% EOG ROC-M1   3,931   98.67% EMG CHIN1-CHIN2   3,782   94.93% PRESSURE   CPAP pressure (PAP only)   2,824   70.88% EMG LLEG-RLEG   2,820   70.78% ECG EKG2-EKG   2,820   70.78% RESP AIRFLOW   Airway pressure with a thermistor   2,820   70.78% TIDAL VOL   Exhaled tidal volume (PAP only)   2,818   70.73% RESP PTAF   Airway pressure with nasal cannula   2,817   70.71% PATIENT EVENT   2,722   68.32% TCCO2   Transcutaneous CO2   1,417   35.57% SNORE_DR   Derived snore from PTAF   1,148   28.82% XFLOW   Derived airflow from Resp chest and abdominal   1,148   28.82% EMG LLEG+-LLEG-   1,146   28.77% EMG RLEG+-RLEG-   1,146   28.77% ECG LA-RA   1,146   28.77% FLOW_DR   Derived flow from Resp airflow   1,146   28.77% RESP FLOW   Airflow channel   1,146   28.77% C-PRESSURE   Positive pressure delivered via a PAP device   1,146   28.77% EEG CHIN1-CHIN2   136   3.41% Table 2:   List of 33 most common channels and their frequencies in 3,984 EDF files.   Other 101 channels appear in less than 1% of the files. Brief descriptions are included for channels that are not measuring EEG, EOG, or EMG. CO2 is carbon dioxide, PAP is positive airway pressure, CPAP is continuous PAP, and PTAF is pressure transducer. 8\n\nonset   duration   description 15985.234375   0.0   Chewing motion 15990.93359375   30.0   Sleep stage W 16002.09375   0.0   Movement 16002.34375   1.21875   Limb Movement Table 3: Example annotations from a .tsv file.   ‚ÄúChewing motion‚Äù and ‚ÄúMovement‚Äù are free text entries by the NCH technicion, while ‚ÄúLimb Movement‚Äù is a standard sleep event labeled by Natus Sleepworks.  Sleep study annotations  The 3,984 annotation files (.tsv) contain a total of 5,046,370 annotations. The minimum number of annotations contained in a sleep study is 5, while the maximum is 6,047, and the mean value is 1,267. Each annotation has the following information, where an example is given in Table 3.  ‚Ä¢   onset: The start time of the event since the beginning of the study in seconds.  ‚Ä¢   duration: The length of the event in seconds.  ‚Ä¢   description: The description of the event, which may be sleep stage label or free-form text entry by the NCH technician, or standard sleep event label by Natus Sleepworks. 35,821 unique descriptions appear in NCH Sleep DataBank. In particular, sleep stages are found in annotations with a duration of 30 seconds, where the descriptions include ‚ÄúSleep stage W‚Äù, ‚ÄúSleep stage N1‚Äù, ‚ÄúSleep stage N2‚Äù, ‚ÄúSleep stage N3‚Äù, ‚ÄúSleep stage R‚Äù, or ‚ÄúSleep stage ?‚Äù.   In sleep stage classification, W indicates awake, R stands for REM sleep, and N1, N2, N3 are non-REM stages 1, 2, 3, respectively. The annotation ‚ÄúSleep stage ?‚Äù typically occurs after ‚ÄúLights On‚Äù, and physiological data acquired during that time can usually be ignored, as it indicates that the study has ended. Of the total number of annotations, 79.48% were related to sleep staging:   6.88% (347,294) are ‚ÄúSleep stage ?‚Äù, 13.19% (665,676) are ‚ÄúSleep stage W‚Äù, 2.54% (128,410) are ‚ÄúSleep stage N1‚Äù, 27.41% (1,383,765) are ‚ÄúSleep stage N2‚Äù, 17.35% (875,486) are ‚ÄúSleep stage N3‚Äù, and 12.11% (611,320) are ‚ÄúSleep stage R‚Äù. This is equivalent to 30,539 hours of data with sleep stage labels. The mean length of such data per study is 7.7 hours, and 96.63% (3,850) of the studies contain between 6 and 10 hours of sleep data with stage labels. Besides sleep stage labels, the most common events include: Oxygen Desaturation, Oximeter Event, EEG Arousal, Obstructive Hypopnea, Limb Movement, Gain/Filter Change, Move, Body Position:   (Left, Right, Supine, Prone, Upright), Obstructive Apnea, Hypopnea, Central Apnea, and Mixed Apnea. Free text annotations by the NCH technician typically describe events in the room, movements, and other patient activities, and will often have a duration of 0 seconds. Additionally, hypopneas, apneas, seizures, and other patient events may be mentioned in the free text annotations. On the other hand, standard sleep event annotations are selected in, or automatically applied by Natus Sleepworks [17, 18], and are likely to have varying durations other than 0 or 30 seconds. While there may be some variation, the general format for sleep studies is as follows:   Sleep staging begins at the annotation ‚ÄúLights Off‚Äù and ends at ‚ÄúLights On‚Äù.   Descriptive annotations 9\n\nwill typically precede sleep stage scoring at irregular intervals prior to ‚ÄúLights Off‚Äù.   Sleep stages are annotated in 30 second epochs, beginning at ‚ÄúLights Off‚Äù; however not all studies include this annotation.  Clinical data  The NCH Sleep DataBank includes patient demographics and longitudinal clinical data such as encounters, medication, measurements, diagnoses, and procedures.   The number of observations and variables for each file are listed in Table 4. More details about the variables can be found in Sleep_Study_Data_File_Format.pdf in the same folder. Note that the age of the patient at the time of sleep study is calculated in SLEEP_STUDY.csv. Measurements include body mass index, body mass index percentile, or blood pressure. Table 5 lists 20 diagnoses that are given to the highest number of unique patients in the NCH Sleep DataBank according to DIAGNOSIS.csv.   Only diagnoses indicated as Final Dx in DX_SOURCE_TYPE were considered for this analysis. Any DX_CODEs recorded in ICD 9 code were converted to the corresponding ICD 10 codes, according to the ICD 10 codes provided under the variable DX_ALT_CODE in DIAGNOSIS.csv.   17 unique ICD 9 diagnoses (across 75 rows) that did not have corresponding ICD 10 codes were disregarded from further consideration.   We leveraged the hierarchical structure of ICD 10 codes to get a broad overview of the patient popu- lation. For example, ICD 10 code ‚ÄúG47.33 Obstructive sleep apnea (adult) (pediatric)‚Äù fall under the more general ICD 10 code ‚ÄúG47.3 Sleep apnea‚Äù which in turn is under the even more general ICD 10 code ‚ÄúG47 Sleep disorders.‚Äù Therefore, two patients with ‚ÄúG47.33 Obstructive sleep apnea (adult) (pediatric)‚Äù and ‚ÄúG47.61 Periodic limb movement disorder‚Äù, respectively, counted as two patients diagnosed with ‚ÄúG47 Sleep disorders‚Äù in Table 5. Note that we started by considering all diagnoses in the EHR data, not just the diagnoses resulting from the specific sleep studies included the NCH Sleep DataBank.  Technical Validation  Validation of de-identification procedure  After EDF files were de-identified, we performed several validation steps to confirm that the data matched the original EDF+ export. We loaded all channels from both the de-identified EDF file and the original EDF+ export and confirmed that all signal channels matched.   Finally, all files included in the data set have been read by Python MNE through this validation procedure and any files with read errors were not included in the data set.  Validation of data maps  We identified and tested three separate points in our data pipeline:   1) mapping of sleep study from Natus Sleepworks to the de-identified EDF file, 2) mapping of clinical data from EHR to the de-identified CSV files, and 3) the linkage between the sleep study and the clinical data. The first was the mapping between the de-identified EDF file and the original sleep data file accessible via Natus Sleepworks.   We first chose four random sleep studies (about 0.1% of the dataset), and a random 30-second segment from each study. Then we confirmed that the sleep data 10\n\nFile name   Variable names   Rows DEMOGRAPHIC.csv   study pat ID, birth date,   pcori gender cd,   pcori race cd, pcori hispanic cd, gender descr, race descr, ethnicity descr, language descr, peds gest age num weeks, peds gest age num days 3,673 SLEEP_STUDY.csv   study pat ID, sleep study ID, sleep study start date- time, sleep study duration datetime, age at sleep study days 3,984 SLEEP_ENC_ID.csv   study pat ID, sleep study ID, study enc ID   3,964 ENCOUNTER.csv   study enc ID, study pat ID, encounter date, visit start datetime, visit end datetime, adt arrival date- time, ed departure datetime, encounter type, visit type cd, visit type descr, ICU visit Y/N, prov ID, prov type, dept ID, dept specialty, admit source, hosp admit source, discharge disposition, discharge destination, drg code, drg name, visit reason 495,138 MEDICATION.csv   study med ID, study enc ID, study pat ID, med start datetime, med end datetime, med order datetime, med   taken   datetime,   med   source   type,   quantity, days supply, frequency, effective drug dose, eff drug dose source value, drug dose unit, refills, RxNorm code, RxNorm term type, medication descr, generic drug descr, drug order status, drug action, route, route source value, prescribing prov ID, pharm class, pharm subclass, thera class, thera subclass 3,035,986 MEASUREMENT.csv   study meas ID, study pat ID, study enc ID, meas recorded datetime, meas type, meas value number, meas value text, meas source, study prov ID 332,569 DIAGNOSIS.csv   study dx ID, study enc ID, study pat ID, dx start datetime, dx end datetime, dx source type, dx enc type, dx code type, dx code, dx name, dx alt code, class of problem, chronic Y/N, prov ID 1,513,853 PROCEDURE.csv   study proc ID, study pat ID, study enc ID, procedure datetime, study prov ID, proc ID NCH, proc code, proc code type, proc descr 283,599 PROCEDURE_SURG_HX.csv   study surghx ID, study pat ID, proc noted date, proc start time, proc end time, proc code, cpt code, proc descr 10,190 Table 4: The variable names and number of observations for each patient data file in Health_Data. More details about the variables can be found in Sleep_Study_Data_File_Format.pdf in the same folder. 11\n\nDiagnosis   ICD 10 code   Patients,   N  Sleep disorders   G47   3,379 Sleep apnea   G47.3   2,558 Sleep disorder, unspecified   G47.9   1,163 Other sleep disorders   G47.8   914 Circadian rhythm sleep disorders   G47.2   566 Insomnia   G47.0   388 Hypersomnia   G47.1   257 Sleep related movement disorders   G47.6   180 Parasomnia   G47.5   165 Narcolepsy and cataplexy   G47.4   47 Abnormalities of breathing   R06   2,776 Encounter for immunization   Z23   1,720 Chronic diseases of tonsils and adenoids   J35   1,686 Encounter   for   general   examination   without   com- plaint, suspected or reported diagnosis Z00   1,587 Acute upper respiratory infections of multiple and unspecified sites J06   1,537 Body mass index (BMI)   Z68   1,417 Suppurative and unspecified otitis media   H66   1,378 Symptoms and signs concerning food and fluid intake   R63   1,369 Acute pharyngitis   J02   1,260 Other symptoms and signs involving the circulatory and respiratory system R09   1,256 Other functional intestinal disorders   K59   1,185 Cough   R05   1,176 Lack of expected normal physiological development in childhood and adults R62   1,097 Encounter for follow-up examination after completed treatment for conditions other than malignant neo- plasm Z09   1,068 Nausea and vomiting   R11   1,051 Fever of other and unknown origin   R50   1,043 Specific developmental disorders of speech and lan- guage F80   1,002 Asthma   J45   991 Gastro-esophageal reflux disease   K21   982 Table 5: 20 diagnoses that are given to the highest number of unique patients in the NCH Sleep DataBank according to DIAGNOSIS.csv. Note that the diagnoses were abstracted to a higher level before being counted. For example, patients with diagnosis ‚ÄúG47.33 Obstructive sleep apnea (adult) (pediatric)‚Äù were counted under G47 and G47.3. 12\n\nviewed on Natus Sleepworks (Figure 3 top) matched data visualized from the corresponding EDF file in the published dataset (Figure 3 bottom). The second mapping was between the de-identified clinical data and the EHR. We extracted from the dataset all clinical data associated with the four random patients chosen in the first verification step, and confirmed that they are identical to the medical records viewed from the physician interface of the EPIC electronic medical record. The last mapping we verified was SLEEP_STUDY_ID, the random identifier linking the sleep studies to the patient data. We verified this by matching the sleep study, which is represented by SLEEP_STUDY_ID, with its corresponding encounter in the patient data, which is represented by STUDY_ENC_ID. If an encounter had procedure codes and departmental codes associated with sleep study, had the same randomly assigned STUDY_PAT_ID as the sleep study, and the same starting date and time (within a window of +/- one hour) as the sleep study start time obtained from Natus Sleepworks, we considered it a match.   We were able to match 3,964 sleep studies to encounter codes in the patient data using this method, therefore providing validation of a mapping between the sleep studies and patient data and consistency of date shifting.   This information is provided in the file SLEEP_ENC_ID.csv.  Sleep stage classification for PSG data validation  We developed a baseline sleep stage classifier and included it in the codebase to demonstrate the technical quality as well as a potential utility of the dataset, especially the PSG data. This simple algorithm predicts the sleep stages (W, N1, N2, N3, R) based on 30 seconds of 7 EEG channels (F4-M1, O2-M1, C4-M1, O1-M2, F3-M2, C3-M2, CZ-O1) after they are down sampled to 128Hz. Wavelet transform is a powerful method that can flexibly represent the time-frequency content of a signal. As such, it is particularly useful in analyzing non-stationary signals, and have previously been used for EEG-based sleep stage classification [21, 22, 23, 24]. After applying multi-resolution Daubechies wavelet transform [25] to each EEG channel, we computed summary statistics such as min, max, mean, and standard deviation of the coefficients, resulting in 84 features.   A random forest classifier with 100 decision trees was then trained on these features using 67% of the dataset, and tested on the rest. Table 6 reports the 3-fold stratified cross validation results on 3,928 sleep studies that had the 7 EEG channels, in addition to the results on some subgroups (0 to 1 year old, 1 to 2 years old, and 18+ patients). Fitting the classifier with default parameters from Scikit-learn [26] took 1 hour on Intel Xeon Gold 3.60GHz CPU in parallel; subgroups took less than 2 minutes each. This quick and straightforward algorithm, without any denoising or parameter tuning, achieves a classification accuracy of over 80% on the 222 adult sleep studies, suggesting high quality of the PSG recordings. Moreover, the difference in classification results between age groups supports the importance of having a dataset dedicated to pediatric sleep.  Prader-Willi syndrome (PWS) patient analysis for EHR data validation  The availability of EHR allows the study of clinically meaningful patient subpopulations in the NCH Sleep DataBank. As a use case, we examine the sleep patterns of PWS patients within this dataset.   To provide context, PWS is a rare genetic disorder that is estimated to affect 1 out of 10,000 to 30,000 people, and many researchers and clinicians are interested in sleep abnormalities and sleep-disordered breathing of PWS patients [27, 28, 29, 30, 31]. We construct two PSG cohorts, 13\n\nFigure 3:   Visual verification that a randomly chosen 30-second segment of sleep data on Natus Sleepworks (top) matches the sleep data in the corresponding EDF file (bottom), especially at the region of interest marked by red box. Natus Sleepworks may denoise or auto-scale some signals for the viewer. 14\n\nAutomated score sleep stage W   N1   N2   N3   R Manual score sleep stage,   N   W (661,645)   63.1   0.   34.0   1.5   1.4 N1 (127,602)   23.9   0.9   68.1   2.1   5.0 N2 (1,375,678)   4.4   0.   88.6   5.8   1.1 N3 (871,200)   1.7   0.   27.2   70.7   0. R (608,180)   6.7   0.   76.6   1.5   15.1  (a) All age groups.   3,928 sleep studies and 3,644,305 samples.   Overall accuracy is 64.4%.  Automated score sleep stage W   N1   N2   N3   R Manual score sleep stage,   N   W (52,979)   89.5   0.1   8.2   0.5   1.7 N1 (8,263)   37.5   2.5   47.4   0.6   12.1 N2 (80,275)   5.6   0.1   89.1   2.9   2.3 N3 (30,612)   2.6   0.   18.3   79.1   0. R (24,006)   9.2   0.   24.7   0.6   65.5  (b) 18 years and older. 222 sleep studies and 196,135 samples. Overall accuracy is 81.1%.  Automated score sleep stage W   N1   N2   N3   R Manual score sleep stage,   N   W (63,041)   83.3   0.   2.4   2.8   11.4 N1 (4,579)   28.7   1.1   24.7   6.2   39.2 N2 (38,525)   9.4   0.   62.9   10.2   17.4 N3 (64,512)   4.5   0.   3.7   83.3   8.5 R (60,167)   11.1   0.   5.0   7.1   76.8  (c) 0-1 year olds.   242 sleep studies and 230,824 samples.   Overall accuracy is 76.6%.  Table 6: Sleep stage classification results of our baseline algorithm applied to different age groups. One sample is a 30-second epoch of sleep. Cell (row   i , column   j ) of the normalized confusion matrix indicates the percentage (%) of samples in stage   i   (manually scored by NCH technician) that were predicted to be in stage   j   (by our automated algorithm). Each row adds to 100%. Bolded diagonal entries are the percentages of samples in each stage that were correctly classified. Overall accuracy is the total number of correctly classified samples divided by the total number of samples in %. All numbers reported are averaged over 3-fold stratified cross validation trials and rounded to one decimal point. Standard deviation was <1% for all entries except one and not shown here. 15\n\nCohort 1   Cohort 2 PSG,   N   16   370 Unique patients,   N   12   311 Age, mean   ¬±   s.d. (years)   10.5   ¬±   5.6   13.2   ¬±   4.7 Sleep time, mean   ¬±   s.d. (hours)   8.0   ¬±   0.7   7.5   ¬±   0.9 W, mean   ¬±   s.d. (%)   14.4   ¬±   7.1   20.5   ¬±   16.1 N1, mean   ¬±   s.d. (%)   4.1   ¬±   2.7   3.5   ¬±   3.4 N2, mean   ¬±   s.d. (%)   45.2   ¬±   7.3   39.9   ¬±   11.5 N3, mean   ¬±   s.d. (%)   20.5   ¬±   6.7   21.1   ¬±   8.5 R, mean   ¬±   s.d. (%)   15.8   ¬±   6.0   15.0   ¬±   7.3 N1 N2, mean   ¬±   s.d. (%)   49.3   ¬±   6.7   43.4   ¬±   11.8 N1 N2 N3, mean   ¬±   s.d. (%)   69.8   ¬±   6.3   64.5   ¬±   13.4 Table 7:   Summary statistics of sleep time and distribution of sleep stages for two PSG cohorts. Cohort 1: PSGs with OSA diagnoses on PWS patients, Cohort 2: PSGs with OSA diagnoses on obese but not PWS patients; sleep time: total amount of time spent in sleep stages W, N1, N2, N3, and R; s.d.: standard deviation. Percentage of each sleep stage is calculated by dividing time spent in each sleep stage by sleep time. All numbers are rounded to one decimal point. where Cohort 1 includes the PSGs of PWS patients, and Cohort 2 consists of PSGs of obese but non-PWS patients. To control for the effect of OSA, both cohorts only consider PSGs during which patients were diagnosed OSA. To construct the PSG cohorts, we first searched for all STUDY_ENC_IDs in DIAGNOSIS.csv during which a patient was given a final diagnosis of OSA. Then, we only kept the encounter IDs that were also present in SLEEP_ENC_ID.csv, as we have matched them with SLEEP_STUDY_IDs in an earlier validation step.   This process identified 860 PSGs (763 unique patients) with OSA diagnoses. Among these, 16 PSGs (12 unique patients) were designated Cohort 1, since they were associated with STUDY_PAT_IDs that had a final diagnosis of PWS in the EHR. For reference, the NCH Sleep DataBank has a total of 34 unique patients who had final diagnosis of PWS in the EHR. On the other hand, 370 PSGs (311 unique patients) were associated with STUDY_PAT_IDs with obesity diagnoses but not PWS, and selected Cohort 2. For every PSG in Cohort 1 and Cohort 2, we tallied the number of each sleep stage (W, N1, N2, N3, R) annotation, and extracted the following sleep characteristics: total length of sleep (sleep time) by counting 30 seconds of sleep for each sleep stage annotation, and distribution of sleep stages, e.g., W constitutes 20% of the sleep time.   Table 7 describes summary statistics of the two cohorts‚Äô sleep characteristics.   In summary, the ease-of-navigation of the EHR data makes it possible to conduct disease-specific data mining using NCH Sleep DataBank, e.g. extraction of sleep characteristics such as apnea-hypopnea index (AHI), and refined statistical analysis that accounts for potential confounding variables such as BMI and age. 16\n\nUsage Notes  The NCH Sleep DataBank can potentially be used to study many problems related to pediatric sleep, including but not limited to:  ‚Ä¢   Automatic sleep scoring (sleep stage classification): Sleep scoring divides sleep into two stages, rapid eye movement (REM), and non-REM, then further divides the latter into shallow sleep (stages N1 and N2) and deep sleep (stage N3) [9, 10, 11], in addition to wake (Stage W). In typical pediatric clinical settings, this is a time-consuming and tedious process done by a technician. Many computational algorithms have shown promise for automatic sleep scoring in adults [12], which encourage exploration on automatic sleep scoring for infants and children. Algorithms that combine PSG modalities beyond EEG or ECG [13] especially warrant more investigation.  ‚Ä¢   Automatic sleep disorder (e.g. obstructive apnea) detection: Large sets of PSG signals pub- lished with expert annotations can be leveraged to develop computational algorithms in sleep disorder detection, unleashing the potential of eventual real-time systems that read these signals and detect sleep disorders at their onsets [14, 15]. OSA detection is particularly im- portant, as OSA is associated with various cardiovascular, respiratory, and neurocognitive deficits and morbidity among infants and children [2, 3].  ‚Ä¢   Diagnosis prediction: Statistical models that predict or measure the risk of diagnoses using other variables (e.g. other diagnoses, demographic, features from PSG, encounters, measure- ment values) can be constructed and validated to create hypotheses for further experiment.  ‚Ä¢   Identifying patient subgroups:   Given the demographics and medical history, patients can be divided into clinically meaningful subgroups before further analysis, as demonstrated in this paper for PWS. Additionally, data-driven approaches may be developed to reveal clusters within the patient population, which could affect their symptoms or best courses of treatment, e.g. as suggested for insomnia [16].  ‚Ä¢   Treatment efficacy analysis: Retrospective studies using the accompanying longitudinal clin- ical data (e.g. medications and procedures) can be used to analyze efficacy of different treat- ments options.  Competing interests  The authors declare no competing interests.  Acknowledgements  Research reported in this publication was supported by the National Institute Of Biomedical Imag- ing And Bioengineering of the National Institutes of Health under Award Number R01EB025018. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.   The authors thank Tim Held for data identification, Melody Kitzmiller for data query, Dan Digby for data pipelines, Rajesh Ganta for data validation, Iris Karhoff for the interpretation of PSG channel names, Rahul Ragesh, Ramachandra Mannava, 17\n\nand Jacob Hoffman for help with sleep stage classifier development, Daniel Mobley and Michael Rueschman for publishing the data to NSRR, and Lucas McCullum and Tom Polland for publishing the data to Physionet.  Author contributions  Y.C. and S.L.L. designed and supervised the study. S.D., Y.H., B.L., and H.L. prepared the dataset. M.L.S. provided clinical interpretations. H.L., B.L., and S.D. conducted data analysis and technical validation. H.L., Y.C., S.D., M.S., Y.H., B.L., and S.L.L. drafted the manuscript.  Code availability  The code that was used to analyze patient data, read EDF files, run baseline sleep stage classifier, and generate figures and tables in this paper is published at   https://github.com/liboyue/sleep_ study .  References  [1] Splaingard, M. L. & May, A. Sleep disturbances (nonspecific). In McInerny, T. K.   et al.   (eds.)  American Academy of Pediatrics Textbook of Pediatric Care , chap. 194 (American Academy of Pediatrics, 2016). [2] Lumeng, J. C. & Chervin, R. D. Epidemiology of pediatric obstructive sleep apnea.   Proc. Am. Thorac. Soc.   5 , 242‚Äì252 (2008). [3] Beebe, D. W.   et al.   Neuropsychological effects of pediatric obstructive sleep apnea.   J. Int. Neuropsychol. Soc.   10 , 962 (2004). [4] American Academy of Sleep Medicine.   International classification of sleep disorders   (American Academy of Sleep Medicine, 2014), 3rd edn. [5] Kushida, C. A.   et al.   Practice parameters for the indications for polysomnography and related procedures: an update for 2005.   Sleep   28 , 499‚Äì523 (2005). [6] Zhang, G.-Q.   et al.   The national sleep research resource:   towards a sleep data commons.  Journal of the American Medical Informatics Association   25 , 1351‚Äì1358 (2018). [7] Goldberger, A. L.   et al.   Physiobank, physiotoolkit, and physionet:   components of a new research resource for complex physiologic signals.   circulation   101 , e215‚Äìe220 (2000). [8] Lee, H., Li, B., Huang, Y., Chi, Y. & Lin, S.   NCH sleep databank:   a large collection of real-world pediatric sleep studies with longitudinal clinical data (version 3.1.0).   PhysioNet  https://doi.org/10.13026/p2rp-sg37 (2021). [9] Grigg-Damberger, M.   et al.   The visual scoring of sleep and arousal in infants and children.   J. Clin. Sleep Med.   3 , 201‚Äì240 (2007). 18\n\n[10] Berry, R. B.   et al.   The AASM manual for the scoring of sleep and associated events: rules, terminology and technical specifications. Version 2.4.   (American Academy of Sleep Medicine, 2017). [11] Berry, R. B.   et al.   The AASM manual for the scoring of sleep and associated events: rules, terminology and technical specifications. Version 2.5.   (American Academy of Sleep Medicine, 2018). [12] Fiorillo, L.   et al.   Automated sleep scoring: A review of the latest approaches.   Sleep Med. Rev.  48 , 101204 (2019). [13] Yan, R.   et al.   Multi-modality of polysomnography signals‚Äô fusion for automatic sleep scoring.  Biomed. Signal Process. Control   49 , 14‚Äì23 (2019). [14] Mendonca, F., Mostafa, S. S., Ravelo-Garc√≠a, A. G., Morgado-Dias, F. & Penzel, T. A review of obstructive sleep apnea detection approaches.   IEEE J. Biomed. Health Inform.   23 , 825‚Äì837 (2018). [15] Xie, B. & Minn, H. Real-time sleep apnea detection by classifier combination.   IEEE Trans. Inf. Technol. Biomed.   16 , 469‚Äì477 (2012). [16] Benjamins, J. S.   et al.   Insomnia heterogeneity:   characteristics to consider for data-driven multivariate subtyping.   Sleep Med. Rev.   36 , 71‚Äì81 (2017). [17]   SleepWorks 8 reference manual   (Natus Medical Incorporated, 2017). [18]   SleepWorks 9 reference manual   (Natus Medical Incorporated, 2017). [19] Gramfort, A.   et al.   MEG and EEG data analysis with MNE-Python.   Front. Neurosci.   7 , 267. [20] Norgeot, B.   et al.   Protected Health Information filter (Philter): accurately and securely de- identifying free-text clinical notes.   NPJ Digit. Med.   3 , 1‚Äì8 (2020). [21] Ebrahimi, F., Mikaeili, M., Estrada, E. & Nazeran, H.   Automatic sleep stage classification based on EEG signals by using neural networks and wavelet packet coefficients. In   2008 30th Annual International Conference of the IEEE Engineering in Medicine and Biology Society , 1151‚Äì1154 (IEEE, 2008). [22] Fraiwan, L., Lweesy, K., Khasawneh, N., Wenz, H. & Dickhaus, H.   Automated sleep stage identification system based on time‚Äìfrequency analysis of a single EEG channel and random forest classifier.   Comput. Methods Programs Biomed.   108 , 10‚Äì19 (2012). [23] Hassan, A. R. & Bhuiyan, M. I. H.   A decision support system for automatic sleep staging from EEG signals using tunable Q-factor wavelet transform and spectral features.   J. Neurosci. Methods   271 , 107‚Äì118 (2016). [24] ≈ûen, B., Peker, M., √áavu≈üoƒülu, A. & √áelebi, F. V.   A comparative study on classification of sleep stage based on EEG signals using feature selection and classification algorithms.   J. Med. Syst.   38 , 18 (2014). [25] Daubechies, I. Orthonormal bases of compactly supported wavelets.   Comm. Pure Appl. Math.  41 , 909‚Äì996 (1988). 19\n\n[26] Pedregosa, F.   et al.   Scikit-learn:   machine learning in Python.   J. Mach. Learn. Res.   12 , 2825‚Äì2830 (2011). [27] Vela-Bueno, A.   et al.   Sleep in the prader-willi syndrome: clinical and polygraphic findings.  Arch. Neurol.   41 , 294‚Äì296 (1984). [28] Hertz, G., Cataletto, M., Feinsilver, S. H. & Angulo, M.   Sleep and breathing patterns in patients with prader willi syndrome (pws):   effects of age and gender.   Sleep   16 , 366‚Äì371 (1993). [29] Nixon, G. M. & Brouillette, R. T.   Sleep and breathing in prader-willi syndrome.   Pediatr. Pulmonol.   34 , 209‚Äì217 (2002). [30] Meyer, S. L.   et al.   Outcomes of adenotonsillectomy in patients with prader-willi syndrome.  Arch. Otolaryngol. Head Neck Surg.   138 , 1047‚Äì1051 (2012). [31] Pavone, M.   et al.   Sleep disordered breathing in patients with prader‚Äìwilli syndrome: A mul- ticenter study.   Pediatr. Pulmonol.   50 , 1354‚Äì1359 (2015). 20",
      "embedding": [
        -0.030501902103424072,
        -0.052943650633096695,
        -0.016840623691678047,
        0.08452295511960983,
        0.050830114632844925,
        0.03088655322790146,
        -0.022629527375102043,
        0.009916622191667557,
        0.04578559100627899,
        0.000834594713523984,
        -0.05976307764649391,
        -0.06272263824939728,
        0.003756418591365218,
        0.08361564576625824,
        -0.030328411608934402,
        0.04408181086182594,
        -0.011699252761900425,
        0.0480630025267601,
        -0.027193868532776833,
        -0.02800370566546917,
        0.07939335703849792,
        0.07033274322748184,
        0.10252394527196884,
        0.031125880777835846,
        0.008538506925106049,
        0.004515852779150009,
        0.03326398879289627,
        -0.10228656977415085,
        -0.055896129459142685,
        0.0029698689468204975,
        -0.05183239281177521,
        0.10887827724218369,
        0.00010895808372879401,
        0.006099627818912268,
        0.03978467732667923,
        0.009391091763973236,
        0.05935600772500038,
        0.04284033179283142,
        -0.09193529933691025,
        0.023364685475826263,
        0.04174422100186348,
        0.026239948347210884,
        0.011831142008304596,
        -0.06264256685972214,
        -0.06131013482809067,
        -0.03248977288603783,
        -0.10051082074642181,
        -0.09178616106510162,
        0.004885165952146053,
        0.10962888598442078,
        -0.07215062528848648,
        -0.02438075840473175,
        -0.03244556486606598,
        0.10583815723657608,
        0.07943081110715866,
        -0.009401711635291576,
        -0.06471727788448334,
        -0.044192124158144,
        0.04785717651247978,
        0.015007439069449902,
        -0.04829932004213333,
        0.052892837673425674,
        0.026447108015418053,
        -0.04204964265227318,
        0.0644361600279808,
        0.08163902908563614,
        -0.02887050248682499,
        0.00003071027094847523,
        -0.023889033123850822,
        -0.017066406086087227,
        -0.07990933209657669,
        -0.04929835721850395,
        0.010053880512714386,
        0.045017458498477936,
        -0.026806136593222618,
        0.03167816251516342,
        0.09586337953805923,
        -0.0036591568496078253,
        0.07000557333230972,
        -0.095354363322258,
        -0.012506293132901192,
        0.08987290412187576,
        0.02654225006699562,
        -0.054579075425863266,
        0.0034699742682278156,
        0.00022846706269774586,
        0.09527479857206345,
        0.04483272135257721,
        -0.1043982282280922,
        0.023612376302480698,
        0.03304905444383621,
        -0.019101213663816452,
        0.018221743404865265,
        0.023119023069739342,
        0.07452583312988281,
        0.023709505796432495,
        -0.0147273950278759,
        -0.042397934943437576,
        0.013030987232923508,
        -0.04819376766681671,
        0.003168606897816062,
        0.08650324493646622,
        0.055172547698020935,
        0.028098423033952713,
        -0.019114967435598373,
        -0.005578093696385622,
        0.02822166495025158,
        -0.08248790353536606,
        -0.04528062418103218,
        -0.03458981588482857,
        -0.04410545155405998,
        0.026254937052726746,
        0.02395201288163662,
        -0.015801172703504562,
        0.0838051438331604,
        -0.02315976284444332,
        0.0012420082930475473,
        0.06024443358182907,
        0.02031758241355419,
        0.06128481402993202,
        0.005724540911614895,
        -0.022712185978889465,
        0.042609091848134995,
        -0.07235774397850037,
        -0.005281136836856604,
        -0.06297356635332108,
        -0.1454983502626419,
        5.070937896705403e-33,
        0.04771912842988968,
        -0.060563281178474426,
        0.01835372857749462,
        0.01792917773127556,
        -0.010085104033350945,
        -0.09663815796375275,
        -0.05544979125261307,
        0.031247619539499283,
        0.016829341650009155,
        0.025853337720036507,
        -0.07218003273010254,
        0.0016152787720784545,
        0.043418265879154205,
        -0.013109255582094193,
        0.030955608934164047,
        0.0643458366394043,
        -0.02554902248084545,
        0.0029445502441376448,
        -0.05618975684046745,
        0.05274002254009247,
        0.007144100498408079,
        0.007458836305886507,
        0.07175280153751373,
        0.020674709230661392,
        0.004515782929956913,
        0.025224976241588593,
        -0.04711493104696274,
        -0.004173034802079201,
        -0.019924145191907883,
        0.018788164481520653,
        -0.008325167931616306,
        0.008035078644752502,
        -0.029986996203660965,
        -0.02568882144987583,
        -0.017888056114315987,
        -0.020032746717333794,
        0.041402462869882584,
        0.00006579699402209371,
        -0.049655038863420486,
        0.029738223180174828,
        -0.08637432008981705,
        0.02813505195081234,
        -0.05223926901817322,
        0.03939058631658554,
        0.0027770011220127344,
        -0.0256298016756773,
        0.00794392079114914,
        0.029347656294703484,
        0.0256977342069149,
        -0.016428375616669655,
        0.037088509649038315,
        -0.024447768926620483,
        -0.04981604591012001,
        -0.08477120846509933,
        -0.136145681142807,
        0.08832211047410965,
        -0.01746402494609356,
        -0.05703093484044075,
        0.0022979266941547394,
        0.05405319109559059,
        0.04875024035573006,
        -0.045639943331480026,
        0.0008079761173576117,
        -0.06929179280996323,
        0.004909777082502842,
        0.0182163305580616,
        -0.05111442506313324,
        -0.02818654663860798,
        0.00035536233917810023,
        -0.07803742587566376,
        0.030936438590288162,
        -0.01879611797630787,
        0.06070294603705406,
        0.016195230185985565,
        0.061903126537799835,
        -0.04056008160114288,
        0.039989031851291656,
        -0.009148837998509407,
        -0.10974564403295517,
        -0.0056312126107513905,
        0.039576757699251175,
        0.0028262012638151646,
        -0.005462344735860825,
        -0.09939590096473694,
        -0.04797988757491112,
        -0.11544297635555267,
        0.005278247874230146,
        0.0342649482190609,
        -0.14223361015319824,
        -0.03974097967147827,
        -0.06594065576791763,
        -0.015950292348861694,
        0.044870760291814804,
        0.005461299791932106,
        -0.058977339416742325,
        -5.54932883265955e-33,
        -0.022189920768141747,
        -0.054482344537973404,
        -0.0392458476126194,
        -0.08104944229125977,
        0.0046203164383769035,
        -0.017064522951841354,
        -0.007979556918144226,
        -0.05089586228132248,
        0.014369006268680096,
        -0.046036817133426666,
        0.07790778577327728,
        -0.06727688014507294,
        0.024733785539865494,
        -0.06173044443130493,
        0.03671596199274063,
        0.0015134913846850395,
        -0.007047973107546568,
        0.046227797865867615,
        -0.08440220355987549,
        0.05666445195674896,
        0.018812309950590134,
        0.034318603575229645,
        -0.12776057422161102,
        -0.03355110064148903,
        0.051681678742170334,
        0.07803893834352493,
        -0.01086527667939663,
        0.07714631408452988,
        0.004217666108161211,
        -0.003285663668066263,
        -0.011283577419817448,
        0.007272673305124044,
        -0.08539470285177231,
        -0.027197349816560745,
        0.0014402157394215465,
        -0.020710980519652367,
        0.025235414505004883,
        -0.02049379236996174,
        -0.06369362026453018,
        -0.0821387767791748,
        0.11586223542690277,
        0.07386019080877304,
        -0.013671948574483395,
        -0.03699387609958649,
        0.04769153520464897,
        0.030806316062808037,
        -0.07743559777736664,
        0.01724056527018547,
        0.001532968133687973,
        0.024730321019887924,
        0.0950385183095932,
        0.03163663670420647,
        -0.018421104177832603,
        0.026588354259729385,
        -0.02885480970144272,
        0.03266020119190216,
        -0.05866173654794693,
        -0.023078126832842827,
        0.0014658888103440404,
        0.026546550914645195,
        0.02833005227148533,
        -0.027077114209532738,
        -0.051804810762405396,
        0.04402798041701317,
        0.02980281412601471,
        -0.01870109513401985,
        -0.028596900403499603,
        -0.1040683165192604,
        0.010252445936203003,
        -0.01753401756286621,
        0.001935337670147419,
        -0.007145843002945185,
        0.017581123858690262,
        0.023950744420289993,
        -0.02020469680428505,
        -0.03846782445907593,
        -0.0026482336688786745,
        -0.04638281092047691,
        -0.0539688840508461,
        -0.012495914474129677,
        0.0405072346329689,
        -0.12532703578472137,
        0.023385634645819664,
        0.054786454886198044,
        -0.05447198078036308,
        -0.05783073604106903,
        0.11829588562250137,
        -0.020000338554382324,
        0.0897059291601181,
        -0.05023498833179474,
        -0.06681964546442032,
        -0.02081550844013691,
        -0.17452771961688995,
        0.019750412553548813,
        0.019759878516197205,
        -5.498100463796618e-8,
        0.06330733001232147,
        -0.06182998791337013,
        -0.01719539240002632,
        0.04976453632116318,
        0.0005183350876905024,
        -0.027940217405557632,
        0.012199269607663155,
        0.056117378175258636,
        -0.031567174941301346,
        0.09675440192222595,
        0.07839750498533249,
        -0.02623628079891205,
        0.01388508453965187,
        -0.08755888789892197,
        0.011833933182060719,
        0.0093921460211277,
        0.008725530467927456,
        0.05056248977780342,
        0.017116401344537735,
        -0.006347430404275656,
        0.01706697791814804,
        0.008933835662901402,
        -0.018282297998666763,
        -0.0017013205215334892,
        0.09547651559114456,
        -0.03191215544939041,
        0.03101518377661705,
        0.06968409568071365,
        -0.02786155417561531,
        -0.09370364248752594,
        0.05043628811836243,
        0.0024374097120016813,
        0.03729479759931564,
        -0.003584625432267785,
        -0.020732302218675613,
        -0.039184652268886566,
        0.07561124116182327,
        -0.016405800357460976,
        -0.031846556812524796,
        0.13199064135551453,
        0.02561911940574646,
        0.02872864343225956,
        -0.011945907957851887,
        0.005777984857559204,
        0.0644523873925209,
        -0.06392718851566315,
        0.05821211263537407,
        -0.018985722213983536,
        0.11517466604709625,
        0.03894330561161041,
        0.011629299260675907,
        -0.04216040298342705,
        0.037549830973148346,
        -0.00018574825662653893,
        0.047921258956193924,
        0.08393901586532593,
        -0.02597787044942379,
        0.02215665951371193,
        0.017085107043385506,
        -0.011053827591240406,
        0.11153578758239746,
        -0.006165585480630398,
        -0.030486077070236206,
        0.026220930740237236
      ],
      "metadata": {
        "title": "Paper_2_A_Large_Collection_of_Real_world_Pediatric_Sleep_S.pdf",
        "createdAt": "2025-12-17T13:56:39.946Z"
      },
      "fileObj": {}
    },
    {
      "id": "doc_14_1765979800895",
      "fileName": "Paper_4_Microbes_in_the_Moonlight__How_the_Gut_Microbiota_.pdf",
      "content": "Title Page  Title: Microbes in the Moonlight: How the Gut Microbiota Influences Sleep  Author: Enso O. Torres Alegre  Affiliation: Pontifical Catholic University of Chile, Santiago, Chile  Email: onill@uc.cl  ORCID: https://orcid.org/0000 - 0002 - 6798 - 8776  Co - authors: None  Conflict of Interest Statement  The author declares no conflicts of interest related to this work.  Funding Statement  No external funding was received to support the preparation of this manuscript.  Data Availability Statement  No new datasets were generated or analyzed for this review. All data discussed in the  manuscript are derived from previously published studies cited in the References  section.  Ethics Approval Statement  Ethics approval was not required for this review article, as it does not involve new  human or animal research.  Patient Consent Statement  Not applicable. This article does not contain any studies involving human  participants.  Permission to Reproduce Material  Figures created using BioRender.com are original to the author. No previously  published material was reproduced.  Clinical Trial Registration  Not applicable. This manuscript does not report results of a clinical trial.\n\nAbstract  The gut microbiota has emerged as a fundamental regulator of sleep physiology, acting  through interconnected neural, immune, and endocrine pathways. This bidirectional  relationship influences neurotransmitter production, circadian rhythms, inflammatory  act ivity, and metabolic balance. Changes in microbial composition, particularly those  affecting serotonin, GABA, and short - chain fatty acid (SCFA) metabolism, have been  associated with insomnia, neuroinflammation, metabolic dysfunction, and mood  disturbances.   The gut microbiota also shapes immune responses and endocrine  signaling. Dysbiosis promotes IL - 1 Œ≤   and TNF - Œ±   mediated inflammation, alters intestinal  permeability, activates the HPA axis, and disrupts cortisol and melatonin rhythms,  which together impair sleep quality. This review synthesizes current evidence on the  integrated interactions among gut microbiota,   sleep regulation, immune activity, and  endocrine function. It also examines emerging therapeutic strategies, including  probiotics,   fecal   microbiota   transplantation   (FMT   and   WMT),   chrononutrition,  nutraceuticals,   and   neuropeptide - based   approaches   aimed   at   r estoring   sleep  homeostasis and improving systemic health.  Abreviations:  BBB   ‚Äì   Blood - Brain Barrier  CNS   ‚Äì   Central Nervous System  ENS   ‚Äì   Enteric Nervous System  GM   ‚Äì   Gut Microbiota  GMBA   ‚Äì   Gut - Microbiota - Brain Axis  HPA   ‚Äì   Hypothalamic - Pituitary - Adrenal Axis  NREMS   ‚Äì   Non - Rapid Eye Movement Sleep  REMS   ‚Äì   Rapid Eye Movement Sleep  SCN   ‚Äì   Suprachiasmatic Nucleus  GABA   ‚Äì   Gamma - Aminobutyric Acid  SCFAs   ‚Äì   Short - Chain Fatty Acids  NE   ‚Äì   Norepinephrine  ACh   ‚Äì   Acetylcholine\n\nDA   ‚Äì   Dopamine  5 - HT   ‚Äì   Serotonin  OX - A/B   ‚Äì   Orexin A/B  IL - 1 Œ≤   ‚Äì   Interleukin 1 Beta  TNF - Œ±   ‚Äì   Tumor Necrosis Factor Alpha  LPS   ‚Äì   Lipopolysaccharides  TLR4   ‚Äì   Toll - Like Receptor 4  GH   ‚Äì   Growth Hormone  GHRH   ‚Äì   Growth Hormone - Releasing Hormone  IGF - 1   ‚Äì   Insulin - Like Growth Factor 1  PGD2   ‚Äì   Prostaglandin D2  FMT   ‚Äì   Fecal Microbiota Transplantation  WMT   ‚Äì   Washed Microbiota Transplantation  SII   ‚Äì   Systemic Immune - Inflammation Index  1.   Introduction:  Sleep is a cyclical and transient state regulated by neurobiological processes, playing a  fundamental role in growth, development, immune function, and overall homeostasis.  However, sleep disorders, such as insomnia, are increasingly prevalent across all a ge  groups   and   represent   significant   risk   factors   for   metabolic,   cardiovascular,   and  neuropsychiatric diseases, including depression, diabetes mellitus, hypertension, and  coronary heart disease. Factors such as stress, anxiety, stimulant consumption, and  ex cessive use of electronic devices before bedtime further exacerbate these disorders,  intensifying their negative impact on health   [1,2] .  In recent years, the prevalence of sleep disorders has risen dramatically due to lifestyle  changes such as remote work, excessive social media exposure, and the effects of the  COVID - 19 pandemic. Chronic sleep deprivation not only impairs cognitive function   but  is also associated with an increased risk of inflammatory, metabolic, and neurological  diseases   [3,4] .   Older adults are particularly vulnerable to sleep disturbances due to age -  related physiological changes, such as prolonged sleep latency, reduced efficiency, and\n\nshorter total sleep duration, predisposing them to circadian rhythm disorders and sleep -  disordered breathing   [5] .  The circadian rhythm, regulated by a hierarchical system of cellular clocks with the  suprachiasmatic   nucleus   as   the   central   pacemaker,   synchronizes   physiological  processes with the 24 - hour cycle. Disruptions to this system can lead to metabolic and  neurops ychiatric imbalances, increasing susceptibility to chronic diseases   [6] .   Modern  societal habits, such as irregular schedules and nighttime light exposure, often cause  circadian misalignment, which has been linked to conditions like metabolic syndrome  and certain cancers   [7] .   Understanding the mechanisms underlying this synchronization  is crucial for developing effective therapeutic strategies.  Recent evidence suggests a bidirectional relationship between the gut microbiota and  circadian   rhythms.   Both   central   and   peripheral   clocks   influence   gut   microbiota  composition and metabolites, while the microbiota, in turn, affects circadian regulation,  cl ock gene expression, and sleep quality. Disruptions in this interplay   induced by factors  such as shift work or obesogenic diets   can compromise metabolic homeostasis and  contribute to sleep disorders   [8] [9] .   Restoring circadian rhythmicity through strategies  like time - restricted feeding and probiotic supplementation has shown promising effects  on sleep improvement and metabolic health   [9] .  The gut - microbiota - brain axis has emerged as a key player in sleep regulation and  cognitive function. It has been proposed that gut dysbiosis contributes to sleep disorders  through   systemic   inflammation   and   neurotransmitter   modulation,   opening   new  therapeu tic possibilities. In this context, non - pharmacological therapies such as  Traditional Chinese Medicine (TCM), light therapy, melatonin, and gut microbiota  modulation have gained relevance in the treatment of insomnia and other sleep  disturbances   [10 ‚Äì 13] .  Given the growing recognition of the gut microbiota‚Äôs role in sleep and circadian  regulation, it is crucial to further explore the underlying mechanisms linking these  systems. This review examines the interconnection between the gut - microbiota - brain  axis a nd its impact on sleep physiology, highlighting its implications for sleep disorder  treatment and potential therapeutic interventions.  Despite the rapid expansion of research linking the gut microbiota with sleep physiology,  existing reviews often address these interactions in isolation ,   focusing either on  circadian rhythms, immune activation, or metabolic pathways. However, no current  synthesis integrates the combined roles of the gut microbiota, immune function,  endocrine signaling, and microbial metabolites in shaping sleep health. This   gap limits a  comprehensive understanding of how these systems converge to influence sleep  architecture and the pathophysiology of sleep disorders. To address this, the present\n\nreview provides an integrated multi - system perspective on the sleep - microbiota axis,  connecting mechanistic evidence with emerging therapeutic strategies.  The following section explores the gut - microbiota - brain axis in greater depth, analyzing  how gut microbiota influences brain function and sleep regulation, as well as its  potential implications for the treatment of sleep disorders .  2.   Literature Search Strategy and Study Selection  A comprehensive literature search was conducted to identify peer - reviewed studies  examining the relationships among gut microbiota, sleep physiology, immune  function, and endocrine regulation. Searches were performed in PubMed, covering  literature publishe d between January 2015 and October 2024. Recent preprints  were considered only when supported by peer - reviewed evidence.  The search strategy combined controlled vocabulary and free - text terms,  including:  ‚Äúgut microbiota AND sleep‚Äù ,   ‚Äúmicrobiome AND circadian rhythm‚Äù ,   ‚Äúsleep  deprivation AND inflammation‚Äù ,   ‚ÄúSCFAs AND sleep‚Äù ,   ‚Äúgut ‚Äì brain axis AND  insomnia‚Äù ,   ‚Äúsleep AND immune system‚Äù ,   ‚Äúmicrobiota AND neurotransmitters‚Äù ,  and   ‚Äúchrononutrition AND sleep.‚Äù  Inclusion criteria  Studies were included if they:  1.   Reported original data in humans or animals on gut microbiota, sleep, immune  signaling, or endocrine outcomes.  2.   Explored   mechanistic   pathways   involving   microbial   metabolites   (SCFAs,  tryptophan derivatives), neuroimmune interactions, or circadian processes.  3.   Evaluated interventions targeting the microbiota ‚Äì sleep axis (e.g., probiotics,  WMT/FMT, dietary approaches, neuropeptides).  4.   Were published in English between 2015 and 2024.  Exclusion criteria  Excluded were:  ‚Äì   Studies without sleep - related outcomes.  ‚Äì   Work focused solely on gastrointestinal disorders without neuroimmune or  endocrine relevance.  ‚Äì   Narrative reviews lacking mechanistic synthesis.  ‚Äì   Studies with insufficient methodological detail.  Study selection  The search yielded 1,263 records. After removing duplicates and screening titles  and abstracts, 247 studies underwent full - text review. A total of 110 articles met\n\ninclusion criteria and were incorporated into this review, covering clinical  research, controlled animal studies, microbiota transplantation models, multi -  omics analyses, and interventional trials.  3.   The Gut - Microbiota - Brain Axis and Its Relationship with Sleep  The gut microbiota (GM) plays a crucial role in regulating various biological functions,  including brain function, behavior, and sleep. Through the Gut - Microbiota - Brain Axis  (GMBA), bidirectional communication occurs via neural, endocrine, and immune  pathw ays. Key components such as the enteric nervous system (ENS) and vagus nerve  mediate this interaction, allowing microbiota alterations to influence cognition,  behavior, and sleep patterns. Conversely, abnormal sleep patterns reciprocally impact  GM   composit ion   and   function.   Evidence   suggests   that   microbiota - targeting  interventions,   including   probiotics   and   fecal   microbiota   transplantation,   hold  therapeutic potential for enhancing brain function and improving sleep quality   [14,15] .  Dysbiosis of gut microbiota disrupts these processes by altering intestinal metabolism,  leading to significant changes in neurotransmission - related metabolites, such as  serotonin and vitamin B6. For instance, studies in antibiotic - induced microbiota -  deplet ed (AIMD) mice revealed disrupted sleep architecture, including reduced time  spent in non - rapid eye movement sleep (NREMS) during the light phase, increased time  in NREMS and rapid eye movement sleep (REMS) during the dark phase, frequent  transitions from   NREMS to REMS, and reduced theta power density during REMS   [16] .  Intestinal dysbiosis disrupts the bidirectional relationship between GM and the central  nervous   system   (CNS),   impacting   host   physiology   through   abnormal   microbial  metabolites and altered signaling pathways. This disruption is increasingly recognized  as a s usceptibility factor for neurodevelopmental and neurological disorders, including  Alzheimer's disease, Parkinson's disease, multiple sclerosis, and autism spectrum  disorder   [17] .   Additionally, the gut microbiota influences neurotransmitter activity,  shaping both gastrointestinal and neurological processes through its metabolic  interactions   [18] .  3.1   Metabolites and neurotransmitter s  GM - diet interactions influence nutrient sensing and signaling along the GMBA,  mediated by metabolites such as short - chain fatty acids (SCFAs), secondary bile  acids, and amino acid - derived compounds. These metabolites activate gut -  endocrine or neural pathwa ys or enter systemic circulation to reach the brain,  shaping communication between the gut and brain. Feeding time and dietary  composition are key factors driving gut microbiota structure and function, with\n\nunhealthy   diets   or   irregular   feeding   patterns   potentially   altering   microbial  metabolite production and nutrient availability   [19] .   Alterations in amino acid  metabolism, such as changes in glutamate and tryptophan levels, can disrupt  neural signaling and contribute to disorders like Parkinson‚Äôs disease (PD). These  disturbances in metabolic pathways are increasingly recognized as potent ial  contributors to non - motor symptoms of PD, including sleep disorders, highlighting  the   importance   of   microbiota   metabolites   in   maintaining   normal  neurophysiological functions   [20] .  3 .1.1 Short - chain fatty acids (SCFA s )  SCFAs, including acetate ,   propionate   and   butyrate   influence emotional state s   and  cognition through the gut - brain axis. Reduced levels of acetate and propionate were  negatively   correlated   with   depressive   symptoms,   as   measured   by   Beck's  Depression   Inventory,   suggesting   their   role   in   modulating   depression   and  highlighting their impor tance in the gut microbiota's impact on mental health   [21] .  Furthermore, short sleep duration in insomnia has been associated with increased  concentrations of SCFAs, in feces, likely due to decreased uptake by gut epithelial  cells, which may compromise their essential role in gut cell function and brain  signaling v ia pathways like serotonin   [22] .   Recent findings show that SCFAs  supplementation in mice undergoing psychosocial stress alleviates anhedonia,  heightened stress responsiveness, and stress - induced intestinal permeability .  These results provide novel insights into how gut microbiota influences brain  homeostasis,   behavior,   and   host   metabolism,   supporting   the   potential  development of microbiota - targeted therapies for stress - related disorders   [23] .  3 .1.2 Serotonin  The sleep ‚Äì wake cycle is a complex, multifaceted process influenced by various  neurotransmitters such as acetylcholine, norepinephrine, serotonin, histamine,  dopamine, orexin, and   Œ≥ - aminobutyric acid   ( GABA ) , all of which can be modulated  by   different   nutrients   that   participate   in   their   metabolic   pathways   [24,25] .  Tryptophan, an essential amino acid and precursor of serotonin, is crucial in the  microbiota - gut - brain axis. Serotonin regulates emotions, sleep, appetite, and gut  motility,   while   tryptophan metabolites,   including those   from the   kynurenine  pathway,   influen ce   neural   activity   and   inflammation.   Gut   microbes   affect  tryptophan metabolism both directly and indirectly, altering behavior and cognition,  making the gut microbiome a potential therapeutic target for neurological and  psychiatric disorders   [26] .   Beyond its neurological role, tryptophan also impacts  sleep through its conversion to melatonin, a key regulator of the sleep - wake cycle.\n\nDiets rich in tryptophan - containing foods, such as fruits, vegetables, and legumes,  have been associated with improved sleep quality, emphasizing the intricate link  between nutrition, microbiota, and sleep health   [27] .   A study demonstrated that  depleting the gut microbiota through antibiotic treatment disrupted sleep/wake  regulation in mice, leading to altered neurotransmitter metabolism, including  reduced serotonin and vitamin B6 levels. This imbalance was associated wi th  changes in sleep architecture, such as reduced non - REM sleep during the light  phase and increased REM sleep episodes, highlighting the influence of the gut  microbiota on sleep regulation   [16] .  3 .1.3 GABA  The main neurons involved in the regulation of arousal and sleep are glutamate and  GABA neurons, which   are in   the reticular core of the brain and, through both local  and distant projections and interactions, control cortical activity and behavior  during wakefulness and sleep states   [28] .   In this context, the gut microbiota plays a  crucial role, as highlighted by a study showing that   Bacteroides ,   Parabacteroides ,  and   Escherichia   species actively express GABA - producing pathways. Genome -  based metabolic modeling and transcriptome analysis of human stool samples  revealed that these bacteria are key contributors to GABA production in the gut,  which may influence sleep regulation throu gh their impact on the gut - brain   axis  [29] .   Another study reveals that intestinal stem cells (ISCs) are involved in sleep -  regulated intestinal homeostasis and function, with gut microbiota dysbiosis and  the GABA pathway playing key roles in this gut - brain communication. Antibiotic  treatment reduced   stem cell division and increased sleep time, suggesting the  involvement of   microbiota , while GABA activation rescued both sleep behavior and  intestinal phenotypes, highlighting potential therapeutic targets for gut disorders  linked to sleep deprivation   [30] .  3 .1.4 Acetylcholine  Acetylcholine, a neurotransmitter, plays a role in regulating REM sleep through  cholinergic neurons in the brainstem and basal forebrain, which project to wide  areas of the cerebral cortex and interact with other neuromodulatory systems to  produce the slee p - wake cycle and different sleep stages   [31] .   Choline, a precursor  of acetylcholine, plays a vital role in brain function and is linked to gut microbiota,  which influences digestion, metabolism, and overall health. Choline metabolism,  partly regulated by gut bacteria, is essential for neurotransmitter   synthesis and may  impact neurodegenerative conditions like Alzheimer's disease   [32] .  3 .1.5 Dopamine\n\nDopamine plays a crucial role in regulating the sleep - wake cycle by promoting  wakefulness, with elevated levels often disrupting sleep. It also influences the  circadian   clock,   including   the   entrainment   of   the   master   clock   in   the  suprachiasmatic nuclei (SCN ), while its own signaling is regulated by circadian  rhythms   [33] .   Moreover, dopamine levels are significantly influenced by the gut  microbiota through the microbiota - gut - brain axis. This interaction is mediated by  pathways involving the vagus nerve, immune system, and microbial metabolites.  Key   bacterial   genera,   such   as   Prevotella,   Bacteroides,   Lactobacillus,  Bifidobacterium, Clostridium, Enterococcus , and   Ruminococcus , contribute to  dopamine metabolism, underscoring the microbiota's essential role in maintaining  optimal dopamine levels   [34] .  3 .1.6 Histamine  Histamine plays a critical role in regulating the sleep - wake cycle, with the histamine  H3 receptor (H3R) being of particular interest due to its unique function as a pre -  and postsynaptic receptor that controls the synthesis and release of histamine and  ot her neurotransmitters in the brain. Preclinical studies have demonstrated that  H3R antagonists/inverse agonists hold promise in modulating sleep - wake cycle  disorders, alongside cognitive impairment and mood regulation   [35] .   Specific  bacterial species, such as   Escherichia coli   and   Morganella morganii , have been  identified for their ability to synthesize and release histamine   [36,37] .  3 .1.7   Orexin  Orexin play s   a pivotal role in regulating the sleep - wake cycle, with orexin mimetics  enhancing wakefulness during the day and orexin receptor antagonists promoting  sleep at night, offering promising therapeutic avenues for improving memory,  cognition,   and   daytime   perf ormance   [38] .   The   hypocretin/orexin   system,  comprising neuropeptides orexin - A and orexin - B, plays a critical role in sleep - wake  regulation,   with   HCRTR2/OX2R   specifically   linked   to   sleep - wake   control.  Therapeutic   compounds   targeting   these   receptors,   such   as   FDA - approved  antagonists for insomnia, highlight the potential of orexin - based therapies in  addressing sleep disorders and advancing our understanding of hypocretin/orexin  neurobiology   [39] .   Recent studies suggest that the gut microbiota, through the  production of acetate and other   SCFAs , may influence the orexinergic system by  modulating   orexin - A ( OX - A )   neuronal activity   [40]   This connection underscores the  interplay between gut health, energy homeostasis, and sleep - wake regulation,  while also pointing to the broader role of   OX - A   in the gut - brain axis, where it exerts  anti - inflammatory and gastroprotective effects. These findings offer novel insights\n\ninto the therapeutic potential of targeting the orexinergic system to address  inflammation, stress responses, and gastrointestinal disorders   [41] .  3 .1.8 Norepinephrine  The amplitude of Norepinephrine   ( NE )   oscillations is crucial for shaping sleep  micro - architecture related to memory performance: prolonged descent of NE  promotes spindle - enriched intermediate state and REM sleep but also associates  with awakenings, whereas shorter NE descents uphold NREM sle ep and micro -  arousals. Thus, the NE oscillatory amplitude may be a target for improving sleep in  sleep disorders   [42] .   Under stress, the enteric nervous system's sympathetic nerve  endings synthesize and secrete NE, which directly affects the gut microbiota and,  in turn, influences the host's physiological state. Exposure to NE increased  microbial diversity in the cecum, wi th shifts in bacterial abundance correlating with  NE levels used to maintain blood pressure   [43] .   A study suggests that   NE   can  modulate   microbial   composition and metabolite production. It was demonstrated  that exposure to NE increased the diversity of the bacterial community, increasing  the abundance of facultative pathogens such as   Hathewaya, Clostridium , and  Streptococcus , while reducing beneficial genera like   Lactobacillus . This could  increase pathogen colonization and infection   [44] .  The influence of the gut microbiota on sleep can be observed in how certain bacterial  species and the metabolites they produce affect key neurotransmitters involved in  sleep regulation, such as serotonin, GABA, and dopamine, among others. The following  T able   1 and   T able 2   emphasize some of these bacteria and their effects on sleep quality .  Table 1:   Gut Microbiota   and Their   Positive Effects on Sleep  Gut Microbiota   Effect on Sleep Disorders   References  Lactobacillus   Decreased   abundance   associated   with   ASD,   reducing   the  production of SCFAs like propionic acid.   Supplementation of  GABA - producing   Lactobacillus   increased plasma GABA levels  and   reduced   stress   hormones,   reversing   sleep   deprivation -  induced gut dysbiosis and stress responses.  [45]   [46]  Lactobacillus  plantarum JYLP - 326  Administration helped to restore disturbed gut microbiota and  reduce anxiety, depression, and insomnia symptoms in test -  anxious students.  [47]  Lactobacillus  plantarum PS128  Reduced depressive symptoms, fatigue, and brainwave activity,  improving sleep quality during deep sleep stages in insomniac  participants.  [48]  Lactobacillus   reuteri  NK33  Promotes better sleep quality and reduces stress and anxiety as  part of the NVP - 1704 formulation.  [49]  Lactobacillus   brevis  DL1 - 11  GABA - fermented milk with   Lactobacillus brevis   DL1 - 11 improved  sleep quality and reduced anxiety, associated with increased  SCFAs and altered gut microbiota .  [50]\n\nLactobacillus  fermentum PS150  Improved   NREM   sleep   length,   reduced   sleep   latency,   and  mitigated fragmented sleep during the first night effect.  [51]  Lactiplantibacillus  plantarum P72  Reduced sleep latency and enhanced sleep duration. Alleviated  insomnia - like behaviors by upregulating GABA and serotonin  systems.  [52]  Bifidobacterium   Increased abundance in participants after consuming a dairy -  based product, which possibly contributed to sleep improvement.  [12]  Bifidobacterium  longum  Negative association with   obstructive sleep apnea ( OSA ) , possibly  lowering the risk of developing OSA.  [53]  Bifidobacterium  adolescentis   NK98  Increased   abundance   linked   to   improved   sleep   quality   and  reduced   depressive   symptoms   after   probiotic   NVP - 1704  treatment.  [49]  Anaerostipes   Inverse association with OSA, suggesting reduced abundance in  individuals with OSA.  [53]  Eubacterium  (xylanophilum group)  Shown to have a protective association against OSA, lowering its  risk.  [54]  Akkermansia  muciniphila  Reduced abundance after sleep deprivation; supplementation  alleviated cognitive dysfunction, prevented hippocampal synaptic  loss, and increased serum SCFAs levels.   Abundance altered by  chronic   intermittent   hypoxia   (CIH)   and   chronic   sleep  fragmentation (CSF ).  [55]   ,   [56]  Parasutterella   Lower levels associated with ASD, which may negatively impact  the production of metabolites important for circadian rhythm  regulation and stress response.  [45]  Muribaculum   Decreased levels in ASD, potentially contributing to disruptions in  gut homeostasis and systemic inflammation that affect sleep  quality.  [45]  Monoglobus   Reduced abundance linked to gut dysbiosis in ASD, possibly  impairing gut - brain communication and contributing to circadian  rhythm misalignment.  [45]  Eubacterium  xylanophilum  Negative   association   with   Obstructive   Sleep   Apnea   (OSA),  potentially reducing the risk of OSA.  [53]  Enterococcus  faecium BS5  Produces GABA, a neurotransmitter with tranquilizing effects,  potentially improving anxiety and sleep quality.  [57]  Parabacteroides  merdae  Negative association with OSA, indicating a potential protective  effect against OSA.  [53]  Bacteroidetes   Decreased   abundance   after   PSD,   with   a   shift   in   the  Firmicutes:Bacteroidetes   ratio linked to metabolic perturbations.  [58]  Faecalibacterium  prausnitzii  Strong association with sleep quality scores, particularly due to its  involvement in metabolic pathways such as L - arginine and L -  tryptophan biosynthesis.  [59]  Lachnospiraceae_NK  4A136  Decreased in sleep - deprived mice, linked to reduced butyrate  levels and worsened memory and inflammatory responses.  [13]  Lachnospiraceae_NK  4A136  Increased   abundance   associated   with   higher   SCFA   levels,  supporting neurotransmitter function and better sleep patterns.  [60]  Table 2: Gut Microbiota and Their Potential Negative Effects on Sleep  Gut Microbiota   Effect on Sleep Disorders   References\n\nCandidatus_Arthromi  tus  Increased abundance associated with acute sleep deprivation  (ASD), potentially contributing to systemic inflammation and  circadian rhythm disruptions.  [45]  Enterobacter   Increased levels linked to ASD, possibly exacerbating gut  inflammation and barrier dysfunction, which can amplify sleep  disturbances.  [45]  Bacteroides   Played a role in altering microbiota network structure during  circadian rhythm disturbances, affecting gut   functionality .  S ignature bacteria for acute insomnia patients, differing from  healthy   controls.   Found   in   paradoxical   insomnia   (P - IN)  patients, distinguishing their microbiota profile, potentially  linked   to   sleep   disturbances.   Positively   correlated   with  Pittsburgh Sleep Quality Index (PSQI) scores, indicating poorer  sleep quality.  [61]   ,   [62]   ,  [63]   ,   [64]  Firmicutes   Increased   abundance   following   partial   sleep   deprivation  (PSD), associated with metabolic disturbances like insulin  resistance.   Increased abundance in pregnant rats subjected to  maternal   sleep   deprivation   ( MSD ) ,   leading   to   microbial  dysbiosis in offspring and neuroinflammation.  [58]   ,   [65]  Lachnospira   Signature bacteria for distinguishing acute insomnia patients   [62]  Blautia   Signature bacteria for chronic insomnia patients   [62]  Aeromonas   Increased in sleep - deprived mice, associated with elevated  LPS levels, hippocampal inflammation, and spatial memory  impairment.  [13]  Ruminococcus_1   Positively correlated with proinflammatory cytokines IL - 1 Œ≤   and  TNF - Œ±   in the offspring of MSD, linked to neuroinflammation.  [65]  Ruminococcaceae_U  CG - 005  Positively correlated with IL - 1 Œ≤   and TNF - Œ±   in MSD offspring,  contributing to neuroinflammation in the brain.  [65]  Ruminococcaceae_U  CG - 002  Mediates the positive association between chronic insomnia  and cardiometabolic diseases (CMD), possibly through the gut  microbiota - bile acid axis.  [66]  Ruminococcaceae_  UCG - 003  Associated with chronic insomnia and CMD, with bile acids like  isolithocholic   acid   and   nor   cholic   acid   mediating   this  relationship.  [66]  Coriobacteriaceae   Associated with objective insomnia (O - IN), potentially linked  to the onset of insomnia.  [63]  Erysipelotrichaceae   Found in O - IN patients, possibly contributing to the microbiota  imbalance seen in insomnia.  [63]  Clostridium   Identified in O - IN patients, related to sleep disturbances and  microbiota alterations in insomnia.   Associated with insomnia  through inflammatory pathways.  [63,67]   ,   [68]  Pediococcus   Present in O - IN patients, contributing to distinct gut microbiota  profiles in insomnia.  [63]  Staphylococcus   Present in P - IN patients, contributing to unique microbiota  profiles in this insomnia subtype.  [63]  Carnobacterium   Present in P - IN patients, potentially associated with altered  sleep - wake regulation.  [63]  Pseudomonas   Linked   to   P - IN,   contributing   to   microbiota   dysbiosis   in  insomnia.  [63]  Odoribacter   A key discriminant in P - IN patients, playing a role in gut - brain  axis dysregulation and sleep disturbance.  [63]  Streptococcus   Found in higher levels in insomniacs, linked to changes in  metabolism and immune responses.  [69]\n\nLactobacillus  crispatus  Elevated in insomnia patients; associated with disruptions in  glycerophospholipid and glutamate metabolism pathways.  [69]  Prevotella amnii,  Prevotella buccalis,  Prevotella  timonensis,  Prevotella colorans  They contribute to inflammation by correlating with elevated  levels of TNF - Œ±   and IL - 1 Œ≤  [69]  Ruminococcaceae  UCG - 009  Positively associated with an increased risk OSA.   [54]  Collinsella   Enriched in REM sleep behavior disorder (RBD) and first -  degree   relatives   of   RBD   (RBD - FDR),   associated   with  inflammation.  [70]  Flavonifractor   Changes in abundance linked to Narcolepsy   T ype 1 (NT1),  indicating potential gut dysbiosis in narcolepsy.  [71]  Sutterella   Positively correlated with daytime dysfunction and may be a  biomarker for poor sleep quality in MA users  [72]  3 .2 Bacteria with Positive Effects on Sleep:  Several bacteria have been linked to improved sleep quality or a reduction in sleep  disturbances, as summarized in   Table 1 . Bifidobacterium longum, Bifidobacterium  adolescentis NK98,   and   Lactobacillus reuteri NK33   are notable for their association  with improved sleep quality, likely through mechanisms involving neurotransmitter  regulation, such as increased GABA levels and the reduction of stress hormones  [45,48,49] . These bacteria, especially when supplemented through probiotics, seem to  restore balance in the gut microbiota, thereby alleviating symptoms of insomnia,  anxiety, and depression   [47,48] .  Furthermore,   Faecalibacterium prausnitzii , a species linked to metabolic pathways like  L - arginine and L - tryptophan biosynthesis, shows a strong positive association with  sleep quality   [59] .   Lactobacillus plantarum   strains, such as P72 and PS128, also  contribute to sleep improvement by modulating GABAergic and serotonergic systems  [50,52] .   These findings suggest that increasing the abundance of these beneficial  bacteria might be a promising therapeutic strategy for improving sleep quality in  individuals with sleep disorders.  Several bacteria have been linked to improved sleep quality or a reduction in sleep  disturbances .   Bifidobacterium   longum,   Bifidobacterium   adolescentis   NK98,   and  Lactobacillus reuteri NK33   are notable for their association with improved sleep quality,  likely through mechanisms involving neurotransmitter regulation, such as increased  GABA levels and the reduction of stress hormones   [45,48,49] . These bacteria,  especially when supplemented through probiotics, seem to restore balance in the gut  microbiota, thereby alleviating symptoms of insomnia, anxiety, and depression   [47,48] .\n\nFurthermore,   Faecalibacterium prausnitzii , a species linked to metabolic pathways like  L - arginine and L - tryptophan biosynthesis, shows a strong positive association with  sleep quality   [59] .   Lactobacillus plantarum   strains, such as P72 and PS128, also  contribute to sleep improvement by modulating GABAergic and serotonergic systems  [50,52] .   These findings suggest that increasing the abundance of these beneficial  bacteria might be a promising therapeutic strategy for improving sleep quality in  individuals with sleep disorders.  3 .3   Bacteria with Negative Effects on Sleep:  In contrast, certain bacteria appear to have a detrimental impact on sleep, particularly  in conditions like   sleep deprivation and insomnia,   as summarized in   Table   2 .  Aeromonas , for instance,   are   found in higher levels in sleep - deprived mice and   are  associated with increased inflammatory markers like LPS, contributing to hippocampal  inflammation and memory impairment   [13] . Similarly,   Collinsella   and   Staphylococcus ,  which are enriched in conditions like REM sleep behavior disorder (RBD) and insomnia,  are linked to systemic inflammation and disrupted sleep patterns   [70,71] . These  bacteria   may impair   the   gut - brain   axis,   leading to   sleep disturbances   through  neuroinflammatory pathways.  3 . 4   Bacteria Linked to Circadian Rhythm and Metabolic Disruptions:  Certain gut bacteria also play a role in the regulation of circadian rhythms and  metabolic processes, both of which are critical for maintaining healthy sleep patterns,  as summarized in   Table 2 . For instance,   Bacteroides , a signature bacterium found in  patients with paradoxical insomnia (P - IN), is positively correlated with poor sleep  quality and disrupted circadian rhythms   [61,62] . In addition,   Ruminococcaceae  species, including   Ruminococcaceae UCG - 002   and   Ruminococcaceae UCG - 003 , are  associated with chronic insomnia and cardiometabolic diseases, suggesting a link  between gut microbiota, sleep disorders, and metabolic health   [54,66] .  4.   S leep - immune - microbiota axis  4 .1 Introduction to Sleep - Immune - Microbiota Axis  Dynamic interactions between gut microbiota and a host‚Äôs innate and adaptive  immune systems are essential in maintaining intestinal homeostasis and inhibiting  inflammation. Gut microbiota metabolizes proteins and complex carbohydrates,  synthesizes vitamins , and produces numerous metabolic products that mediate cross -  talk between the gut epithelium and immune cells   [73] .   The composition of the  intestinal microbiome plays a pivotal role in maintaining the stability of the intestinal  barrier. Dysbiosis contributes to the disruption of this barrier, commonly referred to as\n\n\"leaky gut\"   a condition characterized by increased intestinal permeability .   This  condition facilitates the translocation of bacterial metabolites and endotoxins, such as  LPS into the bloodstream, triggering systemic inflammation and   facilitating   the  development of metabolic and autoimmune diseases   [74] .   Figure 1 illustrates the  integrated bidirectional interactions between sleep, the gut microbiota, the immune  system, and the endocrine system that frame the conceptual basis of this section.  Comprehending these mechanisms highlights potential therapeutic strategies, such as  the use of probiotics, prebiotics, or dietary interventions, to restore gut barrier integrity  and mitigate sleep disturbances . This section explores the intricate relationships  between sleep, immunity, and microbiota, offering insights into their combined role in  maintaining systemic health.  4 .2 Disbiosis, Inflammation, and Barrier Integrity  Restoring gut microbial balance through fecal microbiota transplantation (FMT) has  been shown to reduce LPS levels in the colon, serum, and other tissues, thereby  suppressing the TLR4/MyD88/NF - Œ∫ B signaling pathway and its downstream pro -  inflammatory produc ts   [75] .   This inflammation compromises blood - brain barrier (BBB)  integrity, facilitating the translocation of inflammatory mediators and metabolites into  the brain. These processes contribute to neuroinflammation, neurodegeneration, and  brain aging   [76] .  Several gut microbiota s , especially   Firmicutes   and   Bacteroidetes ,   have   demonstrated  significant effects on mental health. Dysbiosis involving these groups is associated  with mental disorders such as anxiety, depression, and chronic intestinal inflammation  [77,78] .   An increase in opportunistic pathogens, such as   Aeromonas , destabilizes  intestinal tight junction proteins, allowing microorganisms or microbial components  like LPS to enter systemic circulation. This process triggers systemic inflammation,  with LPS reaching the brain and binding to Toll - like receptor 4 (TLR4) o n microglia,  inducing the synthesis and secretion of pro - inflammatory cytokines   [13] .   Conversely,  beneficial bacteria such as   Lactobacillus, Muribaculum , and   Parasutterella   have been  shown to enhance the integrity of both intestinal and brain barriers   [45] .  4 .3 Impact of Maternal Sleep Deprivation (MSD) on Gut and Immune Health  Maternal sleep deprivation (MSD) alters gut microbiota and immune responses in  offspring. Studies using quantitative real - time polymerase chain reaction (qRT - PCR)  and   enzyme - linked   immunosorbent   assay   (ELISA)   revealed   significantly   higher  expression levels   of pro - inflammatory cytokines, such as interleukin 1 Œ≤ ( IL - 1 Œ≤)   and  tumor necrosis factor   Œ± ( TNF - Œ±),   in offspring of MSD - exposed mothers compared to\n\ncontrols. Notably, Ruminococcus_1 and Ruminococcaceae_UCG - 005 were positively  correlated with these cytokines, suggesting a role in MSD - related neuroinflammation  [65] .  4 .4 Sleep, Microbiota, and Immune Dysregulation  Studies on insomnia have demonstrated significant differences in gut microbiota  composition   between   patients   and   healthy   controls.   Insomniacs   exhibited   an  increased relative abundance   of   Lactobacillus ,   Streptococcus , and   Lactobacillus  crispatus . These changes were associated with elevated IL - 1 Œ≤   levels and reduced TNF -  Œ±   levels. Specific bacterial shifts, such as increases in   Prevotella   species, were linked  to altered immune markers, highlighting the role of microbial metabolites in insomnia  pathophysiology   [69] .  Further research into the interplay between sleep, immune function, and microbiota  revealed   that   immunization   with   heat - killed   Mycobacterium   vaccae   (MV),   an  environmental   bacterium   with   immunoregulatory   properties,   mitigates   systemic  inflammation and behavioral changes induced by sleep disruption. MV immunization  prevented   alterations   in   non - REM   (NREM)   and   REM   sleep,   stress - induced  hyperlocomotion, a nd memory deficits, underscoring the therapeutic potential of  microbiota - immune interactions in modulating sl eep deprivation   [79] .  4 .5 Sleep Disturbance, Immune Activation, and Disease Risk  Sleep   disturbances   contribute   to   inflammation - mediated   diseases,   including  depression, through the activation of the innate immune system and an increased risk  of infections. Sleep architecture involves dynamic shifts between T helper 1 (Th1) -  mediated infl ammation during early sleep and T helper 2 (Th2) - mediated responses in  late sleep   [80] .   A study utilizing mass cytometry and single - cell RNA sequencing  revealed that sleep deprivation increases T and plasma cell frequencies while  upregulating autoimmune - related pathways in CD4+ T and B cells. Sleep deprivation  also reduces cytotoxic cell acti vity, increasing susceptibility to infections and tumor  development, while promoting myeloid inflammation and cellular senescence   [81] .  Severe sleep deprivation in mouse models has been linked to significant inflammation  and high mortality. Specifically, increased prostaglandin D2 (PGD2) levels in the brain  were   shown   to   drive   peripheral   immune   pathologies,   including   neutrophil  accumulatio n and cytokine - storm - like syndromes. Disrupting the PGD2/DP1 axis  significantly   reduced   these   inflammatory   effects,   suggesting   it   as   a   potential  therapeutic target   [82] .\n\nObstructive   sleep apnea (OSA) disrupts   systemic immune   function.   Single - cell  transcriptomics (scRNA - seq) analysis revealed OSA - induced transcriptional changes  in peripheral blood mononuclear cells (PBMCs), with severity - dependent alterations in  several   imm une   cell   lineages.   A   molecular   signature   of   32   genes   effectively  distinguished OSA patients from controls, highlighting deregulation in systemic  immunity   [83] .   Data from the National Health and Nutrition Examination Survey  (NHANES) also revealed positive associations between sleep disorders and the  systemic immune - inflammation index   (SII),   with higher SII levels   in individuals  experiencing sleep problems   [84] .  Sleep loss induces significant changes in immune cell composition and function,  particularly in effector CD4+ T cells and myeloid cells. This is mediated by upregulation  of Granulocyte - Macrophage Colony - Stimulating Factor (GM - CSF), a cytokine that  drives t he IL - 23/Th17/GM - CSF feedback mechanism, exacerbating inflammatory  responses and autoimmune conditions such as experimental autoimmune uveitis  (EAU). Targeting GM - CSF offers a promising therapeutic avenue for managing sleep -  related inflammatory diseases   [85] .  5   The Sleep - Endocrine - Microbiota Axis: Interactions and Implications for Health  5 .1 Sleep and the Endocrine System: An Intimate Relationship  Sleep and the endocrine system share a bidirectional relationship, where hormonal  regulation influences sleep quality, and sleep, in turn, modulates endocrine function.  Key hormones such as melatonin, cortisol, leptin, ghrelin, and growth hormone (GH)  play   pivotal roles in this interplay   [86 ‚Äì 89] .  Melatonin, produced by the pineal gland, is a central regulator of the circadian rhythm.  Its secretion is stimulated by darkness and inhibited by light, making it essential for  synchronizing sleep - wake cycles   [86] . Beyond its role in sleep regulation, melatonin  exhibits antioxidant and anti - inflammatory properties, which contribute to cellular  protection and the mitigation of oxidative stress   [90] . Disruptions in melatonin  production, such as those caused by exposure to artificial light at night, have been  linked to sleep disorders and metabolic dysregulation   [91] .  Cortisol, a glucocorticoid released by the adrenal glands, follows a diurnal rhythm with  peak levels in the early morning and a gradual decline throughout the day. Sleep  disturbances, such as insomnia or sleep apnea, can dysregulate cortisol secretion,  lea ding to hyperactivation of the hypothalamic - pituitary - adrenal (HPA) axis. This  dysregulation is associated with increased stress, anxiety, and a higher risk of\n\nmetabolic and cardiovascular diseases   [92] . For instance, sleep deprivation has been  shown to elevate nighttime cortisol levels, exacerbating stress - related disorders   [93] .  Studies have shown that changes in the ghrelin/leptin ratio are significantly correlated  with alterations in subjective hunger during chronic circadian disruption and sleep  restriction   [94] .   Growth hormone (GH) is primarily secreted during slow - wave sleep  (SWS), and its release is regulated by growth hormone - releasing hormone (GHRH) and  somatostatin. GH stimulates the production of insulin - like growth factor 1 (IGF - 1),  which plays a key role i n tissue growth, neuroprotection, and metabolic regulation.  Sleep deprivation significantly reduces GH and IGF - 1 levels, affecting metabolic  homeostasis and cognitive function   [89] .  5 .2 The Role of the Endocrine System in the Microbiota - Sleep Connection  The gut microbiota, through its influence on the intestinal environment and systemic  pathways, is recognized as a functional endocrine organ. It interacts with various  hormones, including estrogen, androgens, and insulin, playing a critical role in  endocri ne regulation   [95] .   R ecent studies have shown that gut dysbiosis can activate  the hypothalamic - pituitary - adrenal (HPA) axis, leading to a hormonal imbalance that  impacts sleep patterns. This activation of the HPA axis can result in elevated cortisol  levels, a stress hormone th at, when excessive, can disrupt sleep architecture and  contribute to sleep disorders   [96] .  Additionally, gut microbiota influences the production of serotonin, a neurotransmitter  that serves as a precursor to melatonin, the primary hormone regulating the sleep -  wake cycle. An imbalance in the microbiota can alter serotonin   [97] .  The relationship between the microbiota and the endocrine system is also evident in  glucose metabolism regulation. A study observed that reduced REM sleep duration is  associated   with   an   unfavorable   glycemic   profile   and   alterations   in   microbiota  composition , suggesting an interaction between sleep, microbiota, and endocrine  regulation of energy metabolism   [98] .  Moreover, interventions that modulate the gut microbiota, such as the use of probiotics  and prebiotics, have shown promising effects in improving sleep disorders. These  interventions may influence the endocrine system by restoring microbiota balance,  norma lizing the production of hormones and neurotransmitters involved in sleep  regulation   [99] .  In summary, the endocrine system acts as a key mediator in the bidirectional  connection between gut microbiota and sleep. Alterations in the microbiota can trigger  endocrine responses that affect sleep quality, while sleep disturbances can influence\n\nmicrobial composition and endocrine function. Understanding this interaction is  essential for developing therapeutic strategies aimed at improving sleep health through  microbiota and endocrine system modulation.  Figure 1 .   Integrated bidirectional interactions between sleep, gut microbiota, the  immune system, and the endocrine system.  Sleep loss reduces microbial diversity, increases intestinal permeability, lowers T/NK  cell activity, elevates cortisol, and disrupts circadian rhythms. Gut dysbiosis alters  SCFA   and   serotonin   production,   activates   TLR4 ‚Äì NF Œ∫ B   signaling,   and   promotes  inflammation. Immune activation (IL - 1 Œ≤ , TNF - Œ± ) disrupts sleep architecture, damages  the   gut   barrier,   and   stimulates   HPA   axis   activity.   Endocrine   dysregulation   is  characterized   by increased cortisol and reduced   melatonin. This   further impairs sleep  and modifies gut microbial composition. Together, these systems form a tightly  interconnected axis in which disturbances in one component propagate through the  others.  6 .0   Emerging Therapies Targeting the Sleep - Microbiota Axis  The sleep - microbiota axis has emerged as a promising frontier in the development of  novel therapeutic strategies. The intricate bidirectional relationship between sleep, gut\n\nmicrobiota, and the immune system offers multiple intervention points to enhance  sleep quality and reduce systemic inflammation. Probiotic interventions, particularly  with strains such as   Lactobacillus   and   Bifidobacterium , have demonstrated potential  in   improving   sleep   by   modulating   the   gut - brain   axis,   altering   neurotransmitter  synthesis, and reducing inflammatory markers associated with sleep disorders   [100] .  In parallel, emerging nutraceutical approaches, such as compositions including   Œ≤ -  glucan, prebiotics, and the herbal extract silymarin, have shown promise. A 90 - day pilot  study demonstrated that these formulations improved sleep quality, mood, and life  qual ity   while   reducing   inflammatory   markers   and   enhancing   metabolic   health,  suggesting their potential as integrative therapies targeting the sleep - microbiota axis  [101] .   As   illustrated   in   Figure   2,   therapeutic   interventions   targeting   the   sleep -  microbiota   axis   encompass   probiotics,   fecal   microbiota   transplantation,  nutraceuticals, neuropeptides, chrononutrition, and acupuncture, all of which act on  microbiota composition, circadian regulation, neurochemical balance, and microbe -  host communication.  Emerging therapeutic approaches continue to explore the potential of fecal microbiota  transplantation (FMT) and its advanced variant, washed microbiota transplantation  (WMT),   as   innovative   interventions   to   restore   gut   integrity   and   mitigate  neuroinflammati on. Notably, WMT has shown promising results in improving sleep  quality among patients with inflammatory bowel disease (IBD)   [102] .   Moreover, a recent  study demonstrated that WMT significantly enhances sleep quality and life quality in  patients with sleep disorders by regulating gut microbiota, with improved outcomes  observed following multiple treatment courses. These findings highlig ht WMT's safety  and efficacy, further supporting its role as a novel therapeutic option for targeting the  sleep - microbiota axis   [103] .  Furthermore, advancements in chronobiology have revealed that gut microbiota  exhibits   a circadian rhythm closely synchronized   with host sleep - wake   cycles.  Dysbiosis disrupts this rhythm, negatively impacting sleep quality. Therapies targeting  the restorati on of microbiota circadian patterns are gaining attention as a strategy for  managing sleep disorders   [104] .   For instance, chrononutrition, or the timing of food  intake in alignment with circadian rhythms, has shown potential to enhance microbial  rhythmicity and improve sleep outcomes. Chrononutrition, which includes practices  such as diurnal fasting, meal timing , and avoiding late eating, has been linked to  improvements   in   sleep   quality,   particularly   through   its   influence   on   metabolic  regulation and circadian alignment   [105] .  Microbial metabolites such as short - chain fatty acids (SCFAs) are increasingly being  investigated for their roles in sleep regulation, particularly in the context of insomnia.\n\nSCFAs, including acetate, butyrate, and propionate, are key byproducts of fiber  fermentation in the gut and influence gut - brain communication pathways associated  with sleep continuity. Evidence from studies in older adults with insomnia symptoms  suggests t hat higher concentrations of SCFAs are linked to poorer sleep efficiency and  longer sleep onset latency, particularly in individuals with the short sleep duration  phenotype, which is considered a more biologically severe form of insomnia   [106] .  These findings highlight the potential of SCFAs not only as biomarkers of sleep  disorders but also as attractive targets for future therapeutic interventions .  Additionally, the use of neuropeptides, such as orexins ,   vasoactive intestinal peptide  (VIP)   and neuropeptide Y   represents another avenue for therapeutic intervention. These  molecules modulate both sleep cycles and gut microbiota interactions, offering a  potential dual - target strategy for improving sleep and gut health   is essential for  wakefulness   maintenance,   while   melanin - concentrating   hormone   and   galanin  promote REM sleep   [107] .   In parallel, neuropeptide S (NPS) has been shown to alleviate  anxiety - like behavior and sleep disturbances caused by paradoxical sleep deprivation  (PSD). NPS modulates wakefulness, suppresses paradoxical sleep, and alters EEG  theta activity. By activating   NPSR receptors in the amygdala, NPS counteracts the  effects of PSD without triggering rebound sleep, which further underscores its potential  as a therapeutic option for anxiety - related sleep disorders.   [108] .  Complementary therapies, such as acupuncture, have demonstrated potential as  nonpharmacological interventions for insomnia by modulating both neurotransmitter  levels and gut microbiota composition. In PCPA (p - chlorophenylalanine) - induced  insomnia models, a cupuncture was shown to reduce serum levels of dopamine, 5 -  hydroxytryptamine, and norepinephrine, while increasing melatonin levels in the pineal  gland. Furthermore, 16S rRNA sequencing revealed that both acupuncture and  hypnotic drugs produced similar imp rovements in gut microbiota composition,  suggesting shared mechanisms of action. Notably, acupuncture networks exhibited  greater   microbial   community   stability   and   fewer   side   effects   compared   to  pharmacological interventions, highlighting its potential as a   safer alternative for  targeting the sleep - microbiota axis   [109] .\n\nFigure 2. Emerging therapeutic strategies targeting the sleep ‚Äì microbiota axis.  Multiple   approaches   aim to restore   sleep quality by modulating gut   microbial  composition, neuroendocrine signaling, and circadian alignment. Probiotics, fecal and  washed microbiota transplantation (FMT/WMT), and microbial metabolites such as  SCFAs support   microbial balance and gut ‚Äì brain communication. Nutraceuticals,  including   silymarin,   prebiotics,   and   Œ≤ - glucan,   enhance   metabolic   and   anti -  inflammatory pathways relevant to sleep regulation. Neuropeptides such as orexin, VIP,  NPY, NPS, and galanin offer additional targets for modulating arousal and sleep  architecture. Chrononutrition strategies   diurnal fasting, meal timing, and circadian -  aligned eating   reinforce microbial and metabolic rhythms. Acupuncture serves as a  nonpharmacological therapy that influences neurotransmitters, increases melatonin,  and promotes a healthier microbiota. Together, these modali ties illustrate a multi -  modal therapeutic framework for improving sleep outcomes.  7 .0   Limitations of Current Literature  Despite major advances in understanding the sleep   microbiota axis, several limitations  constrain   the   current   body   of   evidence.  First, most studies rely on small sample sizes, reducing statistical power and  generalizability. For example, clinical work examining fecal metabolites and sleep\n\nquality uses modest cohorts that limit robust subgroup analyses and mechanistic  inference   [22] .  Second,   much   of   the   mechanistic   evidence   still   comes   from   animal   models,  particularly rodent studies on circadian disruption, sleep loss, and neuroinflammation.  While informative, these models cannot fully capture the complexity of human  microbiota, or the   variability in lifestyle, diet, and circadian behavior seen in real  populations   [45] .  Third, methodological heterogeneity across microbiome studies remains a major  limitation. Differences in sequencing platforms, microbial classification pipelines, and  metabolite profiling approaches create inconsistencies across reports, complicating  direc t   comparisons   between   findings.  Studies evaluating interventions such as nutraceutical compositions or acupuncture  further   illustrate   variability   in   outcome   measures,   microbial   endpoints,   and  inflammatory biomarkers, making it difficult to establish unifie d mechanistic pathways  [101,109] .  Although endocrine pathways are clearly affected by sleep loss, this component of the  axis remains understudied. Current evidence shows that sleep deprivation and  circadian disruption alter cortisol rhythms and HPA - axis activity, contributing to  metabolic   and inflammatory imbalance   [87] .   However, most studies assess cortisol or  sleep outcomes in isolation, without simultaneous measurement of immune or  microbiota variables   [92] .  As a result, very few human studies integrate endocrine, immune, and microbial  markers   within   a   unified   experimental   design.   Finally,   therapeutic   approaches  including chrononutrition, nutraceutical formulations, and microbiota transplantation  have shown promising but preliminary results with significant variability in dosage,  duration, and treatment adherence   [75,101,105]   These limitations highlight the need  for larger, standardized, multimodal studies to fully understand the bidirectional  interactions among sleep, microbiota, endocrine signaling, and immune networks.  8 .0   Future Directions for Research  Future   research   should   integrate   microbiota,   neurochemical   signaling,   immune  activity, and endocrine rhythms to define causal mechanisms of the sleep   microbiota  axis. Sleep - loss ‚Äì driven IL - 23/Th17/GM - CSF inflammation   [85]   together with dysbiosis  induced TLR4/NF - Œ∫ B activation   [75]   highlight the need for interventions targeting barrier  integrity and systemic inflammation. Mechanistic studies must clarify how sleep -  regulating neurotransmitters described in sleep - wake neurochemistry are shaped by\n\nGABA - producing bacteria   [29] , SCFAs, and disrupted serotonin   vitamin B6 metabolism  in antibiotic   depleted models   [110] .  Therapeutically,   both   WMT   improving   sleep   in   humans   [102]   and   acupuncture  modulating microbiota and monoamines in insomnia models   [109]   suggest promising  microbiota   directed interventions. Future work should also evaluate chrononutrition  [105]   and   metabolic   circadian   alignment,   particularly   in   disorders   affecting  leptin / ghrelin oscillations. Finally, deeper characterization of GMBA immune   neural  interactions   [20]   is   essential   for   developing   integrated   neuroimmune   microbial  therapies for sleep disorders.  Conclusions:  The interplay between the gut microbiota and sleep regulation represents a fascinating  and rapidly evolving area of research. While substantial progress has been made,  critical gaps in knowledge remain. For instance, the mechanisms by which specific  microb ial metabolites influence sleep architecture are still not fully understood.  Moreover, the variability in individual microbiota compositions presents challenges in  developing universally effective therapies.  Evidence suggests that targeting microbiota may offer novel therapeutic avenues for  sleep disorders, particularly those with an inflammatory or stress - related component.  Future therapies could integrate microbiota modulation with established clinical  proto cols, such as cognitive - behavioral therapy for insomnia or pharmacological  interventions.   Additionally,   emerging   diagnostic   tools,   like   microbiota - based  biomarkers, hold promise for identifying individuals at risk of sleep disorders or  monitoring treatment   efficacy.  Future   investigations   should   prioritize   integrative   approaches   that   combine  microbiota - targeted   therapies   with   lifestyle   modifications,   such   as   dietary  adjustments, sleep hygiene, and stress management. By addressing these aspects  holistically, researchers   and clinicians can maximize the potential of these therapies to  improve sleep quality and overall health outcomes.  Acknowledgements  Figures in this manuscript were created with BioRender.com.  References  [1]   Sejbuk M, Miro≈Ñczuk - Chodakowska I, Witkowska AM. Sleep Quality: A Narrative  Review on Nutrition, Stimulants, and Physical Activity as Important Factors.  Nutrients 2022;14. https://doi.org/10.3390/nu14091912.\n\n[2]   Irwin MR, Opp MR. Sleep Health: Reciprocal Regulation of Sleep and Innate  Immunity. Neuropsychopharmacology 2017;42:129 ‚Äì 55.  https://doi.org/10.1038/npp.2016.148.  [3]   Cabr√© - Riera A, Torrent M, Donaire - Gonzalez D, Vrijheid M, Cardis E, Guxens M.  Telecommunication devices use, screen time and sleep in adolescents.   Environ  Res 2019;171:341 ‚Äì 7. https://doi.org/10.1016/j.envres.2018.10.036.  [4]   Wehbe AT, Costa TE, Abbas SA, Costa JE, Costa GE, Wehbe TW.   The Effects of  the COVID - 19 Confinement on Screen Time, Headaches, Stress and Sleep  Disorders among Adolescents: A Cross Sectional Study. Chronic Stress 2022;6.  https://doi.org/10.1177/24705470221099836.  [5]   Jaqua EE, Hanna M, Labib W, Moore C, Matossian V. Common Sleep Disorders  Affecting Older Adults. 2022.  [6]   Albrecht U. Timing to Perfection: The Biology of Central and Peripheral  Circadian Clocks. Neuron 2012;74:246 ‚Äì 60.  https://doi.org/10.1016/j.neuron.2012.04.006.  [7]   Koronowski KB, Sassone - Corsi P. Communicating clocks shape circadian  homeostasis. Science (1979) 2021;371.  https://doi.org/10.1126/science.abd0951.  [8]   Mashaqi S, Gozal D. ‚ÄúCircadian misalignment and the gut microbiome. A  bidirectional relationship triggering inflammation and metabolic disorders‚Äù -   a  literature review. Sleep Med 2020;72:93 ‚Äì 108.  https://doi.org/10.1016/j.sleep.2020.03.020.  [9]   Matenchuk BA, Mandhane PJ, Kozyrskyj AL. Sleep, circadian rhythm, and gut  microbiota. Sleep Med Rev 2020;53.  https://doi.org/10.1016/j.smrv.2020.101340.  [10]   Sun S - Y, Chen G - H. Treatment of Circadian Rhythm Sleep ‚Äì Wake Disorders. Curr  Neuropharmacol 2021;20:1022 ‚Äì 34.  https://doi.org/10.2174/1570159x19666210907122933.  [11]   Feng W, Yang Z, Liu Y, Chen R, Song Z, Pan G, et al. Gut microbiota: A new target  of traditional Chinese medicine for insomnia. Biomedicine and  Pharmacotherapy 2023;160. https://doi.org/10.1016/j.biopha.2023.114344.  [12]   Schaafsma A, Mallee L, van den Belt M, Floris E, Kortman G, Veldman J, et al.  The effect of a whey - protein and galacto - oligosaccharides based product on\n\nparameters of sleep quality, stress, and gut microbiota in apparently healthy  adults with moderate sleep disturbances: A randomized controlled cross - over  study. Nutrients 2021;13. https://doi.org/10.3390/nu13072204.  [13]   Wang X, Wang Z, Cao J, Dong Y, Chen Y. Gut microbiota - derived metabolites  mediate the neuroprotective effect of melatonin in cognitive impairment  induced by sleep deprivation. Microbiome 2023;11.  https://doi.org/10.1186/s40168 - 022 - 01452 - 3.  [14]   Asadi A, Shadab Mehr N, Mohamadi MH, Shokri F, Heidary M, Sadeghifard N, et  al. Obesity and gut ‚Äì microbiota ‚Äì brain axis: A narrative review. J Clin Lab Anal  2022;36. https://doi.org/10.1002/jcla.24420.  [15]   Han M, Yuan S, Zhang J. The interplay between sleep and gut microbiota.   Brain  Res Bull 2022;180:131 ‚Äì 46. https://doi.org/10.1016/j.brainresbull.2021.12.016.  [16]   Ogawa Y, Miyoshi C, Obana N, Yajima K, Hotta - Hirashima N, Ikkyu A, et al.   Gut  microbiota depletion by chronic antibiotic treatment alters the sleep/wake  architecture and sleep EEG power spectra in mice. Sci Rep 2020;10.  https://doi.org/10.1038/s41598 - 020 - 76562 - 9.  [17]   Ullah H, Arbab S, Tian Y, Liu CQ, Chen Y, Qijie L, et al. The gut microbiota ‚Äì brain  axis in neurological disorder. Front Neurosci 2023;17.  https://doi.org/10.3389/fnins.2023.1225875.  [18]   Chen M, Ruan G, Chen L, Ying S, Li G, Xu F, et al. Neurotransmitter and Intestinal  Interactions: Focus on the Microbiota - Gut - Brain Axis in Irritable Bowel  Syndrome. Front Endocrinol (Lausanne) 2022;13.  https://doi.org/10.3389/fendo.2022.817100.  [19]   Roman√≠ - P√©rez M, Bullich - Vilarrubias C, L√≥pez - Almela I, Li√©bana - Garc√≠a R,  Olivares M, Sanz Y. The microbiota and the gut - brain axis in controlling food  intake and energy homeostasis. Int J Mol Sci 2021;22.  https://doi.org/10.3390/ijms22115830.  [20]   Le W, Reichmann H, Yang X, Zhao Y, Zhu G. Interactions between gut microbiota  and Parkinson‚Äôs disease: The role of microbiota - derived amino acid  metabolism. n.d.  [21]   Skonieczna - ≈ºydecka K, Grochans E, Maciejewska D, Szkup M, Schneider -  Matyka D, Jurczak A, et al. Faecal short chain fatty acids profile is changed in  Polish depressive women. Nutrients 2018;10.  https://doi.org/10.3390/nu10121939.\n\n[22]   Magzal F, Even C, Haimov I, Agmon M, Asraf K, Shochat T, et al. Associations  between fecal short - chain fatty acids and sleep continuity in older adults with  insomnia symptoms. Sci Rep 2021;11. https://doi.org/10.1038/s41598 - 021 -  83389 - 5.  [23]   van de Wouw M, Boehme M, Lyte JM, Wiley N, Strain C, O‚ÄôSullivan O, et al.  Short - chain fatty acids: microbial metabolites that alleviate stress - induced  brain ‚Äì gut axis alterations. Journal of Physiology 2018;596:4923 ‚Äì 44.  https://doi.org/10.1113/JP276431.  [24]   Holst SC, Landolt HP. Sleep - Wake Neurochemistry. Sleep Med Clin  2018;13:137 ‚Äì 46. https://doi.org/10.1016/j.jsmc.2018.03.002.  [25]   Innocenti A, Lentini G, Rapacchietta S, Cinnirella P, Elia M, Ferri R, et al. The  Role of Supplements and Over - the - Counter Products to Improve Sleep in  Children: A Systematic Review. Int J Mol Sci 2023;24.  https://doi.org/10.3390/ijms24097821.  [26]   Roth W, Zadeh K, Vekariya R, Ge Y, Mohamadzadeh M. Tryptophan metabolism  and gut - brain homeostasis. Int J Mol Sci 2021;22:1 ‚Äì 23.  https://doi.org/10.3390/ijms22062973.  [27]   Zuraikat FM, Wood RA, Barrag√°n R, St - Onge MP. Sleep and Diet: Mounting  Evidence of a Cyclical Relationship. Annu Rev Nutr 2021;41:309 ‚Äì 32.  https://doi.org/10.1146/annurev - nutr - 120420 - 021719.  [28]   Jones BE. Arousal and sleep circuits. Neuropsychopharmacology 2020;45:6 ‚Äì 20.  https://doi.org/10.1038/s41386 - 019 - 0444 - 2.  [29]   Strandwitz P, Kim KH, Terekhova D, Liu JK, Sharma A, Levering J, et al. GABA -  modulating bacteria of the human gut microbiota. Nat Microbiol 2019;4:396 ‚Äì  403. https://doi.org/10.1038/s41564 - 018 - 0307 - 3.  [30]   Zhou J, He L, Liu M, Guo X, Du G, Yan L, et al.   Sleep loss impairs intestinal stem  cell function and gut homeostasis through the modulation of the GABA  signalling pathway in Drosophila. Cell Prolif 2023;56.  https://doi.org/10.1111/cpr.13437.  [31]   Gott JA, St√ºcker S, Kanske P, Haaker J, Dresler M. Acetylcholine and  metacognition during sleep. Conscious Cogn 2024;117.  https://doi.org/10.1016/j.concog.2023.103608.\n\n[32]   Eslami M, Alibabaei F, Babaeizad A, Banihashemian SZ, Mazandarani M,  Hoseini A, et al.   The Importance of Gut Microbiota on Choline Metabolism in  Neurodegenerative Diseases. Biomolecules 2024;14:1345.  https://doi.org/10.3390/biom14111345.  [33]   Ashton A, Jagannath A. Disrupted Sleep and Circadian Rhythms in  Schizophrenia and Their Interaction With Dopamine Signaling. Front Neurosci  2020;14. https://doi.org/10.3389/fnins.2020.00636.  [34]   Hamamah S, Aghazarian A, Nazaryan A, Hajnal A, Covasa M. Role of  Microbiota - Gut - Brain Axis in Regulating Dopaminergic Signaling. Biomedicines  2022;10. https://doi.org/10.3390/biomedicines10020436.  [35]   Alhusaini M, Eissa N, Saad AK, Beiram R, Sadek B. Revisiting Preclinical  Observations of Several Histamine H3 Receptor Antagonists/Inverse Agonists in  Cognitive Impairment, Anxiety, Depression, and Sleep ‚Äì Wake Cycle Disorder.  Front Pharmacol 2022;13. https ://doi.org/10.3389/fphar.2022.861094.  [36]   Barcik W, Pugin B, Westermann P, Perez NR, Ferstl R, Wawrzyniak M, et al.  Histamine - secreting microbes are increased in the gut of adult asthma  patients. Journal of Allergy and Clinical Immunology 2016;138:1491 - 1494.e7.  https://doi.org/10.1016/j.jaci.2016 .05.049.  [37]   Mishima Y, Ishihara S. Molecular Mechanisms of Microbiota - Mediated  Pathology in Irritable Bowel Syndrome. Int J Mol Sci 2020;21:8664.  https://doi.org/10.3390/ijms21228664.  [38]   Toor B, Ray LB, Pozzobon A, Fogel SM. Sleep, Orexin and Cognition, 2021, p. 38 ‚Äì  51. https://doi.org/10.1159/000514960.  [39]   Sun Y, Tisdale RK, Kilduff TS. Hypocretin/Orexin Receptor Pharmacology and  Sleep Phases. Front Neurol Neurosci 2021;45:22 ‚Äì 37.  https://doi.org/10.1159/000514963.  [40]   Forte N, Marfella B, Nicois A, Palomba L, Paris D, Motta A, et al. The short - chain  fatty acid acetate modulates orexin/hypocretin neurons: A novel mechanism in  gut - brain axis regulation of energy homeostasis and feeding. Biochem  Pharmacol 2024;226:116383.   https://doi.org/10.1016/j.bcp.2024.116383.  [41]   Steiner MA, Yanagisawa M, Clozel M, editors. The Orexin System. Basic Science  and Role in Sleep Pathology. vol. 45. S. Karger AG; 2021.  https://doi.org/10.1159/isbn.978 - 3 - 318 - 06844 - 3.\n\n[42]   Kjaerby C, Andersen M, Hauglund N, Untiet V, Dall C, Sigurdsson B, et al.  Memory - enhancing properties of sleep depend on the oscillatory amplitude of  norepinephrine. Nat Neurosci 2022;25:1059 ‚Äì 70.  https://doi.org/10.1038/s41593 - 022 - 01102 - 9.  [43]   Wang J, Fang Z, Dong X, Li W, Wan X. Effect of norepinephrine on host immunity  and bacterial infection. Chin Med J (Engl) 2024;137:362 ‚Äì 4.  https://doi.org/10.1097/CM9.0000000000002931.  [44]   Menon R, Fitzsimmons B, Vanajakumari MU, Lee K, Jayaraman A. Effect of  Norepinephrine on Gut Bacterial Community Structure and Function. The  FASEB Journal 2019;33.  https://doi.org/10.1096/fasebj.2019.33.1_supplement.724.4.  [45]   Yang DF, Huang WC, Wu CW, Huang CY, Yang YCSH, Tung YT. Acute sleep  deprivation exacerbates systemic inflammation and psychiatry disorders  through gut microbiota dysbiosis and disruption of circadian rhythms. Microbiol  Res 2023;268. https://doi.org/10.1016 /j.micres.2022.127292.  [46]   Zhao N, Shu Y, Jian C, Zhou Z, Bao H, Li X, et al. Lactobacillus Ameliorates SD -  Induced Stress Responses and Gut Dysbiosis by Increasing the Absorption of  Gut - Derived GABA in Rhesus Monkeys. Front Immunol 2022;13.  https://doi.org/10.3389/fimmu.2022.915393 .  [47]   Zhu R, Fang Y, Li H, Liu Y, Wei J, Zhang S, et al. Psychobiotic Lactobacillus  plantarum JYLP - 326 relieves anxiety, depression, and insomnia symptoms in  test anxious college via modulating the gut microbiota and its metabolism.  Front Immunol 2023;14. https ://doi.org/10.3389/fimmu.2023.1158137.  [48]   Ho YT, Tsai YC, Kuo TBJ, Yang CCH. Effects of lactobacillus plantarum ps128 on  depressive symptoms and sleep quality in self - reported insomniacs: A  randomized, double - blind, placebo - controlled pilot trial. Nutrients 2021;13.  https://doi.org/10.3390/nu1308 2820.  [49]   Lee HJ, Hong JK, Kim JK, Kim DH, Jang SW, Han SW, et al. Effects of probiotic  nvp - 1704 on mental health and sleep in healthy adults: An 8 - week randomized,  double - blind, placebo - controlled trial. Nutrients 2021;13.  https://doi.org/10.3390/nu13082660.  [50]   Yu L, Han X, Cen S, Duan H, Feng S, Xue Y, et al. Beneficial effect of GABA - rich  fermented milk on insomnia involving regulation of gut microbiota. Microbiol  Res 2020;233. https://doi.org/10.1016/j.micres.2020.126409.\n\n[51]   Lin A, Shih CT, Chu HF, Chen CW, Cheng YT, Wu CC, et al. Lactobacillus  fermentum PS150 promotes non - rapid eye movement sleep in the first night  effect of mice. Sci Rep 2021;11. https://doi.org/10.1038/s41598 - 021 - 95659 - 3.  [52]   Lee DY, Baek JS, Shin YJ, Kim DH. Alleviation of Immobilization Stress or Fecal  Microbiota - Induced Insomnia and Depression - like Behaviors in Mice by  Lactobacillus plantarum and Its Supplement. Nutrients 2024;16.  https://doi.org/10.3390/nu16213711.  [53]   Liu L, He G, Yu R, Lin B, Lin L, Wei R, et al. Causal relationships between gut  microbiome and obstructive sleep apnea: a bi - directional Mendelian  randomization. Front Microbiol 2024;15.  https://doi.org/10.3389/fmicb.2024.1410624.  [54]   Yan W, Jiang M, Hu W, Zhan X, Liu Y, Zhou J, et al. Causality Investigation  between Gut Microbiota, Derived Metabolites, and Obstructive Sleep Apnea: A  Bidirectional Mendelian Randomization Study. Nutrients 2023;15.  https://doi.org/10.3390/nu15214544.  [55]   Li N, Tan S, Wang Y, Deng J, Wang N, Zhu S, et al. Akkermansia muciniphila  supplementation prevents cognitive impairment in sleep - deprived mice by  modulating microglial engulfment of synapses. Gut Microbes 2023;15.  https://doi.org/10.1080/19490976.2023.22 52764.  [56]   Wang F, Zou J, Xu H, Huang W, Zhang X, Wei Z, et al. Effects of Chronic  Intermittent Hypoxia and Chronic Sleep Fragmentation on Gut Microbiome,  Serum Metabolome, Liver and Adipose Tissue Morphology. Front Endocrinol  (Lausanne) 2022;13. https://doi.org/10. 3389/fendo.2022.820939.  [57]   Bs S, Thankappan B, Mahendran R, Muthusamy G, Femil selta DR, Angayarkanni  J. Evaluation of GABA Production and Probiotic Activities of Enterococcus  faecium BS5. Probiotics Antimicrob Proteins 2021;13:993 ‚Äì 1004.  https://doi.org/10.1007/s12602 - 021 - 09759 - 7.  [58]   Benedict C, Vogel H, Jonas W, Woting A, Blaut M, Sch√ºrmann A, et al. Gut  microbiota and glucometabolic alterations in response to recurrent partial  sleep deprivation in normal - weight young individuals. Mol Metab 2016;5:1175 ‚Äì  86. https://doi.org/10.1016/j.m olmet.2016.10.003.  [59]   Seong HJ, Baek Y, Lee S, Jin HJ. Gut microbiome and metabolic pathways linked  to sleep quality. Front Microbiol 2024;15.  https://doi.org/10.3389/fmicb.2024.1418773.\n\n[60]   Li X, Zhang Y, Zhang Q, Cao A, Feng J. Eucalyptus essential oil exerted a  sedative - hypnotic effect by influencing brain neurotransmitters and gut  microbes via the gut microbiota - brain axis. Front Pharmacol 2024;15.  https://doi.org/10.3389/fphar.2024.14646 54.  [61]   Liu Z, Wei Z - Y, Chen J, Chen K, Mao X, Liu Q, et al. Acute Sleep - Wake Cycle Shift  Results in Community Alteration of Human Gut Microbiome. MSphere 2020;5.  https://doi.org/10.1128/msphere.00914 - 19.  [62]   Li Y, Zhang B, Zhou Y, Wang D, Liu X, Li L, et al.   Gut microbiota changes and their  relationship with inflammation in patients with acute and chronic insomnia. Nat  Sci Sleep 2020;12:895 ‚Äì 905. https://doi.org/10.2147/NSS.S271927.  [63]   Barone M, Martucci M, Sciara G, Conte M, Medina LSJ, Iattoni L, et al. Towards a  personalized prediction, prevention and therapy of insomnia: gut microbiota  profile can discriminate between paradoxical and objective insomnia in post -  menopausal women. EPMA   Journal 2024;15:471 ‚Äì 89.  https://doi.org/10.1007/s13167 - 024 - 00369 - 1.  [64]   Tanaka A, Sanada K, Miyaho K, Tachibana T, Kurokawa S, Ishii C, et al. The  relationship between sleep, gut microbiota, and metabolome in patients with  depression and anxiety: A secondary analysis of the observational study. PLoS  One 2023;18. https://doi.o rg/10.1371/journal.pone.0296047.  [65]   Yao ZY, Li XH, Zuo L, Xiong Q, He WT, Li DX, et al. Maternal sleep deprivation  induces gut microbial dysbiosis and neuroinflammation in offspring rats.   Zool  Res 2022;43:380 ‚Äì 90. https://doi.org/10.24272/j.issn.2095 - 8137.2022.023.  [66]   Jiang Z, Zhuo L bao, He Y, Fu Y, Shen L, Xu F, et al.   The gut microbiota - bile acid  axis links the positive association between chronic insomnia and  cardiometabolic diseases. Nat Commun 2022;13.  https://doi.org/10.1038/s41467 - 022 - 30712 - x.  [67]   Li Y, Deng Q, Liu Z. The relationship between gut microbiota and insomnia: a bi -  directional two - sample Mendelian randomization research. Front Cell Infect  Microbiol 2023;13. https://doi.org/10.3389/fcimb.2023.1296417.  [68]   Chen HW, Zhou R, Cao BF, Liu K, Zhong Q, Huang YN, et al. The predictive,  preventive, and personalized medicine of insomnia: gut microbiota and  inflammation. EPMA Journal 2023;14:571 ‚Äì 83. https://doi.org/10.1007/s13167 -  023 - 00345 - 1.\n\n[69]   Wang Q, Chen B, Sheng D, Yang J, Fu S, Wang J, et al. Multiomics Analysis  Reveals Aberrant Metabolism and Immunity Linked Gut Microbiota with  Insomnia. Microbiol Spectr 2022;10. https://doi.org/10.1128/spectrum.00998 -  22.  [70]   Huang B, Chau SWH, Liu Y, Chan JWY, Wang J, Ma SL, et al. Gut microbiome  dysbiosis across early Parkinson‚Äôs disease, REM sleep behavior disorder and  their first - degree relatives. Nat Commun 2023;14.  https://doi.org/10.1038/s41467 - 023 - 38248 - 4.  [71]   Lecomte A, Barateau L, Pereira P, Paulin L, Auvinen P, Scheperjans F, et al. Gut  microbiota composition is associated with narcolepsy type 1. Neurology(R)  Neuroimmunology & Neuroinflammation 2020;7.  https://doi.org/10.1212/NXI.0000000000000896.  [72]   Deng Z, Liu L, Liu W, Liu R, Ma T, Xin Y, et al.   Alterations in the fecal microbiota of  methamphetamine users with bad sleep quality during abstinence. BMC  Psychiatry 2024;24. https://doi.org/10.1186/s12888 - 024 - 05773 - 5.  [73]   Yoo JY, Groer M, Dutra SVO, Sarkar A, McSkimming DI. Gut microbiota and  immune system interactions. Microorganisms 2020;8:1 ‚Äì 22.  https://doi.org/10.3390/microorganisms8101587.  [74]   Di Vincenzo F, Del Gaudio A, Petito V, Lopetuso LR, Scaldaferri F. Gut  microbiota, intestinal permeability, and systemic inflammation: a narrative  review. Intern Emerg Med 2024;19:275 ‚Äì 93. https://doi.org/10.1007/s11739 - 023 -  03374 - w.  [75]   Zhao Z, Ning J, Bao X qi, Shang M, Ma J, Li G, et al. Fecal microbiota  transplantation protects rotenone - induced Parkinson‚Äôs disease mice via  suppressing inflammation mediated by the lipopolysaccharide - TLR4 signaling  pathway through the microbiota - gut - bra in axis.   Microbiome 2021;9.  https://doi.org/10.1186/s40168 - 021 - 01107 - 9.  [76]   Mou Y, Du Y, Zhou L, Yue J, Hu X, Liu Y, et al.   Gut Microbiota Interact With the  Brain Through Systemic Chronic Inflammation: Implications on  Neuroinflammation, Neurodegeneration, and Aging. Front Immunol 2022;13.  https://doi.org/10.3389/fimmu.2022.796288.  [77]   Xiong RG, Li J, Cheng J, Zhou DD, Wu SX, Huang SY, et al. The Role of Gut  Microbiota in Anxiety, Depression, and Other Mental Disorders as Well as the\n\nProtective Effects of Dietary Components. Nutrients 2023;15.  https://doi.org/10.3390/nu15143258.  [78]   Parker BJ, Wearsch PA, Veloo ACM, Rodriguez - Palacios A. The Genus Alistipes:  Gut Bacteria With Emerging Implications to Inflammation, Cancer, and Mental  Health. Front Immunol 2020;11. https://doi.org/10.3389/fimmu.2020.00906.  [79]   Bowers SJ, Lambert S, He S, Lowry CA, Fleshner M, Wright KP, et al.  Immunization with a heat - killed bacterium, Mycobacterium vaccae NCTC  11659, prevents the development of cortical hyperarousal and a PTSD - like  sleep phenotype after sleep disruption and ac ute stress in mice. Sleep  2021;44:1 ‚Äì 16. https://doi.org/10.1093/sleep/zsaa271.  [80]   Feuth T. Interactions between sleep, inflammation, immunity and infections: A  narrative review. Immun Inflamm Dis 2024;12:e70046.  https://doi.org/10.1002/iid3.70046.  [81]   Liu X, Chen B, Huang Z, Duan R, Li H, Xie L, et al. Effects of poor sleep on the  immune cell landscape as assessed by single - cell analysis. Commun Biol  2021;4. https://doi.org/10.1038/s42003 - 021 - 02859 - 8.  [82]   Sang D, Lin K, Yang Y, Ran G, Li B, Chen C, et al. Prolonged sleep deprivation  induces a cytokine - storm - like syndrome in mammals. Cell 2023;186:5500 -  5516.e21. https://doi.org/10.1016/j.cell.2023.10.025.  [83]   Cortese R, Adams TS, Cataldo KH, Hummel J, Kaminski N, Kheirandish - Gozal L,  et al. Single - cell RNA - seq uncovers cellular heterogeneity and provides a  signature for paediatric sleep apnoea. European Respiratory Journal 2023;61.  https://doi.org/10.1183/1399 3003.01465 - 2022.  [84]   Kadier K, Dilixiati D, Ainiwaer A, Liu X, Lu J, Liu P, et al. Analysis of the  relationship between sleep - related disorder and systemic immune -  inflammation index in the US population.   BMC Psychiatry 2023;23.  https://doi.org/10.1186/s12888 - 023 - 05286 - 7.  [85]   Liu X, Su Y, Huang Z, Lv J, Gu C, Li Z, et al.   Sleep loss potentiates Th17 ‚Äê cell  pathogenicity and promotes autoimmune uveitis. Clin Transl Med 2023;13.  https://doi.org/10.1002/ctm2.1250.  [86]   Nava Zisapel C, Zisapel N. New perspectives on the role of melatonin in human  sleep, circadian rhythms and their regulation LINKED ARTICLES 2018.  https://doi.org/10.1111/bph.v175.16/issuetoc.\n\n[87]   De Nys L, Anderson K, Ofosu EF, Ryde GC, Connelly J, Whittaker AC. The effects  of physical activity on cortisol and sleep: A systematic review and meta -  analysis. Psychoneuroendocrinology 2022;143.  https://doi.org/10.1016/j.psyneuen.2022.105843.  [88]   Kurnool S, McCowen KC, Bernstein NA, Malhotra A. Sleep Apnea, Obesity, and  Diabetes   ‚Äî   an Intertwined Trio. Curr Diab Rep 2023;23:165 ‚Äì 71.  https://doi.org/10.1007/s11892 - 023 - 01510 - 6.  [89]   Chennaoui M, L√©ger D, Gomez - Merino D. Sleep and the GH/IGF - 1 axis:  Consequences and countermeasures of sleep loss/disorders. Sleep Med Rev  2020;49. https://doi.org/10.1016/j.smrv.2019.101223.  [90]   Reiter RJ, Mayo JC, Tan DX, Sainz RM, Alatorre - Jimenez M, Qin L. Melatonin as  an antioxidant: under promises but over delivers. J Pineal Res 2016:253 ‚Äì 78.  https://doi.org/10.1111/jpi.12360.  [91]   Tordjman S, Chokron S, Delorme R, Charrier A, Bellissant E, Jaafari N, et al.  Melatonin: Pharmacology, Functions and Therapeutic Benefits. Curr  Neuropharmacol 2017;15:434 ‚Äì 43.  https://doi.org/10.2174/1570159X14666161228122115.  [92]   Hirotsu C, Tufik S, Andersen ML. Interactions between sleep, stress, and  metabolism: From physiological to pathological conditions. Sleep Science  2015;8:143 ‚Äì 52. https://doi.org/10.1016/j.slsci.2015.09.002.  [93]   Kim TW, Jeong JH, Hong SC. The impact of sleep and circadian disturbance on  hormones and metabolism. Int J Endocrinol 2015;2015.  https://doi.org/10.1155/2015/591729.  [94]   McHill AW, Hull JT, Klerman EB. Chronic Circadian Disruption and Sleep  Restriction Influence Subjective Hunger, Appetite, and Food Preference.  Nutrients 2022;14. https://doi.org/10.3390/nu14091800.  [95]   Qi X, Yun C, Pang Y, Qiao J. The impact of the gut microbiota on the reproductive  and metabolic endocrine system. Gut Microbes 2021;13:1 ‚Äì 21.  https://doi.org/10.1080/19490976.2021.1894070.  [96]   Naufel MF, Truzzi G de M, Ferreira CM, Coelho FMS. The brain - gut - microbiota  axis in the treatment of neurologic and psychiatric disorders. Arq  Neuropsiquiatr 2023;81:670 ‚Äì 84. https://doi.org/10.1055/s - 0043 - 1767818.\n\n[97]   Wang Z, Wang Z, Lu T, Chen W, Yan W, Yuan K, et al. The microbiota - gut - brain  axis in sleep disorders. Sleep Med Rev 2022;65:101691.  https://doi.org/10.1016/j.smrv.2022.101691.  [98]   Arnoriaga - Rodr√≠guez M, Leal Y, Mayneris - Perxachs J, P√©rez - Brocal V, Moya A,  Ricart W, et al. Gut Microbiota Composition and Functionality Are Associated  With REM Sleep Duration and Continuous Glucose Levels. Journal of Clinical  Endocrinology and Metabolis m 2023;108:2931 ‚Äì 9.  https://doi.org/10.1210/clinem/dgad258.  [99]   Li L, Liang T, Jiang T, Li Y, Yang L, Wu L, et al. Gut microbiota: Candidates for a  novel strategy for ameliorating sleep disorders. Crit Rev Food Sci Nutr  2024;64:10772 ‚Äì 88. https://doi.org/10.1080/10408398.2023.2228409.  [100]   Smith RP, Easson C, Lyle SM, Kapoor R, Donnelly CP, Davidson EJ, et al. Gut  microbiome diversity is associated with sleep physiology in humans.   PLoS One  2019;14. https://doi.org/10.1371/journal.pone.0222394.  [101]   Santamarina AB, Nehmi Filho V, Freitas JA de, Silva BFRB da, Gusm√£o AF,  Olivieri EHR, et al.   Nutraceutical composition (yeast   Œ≤ - glucan, prebiotics,  minerals, and silymarin) predicts improvement of sleep quality and metabolic  parameters: A randomized pilot study. Clin Nutr ESPEN 2024;63:476 ‚Äì 90.  https://doi.org/10.1016/j.clnesp.2024.06.033.  [102]   Li Q, Liu Y, Zhang Z, Zhang S, Ding X, Zhang F. Washed Microbiota  Transplantation Improves the Sleep Quality in Patients with Inflammatory Bowel  Disease. Nat Sci Sleep 2024;16:1141 ‚Äì 52.  https://doi.org/10.2147/NSS.S460882.  [103]   He H, Li M, Qiu Y, Wu Z, Wu L. Washed microbiota transplantation improves  sleep quality in patients with sleep disorder by the gut - brain axis. Front  Neurosci 2024;18. https://doi.org/10.3389/fnins.2024.1415167.  [104]   Liang X, Bushman FD, FitzGerald GA. Rhythmicity of the intestinal microbiota is  regulated by gender and the host circadian clock. Proc Natl Acad Sci U S A  2015;112:10479 ‚Äì 84. https://doi.org/10.1073/pnas.1501305112.  [105]   Saidi O, Rochette E, Dambel L, St - Onge MP, Duch√© P. Chrono - nutrition and  sleep: lessons from the temporal feature of eating patterns in human studies   -   A  systematic scoping review. Sleep Med Rev 2024;76.  https://doi.org/10.1016/j.smrv.2024.101953.\n\n[106]   Magzal F, Even C, Haimov I, Agmon M, Asraf K, Shochat T, et al. Associations  between fecal short - chain fatty acids and sleep continuity in older adults with  insomnia symptoms. Sci Rep 2021;11. https://doi.org/10.1038/s41598 - 021 -  83389 - 5.  [107]   Shen YC, Sun X, Li L, Zhang HY, Huang ZL, Wang YQ. Roles of Neuropeptides in  Sleep ‚Äì Wake Regulation. Int J Mol Sci 2022;23.  https://doi.org/10.3390/ijms23094599.  [108]   Xie JF, Shao YF, Wang HL, Wang C, Cui GF, Kong XP, et al. Neuropeptide s  counteracts paradoxical sleep deprivation - induced anxiety - like behavior and  sleep disturbances. Front Cell Neurosci 2018;12.  https://doi.org/10.3389/fncel.2018.00064.  [109]   Hong J, Chen J, Kan J, Liu M, Yang D. Effects of acupuncture treatment in  reducing sleep disorder and gut microbiota alterations in PCPA - induced  insomnia mice. Evidence - Based Complementary and Alternative Medicine  2020;2020. https://doi.org/10.1155/2020/3 626120.  [110]   Zhang SL, Bai L, Goel N, Bailey A, Jang CJ, Bushman FD, et al. Human and rat  gut microbiome composition is maintained following sleep restriction.   Proc  Natl Acad Sci U S A 2017;114:E1564 ‚Äì 71.  https://doi.org/10.1073/pnas.1620673114.",
      "embedding": [
        -0.0403028279542923,
        -0.0392315536737442,
        -0.046793192625045776,
        0.11330629140138626,
        0.04117465764284134,
        0.05942467600107193,
        -0.07839608937501907,
        0.02090253308415413,
        0.04959910735487938,
        -0.00341898575425148,
        -0.10842961072921753,
        -0.02390267141163349,
        -0.0013221264816820621,
        0.0331311896443367,
        0.027463164180517197,
        0.05721049755811691,
        0.0685778558254242,
        0.09770909696817398,
        -0.023436924442648888,
        0.05447280406951904,
        0.06644084304571152,
        0.01087433472275734,
        0.08390171825885773,
        0.04164760932326317,
        -0.039691466838121414,
        0.010882498696446419,
        0.020314760506153107,
        -0.03144875168800354,
        -0.12178178876638412,
        0.0011112664360553026,
        -0.011533571407198906,
        0.04554412141442299,
        0.038526032119989395,
        0.010313482955098152,
        0.032348938286304474,
        -0.03405606374144554,
        -0.02439374104142189,
        -0.016566483303904533,
        -0.003596086986362934,
        -0.04218310862779617,
        0.03738800808787346,
        0.006893868092447519,
        0.0005465439171530306,
        -0.00584057904779911,
        -0.05891579017043114,
        -0.05796433240175247,
        0.025529203936457634,
        -0.020260436460375786,
        -0.028016865253448486,
        0.028863154351711273,
        -0.0721350610256195,
        -0.019522804766893387,
        -0.04836755245923996,
        0.11134408414363861,
        0.04262075200676918,
        0.03866690769791603,
        -0.027069099247455597,
        -0.01845388486981392,
        0.005067887715995312,
        0.03631269186735153,
        -0.06223950535058975,
        0.018152957782149315,
        0.06726837158203125,
        -0.03030938096344471,
        0.05195968970656395,
        0.08908096700906754,
        -0.12964577972888947,
        -0.014277328737080097,
        -0.06833996623754501,
        -0.09302174299955368,
        -0.07222583144903183,
        -0.07195497304201126,
        0.03320019692182541,
        0.0605761855840683,
        0.01369137316942215,
        0.055523715913295746,
        0.037648677825927734,
        0.011293294839560986,
        0.012781062163412571,
        -0.06339661777019501,
        0.04333358258008957,
        0.0513639822602272,
        0.058443427085876465,
        0.039894476532936096,
        -0.00863646063953638,
        -0.04326321929693222,
        0.05957862362265587,
        0.11248163133859634,
        0.004806642420589924,
        0.08527478575706482,
        0.08109639585018158,
        -0.03256100043654442,
        0.00041369174141436815,
        -0.011760780587792397,
        0.0445156954228878,
        -0.028897970914840698,
        -0.08833350986242294,
        0.0035376069135963917,
        0.00945988204330206,
        -0.034544941037893295,
        -0.08329115062952042,
        0.07685291022062302,
        -0.007858281955122948,
        -0.03889414295554161,
        -0.012296018190681934,
        0.07487179338932037,
        0.013602233491837978,
        -0.054137587547302246,
        0.019697031006217003,
        0.006144309416413307,
        -0.008451241068542004,
        0.04035281017422676,
        -0.013298261910676956,
        0.03514963760972023,
        0.09135840088129044,
        -0.02065587416291237,
        0.06786951422691345,
        0.09240471571683884,
        0.06561540812253952,
        0.0009638681658543646,
        0.027156705036759377,
        -0.018783211708068848,
        0.10629834979772568,
        -0.09385114163160324,
        0.04896553233265877,
        -0.00930642057210207,
        -0.08239054679870605,
        2.7863699523410647e-33,
        0.05370155721902847,
        -0.006344818975776434,
        0.03184621036052704,
        -0.019912680611014366,
        0.04315464571118355,
        -0.047519393265247345,
        -0.024502983316779137,
        -0.0010727207409217954,
        0.024040570482611656,
        0.04781335964798927,
        -0.04697407782077789,
        -0.032689038664102554,
        -0.014975390397012234,
        0.07444901764392853,
        -0.0025589268188923597,
        0.07950279116630554,
        -0.026598747819662094,
        -0.07791248708963394,
        0.05970826745033264,
        0.0014881185488775373,
        -0.0639989897608757,
        0.003957970067858696,
        0.07122812420129776,
        -0.00030305914697237313,
        -0.026677345857024193,
        -0.005063610151410103,
        0.011271581053733826,
        0.07479618489742279,
        -0.03470369428396225,
        -0.02032180316746235,
        -0.07457823306322098,
        -0.08630263805389404,
        0.11038929969072342,
        -0.026510033756494522,
        0.027289990335702896,
        0.004652440082281828,
        0.0006696786731481552,
        -0.012140732258558273,
        -0.05882583186030388,
        0.008277925662696362,
        0.03782214969396591,
        0.04161607474088669,
        -0.11405466496944427,
        -0.00836868304759264,
        0.009907866828143597,
        -0.049474749714136124,
        -0.03680763021111488,
        0.013792281970381737,
        0.048755742609500885,
        0.08367050439119339,
        0.05055778846144676,
        -0.0005264164065010846,
        -0.028129715472459793,
        -0.057738520205020905,
        -0.04060381278395653,
        -0.04746859148144722,
        0.015292190946638584,
        0.022359805181622505,
        -0.021048173308372498,
        0.03292791172862053,
        -0.05161688104271889,
        -0.05435558781027794,
        0.023665590211749077,
        0.006969748064875603,
        0.08408043533563614,
        0.030547726899385452,
        -0.08749013394117355,
        -0.04870201647281647,
        -0.0803939700126648,
        -0.0313132107257843,
        0.0063888756558299065,
        -0.05472204089164734,
        0.0951070562005043,
        0.05627907067537308,
        -0.005952166859060526,
        -0.04427536949515343,
        -0.00008908568270271644,
        0.03816834092140198,
        -0.011887773871421814,
        -0.07241211086511612,
        0.047944676131010056,
        0.018878838047385216,
        -0.04347047582268715,
        0.016642946749925613,
        -0.06641258299350739,
        0.04852867126464844,
        -0.0001771037932485342,
        0.07300399988889694,
        -0.027278201654553413,
        -0.0684041753411293,
        0.04151224344968796,
        -0.058497995138168335,
        0.05679599568247795,
        0.055858172476291656,
        -0.08746086806058884,
        -3.26753413660819e-33,
        -0.048478614538908005,
        -0.11016293615102768,
        -0.04069899022579193,
        -0.07595013827085495,
        0.02156243473291397,
        0.027587657794356346,
        -0.048481106758117676,
        -0.05033458024263382,
        0.028687262907624245,
        -0.02261197566986084,
        0.05427296832203865,
        -0.0227158572524786,
        0.06005219370126724,
        -0.03660183399915695,
        0.049222175031900406,
        -0.01584249548614025,
        -0.00661828787997365,
        0.02952568046748638,
        -0.07224755734205246,
        0.011053835973143578,
        -0.029877809807658195,
        0.049228109419345856,
        -0.022786956280469894,
        -0.04853905737400055,
        0.03764963522553444,
        0.09312143921852112,
        0.08674675226211548,
        0.1664724200963974,
        0.020270084962248802,
        0.014587325043976307,
        0.026551639661192894,
        0.08224033564329147,
        -0.14286722242832184,
        -0.08952473849058151,
        0.07083971053361893,
        0.0005260894540697336,
        -0.008729711174964905,
        -0.04509074240922928,
        -0.05880662053823471,
        -0.09607554227113724,
        0.059949811547994614,
        0.03944683447480202,
        -0.0346999429166317,
        -0.04072566330432892,
        0.005419990047812462,
        0.06085160747170448,
        0.007126565556973219,
        -0.046702791005373,
        0.006141625810414553,
        0.0278912540525198,
        0.01434287242591381,
        -0.05369345843791962,
        0.00466591352596879,
        -0.018834233283996582,
        -0.0016866055084392428,
        -0.03903908282518387,
        -0.0019157700007781386,
        0.0036776000633835793,
        0.02862507849931717,
        0.0029240453150123358,
        -0.057562876492738724,
        0.06196711212396622,
        0.018496761098504066,
        -0.07487988471984863,
        0.08334150165319443,
        -0.00012703238462563604,
        0.00007903890946181491,
        -0.045286692678928375,
        0.0161365307867527,
        0.005684887524694204,
        0.026123691350221634,
        -0.07201166450977325,
        0.032059360295534134,
        0.02352955751121044,
        -0.029880143702030182,
        0.043370410799980164,
        -0.05530259385704994,
        0.011983086355030537,
        -0.016139019280672073,
        0.055286705493927,
        -0.018873196095228195,
        -0.11616002023220062,
        -0.051735907793045044,
        -0.0025923640932887793,
        -0.053263451904058456,
        -0.058673907071352005,
        -0.00924043357372284,
        0.03921174630522728,
        0.03752835467457771,
        0.04557327181100845,
        -0.023604242131114006,
        -0.03794137388467789,
        -0.06934735924005508,
        -0.019810957834124565,
        -0.03901585936546326,
        -4.908912032419721e-8,
        0.07760979980230331,
        -0.10529973357915878,
        -0.011837544851005077,
        0.019883932545781136,
        0.002085869200527668,
        -0.053512297570705414,
        0.028497496619820595,
        -0.032818883657455444,
        -0.05221925303339958,
        0.05744506046175957,
        0.10588856041431427,
        -0.0049698506481945515,
        0.018403274938464165,
        -0.0036854760255664587,
        -0.05450825020670891,
        0.001938067376613617,
        0.014039348810911179,
        0.00888139195740223,
        0.00295323901809752,
        0.04737977683544159,
        -0.06994116306304932,
        -0.050985969603061676,
        -0.036286842077970505,
        -0.06599349528551102,
        0.11200704425573349,
        -0.0492585152387619,
        0.03916284441947937,
        0.0677337795495987,
        0.010704269632697105,
        -0.05729497969150543,
        0.03542928025126457,
        -0.015454442240297794,
        0.07905109226703644,
        0.02522316575050354,
        -0.05449929088354111,
        -0.09586647152900696,
        0.08916795253753662,
        -0.029934421181678772,
        0.026050012558698654,
        0.08177166432142258,
        0.022619077935814857,
        0.031245499849319458,
        -0.11149513721466064,
        -0.02588401921093464,
        -0.006314069498330355,
        -0.0226389579474926,
        -0.031721848994493484,
        0.04808133468031883,
        -0.02434963919222355,
        -0.027300860732793808,
        -0.044843126088380814,
        -0.0305112823843956,
        0.005892150104045868,
        0.030927639454603195,
        -0.05484630540013313,
        0.03529917076230049,
        0.012882073409855366,
        0.04089963436126709,
        0.050408970564603806,
        -0.10582511872053146,
        0.01156466081738472,
        -0.039704419672489166,
        0.0037797957193106413,
        -0.0342416949570179
      ],
      "metadata": {
        "title": "Microbes in the Moonlight: How the Gut Microbiota Influences Sleep  Author: Enso O. Torres Alegre  Affiliation: Pontifical Catholic University of Chile, Santiago, Chile  Email: onill@uc.cl  ORCID: https://orcid.org/0000 - 0002 - 6798 - 8776  Co - authors: None  Conflict of Interest Statement  The author declares no conflicts of interest related to this work.  Funding Statement  No external funding was received to support the preparation of this manuscript.  Data Availability Statement  No new datasets were generated or analyzed for this review. All data discussed in the  manuscript are derived from previously published studies cited in the References  section.  Ethics Approval Statement  Ethics approval was not required for this review article, as it does not involve new  human or animal research.  Patient Consent Statement  Not applicable. This article does not contain any studies involving human  participants.  Permission to Reproduce Material  Figures created using BioRender.com are original to the author. No previously  published material was reproduced.  Clinical Trial Registration  Not applicable. This manuscript does not report results of a clinical trial.",
        "createdAt": "2025-12-17T13:56:40.895Z"
      },
      "fileObj": {}
    },
    {
      "id": "doc_15_1765979801808",
      "fileName": "Paper_5_Quantified_Sleep__Machine_learning_techniques_for_.pdf",
      "content": "Quantified Sleep  Machine learning techniques for observational n-of-1 studies  Gianluca Truda Vrije Universiteit Amsterdam May 17, 2021  Abstract  This paper applies statistical learning techniques to an observational Quantified-Self (QS) study to build a descriptive model of sleep quality. A total of 472 days of my sleep data was collected with an Oura ring. This was combined with a variety of lifestyle, environmental, and psychological data, harvested from multiple sensors and manual logs. Such n-of-1 QS projects pose a number of specific challenges: heterogeneous data sources with many missing values; few observations and many features; dynamic feedback loops; and human biases. This paper directly addresses these challenges with an end-to-end QS pipeline for observational studies that combines techniques from statistics and machine learning to produce robust descriptive models. Sleep quality is one of the most difficult modelling targets in QS research, due to high noise and a large number of weakly-contributing factors. Sleep quality was selected so that approaches from this paper would generalise to most other n-of-1 QS projects. Techniques are presented for combining and engineering features for the different classes of data types, sample frequencies, and schema. This includes manually-tracked event logs and automatically-sampled weather and geo-spatial data. Relevant statistical analyses for outliers, normality, (auto)correlation, stationarity, and missing data are detailed, along with a proposed method for hierarchical clustering to identify correlated groups of features.   The missing data was overcome using a combination of knowledge-based and statistical techniques, including several multivariate imputation algorithms. ‚ÄúMarkov unfolding‚Äù is presented for collapsing the time series into a collection of independent observations, whilst incorporating historical information. The final model was interpreted in two key ways: by inspecting the internal   Œ≤ -parameters, and using the SHAP framework, which can explain any ‚Äúblack box‚Äù model. These two interpretation techniques were combined to produce a list of the 16 most-predictive features, demonstrating that an observational study can greatly narrow down the number of features that need to be considered when designing interventional QS studies.  Keywords : Quantified-self, machine learning, missing data, imputation, n-of-1, sleep, Oura ring, prediction, supervised learning, biohacking, observational, longitudinal, time series, interpretable, explainable.  Source code : github.com/gianlucatruda/quantified-sleep 1  arXiv:2105.06811v1 [q-bio.QM] 14 May 2021\n\nContents  1   Introduction   4  1.1   Specific challenges   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   4 1.1.1   Establishing causal relationships   . . . . . . . . . . . . . . . . . . . . . . . .   4 1.1.2   Many heterogeneous data sources . . . . . . . . . . . . . . . . . . . . . . . .   5 1.1.3   Human in the dynamic feedback loops . . . . . . . . . . . . . . . . . . . . .   6 1.1.4   Wide datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   6 1.1.5   Missing values   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   7 1.1.6   Complexities of sleep . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   7 1.2   Terminology and notation   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   8  2   Data sources   8  2.1   Sleep data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   8 2.2   Supporting data   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   9  3   Data wrangling   11  3.1   Data ingestion   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   11 3.2   Midnight unwrapping   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   11 3.3   Transformations   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   12 3.4   Aggregation techniques   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   13 3.4.1   Aggregating temporal data   . . . . . . . . . . . . . . . . . . . . . . . . . . .   13 3.4.2   Aggregating location data with geohashes   . . . . . . . . . . . . . . . . . . .   13 3.5   Dataset concatenation   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   14  4   Analysis of dataset properties   15  4.1   Time period . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   15 4.2   Outliers   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   15 4.3   Normality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   16 4.4   Correlation   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   16 4.4.1   Pairwise correlation with target . . . . . . . . . . . . . . . . . . . . . . . . .   17 4.4.2   Hierarchical correlational clustering   . . . . . . . . . . . . . . . . . . . . . .   18 4.4.3   Autocorrelation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   20 4.5   Stationarity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   21  5   Overcoming missing data   22  5.1   Theory of missing data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   22 5.2   Analysis of missing data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   22 5.3   Approaches to handle missing data . . . . . . . . . . . . . . . . . . . . . . . . . . .   24 5.4   Knowledge-based filling   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   24 5.5   Imputation strategies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   25 5.5.1   Univariate imputation   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   25 5.5.2   Multivariate imputation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   25 5.5.3   Multiple imputation   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   25 5.6   Baseline dataset with missing values   . . . . . . . . . . . . . . . . . . . . . . . . . .   26 5.7   Quantifying imputation distance   . . . . . . . . . . . . . . . . . . . . . . . . . . . .   26  6   Collapsing time with Markov unfolding   28  6.1   Markov assumption . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   28 6.2   Markov unfolding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   29 2\n\nQuantified Sleep : CONTENTS   Gianluca Truda  7   Model interpretation   30  7.1   Interpreting model parameters   . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   30 7.1.1   Regularised linear models   . . . . . . . . . . . . . . . . . . . . . . . . . . . .   30 7.1.2   Recursive feature elimination (RFE)   . . . . . . . . . . . . . . . . . . . . . .   30 7.2   Model-agnostic interpretation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   31 7.2.1   Shapley values   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   31 7.2.2   SHAP   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   32  8   Experiments   32 9   Results and discussion   34  9.1   Effectiveness of Markov unfolding . . . . . . . . . . . . . . . . . . . . . . . . . . . .   34 9.2   Comparison of imputation techniques   . . . . . . . . . . . . . . . . . . . . . . . . .   36 9.3   Predictive performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   38 9.4   Model interpretation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   39 9.4.1   Interpreting cross-validated RFE   . . . . . . . . . . . . . . . . . . . . . . . .   39 9.4.2   Interpreting cross-validated Lasso . . . . . . . . . . . . . . . . . . . . . . . .   40 9.4.3   Interpreting model with SHAP   . . . . . . . . . . . . . . . . . . . . . . . . .   41 9.4.4   Combined interpretation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   43 9.5   Feature explanation   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   45  10 Limitations and future work   46  10.1 Ground truth   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   46 10.2 Generalisability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   46 10.3 Markov unfolding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   46 10.4 Imputation   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   47 10.5 Interpretation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   47 10.6 Hierarchical clustering   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   47  11 Conclusions   48 12 Practicalities   49  12.1 Code and data availability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   49 12.2 Replicating this work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   49  A   Appendices   53  Page 3\n\nQuantified Sleep : 1   INTRODUCTION   Gianluca Truda  1   Introduction  Connected wearable devices are making personal data collection ubiquitous. These advances have made Quantified-Self (QS) projects an increasingly-interesting avenue of research into personalised healthcare and life extension [   1 ]. Whilst there has been considerable progress made on the challenges of collecting, storing, and summarising such data, there remains a gap between basic insights (e.g. sleep duration) and the deeper kinds of analysis that allow for effective interventions [   2   ] ‚Äî e.g. taking precisely 0.35 mg of melatonin 1-2 hours before bedtime to increase deep sleep by 22%. There are also major challenges like missing values, few observations, feedback loops, and biological complexity [3]. This QS study utilised 15 months of my personal data to find useful relationships between sleep quality and hundreds of lifestyle and environmental factors. Multiple heterogeneous data sources from both active and passive tracking systems were combined and preprocessed into a day-level timeseries (¬ß2). The study combines various techniques for feature engineering (¬ß3), dataset analysis (¬ß4), missing value imputation (¬ß5), temporal representation (¬ß6), and model interpretation (¬ß7). These methods were evaluated for various learning algorithms through a series of experiments (¬ß8). The context of sleep quality is a good case study in observational n-of-1 research, as its challenges generalise to other areas of QS research. Fig. 1 gives a graphical overview of the components of this study. Data source 1  Data source 2  Data source n  Preprocessing and Aggregation   Unified view  Analysis  Knowledge- based filling  Missing data imputation  . . .  Grid search over datasets and models  Best model and dataset combination  Beta-parameter interpretation  SHAP interpretation  Markov unfolding  Final interpretation  Dataset variants  Figure 1: An overview of the data pipeline for this study, from disparate data sources to a final interpretation of the effects on sleep quality.  1.1   Specific challenges  N-of-1 studies pose a number of unique challenges, but so do QS projects and observational studies. At the intersection of all of these (Fig. 2) is the set of attributes that make this study uniquely challenging. We begin by exploring these challenges.  1.1.1   Establishing causal relationships  The gold standard for experiments involving human subjects is the double-blind, randomised, controlled trial (RCT). Such a study is   interventional , typically having a single variable that is manipulated, such as whether a subject receives a specific drug therapy. All other variables are controlled by strict laboratory conditions, selective recruiting of participants, and rigorous protocols. All of these measures help minimise various statistical and human biases that might affect the outcome. This allows researchers to establish causal links between variables. Page 4\n\nQuantified Sleep : 1   INTRODUCTION   Gianluca Truda Observational   N-of-1 Day-level Quantified Self  This study  Figure 2: Illustrative diagram of how this study sits at the intersection of observational research, n-of-1 experiments, and day-level Quantified-Self (QS) research. In total contrast, we have the n-of-1 QS study.   This involves a single individual who designs, administers, and is the subject of the experiments [   1 ]. This makes the study very difficult to blind. Confounding factors, ordering effects, and human biases are thus exacerbated when studying single individuals. Moreover, it is often unclear at the outset what variables are relevant to study in this way. This paper addresses these challenges by using a wide-spanning   observational   study to identify interesting factors that can then be examined further in controlled studies. Techniques for effectively executing these initial observational studies are the focus of this paper. Whilst there are many challenges in observational n-of-1 research, it is also important to acknowledge the many advantages. Firstly, n-of-1 studies offer something that RCTs cannot. Namely, direct applicability to the subject in question. The cohort of an RCT is very carefully selected. The results of these studies may, therefore, not fully generalise to the genetic, environmental, and psychological attributes of other groups. For complex systems, n-of-1 studies allow data to be collected about the specific individual in question [ 4   ]. Secondly, by beginning with a wide-ranging observational study, n-of-1 research allows the subject to fit the study around their daily life. This further increases the relevance of results, because they fit within the specific context that we are seeking to optimise. The observational approach can also capture unexpected interactions between variables, which helps identify the most relevant factors for future controlled studies.  1.1.2   Many heterogeneous data sources  The QS domain often requires combining multiple bespoke systems to collect both active and passive data [   2 ]. For instance, I log my caffeine intake actively using the   Nomie   app on my phone, but my screen time is monitored passively by the   RescueTime   desktop software. For simple analytics, it is sufficient to work with these sources in isolation. For more valuable multivariate analysis, however, it is essential to unify the data sources and produce a combined dataset. This is challenging for two reasons. Firstly, each source has its own schema for storing, processing, and exporting data. These schema are usually specific to each system. Many tools often limit the level at which data can be exported or analysed. Secondly, the nature and structure of the data differs from source to source. For example, I keep track of caffeine intake by actively logging the date-time-stamp whenever I drink coffee. This follows an event-based scheme, where each date-time-stamp is a record in a relational database. Conversely, my sleep quality is passively measured and logged by my   Oura  ring and stored (primarily) as a daily summary. To analyse the interactions between my caffeine Page 5\n\nQuantified Sleep : 1   INTRODUCTION   Gianluca Truda intake and my sleep, I would need to reconcile these two schema by aggregating the caffeine logs to daily summaries and then aligning the dates with the sleep summaries. Instead of events, I now have daily features like average number of coffees, time of last coffee, etc. As more sources are included in the dataset, the complexity of the processing and alignment increases. This study addresses these challenge by parsing each data source into a dataframe [   5 ], then aligning these into a unified view.   In order to do so, a number of feature aggregation and engineering techniques were developed for this context (¬ß3).  1.1.3   Human in the dynamic feedback loops  The very aspect of n-of-1 QS that makes it interesting also imbues it with challenges. Having a human ‚Äúin the loop‚Äù of the experiment introduces a number of biases and errors [   6 ] that affect the results [   1   ]. It is typically too impractical to use any blinding methods in QS because we mostly study multiple variables at once and cannot control for all the other factors. Self-blinding is quite challenging even for a single independent variable [ 7 ]. For problems like sleep modelling, blinding the subject is outright impossible, as almost all of the interesting variables include at least some degree of subjectivity.   For instance, it may be that tracking my sleep quality makes me more anxious about my sleep, which in turn keeps me up longer and degrades my sleep efficiency. Or, I may be less effective at estimating my mood and energy levels when I am sleep deprived. Or, the act of logging caffeinated drinks or melatonin tablets may have a stronger placebo effect than the actual substance. This means that even an accurate and explainable model will only be able to describe the system it was based on ‚Äî biases, feedback loops, and placebos included. It also means that we need to take great care when interpreting our engineered features and the results we produce. Moreover, modelling   dynamic   systems with feedback loops requires time series techniques. Unfor- tunately, these place constraints on the choice of models and the interpretations we can perform. In this study, a technique called ‚ÄúMarkov unfolding‚Äù (¬ß6) is used to collapse the time series into independent observations, allowing for historical data to be captured by non-temporal models.  1.1.4   Wide datasets  A fundamental challenge for n-of-1 QS projects is having insufficient data. Whilst many sensors collect large quantities of data at high sample rates [   1 ,   3 ], much of this is aggregated down to summaries. This is because we are often interested in longer time periods, like hours or days [ 2 ]. In this study, for instance, the focus is sleep quality. Because this is quantified daily, all data sources must be aggregated to match this day-long window size of observations. A 200 Hz accelerometer ultimately becomes dozens of engineered features summarising daily motion and activity. This has the effect of collapsing low-dimensional, high-frequency data into high-dimensional, low-frequency data. In other words, our dataset becomes wider than it is long. Na√Øve modelling of such a dataset results in overparameterised models that are high in variance [8] and do not generalise [9, 10]. This challenge is addressed through the use of multiple feature selection techniques (¬ß7.1.2), which reduce dimensionality [   3 ]. This is complemented by analysing the distributions of cross-validated results to detect the ones that are robust across subsets of the data (¬ß8). Page 6\n\nQuantified Sleep : 1   INTRODUCTION   Gianluca Truda  1.1.5   Missing values  Missing data is a major problem for modelling, because most techniques assume complete data [ 11 ]. The missing values either have to be filled in (imputed or interpolated) or discarded (dropped) along with all other data for the observation.   Imputation maintains the size and shape of the dataset, but reduces the quality by introducing noise. Dropping introduces no additional noise, but reduces the number of observations ‚Äî making the dataset relatively shorter and wider ‚Äî which increases model variance. N-of-1 QS studies exacerbate the problem of missing data dramatically.   Because the study is about a single individual, there are already fewer observations at the outset. Moreover, there is a great deal of noise and complexity in the observations, as they are specific to the individual being studied [ 7 ]. Additionally, QS projects involve data from multiple heterogeneous sources, and so often require some experimentation with different pieces of software and hardware [ 2 ]. This results in a dataset that has a great deal of missing values in one of a few characteristic types (¬ß5.1). Additionally, sensors and systems can fail, resulting in missing values scattered throughout the data. Active-tracking sources are prone to poor adherence. Fortunately, the unique nature of n-of-1 QS studies also allows us to utilise a collection of tricks and tools that can overcome some of these missing data issues. This paper organises missing values into distinct types (¬ß5.1), inferring some from domain knowledge (¬ß5.4), whilst others are imputed using various sophisticated techniques (¬ß5.5).  1.1.6   Complexities of sleep  This study‚Äôs target variable (sleep quality) posed some additional challenges. Not only is sleep a complex and little-understood process [   12 ], but it is one for which the subject is necessarily not fully conscious, making measurement far more difficult. Many lifestyle factors have been shown to affect sleep quality and quantity [   13 ,   14 ,   15 ].   Poor sleep also impairs a subject‚Äôs ability to accurately assess their sleep quality and quantity [   16 ,   12 ]. Consumer-grade hardware for sleep tracking is increasingly available due to wearable technology, but must infer sleep stages from other physiological markers like heart rate, movement, heart rate variability (HRV), and body temperature [   17 ]. Unlike exercise tracking, the ground truth for sleep tracking is uncertain. This adds additional noise to the target variable. Sleep exists within a complex feedback loop with hundreds of other factors (including itself) [ 15 ,   12 ], so a simple univariate analysis is clearly insufficient. Instead, this study is framed as a modelling problem in which we wish to construct an explanatory model of sleep. To build the best possible model, we convert the task to an optimisation problem under the framework of supervised learning: models with a low prediction error on unseen (out-of-sample) data are more likely to have captured the relevant variable interactions [ 10 ]. However, our end goal is not to make a good   predictive  model. That is just an intermediate step to finding a good   descriptive   model. By interpreting the model (¬ß7), it is possible to find which variables are most influential in determining sleep quality, highlighting potential avenues for further studies. For instance, the model may reveal that melatonin consumption and timing of intense exercise are, together, two of the biggest predictors of sleep quality. This information could then be used to design interventional n-of-1 studies that specifically determine the effect size or optimal ‚Äúdose‚Äù of each variable in isolation. Page 7\n\nQuantified Sleep : 2   DATA SOURCES   Gianluca Truda  1.2   Terminology and notation  Because machine learning sits at the intersection of a number of fields ‚Äî statistics, computer science, and software engineering ‚Äî terminology is varied and overlapping. The goal of this paper is to model a dependent variable (sleep quality) in terms of the independent variables that influence it, such as caffeine consumption, exercise, weather, and previous sleep quality. In this paper, the term   feature   will be used to refer to a preprocessed independent variable, whilst  target   (feature) will be used for the dependent variable (sleep quality).   For instance, caffeine consumption is an   input variable   but, after preprocessing and aggregating, the hour at which caffeine was consumed is a   feature 1 . Input variables are often non-numeric, but all features are numeric. Individual points in time (days) will be called   observations 2 . When we dig beneath this modelling view, datasets are organised as dataframes ‚Äî   m   √ó   n   matrices with labels for each column and row. Row   i   corresponds to an   observation   on a particular day. Column   j   correspond to a timeseries for some   feature . So   columns   are how we practically store our   features   whilst   rows   are how we practically store our   observations . This means that value   x i,j   is the single value in row   i  and column   j   of our data matrix   X   ‚àà   R m √ó n . So on day   i , the   j th feature had a value of   x i,j   .  2   Data sources  An overview of the data sources is found in Table 1. A detailed explanation follows.  2.1   Sleep data  The target variable for this study was sleep quality.   This is a function of several sleep-related variables that were captured using a second-generation Oura ring. The Oura ring is a wearable device with sensors that measure movement, heartbeats, respiration, and temperature changes. Being located on the finger instead of the wrist or chest, it can measure pulse and temperature with greater sensitivity and accuracy, resulting in measurements suitable for sleep analysis [17]. Studies have found that the 250 Hz sensors of the Oura ring are extremely accurate for resting heart rate and heart rate variability (HRV) measurement when compared to medical-grade ECG devices [   18 ].   This is likely due to the use of dual-source infrared sensors instead of the more common single-source green light sensors when performing photoplethysmography [ 17 ]. Respiratory rate was found to be accurate to within 1 breath per minute of electrocardiogram-derived measures by an external study [ 19   ]. Internal studies [ 17 ] found the temperature sensor to be highly correlated with leading consumer hardware, but uncorrelated to environmental temperature. Combining the sensor data, the Oura ring has been found by a number of studies [   20   ,   21 ,   22 ] to produce reasonable estimates of sleep behaviour when compared to medical-grade polysomnography equipment. This is remarkable given the significantly lower cost and invasiveness of the Oura ring. Whilst all of the studies report that sleep detection has high sensitivity (and reasonable specificity), the classification of different sleep stages diverges considerably from the polysomnography reference. This, combined with the underlying opaqueness of sleep, made the target variable of this study noisy  1 Because this paper may be of interest to readers from varying backgrounds, it should be noted that the term  feature   is synonymous with terms like   predictor ,   regressor ,   covariate , and   risk factor   ; whilst the   target   variable might be known to others as a   response   variable,   regressand ,   outcome , or   label .  2 In machine learning,   observations   are sometimes called   examples   or   instances , but that is avoided in this paper to prevent confusion.  Page 8\n\nQuantified Sleep : 2   DATA SOURCES   Gianluca Truda and uncertain. Despite this, the low costs and simplicity of the Oura ring make it an invaluable tool for QS research in the domain of sleep. The Oura API gives access to daily summaries generated from the raw sensor data. For this study, the   oura_score   variable was of most interest, as it is intended to represent the overall sleep quality during a sleep period. It is a weighted average of sleep duration (0.35), REM duration (0.1), deep sleep duration (0.1), sleep efficiency (0.1), latency when falling asleep (0.1), alignment with ideal sleep window (0.1), and 3 kinds of sleep disturbances: waking up (0.05), getting up (0.05), and restless motion (0.05).  2.2   Supporting data  ‚Ä¢   My electronic activities and screen time were tracked with the   RescueTime   application and exported as daily summaries of how much time was spent in each class of activity (e.g. 3h42m on software development).  ‚Ä¢   My GPS coordinates, local weather conditions, and phonecall metadata were logged using the   AWARE   application for iOS and queried from the database using SQL. Local weather conditions and location information were logged automatically at 15-minute intervals (when possible). Phonecall metadata was logged whenever a call was attempted, received, or made.  ‚Ä¢   Full timestamped logs of all caffeine and alcohol consumption were collected with the   Nomie  app for iOS. Logs were made within 5 minutes of beginning to consume the beverage. Caffeine was measured in approximate units of 100mg and alcohol was measured in approximations of standard international alcohol units.  ‚Ä¢   Logs of activity levels and exercise measured on my phone were exported from Apple‚Äôs  HealthKit   using the   QS Export   app in the form of non-resting kilocalories burned at hourly intervals and activities (running, walking, etc.) logged as they began and ended.  ‚Ä¢   Heart rate was recorded approximately once per minute 3   on a   Mi Band 4   and synchronised with   AWARE   via   HealthKit .  ‚Ä¢   My daily habits ‚Äì meditation, practising guitar, reading, etc. ‚Äì were captured (as Boolean values) daily before bedtime using the   Way of Life   iOS app.  ‚Ä¢   My daily eating window (start and end times) was logged in the   Zero   app as daily summaries.  ‚Ä¢   My mood and energy levels were logged at multiple (irregular) times a day in the   Sitrus   app.  ‚Ä¢   A collection of spreadsheets were used to log the timestamps and quantities of sleep-affecting substances like melatonin and CBD oil.  3 Higher frequencies were used during workout tracking and lower frequencies were used when the device was not worn.  Page 9\n\nQuantified Sleep : 2   DATA SOURCES   Gianluca Truda  Kind   Prefix   Hardware   Software   Format   Frequency   Active/Passive   Hoogendoorn- Funk [3] categories  Sleep   oura   Oura ring, 2nd gen.   Oura API   JSON   Daily summaries   Passive   Physical Readiness   oura   Oura ring, 2nd gen.   Oura API   JSON   Daily summaries   Passive   Physical Computer activity   rescue   Personal computer   RescueTime   CSV   Daily summaries   Passive   Mental & Cognitive GPS coordinates   aw_loc   iPhone 8   AWARE v2   SQL   ~15 mins   Passive   Environmental Barometric pressure   aw_bar   iPhone 8   AWARE v2   SQL   ~15 mins   Passive   Environmental Local weather condi- tions aw_weather   iPhone 8   AWARE v2   SQL   ~15 mins   Passive   Environmental Phonecall metadata   aw_call   iPhone 8   AWARE v2   SQL   ~15 mins   Passive   Social, Environmental Activity / Exercise   hk   iPhone 8, Mi Band 3, Oura ring Apple HealthKit   CSV   Hourly summaries   Passive   Physical Heart rate   aw_hr   Mi Band 3   AWARE v2   SQL   ~1 min   Passive   Physical Caffeine and Alcohol   nomie   iPhone 8   Nomie app   CSV   Timestamped logs   Active   Diet Habits   wol   iPhone 8   Way of Life app   CSV   Daily   Active   Mental   &   Cognitive, Psychological,   Situa- tional Eating / Fasting peri- ods zero   iPhone 8   Zero app   CSV   Daily summaries   Active   Physical, Diet Mood and Energy   mood   iPhone 8   Sitrus app   CSV   Timestamped logs   Active   Psychological Melatonin use   melatonin   N/A   Spreadsheet   CSV   Timestamped logs   Active   Diet CBD use   cbd   N/A   Spreadsheet   CSV   Timestamped logs   Active   Diet Daily metrics   daily   ?   N/A   Spreadsheet   CSV   Daily logs   Active   Environmental, Situa- tional  Table 1: The data sources used to build the dataset for this study. The prefix column indicates the string that the feature names in the dataset inherit from their source. These prefixes help associate features with their sources and allow easier grouping of features.   ?   Other prefixes: location, city, country, travelling. Page 10\n\nQuantified Sleep : 3   DATA WRANGLING   Gianluca Truda  3   Data wrangling  The sampling intervals of the data sources ranged from below 1 minute to a full   24   hours. Much of the data was necessarily at irregular intervals because it was an event log (e.g. having coffee or taking melatonin). The data sources were all structured, but were a mix of temporal and numeric types that required different feature engineering and aggregation techniques. Because the target (sleep quality) was calculated at a daily interval, all the data needed to be up- or down-sampled accordingly. This section details how the heterogeneous data sources were ingested (¬ß3.1), how custom feature engineering was used to align (¬ß3.2) and aggregate (¬ß3.3) the different classes of time series, and how the sources were concatenated into a unified dataset (¬ß3.5).  3.1   Data ingestion  Each data source had its own bespoke data ingester that ultimately fed into a single unified view from which features could be engineered to produce a dataset (Fig. 1). Each ingester is a function responsible for reading a data source in its source format, transforming it into a dataframe, renaming the columns with appropriate conventions and a descriptive prefix, then returning the dataframe. This modularity allowed for iterative development during this study. It also allows the downstream code to generalise to future studies on different data sources.  3.2   Midnight unwrapping  Because the data typically showed one sleep pattern per night, the window size for observations in this study was necessarily one sleep-wake cycle (i.e. one day). Because sleep runs over midnight, it was essential to select another time as the point around which each ‚Äúday‚Äù was defined. To determine this, temporal histograms of important activities like sleep, food consumption, and exercise were plotted (e.g. Fig. 3). From this, a time of 05:00 was selected as the offset point. A window size of 24 hours was then applied from that reference. For instance, alcohol and caffeine consumed between midnight and 05:00 count towards aggregates for the   previous   day. This simple technique preserves causal relationships between input features and the target, as the order of events is preserved.  Figure 3: Temporal histograms for for alcohol and caffeine consumption, illustrating how a reference time of 05:00 was selected for midnight unwrapping. Page 11\n\nQuantified Sleep : 3   DATA WRANGLING   Gianluca Truda The summary date (based on 05:00 offset) was generated for each timestamp in each data source. For instance, if alcohol was logged at   2020-04-07 01:03:41 , the summary date was set to   2020-04-06 . All records were then grouped on that summary date attribute, with specific time-domain aggrega- tions applied over the attributes to produce numerical features. This was informed by intuition and domain knowledge and thus the aggregations varied across data sources.  3.3   Transformations  The unified dataset required all sources to be sparse daily summaries. This required aggregations and interpolations. The data sources fell into three groups: 1.   Daily summaries :   those sources that were already daily summaries (e.g.   Oura, Zero, RescueTime). These required no further adjustment, provided their datestamp format was correct. 2.   Event logs : those that were records of the date and time that events occurred (e.g. caffeine, alcohol, melatonin, calls). There sources needed to be   pivoted   into wide format. The dates were then interpolated to daily summaries. Events occurring on the same day were aggregated. 3.   Intra-day samples : higher-frequency records (e.g. weather, location, heart rate). These sources needed aggregation to produce daily summaries. Fig. 4 illustrates how such transformations would take place using highly-simplified scenarios. 2020-05-02  2020-05-03  2020-05-04  138  102  192  78  113  109  73  81  86 Date   Deep sleep REM sleep   Score  2020-05-02  2020-05-02  2020-05-04  00:01  00:02  23:59  63  65  81 Date   Time   Heart rate  2020-05-04   23:58   92  ...  2020-05-04   09:01   Coffee  2020-05-02  2020-05-02  08:12  09:45  Coffee  Coffee Date   Time   Event  2020-05-03   22:17   Alcohol  2020-05-02  2020-05-03  2020-05-04  Date  138  102  192  78  113  109  73  81  86 Deep sleep REM sleep   Score  2  0  1  0  1  0  Coffee   Alcohol  74  78  92  32  29  43  HR avg.   HR std.  2020-05-02  2020-05-03  2020-05-04  2  0  1  0  1  0 Date   Coffee   Alcohol  2020-05-02  2020-05-03  2020-05-04  74  78  92  32  29  43 Date   HR avg.   HR std.  Daily summaries Event logs Intra-day samples  Pivoting & aggregating Aggregating  Figure 4: Toy examples of how the three kinds of data source in this study were transformed prior to concatenation into the unified dataset. Page 12\n\nQuantified Sleep : 3   DATA WRANGLING   Gianluca Truda  3.4   Aggregation techniques  When collapsing event logs and intra-day samples into daily summaries, aggregation functions summarise the distribution. The choice of aggregation functions needs to consider the original data source and the downstream learning pipeline. For continuous variables (e.g.   heart rate), standard summary statistics ‚Äî minimum, mean, maximum, standard deviation ‚Äî capture the shape of the data well. This is particularly true when the variable is close to a normal distribution, which many QS sources are. For categorical variables, one-hot encoding and summation were used to aggregate data. For event logs (e.g. coffee and alcohol consumption), counts are the most intuitive aggregation. Because the times that the events took place is also important, specialised temporal aggregation techniques were needed.  3.4.1   Aggregating temporal data  For event logs, the   hour   of occurrence was encoded as a numeric feature along with the quantity, allowing aggregation with   min ,   max , and   range   functions. Hourly resolution is a reasonable level given the inherent noise in the data. Caffeine data is shown by way of an example:  Summary date   Value sum   Hour min   Hour max   Hour range  2020-06-12   2.0   12   14   2 2020-06-13   1.0   13   13   0 2020-06-15   2.0   11   13   2 Because midnight unwrapping had been applied, the   net   hour of occurrence was used. So having a last beer at 1AM on Saturday would result in the   net_hour_max   feature on   Friday   having a value of 25.  3.4.2   Aggregating location data with geohashes  High-frequency GPS data has huge potential for building information-rich features, but poses two major challenges. Firstly, not all GPS measurements have the same level of accuracy, due to signal availability and power-saving measures. Secondly, comparing or aggregating coordinates is difficult and ill-defined. One solution is to manually define regions as places of interest and calculate which GPS coordinate pairs fall within those regions. This proves to be very computationally expensive and time consuming. Instead, this study used the   geohash   system [23] (Fig. 5). Geohashing recursively divides the earth into 32-cell grids that are each codified with an alphanumeric sequence. Because geohashes are based on the mathematics of z-order curves, they offer some useful properties like arbitrary precision and fast encoding. For example, the GPS coordinates of the Vrije Universiteit can be mapped to a level-6 geohash:   (52 . 3361 ,   4 . 8633)   ‚Üí   u173wx , which corresponds to a rectangle with an area of   0 . 7   km. But by simply truncating the last 3 characters, we can ‚Äúzoom out‚Äù to   u17 , which covers the northern half of the Netherlands. Page 13\n\nQuantified Sleep : 3   DATA WRANGLING   Gianluca Truda  Figure 5:   Illustration of the geohash system and example of the level-6 geohash for the Vrije Universiteit [24]. The variable precision of geohashes helps overcome the GPS accuracy problem. Reducing pairs of GPS co-ordinates to single alphanumeric strings with well-defined neighbourhood properties solves the aggregation problems of GPS data. The geohash   encode   function was mapped over all 61 000 GPS values in the dataset to generate the level-12 geohashes in seconds. By simply truncating digits from the ends of these level-12 geohashes, features were generated for levels 5 through 9. These levels correspond to blocks ranging from  25 m 2   to   25 km 2 , capturing location information at a variety of resolutions. With this in place, daily aggregation was performed in two ways: (1) by counting the number of unique geohashes from each level (5-9) for that day, (2) by finding the 10 most common level-5 geohashes over the entire dataset and counting the proportion of logs that matched each in that day. This produced 15 features that summarised the locations and movements of the day in an efficient format.  3.5   Dataset concatenation  All the preprocessed data sources were sequentially concatenated on the summary date column using a   left join   operation. The sleep dataframe was used as the starting object. This served two purposes. Firstly, it prevented the need for interpolating dates, as the sleep data was complete. Secondly, it automatically resulted in all rows being trimmed to match the start and end of the target feature (contained in the sleep data). This produced a unified dataset with 789 observations (rows) and 309 columns, of which 271 were numeric features. Because the data from the Oura ring contained numerous linear components of the target feature, there was a risk of data leaks.   For instance,   oura_yesterday_total   alone contributes   35%   of the   oura_score   target. But these variables were relevant to predicting future nights of sleep. To remedy this, all variables with the   oura_   prefix were copied, shifted one day later, and re-prefixed with   sleep_yesterday_ . Before fitting the model, the features with the   oura_   prefix were always dropped. This way, each observation had no features leaking information about the target, yet still included useful information about prior sleep behaviour. Page 14\n\nQuantified Sleep : 4   ANALYSIS OF DATASET PROPERTIES   Gianluca Truda  4   Analysis of dataset properties  4.1   Time period  The subset of the data used in this study ran for 472 days from mid-October 2019 to mid-January 2021. Some   65%   of this time was under various restrictions due to the Covid-19 pandemic. This meant much less variety in location and much more consistent patterns of behaviour, due to the stay-at-home orders. This formed a natural experiment by keeping many factors consistent from March 2020 to December 2020. On one hand, this produced a more ‚Äúcontrolled‚Äù experiment, with fewer free variables. On the other hand, the unique circumstances mean that the results may not generalise as well. Moreover, a lack of variability in features makes them less useful to a predictive model [   10   ]. This can result in highly-relevant variables being absent in the final model because they remained consistent during the course of the lockdown. To mitigate this, data from 5 months of pre-pandemic conditions was retained.  4.2   Outliers  It is essential to differentiate   variational   outliers from   measurement-error   outliers [   3   ]. The former are a legitimate result of natural variation in a system and must be retained in order to build a fully-descriptive model. The latter are a result of failed sensor readings, corrupted data, or erroneous data entry. These measurement errors add noise to the dataset that makes it more challenging to fit a model to the underlying signal. They should therefore be removed. Unfortunately, it is often difficult to differentiate the two types of outlier. To err on the side of caution, minimal outlier removal was used in this study. The focus of the study was sleep quality, so the most relevant sleep features were assessed to detect outliers. By inspecting the distributions and linear relationships in the sleep data 4 , the presence of some outliers was apparent. Both the sleep efficiency and overall sleep score were negatively skewed ‚Äî with potential outliers in the left tail. Chauvenet‚Äôs criterion is a technique to find observations that have a probability of occurring lower than   1  cN   , where   N   is the number of observations and   c   is a strictness factor [ 3 ].   Chauvenet‚Äôs criterion ( c   = 2 ) identified a total of 6 outliers across the 4 key sleep features: score, total, efficiency, duration. All but one of these outliers pre-dated the intended timespan of the study, and that outlier was removed. For the non-target features, distribution plots and 5-number summaries were inspected to detect erroneous measurements. For instance, a heart rate of 400 would have been clearly erroneous. No values were deemed obvious errors 5 .  4 See Fig. 24 in the Appendices.  5 It is, of course, possible that some data-entry errors or measurement errors made it past this conservative filter, adding further noise to the data.  Page 15\n\nQuantified Sleep : 4   ANALYSIS OF DATASET PROPERTIES   Gianluca Truda  4.3   Normality  Many learning algorithms assume that the target feature is normally distributed [ 25   ,   26 ]. If it significantly differs from a normal distribution, we can either (1) normalise the target feature, or (2) apply a transformation to the model predictions to map them onto the same distribution as the target feature. Neither of these are ideal. Normalising the target feature makes our model predictions harder to interpret [   27 ]. Transforming the predictions can introduce a number of errors and points of confusion.  Figure 6: Histogram showing the distribution of the target feature for the time period of the study:  oura_score . The median is indicated with a green vertical line. The mean is indicated with a dashed red line. We can see that they are almost identical. Dotted black lines indicate one standard deviation ( œÉ ) in either direction of the mean. The target feature ( oura_score ) followed the general shape of a normal distribution, but with a skewness of   ‚àí 0 . 325   and an excess kurtosis of   0 . 154 , indicating thin tails and a negative skew (Fig. 6). We know that the target is bounded by   [0 ,   100]   and sleep behaviour generally regresses to the mean [   15 ], so there is little chance that the population distribution is extreme [   28 ], even if it is slightly skewed. These heuristics, along with the desire to keep the model interpretable, informed the decision not to transform the target feature.  4.4   Correlation  It is important to understand how features linearly relate with one another (correlation) and with themselves at different points in time (autocorrelation). If features that share a source are highly correlated, we may want to combine them or discard one of them, as this maintains most of the same information (and interpretability), whilst reducing the number of features our model needs to process [   25 ]. More importantly, features that are correlated with the target are strong candidate features for our final model. Page 16\n\nQuantified Sleep : 4   ANALYSIS OF DATASET PROPERTIES   Gianluca Truda  4.4.1   Pairwise correlation with target  At first, we consider only correlations of each feature to the target (Fig. 7). ‚àí\u0004\u0003\b   ‚àí\u0004\u0003\u0007   ‚àí\u0004\u0003\u0006   \u0004\u0003\u0004   \u0004\u0003\u0006   \u0004\u0003\u0007   \u0004\u0003\b   \u0004\u0003   \u0005\u0003\u0004  \u0019\u001e\u001b   \u0010\u000f\u001d\u0014\u0017\u0010 \u001c\u001d   \u001b\u001d \u000f\u0010\u0016\u001d  \u0019\u001e\u001b   \u0017\u0014\u000f\u001a\u0019\u0014\u0018\u001d   \u001d \u000f\u0010\u0016\u001d  \u0019\u001e\u001b   \u0013\u001b \u0016\u0019   \u0010\u001c\u001d  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u0017\u0014\u000f\u001a\u0019\u0014\u0018\u001d \u001d\u0014\u0017\u0010  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u000f\u001e\u001b   \u001d\u0014\u0019\u0018  \u0019\u001e\u001b   \u001a\u0010\u001b\u0014\u0019\u000f \u0014\u000f  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u000f\u0010\u0010\u001a  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001b\u0017\u001c\u001c\u000f  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   !   \u0015\u0010  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001c\u000e\u0019\u001b\u0010 \u001d\u0019\u001d   \u0016  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001d\u0019\u001d   \u0016  \u0019\u001e\u001b   \u0013\u001b   \u001f\u0010\u001b   \u0012\u0010  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   !   \u0010\u000f\u001d\u0014\u0017\u0010 \u0010\u0018\u000f \u000f\u0010\u0016\u001d  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u0016\u0014\u0012\u0013\u001d  \u0019\u001e\u001b   \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010   \u000e\u001d\u0014\u001f\u0014\u001d!   \u0016  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010 \u001a\u001b\u0010\u001f\u0014\u0019\u001e\u001c \u0018\u0014\u0012\u0013  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001c\u000e\u0019\u001b\u0010 \u000f\u0010\u0010\u001a  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001c\u000e\u0019\u001b\u0010  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u0019\u0018\u001c\u0010\u001d \u0016   \u001d\u0010\u0018\u000e!  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010   \u000e\u001d\u0014\u001f\u0014\u001d!   \u0016  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010 \u001b\u0010\u001c\u001d\u0014\u0018\u0012 \u0013\u001b  \u0019\u001e\u001b   \u0019\u0018\u001c\u0010\u001d \u0016   \u001d\u0010\u0018\u000e!  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010 \u001a\u001b\u0010\u001f\u0014\u0019\u001e\u001c \u000f   !  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001c\u000e\u0019\u001b\u0010 \u001b\u0010\u0017  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001b\u0010\u0017  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010 \u001b\u0010\u000e\u0019\u001f\u0010\u001b! \u0014\u0018\u000f\u0010  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u0017\u0014\u000f\u001a\u0019\u0014\u0018\u001d   \u001d \u000f\u0010\u0016\u001d  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010 \u001d\u0010\u0017\u001a\u0010\u001b   \u001d\u001e\u001b\u0010  \u0019\u001e\u001b   \u001d\u0010\u0017\u001a\u0010\u001b   \u001d\u001e\u001b\u0010 \u001d\u001b\u0010\u0018\u000f \u000f\u0010\u001f\u0014   \u001d\u0014  \u0019\u001e\u001b   \u001d\u0010\u0017\u001a\u0010\u001b   \u001d\u001e\u001b\u0010 \u000f\u0010\u001f\u0014   \u001d\u0014\u0019\u0018  \u0019\u001e\u001b   \u001d\u0010\u0017\u001a\u0010\u001b   \u001d\u001e\u001b\u0010 \u000f\u0010\u0016\u001d  \u0019\u001e\u001b   \u001b\u0010   \u001d\u0013   \u001f\u0010\u001b   \u0012\u0010  \u0019\u001e\u001b   \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010 \u001a\u001b\u0010\u001f\u0014\u0019\u001e\u001c \u000f   !  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001c\u000e\u0019\u001b\u0010 \u0016   \u001d\u0010\u0018\u000e!  \u0019\u001e\u001b   \u001b\u0017\u001c\u001c\u000f  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001c\u000e\u0019\u001b\u0010   \u0016\u0014\u0012\u0018\u0017\u0010\u0018\u001d  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001d\u0010\u0017\u001a\u0010\u001b   \u001d\u001e\u001b\u0010 \u001d\u001b\u0010\u0018\u000f \u000f\u0010\u001f\u0014   \u001d\u0014  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001b\u0010\u001c\u001d\u0016\u0010\u001c\u001c  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   !   \u0010\u000f\u001d\u0014\u0017\u0010 \u001c\u001d   \u001b\u001d \u000f\u0010\u0016\u001d  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u0013\u001b \u0016\u0019   \u0010\u001c\u001d  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u0013\u001b   \u001f\u0010\u001b   \u0012\u0010  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001d\u0010\u0017\u001a\u0010\u001b   \u001d\u001e\u001b\u0010 \u000f\u0010\u001f\u0014   \u001d\u0014\u0019\u0018  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001d\u0010\u0017\u001a\u0010\u001b   \u001d\u001e\u001b\u0010 \u000f\u0010\u0016\u001d  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001a\u0010\u001b\u0014\u0019\u000f \u0014\u000f  \u0019\u001e\u001b   \u001c\u000e\u0019\u001b\u0010 \u000f\u0014\u001c\u001d\u001e\u001b   \u0018\u000e\u0010\u001c  \u0019\u001e\u001b   \u0010\u000f\u001d\u0014\u0017\u0010 \u0010\u0018\u000f \u000f\u0010\u0016\u001d  \u0019\u001e\u001b   \u001b\u0010\u001c\u001d\u0016\u0010\u001c\u001c  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001c\u000e\u0019\u001b\u0010 \u0010\u0011\u0011\u0014\u000e\u0014\u0010\u0018\u000e!  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u0010\u0011\u0011\u0014\u000e\u0014\u0010\u0018\u000e!  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010 \u001c\u0016\u0010\u0010\u001a   \u0016   \u0018\u000e\u0010  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   !   \u001b\u0010   \u001d\u0013   \u001f\u0010\u001b   \u0012\u0010  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001c\u000e\u0019\u001b\u0010 \u000f\u0014\u001c\u001d\u001e\u001b   \u0018\u000e\u0010\u001c  \u0019\u001e\u001b   \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010 \u001d\u0010\u0017\u001a\u0010\u001b   \u001d\u001e\u001b\u0010  \u0019\u001e\u001b   \u0015\u0010  \u0019\u001e\u001b   \u001c\u000e\u0019\u001b\u0010 \u0016   \u001d\u0010\u0018\u000e!  \u0019\u001e\u001b   \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010 \u001b\u0010\u001c\u001d\u0014\u0018\u0012 \u0013\u001b  \u0019\u001e\u001b   \u0010\u0011\u0011\u0014\u000e\u0014\u0010\u0018\u000e!  \u0019\u001e\u001b   \u001c\u000e\u0019\u001b\u0010 \u0010\u0011\u0011\u0014\u000e\u0014\u0010\u0018\u000e!  \u0019\u001e\u001b   \u001d\u0014\u0017\u0010\"\u0019\u0018\u0010  \u001c\u0016\u0010\u0010\u001a !\u0010\u001c\u001d\u0010\u001b\u000f   ! \u001d\u0014\u0017\u0010\"\u0019\u0018\u0010  \u0019\u001e\u001b   \u001c\u000e\u0019\u001b\u0010   \u0016\u0014\u0012\u0018\u0017\u0010\u0018\u001d  \u0019\u001e\u001b   \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010 \u001b\u0010\u000e\u0019\u001f\u0010\u001b! \u0014\u0018\u000f\u0010  \u0019\u001e\u001b   \u001c\u000e\u0019\u001b\u0010 \u000f\u0010\u0010\u001a  \u0019\u001e\u001b   \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010 \u001c\u0016\u0010\u0010\u001a   \u0016   \u0018\u000e\u0010  \u0019\u001e\u001b   \u000f\u0010\u0010\u001a  \u0019\u001e\u001b   \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010  \u0019\u001e\u001b   \u0016\u0014\u0012\u0013\u001d  \u0019\u001e\u001b   \u0017\u0014\u000f\u001a\u0019\u0014\u0018\u001d \u001d\u0014\u0017\u0010  \u0019\u001e\u001b   \u001b\u0010\u0017  \u0019\u001e\u001b   \u001c\u000e\u0019\u001b\u0010 \u001b\u0010\u0017  \u0019\u001e\u001b   \u000f\u001e\u001b   \u001d\u0014\u0019\u0018  \u0019\u001e\u001b   \u001c\u000e\u0019\u001b\u0010 \u001d\u0019\u001d   \u0016  \u0019\u001e\u001b   \u001d\u0019\u001d   \u0016  \u0019\u001e\u001b   \u001b\u0010   \u000f! \u001c\u000e\u0019\u001b\u0010 \u001a\u001b\u0010\u001f\u0014\u0019\u001e\u001c \u0018\u0014\u0012\u0013  \u0019\u001e\u001b   \u001c\u000e\u0019\u001b\u0010  \u0019\u001b\u001b\u0010\u0016   \u001d\u0014\u0019\u0018   of sleep variables with target (oura_score) ‚àí\u0004\u0003\u0007   ‚àí\u0004\u0003\u0006   ‚àí\u0004\u0003\u0005   \u0004\u0003\u0004   \u0004\u0003\u0005   \u0004\u0003\u0006  '(+-!\u0019!\u001e&\",)!\u001e+\u001e  \u001c(.'-+2\u0019\u0015\u0014\u0012  \u001c\"-2\u0019\u0010&,-\u001e+\u001d\u001a&  \u001a0\u0019\u001a\u001c-\"/\u0019\u001c2\u001c%\"'  \u001a0\u00190\u001e\u001a-!\u001e+\u0019)+\u001e,,.+\u001e\u0019,-\u001d  +\u001e,\u001c.\u001e\u0019-(-\u001a%\u0019\u001d\",-+\u001a\u001c-\"'   \u0019-\"&\u001e  \u001a0\u00190\u001e\u001a-!\u001e+\u00190\"'\u001d\u0019,)\u001e\u001e\u001d\u0019&\u001e\u001d\"\u001a'  \u001a0\u00190\u001e\u001a-!\u001e+\u0019+\u001a\"'\u0019,-\u001d  +\u001e,\u001c.\u001e\u0019'\u001e0,  +\u001e,\u001c.\u001e\u0019\u001d\",-+\u001a\u001c-\"'  '(&\"\u001e\u0019\u001c\u001a\u001f\u0019/\u001a%.\u001e\u0019,.&  \u001a0\u00190\u001e\u001a-!\u001e+\u00190\"'\u001d\u0019,)\u001e\u001e\u001d\u0019,-\u001d  '(&\"\u001e\u0019\u001c\u001a\u001f\u0019'\u001e-\u0019!(.+\u0019&\u001a1  \u001a0\u0019   \u001e(!\u001a,!   \u0019'.&\u0019.'\"*.\u001e  \u001a0\u00190\u001e\u001a-!\u001e+\u0019\u001c%(.\u001d\"'\u001e,,\u0019&\u001e\u001d\"\u001a'  +\u001e,\u001c.\u001e\u0019\u001e'-\u001e+-\u001a\"'&\u001e'-  \u001a0\u0019   \u001e(!\u001a,!   \u0019'.&\u0019.'\"*.\u001e  '(&\"\u001e\u0019\u001c\u001a\u001f\u0019'\u001e-\u0019!(.+\u0019+\u001a'   \u001e  '(&\"\u001e\u0019\u001c\u001a\u001f\u0019'\u001e-\u0019!(.+\u0019,)+\u001e\u001a\u001d  0(%\u0019&(+'\"'   \u0019#(.+'\u001a%  0(%\u0019\u001f(+&\u001a%\u0019&\u001e\u001d\"-\u001a-\"('  \u001a0\u0019!+\u0019!\u001e\u001a+-\u0019+\u001a-\u001e\u0019&\u001e\u001d\"\u001a'\u0019&(+'  \u001a0\u00190\u001e\u001a-!\u001e+\u0019!.&\"\u001d\"-2\u0019&\u001e\u001d\"\u001a'  \u001a0\u0019!+\u0019!\u001e\u001a+-\u0019+\u001a-\u001e\u0019,-\u001d\u0019\u001d\u001a2  +\u001e,\u001c.\u001e\u0019\u001d\u001e,\"   '  \u001a0\u0019!+\u0019!\u001e\u001a+-\u0019+\u001a-\u001e\u0019,-\u001d\u0019\u001e/\u001e  \u001a0\u0019   \u001e(!\u001a,!   \u0019'.&\u0019.'\"*.\u001e  !$\u0019\u001a\u001c-\u0019\u0006!  +\u001e,\u001c.\u001e\u0019/\u001e+2\u0019\u001d\",-+\u001a\u001c-\"'  !$\u0019\u001a\u001c-\u0019\u0005!  3\u001e+(\u0019'\"   !-\u0019\u001e\u001a-\"'  0(%\u0019/\u001e   \u001e-\u001a+\"\u001a'\u0019\u001d\"\u001e-  \u001a0\u00190\u001e\u001a-!\u001e+\u0019+\u001a\"'\u0019&\u001e\u001d\"\u001a'  !$\u0019\u001a\u001c-\u0019'\"   !-\u0019&\u001e\u001a'  +\u001e,\u001c.\u001e\u0019-(-\u001a%\u0019-\"&\u001e  \u001a0\u0019   \u001e(!\u001a,!   \u0019'.&\u0019.'\"*.\u001e  +\u001e,\u001c.\u001e\u0019,!())\"'  !$\u0019\u001a\u001c-\u0019\u0006\u0006!  !$\u0019\u001a\u001c-\u0019\u0005 4h  rescue_social_network  hk_act_23h  hk_act_ 0h  zero_start_hour_delta  aw_hr_heart_rate_std_morn  aw_loc_speed_max  aw_geohash5_num_unique  nomie_caf_net_hour_min  aw_hr_heart_rate_median_eve  city_Paarl  wol_intensive_workout  wol_take_creatine  aw_weather_cloudiness_std  rescue_productive  rescue_utilities  zero_hours_since_prev_fast  wol_moderate_activity  wol_pescatarian_diet  aw_hr_heart_rate_std_night  rescue_coms_and_scheduling  rescue_total_productice_time  wol_no_alcohol  hk_act_9h  hk_act_ 21h  rescue_very_productice  aw_activ_running  aw_hr_heart_rate_median_night  hk_act_8h  aw_activ_walking  hk_act_16h  hk_act_19h  zero_prev_end_hour_delta  rescue_business  hk_act_1 3h  wol_read_book  is_weekend  rescue_neutral  daily_weekday  daily_year  aw_hr_heart_rate_median_day  hk_act_17h  hk_act_ 20h  zero_hours  aw_activ_automotive  hk_act_4h  wol_brush_teeth_before_bed  aw_loc_altitude_mean  hk_act_7h  rescue_software_dev  hk_act_morn_mean  hk_act_ 3h  hk_act_6h  wol_daily_metrics  hk_act_eve_mean  rescue_reference_and_learning  hk_act_1 0h  aw_weather_humidity_std  hk_act_afternoon_mean  hk_act_5h  hk_act_15h  hk_act_11h  hk_act_1 2h  aw_activ_stationary  hk_act_18h  aw_weather_temperature_min_median  aw_weather_temperature_max_median  aw_weather_temperature_median  aw_weather_pressure_median  wol_caffeinated_drinks_<=_2  wol_no_caffeine_after_3pm  aw_weather_temperature_std  aw_weather_temperature_max_std  aw_weather_temperature_min_std  daily_month  daily_week_no .  country_ZAF  city_Cape Town  Correlation of other variables with target   (oura_score)  Figure 7: Pearson correlations between features and the target ( oura_score ). The left subfigure shows features that originate from the Oura ring, i.e. sleep related. The right subfigure shows features that originate from other data sources. Recall from ¬ß3.5 that the prefix   sleep_yesterday_  is used for a 1-day lag on the   oura_   features to make it easier to remember to remove same-day sleep features that constitute a data leak. So   sleep_yesterday_total   can be interpreted as   oura_total  with a shift of 1 day. As expected, sleep-related features were more strongly correlated with the sleep score than the non-sleep features. Specifically, measures of sleep duration and efficiency had a strong positive correlation with the target ( 0 . 5   ‚â§   r   ‚â§   0 . 9 ). This is expected, knowing that sleep score is a weighted Page 17\n\nQuantified Sleep : 4   ANALYSIS OF DATASET PROPERTIES   Gianluca Truda linear sum over several of these features.   Curiously, a few sleep-related features had no direct correlation with sleep score. Notably, those related to respiration rate and temperature. The bedtime feature had a strong negative correlation with the target ( r   ‚âà ‚àí 0 . 6 ), which is likely because it is considered as part of the ideal sleep window calculation that comprises   10%   of the sleep score. It was important to remove features like this from the dataset prior to training the model, in order to prevent data leaks. The non-sleep features had much weaker correlations with sleep score ( ‚àí 0 . 3   ‚â§   r   ‚â§   0 . 3 ), highlighting that there were no obvious candidate features. The strongest correlations fell into the location, weather, and caffeine categories. Notably, time-related features like the week number and month number showed a notable correlation to sleep quality ( r   ‚âà   0 . 2 ), indicating some trend or seasonality. This would also explain why weather and location features showed strong correlations with the target. Analysis of data stationarity is an essential step (¬ß4.5).  4.4.2   Hierarchical correlational clustering  It is also important to consider how features might correlate with each other. For small numbers of features, correlation matrices are ideal for such analysis. However, these graphics become difficult to interpret when there are more than a dozen features. Instead, this study made use of   agglomerative clustering   of features by their correlations to produce a   dendrogram   (Fig. 8). The dendrogram was generated as follows: First, the features were filtered to only consider those with less than 10% of their values missing. Each of the   n   features then had its absolute Pearson correlation to each other feature calculated, producing an   n   √ó   n   correlation matrix.   Next, the pairwise Euclidean distances between each row of absolute correlations were calculated. Hierarchical clustering was performed on these pairwise distances using the Nearest-Point algorithm. These clusters were then plotted as a coloured dendrogram (Fig. 8). This hierarchical approach to correlations between features is immensely useful and offers more intuitive interpretations than a standard correlation matrix.   By summarising the correlations between all   n   √ó   n   pairs of features into distances in   n -dimensional space, the complexity of the relationships is interpreted for us. This highlights groups of features that are strongly correlated with one another but not with other clusters of features. Moreover, we can use the dendrogram representation to interpret just how correlated subsets of features are. This is immensely useful for validating (and refining) feature engineering in order to achieve the higher sample efficiency needed to model wide QS data. In Fig. 8 we can see that the hourly movement data (prefix   hk_act_ ) clustered together in chunks of time and was highly correlated with aggregation features for this data.   Specifically, we can see that movement between the hours of 1 and 7 was very highly correlated and therefore also highly correlated with their mean ( hk_act_night_mean ) (Fig. 8b). This tells us that most of the (linear) information about nighttime movement can be captured from a single feature that averages over the hourly features. We can also notice that there was low correlation between different time windows of movement features. The morning, afternoon, and evening features clustered within their time windows but not across them (Fig. 8c). This tells us that the different windows of time throughout the day ‚Äî morning, afternoon, evening, night ‚Äî capture different information that might be relevant to our model. A final observation from the dendrogram is that location data formed a number of related, but strongly-separated clusters. Geohashes gave similar information and were clustered (Fig. 8e), but were very far from the cluster of features relating to city, country, and hemisphere (Fig. 8d). This suggests that two levels of resolution are important ‚Äî frequent changes in location at a resolution of metres, and infrequent changes in location at a resolution of kilometres. Page 18\n\nQuantified Sleep : 4   ANALYSIS OF DATASET PROPERTIES   Gianluca Truda b.  c.  d.  e.  a.  Figure 8: Dendrogram of hierarchical correlational clustering for all features with low missing data. Each of the   n   features were clustered based on their distance in   n -dimensional space to other features from the   n   √ó   n   correlation matrix. The dendrogram shows features on the vertical axis and pairwise Euclidean distance on the horizontal axis. Vertices indicate where clusters join into superclusters. The distance between clusters is represented by their vertical distance on the vertical axis. Colour-coding is used to illustrate primary clusters based on a 70% similarity threshold. Note that some feature names are replaced with   location x   to protect private data. Page 19\n\nQuantified Sleep : 4   ANALYSIS OF DATASET PROPERTIES   Gianluca Truda  4.4.3   Autocorrelation  Autocorrelation can be detected by computing the correlation between a feature and a copy of the feature where values are shifted (lagged) by 1 or more points. Autocorrelation gives us an indication of how well a feature predicts its own future values [   29 ]. This was immensely useful in this study because of the inherent time series nature of most QS data. Behavioural and biological patterns often have periodic variations or trends over time. For example, it is common for people to dramatically shift their sleeping patterns on weekends compared with weekdays. This can often be detected by spikes in autocorrelation at intervals of 6-7 days ‚Äî last week somewhat predicts this week. For this study, the autocorrelation of each feature was analysed for varying shifts (lags) up to 25 days. Four interesting patterns are presented in Fig. 9.  (a) No autocorrelation.   (b) Trending autocorrelation.  (c) Periodic autocorrelation.   (d) Trending autocorrelation.  Figure 9: Notable autocorrelation patterns observed across features. Each plot shows the correlation on the vertical axis and the lag (in days) on the horizontal axis. The shaded regions represent a 95% confidence interval for the null hypothesis at each lag level, so values that fall within this region are unlikely to be significant. We can see that the target feature ( oura_score ) had a very low degree of autocorrelation (Fig. 9a). This is extremely surprising, as it implies that previous sleep quality does not have a strong linear relationship to current sleep quality. This highlights how difficult the task of predicting sleep quality is. Interestingly, a lag of 1 day had a small negative correlation with the target ( r 1   ‚âà ‚àí 0 . 2 ). This suggests that sleep oscillates in quality on adjacent nights. We can also see that some features showed a clean trend of autocorrelation with respect to lag (Fig. 9b and 9d). This is to be expected Page 20\n\nQuantified Sleep : 4   ANALYSIS OF DATASET PROPERTIES   Gianluca Truda of a number of features, such as habits and temporally-derived features like   sleep_balance . What is worth noting is the lag point at which the autocorrelation becomes statistically insignificant. This gives us a rough indication of how many days of history may be relevant for our model. Finally, we can see that some features displayed prominent periodicity (Fig. 9c). Productivity time is derived from time spent on my laptop working with specific software or websites that are marked as productive. We can see from the spikes in the plot that the periodicity had a peak-to-peak length of exactly 7 days. This makes a great deal of sense, as my productivity levels are highly influenced by the day of the week.  4.5   Stationarity  A key principle of modelling time series data is that it should be stationary. Specifically, it should exhibit no periodicity or trends, leaving only irregular variations that we attempt to predict using other features [ 3   ]. However, most real-world data is not stationary. As we have already seen, many of the relevant features in this dataset are periodic.  (a) Trend of mean for target.   (b) Trend of variance for target.  Figure 10: Scatterplots of target features ( oura_score ) over time (indexed observations). The left figure superimposes trends of the 7- and 30- day rolling mean. The right figure superimposes trends of the 7- and 30- day rolling variance. The augmented Dickey-Fuller test can be used to assess the stationarity of a sequence of data [   30 ]. This test was applied to each feature in the dataset. A total of 34 input features were found to be non-stationary ( p >   0 . 05 ). Many of these were explicitly temporal features like the year, month, or day. Many were naturally non-stationary data like weather patterns. What we are most concerned with, however, is whether the target feature is stationary. If not, techniques like statistical differencing need to be applied before building a model [ 3 ]. Unfortu- nately, such applications make interpretation much more difficult. Fortunately, the target feature ( oura_score ) was found to be stationary with reasonable confidence ( p <   0 . 01 ). This means that variations had no major periodic or trending patterns.   This is illustrated visually with rolling averages of both the mean and variance in Fig. 10. This was very fortunate for this study, as the interpretation step is easier if we do not have to transform the target feature. This stationarity of the sleep features was likely a happy result of the pandemic conditions. The data included for modelling begins from October 2019. When including data back to December 2018, the target was less likely to be stationary ( p   ‚âà   0 . 09 ). Page 21\n\nQuantified Sleep : 5   OVERCOMING MISSING DATA   Gianluca Truda  5   Overcoming missing data  5.1   Theory of missing data  There are three main types of missing data identified in the statistics literature [   31 ]. Understanding their different properties is integral to selecting robust imputation techniques for filling in the missing values [11].  Missing completely at random (MCAR) : Missing values are considered MCAR if the events that caused them are independent of the other features and occur entirely at random. This means that the nullity (missingness) of the values is unrelated to any of our study features and we can treat the data this   is   present as a representative sample of the data as a whole. Unfortunately, most missing values are not MCAR [11].  Missing at random (MAR) : Despite the name, MAR occurs when the nullity is   not   random, but can be fully accounted for by other features that have no missing values. For instance, I did not explicitly log the city where I slept every night, but the data is MAR because it is fully accounted for by the date index and geohash features, from which I can accurately infer the missing values for the city.  Missing not at random (MNAR) : Data is MNAR when the nullity of the value is related to the reason that it is missing. This makes the dataset as a whole biased. For instance, I am more likely to forget to log my mood when I am very happy or utterly miserable. The missing extreme values in the data are thus MNAR.  5.2   Analysis of missing data  The absence of data points is a major factor in Quantified-Self (QS) projects [ 3 ], especially when combining data from multiple sources. An upfront analysis of the quantity and distribution of missing values is essential before missing values can be rectified. Missing data matrices are an invaluable visualisation in this regard. They give an impression of the dataset in the same rows-as- observations and columns-as-features format that we are accustomed to, with shading to indicate where data is present. In Fig. 11, the entire dataset is rendered as on of these matrices using the superb   missingno   library [   32 ]. It is important to note that this version of the dataset included more than the 15-month timeline of the final dataset. This was for illustrative purposes. Much of the top half of the dataset was ultimately discarded before modelling. In Fig. 12, the columns are grouped by the source prefix (Table 1) in order to get a better understanding of which data sources are to blame for which missing data. When combining columns from the same source, missing values took precedence. In other words, the simplified matrix represents the worst-possible combination of the columns from that source, in terms of nullity. Anecdotally, these patterns are typical of multiple-source QS projects. New data sources are added over time, whilst others fall out of use. Some data is tracked very consistently (often automatically), whilst many of the manually-tracked sources have short sequences of missing values spread all over ‚Äî due to poor adherence to tracking protocols. We can see from the missing data matrices that the sources used changed dramatically over time. The AWARE ( aw ), Nomie, and Zero sources were only adopted later on. Fortunately for the focus of this study, the sleep data ( oura ) was complete and had no missing data, as it was automatically tracked and the ring was worn every night. By having a target feature free of missing data, this study was well-positioned to mitigate the missing data in the other features. Page 22\n\nQuantified Sleep : 5   OVERCOMING MISSING DATA   Gianluca Truda 285 123 1 789  Figure 11: Missing data matrix for the entire raw dataset. The vertical axis represents rows in the dataset (corresponding to daily observations). The horizontal axis represents columns in the dataset (corresponding to features). The dashed blue line indicates the start of the period of time considered for this study. The sparkline on the right indicates the general shape of the data completeness, with the rows of minimum and maximum nullity labelled with a count of the non-missing values in the rows.  Figure 12: Missing data matrix for groups of features in the raw dataset. The vertical axis represents rows in the dataset (corresponding to daily observations). The horizontal axis represents columns in the dataset (corresponding to features). The dashed blue line indicates the start of the period of time considered for this study. The sparkline on the right indicates the general shape of the data completeness, with the rows of minimum and maximum nullity labelled with a count of the non-missing values in the rows. The column names are the prefixes of each source (see Table 1). Page 23\n\nQuantified Sleep : 5   OVERCOMING MISSING DATA   Gianluca Truda  5.3   Approaches to handle missing data  Most modelling techniques assume complete data, meaning that missing values pose a major problem [ 25 ].   There are three common strategies for dealing with missing data: omission, full analysis, and imputation [31, 25, 33].  Omission   (dropping): The most common approach is to omit sections of the dataset that contain missing values. Typically, this involves discarding observations (rows) that contain one or more missing values. This leaves only complete observations, but discards much of the information in the original dataset. In QS datasets with many features from heterogeneous sources, it is often the case that the majority of observations contain at least one missing value. In such cases, dropping all these rows would discard almost all of the dataset. Some features (columns) have more missing values than others, so it is often desirable to discard the worst-offending features first, then discard the observations with missing values from the features that remain. This often results in retaining more overall information. In n-of-1 QS studies, we typically cannot afford to discard much data, so finding the right trade-off between retaining observations and features is a challenge.  Full analysis : Some learning algorithms are designed to use all available data and to tolerate missing values. Many of these are beyond the scope of this study, but the XGBoost implementation of gradient boosted Decision Trees is of interest. XGBoost is a well-engineered ensemble technique that learns default directions in the branches of the Decision Trees that are taken when missing values are encountered [   34 ]. This leverages the values that are present to learn reasonable estimates for missing values. XGBoost is also a high-performing algorithm [   34 ] and was thus a prime candidate from the outset of this study.  Imputation : Instead of omitting missing values, we can try to estimate them using imputation. This has the advantage of retaining the size and shape of the dataset, but the disadvantage of incorporating estimation error into the data ‚Äî resulting in additional noise for the model to overcome [   31 ,   33 ]. This study employed a variety of imputation strategies (¬ß5.5) in combination and compared the resulting model performance. When our data is an ordered time series, we can use a specific kind of imputation called interpolation [ 3 ]. This fills the gaps between available samples by assuming some regular rate of change between samples. For most features in the dataset, the sample frequency was too low for interpolation to be viable. One notable exception was the heart rate data, which was sampled over a thousand times each day. This feature was first resampled at intervals of 1 minute to make it regular, then linear interpolation was applied to smooth over discontinuities.  5.4   Knowledge-based filling  Much of the data in observational n-of-1 studies is MAR or MNAR, both of which can be predicted with an accuracy much greater than random guessing [   11 ]. Furthermore, some QS studies have a unique kind of MCAR data that can be filled accurately, albeit not with prediction. We can refer to these as   informative absences . They are the result of the feature engineering step, but can be overcome due to intimate knowledge of the study protocol and adherence ‚Äî a perk unique to QS research. The informative absences resulted from event logs that were aggregated into daily summaries and, in most cases, could simply be filled with a suitable placeholder value. For instance, alcohol consumption was only logged (with a timestamp) when it occurred. Because I was both the subject and the researcher, I can be extremely confident that I almost never failed to log events like alcohol because I was conscious of my own adherence patterns. When the event logs were aggregated, there were very many days where no alcohol was consumed that simply had no data. Because Page 24\n\nQuantified Sleep : 5   OVERCOMING MISSING DATA   Gianluca Truda I was confident that I adhered well to alcohol logging, I could simply fill this missing data with appropriate values indicating that no alcohol was consumed:   0 . 0   for the sum features, and   ‚àí 1 . 0   for the temporal features. I refer to the manual filling of these kinds of MCAR data as   knowledge-based  filling, as it relies on expert and domain knowledge to determine when and what values should be filled. We can see these informative absences in Fig. 12 for   melatonin ,   nomie , and   aw_calls .  5.5   Imputation strategies  After manually filling the informative absences with the knowledge-based approach, many MAR and MNAR values remained. These were imputed using one of several imputation strategies (see Table 2).  5.5.1   Univariate imputation  The most straightforward imputation strategy is univariate imputation. This is where missing values for the   j -th feature are imputed based on the non-missing values for that   j -th feature. In the case of continuous features, the mean or the median of the non-missing values is calculated for each feature. That value is then filled into the missing values for the respective feature. In this study, both mean and median univariate imputation were utilised (see Table 2).  5.5.2   Multivariate imputation  In the case of data that is MAR, the missing values for the   j -th feature may be more accurately imputed when considering each observation   i   individually and conditioning on information from the other features. For instance, a missing value relating to a particular day‚Äôs activity levels could likely be imputed quite accurately based on non-missing values for weather and heart rate for that same day. This is the intuition behind multivariate imputation. Conceptually, each feature   x j   in our data matrix   X   is modelled as a function   f j   of the other features   X ¬¨ j   . A missing value at  x i,j   can then be imputed using the function   f j   ( X i, ¬¨ j   ) . In reality, the implementation of a specific imputation technique might look very different from this conceptual view. In this study, several approaches to multivariate imputation were explored (see Table 2).  5.5.3   Multiple imputation  So far, we have considered single rounds of univariate or multivariate imputation. However, because many of the multivariate imputation techniques are stochastic, it is common to run multiple independent rounds of imputation on the entire dataset, in what is known as multiple imputation. These rounds can then be either (1) compared to select the one that minimises some cost function, or (2) can be aggregated into a single imputed dataset. The aim of these multiple rounds is to achieve a more accurate estimate of the imputed values. However, when the imputed dataset is then used for subsequent modelling, the uncertainty of these estimates is not considered, meaning there is a greater quantity of noise in the data that the model must overcome. To remedy this, some practitioners keep all versions of the dataset generated from the rounds of multiple imputation and concatenate them instead of aggregating them [   35 ]. If the original dataset was   m   √ó   n   in shape, the multiply-imputed dataset is   km   √ó   n   in shape, where   k   is the number of rounds of multiple imputation. This effectively adds many observations that are slight variants of each other to the dataset, in the hope that the downstream model will make sense of the uncertainty in the imputed values. In this study, a number of multiple imputation strategies were employed (see Table 2). For the MICE technique, the imputation rounds were concatenated into a longer dataset to capture the uncertainty [33]. Page 25\n\nQuantified Sleep : 5   OVERCOMING MISSING DATA   Gianluca Truda  5.6   Baseline dataset with missing values  The unified dataset was filtered down to only numeric features from after   2019-10-05 , resulting in 482 observations and 271 features. Features which had more than 70% of their values missing were removed, leaving 234 features. The remaining data showed a bimodal distribution of nullity. That is, 424 observations had fewer than 15 missing values across all 234 features, whilst the other 119 observations had more than 15 missing values across all the features. A subset of 61 observations were ‚Äúpure‚Äù. That is, they had no missing values in any of their features. An additional column ( is_pure ) was appended to the dataset to label these observations. Only these observations were sampled for scoring model performance in later experiments. This had the advantage of isolating the effect of imputation techniques to only the training data, but came with two caveats. Firstly, there was a huge imbalance between pure and impure features (61:421). Secondly, the target distribution differed between these subsets (Fig. 13a). Data-leaking features with the   oura_   prefix were removed. The resulting   with_nans   dataset of 482 observations and 193 features (including the target) was used as the basis for all the imputations and as a non-imputed baseline. The missing values of this dataset are visualised in Fig. 13b. 20   40   60   80   100   120  0.00  0.01  0.02  0.03  0.04  0.05 Density  Distributions of target feature for 'pure' and 'impure' rows  Pure  Impure  (a) Comparison of target distributions. 193 137 1 482   (b) Missing data matrix.  Figure 13: Left: Comparison of target feature (sleep quality) for ‚Äúpure‚Äù observations, which had no missing data in any of their features, and ‚Äúimpure‚Äù observations, which had some missing values. Right: missing data matrix for   with_nans   dataset.  5.7   Quantifying imputation distance  To quantify the change to a dataset from imputation, the imputation distance metric   D imp.   was defined.   What follows is the derivation of the imputation distance metric from foundational principles of relative entropy. The Jensen-Shannon distance (JSD) between two probability arrays   P   and   Q   is defined as:  JSD ( P   ||   Q ) :=  ‚àö   D KL ( P   ‚Äñ M   ) +   D KL ( Q ‚Äñ M   ) 2   (1) where   M   =   P   + Q  2   is the point-wise mean of the arrays   P   and   Q   and   D KL   is the Kullback-Leibler divergence (relative entropy). Page 26\n\nQuantified Sleep : 5   OVERCOMING MISSING DATA   Gianluca Truda To calculate the JSD for two distributions of some feature, we first have to generate probability array   P   and   Q   for each distribution of the feature. We approximate this by constructing   1000  equal-width bins over the range of each distribution and then counting how many of the observed values fall into those bins. These counts are divided by the number of observations to produce a probability array for each distribution. The JSD has a number of desirable properties. Like KL-divergence, it is a principled information- theoretic measure that is non-negative and is zero only when the distributions are identical. Unlike KL-divergence, however, it is   symmetric   and   smoothed , making it more robust [36]. The JSD was used to compute the change in each feature   j   ‚àà   R n   from the original dataset (with missing values)   X   to the imputed dataset   X ‚Ä≤ . The average distance of an imputation   D imp.   could be estimated by taking the arithmetic mean over all   n   features:  D imp. ( X   ||   X ‚Ä≤ ) :=  1  n  n ‚àë  j =1  JSD   [ P   ( x j   )   ||   Q ( x ‚Ä≤  j   ) ]   (2) The average imputation distances relative to the raw dataset were calculated for each imputation strategy (Table 2).  Name   Distance   Scope   Imputation   Implementation  Univariate mean   0.0923   Univariate   Single   SimpleImputer * Univariate median   0.0535   Univariate   Single   SimpleImputer * Iterative Bayesian ridge (50)   0.0986   Multivariate   Multiple   IterativeImputer * MICE (3) [39]   0.2079   Multivariate   Multiple   IterativeImputer * MICE (15) [39]   0.2292   Multivariate   Multiple   IterativeImputer * KNN (K=3)   0.0658   Multivariate   Single   KNN   ‚Ä†  SoftImpute [40]   0.1319   Multivariate   Multiple   SoftImpute   ‚Ä†  Iterative SVD [41]   0.2147   Multivariate   Multiple   IterativeSVD   ‚Ä†  Matrix factorisation [42]   0.1897   Multivariate   Multiple   MatrixFactorization   ‚Ä†  Table 2: Overview of the imputation strategies used in this study. The name is used to refer to the technique in the paper. The distance between the raw dataset and the imputed dataset was computed using the mean Jenson-Shannon (JSD) distance over all the features (¬ß5.7). A larger distance value indicates more dramatic differences between the distributions of the raw and imputed versions of the dataset. The implementation column refers to the Python class used to implement the technique, from either the Scikit-learn   [37] (*) or   fancyimpute   [38] ( ‚Ä† ) libraries. Univariate imputation of the median had the lowest imputation distance across all features. Univariate mean imputation had a much greater distance than univariate median imputation. This is likely because many of the features had non-normal distributions and the median is far less sensitive to outliers.   Iterative SVD and MICE had the highest imputation distances.   Greater numbers of concatenated MICE iterations (15 versus 3) resulted in a greater imputation distance. Page 27\n\nQuantified Sleep : 6   COLLAPSING TIME WITH MARKOV UNFOLDING   Gianluca Truda  6   Collapsing time with Markov unfolding  6.1   Markov assumption  Building a predictive model of sleep requires us to make the Markov assumption [ 43 ] ‚Äî that the current night‚Äôs sleep depends only on a finite fixed number of previous days‚Äô data. Imagine that we are trying to calculate a probability distribution   P   over the possible sleep scores  y t   ‚àà   [0 ,   100]   on day   t , conditioned on all features from the past. Formally, we are trying to model:  P   ( y t   |   X 1: t ‚àí 1 )   (3) where   y t   is the current night‚Äôs sleep score and   X 1: t ‚àí 1   is the matrix of features for all days prior to day   t . For simplicity,   X 1: t ‚àí 1   includes the vector   y 1: t ‚àí 1 , the previous target values. Eq. 3 implies that the sleep on night   t   depends on all past nights of sleep and all past days of other features. In other words, we require the full history. Now, if we make the Markov assumption:  P   ( y t   |   X 1: t ‚àí 1 ) =   P   ( y t   |   X t ‚àí œÑ   : t ‚àí 1 )   (4) we assume that modelling only the past   œÑ   days produces as good an estimate of the current sleep as looking at the full history. This is a very useful assumption, as it allows us to reframe our time series prediction task to an independent-and-identically-distributed (i.i.d.) prediction task. This, in turn, makes many more techniques ‚Äî for both modelling and interpretation ‚Äî available to us. But how can we assume that the Markov property holds for this data? Clearly, if we set   œÑ   =   t  then the Markov property holds trivially, as we are using the full history. So there must be some  œÑ < t   at which the Markov property breaks down for our data. In reality, we do not care where the property first breaks down, but rather where the amount of information retained is sufficient for our prediction needs. We can estimate the optimal   œÑ   value by analysing our data for autocorrelation, then use it to construct an i.i.d. representation that incorporates the Markov property [43]. The autocorrelation analysis from Section 4.4.3, alongside domain knowledge, highlighted that previous days‚Äô behaviour plays a role in the current characteristics and resulting sleep quality. For instance, I may have had a healthy and balanced day today, but if I was up late partying or revising for an exam the night before, then my sleep is likely to be affected. Page 28\n\nQuantified Sleep : 6   COLLAPSING TIME WITH MARKOV UNFOLDING   Gianluca Truda  6.2   Markov unfolding  We can implement this conversion from a time series to an i.i.d. dataset with a technique I dub  Markov unfolding .   We begin with our   m   √ó   n   data matrix   X .   The data in   X t ‚àí œÑ   : t ‚àí 1   (i.e.   the past   œÑ   days) is ‚Äúunfolded‚Äù into a row vector of length   œÑ n . This is repeated for each time point  t   ‚àà   [ œÑ, m ]   and the resulting vectors are stacked onto   X   to produce a new dataset   X ‚Ä≤   with shape  ( m   ‚àí   œÑ   )   √ó   ( œÑ   + 1) n . 5 x 2   5 x 8  ùúè   = 3  1   6  2   7  3   8  4   9  5   10   5  -   - 1   6  2   7  3   8  4   9  1   6  2   7  3   8  10   4   9  -   -  1   6  2   7  3   8  -   -  1   6  2   7  -   -  -   - -   -  Figure 14: Illustrative example of Markov unfolding a   5   √ó   2   dataset into a   5   √ó   8   dataset using lag of   œÑ   = 3 . After removing the missing values, the final dataset is of shape   2   √ó   8   (outlined). Intuitively, we are copying the columns of the original dataset, shifting them down by   1   row, and stacking them as new columns on the right of the dataset. We repeat this with shifts of   2 ,   3 , ..., œÑ   ; stacking the new columns each time. We have to throw away the first   œÑ   rows from the beginning of the dataset as we did not have enough previous states for them, resulting in missing values. We now have a dataset that is a few rows shorter, but   œÑ   + 1   times the width, than what we started with. We can now treat the rows (observations) in our dataset as totally independent, allowing us to use any supervised learning approach that assumes i.d.d. data. The   œÑ   value was selected by analysing the autocorrelation of key features to set an upper limit (in this case,   œÑ   = 7 ). This is intuitive, as many cycles in behaviour occur at a weekly level, so allowing the models to look up to 7 days back is useful for capturing these patterns. For instance, behaviour around activity, working hours, alcohol consumption, and other lifestyle factors often differs dramatically on weekends. These patterns of behaviour (and their effect on sleep) are often a good predictor of the next week‚Äôs behaviour, making them useful features to include. All the numeric features (including the target,   oura_score ) were unfolded for   œÑ   days prior. This went some of the way to incorporating the Markov assumption into the time series, thus allowing each day to be treated as an independent observation. One major drawback of Markov unfolding is that it can result in low feature efficiency. In other words, too many features, with those from farther back (larger   œÑ   ) being only loosely-correlated to the current ones. This sometimes results in the ‚Äúcurse of dimensionality,‚Äù which can prevent the data from being learnable, given the limited number of observations [ 10   ,   3 ]. This is somewhat mitigated by the use of feature selection (¬ß7.1.2). Page 29\n\nQuantified Sleep : 7   MODEL INTERPRETATION   Gianluca Truda  7   Model interpretation  Using predictive models to capture relationships in the data is integral to observational studies. Models can tell us much more than correlations between pairs of features, as they (1) allow us to control for the effects of other features and (2) can be regularised so that they are desensitised to the noise in the data. There is often a trade-off between the quality and explainability of the model [ 44 ]. In order to gain   descriptive   value from a predictive model, we need techniques for interpretation. There are a number of approaches to model interpretation [ 27 ]. Two of the most relevant approaches for observational n-of-1 QS projects are (1) intrinsically-interpretable models and (2) model-agnostic techniques.  7.1   Interpreting model parameters  Some learning algorithms ‚Äî like linear regression and its variants ‚Äî are   intrinsically   interpretable, as their parameters explain the effect of each feature independently of the other features [   27 ]. Consider the following formula, which describes a standard linear model:  ÀÜ y i   =   Œ≤ bias   +  n ‚àë  j =1  Œ≤ j   x i,j   =   Œ≤ bias   +   Œ≤ 1 x i, 1   +   Œ≤ 2 x i, 2   +   ¬∑ ¬∑ ¬∑   +   Œ≤ n x i,n   (5) where   ÀÜ y i   is the predicted value for observation   i ,   ( Œ≤ 1 , . . . , Œ≤ n , Œ≤ bias )   are the internal model parameters, and   ( x i, 1 , . . . , x i,n )   are the feature values for observation   i .   By analysing these internal model parameters (the   Œ≤ -parameters), we are able to interpret the magnitude and direction of the relationships between each feature and the target feature [27].  7.1.1   Regularised linear models  One major challenge in n-of-1 QS studies is that datasets are wide ‚Äî there are more features than observations. In a linear model, each feature has a corresponding   Œ≤ -parameter. It is well known that having a large number   Œ≤ -parameters allows us to fit arbitrary functions. With our wide dataset, that means we are modelling the noise in the dataset along with the signal, which overfits our model to the data and makes any results spurious [   25 ,   9 ]. One of the best techniques to resolve this is   regularisation , which penalises the model for having large   Œ≤ -parameters [ 25   ]. In Ridge regression, a weighted L2 norm of the   Œ≤ -parameters is added to the loss function. In Lasso regression, a weighted L1 norm is used instead. The mathematical properties of the L1 and L2 norm allow us to shape the effects of the regularisation in desirable ways. In particular, the L1 norm in Lasso regression favours   sparse   Œ≤ -values ‚Äî with values of 0 for features that have only a small effect on the prediction. This serves as built-in feature selection [ 45 ,   25 ]. Only features that are ‚Äúworth their weight‚Äù will have non-zero   Œ≤ -parameters. Both Ridge and Lasso were included as candidate algorithms in this study.  7.1.2   Recursive feature elimination (RFE)  Lasso is a rare example of an intrinsically-interpretable model with built-in feature selection. For other linear models (and tree-based models), best performance can be achieved when pre-selecting the most important features, then fitting a (regularised) model on that subset. RFE [ 46   ] recursively trains some model using various subsets of the features [   47   ]. In the past, feature selection techniques did not consider internal parameters, and instead tried all combinations of features to establish a Page 30\n\nQuantified Sleep : 7   MODEL INTERPRETATION   Gianluca Truda ranking of their importance [   3 ]. This has immense computational cost, as for   n   features a total of   2 n   ‚àí   1   models must be trained ‚Äî one for each subset of features.   RFE makes this process more efficient by utilising internal parameters to help rank feature importance. For best results, the rankings can be averaged over   5 -fold cross-validation. These top features can then be fed to the model. The resulting parameters can be analysed as before. Additionally, the ranking of the features from cross-validated RFE is a good secondary check on which features are most explanatory. RFE was used for both purposes in this study.  7.2   Model-agnostic interpretation  With the proliferation of neural networks, it is increasingly common for the best-fitting model to be a ‚Äúblack box‚Äù. That is, its internal workings are inseparable, making them impossible to interpret in isolation.   Model-agnostic   methods do not rely on internal model parameters. Instead, they rely on access to the dataset and the ability to test the model‚Äôs predictions on various input-output pairs. By systematically varying the inputs, model-agnostic methods can interpret model behaviour and allow us to understand the underlying relationships. This is achieved by building a linear  explanation model   g ( x i )   which is an interpretable approximation of the black-box predictive model  f   ( x i )   for any observation   x i   in our dataset. To construct the explanation model, we turn to the SHapley Additive exPlanations (SHAP) method [   48 ]. Because it is grounded in coalitional Game Theory, it boasts many desirable properties. It is also far more intuitive to interpret than other contemporary techniques, like local interpretable model-agnostic explanations (LIME) [27].  7.2.1   Shapley values  SHAP applies the concept of Shapley values with some algorithmic enhancements. Shapley values were originally demonstrated in Game Theory as a technique for fairly distributing payouts amongst players [ 49 ].   They can be used for model interpretability by reframing the problem: Let each feature be a player and let the total payout for each observation be proportional to the accuracy of the prediction. By evaluating all possible coalitions of features and repeating this for a number of examples, we can calculate Shapley values for each value that each feature takes on [   27 ]. These values represent the average contribution of a feature-value to the prediction. For a model with   n   features, let the set of feature vectors be   N   =   { x 1 ,   x 2 , . . . ,   x n } , such that   x j   is the column vector of values for feature   j . The Shapley values of feature   j   are calculated as:  œÜ j   ( v ) =  1  n !   ¬∑   ‚àë  S ‚äÜ N   \\{ x j   }  | S | !   ¬∑   ( n   ‚àí | S | ‚àí   1)!   ¬∑   [ v   ( S   ‚à™ { x j   } )   ‚àí   v ( S )]   (6) where   S   ‚äÜ   N   \\ { x j   }   denotes a subset   S   of all features   N   that do not include feature   j , and   v   :   S   ‚Üí   R  is a payoff function that evaluates how predictive some subset   S   of the features is, given dataset   X  and a trained model. Intuitively, the Shapley values of a feature   j   are how much each of its observed values shift the model prediction away from the mean prediction. Shapley values have been proven to satisfy a number of axioms in coalitional Game Theory [   49 ]. This makes the technique preferable to earlier approaches like LIME, which fail to ensure that the predictive value is fairly distributed among the features. Moreover, Shapley values allows for contrastive explanations, which many other techniques (including LIME) do not [   27 ]. These are immensely useful for comparing different subsets of the data in terms of the relationships between features ‚Äî e.g. how does a day with terrible sleep compare to one with outstandingly good sleep? Page 31\n\nQuantified Sleep : 8   EXPERIMENTS   Gianluca Truda Whilst extremely computationally expensive 6 , this approach allows much more nuanced interpreta- tions of the relationships between features, as each feature is explained with a   distribution   instead of a mere point estimate. So where interpreting   Œ≤ -parameters gave us an indication of each feature‚Äôs  global   importance, Shapley values give us their   situational   importance ‚Äî based on their effects during each observation.  7.2.2   SHAP  SHapley Additive exPlanations (SHAP) [   48 ] inherits the desirable mathematical properties of the Shapley value, but builds on them in two key ways.   Firstly, SHAP offers methods for global interpretations based on aggregations of Shapley values. Secondly, SHAP can utilise approximation methods that drastically speed up Shapley value computation on certain model architectures [   27 ]. SHAP builds a linear model   g   that approximates the predictive model   f   for any observation   x i   in our dataset:  f   ( x i )   ‚âà   g   ( x i ) =   œÜ bias   +  n ‚àë  j =1  œÜ j   x i,j   (7) where   œÜ j   is the Shapley value of feature   j   for observation   x i,j   . Essentially, SHAP has generated a linear model of the feature contributions for some black box model we gave it, for some specific instance. Now, we can interpret the   œÜ -parameters just as we interpret the   Œ≤ -parameters of any linear model (Eq. 5). Except that   Œ≤ -parameters are   global   and thus apply over all observations in the data, whilst the   œÜ -parameters from SHAP apply to a single observation   x i   ‚àà   X .  8   Experiments  Four experiments were performed to evaluate the techniques presented in this study: (1) assessing the effectiveness of Markov unfolding, (2) comparing imputation techniques, (3) measuring overall predictive performance, (4) final model interpretation. The first three experiments made use of a grid-search over 3 parameters for 10 repeats. The fourth experiment leveraged the results of the prior experiments to train and interpret the most promising model.  Preparing dataset variants : Each of the 10 imputation variants of the dataset was loaded into the grid-search script, duplicated, then transformed with   7 -day Markov unfolding. This resulted in 20 dataset variants of varying sizes.  Learning algorithms : A total of 7 different learning algorithms were included 7 . The first 6 were well-established linear and tree-based algorithms. Lasso and Ridge regression were included as regularised linear models. A basic Decision Tree regressor was included for reference, along with two ensembles of Decision Trees ‚Äî Random Forest (bagging) and XGBoost (boosting). The 7th algorithm was a ‚ÄúNa√Øve regressor‚Äù that always predicts the median value of the target feature from the training set. This served as a baseline for predictive value.  6 In reality, most implementations of Shapley values for model interpretation rely on Monte-Carlo sampling to estimate the values efficiently [27].  7 Earlier experiments found that support vector algorithms had mediocre performance ‚Äî especially without hyperparameter optimisations ‚Äî and fully-connected neural networks were unable to converge due to the limited data, resulting in massive prediction error, as well as excessive training time. These were excluded for the final analysis.  Page 32\n\nQuantified Sleep : 8   EXPERIMENTS   Gianluca Truda  Feature selection : The final datasets often had far more features (columns) than observations (rows), making them incredibly wide and difficult for algorithms to learn effectively [   8 ]. Initially, principal component analysis (PCA) was tested as a means of reducing the feature-space, but the number of components in PCA is limited by the number of observations, making this non-viable for these wide datasets. Recursive feature elimination (RFE) [   46 ] with a Decision Tree base model was used to rank the features independently for each of the 20 dataset variants, based on a single random train-test split of the data. Each non-target feature in the datasets was scaled independently prior to feature selection to speed up convergence.  Grid search : The grid search performed 10 cross-validation repeats over each of the 20 dataset variants. In each repeat, the dataset was split into train- and test- sets with a custom splitting function: each call drew a sample of   40   ‚Äúpure‚Äù observations (¬ß5.6), without repeats, for the test set and kept the remaining observations as the train set. This meant that models were only scored on observations that had complete data and had not undergone imputation ‚Äî which was essential for fair comparison. The train and test sets were scaled independently to avoid data leakage between them. The grid search iterated over all algorithms and values of   n   ‚àà   [2 ,   200] , training each on the   n - highest-ranked features in the train set and scoring the resulting model on the test set. Two of the dataset variants ‚Äî   with_nans   and   pre_markov_with_nans ‚Äî still had missing values. In the case of XGBoost, which can tolerate missing values [   34 ], the scaled training set was given directly to the algorithm. For all other algorithms, the observations with missing values were dropped from the training set before scaling and training.  RMSE metric : The prediction score was measured using the root mean squared error (RMSE) metric: RMSE ( y ,   ÀÜ y ) =  ‚àö ‚àö ‚àö ‚àö   1  m  m ‚àë  i =1  ( y i   ‚àí   ÀÜ y i ) 2   (8) where   y   were the true (target) values,   ÀÜ y   were the predicted values, and   m   = 40   was the number of observations in the test set. RMSE was selected because it is both (1) sensitive to outliers and (2) easily interpreted in the same units ‚Äî sleep score   ‚àà   [0 ,   100]   ‚Äî as the original target feature. Page 33\n\nQuantified Sleep : 9   RESULTS AND DISCUSSION   Gianluca Truda  9   Results and discussion  For each algorithm, dataset variant, and number of features, the RMSE over all 10 repeats was summarised by the mean and standard deviation.  9.1   Effectiveness of Markov unfolding  The best-performing configurations 8   for each model were collected and grouped by whether or not Markov unfolding was applied. Boxplots of the RMSE distributions are shown in Fig. 15. 8  10  12 RMSE  DecisionTreeRegressor   Lasso   NaiveRegressor  No   Yes  Markov unfolded  8  10  12 RMSE  RandomForestRegressor  No   Yes  Markov unfolded  Ridge  No   Yes  Markov unfolded  XGBRegressor  Figure 15: Comparison of prediction error (RMSE) across algorithms between the original dataset and the wider Markov-unfolded dataset. Results are distributions of mean RMSE scores for best- performing hyperparameter combinations for each dataset variant. Boxplots span the interquartile range (IQR) of the distribution, with a line indicating the median. The whiskers extend to the minimum and maximum values observed. Values beyond   1 . 5   times the IQR are considered outliers and plotted as circles. Markov unfolding did allow most algorithms to improve predictive performance, but the improvement was generally small. This was likely because the benefit of the additional information contained in the unfolded features traded off against the added burden of much higher dimensionality [26].  8 The best configurations for each algorithm and dataset were selected by finding the number of features that produced the lowest mean RMSE for that algorithm and dataset.  Page 34\n\nQuantified Sleep : 9   RESULTS AND DISCUSSION   Gianluca Truda By inspection, it is clear that the differences between algorithms were greater than the differences between regular and unfolded datasets in terms of the resulting model error. Lasso yielded the lowest error and saw the greatest benefit from Markov unfolding ( ‚àí 0 . 61 ), but Ridge and XGBoost also saw small improvements. On average, the magnitude of the differences between the regular and Markov-unfolded variants of the datasets was small. This likely indicates limitations in the use of RFE to select features when the datasets are so wide 9 . Lasso was much more effective at leveraging the Markov unfolding than other algorithms, likely due to the sparse L1 regularisation serving as an additional layer of feature selection [   45   ]. The effectiveness of Markov unfolding as a technique is best illustrated by comparing the performance of Lasso across all dataset variants paired with their Markov-unfolded versions. This is shown in Fig. 16. Markov unfolding lowered the prediction error for Lasso across all dataset variants except the variant that underwent no imputation (and thus contained only 21 training observations). These results highlight the immense value of capturing historical data in each observation, provided the algorithm can overcome the increased dimensionality. (iterative_br_50, 0)  (iterative_br_50, 1)  (iterativesvd, 0)  (iterativesvd, 1)  (knn_3, 0)  (knn_3, 1)  (matrixfactorization, 0)  (matrixfactorization, 1)  (mice_15, 0)  (mice_15, 1)  (mice_3, 0)  (mice_3, 1)  (softimpute, 0)  (softimpute, 1)  (univ_imp_mean, 0)  (univ_imp_mean, 1)  (univ_imp_median, 0)  (univ_imp_median, 1)  (with_nans, 0)  (with_nans, 1) [Dataset, Markov unfolded]  6  7  8  9  10  11 RMSE  Lasso performance between 20 and 150 best features across datasets  Figure 16: Distributions of prediction error over all repeats for Lasso model for between 50 and 150 features, across all dataset variants. The narrow version of each dataset is shown in grey. The Markov-unfolded version of each dataset is shown in black. Boxplots span the interquartile range (IQR) of the distribution, with a line indicating the median. The whiskers extend to the minimum and maximum values observed.  9 Manual inspection of the RFE feature rankings for each dataset revealed a great deal of variation in the top features.  Page 35\n\nQuantified Sleep : 9   RESULTS AND DISCUSSION   Gianluca Truda  9.2   Comparison of imputation techniques  Regularised linear algorithms performed the best with imputed data, particularly for the matrix factorisation, KNN, MICE, iterative SVD, and univariate imputation strategies. Fig. 17, compares the best configurations for each algorithm-dataset pair in a heatmap of mean RMSE values over all 10 cross-validation iterations.   This presentation highlights the poor results of the Decision Tree across all datasets, as well as the notable results for Lasso and Ridge when using matrix factorisation, MICE, and univariate median imputation. It is also clear that using no imputation ( with_nans ) resulted in worse results for almost all the algorithms in both the Markov unfolded and pre-Markov treatments. DecisionTreeRegressor  RandomForestRegressor  XGBRegressor  Lasso  Ridge  NaiveRegressor  pre_markov_matrixfactorization  pre_markov_knn_3  pre_markov_mice_3  pre_markov_iterative_br_50  pre_markov_mice_15  pre_markov_univ_imp_mean  pre_markov_univ_imp_median  pre_markov_with_nans  pre_markov_softimpute  pre_markov_iterativesvd  matrixfactorization  knn_3  mice_3  iterative_br_50  mice_15  univ_imp_mean  univ_imp_median  with_nans  softimpute  iterativesvd  Figure 17: Heatmap of mean prediction error (RMSE) over datasets (rows) and algorithms (columns). Colour map: lower values are   colder   (dark blue), medium values are near white, and higher values are   hotter   (dark red). There were weak correlations between imputation distance (¬ß5.7) and prediction error for the tree-based algorithms: Decision Tree ( r   = 0 . 415 ), Random Forest ( r   = 0 . 367 ), XGBoost ( r   = 0 . 499 ). These are well above the (clearly spurious) correlation of the Na√Øve regressor ( r   =   ‚àí 0 . 203 ). The regularised linear models, however, both had negligible correlations: Lasso ( r   =   ‚àí 0 . 276 ), and Ridge ( r   = 0 . 107 ). These correlations were for mean RMSE under the optimal number of features for each dataset. Most of the imputed data was in the contiguous chunk of missing data from the AWARE source at the start of the project. This is visible in the top right of Fig. 13b. To better understand the different classes of imputation and why they produced such different imputation distance scores, it is helpful to look at some examples (Fig. 18). Page 36\n\nQuantified Sleep : 9   RESULTS AND DISCUSSION   Gianluca Truda  (a) Gaussian shape.   (b) Log-normal shape.  (c) Bimodal shape.   (d) Hybrid shape.  Figure 18: Comparison of feature distributions for three notable imputation techniques on different types of underlying distributions. The original data distribution is shown with a solid line. The distribution after imputing missing values is shown with dashed lines, coloured differently for each imputation technique. Fig. 18a: Median imputation copes best with a Gaussian-like distribution, as it minimises the average noise.   However, the multivariate techniques appear to capture much more variance in the data, which gives the final model more information (if it is relevant) to capture underlying relationships. Fig. 18b: A log-normal shape causes univariate imputation to overestimate most imputed values. Median imputation is much less sensitive to the long tail than mean imputation, which explains the lower imputation distance (and better predictive performance). Again, the multivariate imputation techniques appear to capture the underlying properties better. Fig. 18c: The dramatic changes (in location and behaviour) caused by the global pandemic resulted in many features having bimodal distributions.   These resulted in a great deal of error for the median imputation, as it fills values equivalent to the larger mode. In the case of location, this was precisely the wrong mode. Matrix factorisation did a superb job of inferring which values to fill based on other features, thus capturing the underlying distribution quite well. Iterative SVD tracked a similar curve, but also exhibited a failure mode of extremely long (and thin) tails. Note in this case that the feature was only defined on the continuous interval   [0 ,   1] , meaning that the iterative SVD went way beyond plausible imputations for some values. Whilst infrequent, these likely resulted in its much larger imputation distance (and lower predictive performance). Page 37\n\nQuantified Sleep : 9   RESULTS AND DISCUSSION   Gianluca Truda Fig.   18d: Some distributions were hybrids.   The standard deviation of daytime heart rate, for instance, should typically follow a weak power law. But the pandemic changes would have resulted in two different log-normal shapes combining. In this case, the univariate median imputation was overly biased to the peak of the curve, whilst the multivariate imputation techniques appeared to capture more underlying structure. In this specific example, the difference between the iterative SVD and matrix factorisation methods is notable.  9.3   Predictive performance  In general, Lasso had the best predictive results over the 10 cross-validation iterations, except for the outright-best configuration 10 . Most top results were Lasso regression on between 4 and 120 features with univariate median imputation and Markov unfolding (RMSE   6 . 68   ¬±   0 . 62   ‚àí   6 . 82   ¬±   0 . 68 ). However, other top contenders were Lasso with the matrix factorisation imputation and Markov unfolding with 50 to 110 features (RMSE   6 . 84   ¬±   0 . 59   ‚àí   6 . 85   ¬±   0 . 59 ). These had slightly higher error, but also slightly lower variance. Fig. 19 compares the performance of all the algorithms with respect to the number of features for two different datasets.   All algorithms other than the Decision Tree had much lower error when using an imputed dataset. Recall that only non-imputed observations were used to score the algorithms, allowing a direct comparison. Most imputation techniques resulted in more stable results and overall lower error. When there were missing values in the dataset, the median of the target (i.e. Na√Øve regressor) was a better predictor than any of the learning algorithms. When imputation was applied, however, the algorithms could better capture the relationships in the data and outperformed the na√Øve median estimate by a notable magnitude. On the whole, imputation provided the algorithms with vastly more training examples (and variance), resulting in a dramatic improvement in model quality.  (a) Dataset with missing values.   (b) Dataset with matrix factorisation imputation.  Figure 19: Comparison of model prediction error (RMSE) with respect to the number of features for a dataset with missing values (left) and a dataset where missing values were imputing using matrix factorisation (right). Coloured lines represent mean error over 10 independent resamplings. Shaded regions around each line indicate   ¬± 1 œÉ   of variance.  10 Ridge regression on 5 features from the univariate median imputation dataset with Markov unfolding had RMSE of   6 . 67   ¬±   0 . 59 .  Page 38\n\nQuantified Sleep : 9   RESULTS AND DISCUSSION   Gianluca Truda The number of features (which directly relates to the free parameters of the models) had a fairly mild influence on most algorithms. With the exception of Ridge, most algorithms actually reduced their out-of-sample error as the features were increased, instead of overfitting. Random Forest, Lasso, and XGBoost showed almost no trends for these error curves on the imputed dataset (Fig. 19b). This was likely due to regularising effects built into these three algorithms. Lasso uses L1 regularisation on   Œ≤ -parameters [ 45   ], Random Forest is a bagged ensemble ‚Äî which is known to reduce variance [50] ‚Äî and XGBoost has mild L2 regularisation by default [34]. XGBoost also uses default directions in trees to tolerate missing data: when a value is missing, trees automatically follow the paths that maximise gain [   34 ]. We can compare the built-in tolerance to explicit imputation for XGBoost by comparing the performance across Figures 19a and 19b. Close inspection shows that XGBoost performs much better with even a simple explicit imputation than when using its own built-in tolerance for missing values. This reiterates the value of explicit imputation for n-of-1 QS projects.  9.4   Model interpretation  A matrix-factorisation-imputed dataset with Markov unfolding was the dataset variant that yielded the most accurate and consistent predictions 11   with the Lasso algorithm. This combination was selected for the final model interpretation. 5-fold cross-validation of Lasso on all of the observations in the final dataset variant yielded an  R 2 -score of   0 . 546 , with points of greatest error being near the left tail of the distribution.   In other words, nights with very bad sleep were predicted as better than they were (see Fig. 20). A regularisation constant   Œ±   = 0 . 567   was found optimal. 30   40   50   60   70   80   90 Sleep score  30  40  50  60  70  80  90 Model prediction  Predicted sleep vs. actual sleep ( R 2   = 0.546)  Figure 20: Calibration curve for the best algorithm-dataset pairing after 5-fold cross-validation. The vertical axis is the predicted sleep score. The horizontal axis is the true sleep score. The points are coloured by their residuals (prediction error), with lighter colours being higher residuals.  9.4.1   Interpreting cross-validated RFE  RFE with 5-fold cross-validation on the Lasso base revealed that 36 features yielded the best average performance on the selected dataset variant.   The 36 top features are listed in the Appendices (Table 4).  11 Univatiate median imputation and matrix factorisation imputation had similar mean error on Lasso, but matrix factorisation was more consistent (lower   œÉ ). This is clear in Fig. 16.  Page 39\n\nQuantified Sleep : 9   RESULTS AND DISCUSSION   Gianluca Truda  9.4.2   Interpreting cross-validated Lasso  Œ≤ -parameters are sensitive to a number of factors (particularly with regularisation) [ 51   ]. To obtain robust estimates, 20 rounds of 5-fold cross-validation were performed. In each round, 5 different subsets of the final dataset variant were used to fit a Lasso model ( Œ±   = 0 . 567 ). This process resulted in 100 versions of the Lasso model trained on slightly different subsets of 80% of the final dataset variant. The 100 estimates of each   Œ≤ -parameter were used to construct distributions over all features and assess the robustness of the coefficient magnitudes. Because Lasso produces sparse   Œ≤ -parameters, those features which never yielded a coefficient with a magnitude greater than   0 . 5   were ignored. The distributions for the remaining 69 features are shown in Fig. 21. ‚àí\u0005   ‚àí\u0004   ‚àí\u0003   \u0002   \u0003 \u001b\u0012\u0013\u0013\u0016\u0010\u0016\u0012\u001a   importance  sleep_yesterday_duration  sleep_yesterday_midpoint_time  sleep_yesterday_score_total  sleep_yesterday_total  travelling  at_home  hk_act_9h  hk_act_12h  nomie_caf_net_hour_min  nomie_caf_net_hour_range  nomie_caf_net_hour_spread  rescue_shopping  melatonin_hour_taken  melatonin_hour_delta  melatonin_quantity  aw_loc_geohash_u173w_mean  aw_geohash9_num_unique  aw_geohash8_num_unique  aw_hr_heart_rate_std_eve  aw_hr_heart_rate_std_morn  sleep_yesterday_efficiency_-5day  sleep_yesterday_score_disturbances_-4day  sleep_yesterday_score_latency_-4day  sleep_yesterday_ready_score_hrv_balance_-3day  sleep_yesterday_ready_score_sleep_balance_-7day  sleep_yesterday_ready_score_temperature_-5day  at_home_-3day  is_weekend_-2day  hk_act_0h_-6day  hk_act_1h_-7day  hk_act_2h_-1day  hk_act_3h_-7day  hk_act_4h_-1day  hk_act_4h_-5day  hk_act_7h_-5day  hk_act_17h_-2day  hk_act_21h_-1day  nomie_alc_value_sum_-1day  nomie_alc_net_hour_min_-7day  nomie_caf_value_sum_-1day  nomie_caf_value_sum_-3day  nomie_caf_value_sum_-4day  rescue_software_dev_-6day  rescue_total_distracting_time_-3day  rescue_utilities_-3day  cbd_drops_-3day  cbd_hour_taken_-4day  cbd_hour_delta_-3day  zero_hours_-1day  zero_night_eating_-1day  zero_start_hour_delta_-1day  zero_hours_since_prev_fast_-1day  zero_hours_since_prev_fast_-3day  wol_added_to_anki_-3day  wol_made_music_-1day  wol_read_book_-4day  aw_activ_stationary_-7day  aw_calls_call_duration_count_-6day  aw_loc_geohash_u173w_mean_-7day  aw_weather_humidity_median_-6day  aw_weather_humidity_std_-6day  aw_weather_pressure_median_-3day  aw_weather_pressure_std_-3day  aw_weather_rain_median_-5day  aw_weather_wind_speed_std_-3day  aw_weather_wind_speed_std_-4day  aw_hr_heart_rate_median_night_-1day  aw_hr_heart_rate_std_day_-1day  aw_hr_heart_rate_std_night_-1day  Coefficient importance and its variability  Figure 21: Overview of   Œ≤ -parameter variability for features after 20 rounds of 5-fold cross-validation on the best algorithm-dataset pair. Only the features which had non-negligible   Œ≤   parameters (at least one   ‚â•   0 . 5 ) are shown. Each point is a   Œ≤ -parameter from one of the 100 fittings for that feature. Boxplots are superimposed to illustrate the median, interquartile ranges, and non-outlier extremes of each distribution. Page 40\n\nQuantified Sleep : 9   RESULTS AND DISCUSSION   Gianluca Truda Because all the features were scaled prior to fitting, we can directly compare the   Œ≤ -parameter distributions to get an indication of how relevant each feature is. As we see in Fig. 21, many of the   Œ≤ -parameters varied wildly in magnitude as a result of the subset of the data they were fit on. Perhaps the factors that influence sleep varied depending on circumstances ‚Äî such as which country I was in at the time, or what time of year it was. But it is more likely that these wide ranges indicate the very high level of noise in the dataset. The relatively low   R 2 -score makes this a strong possibility. Whilst the parameters varied greatly in magnitude, the direction was very consistent. Most of the features had   Œ≤ -parameters anchored at zero that varied into the positive or negative direction exclusively. This means that although those features were not always deemed relevant by the model, when they   were   deemed relevant, it was always in the same direction. A few of the features had  Œ≤ -parameters with distributions centred well away from zero. These are strong candidates for the most-important features, as they were deemed strongly-relevant by the Lasso model regardless of the subset of the data they were fit on.  9.4.3   Interpreting model with SHAP  SHAP analysis was applied to the optimised Lasso model trained on the final dataset variant. Using the cluster method 12 , SHAP computed the Shapley values for each feature-observation pair and used those to automatically rank the relevant features. These results are presented in a beeswarm plot in Fig. 22. We can see that the majority of features had an negative impact on sleep score, as low (blue) values gather on the right side whilst high (red) values gather on the left.   One interpretation of this is a   subtractive   model of sleep quality, where many factors can detract from a baseline of good sleep. For instance, fewer hours of nighttime eating the previous day ( zero_night_eating_-1day ) pushed the predicted sleep quality up (high SHAP value), whilst more hours of nighttime eating pulled the predicted sleep quality down (low SHAP value). Some features (like   aw_hr_heart_rate_std_morn   and   zero_hours_-1day ) appear to be centred at their mean, with Gaussian-like distributions, whilst others (like   melatonin_quantity   and  wol_read_book_-4day ) clearly reflect their discrete distributions.  12 Running SHAP on a ‚Äúblack box‚Äù model is computationally expensive ‚Äî especially when there are thousands of features to consider. In the case of linear or tree-based models, the computation can be massively accelerated by allowing SHAP to inspect internal parameters [   48   ]. Alternatively, a weighted   k -means clustering can be applied to the dataset prior to a ‚Äúblack box‚Äù SHAP analysis. This method was used, with   k   = 30 . This effectively summarised the data as 30 observations with features that were a weighted average of the points that comprised the cluster. Whilst this was primarily used to reduce the computation time for SHAP, it also served to smooth out a great deal of noise from the dataset and thus provide more robust results.  Page 41\n\nQuantified Sleep : 9   RESULTS AND DISCUSSION   Gianluca Truda ‚àí   ‚àí   ‚àí\b   ‚àí\u0006   \u0004   \u0006   \b  \u0012\u000f   \u0011\u0000(\u0014\u001e'\u0018\u0000 (impact on model output)  sleep_yesterday_ready_score_sleep_balance_-7day zero_hours_-1day rescue_software_dev_-6day aw_hr_heart_rate_std_eve aw_weather_wind_speed_std_-3day travelling aw_hr_heart_rate_std_morn wol_read_book_-4day cbd_hour_delta_-3day sleep_yesterday_score_latency_-4day aw_calls_call_duration_count_-6day nomie_caf_net_hour_spread hk_act_17h_-2day aw_weather_rain_median_-5day aw_geohash8_num_unique melatonin_hour_delta melatonin_quantity aw_weather_pressure_median_-3day aw_loc_geohash_u173w_mean_-7day sleep_yesterday_total aw_activ_stationary_-7day nomie_caf_net_hour_min aw_hr_heart_rate_std_night_-1day zero_night_eating_-1day aw_hr_heart_rate_median_night_-1day  Low High  Feature value  Figure 22: Beeswarm plot for interpreting the final Lasso model using SHAP. Each row is an explanatory feature, in descending order of importance. Each dot represents an observation for that feature. The colour of the dot indicates the observation‚Äôs value for that feature, with low values being cooler and high values being warmer. The horizontal axis is the SHAP value for each observation, indicating the magnitude and direction of its impact on the final model prediction. A common pattern in the beeswarm plot is a strongly-skewed distribution of values on one tail. For example,   nomie_caf_net_hour_spread   measures the variance in the hours when caffeine was consumed throughout the day. A low or medium spread results in a minor increase in sleep quality. However, a high spread results in anywhere from a small to very large decrease in sleep quality. Whilst this does reflect the underlying feature distribution (which is positively skewed), it shows that extreme values can have a large range of effect sizes on the final prediction. Finally, the colour gradients on almost all features change very smoothly with respect to the SHAP value. This reflects the inherently linear nature of the Lasso model used. However, SHAP can be used to interpret any black-box model [ 48 ] and could (in principle) illustrate non-linear relationships captured in the data. Page 42\n\nQuantified Sleep : 9   RESULTS AND DISCUSSION   Gianluca Truda One of the strengths of SHAP is its ability to perform contrastive explanations. We can therefore compare the beeswarm plots of the worst (score   <   50 ) and best (score   >   85 ) nights in the dataset (see Fig. 23). ‚àí   ‚àí   ‚àí\b   ‚àí\u0006   \u0004   \u0006  \u0013\u0010\u000e\u0012\u0000)\u0015\u001f(\u0019\u0000 (impact   on model output)  aw_calls_call_duration_count_-6day sleep_yesterday_score_latency_-4day hk_act_3h_-7day sleep_yesterday_ready_score_sleep_balance_-7day aw_hr_heart_rate_std_morn zero_hours_-1day wol_read_book_-4day melatonin_hour_delta hk_act_4h_-1day aw_geohash8_num_unique hk_act_2h_-1day cbd_hour_delta_-3day melatonin_quantity hk_act_9h sleep_yesterday_total aw_weather_pressure_median_-3day travelling aw_weather_rain_median_-5day nomie_caf_net_hour_spread aw_loc_geohash_u173w_mean_-7day nomie_caf_net_hour_min aw_activ_stationary_-7day aw_hr_heart_rate_std_night_-1day zero_night_eating_-1day aw_hr_heart_rate_median_night_-1day  Low High  Feature value  (a) Sleep score   <   50 ‚àí\u0005   \u0004   \u0005   \u0006   \u0007   \b  \u0012\u000f   \u0011\u0000(\u0014\u001e'\u0018\u0000 (impact on model output)  sleep_yesterday_ready_score_hrv_balance_-3day wol_made_music_-1day hk_act_12h_-6day aw_weather_rain_median_-5day nomie_caf_value_sum_-1day nomie_caf_net_hour_spread aw_weather_wind_speed_std_-3day zero_hours_-1day hk_act_17h_-2day aw_hr_heart_rate_std_eve wol_read_book_-4day aw_calls_call_duration_count_-6day aw_geohash8_num_unique rescue_software_dev_-6day melatonin_hour_delta sleep_yesterday_score_latency_-4day aw_loc_geohash_u173w_mean_-7day aw_weather_pressure_median_-3day melatonin_quantity nomie_caf_net_hour_min sleep_yesterday_total aw_activ_stationary_-7day zero_night_eating_-1day aw_hr_heart_rate_std_night_-1day aw_hr_heart_rate_median_night_-1day  Low High  Feature value   (b) Sleep score   >   85  Figure 23: Contrastive beeswarm plots for 21 nights with terrible sleep quality (left) and 11 nights with superb sleep quality (right). The main difference to note is the reordering of the features. This indicates that some features contributed far more on one extreme of the sleep quality distribution than on the other. For instance,  travelling   appears ninth in the low-scoring nights (23a) but not at all in the high-scoring nights (23b). Moreover, we can see from the distribution of points that not all nights of poor sleep were due to   travelling , but that it was to blame for poor sleep quality when it did occur.  9.4.4   Combined interpretation  The top features from the RFE-based selection, the cross-validated Lasso   Œ≤ -parameters, and SHAP interpretation were combined to find standout features. These can inform future investigations and n-of-1 experiments. By combining the top features from all three interpretation strategies, 16 features were found to be consistent and notable. They are listed along with their full descriptions and relevant importance measures in Table 3. Page 43\n\nQuantified Sleep : 9   RESULTS AND DISCUSSION   Gianluca Truda  Feature name   r   Œ≤   | S |   Description  aw_hr_heart_rate_median_night_-1day   -0.46   -2.17   1.84   Median heart rate in the evening, 1 day prior aw_hr_heart_rate_std_night_-1day   -0.33   -1.21   0.94   Std. heart rate in the evening, 1 day prior zero_night_eating_-1day   -0.44   -0.96   0.99   Hours of eating after sunset, 1 day prior nomie_caf_net_hour_min   -0.02   0.77   0.71   Hour of first caffeine consumption aw_activ_stationary_-7day   0.20   0.75   0.67   Time spent stationary, 7 days prior aw_loc_geohash_u173w_mean_-7day   -0.29   -0.63   0.44   Time in location u173w, 7 days prior melatonin_quantity   -0.21   -0.54   0.47   Quantity of melatonin consumed travelling   -0.21   -0.49   0.17   Whether or not I was travelling long distances sleep_yesterday_total   -0.04   -0.39   0.56   Total time spent sleeping the previous day aw_weather_pressure_median_-3day   0.21   0.39   0.43   Median weather pressure, 3 days prior melatonin_hour_delta   -0.20   -0.37   0.30   The hour melatonin was consumed hk_act_17h_-2day   0.16   0.35   0.23   Activity levels at 17h00, 2 days prior aw_geohash8_num_unique   -0.16   -0.17   0.25   The no. unique level-8 geohashes visited cbd_hour_delta_-3day   -0.25   -0.32   0.21   The hour CBD oil was consumed, 3 days prior wol_read_book_-4day   -0.21   -0.18   0.22   Whether I read a book, 4 days prior zero_hours_-1day   0.35   0.20   0.16   Hours of intermittent fasting, 1 day prior  Table 3: Combined set of model interpretations, showing the 16 most predictive features (roughly ordered) and a written description of what each feature means. The   r   column indicates the Pearson correlation coefficient between the feature and the target in the dataset. The   Œ≤   column indicates the associated   Œ≤ -parameter in the final Lasso model. The   | S |   column indicates the mean absolute Shapley values (over all observations) for each feature after interpretation with SHAP. We can see from the suffixes in Table 3 that 11 of the 16 features were lagged values generated through Markov unfolding 13 . A total of 5 have a 1-day lag, 2 have a 7-day lag, and the remaining 4 have 2-4 day lags. This suggests that history is an important factor in sleep quality. In particular, the previous day and last week on the same day have notable impact. This justifies the need for techniques like Markov unfolding which incorporate history into each observation. It also hints that much of the value of Markov unfolding comes from capturing information from 1 day and one week prior. It is interesting to compare the original correlations ( r -values), the Lasso   Œ≤ -parameters, and the Shapley values for each of these features (see Table 3). All but one of the   r -values have the same positivity as the   Œ≤ -parameters. The exception is   nomie_caf_net_hour_min , which had almost no correlation ( r   =   ‚àí 0 . 02 ). This tells us that correlation analysis correctly identified the direction that each feature ultimately affected sleep quality. However, the magnitudes of these correlations are fairly small and would not have been sufficient to select these 16 features from the full set, based only on correlation (Fig. 7). Most notably,   nomie_caf_net_hour_min   and   sleep_yesterday_total  are important features but displayed negligible correlation to sleep quality. The magnitudes of the   Œ≤ -parameters and the Shapley values correspond closely, except for the   travelling   feature, which SHAP deemed as far less important on average. This is likely a result of SHAP (correctly) down-weighting the travelling feature, as it only has a non-zero value for a handful of observations. This indicates that modelling the data helped isolate which features most impacted sleep quality in a way that simple correlation analysis would not have been capable of. Overall, the results of model interpretation track the direction of simple correlation, but not the magnitude.  13 Recall that the prefix   sleep_yesterday_   is used for a 1-day lag on the   oura_   features to make it easier to remember to remove same-day sleep features that constitute a data leak.   So   sleep_yesterday_total   can be interpreted as   oura_sleep_total_-1day  Page 44\n\nQuantified Sleep : 9   RESULTS AND DISCUSSION   Gianluca Truda  9.5   Feature explanation  Some of the final 16 features are expected. Travelling, eating windows, previous sleep, and melatonin are all known to affect sleep quality [   13 ,   15 ,   14 ,   12 ]. But the direction of some of these effects was unexpected. For instance, melatonin consumption is associated with a   decrease   in sleep quality, when research suggests it should have be increase [ 52 ,   53 ]. The previous night‚Äôs sleep quantity also has an unexpected   decrease   on the present night‚Äôs sleep quality. That implies that there is some kind of trade-off between sleep   quality   and sleep   quantity   on successive nights. These unexpected directions might just be artefacts of the study design, but could also indicate idiosyncrasies in my sleep patterns. Through the process of modelling and interpreting, such unexpected connections are highlighted for future n-of-1 studies. On the other hand, some of the final 16 features were very much unexpected. Specifically, the lag in the features. It is not intuitive that pleasure reading and barometric pressure from many days prior could affect the current night‚Äôs sleep. It is also strange that location changes from an entire week prior are still predictive of the current night‚Äôs sleep. One explanation is that these features merely correlate with other (unmeasured) variables that influence sleep quality, and that this is being captured by the model [   44 ]. Another (complementary) explanation is that the sparsity effect of the Lasso model [ 45 ] caused it to discard all but one feature from each set of highly-correlated features. For instance,   wol_read_book   is highly correlated with a number of Oura-based features, as well as computer usage, location, alcohol consumption, and afternoon activity (Fig. 8a). Given that the Lasso model already includes correlated features for the current day and previous day, it gains no predictive value by including   wol_read_book   with a lag of 0 or 1.   In fact, the L1 regularisation would mean that this extra feature imposes a penalty on the model [ 45 ].   But, including   wol_read_book_-4day   adds information from   earlier   days. And because this reading feature is highly correlated with many other predictive features, it captures a great deal of predictive information from earlier days. This line of reasoning suggests that it is not specifically these 16 features that are most-important for understanding sleep quality. Instead, it is clusters of features that are correlated with these 16 that are of importance. A thorough analysis (which is beyond the scope of this paper) would use results from Table 3 and the dendrogram from Fig.   8 together to build a comprehensive understanding of the relationships affecting sleep quality 14 . The 16 final features are a much reduced subset of the 308 initial features that were explored throughout this observational study, yet they explain the majority of the variation in sleep quality (when controlling for all the other features). The sum of the SHAP scores for the 16 final features is   8 . 59 , while the sum of the SHAP scores for the other 1505 Markov-unfolded features is   2 . 31 . The next step is to design a series of   interventional   n-of-1 QS experiments to explore whether each of these factors is causal and what the effect sizes are. The design and implementation of such studies is outside the scope of this paper, but is well-covered in other literature [7, 54, 2].  14 Indeed, SHAP does include hierarchical interpretation techniques, but they rely on iteratively fitting XGBoost models on different subsets of the features, which is far too computationally expensive for large numbers of features.  Page 45\n\nQuantified Sleep : 10   LIMITATIONS AND FUTURE WORK   Gianluca Truda  10   Limitations and future work  10.1   Ground truth  The lack of accurate ‚Äúground truth‚Äù was a theme at all levels. For instance, the Oura ring ‚Äî whilst a leader in wearable sleep trackers ‚Äî is still vastly less accurate than research-grade polysomnography equipment. Because of the opaque nature of sleep [   12 ], even polysomnography is only an estimation [   16 ]. All of this added a great deal of noise to the target. This made it harder to assess the quality of predictive models. Those models also had the challenge of noisy sensor data and biased event logs as features. Analysis of the underlying distributions of features in the dataset revealed some potential issues. Whilst many biological and environmental factors produce near-normal distributions [   55   ], they were often very skewed or fat-tailed in this dataset. There were also a number of strongly-bimodal distributions caused by the dramatic changes during the first wave of the pandemic.   These distributions are ‚Äúdodgy‚Äù because they deviate [ 28   ] from the perfectly-Gaussian assumptions made by many statistical techniques and learning algorithms [25, 26]. The real-world nature of the dataset meant that there was no ground truth against which to directly evaluate the feature engineering, hierarchical correlation, imputation, Markov unfolding, and model interpretation techniques.   This reduced the power of the evidence presented by the results of this study. Future work could apply the methods of this study to ‚Äúeasier‚Äù datasets and modelling problems to evaluate them in isolation.  10.2   Generalisability  Because this was an n-of-1 study, most results are unlikely to generalise to other individuals. Moreover, many factors ‚Äî the specifics of the tracking tools used, environment, personal behaviour, social factors, pandemic consequences, etc. ‚Äî are likely to vary over time. This means that many of the results of this study may not even generalise to   me   going forward. This is definitely true of specific findings, like the effect of melatonin on my sleep quality. But it may also be true of the results about different techniques used. Whilst Lasso and matrix-factorisation-imputation worked well on this specific dataset, that may not generalise to other n-of-1 QS datasets. Indeed, those who replicate these approaches should also replicate the variety of techniques used. By casting a wide ‚Äúnet‚Äù of possible techniques, it is more likely to find ones that apply best to the specific dataset being modelled.  10.3   Markov unfolding  Markov unfolding was only notably effective in the regularised linear algorithms. This may be because the current implementation increased the dimensionality too much ‚Äî outweighing the value of the historical information. The linear algorithms, especially Lasso, likely dealt with this better because of their regularisation helping prioritise the most important features [   25 ,   45   ]. The predominance of 1-day and 7-day lagged features in the final model interpretation suggests that there may be more sophisticated ways to apply Markov unfolding to maximise the historical information whilst minimising the increase in dimensionality. For example, future work could explore the use of rolling aggregations for the 2-6 day lags. Instead of feature   j   becoming 8 features, it would only become 5:   j ,   j ‚àí 1 ,   j ‚àí 7 ,   j Œº , and   j œÉ   . This captures the information-rich previous day, the cyclical weekly patterns of seven days prior, and a rolling distribution of ‚Äúthe last few days‚Äù. This would also help make features more intuitive and models more interpretable. Page 46\n\nQuantified Sleep : 10   LIMITATIONS AND FUTURE WORK   Gianluca Truda  10.4   Imputation  There were three limitations to the imputation strategy of this paper. Firstly, no ground-truth of error levels across imputation techniques existed for this dataset. The custom distance metric was used as a proxy for the magnitude of change caused by imputation, but this did not directly help select the best-suited imputation algorithm or hyperparameters. Future work can first evaluate imputation techniques on   synthetic   missing values from a sample of the same dataset. The error of the re-imputed values could then be used to select and optimise the imputation method for the dataset. This was beyond the scope of this study, as generating the synthetic missing values in a way that generalises to   real   missing data is a complex topic ‚Äî MAR, MNAR, and MCAR effects (¬ß5.1) all need to be synthesised. Moreover, the fact that there were only 61 observations in the data that did not need imputation would have meant a very biased sample and may have invalidated the synthetic approach on this specific dataset. Secondly, although all features used in imputation were numeric, a subset had an underlying binary structure. In principle, the imputation techniques used should only apply to continuous features [   31 ].   In practise, there were sufficiently few binary features and sufficiently few missing values within them that this was   probably   negligible. Future work could investigate automatic filtering methods for excluding such features. Thirdly, a large number of the imputed values were from a contiguous ‚Äúchunk‚Äù in the AWARE- sourced features from prior to my use of AWARE. This chunk can be clearly seen in the top right of Fig. 13b. It is likely that imputing these values (especially with simpler univariate techniques) resulted in a great deal of additional noise for those features. That may have affected the results in a number of different ways. A key trade-off in this study was between number of observations and number/quality of features. The decision to impute over this large missing chunk was part of that trade-off. Future work could investigate the effects of imputing large chunks of contiguous values on final model interpretation.  10.5   Interpretation  One of the major advantages of SHAP over   Œ≤ -value analysis is that it assigns Shapley values to each feature for each observation, allowing for a nuanced distributional analysis (e.g. Fig. 23). By using a linear final model (Lasso), non-linear feature effects were not able to show up in the SHAP results. It is possible that there were no relevant non-linearities to the most predictive features, but by constraining the scope of this study to a single (linear) model, it became impossible to know. Future work could compare SHAP interpretations over different models and develop techniques for reconciling multiple interpretations.  10.6   Hierarchical clustering  The hierarchical clustering of feature correlations offers many advantages to projects of this nature. Whilst it was used to aid model interpretation, it was under-utilised in feature selection. This was mainly due to it being developed towards the end of this study, when it was too late to overhaul the data pipeline. Future work could (1) validate the hierarchical correlational method‚Äôs efficacy in finding related features, and (2) explore the use of hierarchical correlation for feature selection. The hierarchical correlation of features may offer a better trade-off between accuracy and performance for automated feature selection than RFE or exhaustive search. This is especially relevant to n-of-1 QS projects where most features are weakly correlated to most other features and very weakly correlated with the target [3, 1]. Page 47\n\nQuantified Sleep : 11   CONCLUSIONS   Gianluca Truda  11   Conclusions  This paper presented a case study in how to conduct observational n-of-1 Quantified-Self (QS) research, combining relevant techniques from statistics and machine learning to obtain robust and interpretable results. Several methods were presented for combining heterogeneous data sources and engineering day- level features from different data types and frequencies, including manually-tracked event logs and automatically-sampled weather and geo-spatial data. The resulting dataset was thoroughly analysed ‚Äî for outliers, normality, (auto)correlations, stationarity, and missing data ‚Äî and cleaned accordingly. A notable inclusion was the use of hierarchical clustering of the correlation matrix to identify groups of correlated features. The missing data was organised and filled using a combination of knowledge-based and statistical techniques. The latter included several different imputation methods that have been presented in the literature. Regularised linear algorithms (Lasso and Ridge) performed the best with imputed data, particularly for the matrix factorisation, KNN, MICE, iterative SVD, and univariate imputation strategies. The use of imputation saved hundreds of observations from being discarded and improved overall performance of all the algorithms except the plain Decision Tree. To collapse the time series into a collection of independent observations, the Markov unfolding technique was presented. This added lagged copies of features to each observation to incorporate values from recent history for each engineered feature. Markov unfolding improved the predictive performance of Lasso dramatically, but for other algorithms the improvement was less pronounced. This was likely because the benefit of the additional information traded off against the added burden of much higher dimensionality. Lasso likely performed best because L1 regularisation allowed it to effectively sift through the greater number of features. The paper suggests ways Markov unfolding could be made more feature efficient in future work. From the extensive grid-search, a low-error, low-variance model and dataset combination was selected ‚Äî Lasso regression on a Markov-unfolded version of the dataset which had undergone matrix factorisation imputation. The final model was interpreted in two key ways: (1) by inspecting the internal   Œ≤ -parameters, and (2) using the SHAP framework, which builds local explanatory models for each observation. By repeatedly re-training the Lasso model on different subsets of the dataset, distributions of   Œ≤ -parameters were generated. Features with consistently-large   Œ≤ -coefficients were deemed   globally   important. This was combined with SHAP‚Äôs   situational   assessment of the importance of each feature with respect to each observation ‚Äî which allowed contrastive analysis of extreme examples of sleep quality. These two interpretation techniques were combined to produce a list of the 16 most-predictive features. By comparing the list of predictive features to the hierarchy of correlated features, it became apparent that Lasso‚Äôs ability to learn sparse parameters helped it to find features that were in different correlational clusters, thus making the best use of all the information in the dataset without overfitting. Unfortunately, this made it more complex to infer a   descriptive   model of sleep behaviour. Overall, predictive modelling helped detect relationships in the dataset that simple univariate analysis would not have found. By identifying the factors that most affect sleep, this study showed that it is possible to use an   observational   study to greatly reduce the number of features that need to be considered in   interventional   n-of-1 QS research. Page 48\n\nQuantified Sleep : REFERENCES   Gianluca Truda  12   Practicalities  12.1   Code and data availability  The Python 3 code for methods presented in this study is publicly available as a collection of Jupyter notebooks. These show outputs and documentation inline with the code, making it easier to understand the flow of this study in a sequential order. The code is available under a GNU General Public License (GPLv3), allowing modification and re-use. For the sake of personal data privacy, some outputs and code are redacted from the published notebooks. The dataset from this study will not be made available, as it contains extensive personal information. My current ongoing research into generative differential privacy hopes to find long-term solutions to this trade-off between data privacy and open science. If a version of the dataset does become available in future, it will be made available via the project repository (github.com/gianlucatruda/quantified- sleep).  12.2   Replicating this work  Other QS enthusiasts are encouraged to apply these techniques to their future projects and report on their findings. Much of the progress in this niche of n-of-1 QS occurs outside of the formal scientific literature. One of the goals of this paper was to help bridge the gap between community rules-of-thumb and end-to-end studies. As mentioned, the dataset is not available for privacy reasons.   However, much of the code in the Jupyter notebooks should generalise to other n-of-1 QS projects, provided the sources are similar. Those wishing to replicate the methodology of this study on their own data will need to write their own   ingesters . These are simple Python functions that take in an exported data file (e.g. CSV, JSON, etc.) and return a Pandas dataframe with observations as rows and features as columns. Most of the code was written in a way that minimises the number of changes required to adapt to different sources. Indeed, during the course of this study, I added and updated sources a number of times, finding that much of the code was robust to these changes. Current details of the structure of the code and how to best modify it for your own projects can be found in the repository documentation.  References  [1]   Melanie Swan. The quantified self: Fundamental disruption in big data science and biological discovery.   Big data , 1(2):85‚Äì99, 2013. [2]   Eun Kyoung Choe, Nicole B Lee, Bongshin Lee, Wanda Pratt, and Julie A Kientz. Under- standing quantified-selfers‚Äô practices in collecting and exploring personal data. In   Proceedings of the SIGCHI conference on human factors in computing systems , pages 1143‚Äì1152, 2014. [3]   Mark Hoogendoorn and Burkhardt Funk.   Machine Learning for the Quantified Self . Springer, 2018. ISBN 00278424. doi: 10.1073/pnas.96.11.6558. [4]   Elizabeth O Lillie, Bradley Patay, Joel Diamant, Brian Issell, Eric J Topol, and Nicholas J Schork. The n-of-1 clinical trial: the ultimate strategy for individualizing medicine?   Personal- ized medicine , 8(2):161‚Äì173, 2011. Page 49\n\nQuantified Sleep : REFERENCES   Gianluca Truda [5]   Wes McKinney et al. pandas: a foundational python library for data analysis and statistics.  Python for High Performance and Scientific Computing , 14(9):1‚Äì9, 2011. [6]   Amos Tversky and Daniel Kahneman. Judgment under uncertainty: Heuristics and biases.  science , 185(4157):1124‚Äì1131, 1974. [7]   R Kravitz, N Duan, I Eslick, NB Gabler, HC Kaplan, EB Larson, et al. Design and imple- mentation of n-of-1 trials: a user‚Äôs guide.   Agency for healthcare research and quality, US Department of Health and Human Services , 2014. [8]   Scott Fortmann-Roe. Understanding the bias-variance tradeoff.   URL: http://scott. fortmann- roe. com/docs/BiasVariance. html (h√§mtad 2019-03-27) , 2012. [9]   Douglas M Hawkins. The problem of overfitting.   Journal of chemical information and computer sciences , 44(1):1‚Äì12, 2004. [10]   Vladimir Vapnik.   The nature of statistical learning theory . Springer science & business media, 2013. [11]   Brett Beaulieu-Jones. Machine learning for structured clinical data. In   Advances in Biomedical Informatics , pages 35‚Äì51. Springer, 2018. [12]   Matthew Walker.   Why we sleep: Unlocking the power of sleep and dreams . Simon and Schuster, 2017. [13]   Marie-Pierre St-Onge, Anja Mikic, and Cara E Pietrolungo. Effects of diet on sleep quality.  Advances in Nutrition , 7(5):938‚Äì949, 2016. [14]   Shailesh Bihari, R Doug McEvoy, Elisha Matheson, Susan Kim, Richard J Woodman, and Andrew D Bersten. Factors affecting sleep quality of patients in intensive care unit.   Journal of Clinical Sleep Medicine , 8(3):301‚Äì307, 2012. [15] Teofilo Lee-Chiong.   Sleep medicine: Essentials and review . Oxford University Press, 2008. [16]   Katherine A Kaplan, Jason Hirshman, Beatriz Hernandez, Marcia L Stefanick, Andrew R Hoffman, Susan Redline, Sonia Ancoli-Israel, Katie Stone, Leah Friedman, Jamie M Zeitzer, et al. When a gold standard isn‚Äôt so golden: Lack of prediction of subjective sleep quality from sleep polysomnography.   Biological psychology , 123:37‚Äì46, 2017. [17]   Oura. The accuracy of the oura ring ‚Äì oura help, . URL   https://support.ouraring.com/hc/ en-us/articles/360055999894-The-Accuracy-of-The-Oura-Ring . Accessed: 2021-04-05 11:37:23. [18]   Hannu Kinnunen, Aleksi Rantanen, Tuomas Kentt√§, and Heli Koskim√§ki. Feasible assessment of recovery and cardiovascular health: accuracy of nocturnal hr and hrv assessed via ring ppg in comparison to medical grade ecg.   Physiological measurement , 41(4):04NT01, 2020. [19]   Oura.   How accurate is oura‚Äôs respiratory rate?   - the pulse blog,   .   URL   https:// blog.ouraring.com/how-accurate-is-ouras-respiratory-rate/ .   Accessed: 2021-04-05 11:38:00. [20]   Massimiliano de Zambotti, Leonardo Rosas, Ian M Colrain, and Fiona C Baker. The sleep of the ring: comparison of the ¬Ø oura sleep tracker against polysomnography.   Behavioral sleep medicine , 17(2):124‚Äì136, 2019. Page 50\n\nQuantified Sleep : REFERENCES   Gianluca Truda [21]   Nicholas IYN Chee, Shohreh Ghorbani, Hosein Aghayan Golkashani, Ruth LF Leong, Ju Lynn Ong, and Michael WL Chee. Multi-night validation of a sleep tracking ring in adolescents compared with a research actigraph and polysomnography.   Nature and Science of Sleep , 13: 177, 2021. [22]   Rob ter Horst. Oura ring scientific sleep test (review) - the quantified scientist (youtube). URL   https://www.youtube.com/watch?v=atWcp6FmnbE . Accessed: 2021-04-05 11:38:00. [23]   Gustavo Niemeyer. Tips & Tricks - geohash.org. URL   http://geohash.org/site/tips.html . [24]   Chris Veness. Movable Type Scripts - Geohash. URL   https://www.movable-type.co.uk/ scripts/geohash.jpg . [25]   Andriy Burkov.   The hundred-page machine learning book , volume 1. Andriy Burkov Canada, 2019. [26] Christopher M Bishop.   Pattern recognition and machine learning . springer, 2006. [27]   Christoph Molnar.   Interpretable Machine Learning . 2019.   https://christophm.github.io/ interpretable-ml-book/ . [28]   Nassim Nicholas Taleb.   Statistical consequences of fat tails:   Real world preasymptotics, epistemology, and applications.   arXiv preprint arXiv:2001.10488 , 2020. [29]   Peter J Brockwell, Peter J Brockwell, Richard A Davis, and Richard A Davis.   Introduction to time series and forecasting . Springer, 2016. [30]   Said E Said and David A Dickey. Testing for unit roots in autoregressive-moving average models of unknown order.   Biometrika , 71(3):599‚Äì607, 1984. [31]   Roderick JA Little and Donald B Rubin.   Statistical analysis with missing data , volume 793. John Wiley & Sons, 2019. [32]   Aleksey Bilogur.   Missingno:   a missing data visualization suite.   Journal of Open Source Software , 3(22):547, 2018. [33]   Hyun Kang. The prevention and handling of the missing data.   Korean journal of anesthesiology , 64(5):402, 2013. [34]   Tianqi Chen and Carlos Guestrin. Xgboost: A scalable tree boosting system. In   Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining , pages 785‚Äì794, 2016. [35]   Reza Sahraeian. Reza sahraeian - the industrial challenge of missing data | pydata eindhoven 2020 (youtube). URL   https://www.youtube.com/watch?v=M4CtBKrp59w . Accessed: 2021- 04-27 14:06:00. [36]   Jianhua Lin.   Divergence measures based on the shannon entropy.   IEEE Transactions on Information theory , 37(1):145‚Äì151, 1991. [37]   Fabian Pedregosa, Ga√´l Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al. Scikit-learn:   Machine learning in python.   the Journal of machine Learning research , 12: 2825‚Äì2830, 2011. [38]   Alex Rubinsteyn and Sergey Feldman. fancyimpute: An imputation library for python. URL  https://github.com/iskandr/fancyimpute . Page 51\n\nQuantified Sleep : REFERENCES   Gianluca Truda [39]   S van Buuren and Karin Groothuis-Oudshoorn. mice: Multivariate imputation by chained equations in r.   Journal of statistical software , pages 1‚Äì68, 2010. [40]   Rahul Mazumder, Trevor Hastie, and Robert Tibshirani. Spectral regularization algorithms for learning large incomplete matrices.   The Journal of Machine Learning Research , 11:2287‚Äì2322, 2010. [41]   Olga Troyanskaya, Michael Cantor, Gavin Sherlock, Pat Brown, Trevor Hastie, Robert Tib- shirani, David Botstein, and Russ B Altman.   Missing value estimation methods for dna microarrays.   Bioinformatics , 17(6):520‚Äì525, 2001. [42]   G√°bor Tak√°cs, Istv√°n Pil√°szy, Botty√°n N√©meth, and Domonkos Tikk. Matrix factorization and neighbor based algorithms for the netflix prize problem. In   Proceedings of the 2008 ACM conference on Recommender systems , pages 267‚Äì274, 2008. [43]   Stuart Russel, Peter Norvig, et al.   Artificial intelligence:   a modern approach .   Pearson Education Limited London, 2013. [44] Miguel A Hern√°n and James M Robins. Causal inference, 2010. [45]   Robert Tibshirani. Regression shrinkage and selection via the lasso.   Journal of the Royal Statistical Society: Series B (Methodological) , 58(1):267‚Äì288, 1996. [46]   Xue-wen Chen and Jong Cheol Jeong.   Enhanced recursive feature elimination.   In   Sixth International Conference on Machine Learning and Applications (ICMLA 2007) , pages 429‚Äì 435. IEEE, 2007. [47]   Isabelle Guyon, Jason Weston, Stephen Barnhill, and Vladimir Vapnik. Gene selection for cancer classification using support vector machines.   Machine learning , 46(1):389‚Äì422, 2002. [48]   Scott M Lundberg and Su-In Lee. A unified approach to interpreting model predictions. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors,   Advances in Neural Information Processing Systems 30 , pages 4765‚Äì4774. Curran Associates, Inc., 2017. [49]   Lloyd S Shapley. A value for n-person games.   Contributions to the Theory of Games , 2(28): 307‚Äì317, 1953. [50]   Peter B√ºhlmann, Bin Yu, et al. Analyzing bagging.   The Annals of Statistics , 30(4):927‚Äì961, 2002. [51]   Scikit-Learn. Common pitfalls in interpretation of coefficients of linear models ‚Äî scikit-learn 0.24.1   documentation.   URL   https://scikit-learn.org/stable/auto_examples/ inspection/plot_linear_model_coefficient_interpretation.html?highlight= interpretability . Accessed: 2021-04-15. [52]   Ingeborg M van Geijlswijk, Hubert PLM Korzilius, and Marcel G Smits. The use of exogenous melatonin in delayed sleep phase disorder: a meta-analysis.   Sleep , 33(12):1605‚Äì1614, 2010. [53]   Derk-Jan Dijk and Christian Cajochen.   Melatonin and the circadian regulation of sleep initiation, consolidation, structure, and the sleep eeg.   Journal of biological rhythms , 12(6): 627‚Äì635, 1997. [54]   Azure Grant and Gary Wolf. White paper: Design and implementation of participant-led research in the quantified self community. 2019. [55]   Aidan Lyon. Why are normal distributions normal?   The British Journal for the Philosophy of Science , 65(3):621‚Äì649, 2014. Page 52\n\nQuantified Sleep : A   APPENDICES   Gianluca Truda  A   Appendices  Figure 24: Pairplot matrix over 4 of the most important sleep features. In each row, a feature comprises the vertical axis. In each column a feature comprises the horizontal axis. In cell   i, j , a scatterplot and regression line is shown for   i   vs   j . In cell   i, i , the histogram of feature   i   is shown instead of a redundant scatterplot.  Feature name  sleep_yesterday_midpoint_time sleep_yesterday_rmssd sleep_yesterday_score sleep_yesterday_score_alignment sleep_yesterday_score_deep sleep_yesterday_score_disturbances sleep_yesterday_score_efficiency sleep_yesterday_score_latency travelling hk_act_9h nomie_caf_net_hour_min nomie_caf_net_hour_range nomie_caf_net_hour_spread melatonin_quantity aw_geohash8_num_unique hk_act_2h_-1day hk_act_4h_-1day hk_act_7h_-5day hk_act_17h_-2day hk_act_night_mean_-1day nomie_caf_value_sum_-4day cbd_hour_delta_-3day zero_hours_-1day zero_night_eating_-1day wol_intensive_workout_-2day wol_read_book_-4day aw_activ_stationary_-7day aw_loc_geohash_u173w_mean_-7day aw_weather_pressure_median_-3day aw_weather_rain_median_-5day aw_weather_wind_speed_median_-5day aw_weather_wind_speed_std_-3day aw_hr_heart_rate_median_night_-1day aw_hr_heart_rate_std_day_-1day aw_hr_heart_rate_std_morn_-7day aw_hr_heart_rate_std_night_-1day  Table 4: The 36 most-predictive features (in arbitrary order) after   5 -fold cross-validated recursive feature elimination (RFE) for a Lasso regression model on a markov-unfolded-matrix-factorised variant of the dataset. Page 53",
      "embedding": [
        -0.018114594742655754,
        -0.003416710300371051,
        0.09115419536828995,
        0.14242032170295715,
        0.042088888585567474,
        0.02056185156106949,
        -0.039371307939291,
        -0.008450155146420002,
        0.04983725771307945,
        0.005002560093998909,
        -0.06877303123474121,
        -0.024180304259061813,
        0.017043082043528557,
        0.07002034038305283,
        -0.04743185266852379,
        -0.050560832023620605,
        0.03641814738512039,
        -0.014155464246869087,
        -0.04889320954680443,
        -0.03368676081299782,
        0.06350050866603851,
        0.056483104825019836,
        0.0644184798002243,
        0.107220858335495,
        -0.010361545719206333,
        0.06262774765491486,
        0.026787418872117996,
        -0.01709868758916855,
        -0.08912116289138794,
        -0.005528618115931749,
        -0.03836815804243088,
        0.04721425473690033,
        0.015611863695085049,
        -0.05216096714138985,
        0.009885410778224468,
        0.037488728761672974,
        0.029241785407066345,
        0.07442563027143478,
        -0.07187188416719437,
        0.013399685733020306,
        -0.008122737519443035,
        -0.029657037928700447,
        0.02770734578371048,
        -0.032292596995830536,
        0.031323302537202835,
        -0.017270686104893684,
        -0.07234473526477814,
        -0.08390044420957565,
        -0.07650870829820633,
        0.00906311348080635,
        -0.059449367225170135,
        0.012301314622163773,
        -0.01747044362127781,
        0.07937435060739517,
        0.04757818579673767,
        0.013022804632782936,
        -0.03549238294363022,
        -0.016849976032972336,
        0.02508547157049179,
        0.017871547490358353,
        -0.0101098557934165,
        0.006766264792531729,
        -0.01972254551947117,
        -0.014804132282733917,
        0.05709323287010193,
        0.10496823489665985,
        -0.10334012657403946,
        0.03414624556899071,
        0.013364779762923717,
        0.001738715567626059,
        -0.10319101810455322,
        -0.02915647253394127,
        -0.07186197489500046,
        0.041345953941345215,
        -0.02601492963731289,
        0.09353190660476685,
        0.0914711132645607,
        0.021546341478824615,
        0.07945474237203598,
        -0.025000223889946938,
        -0.005605447571724653,
        0.04653045907616615,
        0.002561471424996853,
        -0.012644533067941666,
        0.043956976383924484,
        -0.007591264322400093,
        0.08399873226881027,
        0.12269902974367142,
        -0.05758679285645485,
        -0.02153584733605385,
        0.015985334292054176,
        0.022375954315066338,
        -0.011921570636332035,
        -0.03221116214990616,
        0.08737863600254059,
        0.006905234884470701,
        -0.002756736474111676,
        -0.018086059018969536,
        0.041397757828235626,
        0.010114425793290138,
        0.027344105765223503,
        0.08384963870048523,
        0.025388548150658607,
        -0.0009838686091825366,
        0.016599001362919807,
        0.012523063458502293,
        0.0050748237408697605,
        -0.023316439241170883,
        0.02626286819577217,
        -0.022548306733369827,
        -0.08964330703020096,
        0.014130587689578533,
        -0.005041067488491535,
        -0.03993438929319382,
        0.08461108058691025,
        0.0670146718621254,
        0.015030443668365479,
        0.07670586556196213,
        0.026699285954236984,
        0.07329616695642471,
        0.06294552236795425,
        -0.05471065640449524,
        0.07011479884386063,
        -0.016255909577012062,
        0.07244950532913208,
        -0.013680546544492245,
        -0.13305822014808655,
        3.392754039671519e-33,
        0.025502754375338554,
        -0.041455548256635666,
        0.0316116064786911,
        0.01762491464614868,
        0.04219520092010498,
        -0.0948135256767273,
        -0.06381615996360779,
        0.016036219894886017,
        0.08629753440618515,
        0.042672619223594666,
        -0.0034850798547267914,
        0.06200891360640526,
        -0.05797743424773216,
        0.0008143577142618597,
        0.04683763533830643,
        0.024796806275844574,
        -0.08683585375547409,
        0.030793245881795883,
        -0.06410405039787292,
        -0.03672665357589722,
        -0.005190372467041016,
        -0.07636076956987381,
        0.0127674899995327,
        0.026020905002951622,
        0.01091006025671959,
        0.05345918610692024,
        0.06809226423501968,
        0.05539197847247124,
        -0.07120733708143234,
        -0.00546378456056118,
        -0.03468058258295059,
        -0.025567034259438515,
        -0.03906140476465225,
        -0.07418809086084366,
        -0.04011276364326477,
        -0.03909878805279732,
        0.03712634742259979,
        -0.006515142973512411,
        0.006943651009351015,
        -0.03067532740533352,
        -0.04438535124063492,
        -0.026260772719979286,
        0.021852869540452957,
        -0.041982658207416534,
        -0.009118599817156792,
        -0.014195299707353115,
        0.07143288850784302,
        -0.04440830647945404,
        -0.012553350999951363,
        -0.004955863580107689,
        -0.030005045235157013,
        -0.04387064278125763,
        -0.04759851470589638,
        -0.10720700770616531,
        -0.12135666608810425,
        0.12891355156898499,
        0.05849626660346985,
        -0.042698971927165985,
        -0.05316329747438431,
        0.07315392792224884,
        -0.014811423607170582,
        0.03323858976364136,
        -0.02065611071884632,
        -0.041008688509464264,
        0.03286535665392876,
        -0.0019169412553310394,
        0.006099467631429434,
        0.073820561170578,
        -0.006855595391243696,
        0.006368615198880434,
        0.016175225377082825,
        -0.0440482497215271,
        0.06447521597146988,
        0.0030918619595468044,
        0.07078434526920319,
        -0.03824423998594284,
        0.00971016101539135,
        0.013402111828327179,
        -0.03983277827501297,
        0.0009731664904393256,
        0.04774489626288414,
        -0.04431252181529999,
        0.02811659872531891,
        -0.11096631735563278,
        -0.020704714581370354,
        -0.06210838630795479,
        0.021789075806736946,
        -0.018724242225289345,
        -0.11484203487634659,
        -0.012729314155876637,
        -0.09481018036603928,
        0.0019350823713466525,
        0.00876199547201395,
        0.06393072754144669,
        -0.08215442299842834,
        -3.6774852200635704e-33,
        -0.09453523904085159,
        -0.06001076102256775,
        -0.029660139232873917,
        0.011212904937565327,
        0.014037190936505795,
        -0.007958420552313328,
        -0.0047984360717237,
        -0.01537317968904972,
        0.045472897589206696,
        -0.10112014412879944,
        -0.002625189023092389,
        -0.07883020490407944,
        0.06656409054994583,
        0.032327327877283096,
        -0.005241035483777523,
        0.07054897397756577,
        -0.03912074863910675,
        -0.031238680705428123,
        -0.036035433411598206,
        0.09627380222082138,
        -0.013122403994202614,
        0.038173381239175797,
        -0.041038017719984055,
        -0.09492407739162445,
        -0.05145444720983505,
        0.06968721002340317,
        0.024740437045693398,
        0.13808917999267578,
        0.007680063135921955,
        -0.03912459313869476,
        0.0017228239448741078,
        -0.06946337223052979,
        -0.12044192105531693,
        -0.03435526043176651,
        -0.013465101830661297,
        0.021570784971117973,
        0.0383438766002655,
        -0.03721648082137108,
        -0.03692134842276573,
        -0.06499207764863968,
        0.12438147515058517,
        0.059788864105939865,
        -0.05300651863217354,
        -0.032493822276592255,
        0.009997048415243626,
        0.027768978849053383,
        -0.06190767139196396,
        -0.016487551853060722,
        -0.0023963626008480787,
        0.04415305331349373,
        0.014043658040463924,
        0.030181273818016052,
        -0.052896227687597275,
        0.07179077714681625,
        -0.041091226041316986,
        -0.016407083719968796,
        0.050366953015327454,
        -0.008510091342031956,
        -0.040966905653476715,
        0.030917145311832428,
        -0.012185895815491676,
        -0.031817998737096786,
        -0.029788345098495483,
        -0.05197274312376976,
        0.08551319688558578,
        0.01106337085366249,
        0.0230155810713768,
        -0.05595311149954796,
        0.02135239727795124,
        -0.01339736208319664,
        -0.023097746074199677,
        -0.013466272503137589,
        -0.004847157746553421,
        -0.025402383878827095,
        0.015507788397371769,
        0.014626258052885532,
        -0.06313785910606384,
        -0.010215080343186855,
        -0.0777493566274643,
        -0.07192640006542206,
        0.012312335893511772,
        -0.1376388520002365,
        -0.023834284394979477,
        0.01576877385377884,
        0.004072913434356451,
        0.01952100731432438,
        0.06324057281017303,
        0.01340900082141161,
        0.0763150155544281,
        -0.03254646435379982,
        -0.06084161996841431,
        0.06665720790624619,
        -0.1159738078713417,
        0.07929540425539017,
        -0.028758209198713303,
        -5.163719052347915e-8,
        0.024087660014629364,
        0.017119454219937325,
        0.03991515561938286,
        -0.01661061868071556,
        0.06989289075136185,
        -0.0902109444141388,
        -0.014058460481464863,
        0.0414716899394989,
        -0.04709431529045105,
        0.035672057420015335,
        0.057642966508865356,
        -0.03126447647809982,
        -0.0155726233497262,
        0.002954239957034588,
        -0.013624227605760098,
        0.0006671943119727075,
        0.05517667159438133,
        0.07620853185653687,
        0.0027823499403893948,
        -0.039050519466400146,
        0.06415275484323502,
        0.002848563715815544,
        -0.07251312583684921,
        -0.04346027970314026,
        0.11996430903673172,
        -0.02230963110923767,
        0.023230360820889473,
        0.06499679386615753,
        0.04942594841122627,
        -0.02629261277616024,
        0.04251638054847717,
        0.0029155495576560497,
        0.03093586675822735,
        -0.04178715869784355,
        -0.019470974802970886,
        0.016644569113850594,
        0.10546393692493439,
        -0.07528183609247208,
        -0.05957338213920593,
        0.0740329697728157,
        -0.04108436033129692,
        0.05857781320810318,
        -0.04901673644781113,
        0.01122395321726799,
        0.0055594355799257755,
        -0.013505118899047375,
        -0.046332038938999176,
        -0.05476729944348335,
        0.06998012214899063,
        0.03561792150139809,
        0.021255124360322952,
        -0.057456642389297485,
        0.046391308307647705,
        0.0022985534742474556,
        0.04907513037323952,
        0.05462915822863579,
        0.08476527035236359,
        0.024542665109038353,
        0.023495592176914215,
        -0.01142547931522131,
        0.04849511384963989,
        -0.012959631159901619,
        -0.06498818099498749,
        0.04428983852267265
      ],
      "metadata": {
        "title": "Paper_5_Quantified_Sleep__Machine_learning_techniques_for_.pdf",
        "createdAt": "2025-12-17T13:56:41.808Z"
      },
      "fileObj": {}
    },
    {
      "id": "doc_16_1765979802722",
      "fileName": "Paper_7_Permutation_time_irreversibility_in_sleep_electroe.pdf",
      "content": "arXiv:2405.02802v1 [stat.CO] 5 May 2024  Permutation time irreversibility in sleep electroencephalograms: Dependence on sleep stage and the effect of equal values  Wenpo Yao 1, 2  1 State Key Laboratory of Organic Electronics and Information Displays, Institute of Advanced Materials, School of Chemistry and Life Sciences, School of Geographic and Biologic Information, Nanjing University of Posts and Telecommunications, Nanjing 210023, China  2 Key Laboratory of Computational Neuroscience and Brain-Inspired Intelligence(Fudan University), Ministry of Education  Time irreversibility (TIR) refers to the manifestation of nonequilibrium brain activity influenced by various physiological conditions; however, the influence of sleep on electroencephalogram (EEG) TIR has not been sufficiently investigated.   In this paper, a comprehensive study on permutation TIR (pTIR) of EEG data under different sleep stages is conducted. Two basic ordinal patterns (i.e., the original and amplitude permutations) are distinguished to simplify sleep EEGs, and then the influences of equal values and forbidden permutation on pTIR are elucidated.   To detect pTIR of brain electric signals, 5 groups of EEGs in the awake, stages I, II, III, and rapid eye movement (REM) stages are collected from the public Polysomnographic Database in PhysioNet. Test results suggested that the pTIR of sleep EEGs significantly decreases as the sleep stage increases (p < 0.001), with the awake and REM EEGs, demonstrating greater differences than others. Comparative analysis and numerical simulations support the importance of equal values. Distribution of equal states, a simple quantification of amplitude fluctuations, significantly increases with the sleep stage (p < 0.001).   If these equalities are ignored, incorrect probabilistic differences may arise in the forward-backward and symmetric permutations of TIR, leading to contradictory results; moreover, the ascending and descending orders for symmetric permutations also lead different outcomes in sleep EEGs. Overall, pTIR in sleep EEGs contributes to our understanding of quantitative TIR and classification of sleep EEGs.  I.   INTRODUCTION  The human brain, which contains large numbers of neurons and interacts with other physiological organs [1, 2], is a highly complex system. Brain activity exhibits evidently nonlinear, nonequilibrium properties and is in- fluenced by various internal and external factors. Sleep is a vital physiological activity for living beings; various changes occur in the physiological systems during sleep, with brain electric activities demonstrating pronounced changes. Therefore, the complex characteristics of sleep electroencephalograms (EEGs) can help in analyzing the sleep mechanisms [3, 4]. Various nonlinear methods, such as fractal approaches and detrended fluctuation analysis, have been used to explore the dynamics of EEGs dur- ing different sleep stages.   Entropy measures [5, 6] are widely employed to detect the complexity of sleep brain signals, such as the Shannon entropy [7, 8], sample en- tropy [9, 10], and multiscale entropy [11]. Among these complex characteristics, the loss of time reversibility is a manifestation of nonequilibrium brain electric activity [12, 13] and has been applied to several neural patholog- ical conditions, including epilepsy [14‚Äì16], Alzheimer‚Äôs disease [17], and alcoholism [18]. Time irreversibility (TIR) [19], also defined as tempo- ral asymmetry (TAS) [20], is an important characteristic of nonequilibrium EEGs.   To quantity TIR, the prob- abilistic differences between the forward-backward pro- cesses or symmetry vectors must be measured [19‚Äì21]; both are nontrivial. In real-world signal processing, TIR is generally quantified by coarse-graining the time series. Probabilistic differences between up and down were in- troduced by Costa [22, 23], Porta [24], and Ehlers et al.   [25, 26] as simplified temporal asymmetries.   La- casa et al.   [27‚Äì29] estimated the irreversibility consid- ering the distinguishability between the in-out distribu- tions of the visibility graph [30].   The in-out difference was then employed to detect irreversible characteristics in effective interactions and particular networked con- nectivity [31, 32].   Given nonequilibrium statistical me- chanics in neuronal spike trains, the network inference and couplings of asymmetric models were investigated via asynchronous update [33, 34].   Symbolic TIR based on a way of coarse-graining or reduction of description is widely adopted in quantitative TIR owing to its com- putational effectiveness and simplified statistical analysis [35, 36]. Among these coarse-graining methods, ordinal patterns convey structural dynamics and do not impose further model assumptions [37‚Äì40]; thus, they are popu- lar in the quantification of TIR [14‚Äì18]. However, several challenges are observed in permutation TIR (pTIR). It should be noted that there are two basic ordinal pat- terns, i.e., original permutation and amplitude permuta- tion; they differently reflect the structural dynamics of any series [40]. Amplitude permutation directly reflects the vector temporal structure, while the application of original permutation might result in conceptual errors in pTIR [15, 41, 42].   Forbidden permutation refers to the missing ordinal pattern in the simplified transformation of a temporal structure.   Amigo et al.   [43‚Äì45] exten- sively analyzed the features of these forbidden ordinal patterns and proposed several methods for chaotic deter-\n\n2 mination in real-world time series analysis.   The distri- butions of forbidden permutation convey important sys- tem information, such as chaotic dynamics, correlation, and nonlinearity [46‚Äì49].   Forbidden permutation is an adverse factor in pTIR because it generates individual permutations and make division-based parameters (e.g., the Kullback-Leibler distance) unsuitable to calculate the probabilistic difference between forbidden and individual permutations [14, 15, 41, 42].   Equal value is another implicated factor because it significantly affects the con- struction of ordinal patterns and permutation analysis. Ma et al.   [50] focused on the indexes of equal values in permutation and modified them into the same sym- bol (rank) for a more accurate characterization of the system structure. Zunino et al. [51] reported erroneous conclusions on permutation entropy (PEn) in the event of equalities in time series; David et al. [52] further iden- tified the weakness of PEn, i.e., the possible ambiguities introduced by equal values in the subsequences.   How- ever, the influence of equal values on pTIR has not been sufficiently analyzed. Equal values are generally assumed to be rare if a process has a continuous distribution [37]. This is partly true; however, equal values are observed in physiological signals such as heartbeats [53, 54] and raw EEGs [55, 56], and they significantly impact per- mutation analysis. Moreover, equal values might gener- ate self-symmetry vectors containing important physical implication (i.e., time reversibility or temporal symme- try) in TIR and produce contradictory findings in real- world series analysis [53, 54]. Furthermore, the different treatment of equal values might lead to inconsistencies between forward-backward and symmetric permutations, thus yielding differences in the quantification of TIR and TAS of time series.   Therefore, the effects on the pTIR during signal processing, particular the TIR and TAS in real-world series analysis, should be comprehensively studied. Owing to these unfavorable factors in the quan- tification of TIR, the time irreversible characteristics of sleep EEGs have not been given the deserved attention. To address this problem, a comprehensive analysis of pTIR and its application in sleep EEG classification is performed.   Accordingly, two basic ordinal patterns are compared to simplify the time series, and several crucial factors in pTIR are clarified.   Subsequently, the distri- butions of equal values and individual permutations that affected the pTIR of sleep EEGs are detected. For com- parison, nonequal permutations of TIR are employed, and PEn is applied to evaluate the complexity of sleep EEGs. Furthermore, several issues are discussed such as equal values in sleep EEGs and the relationship between entropy and TIR. The contributions of this research are as follows:   (1) it elucidates the key factors of pTIR in physiological signal processing, especially the influence of equal values, (2) it explores the time irreversible charac- teristics of EEGs under different sleep conditions, which is helpful for sleep classification.  II.   METHODS A.   Time irreversibility  A process is defined as time reversible if it is invariant under the reversal of the timescale; otherwise, it is time irreversible.   Given below are two statistical definitions of time reversibility: Definition 1. According to Weiss [19], a stationary pro- cess,   X ( t ), is time reversible if   { X ( t 1 ) , X ( t 2 ) , . . . , X ( t m ) }  and   { X ( ‚àí t 1 ) , X ( ‚àí t 2 ) , . . . , X ( ‚àí t m ) }   have the same joint probability distributions for every   t 1 , t 2 , . . . , t m   and   m ; otherwise,   X ( t ) is time irreversible. Definition   2.   Based   on   the   works   of   Kell   [20], if   X ( t )   is   time   reversible,   { X ( t 1 ) , X ( t 2 ) , . . . , X ( t m ) }  and   { X ( ‚àí t 1   +   n ) , X ( ‚àí t 2   +   n ) , . . . , X ( ‚àí t m   +   n ) }  have   the   same   probability   distributions   for   every  t 1 , t 2 , . . . , t m   and   n .   Particularly,   under   n   =  t 1   +   t m ,   symmetric   { X ( t 1 ) , X ( t 2 ) , . . . , X ( t m ) }   and  { X ( t m ) , . . . , X ( t 2 ) , X ( t 1 ) }   have the same joint probabil- ities.   Moreover, the symmetric form of a vector is the same as its counterpart in the time-reversal series. There- fore, TIR is also defined as TAS. To quantify the TIR or TAS of a process, the forward- backward probabilistic difference and symmetric vectors‚Äô probabilistic divergence should be equivalent [21]; how- ever, their applications in real-world processes are differ- ent [14, 15]. The forward-backward approach for TIR is operationally convenient and more reliable in application. Meanwhile, it should have the entire process to obtain the reversed one, which is not feasible if the process is large or uninterrupted; therefore, TIR based on forward- backward differences does not satisfy real-time require- ment.   By contrast, TAS based on the probabilistic dif- ference of symmetric vectors demonstrates real-time per- formance; therefore, it has higher applicability in phys- iological and environmental condition monitoring. Note that TAS based on symmetric vectors has a limitation, i.e., the vector should be faithfully associated with its alternative; otherwise, conceptual misleading may occur [15, 41, 42].  B.   Original and amplitude permutations  TIR can be measured by alternatively calculating the joint probabilistic differences of simplified processes in- stead of the raw process.   Among these simplified mea- sures, pTIR is particularly popular. The ordinal pattern comes naturally from the series and does not pose further model assumptions [37, 40]; hence, it plays an important role in quantitative TIR. According to the representation of a vector structure, there are two basic ordinal patterns, i.e., the original permutation (OrP) and amplitude permutation (AmP) [40, 42]. The OrP consists of the indexes of reorganized\n\n3 values in the original series, while the AmP comprises the positions of the original values in the reordered se- ries.   Given series   X ( i ) =   { x ( i 1 ) , . . . , x ( i i ) , . . . , x ( i m ) } , it is reordered in the ascending or descending order to  X ( j ) =   { x ( j 1 ) , . . . , x ( j j   ) , . . . , x ( j m ) }   e.g., increased as  x ( j 1 )   <   ¬∑ ¬∑ ¬∑   < x ( j j   )   <   ¬∑ ¬∑ ¬∑   < x ( j m ). Then, the OrP and AmP are generated according to the organized indexes of the original and reordered series as Eq. (1).  {   OrP : ( x 1 ,j   , . . . , x i ‚àí 1 ,j   , x i,j   , x i +1 ,j   , . . . , x m,j   ) AmP : ( x i, 1 , . . . , x i,j ‚àí 1   , x i,j   , x i,j +1   , . . . , x i,m )   (1) In   the   construction   of   OrP,   i   increases   from   1 to   m   and   j   is   the   location   of   reorganized   val- ues   in   the   original   series   X ( i ),   i.e.,   OrP j   = ( j 1 , j 2 , . . . , j i ‚àí 1 , j i , j i +1 ,   ¬∑ ¬∑ ¬∑   , j m ‚àí 1 , j m ). In the generation of AmP,   j   increases from 1 to   m   and   i   is the posi- tion of original values in the reordered series   X ( j ), i.e.,  AmP i   =   ( i 1 , i 2 , . . . , i j ‚àí 1 , i j   , i j +1 ,   ¬∑ ¬∑ ¬∑   , i m ‚àí 1 , i m ).   Tak- ing a series with five values   X ( i )   =   { 5 ,   1 ,   7 ,   3 ,   9 }   as an example, the reordered series can be represented as  X ( j ) =   { 1 ,   3 ,   5 ,   7 ,   9 }   in the ascending order.   The in- dexes of reorganized   X ( j ) values in the original   X ( i ) is OrP=(2,4,1,3,5); the positions of the original   X ( i ) values in the reorganized   X ( j ) is AmP=(3,1,4,2,5). Equal values are not rare in real-world signals and are usually generated owing to limitations in signal collec- tion [55, 56], especially the quantization error in analog- to-digital conversion (ADC). Equal values have an im- portant role in the construction of ordinal patterns and permutation analysis [50‚Äì54]; therefore, their indexes in ordinal patterns should be improved accordingly. If there are equal values in series   X ( i ), they can be organized in neighboring orders according to their order of occur- rence; for example,   ¬∑ ¬∑ ¬∑   < x ( i 1 , j 1 ) =   x ( i 2 , j 2 )   <   ¬∑ ¬∑ ¬∑   < x ( i 3 , j 3 ) =   x ( i 4 , j 4 ) =   x ( i 5 , j 5 )   <   ¬∑ ¬∑ ¬∑   . Then, the indexes of equal values can be rewritten to be the same in each group, such as to the smallest indexes as   ¬∑ ¬∑ ¬∑   < x ( i 1 , j 1 ) =  x ( i 1 , j 1 )   <   ¬∑ ¬∑ ¬∑   < x ( i 3 , j 3 ) =   x ( i 3 , j 3 ) =   x ( i 3 , j 3 )   <   ¬∑ ¬∑ ¬∑  [50] or the largest ones as   ¬∑ ¬∑ ¬∑   < x ( i 2 , j 2 ) =   x ( i 2 , j 2 )   <  ¬∑ ¬∑ ¬∑   < x ( i 5 , j 5 ) =   x ( i 5 , j 5 ) =   x ( i 5 , j 5 )   <   ¬∑ ¬∑ ¬∑   , and modify the OrP and AmP accordingly.   Further taking a series with five values   X ( i ) =   { 5 ,   1 ,   9 ,   1 ,   7 }   as an example, the second ‚Äò1‚Äô could be treated as ‚Äò2‚Äô according to its order of occurrence; then, the OrP and AmP become (2,4,1,5,3) and (3,1,5,2,4) in the ascending order, respectively.   In equal-value ordinal patterns, the indexes of equal values are modified to be the smallest; consequently, the OrP and AmP are improved to be (2,2,1,5,3) and (3,1,5,1,4), respectively.   Without equal values, if the length of the series is   m , there exist   m !   ordinal patterns, and there are more motifs if the equality is considered. Equal-value permutation is necessary for the comprehensive reflection of the series‚Äô temporal structure [40, 42]. Figure 1 illus- trates the structures of triple-value series and their OrPs and AmPs. Figure 1 displays the comprehensive temporal struc- tures of triple-value series where equal values have an important role. Furthermore, OrP and AmP are two ba- sic ordinal patterns that differently convey the temporal structure of the series [40]. AmP directly reflects the tem- poral structure of the series because its elements directly correspond to the amplitude of the original sequence el- ement.   Therefore, AmPs of symmetric vectors (e.g.,   y - axis or time symmetric) are all symmetric in Fig. 1, and AmPs of the three temporally self-symmetric vectors are also self-symmetric. By contrast, OrP indirectly reflects the original series structure owing to targets on the re- ordered series, and OrPs of amplitude-symmetric (i.e.,   x - axis symmetry) series are symmetric. The differences be- tween OrP and AmP differently affect permutation anal- ysis.   When ordinal patterns are used as an alternative label or symbol of the series, there are no differences be- tween the two basic permutations, such as in PEn [8, 37]. Otherwise, if ordinal patterns are constructed as a direct replacement of the series structure, OrP and AmP should be dealt with carefully to avoid possible errors, such as in pTIR [15, 41, 42].   In this study, AmP is used as a direct alternative for the temporal structure of the series to avoid possible errors in pTIR.  C.   Permutation time irreversibility  Permutation TIR is the probabilistic difference be- tween forward-backward or symmetry permutations as an alternative to the original series. Owing to the advan- tages of ordinal patterns and their application in quanti- tative TIR, pTIR is widely used in time series analysis. In real world signal analysis, the application of pTIR en- counters some challenges, as listed below: (1) OrP is not a direct reflection of the temporal struc- ture of vectors, as shown in Fig. 1, and its effect on TAS is such that if the probabilistic difference between sym- metric vectors is calculated, symmetric OrPs should not be used. The AmPs of time-symmetric vectors are sym- metric, and symmetric AmPs could be employed as al- ternatives for evaluating TIR [40]. Meanwhile, the OrPs of amplitude-symmetric vectors are symmetric, and sym- metric OrPs should be employed as alternatives for mea- suring amplitude irreversibility [15, 42].   It should be noted that when measuring the joint probabilistic dif- ference of the forward-backward process for TIR, there is no difference between the OrP and AmP. Overall, AmP directly reflects the temporal structure of vectors and is recommended for pTIR. (2)   The   consideration of   equal   values   is   necessary to construct comprehensive and reliable vector struc- tures; more importantly, equal values can generate self- symmetric vectors. Self-symmetric vectors, e.g., the vec- tors and their AmPs in boxes in Fig. 1a) and c), have a special physical implication, i.e.   time reversibility or\n\n4  (1,2,3)  (3,2,1)  (1,3,2)   (3,1,2) (2,1,3) (2,3,1)   (1,1,3) (2,2,1) (1,2,2)   (3,1,1)   (1,1,2) (2,1,1)  (1,1,1)   (1,3,1) (2,1,2) (1,1,3) (3,1,1) (2,2,1) (1,2,2) (1,3,2)   (2,3,1)  (2,1,3) (3,1,2)  y   y x x  (1,2,3)  (3,2,1) (1,1,1)  OrP:  AmP:  a)   b)   c)  time self-symmtry  FIG. 1. OrP and AmP of triple-value series. AmPs are bold and underlined. Indexes of red equal values in the ascending order are modified to be the smallest ones in their corresponding groups. a) OrPs and AmPs of all-up, all-down, and all-equal vectors are always the same. b) Symmetric AmPs of time-symmetric ( y -axis) series are connected by dashed black arrows; symmetric OrPs of   x -axis symmetric series are connected by solid red arrows. c) AmPs of time self-symmetry vectors are symmetric.  temporal symmetry [40, 42].   Furthermore, equal values widely exist in physiological data (either directly col- lected EEGs or indirect heartbeats derived from elec- trocardiography) owing to the nonlinear and irreversible quantization process of signal collection [53, 55,   56]. Therefore, equal values should not be broken by adding small random perturbations or ranked according to their order of appearance, and their indexes in ordinal patterns should be modified accordingly. (3) Forbidden permutations are a special type of for- bidden symbol, i.e., symbols that do not exist for a pro- cess. Forbidden permutations are closely related to sys- tem characteristics [43‚Äì49], but they negatively impact quantitative TIR. Among the pairs of permutations for quantitative TIR, if there exists a forbidden permutation, its corresponding permutation is an individual permuta- tion.   The mathematical difference between the proba- bilities of forbidden and individual permutations is zero or infinite if using division-based parameters, such as the Kullback-Leibler distance. Therefore, such division- based parameters are not suitable for quantitative TIR [14, 15, 41, 42].   It is recommended to use subtraction- based parameters, such as   Y s   in Eq. (2), in quantitative TIR to calculate the probabilistic differences, where   p i  and   p j   probability of corresponding permutations and   p i  should not be less than   p j   .  Y s „Äà p i , p j   „Äâ   =   p i  p i   ‚àí   p j  p i   +   p j  ,   (2) (4) TIR and TAS are statistically consistent;   theo- retically, the probabilistic differences between symmetric permutations and those between forward-backward per- mutations should be the same.   However, the existence of equal values and the traditional treatment that ranks them according to their order of emergence make TIR and TAS different.   Figure 2 illustrates a comparative construction of nonequal and equal-value AmPs consid- ering equal values.  (1,1,1)  (1,2,2)   (2,2,1)   (3,1,1)   (1,1,3) (2,1,2) (1,3,1)  (1,2,3) (1,2,3)   (1,2,3) (2,3,1)   (3,1,2) (1,3,2)   (2,1,3)  equal-value  nonequal  FIG. 2.   AmPs of triple-value series considering equalities. Equal values are represented in red and the crossed greens are their alternatives according to their order of occurrence in the ascending order. In equal-value AmPs (bold and underlined), indexes of red equal values are modified to be the smallest in their corresponding groups.  As evident in Fig. 2, nonequal AmP represents a tem- poral structure of vector without equal values.   Equal values are transformed into ‚Äòfalse up‚Äô in nonequal ordi- nal patterns and their symmetric permutation is ‚Äòreal down‚Äô, but their corresponding permutations in the back- ward series are ‚Äòfalse up‚Äô and ‚Äòreal up‚Äô.   Note that ‚Äòreal down‚Äô in the forward series is ‚Äòreal up‚Äô in the back- ward series; moreover, the probability distributions of ‚Äòup‚Äô in the forward and backward series are both incor- rect. Furthermore, if there are equal values in the process and nonequal permutation is applied, neither TIR nor TAS can be correctly quantified; in addition, the AmPs of symmetric and forward-backward vectors are not the same, leading to inconsistent and even contradictory TIR and TAS in the quantitative nonequilibrium of signal pro-\n\n5 cessing, which will be confirmed in this study.  III.   RESULTS  EEG is a typically complex signal and subject to dif- ferent physiological activities. In this section, EEG data under different sleep conditions are collected from the publicly available PhysioNet [57] to test the sleep stages on pTIR. The probabilistic differences of AmPs are cal- culated using the subtraction-based   Y s   to quantify TIR; TIR and TAS based on equal-value AmP are denoted as pTIR and pTAS, while those based on nonequal AmP are represented as noeTIR and noeTAS, respectively.  A.   Sleep EEGs  The MIT-BIH Polysomnographic Database is a collec- tion of sleep physiologic data.   This database contains information related to the sleep physiological signals of 16 male subjects (age ranging from 32 to 56, mean age 43; weight ranging from 89 to 152 kg, mean weight 119 kg). The database contains over 80 h of four-, six-, and seven-channel polysomnographic recordings, with a stan- dard expert annotation for sleep stages after every 30 s according to the criteria of Rechtschaffen and Kales [58]. EEG signals are recorded from the C4-A1, O2-A1, or C3- O1 channel at a sampling rate of 250 Hz and 12-bit quan- tization. Referring to the annotation files, sleep EEGs in five stages, i.e., awake and sleep stages 1 (SI), 2 (SII), 3 (SIII), and rapid eye movement (REM) are extracted; each stage contained 45 sets of EEG signals with a du- ration of 60 s (15000 points) after visual inspection for artifacts. More detailed information can be found in Ref [57, 59].   The nonparametric Mann‚ÄìWhitney U test is performed to test the statistical differences in pTIR be- tween each of the two stages of sleep EEGs, and Kruskal‚Äì Wallis analysis of variance is applied to measure those in pTIR of sleep EEGs in five stages. Equal values play an important role in the construc- tion of ordinal patterns and might significantly change the probability distribution of permutations; moreover, they convey important physical implication, i.e., time reversibility [14, 15, 40, 42].   The distribution of equal states (DES) [55] is measured by Eq. (3), where   L   de- notes the length of series,   N   ( s ( t ) =   s ( t   +   œÑ   )) represents the number of neighboring equal states with delay   œÑ   . The states of DES indicate EEG values in this report. DES of five groups of sleep EEGs are shown in Fig. 3. DES =   N   ( s ( t ) =   s ( t   +   œÑ   ))  L   ‚àí   œÑ   (3) The results in Fig. 3 are consistent with those obtained in our previous report on the distribution of equal val- ues in sleep EEGs [56].   Raw sleep EEGs have numer- ous neighboring equal values.   Although awake EEGs have minimum equal values, their DES are 12%, and as the sleep stages increase, the DES increase significantly; hence, REM EEGs have almost 34% equal values.   Un- der acceptable data recording resolution, awake EEGs have larger amplitude fluctuations that produce fewer neighboring equal values, and as the depth of sleep in- creases, amplitude fluctuations of the brain‚Äôs electrical activity decrease, thus significantly decreasing the DES. Equal values are generated owing to the limitation of the ADC, i.e., the zero-amplitude fluctuation [55, 56].   Test results suggest that the DES of EEGs under the five sleep conditions are statistically significantly different (p < 0.01 for Mann‚ÄìWhitney U test; p < 0.0001 for Kruskal‚ÄìWallis test), and the DES of REM EEGs are particularly differ- ent between others (p < 0.00001). Therefore, equal values not only have important effects on pTIR, but their distri- bution also serves as a simple parameter for time-domain feature extraction and should not be ignored. The   existence   of   forbidden   permutations   makes division-based parameters unsuitable for pTIR, and their distribution has been widely proved to be closely associ- ated with systematic information [43‚Äì49]. In sleep EEGs, all permutations have their corresponding forms when  m =2 and 3, while the distribution of individual permu- tations is rare when   m =4.   When   m   is 5 and larger, there exist forbidden as well as individual permutations. Further, forbidden permutations contain false forbidden permutations that do not exist because the data length is short, and they decay with the sequence length [44]. Considering false forbidden permutations, if the selected EEG data length is short, the pTIR of classified sleep EEGs might not be reliable. The distribution of individ- ual permutations (DIPs) is expressed in Eq. (4), where  N   ( œÄ I   ) and   N   ( œÄ ) represent the amount of individual per- mutation   œÄ I   and existing permutation   œÄ , respectively. Taking   m =5 as an example, the effect of data length on the DIPs of five groups of sleep EEGs is illustrated in Fig. 4. DIP =   N   ( œÄ I   ) /N   ( œÄ )   (4) Fig. 4 shows that sleep EEG signals contain individual permutations whose probability distributions are affected by the signal length.   With the increase in data length from 1 to 10 s (2500 points), the DIP values of sleep EEGs decrease stepwise and tend to converge when the data length was larger than 20 s (5000 points).   There- fore, when the data length is short, there exist false for- bidden as well as false individual permutations, and they decay when the data length increases.   The DIP is also related to sleep conditions when the EEG length is more than 20 s. SIII and REM EEGs have larger DIPs when awake and SI EEGs exhibit smaller DIPs.   The exis- tence of forbidden and individual permutations suggests\n\n6  -0.03 0 0.03  -0.02 0 0.02  0 0.04  -0.05 0 0.05  0   500   1000   1500   2000   2500  sampling points  -0.01 0 0.01  0 0.1 0.2 0.3 0.4  DES  awake  SI  SII  SIII  REM  =1   =2 SI SII SIII REM awake  \\mV #   *  FIG. 3. Exemplary EEGs in awake, SI‚ÄìSIII, and REM states and the distribution of equal states (mean ¬± standard error) of sleep EEGs. The state in DES is the direct amplitude value during sleep EEGs. # indicates p < 0.0001 across all stages using the Kruskal‚ÄìWallis test and * suggests p < 0.01 between each two stages of sleep EEGs using Mann‚ÄìWhitney U test.  0   5   10   15   20   25   30  length  0 0.2 0.4 0.6  DIP (m=5,   =1)  0   5   10   15   20   25   30  length  0 0.2 0.4 0.6  DIP (m=5,   =2)  awake  SI  SII  SIII  REM  *250   *250  FIG. 4. Distribution of individual permutations (mean ¬± standard error) of wake, SI‚ÄìSIII, and REM EEGs.  that subtraction-based index is a necessity in quantita- tive TIR. Moreover, the length of EEG signals cannot be too low; they should be greater than 30 s in this study, otherwise these false individual permutations will lead to unreliable pTIR for the nonequilibrium analysis of sleep EEGs. Overall, there are equal values and individual permu- tations in sleep EEGs that affect pTIR analysis. Hence, the two basic ordinal patterns must be distinguished con- sidering the necessity of equal-value permutation, the subtraction-based probabilistic difference and require- ment of data length also should be paid attentions in pTIR of sleep EEGs.  B.   pTIR in sleep EEGs  Given the DIPs in sleep EEGs, dimension is set to 2, 3, and 4 in an enumerative manner. The increase in delay is equivalent to the reduction in signal sampling frequency, i.e., 250/ œÑ   Hz [55, 56]. To satisfy the Nyquist sampling rate (i.e., more than twice the signal band), the delay is set to 1‚Äì4, thus maintaining sufficient information about sleep conditions in EEG data. The pTIR of sleep EEGs in awake, SI‚ÄìSIII, and REM stages are shown in Fig. 5. Contrary to the DES in Fig. 3, the pTIR of sleep EEGs exhibit decreasing trends as the sleep depth increase, as shown in Fig. 5.   As the subjects come into sleep from wakefulness, the pTIR of EEG signals significantly de- crease; moreover, as the sleep depth increase, the pTIR consistently decrease.   Particularly, when subjects en- ter the REM state, the pTIR of EEGs show a consid- erable decrease.   The choice of dimension and delay do not affect the trend of EEGs‚Äô pTIR with the increas- ing sleep depth, but it affect the statistical discrimina- tions.   According to statistical results, when   m =3 and  œÑ   =1, the pTIR of EEGs in the five sleep stages exhibit optimal classification (p < 0.0001 for Kruskal‚ÄìWallis test). As shown in Fig. 5, more significant reductions are ob- served in the pTIR of EEGs from the awake to sleep and\n\n7  0 0.002 0.004 0.006 0.008 0.01  pTIR, m=2  0 0.005 0.01 0.015  pTIR,m=3  0 0.01 0.02 0.03  pTIR,m=4  awake   SI   SII   SIII   REM  =1   =2   =3   =4 =4 =3 =2 =1 =4 =3 =2 =1  #  #  * * * *  FIG. 5. pTIR (mean ¬± standard error) of wake, SI‚ÄìSIII, and REM EEGs. # indicates p < 0.0001 across all stages using Kruskal‚Äì Wallis test and * suggests p < 0.01 between pTIR of sleep EEGs and others using Mann‚ÄìWhitney U test.  SIII to REM stages when   m =2 and 3 and   œÑ   =1. There- fore, time irreversible features of brain electric activity decrease as the sleep stages advance, and more significant differences are observed in nonequilibrium features dur- ing the awake‚Äìsleep transformation and REM state. For comparison, the probabilistic differences between sym- metric AmPs, i.e., pTAS, are also calculated. The pTAS and pTIR yielded the same results, suggesting that equal- value AmPs reliably characterize the temporal structure of vectors in sleep EEGs and are not affected by the re- verse process in backward time series. It should be noted that equal values significantly affect the pTIR, and sleep EEGs generally contain numerous equal values [56]. Given the amplitude fluctuations mea- sured by DES in Fig. 3, the noeTIR and noeTAS of EEGs under the five sleep stages are calculated and shown in Fig. 6. As evident in Fig. 6, noeTIR and noeTAS of the five groups of sleep EEGs considerably differed and even showed completely contradictory results based on the nonequal AmP. The comparison shows that noeTIR re- sults exhibited a consistent classification of sleep stages with the pTIR, while noeTAS had contradictory results. Although pTIR and noeTIR demonstrated similar de- creasing trends with the increase in sleep depth, they were not the same in these EEGs.   Statistically, noe- TIR of sleep EEGs was not significantly different, while noeTAS with   m =3 and   œÑ   =1 effectively differed in the five groups of EEGs (p < 0.01 for Mann‚ÄìWhitney U test; p < 0.0001 for Kruskal‚ÄìWallis test). Figure 2 shows that when the signal contained equal elements and was reorga- nized in ascending order, the probabilistic differences of permutations between the forward and backward series were closer to the pTIR, while those of symmetric permu- tations had a greater deviation. Note that neither noe- TIR nor noeTAS yielded correct results. Taking   m =2 as an example, only up, down, and equal forms are observed, among which, equality was transformed into up in both the forward and backward series.   The pTIR, noeTIR, pTAS, and noeTAS were calculated using Eq. (5), where  up p ,   down p , and   equal p   represent the probability of up, down, and equal values, respectively, and   up p /down p   de- notes the probabilistic difference between   up p   and   down p  using   Y s .  Ô£± Ô£¥ Ô£¥ Ô£≤ Ô£¥ Ô£¥ Ô£≥  pTIR : 0 . 5   ‚àó   ( up p /down p   +   down p /up p ) noeTIR : 0 . 5   ‚àó   (   up p   + equal p  down p + equal p   +   down p /up p ) pTAS :   up p /down p  noeTAS : ( up p   +   equal p ) /down p  (5) In Eq. (5), pTIR is the same as pTAS, but different from noeTIR and noeTAS. Due to equal being mistaken as up, both noeTIR and noeTAS wrongly measure the time reversibility of sleep EEGs.   Evidently, if there is no equality, pTIR, noeTIR, pTAS, and noeTAS are the same. To compare with the pTIR, PEn [37, 54], i.e., the Shannon entropy of permutation probability   p ( œÄ ), given in Eq. (6), is further employed in the analysis of sleep EEGs. It is a widely applied statistical parameter used to measure the nonlinear characteristics of complex sys- tems [37]. The selection of OrP and AmP does not affect the calculation of PEn because PEn is the mean informa- tion contained in the existing ordinal patterns [40], while equal values affect PEn in signal analysis [50‚Äì52].   PEn based on equal-value AmP with delay from 1 to 4 and dimension ranging from 2 to 4 of sleep EEGs is displayed in Fig. 7. PEn =   ‚àí   ‚àë   p ( œÄ ) lnp ( œÄ )   (6)\n\n8  0 0.004 0.008  noeTIR, m=2  0 0.005 0.01 0.015  noeTIR, m=3  0 0.01 0.02  noeTIR, m=4  0 0.1 0.2  noeTAS, m=2  0 0.1 0.2 0.3 0.4  noeTAS, m=3  0 0.1 0.2 0.3 0.4 0.5  noeTAS, m=4  awake   SI   SII   SIII   REM  * #  =4 =2   =3 =1   =1   =1   =2   =3   =4 =2   =3   =4  FIG. 6. Contradictory noeTIR and noeTAS (mean ¬± standard error) in wake, SI‚ÄìSIII, and REM EEGs. # indicates p < 0.0001 across all stages using Kruskal‚ÄìWallis test and * suggests p < 0.01 between each of the two stages of sleep EEGs using Mann‚Äì Whitney U test.  0.7 0.8 0.9 1 1.1  PEn, m=2  1.5 2 2.5  PEn, m=3  3 4  PEn, m=4  awake   SI   SII   SIII   REM  =1   =2   =3   =4   =1   =2   =3   =4   =1   =2   =3   =4  FIG. 7. Permutation entropy (mean ¬± standard error) of wake, SI-SIII, and REM EEGs based on equal-value AmP.  As evident from Figs. 7 and 5, PEn is observed to be the opposite of pTIR in the five groups of sleep EEGs. When   m =2, PEn of EEGs increases as the subjects fell asleep and sleep depth increased, suggesting that EEGs have larger complexity with the increase of sleep stages. As   m   increases, no consistent trend is observed in the PEn complexity of EEGs with the increasing sleep stages. Statistically, the PEn of five groups of sleep EEGs is not significantly different.   Therefore, pTIR is more reliable for sleep stage classification owing to the quantification of EEG nonequilibrium features. The contradictory results of pTIR and PEn can be ex- plained by their statistical concepts.   Shannon entropy and TIR compute the difference in probability distribu-\n\n9 tions, but they focus on different sets of probabilistic differences.   PEn calculates the average amount of in- formation contained in the distribution of permutations, i.e., the probabilistic differences in all existing permuta- tions, whereas pTIR measures the difference between for- ward and backward permutation series or that between symmetric permutations of a series. Therefore, when the permutation probability difference is smaller, the entropy complexity of signals will be higher, while the TIR will be smaller. This is the fundamental reason for the opposite outcomes of pTIR and PEn in sleep EEGs, which is con- sistent with the contradictory results obtained in our pre- vious report on heartbeats [54]. Moreover, because they characterize complexity and nonequilibrium features, the results exhibit the diversity of features from different per- spectives of complex physiological signals and enable us to explore complex systems more comprehensively. The comparative analysis of sleep EEGs demonstrated that the TIR, TAS, and Shannon entropy have a complex relationship, as shown in Fig. 8.   TIR and TAS based equal-value AmP share same results while they yielded contradictory outcomes based on nonequal AmP. The trend of noeTIR is consistent with that of pTIR, while noeTAS exhibited different results in the five groups of sleep EEGs. PEn also presented contradictory findings in comparison to pTIR. To determine the difference between these associated measures and the influence of equal val- ues, probability distributions of AmPs are further ana- lyzed numerically. Taking   m =2 and   œÑ   =1 as an example, the probabilities of AmPs with and without equal values of five groups of sleep EEGs are shown in Fig. 8. Figure 8 shows that the distribution of false up (bold  ‚Äò1,2‚Äô ) in nonequal AmPs is a combination of real up (de- noted by ‚Äò1,2‚Äô) and equal (denoted by ‚Äò1,1‚Äô) in equal- value AmPs because equal values are replaced by up patterns, and that of equal values is the DES of sleep EEGs in Fig. 3. The distributions of downs (denoted by ‚Äò2,1‚Äô) are the same in the two types of ordinal patterns. In nonequal AmP, the probability distribution of up in- creases with the sleep depth, while that of down presents the opposite trend.   In equal-value AmP, the probabil- ity distributions of up and down are significantly close, and both decreased as the sleep depth increased. Equal- value AmPs further confirm our conclusion, as shown in Fig. 3, that fluctuations in the EEG amplitude decreased as the sleep depth increased.   Owing to the decrease in amplitude fluctuations in sleep EEGs, the probabilities of both ups and downs in sleep EEGs decrease, while those of equal values (i.e., DES) significantly increase with the sleep depth. The   probabilistic difference   in   AmPs and   different ways to use them directly influenced the different out- comes of pTIR, pTAS, and PEn in sleep EEGs.   Ac- cording to Eq. (5), numerical simulations suggest that the probabilistic difference between false up ( ‚Äò1,2‚Äô ) and down (‚Äò2,1‚Äô) in nonequal AmPs, i.e., (‚Äò1,2‚Äô+‚Äò1,1‚Äô)/‚Äò2,1‚Äô, increased with the sleep depth; hence, noeTAS in Fig. 6 also increased with the sleep depth.   In the backward EEG signal, equal values were transformed into up ‚Äò1,2‚Äô. Therefore, noeTIR is measured using the sum of forward- backward probabilistic differences between up and down, i.e., 0.5*[(‚Äò1,2‚Äô+‚Äò1,1‚Äô)/(‚Äò2,1‚Äô+‚Äò1,1‚Äô)]+‚Äò2,1‚Äô/‚Äò1,2‚Äô, exhibit- ing a decreasing trend in sleep EEGs, as shown in Fig. 6. However, neither noeTIR nor noeTAS truly quantified the nonequilibrium characteristic of sleep EEGs. Mean- while, in equal-value AmPs, pTIR represented the prob- abilistic difference between up and down because equal- ity indicated time reversibility and temporal symmetry, while PEn measured the probabilistic difference between up, down, and equality. Numerical results indicated that the probabilistic difference in up and down decreased as the sleep depth increased, while the average amount of in- formation contained in up, down, and equality increased. Therefore, the pTIR in Fig. 5, i.e., up-down probabilis- tic differences, decreased with the increasing sleep depth, while the PEn of EEGs in Fig. 7 increased with the sleep depth. Hence, the probability distribution of sleep EEG permutation and different usage of probabilistic differ- ence of pTIR, pTAS, and PEn are responsible for the conflicting results in sleep EEGs. In ordinal patterns and permutation analysis, elements are reordered in the ascending order; however, it remains unclear how these methods perform of a series reordered in the descending order. In ordinal patterns, if equal val- ues are organized according to their order of occurrence, they will be treated as down in nonequal permutations in the descending order. If indexes of equal values are mod- ified to be the same in their corresponding groups, the AmP and OrP have the same relationship as that shown in Fig. 1; moreover, the results for TIR, TAS, and PEn show no difference in the ascending order. Otherwise, if the indexes of equal values are not modified, these per- mutation methods might still generate incorrect results as the ascending order. Particularly, noeTAS yields dif- ferent outcomes in the ascending and descending orders. The results of noeTAS ( m =2 and   œÑ   =1) for sleep EEGs are shown in Fig. 9. In the ascending order, noeTAS is the probabilistic dif- ference between ‚Äò up p   +   equal p ‚Äô and ‚Äò down p ‚Äô, while in the descending order, noeTAS is measured by the probabilis- tic difference between ‚Äò down p   +   equal p ‚Äô and ‚Äò up p ‚Äô.   The two noeTAS share consistent results, i.e., their value in- creases as the sleep stage progresses; meanwhile, they are both incorrect. Ordinal pattern is a simplified alternative to the vec- tor; their construction is a coarse-grained procedure to signals. Weak noises and artifacts are eliminated during the generation of permutations; therefore, permutation analysis exhibits evident noise insensitivity [37‚Äì39].   To further test the pTIR, Gaussian noises are added and some frequency components are removed from the sleep EEG data of the five groups. These procedures through\n\n10  pTIR   pTAS noeTIR   noeTAS PEn  0 0.2 0.4 0.6 0.8  Probability distribution  0 0.2 0.4 0.6 0.8  awake  SI  SII  SIII  REM  up   '1,2'   down '2,1'   up '1,2'   equal '1,1' down '2,1'  nonequal AmP   equal-value AmP a)   b)  FIG. 8. Relationship of permutation analysis in sleep EEGs and probability distributions (mean ¬± standard error) of AmPs when dimension is 2 and delay is 1. a) Consistent results of pTIR and pTAS are linked by black solid arrows, while contradictory results of noeTIR and noeTAS are connected by crossed red dashed arrows. b) Probability distributions of down ‚Äò2,1‚Äô in the two types of AmPs are the same, while those of bold   ‚Äò1,2‚Äô   in nonequal AmPs are the sum of those of up ‚Äò1,2‚Äô and equal ‚Äò1,1‚Äô in equal-value AmPs.  0 0.1 0.2 0.3  noeTAS, m=2,   =1  awake  SI  SII  SIII  REM  ascending   descending  FIG. 9.   Different noeTAS (mean ¬± standard error) in wake, SI-SIII, and REM EEG data in ascending and descending ordinal patterns.  software (e.g., MATLAB in this work) eliminate equal values and the information conveyed by DES [56] from sleep EEG data.   Therefore, no difference was observed between TIR and TAS based the ordinal pattern, regard- less of the ascending or descending order. Taking   m =2 and   œÑ   =1 as an example, when Gaussian noises with signal noise ratio (SNR) from 0-0.01 dB are added, the results are not significantly affected that the pTIR values of EEG data decrease as the sleep stage progresses. Alternatively, when a 0.3‚Äì35 Hz bandpass filter is implemented to the sleep EEG data, pTIR also shows a decreased trend with the increase of sleep stages, confirming the robustness of permutation analysis [37‚Äì39]. According to the research on pTIR for sleep classifi- cation, pTIR effectively quantifies nonequilibrium char- acteristics in EEGs, yielding more reliable results than the entropy measure. Owing to the important influence of equal values on ordinal patterns, equal-value permuta- tion is necessary in the pTIR analysis of sleep EEGs. The TIR, TAS, and PEn based on equal-value and nonequal permutations yielded different or even opposite results in the 5 groups of sleep EEG signals; however, this helped us in gaining a deeper understanding of the differences be- tween analytical methods, important role of equal values, and multifaceted characteristics of complex physiological signals.  IV.   DISCUSSIONS  In the research on pTIR in sleep EEGs, several issues should be further discussed. Equal values in time series and their effect on permuta- tion analysis should be given sufficient attention. Equal values are generally ignored considering the limitation resolution of ADC, particularly coarse-grain quantiza- tion. In traditional signal processing theory, an arbitrary time series with a weak stationarity exhibits a continu- ous distribution; therefore, equal values are rare and can be broken numerically by adding small random perturba- tions [37]. The traditional treatment to equality is based on the assumptions that equal values have no significant effect on signal processing and they do not contain infor- mation about systems.   These assumptions are not cor- rect. Equal values significantly impact permutation anal- ysis. Moreover, they are necessary for the comprehensive construction of ordinal patterns [40]. As shown in Fig. 1, irrespective of the OrP or AmP, the structural informa- tion of vectors can be fully displayed only when equal values are considered. The distribution of equal values in some signals conveys important information and has sig- nificant effects on the construction and probability of or- dinal patterns, thus yielding different or even contradic- tory results, such as the results presented in Figs. 5 and 6.\n\n11 According to our previous report, PEn and pTIR exhib- ited contradictory results for PhysioNet heartbeats data with and without equal values [54]. In time reversibility, vectors with equal values might be self-symmetric, such as those in Figs. 1 and 2, and have definitive physical im- plication, i.e., time reversibility and temporal symmetry [40, 42]. Under acceptable ADC resolution, the DES are an effective parameter for quantifying signal amplitude fluctuations in extreme forms, i.e., zero fluctuation. The advantages of DES have been observed in the characteri- zation of sleep and epileptic EEGs [55, 56]; they also ex- hibit reliable performance in heartrate data (derived from electrocardiography) to reflect the decrease in heart rate variability with age and heart failure [53]. If the ADC has a high resolution or the data undergo preprocessing (e.g., software filtering), equal states are rarely observed and amplitude fluctuation information cannon be detected; in this case, a low-pass threshold can be established to filter the differential states for measuring the amplitude fluctu- ation [56]. Otherwise, the equalities can be increased by further coarse graining the digital signal, such as the par- tition symbolic transformation that resembles the ADC. It should be noted that the results of DES were consis- tent with those of pTIR for sleep EEGs. The amplitude fluctuation of signals is the most direct representation of system information, which is influenced by various factors such as frequency composition and dynamic characteris- tics. According to Figs. 3 and 8, the DES of EEG signals increased with the sleep depth, indicating that the am- plitude fluctuation decreased.   In the previous analysis of heartrate signals, amplitude fluctuations in heartrate decreased with age and heart failure, consistent with the theory of loss of complexity [53]. Our results further con- firmed the positive correlation between amplitude fluctu- ations and time irreversible features, and whether there exist other factors closely related to amplitude fluctua- tions require further research. Overall, the distribution of equal values conveyed important information about am- plitude fluctuation and significantly affected signal pro- cessing; moreover, it is required to construct reliable or- dinal patterns and has explicit physical meaning in TIR; hence, equal values cannon be ignored. Time reversibility and temporal symmetry are equiva- lent in statistical definitions, even though they may gen- erate different results in real-world quantification.   In pTIR and pTAS, the construction of ordinal patterns, particularly the treatment of equal values, plays an im- portant role. In traditional ordinal patterns, equal values are generally ranked according to their order of emer- gence. Considering double values, there are three kinds of permutations, namely up, down, and equal. In the tra- ditional ordinal, equal values are neglected and treated as up. As shown in Figs. 2 and 8, the probabilistic difference between ‚Äôup+equal‚Äô and down is calculated in noeTAS, while that between ‚Äòup+equal‚Äô and ‚Äòdown+equal‚Äô is mea- sures in noeTIR. Numerical calculations demonstrated that the difference in forward-backward permutations was closer to the pTIR than that in symmetric permu- tations, but both were wrong. The noeTIR and noeTAS were both incorrect and not the same. Taking an extreme example, for a series of all-equal values, the pTAS is 1, indicating the difference between all up and zero down, while the noeTIR is 0 for the forward and backward se- ries (it is the same as the pTIR of 1). If more values are considered, the situation will become more complex. Next, the relationship between PEn and pTIR requires more discussion.   Test results indicated that pTIR en- ables the more effective classification of sleep stages than PEn, consistent with the results of our previous report on epilepsy EEGs [14]. TIR and Shannon entropy are both statistical parameters for measuring probabilistic differ- ences; they are both widely employed in complex process analysis. Shannon entropy quantifies the static complex- ity and unpredictability considering the amount of infor- mation, i.e., the mean logarithmic calculation of all prob- abilities of permutations. TIR measures nonequilibrium features considering the sum of probabilistic differences between vectors in forward-backward series or pairs of symmetric vectors. Mathematically, if two permutations have larger probabilistic differences, they convey less in- formation while being more nonequilibrium, thus lead- ing to smaller PEn and bigger pTIR. In the special case where all permutations of symmetric vectors have the same probability distribution, PEn reaches a maximum value while pTIR is 0. In another special case where all permutations are single permutations, pTIR is the maxi- mum 1 while PEn varies with the difference among prob- ability distributions. This is the fundamental reason for different or even contradictory results in the same pro- cess. Similar results have also been reported in heartrate analysis [54]; irrespective of nonequal or equal-value per- mutation, PEn and pTIR yielded contradictory results. Such discrepant results of pTIR and PEn inspired us to gain a more comprehensive and profound understanding of the characteristics of complex systems from different perspectives. Forbidden permutation is an important influencing fac- tor that is generally overlooked in the pTIR analysis of real-world signals.   The existence of forbidden permu- tations might generate individual permutations, which have no symmetric form in forward series and de not ex- ist in backward series; moreover, their probabilistic dif- ference is zero or infinite considering division-based pa- rameters, which is not appropriate in quantitative TIR. Associated with forbidden permutations, individual per- mutations also convey information about sleep EEGs. In Fig. 4, the DIPs generally increased with the sleep stage when the data length was larger than 20 s. This may be because as the sleep depth increased, amplitude fluctua- tions, type of temporal structure, and number of ordinal patterns decreased, yielding more forbidden as well as individual permutations.   Similar associations have also\n\n12 been reported in epileptic EEG analysis [14, 55]. Seizure ictal EEGs exhibit abnormally large amplitude fluctua- tions and TIR owing to the development of synchronous neuronal firings, while seizure-free postictal brain activ- ity exhibits rather smooth amplitude fluctuations as well as smaller TIR [55].   Consistently, brain electric signals under ictal and postictal states demonstrate larger and smaller DIP values, respectively [14]. In a series of related studies, Amigo et al. found that the existence of forbid- den patterns is a feature of chaotic dynamics and can be used to distinguish random from pseudorandom orbit generation [43]; subsequently, they identified false for- bidden patterns [44] and detected determinism in noisy time series based on the properties of topological PEn [45].   The decay rate of forbidden permutations [47] in stochastic processes has been reported to be associated with their correlation structures; moreover, nonlinearity in time series can be possibly detected by the number of forbidden permutations [48, 49].   Given the systematic information conveyed by forbidden permutations and as- sociation of DIPs with sleep stages, individual permuta- tions might also be potentially used for feature detection in complex systems.  V.   CONCLUSIONS  In this study, pTIR in sleep EEG particular the depen- dence on sleep stage and the effect of equal EEG values are analyzed. Main findings are summarized below: Permutation TIR is an important measure for the quantification of nonequilibrium EEGs. When symmet- ric vector differences are used for real-time requirements, AmP is more suitable as a direct alternative to vec- tor. Moreover, equal-value ordinal patterns are required because they construct comprehensive vector structures and self-symmetric vectors convey an important physical implication, i.e., time reversibility. Brain electrical activity demonstrates nonequilibrium features that are influenced by sleep conditions.   EEGs during wakefulness exhibit higher pTIR; during sleep and with the advancement of sleep stages, the pTIR values of EEGs significantly decrease. These findings suggest that when people fall asleep, their brain electric activity con- tains less nonequilibrium characteristics.   The effective classification of sleep EEGs suggested that pTIR could serve as an aid for the expert manual annotation of sleep stages. When constructing ordinal patterns, if equal values are ordered according to their order of occurrence, the values of noeTIR and noeTAS may be inconsistent, and even if noeTIR is closer to the actual result, they would both be wrong.   Moreover, noeTAS performs differently over series reordered in the ascending and descending orders. Therefore, the consideration of equal values is necessary to construct reliable permutations, and it is important to modify the indexes of equal values to same forms in permutation TIR. Equal values and individual permutations affect the pTIR, but both DES and DIP contain important infor- mation about sleep EEGs. The DES characterize ampli- tude fluctuations in sleep EEGs such that as the sleep stages advance, DES values significantly increase as am- plitude fluctuations decrease.   The DIP may be related to structures that require further investigation. Comparative analysis of pTIR and PEn as well as nu- merical simulations of permutation probability distribu- tions verified the different and even contradictory results of time reversibility and entropy complexity, thus pro- viding us with valuable insights on statistical measures and enabling us to explore complex physiological signals more comprehensively.  VI.   ACKNOWLEDGMENT  The project is supported by the Natural Science Foun- dation   of   Jiangsu   Province   (Grant   No.BK20220383), Natural   Science   Research   of   Jiangsu   Higher   Educa- tion   Institutions   of   China   (Grant   No.22KJB110003), Natural Science Foundation of Nanjing   University of Posts and Telecommunications (Grant Nos. NY221142, NY222172), Shanghai Municipal Science and Technology, China Major Project (Grant No. 2018SHZDZX01), Key Laboratory of Computational Neuroscience and Brain- Inspired Intelligence (LCNBI) and ZJLab.  [1] A. K. Andrea, B. Misic,   and O. Sporns, Nature Reviews Neuroscience   19 , 17 (2018). [2] A. Bashan, R. P. Bartsch, J. W. Kantelhardt, S. Havlin, and P. C. Ivanov, Nature Communications   3 , 702 (2012). [3] D. Zhao, Y. Wang, Q. Wang,   and X. Wang, Computer methods and programs in biomedicine   175 , 53 (2019). [4] H. Phan and K. Mikkelsen, Physiological Measurement  43 , 04TR01 (2022). [5] Y. Ma, W. Shi, C.-K. Peng,   and A. C. Yang, Sleep medicine reviews   37 , 85 (2018). [6] W. Xiong, L. Faes,   and P. C. Ivanov, Physical Review E   95 , 062114 (2017). [7] F. Hou, L. Zhang, B. Qin, G. Gaggioni, X. Liu,   and G. Vandewalle, Sleep   44   (2021). [8] C. Bandt, Entropy   19 , 197 (2017). [9] X. Liang, J. Xiong, Z. Cao, X. Wang, J. Li,   and C. Liu, Physiological Measurement   42 , 044001 (2021). [10] Y.-H. Wang, I.-Y. Chen, H. Chiueh,   and S.-F. Liang, IEEE   Transactions   on   Instrumentation and   Measure- ment   70 , 1 (2021).\n\n13  [11] V. Miskovic, K. J. MacDonald, L. J. Rhodes,   and K. A. Cote, Human brain mapping   40 , 538 (2019). [12] X. Fang, K. Kruse, T. Lu,   and J. Wang, Reviews of Modern Physics   91 , 045004 (2019). [13] C. W. Lynn, E. J. Cornblath, L. Papadopoulos, M. A. Bertolero, and D. S. Bassett, Proceedings of the National Academy of Sciences   118   (2021). [14] W. P. Yao, J. Dai, M. Perc, J. Wang, D. Yao,   and D. Guo, Nonlinear Dynamics   100 , 907 (2020). [15] W. P. Yao, J. Wang, M. Perc, W. L. Yao, J. Dai, D. Guo, and D. Yao, Communications in Nonlinear Science and Numerical Simulation   96 , 105688 (2021). [16] J. H. Martinez, J. L. Herrera-Diestra,   and M. Chavez, Chaos: An Interdisciplinary Journal of Nonlinear Science  28 , 123111 (2018). [17] J. A. Martin Gonzalo, I. Pulido Valdeolivas, Y. Wang, T.   Wang,   G.   Chiclana   Actis,   M.   d.   C.   Algarra   Lu- cas, I. Palm¬¥ ƒ± Cort¬¥ es, J. Fern¬¥ andez Travieso, M. D. Tor- recillas Narv¬¥ aez,   A. A. Miralles Martinez,   E. Rausel, D. G¬¥ omez Andr¬¥ es,   and M. Zanin, Entropy   21 , 868 (2019). [18] M. Zanin, Chaos:   An Interdisciplinary Journal of Non- linear Science   31 , 103118 (2021). [19] G. Weiss, Journal of Applied Probability   12 , 831 (1975). [20] F. P. Kelly,   Reversibility and stochastic networks   (Cam- bridge University Press, Chichester, 1979). [21] J. B. Ramsey and P. Rothman, Journal of Money Credit & Banking   28 , 1 (1995). [22] M. D. Costa, A. L. Goldberger, and C. K. Peng, Physical Review Letters   95 , 198102 (2005). [23] M. D. Costa, C. K. Peng,   and A. L. Goldberger, Car- diovascular Engineering   8 , 88 (2008). [24] A. Porta, K. R. Casali, A. G. Casali, T. Gnecchi-Ruscone, E. Tobaldini, N. Montano, S. Lange, D. Geue, D. Cysarz, and P. Van Leeuwen, American Journal of Physiology Regulatory Integrative & Comparative Physiology   295 , 550 (2008). [25] P. Guzik, J. Piskorski, T. Krauze, A. Wykretowicz,   and H. Wysocki, Biomedizinische Technik Biomedical Engi- neering   51 , 272 (2006). [26] C. L. Ehlers, J. Havstad, D. Prichard,   and J. Theiler, Journal of Neuroscience the Official Journal of the Soci- ety for Neuroscience   18 , 7474 (1998). [27] L. Lacasa, A. Nunez, E. Roldan, J. M. R. Parrondo, and B. Luque, European Physical Journal B   85 , 217 (2012). [28] L.   Lacasa   and   R.   Flanagan,   Physical   Review   E   92 , 022817 (2015). [29] R. Flanagan and L. Lacasa, Physics Letters A   380 , 1689 (2016). [30] L. Lacasa, B. Luque, F. Ballesteros, L. Jordi,   and J. C. Nuno, Proceedings of the National Academy of Sciences of the United States of America   105 , 4972 (2008). [31] J. F. Donges, R. V. Donner, and J. Kurths, Europhysics Letters   102 , 381 (2013). [32] Y. Zou, R. V. Donner, N. Marwan, J. F. Donges,   and J. Kurths, Physics Reports   787 , 1 (2019). [33] H. Zeng, M. Alava, E. Aurell, J. Hertz,   and Y. Roudi, Physical Review Letters   110 , 210601 (2013). [34] H. Zeng, E. Aurell, M. Alava,   and H. Mahmoudi, Phys- ical Review E   83 , 041135 (2011). [35] C. S. Daw, C. E. A. Finney,   and E. R. Tracy, Review of Scientific Instruments   74 , 915 (2003). [36] C. Cammarota and E. Rogora, Chaos, Solitons & Fractals  32 , 1649 (2007). [37] C. Bandt and B. Pompe, Physical Review Letters   88 , 174102 (2002). [38] C. Bandt, ‚ÄúPermutation entropy and order patterns in long time series,‚Äù in   Time Series Analysis and Forecast- ing   (Springer, 2016) pp. 61‚Äì73. [39] C. Bandt, Statistical Papers   61 , 1565 (2020). [40] W. Yao, W. Yao,   and J. Wang, Physics Letters A   430 , 127977 (2022). [41] W. Yao, W. Yao, J. Wang,   and J. Dai, Physics Letters A   383 , 738 (2019). [42] W. Yao,   W. Yao,   R. Xu,   and J. Wang, Communi- cations in Nonlinear Science and Numerical Simulation  117 , 106925 (2023). [43] J. M. Amigo, L. Kocarev,   and J. Szczepanski, Physics Letters A   355 , 27 (2006). [44] J. M. Amigo, S. Zambrano,   and M. A. Sanju¬¥ an, Euro- physics Letters   79 , 50001 (2007). [45] J. M. Amigo, S. Zambrano,   and M. A. Sanju¬¥ an, Euro- physics Letters   83 , 60005 (2008). [46] M. Zanin, Chaos:   An Interdisciplinary Journal of Non- linear Science   18 , 013119 (2008). [47] L. C. Carpi, P. M. Saco,   and O. Rosso, Physica A: Sta- tistical Mechanics and its Applications   389 , 2020 (2010). [48] C. W. Kulp, L. Zunino, T. Osborne,   and B. Zawadzki, Physical Review E   96 , 022218 (2017). [49] D. Cuesta Frau, Entropy   22 , 494 (2020). [50] C. Bian, C. Qin, Q. D. Ma, and Q. Shen, Physical Review E   85 , 021906 (2012). [51] L. Zunino, F. Olivares, F. Scholkmann, and O. A. Rosso, Physics Letters A   381 , 1883 (2017). [52] D. Cuesta Frau, M. Varela Entrecanales, A. Molina Pico, and B. Vargas, Complexity   2018 , 1324696 (2018). [53] W. Yao, W. Yao,   and J. Wang, Physics Letters A   383 , 1764 (2019). [54] W. Yao, W. Yao, D. Yao, D. Guo, and J. Wang, Applied Physics Letters   116 , 014101 (2020). [55] W. Yao, W. Yao, Y. Ju, Y. Xia, D. Guo,   and D. Yao, Biomedical Signal Processing and Control   69 , 102738 (2021). [56] W. Yao, W. Yao,   and J. Wang, Physiological Measure- ment   44 , 095004 (2023). [57] A. L. Goldberger, L. A. Amaral, L. Glass, J. M. Haus- dorff, P. C. Ivanov, R. G. Mark, J. E. Mietus, G. B. Moody, C. Peng,   and H. E. Stanley, Circulation   101 , e215 (2000). [58] A. Rechtschaffen and A. Kales,   A manual of standard- ized terminology, techniques and scoring system for sleep stages of human subjects   (U.S. Government Printing Of- fice, National Institute of Health Publication, Washing- ton, D.C.,, 1968). [59] Y. Ichimaru and G. B. Moody, Psychiatry and Clinical Neurosciences   53 , 175 (1999).",
      "embedding": [
        -0.0039859251119196415,
        -0.05434296652674675,
        0.07728993892669678,
        -0.021301094442605972,
        0.013112742453813553,
        0.013421798124909401,
        0.0400426983833313,
        -0.024440370500087738,
        0.1511179804801941,
        0.030654143542051315,
        -0.028199123218655586,
        -0.026555135846138,
        0.05057096853852272,
        0.016007350757718086,
        -0.002941872226074338,
        -0.044701989740133286,
        -0.01852421462535858,
        -0.02065616101026535,
        -0.03362632542848587,
        0.02370707504451275,
        0.10020249336957932,
        -0.060392484068870544,
        0.010479026474058628,
        -0.05909416824579239,
        -0.026315977796912193,
        0.03763918951153755,
        0.01901897042989731,
        -0.018725911155343056,
        -0.012326788157224655,
        -0.09327363222837448,
        -0.034365732222795486,
        0.04735241085290909,
        -0.024857280775904655,
        -0.0002809882571455091,
        -0.03181668370962143,
        0.004745465703308582,
        0.03197844326496124,
        -0.03319358825683594,
        -0.07767388224601746,
        0.00016655464423820376,
        0.04548915848135948,
        0.00223718723282218,
        0.0037773624062538147,
        -0.0641445443034172,
        0.01430622860789299,
        0.06009340286254883,
        0.030656039714813232,
        -0.15856681764125824,
        -0.0956910252571106,
        -0.00490204244852066,
        -0.012017570436000824,
        0.10045622289180756,
        -0.034044232219457626,
        0.06262265145778656,
        -0.02111729048192501,
        0.02135150507092476,
        0.001287518534809351,
        0.043206725269556046,
        0.022456441074609756,
        0.04411587864160538,
        -0.06845451146364212,
        0.04273942857980728,
        0.07244002819061279,
        -0.06446363031864166,
        0.07689739763736725,
        0.08969752490520477,
        0.000010856300832529087,
        -0.06039780005812645,
        -0.005975362844765186,
        -0.038491036742925644,
        -0.08198285847902298,
        -0.0014273577835410833,
        -0.017849644646048546,
        -0.028318116441369057,
        -0.050840381532907486,
        0.050366681069135666,
        0.0562482625246048,
        -0.022770872339606285,
        0.0036728051491081715,
        -0.09217730164527893,
        -0.04680701345205307,
        0.023262251168489456,
        0.027266576886177063,
        -0.015052160248160362,
        0.028341205790638924,
        0.0011068822350353003,
        0.03384982794523239,
        0.09084255248308182,
        -0.03069152869284153,
        0.04268328845500946,
        0.010026147589087486,
        -0.03953472152352333,
        -0.018146736547350883,
        -0.00912892259657383,
        0.0856037586927414,
        0.06255975365638733,
        0.026478465646505356,
        0.04981636628508568,
        0.11955388635396957,
        -0.03031321056187153,
        0.01543625257909298,
        0.028968721628189087,
        -0.027795862406492233,
        0.04615321755409241,
        -0.0023478693328797817,
        0.022394385188817978,
        0.05183558166027069,
        -0.059510260820388794,
        0.01198927778750658,
        -0.02203935757279396,
        -0.04616805538535118,
        0.0565682128071785,
        0.038467515259981155,
        0.08661123365163803,
        0.026896774768829346,
        0.02729467861354351,
        -0.0748598724603653,
        0.10763604193925858,
        0.12252483516931534,
        -0.027492888271808624,
        0.09426125884056091,
        -0.03933049738407135,
        0.06194201484322548,
        -0.07354000210762024,
        0.03902151435613632,
        -0.027887487784028053,
        -0.06599478423595428,
        7.076051344615936e-33,
        -0.035649918019771576,
        0.0018167586531490088,
        -0.011202109977602959,
        -0.047010041773319244,
        0.011910956352949142,
        -0.020339224487543106,
        -0.04247484728693962,
        0.019564127549529076,
        0.058803655207157135,
        0.05080888047814369,
        -0.049937859177589417,
        0.05039322376251221,
        0.057801198214292526,
        -0.013363045640289783,
        0.010752021335065365,
        0.018849974498152733,
        -0.03035208210349083,
        0.02210995741188526,
        -0.022141017019748688,
        -0.1129569485783577,
        0.050828784704208374,
        -0.02144790068268776,
        0.03633156046271324,
        -0.010418196208775043,
        -0.034417301416397095,
        0.01652591861784458,
        -0.0702214166522026,
        0.0006206708494573832,
        -0.05723525583744049,
        -0.005995892453938723,
        0.006962033454328775,
        0.03109576739370823,
        -0.0338798426091671,
        -0.04628264158964157,
        0.015171392820775509,
        -0.04174923151731491,
        0.07859614491462708,
        0.04234958812594414,
        0.013564273715019226,
        0.003589482279494405,
        0.003374699503183365,
        0.04553356394171715,
        0.006716038566082716,
        0.015151900239288807,
        0.03664287552237511,
        -0.019485898315906525,
        0.046597711741924286,
        0.08241847157478333,
        0.05306458845734596,
        0.010502257384359837,
        -0.08460765331983566,
        -0.09260521829128265,
        0.018627207726240158,
        -0.1063605397939682,
        -0.007506642024964094,
        0.015786541625857353,
        0.00725041376426816,
        0.025973431766033173,
        -0.0340951569378376,
        0.10540155321359634,
        -0.02419949509203434,
        0.0859624519944191,
        0.04291105270385742,
        -0.057606957852840424,
        0.04554113373160362,
        -0.004587275441735983,
        -0.10041174292564392,
        -0.04271285980939865,
        0.02567710541188717,
        -0.02350999228656292,
        0.06995978206396103,
        0.040986157953739166,
        0.04786045849323273,
        -0.02918204851448536,
        0.07806793600320816,
        -0.04817354679107666,
        -0.01907501183450222,
        0.0693715438246727,
        -0.07731543481349945,
        -0.0958266407251358,
        0.008127095177769661,
        -0.025565342977643013,
        -0.0304048340767622,
        -0.08965370059013367,
        -0.0258595272898674,
        -0.022193657234311104,
        0.01927887462079525,
        0.0115181440487504,
        -0.17422768473625183,
        -0.01589992828667164,
        0.06781890988349915,
        -0.03045782446861267,
        0.062165819108486176,
        -0.004449757747352123,
        -0.11279183626174927,
        -6.668879937958266e-33,
        -0.03939079865813255,
        -0.02522878907620907,
        -0.018888477236032486,
        0.01472284272313118,
        0.07223260402679443,
        -0.009020947851240635,
        0.08553555607795715,
        0.0077765570022165775,
        -0.03183864429593086,
        -0.0685872808098793,
        0.07332869619131088,
        -0.025174684822559357,
        -0.0014635997358709574,
        0.005663893185555935,
        0.02823113463819027,
        -0.035862892866134644,
        0.007794292643666267,
        0.09325892478227615,
        -0.009977592155337334,
        0.09703628718852997,
        -0.0714329406619072,
        0.04072682186961174,
        -0.07359579205513,
        -0.031856928020715714,
        0.022424301132559776,
        0.11338102072477341,
        0.03608737885951996,
        0.06632788479328156,
        0.02316214144229889,
        -0.00034403573954477906,
        -0.04972995072603226,
        0.019753839820623398,
        -0.11618088185787201,
        0.024910544976592064,
        0.029951991513371468,
        -0.03846431151032448,
        0.020983897149562836,
        -0.0609775111079216,
        -0.03229577839374542,
        -0.062285687774419785,
        0.08719727396965027,
        0.1312817484140396,
        0.032172512263059616,
        -0.07989653944969177,
        0.028915027156472206,
        0.05609744042158127,
        -0.0395524725317955,
        -0.007446458097547293,
        -0.029632791876792908,
        -0.019334957003593445,
        0.05270460620522499,
        0.022273609414696693,
        -0.06475028395652771,
        -0.0326068215072155,
        -0.028176363557577133,
        0.01824100874364376,
        -0.0167473666369915,
        0.019608426839113235,
        0.0255870521068573,
        0.024715032428503036,
        -0.02331765554845333,
        -0.001551149063743651,
        0.07157779484987259,
        -0.012781037017703056,
        0.004780877381563187,
        0.047526322305202484,
        0.0035113245248794556,
        -0.029625123366713524,
        0.05738363787531853,
        -0.06360994279384613,
        0.029863299801945686,
        -0.03652750700712204,
        0.02066195011138916,
        -0.029673242941498756,
        0.0055144657380878925,
        0.034598011523485184,
        0.030077584087848663,
        -0.04692384600639343,
        -0.025492867454886436,
        -0.10082077234983444,
        -0.07179535180330276,
        -0.03791666030883789,
        -0.09651058912277222,
        -0.061505258083343506,
        -0.07981263101100922,
        0.010163163766264915,
        -0.013536759652197361,
        -0.001149123185314238,
        0.0817401260137558,
        -0.04749840125441551,
        -0.030090458691120148,
        0.027734648436307907,
        -0.06568580120801926,
        0.02846689149737358,
        0.06055057421326637,
        -5.7510625595114107e-8,
        0.04538595676422119,
        -0.05522625148296356,
        0.02991745062172413,
        0.051951345056295395,
        0.03826495632529259,
        -0.019199173897504807,
        0.0718369111418724,
        -0.06235139071941376,
        -0.07465440034866333,
        -0.010298393666744232,
        0.13345159590244293,
        -0.017523426562547684,
        0.058019738644361496,
        -0.07267694920301437,
        0.04771297797560692,
        0.02802959270775318,
        0.00044911581790074706,
        0.02557467669248581,
        -0.016086647287011147,
        -0.05799976736307144,
        0.004328983370214701,
        -0.032770298421382904,
        -0.06537390500307083,
        -0.04542268440127373,
        0.04557779058814049,
        0.043634943664073944,
        -0.027716726064682007,
        -0.03511359170079231,
        -0.014810770750045776,
        -0.07120615988969803,
        0.03076634742319584,
        -0.02311648055911064,
        0.05500255897641182,
        0.0046812319196760654,
        0.019491367042064667,
        -0.04506561905145645,
        0.035046208649873734,
        0.007858434692025185,
        -0.006832416635006666,
        0.12322528660297394,
        -0.026176171377301216,
        -0.08005037903785706,
        -0.08435327559709549,
        0.0073188054375350475,
        0.046662215143442154,
        -0.033272258937358856,
        0.02827063947916031,
        -0.07243264466524124,
        0.00046678874059580266,
        -0.03289054334163666,
        -0.04356661066412926,
        -0.03798506781458855,
        -0.019263798370957375,
        -0.0702725425362587,
        0.009494556114077568,
        0.019438423216342926,
        0.005750584416091442,
        -0.012699867598712444,
        -0.013335766270756721,
        -0.031230328604578972,
        0.11316066980361938,
        0.040986962616443634,
        -0.08506027609109879,
        -0.039435118436813354
      ],
      "metadata": {
        "title": "Paper_7_Permutation_time_irreversibility_in_sleep_electroe.pdf",
        "createdAt": "2025-12-17T13:56:42.722Z"
      },
      "fileObj": {}
    },
    {
      "id": "doc_17_1765979803632",
      "fileName": "Paper_6_Quantum_Anti_Zeno_Treatment_of_Zeno_type_Sleep_Dis.pdf",
      "content": "1  Quantum Anti-Zeno Treatment of Zeno-type Sleep Disorders  Rajat Kumar Pradhan* Rajendra College, Bolangir, Odisha, India-767002 (Date: 19.11.2011)  Abstract  It is proposed that for those sleep disorders of psychological origin which can be considered to be a Quantum Zeno Effect-type phenomenon of   persistence in the waking state   due to the inhibition of the transition to the Deep Sleep state, the treatment may very well lie in the application of the principle of   accelerating the decay by the introduction of a third state   which facilitates the transition as realized in the Quantum Anti-Zeno effect. Steps of practical therapeutic implementation of the program are delineated. Keywords: Quantum Zeno Effect, Quantum Anti-Zeno Effect, Sleep Disorders, Insomnia, States of Consciousness. PACS Numbers: 03.65.Xp, 87.19.Xx, 87.10+e, 87.19La  *email:   rajat@iopb.res.in\n\n2  1. Introduction  Quantum theory[1,2,3] is gradually proving to be the most versatile and the most successful framework for the investigation of diverse phenomena in the realms of matter as well as mind.   It has been proposed that the well-known Quantum Zeno Effect (QZE)[4,5] plays the most important role   in   establishing   the   mind-brain   relationship[6,7]   through   continued   attention.   That   the phenomena in the planes of the physical and the psychical have a lot of parallels and that they can be described by very similar methods was realized long ago by Pauli and Jung[8]. It has also been proposed recently by the present author[9] that the three states of consciousness, viz. waking, dreaming and sleep, experienced daily may be described by the composition of two spin-like quantum mechanical observables characterizing the subject and the object. The formulation is such that it allows for finer experiential modes or levels within each state or band. For example, one can say that the experiential state   |   (   i ,t)>   at time t is that of the i th   thought-form   i . In the waking state   |   1 (   i ,t)>   each thought-form has an objective counterpart   i   in the external physical world whose neural correlate is perceived as that thought-form or mental image   i . Similarly, we can also characterize the dream state at time t as   |   2 (   i ¬¥,t)>   ( ‚Äòt‚Äô is the waking time)   when the dream-form   i ¬¥ corresponding to   i   is experienced.   The continuous streams of such thought-forms make up our daily experience in the waking and dream states. However, the state of deep sleep   |   3 >   happens to be different since it is characterized by   non-perception   of   either   the   internal   thought-forms   or   of   their   external   objective counterparts. It is an objectless and thoughtless state of ignorance or unconsciousness that we call deep sleep. The period spent by a healthy adult in deep sleep is roughly 6-7 hrs/day i.e. about one-third of the period spent in non-sleep. The transition to sleep and also the emergence therefrom is usually through the intermediate state of dream   |   2 >   in healthy and normal persons although the direct route is also available[9]. Insomnia (sleeplessness) then becomes a phenomenon in which the transition from   |   1 >   to   |   3 >   through the direct and the dream routes is inhibited due to any one or more of the three factors: (a) Environmental factors (b) Physiological factors and (c) Psychological factors. In this article, we shall assume that the first two factors are either absent or have been fully taken care of and that the sleep disorder is due only to the psychological causes i.e. the patient tries to sleep at the appropriate time but because of some thoughts running riot in his head he is unable to   ‚Äò switch himself off   ‚Äô   to move into dream and consequently to sleep. (It is to be remembered that normally the pre-sleep dreams are not registered as experience unless  some disturbance wakes one up in the threshold of one‚Äôs entry into deep sleep. ). Just as a person can come directly to   |   1 >   from   |   3 >   when there is some sudden disturbance (external noise or some other such forceful sensory input), so also the sleeping pills can enforce the direct transition to   |   3 >   from   |   1 >   which is more important in the treatment in acute cases. This is because the dream route requires   |   4 > , the fourth state, which is even more difficult to pass on to compared to   |   3 >   in the case of patients with acute sleep disorder. However, once the acuteness is reduced by medication, the case is not cured but reduces to chronic insomnia. Thus, we assume that once the patient is led into   |   2 > , the transition to   |   3 >   is automatic and smooth and the central problem then becomes one of effecting the transition from   |   1 >   to   |   4 >   which will lead naturally to   |   2 >   and from then on to   |   3 > .\n\n3  We propose that this particular type of insomnia can be modeled as a QZE-type inhibition of the transition from   |   1 >   to   |   4 >   due to the persistent experience of the rioting thoughts in the waking state. This persistent experience of the waking state is the counterpart of inhibition of transition due to continuous measurement in QZE. We propose further a non- medicinal treatment of the same disorder basing on the inverse phenomenon of Quantum Anti-Zeno Effect (QAZE) [10,11], wherein the intentional introduction of an auxiliary state  |   1 (   a , t)> facilitates this transition. In section-2 we paraphrase the problem of stress-induced insomnia as a QZE and in section-3   we   present   the   proposed   solution   via   QAZE.   In   section-4   practical   steps   of eliminating the environmental and physical factors and of aiding the QAZE transition are delineated which can be practiced under expert supervision for the first one week or so individually or in groups. Afterwards, the patients may be asked to continue the method of perfecting the QAZE-transition themselves. In section-5 we conclude with a discussion of the limitations of the method and other possible applications. The whole article is written in a non-technical manner so that it is easily accessible to doctors, psychiatrists as well as to the patients and laymen.  2. Insomnia as Quantum Zeno Effect  The majority of secondary insomnia cases happen to be due to psychological factors which delay the onset of sleep beyond limit and the patients complain of uncontrollable thoughts running riot the moment they retire to bed and close their eyes. The problem gets further complicated by the apprehension of recurrence of the same phenomenon every night and this weakens the will of the patients considerably and they complain of recurrent sleepless nights i.e. chronic insomnia. In most of the cases, it is found that the kinds of thoughts that bother them are mostly those of some past or future trouble. It is only very rarely that one gets sleep disorders due to too much of pleasant experiences. Pleasant experiences, fancies and fantasies usually usher in good sleep! It is the unpleasant experiences like disasters and debacles, fears and phobias, failures and frustrations, insults and abuses, mishaps and misfortunes, losses and bereavements, traumas and tortures etc. which one has undergone or is likely to undergo that come to haunt the patient on the bed. The patient may struggle for hours together without getting any semblance of sleep and this phenomenon in chronic cases may continue even beyond a month or so. This is the case that can be taken up as a classic illustration of Quantum Zeno Effect in the psychological domain, where the continuous cognizance of the problematic thoughts   p   by the consciousness prevents the momentary slide into the fourth state which could have brought the dream state on, and which in its sequel would have ushered in deep sleep. It is proposed here that this inhibited transition from   |   1 (   p   ,t)> to   |   4 >   due to continuous observation can be removed by recourse to the inverse process of Quantum Anti-Zeno Effect.  In fact, it seems that all cases of insomnia, including the primary ones of unknown causes, whether chronic or acute, can be considered as being effectively due to this kind of QZE and correspondingly can be cured using QAZE. It is clear that the proposed solution will have to be of the psychological type, and hence, non-medicinal, but one that can easily be practiced by anyone suffering from any kind of insomnia. In this respect, when it comes to the choice of an auxiliary state in QAZE for fixing the attention on, it is worth emphasizing that of the many involuntary processes that continue throughout the day including the period of deep sleep the most important\n\n4  and vitally significant one is respiration and the awareness effortlessly but very effectively be fixed on the breathing process.  3. Insomnia Treatment by Quantum Anti-Zeno Effect  The insomnia patient‚Äôs main trouble is the inability to withdraw the mind from the  problematic thoughts and this can effectively be dealt with by introducing another thought on which the attention can be easily fixed. This new thought will be the auxiliary thought-form with a greater awareness and willful attention than the problematic thought-form and it will decrease the frequency with which the problematic thoughts were engaging the attention. The characteristic restlessness of the mind implies that it gets bored of monotony and one-pointedness and if continuously and consciously it is fed with something monotonous it will easily lapse into sleep. Consciously trying to focus on this auxiliary thought-form will gradually bring in the required transition to the fourth state from which the patient will move into the dream and from then on to deep sleep. This is the program of treatment by the ant-Zeno effect. In many situations in physics, it has been observed that a normal transition is inhibited by the QZE and is accelerated by the QAZE in the presence of the auxiliary state. Further as required by the theory of QAZE, the auxiliary state is of higher energy (i.e. frequency) compared to the problem state and admits of transitions back and forth with it. This is precisely the case here but only thing is that we are considering the application in a psychological setting. The four states of consciousness are depicted in Fig. 1a below and in Fig. 1b we show all the transitions as per the QAZE.  As shown in Fig.1a, for normal persons, the transition from waking to dream through the thin layer of the fourth state is naturally accomplished without any effort and then deep sleep ensues as a matter of course, while for the insomniac this transition is inhibited by the QZE-type continuous dwelling in the problematic waking state   |   1 (   p   ,t)>. In Fig. 1b,   |   1 (   a   ,t)> is the auxiliary waking state with a different thought-form   a ,   introduced   to   divert the attention from   p   and thus disrupt the QZE. Again, there will be a seeming tussle between   a   and   p   to engage the patient‚Äôs  continued attention and in the beginning the auxiliary state may seem to be an additional complication!   It is almost an implementation of the old adage: ‚Äú  set a thief to catch a thief !‚Äù   But, it works, thanks to the mysterious nature of Quantum phenomena which baffle classical thinking, whether applied to the physical or the psychological phenomena, and one finds to  |   4 >  FIG. 1 a :   Schematic of the four states of conscious -  - ness with   |   4 >   as common background  WAKING:   |   1 >  AUXILIARY STATE :   |   1 (   a   ,t)>  PROBLEM   STATE :   |   1 (   p   ,t)>  DREAM STATE:   |   2 >  DEEP SLEEP STATE :   |   3 >  THE FOURTH STATE:   |   4 > ( Both   individual awareness and willful attention  increase vertically upwards in this diagram)  FIG. 1b   : The transitions in the QAZE sequence  DREAM:   |   2 >  DEEP SLEEP:   |   3 >\n\n5  one‚Äôs surprise that in a matter of   about ten minutes to half an hour or so, the patient will be fast asleep via the QAZE transitions! Now comes the question of the exact nature of the auxiliary thought   a , which is of central importance in the entire process. Although   a   could be any pleasant thought-form on which the patient likes to dwell upon for a longer period, it turns out that the most effective, unbiased and natural choice is the   ‚Äò  attention on the breath ‚Äô . Just gently trying to focus on the normal, natural, relaxed breathing will do the trick! Initially, if need be, one may count the exhalations   one   by   one   serially   if   the   disturbance   from   the   thought(s)   p   is   a   bit uncontrollable, but after the first five minutes or so, one may stop counting and try to concentrate   only   on   the   natural   breathing   pattern   without   bothering   much   about   the frequency of   p . In the first few attempts the patient may feel a little tired or bored of the entire exercise, and may, if need be, allowed to have an accompanying mental utterance of some self-chosen holy name or formula ( mantra) depending on the faith and temperament. This has a very helpful effect but it is not absolutely necessary in all cases. Only a little patience on the part of the patient in participating in the whole therapy will work wonders even if   a   is  only the ‚Äòconcentration on the breathing‚Äô.  It is to be emphasized that the conscious focusing of attention on   a   must not be considered as a fight or a battle with the persistence of   p , rather, one should deal with the issue in a very mild and gentle manner allowing the mind its own freedom of dwelling on   p  every now and then. The only job is to focus on   a , and not to fight a battle with   p . As many times as it wonders off to   p , so many times very calmly and gently it should be brought back to   a   without generating any tension or sense of struggle.  4. Practical steps of Anti Zeno-therapy  The most important part of this delicate method of treatment is the preparation stage for the application of the Anti-Zeno therapy to insomnia cases. It is to be emphasized that the three conditions necessary for an early onset of sleep are: (a) a relaxed body (b) a natural rhythmical breathing and (c) a calm, tension-free mind.   In one phrase it is ‚Äòa total relaxation‚Äô of the individual - relaxed body, relaxed breathing and relaxed mind. Therefore, apart from ensuring that the patient has the right kind of cooperative attitude to receive the therapy and a positive attitude towards the efficacy of the therapy the following steps may be noted by the therapist:  Removal/avoidance of all environmental and physiological factors which have the potential to disturb or delay the onset of sleep i.e. stimulating food, drinks, music and video that excite the mind too much. All sensory inputs throughout the day must invariably be of a soothing nature which helps bring about a calm interior. All kinds of worries, cares and anxieties are to be avoided at all costs.  Making available all the helpful factors for inducing sleep such as:   (a) sleeping on back or on the left side (b) remaining fully engaged in some self-chosen work which the patient enjoys doing in the most relaxed manner possible during the day (c) regularity of the daily schedule of life etc.  Instructions may be given directly or through a record-player in a commanding voice to start with, followed by a gradual switch over to a very soothing and sweet voice as the patient is guided into deep sleep. The commands in the beginning lessen the vehemence of the problematic thoughts by much, more so if the treatment is in a group. They also have a very\n\n6  positive impact on the overall receptivity of the patient and the fixing of attention on the breath becomes much easier.  In case of individual patients, constant watch may be kept on the patient‚Äôs eyelids for the  onset of dream through REM-sleep, in which case the instructions may be switched off to allow for sleep to ensue.  In group-therapy sessions, the instructor may switch over to the soothing mode after the first five minutes or so.  The first few instructions should be on lying flat on the back followed by the step-by-step relaxation of the whole body starting with the toes and ending at the crown of the head.  The whole session should be in a very friendly and warm environment where the patient feels completely relieved and relaxed and fully at home.  These are some of the very helpful practical hints which are essential for the therapy. With experience the therapist will gain strength and the success rate will be very high. After a week of guided therapeutic sessions the patients should be watched in one or two do-it-yourself sessions before their release. Once the patient gets confidence in the Anti-Zeno practice, insomnia is effectively fully cured.  5. Discussion & Conclusion  We have proposed for the first time a novel method of treatment of insomnia exploiting the parallelism of the situation involving the states of consciousness with the physics of Quantum Zeno and the Anti-Zeno Effects, which have been experimentally observed in laboratories in many physical systems. A theoretical objection may be raised regarding the efficacy of the procedure in the event of the continuous observation of the breathing leading to another Quantum Zeno Effect involving this new auxiliary state, in which case the patient effectively has now   a   ‚Äì   insomnia in place of   p   ‚Äì   insomnia! This apprehension, however, is without basis since breathing is natural in sleep and is therefore not an obstacle to sleep, while the problematic thoughts are an obstacle. As regards the awareness of breaths which is not natural to sleep, since sleep means non-awareness of everything including breathing, the state of the patient then becomes one of  ‚ÄúYogic   sleep‚Äù   or  Yoga-nidra,   [12],   which   grants   all   the   benefits   of   sleep   (restfulness, rejuvenation, freshness, renewed vigor and vitality etc.) and at the same time takes away all the evils of insomnia (uneasiness, weirdness, heaviness, headache, drowsiness, sloth, stupor, fatigue, etc.), in which case also the patient is cured! Also, as far as the cure is concerned it matters little whether the transition is from   a   or   p   and whether the transition is direct or through intermediate states.  In fact, the Anti-Zeno Therapy proposed here has been somewhat in practice in the theory and practice of Yoga and Meditation[12]. In particular, the step-by-step whole-body-relaxation is an essential part of the practice of a Yogic posture known as   savasana   (the corpse pose) which very often lands the practitioner in deep sleep. Similarly,   ‚Äò concentration on the breath ‚Äô is a preliminary  technique in the practice of concentration and meditation with a view to making the mind one- pointed and finally thoughtless. But in both the cases, the lapse to sleep is the most undesirable event and is considered as an obstacle, since the continuity of awareness is of paramount importance in all yogic practices, and the onset of sleep obviously deprives one of that. But, the failure (lapse- to-sleep) of the Yoga-meditation practitioner is verily th e ‚Äòglorious triumph‚Äô for the insomniac!   And,  it seems that finally there must be some truth in alternative therapies like ‚ÄòYoga‚Äô.\n\n7  It is worth noting that the problematic thought-form   p   is not a singular form but is usually dressed with two or three other associated thought-forms which succeed in keeping the mind revolving, though centered on   p . Thus, there is a difference between   p   and the auxiliary thought-form   a   which is more of a singular nature and thus easily succeeds in getting the mind bored of monotony thereby facilitating the transition to sleep. The application of quantum theory to understand the dynamics of the mind has, of course, its own limitations. For one thing, the physical systems investigated in relation to QZE and QAZE are more or less of known eigenstates with known energy eigenvalues, while here the corresponding property is the willful attention (or awareness) which evolves with time and thus the states corresponding to   p   and   a   do not remain fixed with time. The actual dynamics demands that they gradually shift downwards (see Fig. 1b). It may even so happen that as the attention stabilizes more and more on   a   and, consequently, as the mind starts withdrawing itself,   |   1 (   a   ,t)> may slide below   |   1 (   p   ,t)> and this may bring in another real but beneficial QZE with   |   1 (   a   ,t)>. In this case the QAZE transition may very well involve the dream state   |   2 >   itself because of its closeness to the auxiliary state. In such a situation, whether a similar Anti-zeno therapy will be the helpful in the cases of dreamful insomnia, where   |   2 >   rather than   |   1 >   is the problematic state, needs further investigation.  Acknowledgements  The author gratefully acknowledges the impetus, invitation and inspiration from Reem Ali for writing this article.  References  [1] H. P. Stapp,   Mindful Universe: Quantum mechanics and the Participating Observer , (Springer, Berlin, Heidelberg, New York, 2007).  [2]   J. M. Schwartz, H.P. Stapp, and M. Beauregard,   Quantum theory in neuroscience and Psychology:A neurophysical model of the mind/brain interaction . Phil. Trans. Royal Soc. B 360 (1458) 1306 (2005).  [3]   H. P. Stapp ,   A Model of the Quantum-Classical and Mind-Brain Connections, and of the Role of The Quantum Zeno Effect in the Physical Implementation of Conscious Intent , (2008)  http://arXiv.org/abs/0803.1633  [4] B. Misra and E.C.G. Sudarshan   J. Math. Phys.   18 756,(1977) [5] W. M. Itano, D. J. Heinzen and J.J. Bollinger, and D. J. Wineland,   Phys. Rev.   A 41 2295(1990) [6] E. Manousakis,   Quantum formalism to describe Binocular rivalry .Biosystems, 98, 57-66, (2009) [7] H. P. Stapp ,   The Quantum-Classical and Mind-Brain Linkages: The Quantum Zeno Effect  in Binocular Rivalry ,   http://arXiv.org/abs/0710.5569  [8] W. Pauli and C. G. Jung, Atom and the Archetype, Pauli/Jung, letters, 1932-1958, Ed. C. A. Meier, (Princeton University Press, Princeton, 2001). [9] R. K. Pradhan,   Subject-Object duality and tha states of Consciousness: A Quantum Approach , Neuroquantlogy, 8, 3, 262-278,( 2010)  [10] B. Kaulakys, V. Gontis, Quantum anti-Zeno effect, phys. rev. A 56, 2, 1997, 1050-2947 [11] Qing Ai, Dazhi Xu, Su Yi, A. G. Kofman, C. P. Sun and Franco Nori ,   Quantum anti-Zeno  effect without wave function reduction ,   http://arXiv.org/abs/1007.4859  [12] Swami   Sivananda, ‚Äò How to Get Sound Sleep ‚Äô,   3 rd   edition, DLS Publications, India, (2003).",
      "embedding": [
        -0.0862414538860321,
        0.007877588272094727,
        -0.04279585927724838,
        0.08092848211526871,
        -0.034819670021533966,
        0.05688481032848358,
        0.05670889839529991,
        -0.031200192868709564,
        0.13016866147518158,
        0.011861167848110199,
        -0.0652695745229721,
        -0.010418886318802834,
        -0.00362091395072639,
        0.007099635899066925,
        0.02554173581302166,
        0.029399141669273376,
        0.04110652580857277,
        0.03809477761387825,
        -0.03228391706943512,
        0.06643848121166229,
        0.04288046434521675,
        -0.027673417702317238,
        0.049199726432561874,
        -0.017680896446108818,
        -0.01575998030602932,
        0.021116182208061218,
        0.033698756247758865,
        -0.07879845052957535,
        0.025314832106232643,
        0.01190291065722704,
        0.01155026350170374,
        0.14582064747810364,
        -0.06269629299640656,
        -0.03142427280545235,
        -0.013040811754763126,
        -0.005541274324059486,
        -0.022852465510368347,
        0.02248499169945717,
        -0.06399606913328171,
        -0.059791941195726395,
        0.06778506189584732,
        0.05687185749411583,
        -0.1059550940990448,
        -0.03215968608856201,
        -0.023723406717181206,
        0.009319370612502098,
        0.06278865039348602,
        -0.029237858951091766,
        -0.06652818620204926,
        -0.11630746722221375,
        -0.08746565878391266,
        0.026787683367729187,
        -0.03623262047767639,
        0.10952520370483398,
        0.013658602721989155,
        0.03932798653841019,
        0.010665223002433777,
        0.050927694886922836,
        -0.10970843583345413,
        -0.039281755685806274,
        -0.06532592326402664,
        0.026889050379395485,
        -0.0016748529160395265,
        -0.005054608918726444,
        0.13753865659236908,
        0.04203571379184723,
        -0.05556318536400795,
        -0.0012079030275344849,
        0.010546964593231678,
        -0.04638834297657013,
        -0.07263042777776718,
        -0.0081714428961277,
        -0.040153175592422485,
        -0.06700596958398819,
        0.012868172489106655,
        -0.01889510452747345,
        0.04522457718849182,
        0.04050757363438606,
        0.004521229304373264,
        -0.03269201144576073,
        0.028205446898937225,
        0.019189324229955673,
        0.06487478315830231,
        -0.07677284628152847,
        -0.01280367560684681,
        0.08459991216659546,
        0.0404789000749588,
        0.05769861489534378,
        -0.057975150644779205,
        0.050092149525880814,
        0.025442562997341156,
        -0.03868631273508072,
        -0.07582420110702515,
        -0.019592206925153732,
        0.10951287299394608,
        -0.036325156688690186,
        0.04317382350564003,
        0.019994189962744713,
        0.07915903627872467,
        0.015128170140087605,
        0.11212925612926483,
        0.019009053707122803,
        0.008816100656986237,
        -0.022082190960645676,
        0.025935964658856392,
        0.031895216554403305,
        0.02622593194246292,
        -0.07164418697357178,
        -0.02517414465546608,
        0.017166467383503914,
        -0.057721469551324844,
        -0.060241781175136566,
        0.0017366270767524838,
        -0.01661701686680317,
        -0.008252804167568684,
        0.02762899361550808,
        0.029621805995702744,
        0.15168945491313934,
        0.02343423292040825,
        0.011719764210283756,
        0.06839220225811005,
        -0.06650859117507935,
        0.025602979585528374,
        -0.05257784202694893,
        0.03641956299543381,
        0.017989106476306915,
        -0.08405189216136932,
        4.901707485147288e-33,
        -0.0112437903881073,
        -0.06873595714569092,
        -0.035341259092092514,
        -0.034255411475896835,
        0.03373194485902786,
        -0.022450095042586327,
        0.015247486531734467,
        -0.04976467043161392,
        0.012385819107294083,
        0.014607004821300507,
        -0.017966508865356445,
        0.03175170719623566,
        0.08759170770645142,
        0.013402985408902168,
        0.021720172837376595,
        0.014462324790656567,
        -0.10663717985153198,
        -0.03738314285874367,
        0.04148462414741516,
        -0.08938930183649063,
        0.0029954477213323116,
        0.08270261436700821,
        -0.0219525508582592,
        -0.026689432561397552,
        -0.031229620799422264,
        0.03625210002064705,
        0.020253192633390427,
        0.01844729669392109,
        -0.10468719899654388,
        0.000666008039843291,
        0.013451104052364826,
        0.08493614941835403,
        -0.09048602730035782,
        -0.07073867321014404,
        0.0010128222638741136,
        -0.013422748073935509,
        0.029449617490172386,
        0.0008661285974085331,
        -0.04392314329743385,
        -0.08109626173973083,
        -0.025495430454611778,
        -0.021434109658002853,
        -0.032445020973682404,
        0.034731972962617874,
        -0.0019094895105808973,
        -0.014401479624211788,
        0.04311962425708771,
        0.017510205507278442,
        0.0295683816075325,
        -0.04266113415360451,
        0.0022360312286764383,
        -0.09736748039722443,
        -0.07109897583723068,
        -0.07193771749734879,
        -0.06108615919947624,
        -0.008741007186472416,
        0.06505435705184937,
        0.02429153583943844,
        -0.019099511206150055,
        0.03549489378929138,
        -0.08596538752317429,
        -0.04764179512858391,
        0.007403731346130371,
        -0.02866053394973278,
        0.012093435041606426,
        -0.03561091423034668,
        -0.13466399908065796,
        -0.08940146118402481,
        -0.007812539115548134,
        0.030242161825299263,
        0.004060450010001659,
        0.03685920313000679,
        0.06867154687643051,
        0.007642653770744801,
        0.023880546912550926,
        -0.08069731295108795,
        0.015740351751446724,
        0.00996191706508398,
        -0.07586990296840668,
        0.0351712740957737,
        0.07251813262701035,
        0.003479959676042199,
        -0.04061535373330116,
        0.0007730976212769747,
        -0.050063829869031906,
        0.01075590681284666,
        -0.024388257414102554,
        -0.054063234478235245,
        -0.09971096366643906,
        0.0075624375604093075,
        0.017494283616542816,
        -0.032249998301267624,
        0.13274215161800385,
        0.004061052110046148,
        -0.05078742280602455,
        -5.4843456682361704e-33,
        -0.015261281281709671,
        -0.030758272856473923,
        -0.037043966352939606,
        -0.021276837214827538,
        0.07706848531961441,
        -0.013393179513514042,
        -0.04386742040514946,
        0.007315307855606079,
        -0.053048595786094666,
        -0.06858095526695251,
        0.04753195121884346,
        0.03822849690914154,
        0.059753261506557465,
        0.0802174061536789,
        0.00182232609950006,
        -0.02092112973332405,
        0.015963539481163025,
        -0.016545793041586876,
        -0.006207028403878212,
        0.030827099457383156,
        -0.014498275704681873,
        0.022314012050628662,
        -0.05747343227267265,
        -0.060282252728939056,
        0.0252003725618124,
        0.03493889048695564,
        0.10046933591365814,
        0.0734194740653038,
        0.002660581609234214,
        -0.012088604271411896,
        0.004588244948536158,
        -0.09466104209423065,
        -0.12912394106388092,
        0.003827151842415333,
        -0.010586006566882133,
        0.010221457108855247,
        0.06760549545288086,
        -0.021960416808724403,
        -0.09052858501672745,
        -0.115170419216156,
        0.011735481210052967,
        -0.0034702031407505274,
        0.09075658023357391,
        -0.035991597920656204,
        0.028016718104481697,
        -0.010591117665171623,
        -0.05262945219874382,
        0.015553190372884274,
        -0.12714718282222748,
        0.046917058527469635,
        0.04379265755414963,
        0.05600089207291603,
        -0.09078750014305115,
        0.04098116233944893,
        -0.009991778060793877,
        0.0037410161457955837,
        -0.01109446119517088,
        -0.0215365719050169,
        0.05878770351409912,
        0.004677400924265385,
        0.00015370453184004873,
        0.004715678282082081,
        0.04238039255142212,
        0.0265911053866148,
        0.09358453750610352,
        0.021444527432322502,
        0.009878788143396378,
        0.05446323752403259,
        0.048986755311489105,
        -0.06437262147665024,
        0.006773060187697411,
        -0.002534380415454507,
        0.004586217924952507,
        0.05903793126344681,
        0.018297942355275154,
        0.03545165807008743,
        0.00701155373826623,
        -0.02821076102554798,
        -0.011758354492485523,
        -0.011878673918545246,
        -0.052079860121011734,
        -0.054801564663648605,
        -0.01915389485657215,
        0.009495064616203308,
        -0.0648227110505104,
        -0.030444981530308723,
        -0.023674802854657173,
        -0.0024506563786417246,
        0.056795015931129456,
        -0.05421796441078186,
        -0.03194738179445267,
        0.028020741418004036,
        -0.04098252207040787,
        -0.003857131814584136,
        0.019675282761454582,
        -5.5419665301315035e-8,
        0.054827675223350525,
        -0.15210478007793427,
        -0.0022566907573491335,
        0.06730201095342636,
        0.024610571563243866,
        -0.04186601936817169,
        0.09136170148849487,
        0.009011177346110344,
        -0.15553322434425354,
        0.043777402490377426,
        0.06680377572774887,
        0.004083212930709124,
        0.036560751497745514,
        -0.0049682362005114555,
        0.025135107338428497,
        0.0425921231508255,
        -0.00997799914330244,
        0.03365993872284889,
        0.00023848919954616576,
        -0.06683041900396347,
        0.058675043284893036,
        -0.0032376879826188087,
        -0.025990579277276993,
        -0.009115350432693958,
        0.049235932528972626,
        0.00706569105386734,
        -0.04497341811656952,
        -0.019392361864447594,
        -0.05629025027155876,
        -0.03075571171939373,
        0.03220692276954651,
        0.03450702503323555,
        0.08880241960287094,
        0.05525979399681091,
        -0.03701246902346611,
        -0.06875862926244736,
        0.050422653555870056,
        -0.018245795741677284,
        -0.06329817324876785,
        0.10247746109962463,
        0.05180203914642334,
        -0.01126603689044714,
        -0.004693645518273115,
        0.021058565005660057,
        0.054187972098588943,
        -0.06770805269479752,
        0.015871437266469002,
        -0.044703900814056396,
        0.04619399458169937,
        0.05962808057665825,
        0.01256448496133089,
        0.07322851568460464,
        0.023899957537651062,
        -0.01813875511288643,
        -0.023321473971009254,
        0.0004162247641943395,
        0.03547252342104912,
        0.017534950748085976,
        -0.008589152246713638,
        0.040085915476083755,
        0.11796445399522781,
        0.02857353538274765,
        -0.0061371661722660065,
        0.033222347497940063
      ],
      "metadata": {
        "title": "Paper_6_Quantum_Anti_Zeno_Treatment_of_Zeno_type_Sleep_Dis.pdf",
        "createdAt": "2025-12-17T13:56:43.632Z"
      },
      "fileObj": {}
    },
    {
      "id": "doc_18_1765979804551",
      "fileName": "Paper_9_Multi_Scored_Sleep_Databases__How_to_Exploit_the_M.pdf",
      "content": "Accepted Manuscript  ¬© Sleep Research Society 2023. Published by Oxford University Press on behalf of the Sleep Research Society. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.  Multi - Scored Sleep Databases: How to Exploit the  Multiple - Labels in Automated Sleep Scoring  Luigi Fiorillo 1,2,*, ‚Ä† , Davide Pedroncelli 3, ‚Ä† , Valentina Agostini 3 ,  Paolo Favaro 1   and Francesca Dalia Faraci 2  1 Institute of Informatics, University of Bern, Bern, Switzerland,   2 Institute of Digital Technologies for Personalized Healthcare (MeDiTech), Department of Innovative Technologies, University of Applied Sciences and Arts of Southern Switzerland, Lugano, Switzerland,   3 Department of Electronics and Telecommunications, Politecnico di Torino, Torino, Italy.  Institution where work was performed: Institute of Digital Technologies for Personalized Healthcare (MeDiTech), Department of Innovative Technologies, University of Applied Sciences and Arts of Southern Switzerland, Lugano, Switzerland.  ‚Ä†These authors contributed equally to this work.  *Corresponding author. Luigi Fiorillo, Institute of Digital Technologies for Personalized Healthcare (MeDiTech), Department of Innovative Technologies, University of Applied Sciences and Arts of Southern Switzerland, Lugano, Switzerland. Email: luigi.fiorillo@supsi.ch.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Abstract  Study Objectives:   Inter-scorer variability in scoring polysomnograms is a well-known problem. Most of the existing automated sleep scoring systems are trained using labels annotated by a single scorer, whose subjective evaluation is transferred to the model. When annotations from two or more scorers are available, the scoring models are usually trained on   the scorer consensus. The averaged scorer‚Äôs subjectivity is transferred into the model,  losing information about the internal variability among different scorers. In this study, we aim to insert the multiple-knowledge of the different physicians into the training procedure. The goal is to optimize a model training, exploiting the full information that can be extracted from the consensus of a group of scorers.  Methods:   We train two lightweight deep learning based models on three different multi- scored databases. We exploit the label smoothing technique together with a   soft-consensus  ( LS SC ) distribution to insert the multiple-knowledge in the training procedure of the model. We introduce the averaged cosine similarity metric (   ) to quantify the similarity between the hypnodensity-graph generated by the models with- LS SC   and the hypnodensity-graph generated by the scorer consensus.  Results:   The performance of the models improves on all the databases when we train the models with our   LS SC . We found an increase in   (up to 6.4%) between the hypnodensity- graph generated by the models trained with- LS SC   and the hypnodensity-graph generated by the consensus.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Conclusion:   Our approach definitely enables a model to better adapt to the consensus of the group of scorers. Future work will focus on further investigations on different scoring architectures and hopefully large-scale-heterogeneous multi-scored datasets.  Keywords:   automatic sleep stage classification, machine learning, deep learning, multi- scored sleep databases.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Graphical abstract  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Statement of Significance  Visual scoring of polysomnography is a highly subjective procedure. Several studies consistently reported the poor agreement between different physicians scoring the same whole-night recording. Existing sleep scoring algorithms, trained on multi-scored databases, overlook to encode in their models the variability among the scorers. We propose a technique to wholly insert the multiple-knowledge of the different physicians into the training procedure of a scoring algorithm. Our approach enables the model to better adapt to the consensus of the group of scorers. Whenever multi-scored databases are available, future researchers should train their models considering the annotations of all the physicians at the same time, rather than averaging their labels and training their algorithm on the averaged consensus.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Introduction  Sleep disorders represent a significant public health problem that affects millions of people worldwide [1]. Since the late 1950s, the polysomnography (PSG) exam has been the gold standard to study sleep and to identify sleep disorders. It monitors electrophysiological signals such as electroencephalogram (EEG), electrooculogram (EOG), electromyogram (EMG) and electrocardiogram (ECG). The physicians visually extract sleep cycle information from these signals. The whole-night recording is divided in 30-second epochs, and each epoch is classified into one of the five sleep stages (i.e., wakefulness W, stage N1, stage N2, stage N3, and stage REM) according to the AASM guidelines [2]. Worst case scenario, an eight-hour PSG may require up to two hours of tedious repetitive and time-consuming work to be scored. In addition, this manual procedure is highly affected by a low inter-rater scoring agreement (i.e., the agreement between different physicians scoring the same whole-night recording). The inter-rater scoring agreement value ranges from 70% up to slightly more than 80% [3-5]. In [3] the averaged inter-rater agreement of about 83% results from a study conducted on the AASM Inter-scorer reliability dataset, by using sleep stages annotated from more than 2,500 sleep scorers. The agreement was higher than 84% for awake, N2 and REM stages, but it dropped to 63% and 67% for N1 and N3 stages respectively. In fact, the inter- rater agreement varies among sleep stages, patients, sleep disorders and across sleep centers [3], [6].  Since 1960 many different approaches and algorithms have been proposed to automate this time- consuming scoring procedure. Mainly, two different approaches emerged: sleep scoring algorithms learning from well defined features extracted from the knowledge of the experts (shallow learning), and sleep scoring algorithms learning directly from the raw data (deep learning). Thorough reviews about feature based [7-8] and deep learning based [9-10] sleep scoring algorithms can be found in literature. Although the latter algorithms emerged only five years ago, their impressive results have  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  never been reached with the previous conventional feature based approaches. Autoencoders [11], deep neural networks [12], convolutional neural networks [13-20], recurrent neural networks [21- 23] and different combinations of them [24-30] have been all proposed only in these last five years.  Almost all of the above algorithms have been trained on recordings scored by a single expert physician. The first remarkable exception comes from [27], where they consider recordings scored by six different physicians [31]. The scoring algorithm was trained on the six-scorer consensus (i.e., based on the majority vote weighted by the degree of consensus from each physician). In [23] the  Dreem   group introduced two publicly-available datasets scored by five sleep physicians. Similarly, they used the scorer consensus to train their automated scoring system. It has been shown that the performance of an automated sleep scoring system is on-par with the scorer consensus [23,27], and mainly that their best scoring algorithm is better than the best human scorer - i.e., the scorer with the higher consensus among all the physicians in the group. Although they both considered the knowledge from the multiple scorers - by averaging their labels and by training their algorithm on the averaged consensus - they still trained the algorithm on a single one-hot encoded label. Indirectly, they are still transferring the best   scorer‚Äôs subjectivity into the model, and they are not  explicitly training the model to adapt to the consensus of the group of scorers.  In this work, we train two existing lightweight deep learning-based sleep staging algorithms, our DeepSleepNet-Lite (DSN-L) [32] and SimpleSleepNet (SSN) [23], on three open-access multi-scored sleep datasets. First, we assess the performance of both scoring algorithms trained with the labels given by scorer consensus (i.e., majority vote among the different scorers) and compare it to the performance of the individual scorer-experts. Then we propose to exploit label smoothing along with the   soft-consensus   distribution ( base+LS SC ) to insert the multiple-knowledge into the training procedure of the models and to better calibrate the scoring architectures. For the first time in sleep scoring, we are considering the multiple-labels in the training procedure, the annotations of all the  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  scorers are taken into account at the same time. We finally assess the performance and we quantify the similarity between the hypnodensity-graph generated by the models - trained with and without label smoothing - and the hypnodensity-graph generated by the scorer consensus.  In the present work we investigate a different approach in exploiting multi-scored database information. In particular: (1) we demonstrate the efficiency of label smoothing along with the   soft- consensus   distribution in both calibrating and enhancing the performance of both DSN-L and SSN; (2) we show how the model can better resemble the scorer group consensus, leading to a similarity increase between the hypnodensity-graph generated by the model and the hypnodensity-graph generated by the scorer consensus.  Methods  In this section we first present the three publicly available databases used in this study: IS-RC (Inter- scorer Reliability Cohort) [31]; DOD-H (Dreem Open Dataset - Healthy) and DOD-O (Dreem Open Dataset - Obstructive) [23]. We then briefly describe the architectures of the two deep learning- based scoring algorithms DSN-L [32] and SSN [23]. Next, we show how to compute the consensus in a multi-scored dataset, i.e., how to compute the label among multiple-scorers so as to train our  baseline   algorithms and to be able to evaluate their performance. In   Label smoothing with soft- consensus   subsection we describe in detail how to compute the   soft-consensus   distribution, and how to exploit it along with the label smoothing technique during the training procedure. The aim is to show how to insert the multiple-labels of the different scorers into the training procedure of our algorithms. We finally report all the experiments conducted on both DSN-L and SSN algorithms, i.e. , base,   base+LS U   and base+LS SC   models, and the metrics exploited to evaluate their performance.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Datasets  IS-RC.   The dataset contains 70 recordings (0 males and 70 females) from patients with sleep- disordered breathing aged from 40 to 57. The recordings were collected at the University of Pennsylvania. Each recording includes the EEG derivations C3-M2, C4-M1, O1-M2, O2-M1, one EMG channel, left/right EOG channels, one ECG channel, nasal airway pressure, oronasal thermistor, body position, oxygen saturation and abdominal excursion. The recordings are sampled at 128 Hz.  We only consider the single-channel EEG C4-M1 to train our DSN-L architecture, and we use multi- channel EEG, EOG, EMG and ECG to train the SSN architecture. A band-pass Chebyshev IIR filter is applied between [0.3, 35] Hz. Each recording is scored by six clinicians from five different sleep  centers (i.e., University of Pennsylvania, University of Wisconsin at Madison, St. Luke‚Äôs Hospital  (Chesterfield), Stanford University and Harvard University) according to the AASM rules [2]. The dataset contains the following annotations   ,   ,   ,   ,   , and   , where   is a not classified epoch. Some epochs are not scored by all the six physicians, and even for some of them we don't have any annotation (i.e   ). We decided to remove the epochs classified by all the scorers as  . Epochs with less than six annotations are equally taken into account to avoid excessive data loss.  DOD-H.   The dataset contains 25 recordings (19 males and 6 females) from healthy adult volunteers aged from 18 to 65 years. The recordings were collected at the French Armed Forces Biomedical  Research Institute‚Äôs (IRBA) Fatigue and Vigilance Unit (Bretigny -Sur-Orge, France). Each recording includes the EEG derivations C3-M2, C4-M1, F3-F4, F3-M2, F3-O1, F4-O2, O1-M2, O2-M1, one EMG channel, left/right EOG channels and one ECG channel. The recordings are sampled at 512 Hz.  DOD-O.   The dataset contains 55 recordings (35 males and 20 females) from patients suffering from obstructive sleep apnea (OSA) aged from 39 to 62 years. The recordings were collected at the Stanford Sleep Medicine Center. Each recording includes the EEG derivations C3-M2, C4-M1, F4-M1,  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  F3-F4, F3-M2, F3-O1, F4-O2, FP1-F3, FP1-M2, FP1-O1, FP2-F4, FP2-M1, FP2-O2, one EMG channel, left/right EOG channels and one ECG channel. The recordings are sampled at 250 Hz.  We only consider the single-channel EEG C4-M1 to train our DSN-L architecture, and we use all the available channels to train SSN architecture, on both DOD-H and DOD-O. As in [23], a band-pass Butterworth IIR filter is applied between [0.4, 18] Hz to remove residual PSG noise, and the signals are resampled at 100 Hz. The signals are then clipped and divided by 500 to remove extreme values. The recordings from both DOD-H and DOD-O datasets are scored by five physicians from three different sleep centers according to the AASM rules [2].  DOD-H and DOD-O contain the following annotations   ,   ,   ,   ,   , and   , where   is a not classified epoch. All the scorers agree about the   epochs (100% of agreement). Therefore, all of them are removed from the data. Unlike the previous IS-RC database, for each epoch five annotations are always available.  In Table 1 we report a summary of the total number and percentage of the epochs per sleep stage for the DOD-H, DOD-O and IS-RC datasets.  Deep learning-based scoring architectures  DSN-L   [32] is a simplified   feed-forward   version of the original DeepSleepNet by [24]. Unlike the original network, in [32] we proposed to employ only the first   representation learning   block, and we proposed to simply train it with a   sequence-to-epoch   learning approach. The architecture receives in input a sequence of 90-second epochs, and it predicts the corresponding target of the central epoch of the sequence, i.e., many-to-one or sequence-to-epoch classification scheme. The   representation learning   architecture consists of two parallel convolutional neural networks ( CNNs)   branches, with small   and large   filters at the first layer. The principle is to extract high-time resolution patterns with the small filters, and to extract high-frequency resolution patterns with the large ones. This idea comes from the way the signal processing experts define the trade-off between  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  temporal and frequency precision in the feature extraction procedure [33]. Each CNN branch consists of four convolutional layers and two max-pooling layers. Each convolutional layer executes three basic operations: 1-Dimensional convolution of the filters with the sequential input; batch normalization [34]; element-wise rectified linear unit (ReLU) activation function. Then the pooling layers are used to downsample the input. In Figure 1 we report an overview of the architecture, with details about the filter size, the number of filters and the stride size of each convolutional layer. The pooling size and the stride size for each pooling layer are also specified.  SSN   [23] consists of two main parts as shown in Figure 2: (i) The   epoch encoder   part, inspired by [22], or what we refer to as epoch processing block ( EPB ), is designed to process 30-second multi-channel EEG epochs, and it aims at learning epoch-wise features. (ii) The   sequence encoder   part, inspired by [24], or what we refer to as sequence processing block ( SPB ), is designed to process sequences of epochs, and it aims to encode the temporal information (e.g., stage transition rules). The   SPB   block consists of two layers of bidirectional gated recurrent unit (GRU) with skip-connections (SkipGRU) and the final classification layer. The architecture receives in input a sequence of PSG epochs, specifically temporal context is set to twenty-one, and it outputs the corresponding sequences of sleep stages at once, i.e., many-to-many or sequence-to-sequence classification scheme.  In both, DSN-L and SSN, the softmax function and the cross-entropy loss function   (see Supplementary Analyses) are used to train the models to output the probabilities ÃÇ   for the five mutually exclusive classes   , that correspond to the five sleep stages. The cross-entropy loss quantify the agreement between the prediction   and the target   (i.e., sleep stage label) for each sleep epoch .   The aim is to minimize the cross-entropy loss function   , i.e., minimize the distance between the prediction   and the target   .  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  The models are trained end-to-end via backpropagation, using mini-batch Adam gradient-based optimizer [35], with a learning rate   . The training procedure runs up to a maximum number of iterations (e.g., 100 iterations), as long as the break early stopping condition is satisfied (i.e., the validation F1-score stopped improving after more than a certain epochs; the model with the best validation F1-score is used at test time). All the training parameters (e.g., adam-optimizer parameters beta1 and beta2, mini-batch size, learning rate etc.) are all set as recommended in [32] and [23].  In Supplementary Analyses we also report additional mathematical details about both the scoring architectures.  Consensus in multi-scored datasets  Inspired by [23,27], we evaluate the performance of the sleep scoring architectures, as well as the performance of each physician, using the consensus among the five/six different scorers. The majority vote from the scorers has been computed - i.e., we assign to each 30-second epoch the most voted sleep stage among the physicians. In case of ties, we consider the label from the most reliable scorer. The most reliable scorer is the one that is frequently in agreement with all the others. We use the   -   metric proposed in [23] to rank the reliability of each physician, and to finally define the most reliable scorer. We denote with   the total number of scorers and with   the single-scorer. The one-hot encoded sleep stages given by the scorer   are: ÃÇ   , where   is the number of classes, i.e.,  sleep stages, and   is the total number of epochs. The probabilistic consensus ÃÇ   among the  scorers (   excluded) is computed using the following:  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  ÃÇ  ‚àë ÃÇ  ‚àë ÃÇ   (1)  where   is the   -   epoch of   epochs and ÃÇ   , i.e.,   is assigned to a stage if it matches the majority or if it is involved in a tie. The   -   is then computed across all the  epochs as:  -   ‚àë ÃÇ   (2)  where ÃÇ   denotes the probabilistic consensus of the sleep stage chosen by the scorer   for the   -  epoch.   -   , where the zero value is assigned if the scorer   systematically scores all the annotations incorrectly compared to the others, whilst   is assigned if the scorer   is always involved in tie cases or in the majority vote. The   -   is computed for all the scorers, and the values are sorted from the highest - high reliability - to the lowest - low reliability. The   -   is computed for each patient, i.e., the scorers are ranked for each patient, and in case of a tie the top-1 physician will be the one used for that patient.  Label smoothing with   soft-consensus  The predicted sleep stage for each 30-second epoch is associated to a probability value ÃÇ   , which should mirror its ground truth correctness likelihood. When this happens, we can state that the model is well calibrated, or that the model provides a   calibrated confidence   measure along with its prediction [36]. Consider, for example, a model trained to classify images as either containing a dog or not; out of ten test set images it outputs the probability of there being a dog as 0.60 for every image. The model is perfectly calibrated if six dog images are present in the test set. Label smoothing [37] has been shown to be a suitable technique to improve the calibration of the model.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  By default, the cross-entropy loss function   is computed between the prediction   and the target  (i.e., the one-hot encoded sleep stages,   for the correct class and   for all the other classes). Whenever a model is trained with the label smoothing technique, the hard target is usually smoothed with the standard   uniform   distribution   (3) . Thus, the cross-entropy loss function   (4)   is minimized by using the weighted mixture of the target   .  (3)  ‚àë ÃÇ   (4)  where   is the smoothing parameter,   the number of sleep stages,   the weighted mixture of the target and ÃÇ   the output of the model with the predicted probability values.  In our study, we exploit the label smoothing technique to improve the insertion of the knowledge from the multiple-scorers in the learning process. We propose to use the   -   (5)   as our new distribution to smooth the hard target   .  -   (   )   (5)  where   is the set of observations - i.e., annotations given by the different physicians - for the   -  epoch,   is the class index,   is the number of observations and   is the cardinality of the set  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  (   ) . In simple words, the probability value for each sleep stage   is computed as the sum of its occurrences divided by the total number of observations.  -   is the one-dimensional vector that we use to smooth the hard target  (6) , and then minimize the cross-entropy loss function   (7) .  -   (6)  ‚àë ÃÇ   (7)  To make it clearer, we report a practical example on how to compute the   soft-consensus  distribution, and how to exploit it to smooth our labels. Consider the following set of observations  given by five different physicians for the same   -   epoch.  We can calculate the   consensus as following:  -  -  By applying   (5)   and   (6)   we obtain the following   smoothed hard-target with   :  -  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  that corresponds to the one-hot encoded target:  We perform a simple grid-search to set the smoothing hyperparameter   . When the model is trained with the labels smoothed by the   uniform   distribution the   value ranges between  with step   . Extreme values are not considered as for   the model is trained using the standard hot-encoding vector; whilst for values higher than   , e.g.,   , the model would be trained using mainly/only the   uniform   distribution   for each sleep stage. When the model is trained with the labels smoothed by the   -   distribution the   value ranges between  with step   . In the latter case we also investigate an   value equal to   to evaluate the full impact of the consensus distribution on the learning procedure.  Experimental design  We evaluate DSN-L and SSN using the   -fold cross-validation scheme. We set   equal to   for IS-RC,  for DOD-H (leave-one-out evaluation procedure) and   for DOD-O datasets, consistent with what was done in [23]. In Table 2 we summarize the data split for each dataset.  The following experiments are conducted on both DSN-L and SSN models for each dataset:  ‚óè   base . The models are trained without label smoothing.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  ‚óè   base+LS U . The models are trained with label smoothing using the standard   uniform  distribution - i.e., the hard targets (scorer consensus) are weighted with the   uniform  distribution.  ‚óè   base+LS SC . The models are trained with label smoothing using the proposed   soft-consensus   - i.e., the hard targets (scorer consensus) are weighted with the   soft-consensus   distribution.  These models, differently trained, have been evaluated with and without   MC   dropout ensemble technique. In Table 4, Table 5 and Table 6 section   Results   we present the results obtained for each experiment on both DSN-L and SSN evaluated on IS-RC, DOD-H and DOD-O datasets.  Metrics  Performance.  The per-class F1-score, the overall accuracy (Acc.), the macro-averaging F1-score, the weighted- averaging F1-score (i.e., the metric is weighted by the number of true instances for each label, so as  to consider the high imbalance between the sleep stages) and the Cohen‚Äôs kappa have been  computed per-subject from the predicted sleep stages from all the folds to evaluate the performance of our model [38, 39].  Hypnodensity graph.  The hypnodensity-graph is an efficient visualization tool introduced in [27] to plot the probability distribution over each sleep stage for each 30-second epoch over the whole night. Unlike the standard hypnogram sleep cycle visualization tool, the hypnodensity-graph shows the probability of occurrence of each sleep stage for each 30-second epoch; so it is not limited to the discrete sleep stage value (see Figure 3). In our study we have used the hypnodensity-graph to display both the model output - i.e., the probability vectors ÃÇ   - and the multi-scorer   -   probability distributions.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  The Averaged Cosine Similarity (   ) is used to quantify the similarity between the hypnodensity- graph generated by the model and the hypnodensity-graph generated by the   -   . The  has been computed as follows:  ‚àë ÃÇ   ||   ||   ||ÃÇ   ||   (8)  where   is the number of epochs in the whole night,   || ||   is the norm computed for the predicted probability vector ÃÇ   and the   -   ground-truth vector for the   -   epoch. Thus, the cosine-similarity is averaged across all the epochs   to obtain our averaged   unique score of similarity. The cosine-similarity values may range between   i.e., high dissimilarity and   i.e., high similarity between the vectors.  Calibration.  The calibration of the model is evaluated by using the expected calibration error (   ) metric proposed in [40]. By   we compute the difference in expectation between the accuracy  and the   (i.e., the   softmax   output probabilities) values. More in detail, the predictions are divided into   equally spaced bins (with size   ), then we compute the accuracy   and the average predicted probability value   for each bin as follows:  |   |   ‚àë ÃÇ   (9)  |   |   ‚àë ÃÇ   (10)  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  where   is the true label and ÃÇ ÃÇ   is the predicted label for the   -   epoch;   is the group of samples whose predicted probability values fall in   and ÃÇ ÃÇ  is the predicted probability value for sample the   -   30-second epoch. Finally, the  value is computed as the weighted average of the difference between the   and the   among the   bins:  ‚àë   |   |   |   |   (11)  where   is the number of samples in each bin. Perfectly calibrated models have  for all   {   } , resulting in   .  Results  In Table 3 we first report for all the multi-scored databases IS-RC, DOD-H and DOD-O, the overall scorers performance and their   (   ), i.e., the agreement of each scorer with the consensus among the physicians. On IS-RC we have on average a lower inter-scorer agreement (  equal to 0.69, with an F1-score 69.7%) compared to both DOD-H and DOD-O (   equal to 0.89 and 0.88, with an F1-score 88.1% and 86.4% respectively). Consequently, we expect a higher efficiency of our label smoothing with the   soft-consensus   approach ( base+LS SC ) on the experiments conducted on the IS-RC database. The lower the inter-scorer agreement, the lower should be the performance of a model trained with the one-hot encoded labels (i.e., the majority vote weighted by the degree of consensus from each physician).  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  In Table 4 and Table 5 we report the overall performance, the calibration measure and the hypnodensity similarity measure of the three different DSN-L and SSN models on the three databases IS-RC, DOD-H and DOD-O. The performance of the DSN-L   base   models are higher compared to the performance averaged among the scorers on the IS-RC database, but not on the DOD-H and DOD-O databases. In contrast, the performance of the SSN   base   models are always higher than the performance averaged among the scorers on all the databases. We highlight that the results we report for SSN on DOD-H and DOD-O are slightly different compared to the one reported in [23]. We decided to not compute a weight (from 0 to 1) for each epoch, based on how many scorers voted for the consensus. We do not balance the importance of each epoch when we compute the above mentioned metrics. We think it is unfair to constrain any metrics based on the amount of voting physicians. Overall, the results show an improvement in performance on all the databases (i.e overall accuracy, MF1-score, Cohen's kappa (   ), and F1-score) from the baseline ( base ) and the label smoothing with the   uniform   distribution ( base+LS U ) models, to the ones trained with label smoothing along with the proposed   soft-consensus   distribution (ie.   base+LS SC ).  The   is the metric that best quantifies the ability of the model in adapting to the consensus of the group of scorers. A higher   value means a higher similarity between the hypnodensity-graph generated by the model and the hypnodensity-graph generated by the   soft-consensus   (i.e., the model better adapts to the consensus of the group of physicians). As all the other metrics the  value is computed per subject, but here we report the mean and also the standard deviation across subjects   . We found a significant improvement in the   value from the   base   and the  base+LS U   models to the   base+LS SC   models on all the databases and on both DSN-L (p-values < 0.01) and SSN (p-values < 0.05). Hence, our approach enables both DSN-L and SSN architectures to significantly adapt to the group consensus on all the multi-scored datasets.  We could easily infer that the SSN architecture is better (i.e., higher performance) compared to our  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  DSN-L architecture. The purpose of our study is not to highlight whether one architecture is better than the other, but we can not fail to notice the high values of confidence (the   value is the average of the softmax output max-probabilities) obtained on the SSN based models. High values of confidence still persist despite smoothing the labels (with both   uniform   and soft-consensus distributions) during the training procedure. The SSN architecture is not highly responsive to the changes in probability values we implemented on the one-hot encoded labels. It always rely/overfit on the   probability value given for each epoch, i.e., the consensus among the five/six different scorers. Indeed, on the IS-RC, which is the database with the lower inter-scorer agreement, the SSN  base+LS SC   model reaches a higher value of F1-score, i.e., 81.6%, compared to our DSN-L   base+LS SC  model, i.e., 75.9% , but a lower value of   (0.817 on SSN and 0.836 on DSN-L, with a p-value < 0.01). The SSN model overfit to the majority vote or the   probability value given for each epoch, whilst the DSN-L better adapts to the consensus of the group of scorers (i.e., better encodes the variability among the physicians).  The last statement is also strengthened by the Supplementary Figure S1 and Figure S2. For DSN-L and SSN we report the   values across all the experimented   values, on both the   base+LS U   and the   base+LS SC   models tested on the three databases. As expected, the DSN-L model shows a high sensitivity in   values to changes in Œ± -hyperparameter across all databases. This sensitivity is not as strong with the SSN model.  Moreover, we want to stress that the standard   uniform   distribution is not as efficient as the proposed   soft-consensus   distribution in encoding the scorer‚Äôs variability. By using the   uniform  distribution we are not able to learn as well the complexity of the degree of agreement between the different physicians. Indeed, in Supplementary Figure S1, on the DSN-L model, we clearly show how the   value proportionally increases with the Œ± -hyperparameter only by using the proposed   soft-  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  consensus   distribution. In Figure 4 we also show, on a patient from the DOD-O dataset, how we achieve a higher   value with the proposed   base+LS SC   model with the   soft-consensus   distribution, compared to   base+LS U   model with the standard   uniform   distribution. The graph clearly highlights the differences between the output probabilities predicted by the different models. The probabilities predicted using our approach   base+LS SC   (d) are closer to the ground-truth (a) compared to the ones predicted from the other models (e.g. refer to min. 300 and to the probabilities associated with the sleep stage N3).  Discussion  Many deep learning based approaches are available and from a technical point of view there is not that much that is left to be done to improve their performance. It is not reasonable to reach a performance higher than the gold standard that is used to train the architectures. Infact, the real limitation is the low inter-rater agreement due to subjective interpretation.  Therefore in this paper we focus on how to better integrate the inter-rater agreement information into the automated sleep scoring algorithms. Presently, information about the variability is not completely exploited. The algorithms are trained on the majority vote consensus, leading to overfitting on the majority vote weighted by the degree of consensus from each physician.  We introduce a   more complete methodology to integrate scorer‚Äôs variability in the training  procedure. We demonstrate the efficiency of label smoothing along with the   soft-consensus  distribution in encoding the scorers‚Äôs variability into the training procedure of both DS N-L and SSN scoring algorithms. The results show an improvement in overall performance from the   base   models to the ones trained with   base+LS SC . We introduce the averaged cosine similarity metric to better quantify the similarity between the probability distribution predicted by the models and the ones generated by the scorer consensus. We obtain a significant improvement in the   values from the  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  base   models to the   base+LS SC   models on both DSN-L and SSN architectures. Based on the reported high confidence values, we found that SSN tends to overfit on each dataset. Specifically, it tends to overfit on the majority vote weighted by the degree of consensus from each physician, but does not encode as well their variability.  To our knowledge, our work is the first attempt to transfer the variability, the uncertainty and the noise among multiple-scorers to an automated sleep scoring system.  We have proved the strength of our approach and especially the use of the soft-consensus distribution by comparing it with the   base   models and the implemented models trained with label smoothing but using the uniform distribution. We clearly show on all the experiments the higher overall performance and   values achieved with the soft-consensus distribution.  In order to generalize our approach, there are two big limitations. The first is that a far bigger datasets, highly heterogeneous (with different diagnosis, age range, gender etc.) scored by multiple scorers would be necessary. The second is that the recordings exploited in this study are not labeled by a homogeneous group of board certified sleep scorers. Further studies should be carried out to better quantify the resilience and the reproducibility of the proposed approach. To achieve a high- performance sleep scoring algorithm, we must take into account both the variability of the recordings and the variability between the different sleep scorers. We should train our sleep scoring models on PSG recordings from different large-scale-heterogeneous data cohorts, and ideally with each recording scored by multiple physicians.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  In summary, the possibility of exploiting the full set of information that is hidden in a multi-scored dataset would certainly enhance automated deep learning algorithms performance. The present approach enables us to better adapt to the consensus of the group of scorers, and, as a consequence, to better quantify the disagreement we have between the different scorers. The  proposed approach results quite effective in encoding the complexity of the scorers‚Äô consensus  within the classification algorithm, whose importance is often underestimated.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Funding  Prof. F. D. Faraci was supported by SPAS: Sleep Physician Assistant System project, from Eurostars funding programme. Prof. P. Favaro was supported by the IRC Decoding Sleep: From Neurons to Health and Mind, from the University of Bern, Switzerland.  Disclosure Statement  Conflicts of interest. The authors declare that they have no conflict of interest. Financial Disclosure: none. Non financial Disclosure: none.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  References  [1] National Center on Sleep Disorders Research, National Inst. Health Sleep Disorders Res. Plan, Bethesda, MD, USA, 2011.  [2] C. Iber, S. Ancoli-Israel, A. L. Chesson, and S. F. Quan, The AASM Manual for the Scoring of Sleep and Associated Events: Rules, Terminology, and Technical Specifications. Westchester, IL, USA: American Academy Sleep Medicine, 2007.  [3] Rosenberg RS, Van Hout S. The American academy of sleep medicine inter-scorer  reliability program: sleep stage scoring. J Clin Sleep Med 2013;9(01):81e7.  [4] Younes M, Raneri J, Hanly P. Staging sleep in polysomnograms: analysis of  inter-scorer variability. J Clin Sleep Med 2016;12(06):885e94.  [5] Muto V, Berthomier C, Schmidt C, Vandewalle G, Jaspar M, Devillers J, et al.  0315 Inter-and intra-expert variability in sleep scoring: comparison between  visual and automatic analysis. Sleep 2018;41(suppl_1):A121.  [6] Danker-hopfe H, Anderer P, Zeitlhofer J, Boeck M, Dorn H, Gruber G, et al.  Interrater reliability for sleep scoring according to the Rechtschaffen & Kales  and the new AASM standard. J Sleep Res 2009;18(1):74e84.  [7] Aboalayon K, Faezipour M, Almuhammadi W, Moslehpour S. Sleep stage  classification using EEG signal analysis: a comprehensive survey and new  investigation. Entropy 2016;18(9):272.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  *8+ Ronzhina M, Janou≈°ek O, Kol√°≈ôov√° J, Nov√°kov√° M, Honz√≠k P, Provazn√≠k I. Sleep scoring using  artificial neural networks. Sleep medicine reviews. 2012 Jun 1;16(3):251-63.  *9+ L. Fiorillo et al., ‚ÄúAutomated sleep scoring: A review of the latest approaches,‚Äù Sleep Medicine  Reviews, vol. 48, pp. 101204, 2019.  *10+ O. Faust et al., ‚ÄúA review of automated sleep stage   scoring based on physiological signals for the  new millennia,‚Äù Comput Methods Programs Biomed, vol. 176, pp. 81‚Äì 91, 2019.  *11+ Tsinalis, Orestis, Paul M. Matthews, and Yike Guo. ‚ÄùAutomatic sleep stage scoring using time - frequency analysis and stacked spar se autoencoders.‚Äù Annals of biomedical engineering 44.5 (2016):  1587-1597.  *12+ Dong, Hao, et al. ‚ÄùMixed neural network approach for temporal sleep stage classification.‚Äù IEEE  Transactions on Neural Systems and Rehabilitation Engineering 26.2 (2017): 324-333.  *13+ Vilamala, Albert, Kristoffer H. Madsen, and Lars K. Hansen. ‚ÄùDeep convolutional neural networks for interpretable analysis of EEG sleep stage scoring.‚Äù 2017 IEEE 27th International Workshop on  Machine Learning for Signal Processing (MLSP). IEEE, 2017.  *14+ Chambon, Stanislas, et al. ‚ÄùA deep learning architecture for temporal sleep stage classification using multivariate and multimodal time series.‚Äù IEEE Transactions on Neural Systems and  Rehabilitation Engineering 26.4 (2018): 758-769.  [15] Cui, Zh ihong, et al. ‚ÄùAutomatic Sleep Stage Classification Based on Convolutional Neural  Network and Fine- Grained Segments.‚Äù Complexity 2018 (2018).  *16+ Patanaik, Amiya, et al. ‚ÄùAn end -to-end framework for real-time automatic sleep stage  classification.‚Äù Sleep 4 1.5 (2018): zsy041.  *17+ Sors, Arnaud, et al. ‚ÄùA convolutional neural network for sleep stage scoring from raw single -  channel EEG.‚Äù Biomedical Signal Processing and Control 42 (2018): 107 -114.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  [18] Yildirim, Ozal, Ulas Baran Baloglu, and U. Rajendra Achary a. ‚ÄùA deep learning model for automated sleep stages classification using psg signals.‚Äù International journal of environmental  research and public health 16.4 (2019): 599  [19] Olesen AN, J√∏rgen Jennum P, Mignot E, Sorensen HB. Automatic sleep stage classification with deep residual networks in a mixed-cohort setting. Sleep. 2021 Jan;44(1):zsaa161.  [20] Perslev M, Darkner S, Kempfner L, Nikolic M, Jennum PJ, Igel C. U-Sleep: resilient high-frequency sleep staging. NPJ digital medicine. 2021 Apr 15;4(1):1-2.  *21+ Michielli, Nicola, U. Rajendra Acharya, and Filippo Molinari. ‚ÄùCascaded LSTM recurrent neural  network for automated sleep stage classification using single- channel EEG signals.‚Äù Computers in  biology and medicine 106 (2019): 71-81.  [22] H. Phan, F. An dreotti, N. Cooray, O. Y. Ch√©n, and M. De Vos, ‚ÄúSeqSleepNet: end -to-end  hierarchical recurrent neural network for sequence-to- sequence automatic sleep staging,‚Äù IEEE  Trans. on Neural Systems and Rehabilitation Engineering (TNSRE), vol. 27, no. 3, pp. 400 ‚Äì 410, 2019.  *23+ A. Guillot, F. Sauvet, E. H. During, and V. Thorey, ‚ÄúDreem   open datasets: Multi-scored sleep  datasets to compare human and automated sleep staging,‚Äù IEEE Transactions on Neural Systems and  Rehabilitation Engineering, vol. 28, no. 9, pp. 1955 ‚Äì 1965, 2020.  *24+ Supratak, Akara, et al. ‚ÄùDeepSleepNet: A model for auto matic sleep stage scoring based on raw single- channel EEG.‚Äù IEEE Transactions on Neural Systems and Rehabilitation Engineering 25.11  (2017): 1998-2008.  *25+ Biswal, Siddharth, et al. ‚ÄùExpert - level sleep scoring with deep neural networks.‚Äù Journal of the  American Medical Informatics Association 25.12 (2018): 1643-1650.  *26+ Malafeev, Alexander, et al. ‚ÄùAutomatic human sleep stage scoring using deep neural networks.‚Äù  Frontiers in neuroscience 12 (2018): 781.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  [27] Stephansen, Jens B., et al. Neural network analysis of sleep stages enables efficient diagnosis of narcolepsy. Nature communications, 2018, 9.1: 1-15.  [28] Mousavi, Sajad; AFGHAH, Fatemeh; ACHARYA, U. Rajendra. SleepEEGNet: Automated sleep stage scoring with sequence to sequence deep learning approach. PloS one, 2019, 14.5: e0216456.  [29] Phan, Huy, et al. XSleepNet: Multi-view sequential model for automatic sleep staging. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2021.  U-Sleep  [30] Maurice Abou Jaoude, Haoqi Sun, Kyle R Pellerin, Milena Pavlova, Rani A Sarkis, Sydney S Cash, M Brandon Westover, Alice D Lam, Expert-level automated sleep staging of long-term scalp electroencephalography recordings using deep learning,   Sleep , Volume 43, Issue 11, November 2020, zsaa112, https://doi.org/10.1093/sleep/zsaa112  [31] Kuna ST, Benca R, Kushida CA, Walsh J, Younes M, Staley B, Hanlon A, Pack AI, Pien GW, Malhotra A. Agreement in computer-assisted manual scoring of polysomnograms across sleep centers. Sleep. 2013 Apr 1;36(4):583-9.  [32] Fiorillo L, Favaro P, Faraci FD. Deepsleepnet-lite: A simplified automatic sleep stage scoring model with uncertainty estimates. IEEE Transactions on Neural Systems and Rehabilitation Engineering. 2021 Oct 14;29:2076-85.  [33] Cohen, Mike X. Analyzing neural time series data: theory and practice. MIT press, 2014.  [34] Ioffe S, Szegedy C. Batch normalization: Accelerating deep network training by reducing internal covariate shift. InInternational conference on machine learning 2015 Jun 1 (pp. 448-456). PMLR.  [35] Kingma DP, Ba J. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980. 2014 Dec 22.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  [36] Guo C, Pleiss G, Sun Y, Weinberger KQ. On calibration of modern neural networks. InInternational Conference on Machine Learning 2017 Jul 17 (pp. 1321-1330). PMLR.  [37] Szegedy C, Vanhoucke V, Ioffe S, Shlens J, Wojna Z. Rethinking the inception architecture for computer vision. InProceedings of the IEEE conference on computer vision and pattern recognition 2016 (pp. 2818-2826).  [38] Cohen, Jacob. A coefficient of agreement for nominal scales. Educational and psychological measurement, 1960, 20.1: 37-46.  [39] Sokolova, Marina; Lapalme, Guy. A systematic analysis of performance measures for classification tasks. Information processing & management, 2009, 45.4: 427-437.  [40] Naeini, Mahdi Pakdaman; Cooper, Gregory F.; Hauskrecht, Milos. Obtaining well calibrated probabilities using bayesian binning. AAAI Conference on Artificial Intelligence. AAAI Conference on Artificial Intelligence. NIH Public Access, 2015. p. 2901.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Figure Captions  Figure 1.   DeepSleepNet-Lite architecture. An overview of the   representation learning   architecture from [24], with our   sequence-to-epoch  training approach.  Figure 2.   SimpleSleepNet architecture.  An overview of the SimpleSleepNet architecture from [23].   represent the hidden states of the GRU layers from the previous epoch of the sequence and   the hidden states of the GRU layers from the next epoch of the sequence.   is the embedding of the current epoch.  Figure 3.   Hypnogram and hypnodensity-graph from the scorers labels.  Example of hypnogram and hypnodensity-graph for a subject from the DOD-H with the highest percentage 14% of N1 sleep stages. For each 30-second epoch we report on top the hypnogram, i.e., the discrete sleep stage values (majority vote from the scorers labels); on bottom the hypnodensity- graph, i.e., the cumulative probabilities of each sleep stage ( soft- consensus computed from the scorers labels). The hypnodensity-graph allows us to better appreciate the low level of agreement of a specific sleep stage among the different scorers. In this example, the sleep stages N1 are often associated with a high percentage of residual probability in awake or N2, thus at the transitions from one sleep stage to another.  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Figure 4.   Hypnodensity-graphs from the scorers labels and from the predicted probabilities from the experimented models.  Example of hypnodensity-graphs for a subject from the DOD-O. (a) Soft-consensus computed from the scorers labels; (b) DSN-L   base   model; (c) DSN-L   base+LS U ; (d) DSN-L   base+LS SC   . We also report the ACS value computed between the hypodensity-graph associated to soft-consensus and the ones generated from the predicted probabilities of each model. We reach a higher   value with the proposed   base+LS SC   model with the   soft-consensus   distribution (d), compared to the baseline (b) and the   base+LS U   model with the standard   uniform   distribution (c).  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Tables  Table 1  Number and percentage of 30-second epochs per sleep stage for the IS-RC, DOD-H and DOD-O datasets.  W   N1   N2   N3   R   Total  IS - RC  24517  (29.1%)  3773  (4.5%)  40867  (48.5%)  3699  (4.4%)  11475  (13.6%)  84331  DOD - H  3075  (12.5%)  1463  (5.9%)  12000  (48.7%)  3442  (14.0%)  4685  (19.0%)  24665  DOD - O  10520  (19.8%)  2739  (5.1%)  26213  (49.2%)  5617  (10.6%)  8147  (15.3%)  53236  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Table 2  Data split on the IS-RC, DOD-H and DOD-O datasets.  Size  Experimental  Setup  Held - out  Validation Set  Held - out  Test Set  IS - RC   70   10-fold CV   13 subjects   7 subject  DOD - H   25   25-fold CV   6 subjects   1 subjects  DOD - O   55   10-fold CV   12 subjects   6 subjects  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Table 3  Scorers performance on IS-RC, DOD-H and DOD-O datasets with   (   ), overall accuracy (%Acc.), macro F1- score (%MF1), Cohen‚Äôs Kappa ( k ), weighted-averaging F1-score (%F1) and % per-class F1-score. The scorer with the best performance (i.e., high agreement with the consensus among the different physicians) is indicated in bold.  Overall Metrics   Per - Class F1 - Score  Scorers   SA   Acc.   MF1   k   F1   W   N1   N2   N3   R  IS - RC  Scorer - 1   0.79   83.0   69.5   0.72   83.8   83.1   47.2   87.3   48.0   82.1  Scorer - 2   0.81   89.4   72.8   0.82   89.2   91.3   57.6   92.5   32.9   89.8  Scorer - 3   0.53   40.7   26.5   0.11   40.8   29.8   14.7   54.5   17.9   15.6  Scorer - 4   0.52   38.9   26.1   0.12   40.5   28.6   14.7   54.2   15.4   17.5  Scorer - 5   0.70   73.7   61.6   0.63   75.8   88.7   36.9   70.2   25.8   86.2  Scorer - 6   0.79   87.2   77.2   0.81   88.2   92.5   54.6   89.4   59.8   89.5  Average   0.69   68.7   55.5   0.53   69.7   68.9   37.6   74.7   33.3   63.5  DOD - H  Scorer - 1   0.88   87.0   81.5   0.81   87.4   87.5   60.0   89.4   84.8   85.7  Scorer - 2   0.91   89.3   84.1   0.84   89.7   87.4   65.1   91.6   84.3   92.2  Scorer - 3   0.92   90.6   84.5   0.86   90.4   89.9   67.5   92.1   77.9   95.3  Scorer - 4   0.84   82.6   76.7   0.75   83.1   76.5   49.1   85.4   80.7   92.0  Scorer - 5   0.92   89.9   83.6   0.85   89.9   86.7   66.0   92.1   81.0   92.2  Average   0.89   87.9   82.1   0.82   88.1   85.5   61.5   90.0   81.7   91.5  DOD - O   Scorer - 1   0.87   85.0   75.1   0.77   84.6   90.0   49.5   85.2   67.6   83.3  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Scorer - 2   0.87   85.0   78.2   0.78   86.0   89.3   58.4   85.4   69.1   88.6  Scorer - 3   0.88   86.0   75.0   0.78   84.6   91.0   54.3   86.5   56.1   87.0  Scorer - 4   0.88   86.7   77.7   0.80   87.2   91.2   59.3   89.4   62.9   85.8  Scorer - 5   0.91   89.9   82.3   0.84   90.0   93.7   68.3   90.7   70.5   88.2  Average   0.88   86.5   77.6   0.79   86.4   91.0   58.0   87.3   65.2   86.5  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Table 4  Overall metrics, per-class F1-score, calibration and   hypnodensity graph similarity measures of the DSN-L models obtained from 10-fold cross-validation on IS-RC dataset, from 25-fold cross- validation on DOD-H dataset, and from 10-fold cross-validation on DOD-O dataset. Best shown in bold.  Overall Metrics   Pe r - Class F1 - Score   Calibration   Hypn.  Models   Acc.   MF1   k   F1   W   N1   N2   N3   R   ECE  IS - RC  base   -   69.6   50.6   0.56   70.0   81.6   11.8   71.9   27.2   60.7   0.096   79.0   0.772   0.075  base+LS U   0.4   74.8   57.0   0.63   75.8   83.3   24.3   79.0   30.6   67.7   0.296   45.2   0.806   0.042  base+LS SC   0.6   75.8   56.5   0.69   75.9   83.5   19.5   79.7   33.3   66.4   0.190   56.7   0.836   0.041  DOD - H  base   -   76.9   70.0   0.68   77.2   79.7   39.5   78.8   76.5   75.2   0.163   92.7   0.817   0.097  base+LS U   0.2   75.3   68.7   0.66   75.2   78.8   40.0   75.9   72.0   76.8   0.059   68.9   0.829   0.068  base+LS SC   0.8   80.2   72.4   0.72   80.4   80.4   42.3   83.4   77.6   78.8   0.016   81.4   0.873   0.053  DOD - O  base   -   77.3   67.8   0.66   78.0   80.7   41.2   81.0   68.1   68.3   0.131   90.2   0.840   0.073  base+LS U   0.1   77.5   68.0   0.67   78.2   80.8   41.9   80.4   68.4   68.7   0.009   78.4   0.859   0.072  base+LS SC   1   79.4   69.6   0.69   79.9   80.4   43.8   83.5   72.5   68.1   0.009   78.3   0.878   0.061  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Table 5  Overall metrics, per-class F1-score, calibration and   hypnodensity graph similarity measures of the SSN models obtained from 10-fold cross-validation on IS-RC dataset, from 25-fold cross- validation on DOD-H dataset, and from 10-fold cross-validation on DOD-O dataset. Best shown in bold.  Overall Metrics   Per - Class F1 - Score   Calibration   Hypn.  Models   Acc.   MF1   k   F1   W   N1   N2   N3   R   ECE  IS - RC  base   -   81.8   60.8   0.72   80.8   86.3   29.9   85.3   24.3   78.1   0.174   99.4   0.806   0.052  base+LS U   0.3   82.5   59.8   0.72   81.1   86.5   28.8   86.5   18.7   78.7   0.169   99.3   0.811   0.058  base+LS SC   0.7   83.1   60.2   0.73   81.6   86.7   27.6   86.8   20.1   79.8   0.162   99.2   0.817   0.047  DOD - H  base   -   87.1   80.2   0.81   87.1   83.6   55.5   90.0   83.3   89.0   0.126   99.7   0.890   0.047  base+LS U   0.4   87.6   81.0   0.81   87.5   85.5   57.3   90.2   82.1   90.3   0.120   99.5   0.899   0.034  base+LS SC   0.5   88.8   82.3   0.83   88.7   86.4   58.8   90.9   83.2   92.1   0.108   99.6   0.907   0.039  DOD - O  base   -   85.3   75.9   0.77   85.2   88.2   50.4   87.1   65.9   88.0   0.145   99.7   0.889   0.056  base+LS U   0.1   85.6   75.8   0.78   85.2   88.2   51.2   87.3   64.3   88.4   0.141   99.6   0.893   0.052  base+LS SC   1   86.8   77.7   0.79   86.7   89.0   51.0   88.3   69.3   91.1   0.125   99.2   0.906   0.043  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Table 6  Overall metrics and   hypnodensity graph similarity measures on the DSN-L and SSN   base+LS SC  models, obtained from 10-fold cross-validation on IS-RC dataset, from 25-fold cross-validation on DOD-H dataset, and from 10-fold cross-validation on DOD-O dataset with and without   MC . Best shown in bold.  Overall Metrics   Hypn.  Acc.   MF1   k   F1  IS - RC  DSN - L  w/o MC   75.8   56.5   0.69   75.9   0.836   0.041  w/   MC   78.6   57.6   0.67   78.0   0.850   0.036  SSN  w/o MC   83.1   60.2   0.73   81.6   0.817   0.047  w/   MC   83.0   59.2   0.73   81.1   0.818   0.048  DOD - H  DSN-L  w/o MC   80.2   72.4   0.72   80.4   0.873   0.053  w/   MC   84.4   75.9   0.76   84.2   0.906   0.026  SSN  w/o MC   88.8   82.3   0.83   88.7   0.907   0.039  w/   MC   89.1   82.6   0.84   89.0   0.910   0.039  DOD - O  DSN - L  w/o MC   79.4   69.6   0.69   79.9   0.878   0.061  w/   MC   80.7   70.8   0.71   80.9   0.889   0.059  SSN  w/o MC   86.8   77.7   0.79   86.7   0.906   0.043  w/   MC   87.1   78.0   0.80   86.9   0.909   0.041  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Figure 1  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Figure 2  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Figure 3  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023\n\nAccepted Manuscript  Figure 4  Downloaded from https://academic.oup.com/sleep/advance-article/doi/10.1093/sleep/zsad028/7034145 by guest on 12 February 2023",
      "embedding": [
        0.03002842888236046,
        0.03979307785630226,
        -0.016291983425617218,
        0.030381035059690475,
        0.030840124934911728,
        0.037359412759542465,
        0.061158061027526855,
        0.0626743957400322,
        0.07081054896116257,
        -0.04672550410032272,
        -0.08688363432884216,
        -0.03405566141009331,
        0.09603482484817505,
        0.04596550017595291,
        -0.03274405375123024,
        -0.04235008358955383,
        0.05435217544436455,
        0.018833057954907417,
        -0.05512959137558937,
        0.014160475693643093,
        0.048738814890384674,
        0.010562125593423843,
        0.07181277126073837,
        0.0651472881436348,
        -0.006721631158143282,
        -0.04825790971517563,
        -0.025520633906126022,
        -0.03872382640838623,
        -0.0565481074154377,
        -0.011179936118423939,
        -0.005920020397752523,
        0.08559457957744598,
        0.06467196345329285,
        -0.003620227100327611,
        -0.04281372204422951,
        -0.04908493161201477,
        -0.03645365312695503,
        0.07591241598129272,
        -0.0553242564201355,
        0.024555645883083344,
        0.03578164055943489,
        -0.017491571605205536,
        0.02827795222401619,
        -0.012183630838990211,
        0.003842191305011511,
        0.009705523028969765,
        -0.1472918540239334,
        -0.04934324696660042,
        -0.07125809788703918,
        0.15124839544296265,
        -0.1355975866317749,
        -0.026561396196484566,
        -0.020016439259052277,
        0.05866774916648865,
        -0.006660762708634138,
        0.031742341816425323,
        0.007094855885952711,
        -0.018847068771719933,
        0.0030123144388198853,
        0.06136861816048622,
        -0.0736469253897667,
        0.010333426296710968,
        -0.01821800135076046,
        0.019657369703054428,
        0.07142225652933121,
        0.06558293104171753,
        -0.05216020345687866,
        -0.012274413369596004,
        -0.01613418385386467,
        -0.03897630795836449,
        -0.07779518514871597,
        0.06441567093133926,
        -0.021572094410657883,
        0.020564021542668343,
        -0.016255829483270645,
        0.035088665783405304,
        0.04345518723130226,
        -0.0740300789475441,
        0.04607706144452095,
        -0.012148949317634106,
        -0.012911845929920673,
        0.05594785511493683,
        0.02813495136797428,
        -0.034912433475255966,
        0.042108748108148575,
        -0.016512230038642883,
        0.10673944652080536,
        0.06987732648849487,
        0.0037963842041790485,
        0.03147143870592117,
        0.02319711446762085,
        0.005755309481173754,
        0.015123599208891392,
        -0.0026477400679141283,
        0.041485659778118134,
        0.006266556680202484,
        -0.013808146119117737,
        -0.039865151047706604,
        0.0003467846545390785,
        0.03977283090353012,
        0.0044624158181250095,
        0.0576288141310215,
        -0.0034949681721627712,
        -0.05860332399606705,
        0.012557320296764374,
        -0.01538589783012867,
        0.014061949215829372,
        -0.0358198918402195,
        0.005679427180439234,
        -0.07501626014709473,
        -0.04413952678442001,
        0.08833584934473038,
        0.0015416431706398726,
        -0.009848017245531082,
        0.026904242113232613,
        0.07485591620206833,
        0.02785833179950714,
        0.10534605383872986,
        0.09328115731477737,
        0.05870679393410683,
        0.004895768593996763,
        -0.036885444074869156,
        0.06919775903224945,
        -0.09113708883523941,
        0.015364715829491615,
        -0.06730769574642181,
        -0.08193042129278183,
        6.153464603373064e-33,
        -0.020093590021133423,
        -0.03636539354920387,
        0.03479098901152611,
        0.011730404570698738,
        -0.006516662891954184,
        -0.04066181927919388,
        -0.07609657943248749,
        0.049429818987846375,
        0.021610653027892113,
        -0.022927962243556976,
        -0.0856439396739006,
        0.06949716061353683,
        -0.004153641406446695,
        0.06020335853099823,
        0.09750954806804657,
        0.03514522686600685,
        -0.025421656668186188,
        0.1001189574599266,
        -0.03610856831073761,
        0.018168039619922638,
        0.02390398271381855,
        -0.029360884800553322,
        0.0711047574877739,
        0.04516679048538208,
        -0.017166994512081146,
        0.029831629246473312,
        -0.03353061154484749,
        0.0480683259665966,
        -0.022915489971637726,
        0.0003122822963632643,
        -0.0679595023393631,
        -0.014393790625035763,
        0.02932192198932171,
        -0.04108564555644989,
        0.014972961507737637,
        -0.04804447293281555,
        0.00029127439484000206,
        -0.007501671556383371,
        0.015985477715730667,
        -0.0242842435836792,
        -0.07336097955703735,
        0.04263455420732498,
        0.06952559947967529,
        -0.015704559162259102,
        -0.049443069845438004,
        0.044025592505931854,
        -0.0028396490961313248,
        0.0014070861507207155,
        -0.037525005638599396,
        -0.02539326436817646,
        -0.0718693733215332,
        0.014830530621111393,
        -0.018325593322515488,
        -0.09077280759811401,
        -0.09559842944145203,
        0.04743676632642746,
        -0.008704823441803455,
        -0.009554342366755009,
        -0.03922528401017189,
        0.012295174412429333,
        0.04963607341051102,
        -0.0025050288531929255,
        0.03479804843664169,
        -0.0611874982714653,
        0.05712032690644264,
        0.056851282715797424,
        -0.011674420908093452,
        -0.04801304265856743,
        0.06712455302476883,
        -0.0831565409898758,
        -0.012894144281744957,
        -0.0012966978829354048,
        0.015620597638189793,
        0.010567926801741123,
        -0.014467630535364151,
        -0.016019238159060478,
        0.033483825623989105,
        0.033180177211761475,
        -0.030363358557224274,
        -0.09190907329320908,
        0.044308289885520935,
        0.004259567707777023,
        -0.061436209827661514,
        -0.0887175053358078,
        0.03187061473727226,
        -0.013360784389078617,
        0.008967314846813679,
        0.020294861868023872,
        -0.1679396778345108,
        0.01475602574646473,
        -0.06642841547727585,
        -0.013962449505925179,
        0.014637998305261135,
        0.05775904655456543,
        -0.0584808848798275,
        -6.680218315655916e-33,
        -0.14237473905086517,
        -0.03369633108377457,
        -0.040115825831890106,
        -0.010739123448729515,
        0.08206215500831604,
        -0.04537978768348694,
        0.009909817017614841,
        -0.051760945469141006,
        -0.03190053254365921,
        0.026629170402884483,
        -0.003286129329353571,
        -0.06867005676031113,
        -0.009679784998297691,
        -0.023877054452896118,
        0.026656953617930412,
        0.0422491729259491,
        -0.04300415515899658,
        0.0594167523086071,
        -0.04892520233988762,
        0.1014900803565979,
        0.025730770081281662,
        0.0895993635058403,
        -0.07706978917121887,
        -0.017531743273139,
        -0.014481239020824432,
        0.10131683200597763,
        0.010727002285420895,
        0.05765718221664429,
        -0.008487202227115631,
        -0.04127340018749237,
        -0.02062835730612278,
        -0.043774962425231934,
        -0.14713609218597412,
        -0.0023516162764281034,
        0.03918590769171715,
        -0.04971231892704964,
        -0.009334544651210308,
        -0.10868653655052185,
        -0.01573016680777073,
        0.010427751578390598,
        0.05556529387831688,
        0.07301577180624008,
        -0.10661108791828156,
        -0.028928358107805252,
        0.03754616156220436,
        0.013029712252318859,
        -0.059453144669532776,
        -0.09897623211145401,
        0.02678811550140381,
        0.014098583720624447,
        -0.011093229055404663,
        0.0035756737925112247,
        -0.059734392911195755,
        0.0581776387989521,
        -0.05480187386274338,
        -0.060631148517131805,
        0.0104000149294734,
        -0.02639508619904518,
        -0.014160767197608948,
        -0.014015410095453262,
        -0.014421224594116211,
        -0.026095112785696983,
        -0.0272819884121418,
        -0.012891123071312904,
        0.09083563089370728,
        0.036383576691150665,
        0.04376588016748428,
        -0.014491311274468899,
        -0.04824268817901611,
        0.03719169646501541,
        0.003798751626163721,
        -0.0029278816655278206,
        0.04040662944316864,
        -0.015221918001770973,
        -0.0388258621096611,
        -0.04004325345158577,
        -0.056441809982061386,
        -0.013128727674484253,
        -0.10337623208761215,
        -0.059546686708927155,
        -0.008340704254806042,
        -0.15436431765556335,
        0.009601944126188755,
        0.08344850689172745,
        -0.056732796132564545,
        -0.018007153645157814,
        0.14888638257980347,
        -0.03672242537140846,
        0.02114083245396614,
        0.02407757379114628,
        0.015882758423686028,
        0.08436070382595062,
        -0.0683961808681488,
        0.054978303611278534,
        -0.014564571902155876,
        -6.569458577132536e-8,
        0.018796473741531372,
        -0.06666270643472672,
        -0.02567819319665432,
        0.049674127250909805,
        -0.013335748575627804,
        -0.04360692948102951,
        -0.07660472393035889,
        -0.015302905812859535,
        -0.07821371406316757,
        0.04680619016289711,
        0.10358192771673203,
        -0.036699358373880386,
        0.06188736483454704,
        -0.030392898246645927,
        0.013585273176431656,
        0.018555443733930588,
        -0.030003244057297707,
        0.09159720689058304,
        -0.03379769250750542,
        0.0028664746787399054,
        0.053888965398073196,
        -0.011137865483760834,
        -0.005329039413481951,
        -0.06259556114673615,
        0.07424845546483994,
        0.017960958182811737,
        0.0034863760229200125,
        0.025992942973971367,
        0.022555509582161903,
        0.026641041040420532,
        0.04979422688484192,
        -0.021675823256373405,
        0.02172241546213627,
        0.022858334705233574,
        0.01634596660733223,
        0.0001009744155453518,
        0.0390213318169117,
        -0.0966050997376442,
        -0.008401883766055107,
        0.12664997577667236,
        -0.015598857775330544,
        0.0012291435850784183,
        -0.08544034510850906,
        0.04925934597849846,
        0.09475880116224289,
        -0.06786725670099258,
        0.038193248212337494,
        -0.018779776990413666,
        0.04986198619008064,
        0.0496852844953537,
        0.02151748351752758,
        -0.044761285185813904,
        -0.017918288707733154,
        0.006888938136398792,
        0.08747057616710663,
        0.0028252964839339256,
        0.0012650166172534227,
        -0.0044516935013234615,
        0.011805077083408833,
        0.0657343864440918,
        0.057740550488233566,
        -0.034118615090847015,
        -0.03287876397371292,
        -0.012779259122908115
      ],
      "metadata": {
        "title": "Paper_9_Multi_Scored_Sleep_Databases__How_to_Exploit_the_M.pdf",
        "createdAt": "2025-12-17T13:56:44.551Z"
      },
      "fileObj": {}
    },
    {
      "id": "doc_19_1765979805442",
      "fileName": "Paper_8_Brain_Damage_and_Motor_Cortex_Impairment_in_Chroni.pdf",
      "content": "SLEEP, Vol. 39, No. 2, 2016 327 Motor Cortex Impairment in COPD‚ÄîAlexandre et al.  SLEEP DISORDERED BREATHING Brain Damage and Motor Cortex Impairment in Chronic Obstructive Pulmonary Disease: Implication of Nonrapid Eye Movement Sleep Desaturation  Francois Alexandre, PhD 1,2   ; Nelly Heraud, PhD   2,3   ; Anthony M.J. Sanchez, PhD   4,5   ; Emilie Tremey, PhD   2,3   ; Nicolas Oliver, MD   2   ; Philippe Guerin, MD   3   ; Alain Varray, PhD 1  1 Movement To Health Laboratory, Euromov, University of Montpellier, Montpellier, France;   2 Clinique du Souffle La Vallonie, Fontalvie, Lod√®ve, France;   3 Clinique du Souffle  Les Clarines, Fontalvie, Riom-es-Montagnes, France;   4   UMR866 Dynamique Musculaire et M√©tabolisme, INRA, University of Montpellier, Montpellier, France;   5   Laboratoire  Performance Sant√© Altitude, EA 4604, University of Perpignan Via Domitia, Font-Romeu, France  Study Objectives:   Nonrapid eye movement (NREM) sleep desaturation may cause neuronal damage due to the withdrawal of cerebrovascular reactivity. The current study (1) assessed the prevalence of NREM sleep desaturation in nonhypoxemic patients with chronic obstructive pulmonary disease (COPD) and (2) compared a biological marker of cerebral lesion and neuromuscular function in patients with and without NREM sleep desaturation.  Methods:   One hundred fifteen patients with COPD (Global Initiative for Chronic Obstructive Lung Disease [GOLD] grades 2 and 3), resting PaO 2   of 60‚Äì80  mmHg, aged between 40 and 80 y, and without sleep apnea (apnea-hypopnea index < 15) had polysomnographic sleep recordings. In addition, twenty-nine  patients (substudy) were assessed i) for brain impairment by serum S100B (biological marker of cerebral lesion), and ii) for neuromuscular function via motor cortex activation and excitability and maximal voluntary quadriceps strength measurement.  Results:   A total of   51.3% patients (n = 59) had NREM sleep desaturation (NREM   Des ). Serum S100B was higher in the NREM   Des   patients of the substudy  (n = 14): 45.1 [Q1: 37.7, Q3: 62.8] versus 32.9 [Q1: 25.7, Q3: 39.5] pg.ml   ‚àí1   (P = 0.028). Motor cortex activation and excitability were lower in NREM   Des   patients (both P = 0.03), but muscle strength was comparable between groups (P = 0.58).  Conclusions:   Over half the nonhypoxemic COPD patients exhibited NREM sleep desaturation associated with higher values of the cerebral lesion biomarker and lower neural drive reaching the quadriceps during maximal voluntary contraction. The lack of muscle strength differences between groups suggests a compensatory mechanism(s). Altogether, the results are consistent with an involvement of NREM sleep desaturation in COPD brain impairment.  Clinical Trial Registration:   The study was registered at www.clinicaltrials.gov as NCT01679782.  Keywords:   central nervous system, cerebral cortex, electromyography, muscle weakness, voluntary activation  Citation:   Alexandre F, Heraud N, Sanchez AM, Tremey E, Oliver N, Guerin P, Varray A. Brain damage and motor cortex impairment in chronic obstructive pulmonary disease: implication of nonrapid eye movement sleep desaturation.   SLEEP   2016;39(2): 327 ‚Äì335.  INTRODUCTION  Patients with chronic obstructive pulmonary disease (COPD) present several neurological disorders that directly affect daily life. These disorders include cognitive dysfunction, which degrades quality of life by, for example, decreasing driving ability. 1   In our laboratory, we previously showed that motor cortex impairment could be involved in COPD muscle weak- ness due to inadequate motor cortex activation.   2 The origin of the cerebral dysfunction in patients with COPD remains unelucidated. The potential role of hypoxemia in triggering neuronal damage and dysfunction by cerebral ox- ygen deprivation has often been hypothesized.   3   However, sev- eral studies have provided evidence of cerebral dysfunction in nonhypoxemic COPD patients, indicating that hypoxemia   per se   is not the main factor. 4‚Äì6   This observation is unsurprising because an adequate oxygen supply to the brain is perma- nently ensured through cerebrovascular oxygen (O   2   ) reactivity. During hypoxemia or oxygen desaturation, cerebrovascular O   2   reactivity prevents cerebral hypoxia by increasing cerebral  blood flow (CBF) up to 200%. 7,8   Consequently, the resting CBF  is much higher in hypoxemic than in nonhypoxemic COPD patients and healthy controls. 9,10   For the same reason, CBF in - creases in COPD during exercise-induced desaturation. 11   This  pii: sp- 00025 -15   http://dx.doi.org/10.5665/sleep.5438  Significance  This study reveals that over half of COPD patients (grade 2 and 3) nonhypoxemic at rest have nocturnal desaturation during nonrapid eye movement sleep stages. These patients also present an increased cerebral lesion biomarker and a reduced motor cortex activation and excitability during quadriceps voluntary contractions. These results are consistent with the development of cerebral lesions in case of nonrapid eye movement sleep desaturation, and corroborate the hypothesis of an absence of cerebrovascular reactivity during these stages. The prevention of nonrapid eye movement sleep desaturation thus appears as a relevant clinical perspective to prevent COPD brain injury or even to restore brain function.  results in adequate cerebral oxygen delivery even in the case of hypoxemia. 11   As a whole, these studies provide evidence that cerebrovascular O   2   reactivity prevents brain hypoxia in COPD. Unfortunately, cerebrovascular reactivity is impaired during nonrapid eye movement (NREM) sleep stages. 12‚Äì15   Numerous  studies have reported an unexpected absence of CBF modula - tion during NREM sleep (but not during rapid eye movement [REM] sleep) in individuals who experience NREM sleep de- saturation. 12‚Äì15   Indeed, by decreasing arterial saturation of ox- ygen (SaO   2 ) artificially by 5% to 10%, Meadows et al. 15   found  a consistent CBF increase in wake states, whereas it tended to  decrease during slow wave sleep in hypoxemia. Therefore, if the arterial oxygen content falls below the normal value during NREM sleep, it may not be compensated, potentially leading to neuronal injury. 16 Nocturnal desaturation is frequent in nonhypoxemic COPD patients. The prevalence of COPD patients who are normoxic  while awake and who spend at least 30% of the total sleep time  (TST) with a saturation of peripheral oxygen (SpO   2 ) below  90% ranges from 38% to 70%. 17‚Äì19   To the best of our knowledge, the prevalence of  NREM sleep desaturation in COPD has never been specifi - cally assessed. It is generally acknowledged that the deepest\n\nSLEEP, Vol. 39, No. 2, 2016 328 Motor Cortex Impairment in COPD‚ÄîAlexandre et al.  desaturation occurs during REM sleep. However, because  REM sleep represents only about 13% of the TST in COPD,   20  patients with COPD and nocturnal desaturation (for at least  30% of TST) also necessarily experience desaturation for a sig -  nificant proportion of NREM sleep.  Central nervous system (CNS) injury in COPD was re- cently evidenced by magnetic resonance imaging (MRI) and  measurement of serum S100B levels. 21,22   S100B is a calcium  binding protein, mainly produced by astrocytes,   23   that is re- leased in the blood circulation in response to glia cell activa- tion during acute and chronic conditions of brain damage.   24  An increase in serum S100B concentration has been described  in a wide range of neurological disorders such as acute isch- emic and traumatic brain injury and hypoxic brain damage.   25‚Äì27  Serum S100B is considered as a surrogate biomarker for neu - ronal injury   28   and has the main advantage of providing an easy- to-use assessment of cerebral damage.   29 The aim of the study was twofold: to determine the preva- lence of patients with COPD who are nonhypoxemic but ex- perience nocturnal desaturation during NREM sleep; and to compare CNS injury and neuromuscular function in patients experiencing desaturation and those who are not during NREM sleep and assess the repercussions of desaturation on neural drive during maximal voluntary muscle contraction. We hy-  pothesized higher levels of serum S100B associated with lower  motor cortex activation and lower muscle strength in patients with COPD who experience desaturation during NREM sleep.  METHODS Participants  The study was conducted between 2012 and 2014 at the Cli -  nique du Souffle La Vallonie in Lodeve, France, and the Cli -  nique du Souffle Les Clarines in Riom-es-Montagnes, France.  Over this period, 1,213 patients taking part in a 4-w inpa- tient pulmonary rehabilitation program underwent a routine  medical examination in the first days following admission,  composed of anthropometric evaluation, resting pulmonary function assessment, resting blood gas assessment, the 6-min walk test, and polysomnographic sleep (PSG) recordings. after completion, patient records were screened to identify those pa-  tients who met the following criteria: between 40 and 80 y old,  diagnosis of COPD with postbronchodilator forced expiratory  volume in 1 sec (FEV 1 ) between 30% and 80% of predicted  values (corresponding to grades 2 and 3 of the Global Initia-  tive for Chronic Obstructive Lung Disease [GOLD] classifica - tion 30 ), resting partial pressure of oxygen (PaO   2 ) between 60 and 80 mmHg, and an apnea-hypopnea index (AHI) lower than 15 events per hour. One hundred fifteen patients fulfilled  these criteria and were thus selected for a study to determine the prevalence of NREM sleep desaturation in nonhypoxemic  COPD patients (Figure 1).  In a second step, we compared the neuromuscular function between patients with COPD with and without NREM sleep desaturation. Over a 6-mo period, a total of 29 consecutive patients underwent additional blood sampling and neuromus- cular assessment. Patients were not eligible for neuromuscular assessment if they were unable to give written consent or per- form the experimental maneuvers, were on medication known to impair brain function, or had impaired visual function, a pacemaker, current or past alcohol abuse, an exacerbation in the past 4 w, or neurologic or neuromuscular disease. Proce- dures were approved by the local Ethics Committee (Comit√©  de protection des personnes Sud Est VI, number AU980) and  complied with the principles of the Declaration of Helsinki for human experimentation. The study was registered at www.  clinicaltrials.gov as NCT01679782.  Design  All tests were completed within the first week after admis -  sion. All participants were first evaluated for anthropometric  parameters, resting pulmonary function, resting blood gases, the 6-min walk test, and polysomnographic sleep (PSG) re- cordings. The patients eligible for neuromuscular assessment were then probed and underwent medical examination after giving written consent. These patients were familiarized with  the neuromuscular tests on the first day. Blood samples were collected the next day at patient wake-up, and between 06:30 and 07:30. The neuromuscular tests took place in the morning.  The design of the neuromuscular tests is detailed in the Pro- tocol section.  Measurements  Pulmonary function test  Diagnosis and staging of COPD were based on spirometry  (V6200 Autobox, Sensormedics Corp., Yorba Linda, CA, USA). Measurements included forced vital capacity (FVC) and FEV 1 .  The presence of persistent airflow obstruction and thus COPD was defined by a postbronchodilator FEV 1 /FVC ratio < 70%. The FEV 1   values were compared with the predicted values of Quanjer et al.   31  Figure 1 ‚ÄîFlow diagram of the trial. The patients were assessed for eligibility at the beginning of a 4-w inpatient pulmonary rehabilitation  program. All tests were completed within the first week following  admission.\n\nSLEEP, Vol. 39, No. 2, 2016 329 Motor Cortex Impairment in COPD‚ÄîAlexandre et al.  Blood gas analysis  Blood gases (PaO 2   and partial arterial pressure of carbon dioxide [PaCO   2 ]) collected from the radial artery were measured in the resting patients while they breathed room air, using a blood gas  analyzer (ABL 825, Radiometer Medical, Bronshoj, Denmark).  Polysomnographic sleep recordings  PSG was performed using standard techniques and manually analyzed according to the latest guidelines of the American Academy of Sleep Medicine.   32   Stage epoch classification and  SpO   2   were exported at 1 Hz in a text file. Then the percentage  of SpO   2   below 90% during NREM sleep was analyzed with an automatic routine developed in MATLAB (MATLAB 8.0, The  MathWorks, Inc., Natick, MA, USA). Patients who spent more  than 10% with SpO 2   below 90% during NREM sleep were classified as NREM sleep desaturators (NREM Des ), and non- NREM sleep desaturators otherwise (NREM   noDes ), according to published data giving evidence of cognitive dysfunction for similar levels of desaturation.   33  Exercise-induced desaturation  Exercise-induced desaturation was assessed during a 6-min walk test,   34   which was performed indoors along a 15-m cor- ridor following the current international recommendations.   35 The SpO   2   was monitored throughout the test with a digital pulse oximeter (Nonin Medical, Inc. Minneapolis, MN, USA).  S100B measurement  Blood serum was obtained by centrifuging the blood samples for 10 min at 4,000 rpm and was kept frozen at ‚àí80¬∞C until studied. Serum samples were analyzed for human S100B using commer - cial enzyme-linked immunosorbent assay kits (EMD Millipore,  Billerica, MA, USA). S100B concentrations are expressed in pg/ mL and the limit of detection was 2.74 pg/mL. More details on S100B measurement can be found in the supplemental material.  Torque and electromyography recordings  Maximal quadriceps torque was studied during isometric max-  imal voluntary contractions (MVCs) of the dominant leg with hip and knee angles set at 90¬∞ and using the same settings as  previously described.   2   The surface electromyography (EMG) signal of the vastus medialis was recorded using bipolar, silver chloride, surface electrodes. The surface EMG signal was am-  plified (√ó1000) and recorded at a sampling frequency of 4096 Hz (Biopac MP100, Biopac Systems, Santa Barbara, CA, USA).  Neuromuscular excitability and activation  Peripheral nerve stimulation was used to measure peripheral  voluntary   activation   (peripheral   VA),   muscle   contractility  (peak twitch), muscle excitability (M-wave), and spinal excit- ability (H-wave). The femoral nerve of the dominant leg was stimulated with a constant-current, high-voltage stimulator (DS7AH, Digitimer, Hertforshire, UK). A recruitment curve was performed at rest to determine which intensities to use during the protocol to elicit maximal M-waves (Mmax) and H-waves (Hmax). Transcranial magnetic stimulation was used to measure cor-  tical voluntary activation (cortical VA) and corticospinal excit - ability. Single transcranial magnetic stimulation (TMS) pulses of 1-ms duration were delivered over the motor cortex using  a Magstim 200 (Magstim Co., Whitland, UK). A recruitment curve was performed during voluntary contraction at 10%  of the maximal quadriceps torque in order to determine the maximal intensity.   36   The intensity at which the highest motor- evoked potentials (MEP) was observed was then used during  the protocol to assess cortical VA and corticospinal excitability.  More details on the peripheral nerve and transcranial mag- netic stimulation procedures are provided in the supplemental material.  Protocol  The neuromuscular tests consisted of four MVCs of the knee extensors, each separated by 2 min of recovery (Figure 2). Par - ticipants were asked to maintain maximal effort for at least  4 sec. A double pulse at 100 Hz was delivered at the Mmax  intensity over the femoral nerve during the force plateau of the  first two MVCs (superimposed doublet) and 2 sec after relax - ation (control doublet), according to the twitch interpolation  Figure 2 ‚ÄîExperimental design. Gray rectangles represent voluntary quadriceps contractions at maximal (MVC) or submaximal intensity at 50 and 30% of MVC. Superimposed and control doublets, maximal M-waves (Mmax), and maximal H-waves (Hmax) were delivered via electrical stimulation over the femoral nerve. Motor-evoked potentials (MEP) were delivered over the motor cortex via transcranial magnetic stimulation.\n\nSLEEP, Vol. 39, No. 2, 2016 330 Motor Cortex Impairment in COPD‚ÄîAlexandre et al.  technique.   37   A single transcranial magnetic stimulation pulse was delivered over the motor cortex to elicit MEPs during the  force plateau of the last two MVCs. Three single pulses at Mmax intensity or Hmax intensity separated by 10 sec were delivered twice between MVCs to elicit Mmax and Hmax at rest, respectively (see Figure 2 for more details). After the MVCs, three submaximal voluntary contractions (SVCs) with visual feedback were performed at 50% and 30% of MVC. A  single transcranial magnetic stimulation pulse was delivered  during the force plateau of each SVC to elicit superimposed twitch responses at 30% and 50% of MVC. Then the transcra - nial magnetic stimulation resting twitch was determined by extrapolation of the linear regression between voluntary force  and the superimposed twitch evoked at 30%, 50%, and during MVC. 38  Data Analysis  Maximal quadriceps torque (Q MVC ) was selected as the highest  torque plateau of 500 ms from the four MVCs. Muscle contrac - tile properties were evaluated by the quadriceps peak twitch (Q   Pt ) from the highest twitch response induced by femoral nerve stimulation at rest. Muscle excitability was determined as the highest Mmax peak-to-peak amplitude induced by femoral nerve stimulation at rest. Spinal excitability was determined as the highest Hmax peak-to-peak amplitude normalized with respect to muscle ex- citability (i.e., Hmax/Mmax).  The amount of neural drive to the muscle was quantified  by the root mean square of the vastus medialis EMG signal (EMG   RMS ) during the highest torque plateau of 500 ms normal - ized with respect to muscle excitability (i.e., EMG   RMS   /Mmax).  Peripheral VA was calculated via femoral nerve stimulation  according to the twitch interpolation technique 37   as follows:  Peripheral VA (%) = [1 ‚àí ((superimposed doublet) ‚ÅÑ (control doublet)) √ó 100] Motor cortex activation (cortical VA) was calculated via transcranial magnetic stimulation. Because the relationship  between   superimposed   transcranial   magnetic   stimulation twitch and voluntary force is not linear for intensities below  25% of MVC (reduced cortical and spinal excitability at low  force levels 39 ), the transcranial magnetic stimulation resting twitch was estimated by extrapolation of the linear regression between voluntary force and the superimposed twitch evoked  at 30% of MVC, 50% of MVC, and during MVC. 38   The cortical  VA was calculated as follows 38   :  Cortical VA (%) = [1 ‚àí ((superimposed twitch) ‚ÅÑ (estimated resting twitch)) √ó 100]  Corticospinal excitability was assessed by the amplitude of the maximal MEP induced by transcranial magnetic stimu-  lation during MVCs, normalized with respect to muscle ex - citability (i.e., MEP/Mmax). The cortical silent period (CSP) duration was measured as the time between MEP onset and the return of voluntary EMG activity. The central motor conduc- tion time (CMCT) was calculated from the delay between the stimulus artifact and MEP onset.  Statistical Analysis  All statistical analyses were performed using Statistica software  (StatSoft, Inc., version 6.0, Tulsa, OK, USA). All data were ex - amined for normality using a Shapiro-Wilk test. Differences between NREM   Des   and NREM   noDes   patients were studied using unpaired   t -tests for parametric data, and nonparametric Mann- Whitney   U   tests otherwise. The required sample size for the sub- study was calculated on the level of voluntary activation (main  outcome), based on a between-groups difference of 20%. 40   With  a 5% significance level and a power of 90%, the required sample  size was ten per group. Data are reported as mean and standard deviation (SD) or median and quartiles (lower and upper quar- tiles labeled respectively by Q1 and Q3) in the case of nonpara-  metric statistics. The significance level was set at P ‚â§ 0.05.  RESULTS Prevalence of NREM Sleep Desaturation  The main characteristics of the NREM   noDes   and NREM   Des   pa- tients are depicted in Table 1. The NREM   Des   group was com-  posed of 59 patients (51.3% of the study sample), meaning that over half of the patients with COPD spent more than 10% of  NREM sleep time with SpO   2   below 90%. Mean SpO 2   during  NREM sleep was 92.9 ¬± 1.51% in the NREM noDes   patients  versus 88.9 ¬± 1.96% in the NREM Des   patients (P < 0.001). There was no significant difference between the NREM Des   and NREM   noDes   patients regarding age (P = 0.78), weight (P = 0.98), body mass index (BMI; P = 0.71), FEV 1   (P = 0.32), FEV 1 /FVC (P = 0.13), blood gases (P = 0.15 and P = 0.98 for PaO   2   and PaCO   2 , respectively) or AHI (P = 0.81).  Subsample Characteristics and Blood Sample Analysis  The NREM   Des   and NREM   noDes   patients who took part in the  neuromuscular tests (n = 29) did not exhibit any significant dif -  ferences regarding age, weight, BMI, FEV 1 , FEV 1 /FVC, blood  gases, or time to desaturate during exercise (Table 2). The total sleep time, arousal index, and AHI were also comparable be-  tween groups (P = 0.26, 0.97, and 0.92, respectively). Serum levels of S100B were significantly higher in the NREM Des   com- pared with NREM   noDes   patients (P = 0.028). The values were 45.1 [Q1: 37.7, Q3: 62.8] versus 32.9 [Q1: 25.7, Q3: 39.5] pg.mL ‚àí1   in the NREM   Des   and NREM   noDes   patients, respectively (Figure 3).  Quadriceps Torque and Voluntary Activation  The data are presented in Figure 4. There were no significant  differences on Q MVC   (P = 0.58) or Q Pt   (P = 0.48) between the  NREM   Des   and NREM   noDes   patients. Q MVC   values were 101.1 ¬± 39 and 110.9 ¬± 61 Nm, and Q Pt   values were 41 ¬± 20 and 37 ¬± 16 Nm,  for the NREM   Des   and NREM   noDes   patients, respectively. Con-  versely, peripheral VA was significantly lower in the NREM Des  patients (90.7 ¬± 7.6 versus 95.9 ¬± 3.3%, P = 0.022). The cortical VA was also decreased in the NREM Des   group compared with NREM   noDes   and was 89.5% [Q1: 85.8, Q3: 93.6] versus 94.1% [Q1: 93.6, Q3: 96.8), respectively (P = 0.03, Figure 4B).  Electrophysiological Data  The data are presented in Table 3. EMG   RMS   /Mmax and MEP/  Mmax were significantly lower in the NREM Des   compared\n\nSLEEP, Vol. 39, No. 2, 2016 331 Motor Cortex Impairment in COPD‚ÄîAlexandre et al.  with NREM   noDes   patients (P = 0.031 and P = 0.03, respectively). Mmax amplitude (P = 0.08), Hmax/Mmax (P = 0.66), CSP (P = 0.28) and CMCT (P = 0.88) were not significantly dif   - ferent between groups.  DISCUSSION  The major findings of the study were that more than half of the nonhypoxemic COPD patients spent more than 10% of NREM  sleep time with SpO   2   below 90%, and the nonhypoxemic COPD patients who spent more than 10% of NREM sleep time  in desaturation had reduced motor cortex activation and ex- citability during maximal voluntary contractions and higher  serum S100B concentrations.  Prevalence of NREM Sleep Desaturation  The prevalence of O 2   desaturation during sleep is thought to be  in the range of 38% to 70% in nonhypoxemic COPD patients,  and our data are consistent with this range. 17‚Äì19   In the current  Table 1 ‚ÄîCharacteristics of the patients included in the study.  Total Sample   NREM noDes   NREM Des   P  n (% total sample)   115 (100%)   56 (48.7%)   59 (51.3%) Sex M/F   61/54   29/27   32/27  Age, y   64.28 (9.2)   64.04 (9.3)   64.53 (9.1)   0.78  Weight, kg   79.5 (19.2)   79.5 (19)   79.5 (19.6)   0.98  BMI, kg.m   ‚àí2   28.7 (6.31)   28.5 (6.03)   28.9 (6.6)   0.71  FEV   1 , L   1.48 (0.56)   1.53 (0.58)   1.43 (0.54)   0.32 FEV   1   , % of predicted values   55.7 (15.5)   56.9 (15.5)   54.6 (15.5)   0.44 FEV   1   /FVC %   54.1 (10.7)   55.7 (10.4)   52.6 (10.9)   0.13 PaO   2   , mmHg   68.7 (5.2)   69.4 (5.78)   68 (4.54)   0.15 PaCO 2   , mmHg   39.4 (5.56)   39.5 (5.8)   39.4 (4.5)   0.98 SaO   2   , %   92.9 (2.39)   93.3 (2.41)   92.5 (2.32)   0.07 AHI, events.h   ‚àí1   6.58 (4.93)   6.43 (5.38)   6.73 (4.5)   0.81 % of NREM sleep time with SpO   2   < 90%   29 (35.4)   0.89 [0, 2.1]   46.2 [25.3, 89.9]   < 0.001  Values are means (standard deviation) or median [Q1, Q3 quartiles] in the case of nonparametric statistics. % of NREM sleep time with SpO 2   < 90% is  the percentage of time spent with pulse oxygen saturation below 90% during the NREM sleep stage. AHI, apnea-hypopnea index; BMI, body mass index,  FEV 1   , forced expiratory volume in 1 sec, FVC, forced vital capacity, PaCO   2   , arterial carbon dioxide tension; PaO   2   , arterial oxygen tension; SaO   2   , arterial oxygen saturation.  Table 2 ‚ÄîCharacteristics of the patients who took part in the neuromuscular tests.  NREM noDes   (n = 15)   NREM Des   (n = 14)   P  Sex M/F   10/5   9/5 Age, y   61.5 (8.57)   61.7 (6.09)   0.93 Weight, kg   69.5 (18.3)   74.6 (19.3)   0.46  BMI, kg.m   ‚àí2   25 (6.66)   25.9 (5.85)   0.69 FEV 1 , L   1.28 (0.54)   1.36 (0.57)   0.71  FEV   1   , % of predicted values   45.9 (15.5)   49.1 (16.8)   0.61 FEV   1   /FVC %   46.5 (11.5)   46.6 (11.5)   0.98 PaO   2   mmHg   73.5 (6.33)   71.6 (10.5)   0.56 PaCO 2   mmHg   38.9 (3.78)   41.1 (5.85)   0.35 SaO   2   %   94.4 (1.68)   93.7 (3.04)   0.44 % of 6 MWT time with SpO   2   < 90%   41.1 (35.6)   59.5 (40.7)   0.20 Total sleep time, min   370.2 (92.4)   324.9 (86.8)   0.26 Arousal index, events.h ‚àí1   16.1 (9.64)   16.3 (11.66)   0.97 AHI, events.h   ‚àí1   6.77 (7.91)   7.42 (6.81)   0.84 % of NREM sleep time with SpO   2   < 90%   0.6 [0, 5]   50.45 [16.6, 69]   < 0.001  Values are means (standard deviation) or median [Q1, Q3 quartiles] in the case of nonparametric statistics. % of 6 MWT time with SpO 2   < 90% is the percentage of time spent with pulse oxygen saturation below 90% during the 6 min walking test. % of NREM sleep time with SpO   2   < 90% is the percentage  of time spent with pulse oxygen saturation below 90% during the nonrapid eye movement (NREM) sleep stage. AHI, apnea-hypopnea index; BMI, body  mass index; FEV 1   , force expiratory volume in 1 sec; FVC, forced vital capacity; PaCO   2   , arterial carbon dioxide tension; PaO   2   , arterial oxygen tension; SaO   2   , arterial oxygen saturation.\n\nSLEEP, Vol. 39, No. 2, 2016 332 Motor Cortex Impairment in COPD‚ÄîAlexandre et al.  study, we used a cutoff of only 10% of the NREM sleep time,  with SpO 2   below 90% to diagnose NREM sleep desaturation. As NREM sleep desaturation has never been specifically assessed in  COPD, our choice was dictated by the criteria used to diagnose desaturation during TST. Although no clear consensus exists, a percentage of the TST with SpO 2   below 90% is frequently cited  in the literature. 41   We opted for a 10% criterion with SpO 2   below  90% as it has classically been used to study brain impairment. 33  This study is the first to assess the prevalence of NREM sleep  desaturation in COPD. Although it is indisputable that the deepest O 2   desaturation occurs during REM sleep, 41   a few studies have observed NREM sleep desaturation in patients with COPD who experience nocturnal desaturation. 42,43   Our results are consistent with these observations and provide further evidence that O   2   de- saturation during sleep is not restricted to REM sleep in COPD. It should be noted that the mechanisms responsible for NREM desaturation cannot be determined from our results, although the phenomenon seems unlikely to be explained by obstructive sleep apnea (OSA). Indeed, patients with severe OSA were excluded, and the AHIs were comparable in the two groups of patients with and without NREM sleep desaturation.  Furthermore, the mechanisms are unlikely to involve the levels  of diurnal PaO   2   , given the absence of diurnal PaO   2   differ- ences between the groups. This result is unsurprising because PaO   2   changes during sleep are not correlated with the diurnal PaO   2   levels in COPD. 44   Two important candidates to explain desaturation during sleep in COPD, especially during REM sleep, are alveolar hypoventilation and ventilation-perfusion mismatching. 41   Their potential implication in NREM sleep de- saturation remains to be investigated.  Effect of NREM Sleep Desaturation on Neuronal Damage and Neuromuscular Function  The second purpose of the study was to assess the repercus- sions of NREM sleep desaturation on neuronal damage and  neuromuscular function. To do so, serum S100B, an easy-to-  use and cost-effective biomarker of neuronal damage,   25‚Äì28   was analyzed in a subgroup of patients with COPD. The ability of  serum S100B to detect brain impairment was recently con -  firmed in COPD and found to be associated with hippocampal  atrophy and impaired cognitive function.   22   In the current study,  we observed a higher S100B concentration in patients with  NREM sleep desaturation, but without having the possibility to  localize the impaired brain areas. The higher serum S100B con - centrations could be linked to confounding factors other than NREM sleep desaturation, such as decreased sleep quality or sleep deprivation. 45   Importantly, we did not find any differences  between the patients who did and did not experience desatura- tion during NREM sleep regarding TST and the arousal index.  Figure 4 ‚Äî (A)   Maximal quadriceps torque (Q MVC ), quadriceps peak  twitch (Q Pt   ) and peripheral voluntary activation (peripheral VA) in patients with COPD experiencing desaturation (NREM   Des ) and nondesaturation (NREM   noDes ).   (B)   Medians and quartile box plots of motor cortex activation (cortical VA) in patients with COPD experiencing desaturation (NREM   Des ) and nondesaturation (NREM   noDes ) (nonparametric data). NREM, nonrapid eye movement.  A B Figure 3 ‚ÄîMedian and quartiles box plots of serum S100B concentration in the patients with COPD experiencing desaturation (NREM   Des ) and nondesaturation (NREM   noDes ) (non-parametric data). NREM = nonrapid eye movement.\n\nSLEEP, Vol. 39, No. 2, 2016 333 Motor Cortex Impairment in COPD‚ÄîAlexandre et al.  The functional repercussions of neuronal damage can be  numerous. We chose to focus specifically on neuromuscular  function and its effect on maximal quadriceps strength, as pe- ripheral muscle weakness is one of the main deleterious sys- temic effects in COPD. 46   By stimulating the motor cortex, we  observed lower MEP/M amplitude in the NREM   Des   patients during maximal voluntary contractions. The MEP/M ampli-  tude reflects both spinal and cortical excitability. 47   In the cur-  rent study, the comparable H-reflex amplitude observed in  the NREM   Des   and NREM   noDes   patients indicates that the lower MEP/M could not be attributed to lower spinal excitability and thus is mainly explained by reduced motor cortex excitability.  Furthermore, the reduced cortical excitability was associated  with lower motor cortex activation as well as lower quadri-  ceps motor unit activation (as measured by peripheral VA and  EMG   RMS   /M). These results support the hypothesis that patients with COPD who experience NREM sleep desaturation have reduced neural drive reaching the quadriceps muscle during  MVC because of motor cortical output failure.  Impaired neural drive to the quadriceps has been a contro- versial topic in COPD. One study reported lower activation at the muscle level in patients with COPD compared with healthy controls, 40   whereas others did not. 48,49   More recently, we found lower cortical activity through neuroimaging assessment in  patients with COPD during MVCs. 2   By using the neuroim - aging technique, it was not possible to infer that the lower cortical activity resulted in lower cortical output.   2   In the cur- rent study, we assessed the cortical motor output with a more direct approach by stimulating the motor cortex. Our results  confirm that cortical output is impaired in COPD but that it  mainly concerns those patients with NREM sleep desaturation, as the values of voluntary activation reached by the NREM   noDes  patients (around 95%) were substantially similar to those of  healthy subjects reported in other studies.   38,49   In addition, our data suggest that the discrepancies in previous studies might be explained by differences in the number of patients with COPD who experience NREM desaturation, which was not taken into account in previous works. Maximal muscle torque depends in part on the ability to activate the muscle. 50   In addition, as the relationship between  peripheral VA and torque is curvilinear, small modulations in peripheral VA induce much larger Q   MVC   changes at near- maximal contraction intensities.   51,52   For example, it was shown that a 5.7% increase in peripheral VA induced a 20.4% increase  in Q MVC. 52   Conversely, a 3% decrease in peripheral VA caused by neuromuscular fatigue has been associated with a 11% de - crease in Q MVC. 45   Therefore, the relatively low peripheral VA  for NREM   Des   compared with NREM   noDes   patients (average of  5.2% less) should have expressed a greater loss of strength in these patients than the average of 9% (nonsignificant) strength reduction (101 versus 111 Nm, P = 0.58). The finding that  the NREM   Des   patients reached the same torque level as the NREM   noDes   patients could be explained by low statistical power, or it may suggest a compensatory mechanism(s). Concerning  the first explanation, it is important to note that the SD of the  Q MVC   data are in accordance with those of other studies.   53   In addition, the current Q MVC   data are far from the level of sta-  tistical significance and we calculated the   a posteriori   number  of subjects needed to obtain 90% statistical power (400 par - ticipants). These observations are in accordance with a limited experimental effect, if proven. Any potential compensatory mechanism is unlikely to be linked to a difference in intrinsic muscle capacity (due to higher muscle mass or contractility) because Q   Pt   was comparable between groups. Muscle torque at a joint is the result of contributions from both agonist and antagonist muscles. In a condition of decreased agonist torque (due to lower cortical activation), any lower torque developed  by the antagonist knee flexor muscles during maximal quadri - ceps contraction in the NREM   Des   group could account for the comparable resultant torque; that is, comparable Q MVC . Unfor- tunately, the antagonist activity was not assessed in this study, but this hypothesis is supported by a study carried out by Simoneau et al.   54   These authors reported no differences in the  resultant maximal torque of the dorsiflexors in elderly subjects compared with young subjects, despite a 40% decrease in ago - nist maximal torque. This was explained by an activation of the  antagonist plantar flexor muscle during maximal dorsiflexion  that was almost twofold lower in the elderly, showing that in some circumstances maximal voluntary torque can apparently  be preserved despite a significant decrease in agonist torque.  Study Limitations  Serum S100B, which was used as a marker of CNS injury, has  the advantage of being a strong, sensitive, and easy-to-use marker of neuronal damage.   29   However, although S100B is a  marker of cerebral damage, it does not inform the location of the damage and cannot be used to localize the impaired brain areas. Computed tomography and MRI are likely to provide  Table 3 ‚ÄîElectrophysiological responses to transcranial magnetic and femoral nerve stimulation.  NREM noDes   (n = 15)   NREM Des   (n = 14)   P  Mmax amplitude mV   2.44 [1.64, 3.22]   4.32 [2.12, 7.9]   0.08 Hmax/Mmax   0.259 (0.208)   0.220 (0.153)   0.66 EMG   RMS /Mmax   0.077 (0.040)   0.046 (0.029)   0.031 MEP/Mmax   0.529 (0.143)   0.285 (0.243)   0.03 CSP ms   110 (20.3)   101 (14.2)   0.28 CMCT ms   20.6 (3.8)   20.2 (5.71)   0.88  Values are means (standard deviation) or median [Q1, Q3 quartiles] in the case of non-parametric statistics. CMCT, central motor conduction time;  CSP, corticospinal silent period; EMG   RMS   , root mean square of the vastus medialis electromyogram; MEP, motor-evoked potential; Mmax, maximal M-wave.\n\nSLEEP, Vol. 39, No. 2, 2016 334 Motor Cortex Impairment in COPD‚ÄîAlexandre et al.  useful complementary information on the cerebral damage in   patients   with   COPD   experiencing   desaturation   during NREM sleep. We did not directly assess the cerebrovascular O   2   reactivity during sleep. Therefore, although our results are highly con- sistent with an effect of NREM sleep desaturation on brain impairment, the occurrence of brain hypoxia during NREM sleep in the patients experiencing desaturation could only be inferred from the literature data. 12,13,55,56   A study to address the effect of correcting NREM sleep desaturation on serum  S100B levels and motor cortex impairment would address  this limitation.  CONCLUSION  NREM sleep desaturation is far from negligible as it concerns approximately one of two patients with moderate to severe COPD and a resting PaO   2   between 60 and 80 mmHg. The pa - tients with COPD who experience desaturation during NREM sleep exhibited an elevated level of a biomarker of CNS injury  (i.e., serum S100B) and lower neural drive during quadriceps MVCs due to impaired cortical motor output. The observation  that quadriceps muscle weakness was not more marked in the patients who experience desaturation suggests the existence of compensatory mechanisms whose nature and origin remain to be determined. Overall, the results are consistent with an involvement of NREM sleep desaturation in triggering CNS injury and decreasing neural drive to the quadriceps in COPD. The prevention of NREM sleep desaturation may well be an important clinical perspective to promote cerebral plasticity in  COPD. Further studies are needed to determine the extent to which reversing neural activity is beneficial for the maximal  voluntary force and functional capacity of patients with COPD.  REFERENCES  1.   Orth M, Diekmann C, Suchan B, et al. Driving performance in patients  with chronic obstructive pulmonary disease. J Physiol Pharmacol  2008;59:539‚Äì47.  2.   Alexandre F, Heraud N, Oliver N, Varray A. Cortical implication in  lower voluntary muscle force production in non-hypoxemic COPD  patients. PloS Oone 2014;9:e100961.  3.   Zheng GQ, Wang Y, Wang XT. Chronic hypoxia-hypercapnia influences cognitive function: a possible new model of cognitive  dysfunction in chronic obstructive pulmonary disease. Med  Hypotheses 2008;71:111‚Äì3.  4.   Dodd JW, Getov SV, Jones PW. Cognitive function in COPD. Eur Respir J 2010;35:913‚Äì22.  5.   Gupta PP, Sood S, Atreja A, Agarwal D. A comparison of cognitive functions in non-hypoxemic chronic obstructive pulmonary disease (COPD) patients and age-matched healthy volunteers using mini- mental state examination questionnaire and event-related potential,  P300 analysis. Lung India 2013;30:5‚Äì11.  6.   Liesker JJ, Postma DS, Beukema RJ, et al. Cognitive performance in patients with COPD. Respir Med 2004;98:351‚Äì6.  7.   Harris AD, Murphy K, Diaz CM, et al. Cerebral blood flow response to acute hypoxic hypoxia. NMR Biomed 2013;26:1844‚Äì52.  8.   Shapiro W, Wasserman AJ, Baker JP, Patterson JL Jr. Cerebrovascular  response to acute hypocapnic and eucapnic hypoxia in normal  man. J Clin Invest 1970;49:2362‚Äì8.  9.   Albayrak R, Fidan F, Unlu M, et al. Extracranial carotid Doppler ultrasound evaluation of cerebral blood flow volume in COPD patients. Respir Med 2006;100:1826‚Äì33. 10.   Yildiz S, Kaya I, Cece H, et al. Impact of COPD exacerbation on cerebral blood flow. Clin Imaging 2012;36:185‚Äì90.  11.   Vogiatzis I, Louvaris Z, Habazettl H, et al. Cerebral cortex oxygen  delivery and exercise limitation in patients with COPD. Eur Respir J  2013;41:295‚Äì301.  12.   Hajak G, Klingelhofer J, Schulz-Varszegi M, Sander D, Ruther  E. Sleep apnea syndrome and cerebral hemodynamics. Chest  1996;110:670‚Äì9.  13.   Balfors EM, Franklin KA. Impairment of cerebral perfusion  during obstructive sleep apneas. Am J Respir Crit Care Med  1994;150:1587‚Äì91.  14.   Meyer JS, Ishikawa Y, Hata T, Karacan I. Cerebral blood flow in normal and abnormal sleep and dreaming. Brain Cogn 1987;6:266‚Äì94.  15.   Meadows GE, O‚ÄôDriscoll DM, Simonds AK, Morrell MJ, Corfield DR. Cerebral blood flow response to isocapnic hypoxia during slow-wave sleep and wakefulness. J Appl Physiol 2004;97:1343‚Äì8.  16.   Corfield DR, Meadows GE. Control of cerebral blood flow during sleep and the effects of hypoxia. Adv Exp Med Biol 2006;588:65‚Äì73.  17.   Lacasse Y, Series F, Vujovic-Zotovic N, et al. Evaluating nocturnal oxygen desaturation in COPD--revised. Respir Med 2011;105:1331‚Äì7.  18.   Levi-Valensi P, Weitzenblum E, Rida Z, et al. Sleep-related oxygen  desaturation and daytime pulmonary haemodynamics in COPD  patients. Eur Respir J 1992;5:301‚Äì7.  19.   Chaouat A, Weitzenblum E, Kessler R, et al. Sleep-related O2 desaturation and daytime pulmonary haemodynamics in COPD  patients with mild hypoxaemia. Eur Respir J 1997;10:1730‚Äì5. 20.   McSharry DG, Ryan S, Calverley P, Edwards JC, McNicholas WT. Sleep quality in chronic obstructive pulmonary disease. Respirology  2012;17:1119‚Äì24.  21.   Lahousse L, van den Bouwhuijsen QJ, Loth DW, et al. Chronic  obstructive pulmonary disease and lipid core carotid artery plaques in the elderly: the Rotterdam Study. Am J Respir Crit Care Med  2013;187:58‚Äì64.  22.   Li J, Fei GH. The unique alterations of hippocampus and cognitive  impairment in chronic obstructive pulmonary disease. Respir Res  2013;14:140.  23.   Reeves RH, Yao J, Crowley MR, et al. Astrocytosis and axonal proliferation in the hippocampus of S100b transgenic mice. Proc Natl  Acad Sci U S A 1994;91:5359‚Äì63. 24.   Van Eldik LJ, Wainwright MS. The Janus face of glial-derived S100B: beneficial and detrimental functions in the brain. Restor Neurol Neurosci 2003;21:97‚Äì108.  25.   Vos PE, Lamers KJ, Hendriks JC, et al. Glial and neuronal proteins in  serum predict outcome after severe traumatic brain injury. Neurology  2004;62:1303‚Äì10.  26.   Abraha HD, Butterworth RJ, Bath PM, Wassif WS, Garthwaite J, Sherwood RA. Serum S-100 protein, relationship to clinical outcome in acute stroke. Ann Clin Biochem 1997;34:546‚Äì50.  27.   Bottiger BW, Mobes S, Glatzer R, et al. Astroglial protein S-100 is an  early and sensitive marker of hypoxic brain damage and outcome after  cardiac arrest in humans. Circulation 2001;103:2694‚Äì8.  28.   Sen J, Belli A. S100B in neuropathologic states: the CRP of the brain? J Neurosci Res 2007;85:1373‚Äì80.  29.   Pham N, Fazio V, Cucullo L, et al. Extracranial sources of S100B do not affect serum levels. PloS One 2010;5:e12691. 30.   GOLD. Global Strategy for the Diagnosis, Management and Prevention of COPD. Global Initiative for Chronic Obstructive Lung Disease (GOLD), 2014.Available from: http://www.goldcopd.org/.  31.   Quanjer PH, Tammeling GJ, Cotes JE, Pedersen OF, Peslin R, Yernault JC. Lung volumes and forced ventilatory flows. Report Working Party Standardization of Lung Function Tests, European Community for Steel and Coal. Official Statement of the European Respiratory Society. Eur Respir J Suppl 1993;16:5‚Äì40.  32.   Berry RB, Budhiraja R, Gottlieb DJ, et al. Rules for scoring respiratory events in sleep: update of the 2007 AASM Manual for the  Scoring of Sleep and Associated Events. Deliberations of the Sleep  Apnea Definitions Task Force of the American Academy of Sleep Medicine. J Clin Sleep Med 2012;8:597‚Äì619.\n\nSLEEP, Vol. 39, No. 2, 2016 335 Motor Cortex Impairment in COPD‚ÄîAlexandre et al.  33.   Park SY, Kim SM, Sung JJ, et al. Nocturnal hypoxia in ALS is related  to cognitive dysfunction and can occur as clusters of desaturations.  PloS One 2013;8:e75324.  34.   van Gestel AJ, Clarenbach CF, Stowhas AC, et al. Prevalence and  prediction of exercise-induced oxygen desaturation in patients with chronic obstructive pulmonary disease. Respi Int Rev Thorac Dis  2012;84:353‚Äì9.  35.   Brooks D, Solway S, Gibbons WJ. ATS statement on six-minute walk test. Am J Respir Crit Care Med 2003;167:1287.  36.   Temesi J, Gruet M, Rupp T, Verges S, Millet GY. Resting and  active motor thresholds versus stimulus-response curves to determine transcranial magnetic stimulation intensity in quadriceps  femoris. J Neuroeng Rehabil 2014;11:40.  37.   Allen GM, Gandevia SC, McKenzie DK. Reliability of measurements of muscle strength and voluntary activation using twitch interpolation.  Muscle Nerve 1995;18:593‚Äì600.  38.   Sidhu SK, Bentley DJ, Carroll TJ. Cortical voluntary activation of the  human knee extensors can be reliably estimated using transcranial  magnetic stimulation. Muscle Nerve 2009;39:186‚Äì96.  39.   Lee M, Gandevia SC, Carroll TJ. Cortical voluntary activation can  be reliably measured in human wrist extensors using transcranial  magnetic stimulation. Clin Neurophysiol 2008;119:1130‚Äì8. 40.   Vivodtzev I, Flore P, Levy P, Wuyam B. Voluntary activation during  knee extensions in severely deconditioned patients with chronic  obstructive pulmonary disease: benefit of endurance training. Muscle Nerve 2008;37:27‚Äì35.  41.   Weitzenblum E, Chaouat A. Sleep and chronic obstructive pulmonary  disease. Sleep Med Rev 2004;8:281‚Äì94.  42.   Becker HF, Piper AJ, Flynn WE, et al. Breathing during sleep in  patients with nocturnal desaturation. Am J Respir Crit Care Med 1999;159:112‚Äì8. 43.   Zanchet RC, Viegas CA. Nocturnal desaturation: predictors and the  effect on sleep patterns in patients with chronic obstructive pulmonary  disease and concomitant mild daytime hypoxemia. J Bras Pneumol 2006;32:207‚Äì12.  44.   Koo KW, Sax DS, Snider GL. Arterial blood gases and pH during  sleep in chronic obstructive pulmonary disease. Am J Med  1975;58:663‚Äì70.  45.   Papaiordanidou M, Guiraud D, Varray A. Kinetics of neuromuscular  changes during low-frequency electrical stimulation. Muscle Nerve  2010;41:54‚Äì62.  46.   Barnes PJ, Celli BR. Systemic manifestations and comorbidities of COPD. Eur Respir J 2009;33:1165‚Äì85.  47.   Fryer G, Pearce AJ. The effect of lumbosacral manipulation on corticospinal and spinal reflex excitability on asymptomatic participants. J Manipulative Physiol Ther 2012;35:86‚Äì93.  48.   Mador MJ, Deniz O, Aggarwal A, Kufel TJ. Quadriceps fatigability after single muscle exercise in patients with chronic obstructive  pulmonary disease. Am J Respir Crit Care Med 2003;168:102‚Äì8.  49.   Seymour JM, Ward K, Raffique A, et al. Quadriceps and ankle dorsiflexor strength in chronic obstructive pulmonary disease. Muscle Nerve 2012;46:548‚Äì54. 50.   Klass M, Baudry S, Duchateau J. Voluntary activation during maximal  contraction with advancing age: a brief review. Eur J Appl Physiol  2007;100:543‚Äì51.  51.   Herbert RD, Gandevia SC. Twitch interpolation in human muscles: mechanisms and implications for measurement of voluntary activation. J Neurophysiol 1999;82:2271‚Äì83. 52.   Kooistra RD, de Ruiter CJ, de Haan A. Conventionally assessed voluntary activation does not represent relative voluntary torque  production. Eur J Appl Physiol 2007;100:309‚Äì20.  53.   Menon MK, Houchen L, Harrison S, Singh SJ, Morgan MD, Steiner  MC. Ultrasound assessment of lower limb muscle mass in response to  resistance training in COPD. Respir Res 2012;13:119.  54.   Simoneau EM, Billot M, Martin A, Van Hoecke J. Antagonist  mechanical contribution to resultant maximal torque at the ankle joint  in young and older men. J Electromyogr Kinesiol 2009;19:e123‚Äì31.  55.   Olopade C, Mensah E, Gupta R, et al. Noninvasive determination of brain tissue oxygenation during sleep in obstructive sleep apnea: a  near-infrared spectroscopic approach. Sleep 2007;30:1747‚Äì55.  56.   Matsuo A, Inoue Y, Namba K, Chiba H. Changes in cerebral  hemoglobin indices in obstructive sleep apnea syndrome with  nasal continuous positive airway pressure treatment. Sleep Breath 2011;15:487‚Äì92.  ACKNOWLEDGMENTS  The authors thank Professor Robin Candau and Dr. Henri Bernardi for  assistance and the use of their facilities for serum data analyses, and  Dr. Mathieu Gueugnon for assistance in Matlab analyses. Furthermore,  the authors also thank the patient‚Äôs association Apard for the use of the polysomnograph.  SUBMISSION & CORRESPONDENCE INFORMATION  Submitted for publication January, 2015 Submitted in final revised form August, 2015 Accepted for publication September, 2015 Address correspondence to: Francois Alexandre, Movement To Health (M2H), Euromov, University of Montpellier, 700 avenue du Pic Saint Loup, 34090 Montpellier, France; Tel: (+33) 434 432 632; Fax: (+33) 434 432 644;  Email: alexandre.francois88@gmail.com  DISCLOSURE STATEMENT  This was not an industry supported study. Dr. Alexandre was partially  supported by a grant in aid from the French Ministry through the  ‚ÄúAssociation Nationale de la Recherche et de la Technologie‚Äù (National Agency for Research and Technology). The authors have no other funding  to declare. The authors have indicated no financial conflicts of interest. The work was performed at the Clinique du Souffle La Vallonie, Fontalvie, 800 avenue Joseph Vallot, 34700 Lod√®ve, France, and Clinique du Souffle Les Clarines, Fontalvie, Route de Condat, Le S√©dour Sud, 15400 Riom-es- Montagnes, France.",
      "embedding": [
        -0.0029252218082547188,
        -0.04370589926838875,
        -0.014798536896705627,
        0.04738366976380348,
        -0.02133866399526596,
        0.07628532499074936,
        -0.05962241813540459,
        0.044973600655794144,
        0.06432992219924927,
        0.044250890612602234,
        -0.03619738668203354,
        -0.012890295125544071,
        0.052101366221904755,
        0.03811738267540932,
        -0.03554379194974899,
        0.012086627073585987,
        0.05248471349477768,
        0.11111807823181152,
        -0.045831114053726196,
        0.06213783845305443,
        0.09294389188289642,
        0.06304620951414108,
        0.06766421347856522,
        0.01959138549864292,
        0.019199933856725693,
        0.04853196069598198,
        -0.07102160900831223,
        -0.07504535466432571,
        -0.041054610162973404,
        0.01949859969317913,
        -0.035242777317762375,
        0.055432528257369995,
        -0.04260332137346268,
        0.0038138169329613447,
        0.022516965866088867,
        -0.05368011072278023,
        0.014892644248902798,
        0.035857200622558594,
        -0.08934785425662994,
        -0.03389083594083786,
        -0.030238958075642586,
        0.001345180906355381,
        -0.06810463219881058,
        -0.03402959555387497,
        -0.06191636621952057,
        0.005468175280839205,
        -0.056034352630376816,
        -0.0021249353885650635,
        -0.08470108360052109,
        0.06513017416000366,
        0.01993044838309288,
        -0.012301520444452763,
        -0.02955297753214836,
        0.03986286744475365,
        0.004055321216583252,
        0.0015653218142688274,
        -0.0626600980758667,
        -0.0039490084163844585,
        -0.02801666408777237,
        0.04383666813373566,
        -0.09078808128833771,
        0.030735211446881294,
        0.08861759305000305,
        -0.034223854541778564,
        0.05979534983634949,
        0.04742073267698288,
        -0.044891394674777985,
        -0.07454315572977066,
        -0.03019554726779461,
        -0.03530136123299599,
        -0.05314665660262108,
        -0.11070310324430466,
        0.009171012789011002,
        0.0005569051136262715,
        -0.0728866383433342,
        0.004303844645619392,
        0.08252673596143723,
        -0.07132330536842346,
        0.018247483298182487,
        -0.10874123126268387,
        0.06165517121553421,
        0.0670839175581932,
        -0.01380275096744299,
        0.011256551370024681,
        0.014507153071463108,
        0.034291282296180725,
        0.04442233964800835,
        0.12796062231063843,
        -0.0425754152238369,
        0.004656633827835321,
        0.029347186908125877,
        0.010265184566378593,
        -0.11495515704154968,
        -0.0272513497620821,
        0.06327514350414276,
        -0.061479680240154266,
        -0.024915648624300957,
        0.035698968917131424,
        0.014647410251200199,
        -0.07806587219238281,
        0.07066700607538223,
        0.03049447387456894,
        0.040168363600969315,
        0.006681518163532019,
        -0.010197881609201431,
        0.03003351390361786,
        0.06990572065114975,
        -0.12295802682638168,
        -0.0035163527354598045,
        0.03359729424118996,
        -0.014981923624873161,
        0.05413917452096939,
        -0.01841861382126808,
        0.04738385230302811,
        0.10279824584722519,
        0.0757383182644844,
        -0.08689691126346588,
        0.0960005670785904,
        0.04716178774833679,
        0.0070051150396466255,
        0.02057054080069065,
        -0.07920841127634048,
        0.06257708370685577,
        -0.112330861389637,
        0.05935385078191757,
        -0.0030346575658768415,
        -0.05462917685508728,
        4.301855289316567e-33,
        0.04469422250986099,
        -0.03479515761137009,
        -0.010860622860491276,
        -0.011774539947509766,
        0.0013276744866743684,
        -0.0889534056186676,
        -0.00844668224453926,
        0.07621271908283234,
        0.03565305843949318,
        0.02661590650677681,
        -0.011923038400709629,
        -0.021981256082654,
        -0.000290683499770239,
        0.010241161100566387,
        0.012412254698574543,
        0.0683845803141594,
        -0.014741583727300167,
        -0.055675216019153595,
        0.025129515677690506,
        -0.04047041013836861,
        0.025226663798093796,
        0.002394885290414095,
        0.06543972343206406,
        0.04025053232908249,
        -0.009996066801249981,
        -0.043947484344244,
        -0.07832644134759903,
        0.05557939410209656,
        -0.04423734173178673,
        0.009742106311023235,
        0.004590316209942102,
        -0.05292302370071411,
        -0.04688335582613945,
        -0.05931410565972328,
        -0.006077006459236145,
        -0.02289920300245285,
        0.006636683829128742,
        0.026859961450099945,
        -0.06326758116483688,
        0.03637311980128288,
        -0.06665249168872833,
        0.03657021000981331,
        -0.047407910227775574,
        -0.03031766787171364,
        -0.01982075721025467,
        -0.09594420343637466,
        0.005614472087472677,
        0.025170743465423584,
        0.04163585230708122,
        0.008998511359095573,
        0.0370437353849411,
        -0.06427463889122009,
        0.02093086577951908,
        -0.09393924474716187,
        -0.010337695479393005,
        0.02613260969519615,
        0.008349732495844364,
        0.014992943964898586,
        -0.048320360481739044,
        0.0429781936109066,
        -0.0026777847670018673,
        0.039129506796598434,
        -0.01592487096786499,
        0.00015763365081511438,
        0.045033909380435944,
        0.032478295266628265,
        -0.08548389375209808,
        0.03933028504252434,
        -0.01954844780266285,
        -0.023663628846406937,
        0.06494560092687607,
        -0.05100822076201439,
        0.0567798838019371,
        0.009858210571110249,
        0.06399635970592499,
        -0.0027979365549981594,
        0.028301723301410675,
        0.0814727172255516,
        -0.09096085280179977,
        -0.03679625317454338,
        0.07535938918590546,
        0.07250478863716125,
        -0.06785004585981369,
        -0.06884594261646271,
        0.007252840790897608,
        -0.061181873083114624,
        0.030955281108617783,
        0.0627085268497467,
        -0.09483804553747177,
        -0.031049763783812523,
        0.10134418308734894,
        -0.03082314319908619,
        -0.002417525975033641,
        -0.015109354630112648,
        -0.05661388114094734,
        -5.75401729662625e-33,
        -0.03619944304227829,
        0.0012851681094616652,
        -0.013979680836200714,
        -0.012582361698150635,
        0.014982818625867367,
        0.06470924615859985,
        0.013895750977098942,
        -0.002464849269017577,
        -0.00768778333440423,
        -0.12933574616909027,
        0.02789137326180935,
        -0.027705201879143715,
        -0.03219781443476677,
        -0.0027034026570618153,
        0.09323037415742874,
        -0.004402481950819492,
        -0.11538311839103699,
        0.0316837914288044,
        -0.06024380400776863,
        0.07008878886699677,
        0.03692067414522171,
        -0.016544833779335022,
        -0.02594582736492157,
        0.005239509046077728,
        0.06185382604598999,
        0.054526373744010925,
        -0.04206879064440727,
        0.04937908425927162,
        0.06606870889663696,
        -0.03416477516293526,
        0.07419189065694809,
        0.056733325123786926,
        -0.13950952887535095,
        0.011684753000736237,
        0.025474179536104202,
        -0.02446035109460354,
        0.0010300130816176534,
        0.031486187130212784,
        -0.07484328746795654,
        -0.04042578116059303,
        0.01837795600295067,
        0.06603524088859558,
        0.05314895138144493,
        0.042107269167900085,
        0.10867833346128464,
        -0.001382993534207344,
        -0.012753354385495186,
        -0.1269613653421402,
        -0.037148430943489075,
        0.006786833517253399,
        0.02249891497194767,
        0.05087031051516533,
        -0.0632389709353447,
        0.01758190430700779,
        0.037725359201431274,
        0.037307530641555786,
        -0.003469921415671706,
        0.004333608318120241,
        -0.06194085255265236,
        -0.006767971906810999,
        0.038396552205085754,
        0.0507245808839798,
        -0.059272486716508865,
        -0.07198481261730194,
        0.0799681767821312,
        0.004938287660479546,
        -0.0161433145403862,
        0.018029509112238884,
        0.11738734692335129,
        0.010794715955853462,
        -0.06010990962386131,
        -0.08427038043737411,
        -0.028934583067893982,
        0.002315016696229577,
        0.028850391507148743,
        0.06450557708740234,
        0.046561695635318756,
        -0.0003244820691179484,
        -0.033466823399066925,
        0.0032627785112708807,
        -0.013390828855335712,
        -0.021350592374801636,
        -0.022954387590289116,
        -0.007791025098413229,
        -0.01149836927652359,
        0.008189821615815163,
        -0.020690808072686195,
        -0.06350957602262497,
        0.12240643799304962,
        -0.03625568747520447,
        -0.028964128345251083,
        -0.0022656249348074198,
        -0.09386807680130005,
        -0.005333369132131338,
        0.0009476025006733835,
        -5.270799974255169e-8,
        -0.019219350069761276,
        -0.017986798658967018,
        0.03766782209277153,
        0.03355032950639725,
        -0.0023042771499603987,
        -0.045521389693021774,
        0.08627603948116302,
        -0.045698270201683044,
        -0.04829811677336693,
        0.08016661554574966,
        0.07103601098060608,
        -0.027602100744843483,
        0.05678499862551689,
        -0.08320526033639908,
        0.00523553928360343,
        -0.019743159413337708,
        -0.008939680643379688,
        0.037689223885536194,
        0.020005445927381516,
        0.03977598249912262,
        0.02795698493719101,
        -0.04311438649892807,
        -0.058750227093696594,
        -0.028150178492069244,
        0.03503939509391785,
        -0.08261838555335999,
        -0.020845741033554077,
        -0.022684821859002113,
        0.000053901512728771195,
        -0.03979871794581413,
        -0.0019914028234779835,
        -0.004130270332098007,
        0.010325646959245205,
        -0.04690200835466385,
        0.013024658896028996,
        -0.08158683031797409,
        0.1014251559972763,
        0.018682638183236122,
        -0.030130678787827492,
        0.1762407124042511,
        0.018211178481578827,
        0.003699067747220397,
        -0.013354821130633354,
        0.014272605068981647,
        0.08776532858610153,
        -0.05862998589873314,
        -0.014976898208260536,
        -0.06714921444654465,
        0.0012974417768418789,
        -0.09462250024080276,
        -0.0629551038146019,
        -0.041259657591581345,
        -0.036665283143520355,
        0.005465612281113863,
        -0.08661272376775742,
        0.045709505677223206,
        -0.03692621737718582,
        0.024242153391242027,
        -0.0011134302476420999,
        -0.07485219091176987,
        0.004237193148583174,
        0.011388423852622509,
        -0.02560371160507202,
        -0.0070338076911866665
      ],
      "metadata": {
        "title": "Paper_8_Brain_Damage_and_Motor_Cortex_Impairment_in_Chroni.pdf",
        "createdAt": "2025-12-17T13:56:45.442Z"
      },
      "fileObj": {}
    }
  ]
}