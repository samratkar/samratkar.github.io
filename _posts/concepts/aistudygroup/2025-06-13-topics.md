### Meetup Link 

https://meet.google.com/cag-tcwi-eju 

### Sunday 6-6-2025

#### Today's topics covered - 
1. Deep learning - backward propagation intuition
2. Improvements on deep learning - RNN and LSTM high level overview
3. Attention mechanism and transformer architecture overview
4. Position embeddings, Attention scores
5. RL overview
6. Value alignment overview
7. Limitation of LLM and need for multi agentic systems
8. Introduction to langchain and llama index and how it helps build multi agentic systems

#### Notes 
1. Attention is all you need paper - https://arxiv.org/abs/1706.03762
2. RNN - https://samratkar.github.io/2025/02/01/RNN-theo.html
3. LSTM - https://samratkar.github.io/2025/02/15/LSTM-theory.html
4. Position embedding - https://samratkar.github.io/2025/03/11/position-embed.html
5. Attention mechanism - https://samratkar.github.io/2025/03/14/attention-overview.html
6. Gradient Descent - https://www.youtube.com/watch?v=jl5LjHyrgBg&t=310s 

#### Courses - 
1. Jay Alammar Course on Attention mechanism - https://learn.deeplearning.ai/courses/how-transformer-llms-work/lesson/nfshb/introduction
2. Joshua Starmer's Course on Attention mechanism - https://learn.deeplearning.ai/courses/attention-in-transformers-concepts-and-code-in-pytorch/lesson/han2t/introduction

#### Books - 
Book to buy to  understand the internals of attention mechanism - Hands-On Large Language Models by Jay Alammar https://www.shroffpublishers.com/books/9789355425522/ 

#### Youtube channels to subscribe for attention mechanism internals - 
1. https://www.youtube.com/@vizuara - Vizuara by Raj Dandekar
2. https://www.youtube.com/@SebastianRaschka - Sebastian Raschka 
3. https://www.youtube.com/@arp_ai - Jay Alammar
4. https://www.youtube.com/@statquest - Joshua Starmer

#### Youtube channel to subscribe for LLM based app development 
1. Krish Naik - https://www.youtube.com/@krishnaik06

