{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce785044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4299bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b723455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2abe5ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25b19322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! I'm just a program, so I don't have feelings, but I'm here to help you. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 13, 'total_tokens': 40, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_80956533cb', 'id': 'chatcmpl-C8qSvf9GtzMKYgtEi2gFPcfUGd0v2', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b574e17a-7022-43d7-8bf4-d4c5a340daf5-0', usage_metadata={'input_tokens': 13, 'output_tokens': 27, 'total_tokens': 40, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hi hello how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbb6ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "919250c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64485964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AgentState(TypedDict):\n",
    "#     messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "#     Name:str\n",
    "#     age:int\n",
    "#     DOB:int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5674bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_number(state):\n",
    "    result=state[\"num1\"]+state[\"num2\"]\n",
    "    print(f\"addition is {result}\")\n",
    "    return Command(goto=\"multiply\",update={\"sum\":result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61dcdd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state={\"num1\":10,\"num2\":20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11ada0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addition is 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Command(update={'sum': 30}, goto='multiply')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_number(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3be377",
   "metadata": {},
   "source": [
    "### Creating one dummy multiagent\n",
    "\n",
    "it is for network/collab multiagent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4e4e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e06526b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def transfer_to_multiplication_expert():\n",
    "    \"\"\"Ask multiplication agent for help\"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e610d2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def transfer_to_addition_expert():\n",
    "    \"\"\"Ask addition agent for help\"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b00032aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tool=llm.bind_tools([transfer_to_addition_expert])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aecb33b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=llm_with_tool.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36429fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2499954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "466263d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=llm_with_tool.invoke(\"what is 2+2?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "01c07057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "81f4991d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'transfer_to_addition_expert',\n",
       "  'args': {},\n",
       "  'id': 'call_efUFRfP7dDZYAYVdr6qQ5O0q',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51555fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "        \"You are an addition expert, you can ask the multiplication expert for help with multiplication.\"\n",
    "        \"Always do your portion of calculation before the handoff.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ad3bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [\"can you tell me the addition of 2 and 2?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05f3e211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an addition expert, you can ask the multiplication expert for help with multiplication.Always do your portion of calculation before the handoff.'},\n",
       " 'can you tell me the addition of 2 and 2?']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bce10c",
   "metadata": {},
   "source": [
    "[{'role': 'system',\n",
    "  'content': 'You are an addition expert, you can ask the multiplication expert for help with multiplication.Always do your portion of calculation before the handoff.'},\n",
    " 'can you tell me the addition of 2 and 2?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11585150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Literal\n",
    "from langgraph.graph import MessagesState,StateGraph, START,END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "80dd87d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def additional_expert(state:MessagesState)-> Command[Literal[\"multiplication_expert\", \"__end__\"]]:\n",
    "    \n",
    "    system_prompt = (\n",
    "        \"You are an addition expert, you can ask the multiplication expert for help with multiplication.\"\n",
    "        \"Always do your portion of calculation before the handoff.\"\n",
    "    )\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "    \n",
    "    \n",
    "    ai_msg = llm.bind_tools([transfer_to_multiplication_expert]).invoke(messages)\n",
    "    \n",
    "    \n",
    "    if len(ai_msg.tool_calls) > 0:\n",
    "        tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
    "        tool_msg = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": \"Successfully transferred\",\n",
    "            \"tool_call_id\": tool_call_id,\n",
    "        }\n",
    "        \n",
    "        return Command(\n",
    "            goto=\"multiplication_expert\", update={\"messages\": [ai_msg, tool_msg]}\n",
    "        )\n",
    "    return {\"messages\": [ai_msg]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6e977eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Agent2\n",
    "def multiplication_expert(state:MessagesState)-> Command[Literal[\"additional_expert\", \"__end__\"]]:\n",
    "    \n",
    "    system_prompt = (\n",
    "        \"You are a multiplication expert, you can ask an addition expert for help with addition. \"\n",
    "        \"Always do your portion of calculation before the handoff.\"\n",
    "    )\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "    \n",
    "    ai_msg = llm.bind_tools([transfer_to_addition_expert]).invoke(messages)\n",
    "    \n",
    "    if len(ai_msg.tool_calls) > 0:\n",
    "        tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
    "        tool_msg = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": \"Successfully transferred\",\n",
    "            \"tool_call_id\": tool_call_id,\n",
    "        }\n",
    "        return Command(goto=\"additional_expert\", update={\"messages\": [ai_msg, tool_msg]})\n",
    "    return {\"messages\": [ai_msg]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b4409b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(MessagesState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fd04308c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1bc956680a0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_node(\"additional_expert\",additional_expert)\n",
    "graph.add_node(\"multiplication_expert\",multiplication_expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c000d482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1bc956680a0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_edge(START, \"additional_expert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "167451f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "app=graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cf783fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"what's (3 + 5) * 12. Provide me the output\", additional_kwargs={}, response_metadata={}, id='504276e8-c619-4691-ac26-295af5c6984d'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_HyFaM2WWuNu6xLxTB8bbQf0X', 'function': {'arguments': '{}', 'name': 'transfer_to_multiplication_expert'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 86, 'total_tokens': 100, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Bl74ZmahG9pCAdfp8KYhPKfG6oULJ', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d9308028-8f59-44a9-ba7f-df9bd62647dd-0', tool_calls=[{'name': 'transfer_to_multiplication_expert', 'args': {}, 'id': 'call_HyFaM2WWuNu6xLxTB8bbQf0X', 'type': 'tool_call'}], usage_metadata={'input_tokens': 86, 'output_tokens': 14, 'total_tokens': 100, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Successfully transferred', id='c354a127-40f8-4207-86b1-4bb103ee4203', tool_call_id='call_HyFaM2WWuNu6xLxTB8bbQf0X'),\n",
       "  AIMessage(content=\"I have transferred the calculation to the multiplication expert. Let's wait for their response.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 114, 'total_tokens': 132, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Bl74ZeszRuGB35D2sGggAZ77AdxAm', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--13b6ef47-d79d-4fb7-8a3b-d1b3821fc74a-0', usage_metadata={'input_tokens': 114, 'output_tokens': 18, 'total_tokens': 132, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"messages\":[(\"user\",\"what's (3 + 5) * 12. Provide me the output\")]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b341d8f2",
   "metadata": {},
   "source": [
    "## With realtime tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f1da329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e8e8ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_tool=DuckDuckGoSearchRun()\n",
    "\n",
    "import os\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "TAVILY_API_KEY=os.getenv(\"TAVILY_API_KEY\")\n",
    "search_tool=TavilySearchResults(tavily_api_key=TAVILY_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "716ea8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Prime Minister - GOV.UK',\n",
       "  'url': 'https://www.gov.uk/government/ministers/prime-minister',\n",
       "  'content': 'The Prime Minister is the leader of His Majesty’s Government and is ultimately responsible for the policy and decisions of the government.\\n\\nAs leader of the UK government the Prime Minister also:\\n\\n## Current role holder\\n\\n### The Rt Hon Sir Keir Starmer KCB KC MP\\n\\nSir Keir Starmer became Prime Minister on 5 July 2024.\\n\\n## Education [...] Keir attended Reigate Grammar School, before studying Law at the University of Leeds. He went on to do postgraduate studies at the University of Oxford, receiving a Bachelor of Civil Law (BCL) degree.\\n\\n## Political Career\\n\\nKeir was elected a Member of Parliament for Holborn and St Pancras in May 2015. He was elected leader of the Labour Party in April 2020.\\n\\n## Career before politics [...] Find out more about previous holders of this role in our past Prime Ministers section.\\n\\n## Announcements\\n\\n## Subscriptions\\n\\n## Is this page useful?\\n\\n## Help us improve GOV.UK\\n\\nDon’t include personal or financial information like your National Insurance number or credit card details.\\n\\n## Help us improve GOV.UK\\n\\nTo help us improve GOV.UK, we’d like to know more about your visit today.\\nPlease fill in this survey (opens in a new tab and requires JavaScript).\\n\\n## Services and information',\n",
       "  'score': 0.8235701},\n",
       " {'title': 'Prime Minister of the United Kingdom - Wikipedia',\n",
       "  'url': 'https://en.wikipedia.org/wiki/Prime_Minister_of_the_United_Kingdom',\n",
       "  'content': \"Prime Minister of the United Kingdom ; Incumbent Keir Starmer. since 5 July 2024 ; Government of the United Kingdom · Prime Minister's Office\",\n",
       "  'score': 0.8051581},\n",
       " {'title': 'Keir Starmer - Wikipedia',\n",
       "  'url': 'https://en.wikipedia.org/wiki/Keir_Starmer',\n",
       "  'content': 'Sir Keir Rodney Starmer (born 2 September 1962) is a British politician and lawyer who has served as Prime Minister of the United Kingdom since 2024 and as',\n",
       "  'score': 0.76659125},\n",
       " {'title': 'The Rt Hon Sir Keir Starmer KCB KC MP - GOV.UK',\n",
       "  'url': 'https://www.gov.uk/government/people/keir-starmer',\n",
       "  'content': \"### Services and information\\n\\n### Government activity\\n\\nDepartments, agencies and public bodies\\n\\nNews stories, speeches, letters and notices\\n\\nDetailed guidance, regulations and rules\\n\\nReports, analysis and official statistics\\n\\nConsultations and strategy\\n\\nData, Freedom of Information releases and corporate reports\\n\\n### Search\\n\\n# The Rt Hon Sir Keir Starmer KCB KC MP\\n\\n## Contents\\n\\n## Biography\\n\\nSir Keir Starmer became Prime Minister on 5 July 2024.\\n\\n## Education [...] To help us improve GOV.UK, we’d like to know more about your visit today.\\nPlease fill in this survey (opens in a new tab and requires JavaScript).\\n\\n## Services and information\\n\\n## Government activity\\n\\n## Support links [...] As Minister for the Union, the Prime Minister works to ensure that all of government is acting on behalf of the entire United Kingdom: England, Northern Ireland, Scotland, and Wales.\\n\\nMore about this role\\n\\nCabinet Office and Prime Minister's Office, 10 Downing Street\\n\\n## Announcements\\n\\n## Subscriptions\\n\\n## Is this page useful?\\n\\n## Help us improve GOV.UK\\n\\nDon’t include personal or financial information like your National Insurance number or credit card details.\\n\\n## Help us improve GOV.UK\",\n",
       "  'score': 0.6420965},\n",
       " {'title': \"Prime Minister's Office, 10 Downing Street - GOV.UK\",\n",
       "  'url': 'https://www.gov.uk/government/organisations/prime-ministers-office-10-downing-street',\n",
       "  'content': \"Up to 880,000 households across the UK may be missing out on support worth on average over £3,900 a year. Read more about claiming for yourself or a loved one.\\n\\n### Our plan to build more homes\\n\\n30 July 2024 — News story\\n\\nNew targets will boost housebuilding in areas most in need.\\n\\n## Latest news\\n\\n## PM call with President Nawrocki of Poland: 12 September 2025\\n\\n## Videos\\n\\n### Prime Minister Keir Starmer travels to Germany to meet Chancellor Scholz\\n\\nView the 10 Downing Street Youtube channel [...] ## Meet the Prime Minister\\n\\nKeir Starmer\\n\\n## History\\n\\nThe door of Number 10 Downing Street\\n\\n## Contact Number 10\\n\\n### Prime Minister's Office enquiries\\n\\nContact: Prime Minister's Office enquiries [...] Due to the exceptionally high volumes of emails being received at this time, the Prime Minister’s Office is only able to deal with those that relate directly to the Prime Minister. At this time we are not able to respond to emails that do not fall into this category or are of a general nature.  \\n  \\nPlease consider carefully whether your email is necessary and note that emails are not monitored throughout the day or at weekends.\",\n",
       "  'score': 0.5164741}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tool.invoke(\"who is a current pm of uk?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bebeb27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.utilities import PythonREPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eab67be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "repl=PythonREPL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d391e871",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "x = 5\n",
    "y = x * 2\n",
    "print(y)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "62617dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'10\\n'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repl.run(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cde22425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a5d71f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def python_repl_tool(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
    "):\n",
    "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    \n",
    "    result_str = f\"Successfully executed:\\n\\`\\`\\`python\\n{code}\\n\\`\\`\\`\\nStdout: {result}\"\n",
    "    return (\n",
    "        result_str + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65996c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='python_repl_tool', description='Use this to execute python code. If you want to see the output of a value,\\n    you should print it out with `print(...)`. This is visible to the user.', args_schema=<class 'langchain_core.utils.pydantic.python_repl_tool'>, func=<function python_repl_tool at 0x0000025A5A74EDE0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_repl_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9281fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully executed:\n",
      "\\`\\`\\`python\n",
      "\n",
      "x = 5\n",
      "y = x * 2\n",
      "print(y)\n",
      "\n",
      "\\`\\`\\`\n",
      "Stdout: 10\n",
      "\n",
      "\n",
      "If you have completed all tasks, respond with FINAL ANSWER.\n"
     ]
    }
   ],
   "source": [
    "print(python_repl_tool.invoke(code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a9688b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully executed:\n",
      "\\`\\`\\`python\n",
      "\n",
      "x = 5\n",
      "y = x * 2\n",
      "print(y)\n",
      "\n",
      "\\`\\`\\`\n",
      "Stdout: 10\n",
      "\n",
      "\n",
      "If you have completed all tasks, respond with FINAL ANSWER.\n"
     ]
    }
   ],
   "source": [
    "print(python_repl_tool.invoke(code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a1a49fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_system_prompt(instruction:str)->str:\n",
    "    return  (\n",
    "        \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "        \" Use the provided tools to progress towards answering the question.\"\n",
    "        \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "        \" will help where you left off. Execute what you can to make progress.\"\n",
    "        \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "        \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "        f\"\\n{instruction}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e26d71ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are a helpful AI assistant, collaborating with other assistants. Use the provided tools to progress towards answering the question. If you are unable to fully answer, that's OK, another assistant with different tools  will help where you left off. Execute what you can to make progress. If you or any of the other assistants have the final answer or deliverable, prefix your response with FINAL ANSWER so the team knows to stop.\\nYou can only do research. You are working with a chart generator colleague.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_system_prompt(\"You can only do research. You are working with a chart generator colleague.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7680be1",
   "metadata": {},
   "source": [
    "\"You are a helpful AI assistant, collaborating with other assistants. Use the provided tools to progress towards answering the question. If you are unable to fully answer, that's OK, another assistant with different tools  will help where you left off. Execute what you can to make progress. If you or any of the other assistants have the final answer or deliverable, prefix your response with FINAL ANSWER so the team knows to stop.\\nYou can only do research. You are working with a chart generator colleague.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e1003d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langgraph.graph import MessagesState,StateGraph, START,END\n",
    "from typing_extensions import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2528e31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_node(last_message:BaseMessage, goto:str):\n",
    "    if \"FINAL ANSWER\" in last_message.content:\n",
    "        # Any agent decided the work is done\n",
    "        return END\n",
    "    return goto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eaa635",
   "metadata": {},
   "source": [
    "result=[humanmesssage\n",
    "aimessgae\n",
    "toolmessage\n",
    "aimessage\n",
    "toolmessage\n",
    "aimessage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63b1c75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent1\n",
    "def research_node(state:MessagesState)->Command[Literal[\"chart_generator\", END]]:\n",
    "    research_agent=create_react_agent(\n",
    "        llm,\n",
    "        tools=[search_tool],\n",
    "        prompt=make_system_prompt(\n",
    "        \"You can only do research. You are working with a chart generator colleague.\"\n",
    "    ), \n",
    "        )\n",
    "    \n",
    "    \n",
    "    \n",
    "    result=research_agent.invoke(state)\n",
    "    \n",
    "    # result=[messages:{humanmesssage\n",
    "    #                 aimessgae\n",
    "    #                 toolmessage\n",
    "    #                 aimessage\n",
    "    #                 toolmessage\n",
    "    #                 aimessage}]\n",
    "    \n",
    "    goto=get_next_node(result[\"messages\"][-1],\"chart_generator\")\n",
    "    \n",
    "    result[\"messages\"][-1] = HumanMessage(content=result[\"messages\"][-1].content, name=\"researcher\")\n",
    "    \n",
    "    return Command(update={\"messages\": result[\"messages\"]},goto=goto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f9d7a98",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2825819459.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[40], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    agent1(human1)-->agent2(human2)\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "agent1(human1)-->agent2(human2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fde9130",
   "metadata": {},
   "source": [
    "AIMessage(content=\"Here are the UK GDP figures for the past three years:\\n\\n- **2021**: $3,141.51 billion\\n- **2022**: $3,088.84 billion\\n- **2023**: $3,340.03 billion\\n\\nLet's create a line chart with this data. I'll pass these figures to my colleague to make the chart.\", additional_kwargs={'tool_calls': [{'id': 'call_jFcUWkL9Zq54uWKBe5rMC9Yh', 'function': {'arguments': '{\"query\":\"UK GDP 2023 2022 2021 line chart\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 106, 'prompt_tokens': 9945, 'total_tokens': 10051, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 7936}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-Bl84FVwNUMyu4khQNXpftP508oUlR', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d068c020-31cb-463f-878a-9a83f88bf9d5-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'UK GDP 2023 2022 2021 line chart'}, 'id': 'call_jFcUWkL9Zq54uWKBe5rMC9Yh', 'type': 'tool_call'}], usage_metadata={'input_tokens': 9945, 'output_tokens': 106, 'total_tokens': 10051, 'input_token_details': {'audio': 0, 'cache_read': 7936}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f10f63d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent2\n",
    "def chart_node(state:MessagesState)-> Command[Literal[\"researcher\", END]]:\n",
    "    chart_agent=create_react_agent(\n",
    "        llm,\n",
    "        tools=[python_repl_tool],\n",
    "        prompt=make_system_prompt(\n",
    "        \"You can only generate charts. You are working with a researcher colleague.\"\n",
    "    ),\n",
    "        )\n",
    "    result=chart_agent.invoke(state)\n",
    "    goto=get_next_node(result[\"messages\"][-1],\"researcher\")\n",
    "    result[\"messages\"][-1] = HumanMessage(content=result[\"messages\"][-1].content, name=\"chart_generator\")\n",
    "    return Command(update={\"messages\": result[\"messages\"]},goto=goto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f2afdc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"researcher\", research_node)\n",
    "workflow.add_node(\"chart_generator\", chart_node)\n",
    "\n",
    "workflow.add_edge(START, \"researcher\")\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e118402e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x0000025A5AF729D0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ef0b13f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-97LQrOtNCzQ5z4PU3BOL6nJI on tokens per min (TPM): Limit 30000, Used 30000, Requested 156. Please try again in 312ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget the UK\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms GDP over the past 3 years, then make a line chart of it.Once you make the chart, finish.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2719\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2716\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2717\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 2719\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2720\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2723\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2724\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2725\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2728\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2729\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2730\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2731\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2732\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2733\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m:=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m   2734\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2436\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[0;32m   2434\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[0;32m   2435\u001b[0m             loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2436\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2437\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2438\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2439\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2440\u001b[0m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2441\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2442\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[0;32m   2443\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2444\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\langgraph\\pregel\\runner.py:161\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[0;32m    159\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 623\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    375\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 377\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[39], line 13\u001b[0m, in \u001b[0;36mresearch_node\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mresearch_node\u001b[39m(state:MessagesState)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39mCommand[Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchart_generator\u001b[39m\u001b[38;5;124m\"\u001b[39m, END]]:\n\u001b[0;32m      3\u001b[0m     research_agent\u001b[38;5;241m=\u001b[39mcreate_react_agent(\n\u001b[0;32m      4\u001b[0m         llm,\n\u001b[0;32m      5\u001b[0m         tools\u001b[38;5;241m=\u001b[39m[search_tool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     ), \n\u001b[0;32m      9\u001b[0m         )\n\u001b[1;32m---> 13\u001b[0m     result\u001b[38;5;241m=\u001b[39m\u001b[43mresearch_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# result=[messages:{humanmesssage\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m#                 aimessgae\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m#                 toolmessage\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m#                 aimessage\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m#                 toolmessage\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m#                 aimessage}]\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     goto\u001b[38;5;241m=\u001b[39mget_next_node(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchart_generator\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2719\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2716\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2717\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 2719\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2720\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2723\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2724\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2725\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2728\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2729\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2730\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2731\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2732\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2733\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m:=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m   2734\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2436\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[0;32m   2434\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[0;32m   2435\u001b[0m             loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2436\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2437\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2438\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2439\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2440\u001b[0m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2441\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2442\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[0;32m   2443\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2444\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\langgraph\\pregel\\runner.py:161\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[0;32m    159\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 623\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\langgraph\\utils\\runnable.py:370\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 370\u001b[0m         ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    372\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\langgraph\\prebuilt\\chat_agent_executor.py:505\u001b[0m, in \u001b[0;36mcreate_react_agent.<locals>.call_model\u001b[1;34m(state, config)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_model\u001b[39m(state: StateSchema, config: RunnableConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m StateSchema:\n\u001b[0;32m    504\u001b[0m     state \u001b[38;5;241m=\u001b[39m _get_model_input_state(state)\n\u001b[1;32m--> 505\u001b[0m     response \u001b[38;5;241m=\u001b[39m cast(AIMessage, \u001b[43mmodel_runnable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;66;03m# add agent name to the AIMessage\u001b[39;00m\n\u001b[0;32m    507\u001b[0m     response\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3047\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3045\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3046\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3047\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3048\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3049\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5430\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5423\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   5424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5425\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5428\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5429\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5431\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5432\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5433\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5434\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:372\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    368\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    369\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 372\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    382\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:957\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    950\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    955\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    956\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:776\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    774\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    775\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 776\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m         )\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1022\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1020\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1022\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1026\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:973\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 973\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:925\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    922\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    923\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    924\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    936\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    937\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\openai\\_base_client.py:1239\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1226\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1227\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1235\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1236\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1237\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[1;32m-> 1239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\openai\\_base_client.py:1034\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1031\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1033\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1034\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-97LQrOtNCzQ5z4PU3BOL6nJI on tokens per min (TPM): Limit 30000, Used 30000, Requested 156. Please try again in 312ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "\u001b[0mDuring task with name 'agent' and id '4b4f31fe-a8bf-8f39-ac9d-240666f3b16d'",
      "\u001b[0mDuring task with name 'researcher' and id 'dc4230ba-bf1d-4100-477b-57dc7ed28063'"
     ]
    }
   ],
   "source": [
    "app.invoke({\"messages\": [(\"user\",\"get the UK's GDP over the past 3 years, then make a line chart of it.Once you make the chart, finish.\")],})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dabf37",
   "metadata": {},
   "source": [
    "code=\"\"\"import matplotlib.pyplot as plt\\\\n\\\\n# Data for the UK GDP over the past 3 years\\\\nyears = [2019, 2020, 2021]\\\\ngdp_values = [2851.41, 2697.81, 3141.51]  # in billion $ \\\\n\\\\ndef create_line_chart(years, gdp_values):\\\\n    plt.figure(figsize=(10, 6))\\\\n    plt.plot(years, gdp_values, marker=\\'o\\', color=\\'b\\', linestyle=\\'-\\', linewidth=2)\\\\n    plt.title(\\'UK GDP Over the Past 3 Years\\')\\\\n    plt.xlabel(\\'Year\\')\\\\n    plt.ylabel(\\'GDP (in billion $)\\')\\\\n    plt.grid(True)\\\\n    plt.tight_layout()\\\\n    plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "39ff963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "code=\"\"\"import matplotlib.pyplot as plt\\\\n\\\\n# Data for the UK GDP over the past 3 years\\\\nyears = [2019, 2020, 2021]\\\\ngdp_values = [2851.41, 2697.81, 3141.51]  # in billion $ \\\\n\\\\ndef create_line_chart(years, gdp_values):\\\\n    plt.figure(figsize=(10, 6))\\\\n    plt.plot(years, gdp_values, marker=\\'o\\', color=\\'b\\', linestyle=\\'-\\', linewidth=2)\\\\n    plt.title(\\'UK GDP Over the Past 3 Years\\')\\\\n    plt.xlabel(\\'Year\\')\\\\n    plt.ylabel(\\'GDP (in billion $)\\')\\\\n    plt.grid(True)\\\\n    plt.tight_layout()\\\\n    plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "808a2b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import matplotlib.pyplot as plt\\n\\n# Data for the UK GDP over the past 3 years\\nyears = [2019, 2020, 2021]\\ngdp_values = [2851.41, 2697.81, 3141.51]  # in billion $ \\n\\ndef create_line_chart(years, gdp_values):\\n    plt.figure(figsize=(10, 6))\\n    plt.plot(years, gdp_values, marker='o', color='b', linestyle='-', linewidth=2)\\n    plt.title('UK GDP Over the Past 3 Years')\\n    plt.xlabel('Year')\\n    plt.ylabel('GDP (in billion $)')\\n    plt.grid(True)\\n    plt.tight_layout()\\n    plt.show()\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"import matplotlib.pyplot as plt\\\\n\\\\n# Data for the UK GDP over the past 3 years\\\\nyears = [2019, 2020, 2021]\\\\ngdp_values = [2851.41, 2697.81, 3141.51]  # in billion $ \\\\n\\\\ndef create_line_chart(years, gdp_values):\\\\n    plt.figure(figsize=(10, 6))\\\\n    plt.plot(years, gdp_values, marker=\\'o\\', color=\\'b\\', linestyle=\\'-\\', linewidth=2)\\\\n    plt.title(\\'UK GDP Over the Past 3 Years\\')\\\\n    plt.xlabel(\\'Year\\')\\\\n    plt.ylabel(\\'GDP (in billion $)\\')\\\\n    plt.grid(True)\\\\n    plt.tight_layout()\\\\n    plt.show()\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86f7531",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver_tool=documents\n",
    "\n",
    "def fun(document):\n",
    "    calcualtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea274452",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_bind_tool=llm.bind_tools(fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fa2b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_bind_tool.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b61ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_calls\n",
    "\n",
    "{\n",
    "    tool_name(function name)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3176b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict={\n",
    "   funcation_name: fun\n",
    "   function_name2: fun2\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69130ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "func=dict[tool_calls.tool_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967e6cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "func(docu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_2_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
