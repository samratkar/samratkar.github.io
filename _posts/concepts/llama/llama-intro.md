# What is llama 

1. **open source** - Llama is an open source LLM. 
2. **transparent** - It is transparent. We can see exactly how the model is built. We can find its shortcomings and where it can outperform others. 
3. **customize** - We can customize it. We can make smaller models, or do fine tuning. 
4. **accuracy** - We can have more accurate model with smaller size. 
5. **smaller** - it is smaller than most of the propreitary models.
6. **use case** - you can fine tune the model for your own use cases, specific to you

## History of Llama 

1. **V1 - 7B - 69B - Feb 23** 
2. **V2 - 7B - 70B - Jul 23** - much higher performance with same size.
3. **Code llama - Aug 23** 
4. **V3 - 7B - 70B - Apr 24** - much higher performance with the same size.
5. **V3.1 - 405B Jul 24** - 
   1. Multi-lingual support
   2. Context window - amount of data that is output of the model relative to the number of tokens. i.e. more data can be passed as context, and need not to be passed as an prompt query. Llama can produce more text at a single run of the model. 
   3. llama guard - impacts and implements security. prompt injection attacks are prevented.
   4. Performance - 405 B parameters. 
6. **V3.2 Sep 24** 

## Usecases 

1. **Data generation** - Your own data cna be created synthetically from llama. 
2. **Knowledge distillation** -  You can distill knowledge from llama.