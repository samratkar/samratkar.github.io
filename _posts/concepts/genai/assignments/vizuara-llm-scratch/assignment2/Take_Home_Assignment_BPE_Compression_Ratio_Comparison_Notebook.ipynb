{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjqkeMLhdGIo"
      },
      "source": [
        "# BPE and Tokenization assignment\n",
        "\n",
        "This notebook demonstrates:\n",
        "- Applying BPE on text in English, French, Spanish, and German.\n",
        "- Computing compression ratios for each language using BPE.\n",
        "- Computing compression ratios using the GPT tiktoken library and comparing\n",
        "- Computing the effect of vocabulary size on compression ratio for English, French, Spanish and German.\n",
        "- Analyzing the effect of file size on the compression ratio for English text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Make use of LLMs like ChatGPT and Claude to help you with code!\n",
        "\n",
        "You can give a good, detailed prompt and get code for plotting, varying file sizes etc.\n",
        "\n",
        "Make sure to use the codes we discussed in class also.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "bSJ1cTJ2r9yi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 1: Install necessary packages\n",
        "You might need tiktoken and matplotlib\n"
      ],
      "metadata": {
        "id": "XnMp6cohBaMW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 2: Write BPE code which takes a text file, performs BPE and finds compression ratio.\n",
        "\n",
        "- You can use the code we discussed in class.\n",
        "\n",
        "- The dataset files for all languages (English, French, German and Spanish) have been provided to you.\n",
        "\n",
        "- Note that you can consider the final vocabulary size you can consider = Original vocabulary size  + 200 extra tokens."
      ],
      "metadata": {
        "id": "O4UxJ7kCBiVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your code here. Feel free to use ChatGPT, Claude for help."
      ],
      "metadata": {
        "id": "otfswLMSB3Yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 3: Make bar plot of compression ratio for the 4 languages: English, French, German and Spanish."
      ],
      "metadata": {
        "id": "wKOit0m2B4oA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your code here. Feel free to use ChatGPT, Claude for help."
      ],
      "metadata": {
        "id": "o2320hCbCCO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 4: Use tiktoken library and use tokenization schemes for GPT-2, GPT-3.5 and GPT-4. Find compression ratio for all 4 languages.\n",
        "\n",
        "- You can use the tiktoken code we have seen in class."
      ],
      "metadata": {
        "id": "thB-VtS-CIKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your code here. Feel free to use ChatGPT, Claude for help."
      ],
      "metadata": {
        "id": "AP0955wSCYQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Make bar plots to compare compression ratios for BPE, GPT-2, GPT-3.5 and GPT-4 for all 4 languages"
      ],
      "metadata": {
        "id": "FXBCFHW-CZl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your code here. Feel free to use ChatGPT, Claude for help."
      ],
      "metadata": {
        "id": "MgozcExlCi3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Vary the extra tokens from 200 to 500 to 800. Write code to find effect of extra tokens on the compression ratio. Do this for all languages\n",
        "\n",
        "Hint: You already have written the BPE code for extra tokens = 200 in Step 2. Use this as reference."
      ],
      "metadata": {
        "id": "UV3xafCTCkz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your code here. Feel free to use ChatGPT, Claude for help."
      ],
      "metadata": {
        "id": "Tg8lwjx1CwsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Write code for varying input file size and see effect on compression ratio (only for English language).\n",
        "\n",
        "- Create text files with decreasing sizes using the scaling factors: 10, 8, 6.\n",
        "\n",
        "- Note that the final vocabulary size you can consider = Original vocabulary size + 5% of the total text size.\n",
        "\n",
        "Hint: Here is how you can use scaling factor of let's say 10.\n",
        "\n",
        "\n",
        "```\n",
        "fraction = 1 / 10\n",
        "\n",
        "subtext = input_text[:int(len_text * fraction)]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "YlC_VPADCyRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your code here. Feel free to use ChatGPT, Claude for help."
      ],
      "metadata": {
        "id": "TGzO0gw6C6Yu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}