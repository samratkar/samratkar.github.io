{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective : \n",
    "Translate English sentence - \"I go\" to Hindi sentence - \"मैं जाता हूँ\" using Recurrent neural network\n",
    "\n",
    "## Encoding :\n",
    "### Step 1 : Embedding inputs \n",
    "Convert the input tokens into embeddings. \n",
    "Let x(\"I\") = x1 = 1\n",
    "Let x(\"go\") = x2 = 2\n",
    "\n",
    "### Step 2 : Decide number of hidden layers & states in the hidden layer. \n",
    "Decide number of hidden layers in the neural network and number of states in each layer. \n",
    "Let hidden state size = s = 2. Number of layers of the neural network = n = 1\n",
    "\n",
    "### Step 3 : Initialize the 1st hidden state of the encoder\n",
    "Initialize the 1st hidden state $h_0$ based on the hidden size s. It will be a matrix of dimensions s x n = 2x1. Number of rows = Number of hidden states in the layer. Number of columns = Number of layers in the neural network. **The matrix is like a neural network standing erect.**\n",
    "$$\n",
    "h_0 = \\begin{bmatrix}\n",
    "0 \\\\\n",
    "0 \n",
    "\\end{bmatrix}_{2*1}\n",
    "$$\n",
    "\n",
    "### Step 4 : Mathematical relation between the hidden state \n",
    "Mathematical relation between the hidden state - \\\n",
    "$$h_t = \\tanh(Wh_{t-1} + Ux_t + b)$$ \\\n",
    "where $\\tanh()$ is the activation function, W is the weight matrix for the hidden state, U is the weight matrix for the input, b is the bias\n",
    "\n",
    "### Step 5 : Initialize the weights and biases of the neural network randomly\n",
    "\n",
    "$$\n",
    "W = \\begin{bmatrix}\n",
    "0.3 & -0.1 \\\\\n",
    "0 & 0.2\n",
    "\\end{bmatrix}_{2*2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "U = \\begin{bmatrix}\n",
    "0.5 \\\\\n",
    "0.7\n",
    "\\end{bmatrix}_{2*1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b = \\begin{bmatrix}\n",
    "0 \\\\\n",
    "0\n",
    "\\end{bmatrix}_{2*1}\n",
    "$$\n",
    "\n",
    "#### Code for Step 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Initialization of the weight and biases for the neural network\n",
    "W = np.array([[0.30, -0.10], [0, 0.20]])\n",
    "h0 = np.array([[0.0], [0.0]])\n",
    "U = np.array([[0.50], [0.70]])\n",
    "b = np.array([[0.0], [0.0]])\n",
    "x1 = 1\n",
    "x2 = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 : Calculate the hidden states $h_1$ and $h2$ using the formula in step 4\n",
    "\n",
    "$h_1 = \\tanh(Wh_0 + Ux1 + b)$  \n",
    "\n",
    "$\n",
    "    h_1 = \\begin{bmatrix}\n",
    "    0.5 \\\\\n",
    "    0.7\n",
    "    \\end{bmatrix}\n",
    "$\n",
    "\n",
    "$h_2 = \\tanh(Wh_1 + Ux2 + b)$  \n",
    "\n",
    "$\n",
    "    h_2 = \\begin{bmatrix}\n",
    "    1.08 \\\\\n",
    "    1.54\n",
    "    \\end{bmatrix}\n",
    "$\n",
    "\n",
    "#### Code for Step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1:\n",
      " [[0.5]\n",
      " [0.7]]\n",
      "h2:\n",
      " [[1.08]\n",
      " [1.54]]\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "h1 = np.matmul(W, h0) + U * x1 + b\n",
    "h2 = np.matmul(W, h1) + U * x2 + b\n",
    "\n",
    "print(\"h1:\\n\", h1)\n",
    "print(\"h2:\\n\", h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding\n",
    "### Step 1 : Create embeddings of the Hindi words.\n",
    "\n",
    "- Let y(Go) = y1 = 0.5, \n",
    "- y(\"मैं\") = y2 = 1, \n",
    "- y(\"जाता\") = y3 = 1.1, \n",
    "- y(\"हूँ\") = y4 = 0.9, \n",
    "- y(EOS) = y5 = 0.0\n",
    "\n",
    "### Step 2 : Decide number of hidden layers & state\n",
    "\n",
    "It remains same as that of the encoder. \n",
    "\n",
    "### Step 3 : Initialize the 1st hidden state\n",
    "\n",
    "The first output layer will be a copy of the last hidden state of the encoder. \n",
    "$$s_0 = h_2 = \\begin{bmatrix} 1.08 \\\\ 1.54 \\end{bmatrix}$$\n",
    "\n",
    "### Step 4 : Mathematical relation between the hidden state \n",
    "\n",
    "Mathematical relation between the hidden state - \\\n",
    "$$s_t = \\tanh(W_{dec} s_{t-1} + Vy_t + c)$$ \\\n",
    "where $\\tanh()$ is the activation function, W' is the weight matrix for the hidden state, V is the weight matrix for the output y, c is the bias\n",
    "\n",
    "### Step 5 : Initialize the weights and biases of the neural network randomly\n",
    "\n",
    "$$W_{dec} = \\begin{bmatrix} 0.2 & 0.1 \\\\ 0.3 & 0.4 \\end{bmatrix}_{2*2}$$\n",
    "$$V = \\begin{bmatrix} 0.1 \\\\ 0.2 \\end{bmatrix}_{2*1}$$\n",
    "$$d = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}_{2*1}$$\n",
    "\n",
    "#### Code for Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of the weight and biases for the neural network\n",
    "W_dec = np.array([[0.20, 0.10], [0.3, 0.40]])\n",
    "s0 = h2 \n",
    "V = np.array([[0.10], [0.20]])\n",
    "b = np.array([[0.0], [0.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 : Calculate the hidden states $s_1$ and $s2$  using the formula in step 4\n",
    "\n",
    "$h_1 = \\tanh(Wh_0 + Ux1 + b)$  \n",
    "\n",
    "$\n",
    "    h_1 = \\begin{bmatrix}\n",
    "    0.5 \\\\\n",
    "    0.7\n",
    "    \\end{bmatrix}\n",
    "$\n",
    "\n",
    "$h_2 = \\tanh(Wh_1 + Ux2 + b)$  \n",
    "\n",
    "$\n",
    "    h_2 = \\begin{bmatrix}\n",
    "    1.08 \\\\\n",
    "    1.54\n",
    "    \\end{bmatrix}\n",
    "$\n",
    "\n",
    "#### Code for Step 6\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Few observations \n",
    "\n",
    "1. The hidden state at time t is a function of the hidden state at time t-1, the input at time t and the bias term.\n",
    "2. W and U are the weight matrices or parameters. That are trained using the training set. In the beginning, they are randomly initialized. And then they are trained, using the corpus so that the loss is minimized.\n",
    "3. b is the bias term. It is also randomly initialized and then trained.\n",
    "4. $x_t$ is the input at time t. It is the embedding of the token at time t.\n",
    "5. $h_t$ is the hidden state at time t. It is the memory of the network at time t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
