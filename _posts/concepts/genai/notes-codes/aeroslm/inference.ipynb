{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "502d2df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\github\\\\samratkar.github.io\\\\_posts\\\\concepts\\\\genai\\\\notes-codes\\\\aeroslm'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4643e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(50257, 384)\n",
       "    (wpe): Embedding(128, 384)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x Block(\n",
       "        (ln1): LayerNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (c_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln2): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=384, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import aeroslm\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "pt_path = hf_hub_download(\n",
    "    repo_id=\"samratkar/slm_tinystories\",\n",
    "    filename=\"slm_tinystories.pt\",\n",
    ")\n",
    "# Load the model\n",
    "model = aeroslm.GPT()\n",
    "state_dict = torch.load(pt_path, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()  # Set to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "490b2a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Once upon a time there was a pumpkin. Inside the field, there was a family. One day, they decided to wear baby, who was walking in the park.\\n\\nWhen they decided to go to the beach, it was cold and cold. They buckled hands and stirred the water and started to jump into the water.\\n\\nWhen they got home, they saw a big fountain in the sink. Jim wanted to get back but he couldn't wait. Then, the dragon swam back inside, when he stopped. When he got there, he saw something exciting. It was a busy man with a white nose. The man lay down on the more and hear them crawl from Tim's pocket.Ben and his mom were in a long city. Ben liked the fields and beautiful animals. They watched them go deep and usually got very slowacked.\\n\\nOne day, they decided to go to a school. Ben went to the jungle with his mom. He saw many kids playing a game of rocks. Ben thinks they are\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer(\"Once upon a time there was a pumpkin.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af2b93a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\nModule 'CausalSelfAttention' has no attribute 'bias' :\n  File \"c:\\github\\samratkar.github.io\\_posts\\concepts\\genai\\notes-codes\\aeroslm\\aeroslm.py\", line 46\n        else:\n            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n            att = att.masked_fill(self.bias[:, :, :T, :T] == 0, float('-inf'))\n                                  ~~~~~~~~~ <--- HERE\n            att = F.softmax(att, dim=-1)\n            att = self.attn_dropout(att)\n'CausalSelfAttention.forward' is being compiled since it was called from 'Block.forward'\n  File \"c:\\github\\samratkar.github.io\\_posts\\concepts\\genai\\notes-codes\\aeroslm\\aeroslm.py\", line 73\n    def forward(self, x):\n        x = x + self.attn(self.ln1(x))\n                                   ~ <--- HERE\n        x = x + self.mlp(self.ln2(x))\n        return x\n'Block.forward' is being compiled since it was called from 'GPT.forward'\n  File \"c:\\github\\samratkar.github.io\\_posts\\concepts\\genai\\notes-codes\\aeroslm\\aeroslm.py\", line 140\n        x = self.transformer.drop(tok_emb + pos_emb)\n        for block in self.transformer.h:\n            x = block(x)\n                      ~ <--- HERE\n        x = self.transformer.ln_f(x)\n    \n'GPT.forward' is being compiled since it was called from 'GPT.generate'\n  File \"c:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 169\n        for _ in range(max_new_tokens):\n            idx_cond = idx if idx.size(1) <= self.block_size else idx[:, -self.block_size:]\n            logits = self(idx_cond)\n                          ~~~~~~~~ <--- HERE\n            logits = logits[:, -1, :] / temperature\n            if top_k is not None:\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m aeroslm\u001b[38;5;241m.\u001b[39mGPT()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Trace the model's forward pass\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m traced_model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m traced_model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslm_tinystories_scripted.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\torch\\jit\\_trace.py:1002\u001b[0m, in \u001b[0;36mtrace\u001b[1;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[0;32m    989\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`optimize` is deprecated and has no effect. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `with torch.jit.optimized_execution()` instead\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    993\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    994\u001b[0m     )\n\u001b[0;32m    996\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    997\u001b[0m     check_if_torch_exportable,\n\u001b[0;32m    998\u001b[0m     log_torch_jit_trace_exportability,\n\u001b[0;32m    999\u001b[0m     log_torchscript_usage,\n\u001b[0;32m   1000\u001b[0m )\n\u001b[1;32m-> 1002\u001b[0m traced_func \u001b[38;5;241m=\u001b[39m \u001b[43m_trace_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_compilation_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_kwarg_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m log_torchscript_usage(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrace\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_id\u001b[38;5;241m=\u001b[39m_get_model_id(traced_func))\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_if_torch_exportable():\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\torch\\jit\\_trace.py:696\u001b[0m, in \u001b[0;36m_trace_impl\u001b[1;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    695\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_kwarg_inputs should be a dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 696\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrap_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_inputs_is_kwarg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexample_kwarg_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    710\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    713\u001b[0m ):\n\u001b[0;32m    714\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m example_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\torch\\jit\\_trace.py:1244\u001b[0m, in \u001b[0;36mtrace_module\u001b[1;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_inputs_is_kwarg, _store_inputs)\u001b[0m\n\u001b[0;32m   1241\u001b[0m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_trace\u001b[38;5;241m.\u001b[39m_trace_module_map \u001b[38;5;241m=\u001b[39m trace_module_map\n\u001b[0;32m   1242\u001b[0m register_submods(mod, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__module\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1244\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mmake_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_compilation_unit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method_name, example_inputs \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1248\u001b[0m         \u001b[38;5;66;03m# \"forward\" is a special case because we need to trace\u001b[39;00m\n\u001b[0;32m   1249\u001b[0m         \u001b[38;5;66;03m# `Module.__call__`, which sets up some extra tracing, but uses\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m         \u001b[38;5;66;03m# argument names of the real `Module.forward` method.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\torch\\jit\\_trace.py:623\u001b[0m, in \u001b[0;36mmake_module\u001b[1;34m(mod, _module_class, _compilation_unit)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_jit_internal\u001b[38;5;241m.\u001b[39mmodule_has_exports(mod):\n\u001b[0;32m    622\u001b[0m     infer_methods_stubs_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_recursive\u001b[38;5;241m.\u001b[39mmake_stubs_from_exported_methods\n\u001b[1;32m--> 623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_script_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfer_methods_stubs_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshare_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_tracing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _module_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\torch\\jit\\_recursive.py:556\u001b[0m, in \u001b[0;36mcreate_script_module\u001b[1;34m(nn_module, stubs_fn, share_types, is_tracing)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tracing:\n\u001b[0;32m    555\u001b[0m     AttributeTypeIsSupportedChecker()\u001b[38;5;241m.\u001b[39mcheck(nn_module)\n\u001b[1;32m--> 556\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_script_module_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstubs_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\torch\\jit\\_recursive.py:629\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[1;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;66;03m# Compile methods if necessary\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concrete_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m concrete_type_store\u001b[38;5;241m.\u001b[39mmethods_compiled:\n\u001b[1;32m--> 629\u001b[0m     \u001b[43mcreate_methods_and_properties_from_stubs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconcrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_stubs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperty_stubs\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;66;03m# Create hooks after methods to ensure no name collisions between hooks and methods.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;66;03m# If done before, hooks can overshadow methods that aren't exported.\u001b[39;00m\n\u001b[0;32m    634\u001b[0m     create_hooks_from_stubs(concrete_type, hook_stubs, pre_hook_stubs)\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\torch\\jit\\_recursive.py:465\u001b[0m, in \u001b[0;36mcreate_methods_and_properties_from_stubs\u001b[1;34m(concrete_type, method_stubs, property_stubs)\u001b[0m\n\u001b[0;32m    462\u001b[0m property_defs \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mdef_ \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m property_stubs]\n\u001b[0;32m    463\u001b[0m property_rcbs \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mresolution_callback \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m property_stubs]\n\u001b[1;32m--> 465\u001b[0m \u001b[43mconcrete_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_methods_and_properties\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproperty_defs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperty_rcbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_defs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_rcbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_defaults\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\torch\\jit\\_recursive.py:1026\u001b[0m, in \u001b[0;36mcompile_unbound_method\u001b[1;34m(concrete_type, fn)\u001b[0m\n\u001b[0;32m   1022\u001b[0m stub \u001b[38;5;241m=\u001b[39m make_stub(fn, fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_jit_internal\u001b[38;5;241m.\u001b[39m_disable_emit_hooks():\n\u001b[0;32m   1024\u001b[0m     \u001b[38;5;66;03m# We don't want to call the hooks here since the graph that is calling\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m     \u001b[38;5;66;03m# this function is not yet complete\u001b[39;00m\n\u001b[1;32m-> 1026\u001b[0m     \u001b[43mcreate_methods_and_properties_from_stubs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mstub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stub\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\torch\\jit\\_recursive.py:465\u001b[0m, in \u001b[0;36mcreate_methods_and_properties_from_stubs\u001b[1;34m(concrete_type, method_stubs, property_stubs)\u001b[0m\n\u001b[0;32m    462\u001b[0m property_defs \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mdef_ \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m property_stubs]\n\u001b[0;32m    463\u001b[0m property_rcbs \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mresolution_callback \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m property_stubs]\n\u001b[1;32m--> 465\u001b[0m \u001b[43mconcrete_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_methods_and_properties\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproperty_defs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperty_rcbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_defs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_rcbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_defaults\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\torch\\jit\\_recursive.py:1026\u001b[0m, in \u001b[0;36mcompile_unbound_method\u001b[1;34m(concrete_type, fn)\u001b[0m\n\u001b[0;32m   1022\u001b[0m stub \u001b[38;5;241m=\u001b[39m make_stub(fn, fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_jit_internal\u001b[38;5;241m.\u001b[39m_disable_emit_hooks():\n\u001b[0;32m   1024\u001b[0m     \u001b[38;5;66;03m# We don't want to call the hooks here since the graph that is calling\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m     \u001b[38;5;66;03m# this function is not yet complete\u001b[39;00m\n\u001b[1;32m-> 1026\u001b[0m     \u001b[43mcreate_methods_and_properties_from_stubs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mstub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stub\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\torch\\jit\\_recursive.py:465\u001b[0m, in \u001b[0;36mcreate_methods_and_properties_from_stubs\u001b[1;34m(concrete_type, method_stubs, property_stubs)\u001b[0m\n\u001b[0;32m    462\u001b[0m property_defs \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mdef_ \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m property_stubs]\n\u001b[0;32m    463\u001b[0m property_rcbs \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mresolution_callback \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m property_stubs]\n\u001b[1;32m--> 465\u001b[0m \u001b[43mconcrete_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_methods_and_properties\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproperty_defs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperty_rcbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_defs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_rcbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_defaults\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\torch\\jit\\_recursive.py:1026\u001b[0m, in \u001b[0;36mcompile_unbound_method\u001b[1;34m(concrete_type, fn)\u001b[0m\n\u001b[0;32m   1022\u001b[0m stub \u001b[38;5;241m=\u001b[39m make_stub(fn, fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_jit_internal\u001b[38;5;241m.\u001b[39m_disable_emit_hooks():\n\u001b[0;32m   1024\u001b[0m     \u001b[38;5;66;03m# We don't want to call the hooks here since the graph that is calling\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m     \u001b[38;5;66;03m# this function is not yet complete\u001b[39;00m\n\u001b[1;32m-> 1026\u001b[0m     \u001b[43mcreate_methods_and_properties_from_stubs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mstub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stub\n",
      "File \u001b[1;32mc:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\torch\\jit\\_recursive.py:465\u001b[0m, in \u001b[0;36mcreate_methods_and_properties_from_stubs\u001b[1;34m(concrete_type, method_stubs, property_stubs)\u001b[0m\n\u001b[0;32m    462\u001b[0m property_defs \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mdef_ \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m property_stubs]\n\u001b[0;32m    463\u001b[0m property_rcbs \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mresolution_callback \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m property_stubs]\n\u001b[1;32m--> 465\u001b[0m \u001b[43mconcrete_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_methods_and_properties\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproperty_defs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperty_rcbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_defs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_rcbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_defaults\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \nModule 'CausalSelfAttention' has no attribute 'bias' :\n  File \"c:\\github\\samratkar.github.io\\_posts\\concepts\\genai\\notes-codes\\aeroslm\\aeroslm.py\", line 46\n        else:\n            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n            att = att.masked_fill(self.bias[:, :, :T, :T] == 0, float('-inf'))\n                                  ~~~~~~~~~ <--- HERE\n            att = F.softmax(att, dim=-1)\n            att = self.attn_dropout(att)\n'CausalSelfAttention.forward' is being compiled since it was called from 'Block.forward'\n  File \"c:\\github\\samratkar.github.io\\_posts\\concepts\\genai\\notes-codes\\aeroslm\\aeroslm.py\", line 73\n    def forward(self, x):\n        x = x + self.attn(self.ln1(x))\n                                   ~ <--- HERE\n        x = x + self.mlp(self.ln2(x))\n        return x\n'Block.forward' is being compiled since it was called from 'GPT.forward'\n  File \"c:\\github\\samratkar.github.io\\_posts\\concepts\\genai\\notes-codes\\aeroslm\\aeroslm.py\", line 140\n        x = self.transformer.drop(tok_emb + pos_emb)\n        for block in self.transformer.h:\n            x = block(x)\n                      ~ <--- HERE\n        x = self.transformer.ln_f(x)\n    \n'GPT.forward' is being compiled since it was called from 'GPT.generate'\n  File \"c:\\Users\\samra\\anaconda3\\envs\\agentic_2_base\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 169\n        for _ in range(max_new_tokens):\n            idx_cond = idx if idx.size(1) <= self.block_size else idx[:, -self.block_size:]\n            logits = self(idx_cond)\n                          ~~~~~~~~ <--- HERE\n            logits = logits[:, -1, :] / temperature\n            if top_k is not None:\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "import aeroslm\n",
    "\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "context = torch.tensor(enc.encode_ordinary(\"There was an ai agent\")).unsqueeze(dim=0)\n",
    "model = aeroslm.GPT()\n",
    "# Trace the model's forward pass\n",
    "traced_model = torch.jit.trace(model, context)\n",
    "traced_model.save(\"slm_tinystories_scripted.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_2_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
