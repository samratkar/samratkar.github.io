---
layout : mermaid
type : concept
title : "GAN - Generative Adversarial Networks"
---
## Introduction
Generative Adversarial Networks (GANs) are a class of machine learning frameworks designed for unsupervised learning. They consist of two neural networks, the **generator** and the **discriminator**, which are trained simultaneously through **adversarial processes**. The generator creates fake data, while the discriminator evaluates the authenticity of the data, leading to improved performance in generating realistic samples.
[GAN generated images](https://thispersondoesnotexist.com/)

The real innovation is in the **generator** which is a neural network that takes random noise as inputs and generates data that resembles the training data. The generator is trained to produce data that is indistinguishable from real data, while the discriminator is trained to differentiate between real and fake data.

This idea was proposed by Ian Goodfellow and his colleagues in 2014. The GAN framework has since gained popularity due to its ability to generate high-quality images, videos, and other types of data.

## Architecture
<div class="mermaid">
graph TD
    A(2.Generator NN) -->|2.Fake Image| B(1.Discriminator / Adversary NN)
    B -->|Real or Fake| C(Loss Function)
    C -->|Feedback| A
    C -->|Feedback| B
    D(Real Image) -->|Trains| B
</div>

![](/images/genai/gan-arch-steps.svg)

## Design and workflow 
### Overall GAN design
![](/images/genai/gan-sys.svg)
### Discriminator 
![](/images/genai/gan-flowchart.svg)

### Generator
![](/images/genai/generator.svg)

### Training the Discriminator 
Randomly initialize the weights of both the generator and discriminator networks.

#### Step 1 : Load sample real image from the training set.
Loading the CIFAR-10 dataset, which contains 60,000 32x32 color images in 10 classes, with 6,000 images per class. The dataset is divided into 50,000 training images and 10,000 test images. The CIFAR-10 dataset is commonly used for training machine learning models and is a standard benchmark in the field of computer vision.

```python
# example of loading and plotting the cifar10 dataset
from keras.datasets.cifar10 import load_data
from matplotlib import pyplot
# load the images into memory
(trainX, trainy), (testX, testy) = load_data()
# plot images from the training dataset
for i in range(49):
	# define subplot
	pyplot.subplot(7, 7, 1 + i)
	# turn off axis
	pyplot.axis('off')
	# plot raw pixel data
	pyplot.imshow(trainX[i])
pyplot.show()

```
![](/images/genai/cifar-plot.png)

```python
print (trainX.shape)
Output >>
(50000, 32, 32, 3)
```
#### Step 2 : Wiring a new CNN for Discriminator
```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, LeakyReLU
from tensorflow.keras.utils import plot_model
import numpy as np

# Define the discriminator model
def define_discriminator(in_shape=(32,32,3)):
    model = Sequential()

    # First convolutional block
    model.add(Conv2D(64, (3,3), padding='same', input_shape=in_shape))
    model.add(LeakyReLU(alpha=0.2))

    # Second convolutional block (downsample)
    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))
    model.add(LeakyReLU(alpha=0.2))

    # Third convolutional block (downsample)
    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))
    model.add(LeakyReLU(alpha=0.2))

    # Fourth convolutional block (downsample)
    model.add(Conv2D(256, (3,3), strides=(2,2), padding='same'))
    model.add(LeakyReLU(alpha=0.2))

    # Classifier block
    model.add(Flatten())
    model.add(Dropout(0.4))
    model.add(Dense(1, activation='sigmoid'))

    # Compile the model using the correct parameter: learning_rate
    opt = Adam(learning_rate=0.0002, beta_1=0.5)
    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])

    return model
```
#### Step 3 : instantiate a discriminator model
```python
# Create the discriminator
model = define_discriminator()

# Display model summary
model.summary()
```
![](./images/genai/discriminator-cnn-model-summary.png)

#### Step 4 : Load and prepare cifar training set for real images
##### Step 4.1 : normalize the data from [0,255] to [-1,1]
```python
# load and prepare cifar10 training images
def load_real_samples():
	# load cifar10 dataset
	(trainX, _), (_, _) = load_data()
	# convert from unsigned ints to floats
	X = trainX.astype('float32')
	# scale from [0,255] to [-1,1]
	X = (X - 127.5) / 127.5
	return X
```
```python
Xcheck = load_real_samples()
print(Xcheck.shape)

Output >>
(50000,32,32,3)
```
##### Step 4.2 : load the training data set for real images, for both x and y, for 64 images.
```python
from numpy.random import randint
from numpy import ones

# select real samples (we select 64 real images from the dataset)
def generate_real_samples(dataset, n_samples):
    # choose random instances
    ix = randint(0, dataset.shape[0], n_samples)
    # retrieve selected images
    X = dataset[ix]
    # generate 'real' class labels (1)
    y = ones((n_samples, 1))
    return X, y

Xcheck,ycheck = generate_real_samples(Xcheck, 64)
print(Xcheck.shape)
print(ycheck.shape)

Output >>
(64, 32, 32, 3)
(64, 1)
```
#### Step 5 : Generate the fake training data (without generator)

```python
from numpy.random import rand
from numpy import zeros

# generate n fake samples with class labels
def generate_fake_samples(n_samples):
    # generate uniform random numbers in [0,1]
    X = rand(32 * 32 * 3 * n_samples)
    # update to have the range [-1, 1]
    X = -1 + X * 2
    # reshape into a batch of color images
    X = X.reshape((n_samples, 32, 32, 3))
    # generate 'fake' class labels (0)
    y = zeros((n_samples, 1))
    return X, y

Xcheck,ycheck = generate_fake_samples(64)
print(Xcheck.shape)
print(ycheck.shape)

Output >>
(64, 32, 32, 3)
(64, 1)
```

```python
pyplot.imshow(Xcheck[10])
```
![](/images/genai/noise.png)

#### Step 6 : Train the Discriminator with real images and random noise generated above.
```python
# train the discriminator model
def train_discriminator(model, dataset, n_iter=100, n_batch=128):
	half_batch = int(n_batch / 2)
 #128/2 = 64
	# manually enumerate epochs
	for i in range(n_iter):
		# get randomly selected 'real' samples
		X_real, y_real = generate_real_samples(dataset, half_batch)
		# update discriminator on real samples
		_, real_acc = model.train_on_batch(X_real, y_real)
		# generate 'fake' examples
		X_fake, y_fake = generate_fake_samples(half_batch)
		# update discriminator on fake samples
		_, fake_acc = model.train_on_batch(X_fake, y_fake)
		# summarize performance
		print('>%d real=%.0f%% fake=%.0f%%' % (i+1, real_acc*100, fake_acc*100))
#Example Training

# define the discriminator model
model = define_discriminator()
# load image data
dataset = load_real_samples()
# fit the model
train_discriminator(model, dataset)
```

### Configuring the Generator
#### Step 1 : Define the hyper parameters
1. The dimension of random noise vector from Gaussian distribution. Defined that as 100 in this case.
2. The number of images to be generated in each batch. Defined that as 64 in this case.
3. Each image is 32x32 pixels and has 3 channels (RGB).

#### Step 2 : Define the generator model
##### Build the Generator model.
1. Build a Convolutional 2D Transpose model with the following layers, to define the generator model:
```python
def define_generator(latent_dim):
	model = Sequential()
	# foundation for 4x4 image

  ## We first convert the 100 input nodes to 256 images of size 4*4.
  ## Why 256: Because each image can capture different features of input data.
  ## Why specifically 4*4 and 256: it's an experimental choice.

	n_nodes = 256 * 4 * 4
	model.add(Dense(n_nodes, input_dim=latent_dim))
	model.add(LeakyReLU(alpha=0.2))
	model.add(Reshape((4, 4, 256)))

	# upsample to 8x8. Conv2D is used for upsampling.
	model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))
	model.add(LeakyReLU(alpha=0.2))
	# upsample to 16x16
	model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))
	model.add(LeakyReLU(alpha=0.2))
	# upsample to 32x32
	model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))
	model.add(LeakyReLU(alpha=0.2))
	# output layer
	model.add(Conv2D(3, (3,3), activation='tanh', padding='same'))
	return model
```
2. In the model the convolutional 2D transpose is used to upsample the image. The generator model takes a random noise vector as input and generates a 32x32 RGB image as output.
3. In the intermediate step, following upsampling is done
    - 4x4 -> 8x8
    - 8x8 -> 16x16
    - 16x16 -> 32x32

#### Step 3 : Generate the random noise based on the latent dimension defined
One 100 dimensional vector for 1 image. 
For 64 images, 64 such 100 dimensional vectors are generated.

```python
from numpy.random import randn

# generate points in latent space as input for the generator
# function 1
def generate_latent_points(latent_dim, n_samples):
	# generate points in the latent space
	# 64*100 = 6400 values
	x_input = randn(latent_dim * n_samples)
	# reshape into a batch of inputs for the network
	x_input = x_input.reshape(n_samples, latent_dim)
	return x_input
x_input = generate_latent_points(100, 64)
print(x_input.shape)

Output >>
(64, 100)
```
#### Step 4 : Generate the fake images using the generator model
```python
# use the generator to generate n fake examples, with class labels
# function 2
def generate_fake_samples(g_model, latent_dim, n_samples):
	# generate points in latent space
	x_input = generate_latent_points(latent_dim, n_samples)
	# predict outputs
	X = g_model.predict(x_input)
	# create 'fake' class labels (0)
	y = zeros((n_samples, 1))
	return X, y
# size of the latent space
latent_dim = 100
# define the discriminator model
model = define_generator(latent_dim)
# generate samples
n_samples = 64
X, _ = generate_fake_samples(model, latent_dim, n_samples)
# scale pixel values from [-1,1] to [0,1]
X = (X + 1) / 2.0
# plot the generated samples
for i in range(n_samples):
	# define subplot
	pyplot.subplot(8, 8, 1 + i)
	# turn off axis labels
	pyplot.axis('off')
	# plot single image
	pyplot.imshow(X[i])
# show the figure
pyplot.show()
```
**Output >>**
![](/images/genai/generator-fakes.png)

### Connect the Generator and Discriminator

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam

# define the combined generator and discriminator model (GAN)
def define_gan(g_model, d_model):
    # make discriminator weights not trainable during GAN training
    d_model.trainable = False

    # create sequential GAN model
    model = Sequential()

    # add generator model
    model.add(g_model)

    # add discriminator model
    model.add(d_model)

    # compile GAN model with corrected learning_rate argument
    opt = Adam(learning_rate=0.0002, beta_1=0.5)
    model.compile(loss='binary_crossentropy', optimizer=opt)

    return model

# size of the latent space
latent_dim = 100
# create the discriminator
d_model = define_discriminator()
# create the generator
g_model = define_generator(latent_dim)
# create the gan
gan_model = define_gan(g_model, d_model)
# summarize gan model
gan_model.summary()
# plot gan model
plot_model(gan_model, to_file='gan_plot.png', show_shapes=True, show_layer_names=True)
```
### Train the full GAN
![](/images/genai/hl-wflow-gan.svg)

#### Train the Generator and Discriminator
##### Loss functions
1. Loss 1 - Discriminator loss on real images - d_loss1 - real images prediction correctness
2. Loss 2 - Discriminator loss on fake images - d_loss2 - fake images prediction correctness
3. Loss 3 - Generator loss on fake images - g_loss - generator loss, by freezing discriminator to return 1, on a combined gan model containing frozen discriminator at 1, and trainable generator.

```python
# train the generator and discriminator
def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=200, n_batch=128):
	bat_per_epo = int(dataset.shape[0] / n_batch)
	half_batch = int(n_batch / 2)
	# manually enumerate epochs
	for i in range(n_epochs):
		# enumerate batches over the training set
		for j in range(bat_per_epo):
			# get randomly selected 'real' samples
			X_real, y_real = generate_real_samples(dataset, half_batch)
			# update discriminator model weights
			d_loss1, _ = d_model.train_on_batch(X_real, y_real)
			# generate 'fake' examples
			X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)
			# update discriminator model weights
			d_loss2, _ = d_model.train_on_batch(X_fake, y_fake)
			# prepare points in latent space as input for the generator
			X_gan = generate_latent_points(latent_dim, n_batch)
			# create inverted labels for the fake samples
			### Labels or the actual result which we want
			y_gan = ones((n_batch, 1))
			# update the generator via the discriminator's error
			g_loss = gan_model.train_on_batch(X_gan, y_gan)
			# summarize loss on this batch
			print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %
				(i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))
		# evaluate the model performance, sometimes
		if (i+1) % 1 == 0:
			summarize_performance(i, g_model, d_model, dataset, latent_dim)

# size of the latent space
latent_dim = 100
# create the discriminator
d_model = define_discriminator()
# create the generator
g_model = define_generator(latent_dim)
# create the gan
gan_model = define_gan(g_model, d_model)
# load image data
dataset = load_real_samples()
# train model

train(g_model, d_model, gan_model, dataset, latent_dim)
```
## References
1. [Lecture Video - Vizuara](https://youtu.be/pYEAJzEZtg4)
2. [Code implementing the GAN code]( https://github.com/samratkar/samratkar.github.io/blob/main/_posts/concepts/genai/notes-codes/gan/GenAI_Fundamentals_Build_First_GAN_(1).ipynb)
