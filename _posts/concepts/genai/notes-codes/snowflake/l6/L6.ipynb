{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 6: Improve Agent's GPA\n",
    "\n",
    "In this lesson, you'll make two targeted changes to the agent:\n",
    "\n",
    "1. Adjust the planning prompt to include explicit goals, pre-conditions, and post-conditions for each step. This helps the executor understand the sub-goals it needs to reach.\n",
    "\n",
    "2. You will add inline evals so the agent receives feedback on when to do additional research. This provides the executor feedback on whether it's reaching its sub-goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "\n",
    "load_dotenv(override=True)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ[\"TRULENS_OTEL_TRACING\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> ðŸ’» &nbsp; <b>To access <code>requirements.txt</code>, <code>env.template</code>, <code>prompts.py</code>, and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook 2) click on <em>\"Open\"</em>.\n",
    "\n",
    "<p> â¬‡ &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Add inline evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "from langgraph.graph import END\n",
    "from langgraph.types import Command\n",
    "from typing import Literal\n",
    "from trulens.otel.semconv.trace import SpanAttributes\n",
    "from trulens.core.otel.instrument import instrument\n",
    "from helper import cortex_agent, State, f_context_relevance\n",
    "\n",
    "from trulens.apps.langgraph.inline_evaluations import inline_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@inline_evaluation(f_context_relevance)\n",
    "@instrument(\n",
    "    span_type=SpanAttributes.SpanType.RETRIEVAL,\n",
    "    attributes=lambda ret, exception, *args, **kwargs: {\n",
    "        SpanAttributes.RETRIEVAL.QUERY_TEXT: args[0].get(\"agent_query\") if args[0].get(\"agent_query\") else None,\n",
    "        SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: [\n",
    "            ret.update[\"messages\"][-1].content\n",
    "        ] if hasattr(ret, \"update\") else \"No tool call\",\n",
    "    },\n",
    ")\n",
    "def cortex_agents_research_node(\n",
    "    state: State,\n",
    ") -> Command[Literal[\"executor\"]]:\n",
    "    query = state.get(\"agent_query\", state.get(\"user_query\", \"\"))\n",
    "    # Call the tool with the string query\n",
    "    agent_response = cortex_agent.invoke({\"messages\":query})\n",
    "    # Compose a message content string with all results new HumanMessage with the result\n",
    "    new_message = HumanMessage(content=agent_response['messages'][-1].content, name=\"cortex_researcher\")\n",
    "    # Append to the message history\n",
    "    goto = \"executor\"\n",
    "    return Command(\n",
    "        update={\"messages\": [new_message]},\n",
    "        goto=goto,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import web_search_agent\n",
    "\n",
    "@inline_evaluation(f_context_relevance)\n",
    "@instrument(\n",
    "    span_type=SpanAttributes.SpanType.RETRIEVAL,\n",
    "    attributes=lambda ret, exception, *args, **kwargs: {\n",
    "        SpanAttributes.RETRIEVAL.QUERY_TEXT: args[0].get(\"agent_query\", \"\"),\n",
    "        SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: [\n",
    "            ret.update[\"messages\"][-1].content\n",
    "        ] if hasattr(ret, \"update\") else \"No tool call\",\n",
    "    },\n",
    ")\n",
    "def web_research_node(\n",
    "    state: State,\n",
    ") -> Command[Literal[\"executor\"]]:\n",
    "    agent_query = state.get(\"agent_query\")\n",
    "    result = web_search_agent.invoke({\"messages\":agent_query})\n",
    "    goto = \"executor\"\n",
    "    # wrap in a human message, as not all providers allow\n",
    "    # AI message at the last position of the input messages list\n",
    "    result[\"messages\"][-1] = HumanMessage(\n",
    "        content=result[\"messages\"][-1].content, name=\"web_researcher\"\n",
    "    )\n",
    "    return Command(\n",
    "        update={\n",
    "            # share internal message history of research agent with other agents\n",
    "            \"messages\": result[\"messages\"],\n",
    "        },\n",
    "        goto=goto,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Update the planning prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add pre-conditions, post-conditions, and goals to each step in the agent's plan.\n",
    "\n",
    "Adding this explicit detail helps the executor understand the goal of each step, which improves tool calling and agent decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper\n",
    "import prompts\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "def patched_plan_prompt(state):\n",
    "    base = prompts.plan_prompt(state).content\n",
    "    insertion = '\"action\": \"string\",\\n            \"pre_conditions\": [\"string\", ...],\\n            \"post_conditions\": [\"string\", ...],\\n            \"goal\": \"string\",'\n",
    "    base = base.replace('\"action\": \"string\",', insertion)\n",
    "    return HumanMessage(content=base)\n",
    "\n",
    "helper.plan_prompt = patched_plan_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from helper import State, planner_node, executor_node, chart_node, chart_summary_node, synthesizer_node\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"planner\", planner_node)\n",
    "workflow.add_node(\"executor\", executor_node)\n",
    "workflow.add_node(\"web_researcher\", web_research_node)\n",
    "workflow.add_node(\"cortex_researcher\", cortex_agents_research_node)\n",
    "workflow.add_node(\"chart_generator\", chart_node)\n",
    "workflow.add_node(\"chart_summarizer\", chart_summary_node)\n",
    "workflow.add_node(\"synthesizer\", synthesizer_node)\n",
    "\n",
    "workflow.add_edge(START, \"planner\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Create a TruLens session for logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core.session import TruSession\n",
    "from trulens.core.database.connector.default import DefaultDBConnector\n",
    "\n",
    "# Initialize connector with SQLite database one folder back\n",
    "connector = DefaultDBConnector(database_url=\"sqlite:///default.sqlite\")\n",
    "\n",
    "# Create TruSession with the custom connector\n",
    "session = TruSession(connector=connector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Register the new version of the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> \n",
    "    <p>ðŸš¨ &nbsp; In this notebook, you are directly provided with the results obtained during filming. This is to help eliminate waiting time, and to prevent potential rate limit errors that might occur in this learning environment (this learning environment is constrained, and the GPA evaluation metrics consume a significant number of tokens).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the code that registers the agent with TruLens:\n",
    "\n",
    "```python\n",
    "from trulens.apps.langgraph import TruGraph\n",
    "\n",
    "from helper import f_answer_relevance, f_context_relevance, f_groundedness, f_logical_consistency, f_execution_efficiency, f_plan_adherence, f_plan_quality\n",
    "\n",
    "tru_recorder = TruGraph(\n",
    "    graph,\n",
    "    app_name=\"Sales Data Agent\",\n",
    "    app_version=\"L6: Inline evals + sub-goals in planning prompt\",\n",
    "    feedbacks=[\n",
    "        f_answer_relevance,\n",
    "        f_context_relevance,\n",
    "        f_groundedness,\n",
    "        f_logical_consistency,\n",
    "        f_execution_efficiency,\n",
    "        f_plan_adherence,\n",
    "        f_plan_quality,\n",
    "    ],\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 Re-test the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> \n",
    "    <p>ðŸš¨ &nbsp;<b>Run Results:</b> In this notebook, you are directly provided with the results obtained during filming. This is to help eliminate waiting time, and to prevent potential rate limit errors that might occur in this learning environment (this learning environment is constrained, and the GPA evaluation metrics consume a significant number of tokens).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code for query 1:**\n",
    "``` python\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "with tru_recorder as recording:\n",
    "    query = \"What are our top 3 client deals? Chart the deal value for each.\"\n",
    "    print(f\"Query: {query}\")\n",
    "    state = {\n",
    "                \"messages\": [HumanMessage(content=query)],\n",
    "                \"user_query\": query,\n",
    "                \"enabled_agents\": [\"cortex_researcher\", \"web_researcher\", \"chart_generator\", \"chart_summarizer\", \"synthesizer\"],\n",
    "            }\n",
    "    graph.invoke(state)\n",
    "\n",
    "    print(\"--------------------------------\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, feedback = session.get_records_and_feedback()\n",
    "print(f\"Query: {records.iloc[3]['input']}\\n\")\n",
    "print(f\"Output: {records.iloc[3]['output']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code for query 2**\n",
    "\n",
    "```python\n",
    "with tru_recorder as recording:\n",
    "    query = \"Identify our pending deals, research if they may be experiencing regulatory changes, and using the meeting notes for each customer, provide a new value proposition for each given the regulatory changes.\"\n",
    "    print(f\"Query: {query}\")\n",
    "    state = {\n",
    "                \"messages\": [HumanMessage(content=query)],\n",
    "                \"user_query\": query,\n",
    "                \"enabled_agents\": [\"cortex_researcher\", \"web_researcher\", \"chart_generator\", \"chart_summarizer\", \"synthesizer\"],\n",
    "            }\n",
    "    graph.invoke(state)\n",
    "\n",
    "    print(\"--------------------------------\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Query: {records.iloc[4]['input']}\\n\")\n",
    "print(f\"Output: {records.iloc[4]['output']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code for query 3**\n",
    "```python\n",
    "with tru_recorder as recording:\n",
    "    query = \"Identify our largest client deal, then find important topics in the meeting notes with that company, and find a news article related to the important topics discussed.\"\n",
    "    print(f\"Query: {query}\")\n",
    "    state = {\n",
    "                \"messages\": [HumanMessage(content=query)],\n",
    "                \"user_query\": query,\n",
    "                \"enabled_agents\": [\"cortex_researcher\", \"web_researcher\", \"chart_generator\", \"chart_summarizer\", \"synthesizer\"],\n",
    "            }\n",
    "    graph.invoke(state)\n",
    "\n",
    "    print(\"--------------------------------\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Query: {records.iloc[5]['input']}\\n\")\n",
    "print(f\"Output: {records.iloc[5]['output']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 Launch TruLens dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing to the previous version, we can validate the changes.\n",
    "\n",
    "**Note:** Make sure to click on the second link (not the localhost) to open the TruLens dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "import os\n",
    "str_port = 8005\n",
    "_ = run_dashboard(port=str_port)\n",
    "print(os.environ['DLAI_LOCAL_URL'].format(port=str_port))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What other improvements could be also done?**\n",
    "- In this course, we focused on evaluating the end-to-end agent behavior. We could have also tested the behavior of each specialized agent separately to optimize their prompt and design.\n",
    "- We could have added other metrics for inline-evaluations.\n",
    "- We could also updated the prompt of the executor. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
