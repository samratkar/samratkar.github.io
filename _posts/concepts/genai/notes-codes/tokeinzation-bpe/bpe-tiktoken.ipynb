{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHhrmYGJGYYI"
      },
      "source": [
        "## Why does character level tokenization fail?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzNb6UXDGVIw",
        "outputId": "9855be87-7912-463e-d5b6-dd0a17ccab74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word tokens: ['Today,', 'I', 'want', 'to', 'start', 'my', 'day', 'with', 'a', 'cup', 'of', 'coffee']\n",
            "Number of words: 12\n",
            "Character tokens: ['T', 'o', 'd', 'a', 'y', ',', ' ', 'I', ' ', 'w', 'a', 'n', 't', ' ', 't', 'o', ' ', 's', 't', 'a', 'r', 't', ' ', 'm', 'y', ' ', 'd', 'a', 'y', ' ', 'w', 'i', 't', 'h', ' ', 'a', ' ', 'c', 'u', 'p', ' ', 'o', 'f', ' ', 'c', 'o', 'f', 'f', 'e', 'e']\n",
            "Number of characters: 50\n"
          ]
        }
      ],
      "source": [
        "sentence = \"Today, I want to start my day with a cup of coffee\"\n",
        "\n",
        "# Split on whitespace to get individual words\n",
        "words = sentence.split()\n",
        "\n",
        "# Print the list of word tokens\n",
        "print(\"Word tokens:\", words)\n",
        "\n",
        "# Print the total number of words\n",
        "print(\"Number of words:\", len(words))\n",
        "\n",
        "\n",
        "sentence = \"Today, I want to start my day with a cup of coffee\"\n",
        "\n",
        "# Convert the sentence into a list of individual characters\n",
        "characters = list(sentence)\n",
        "\n",
        "# Print the list of character tokens\n",
        "print(\"Character tokens:\", characters)\n",
        "\n",
        "# Print the total number of characters\n",
        "print(\"Number of characters:\", len(characters))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoMWyOeyQ7B2"
      },
      "source": [
        "## Implementing Byte Pair Encoding (BPE) from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEX_J-vjWVos"
      },
      "source": [
        "ðŸ¦‡ðŸ¦‡ðŸ¦‡"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7swCSW0jTAz7"
      },
      "source": [
        "### Step 1: Take raw text and tokenize into characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "vso_LnYaQ-lt"
      },
      "outputs": [],
      "source": [
        "#\n",
        "text = \"\"\"The Dark Knight Rises is a superhero movie released in 2012. It is the final part of Christopher Nolan Dark Knight trilogy, following Batman Begins and The Dark Knight. The film stars Christian Bale as Bruce Wayne Batman, who has been retired as Batman for eight years after the events of the previous movie.\n",
        "\"\"\" \n",
        "text1 = \"\"\"The Dark Knight Rises is a superhero movie released in 2012. It is the final part of Christopher Nolanâ€™s Dark Knight trilogy, following Batman Begins and The Dark Knight. The film stars Christian Bale as Bruce Wayne/Batman, who has been retired as Batman for eight years after the events of the previous movie.\n",
        "\n",
        "The main villain in the movie is Bane, played by Tom Hardy. Bane is a powerful and intelligent terrorist who threatens Gotham City with destruction. He forces Bruce Wayne to come out of retirement and become Batman again. Anne Hathaway plays Selina Kyle, also known as Catwoman, a skilled thief with her own agenda.\n",
        "\n",
        "The movie is about Bruce Wayneâ€™s struggle to overcome his physical and emotional challenges to save Gotham. It also shows themes of hope, sacrifice, and resilience. The film has many exciting action scenes, such as a plane hijack and a massive battle in Gotham.\n",
        "\n",
        "In the end, Batman saves the city and inspires the people of Gotham. However, he is believed to have sacrificed his life. The movie ends with a twist, suggesting that Bruce Wayne is alive and has moved on to live a quiet life.\n",
        "\n",
        "The Dark Knight Rises was a big success and is loved by many fans for its epic story, strong characters, and thrilling action.\\\n",
        "\"\"\"\n",
        "\n",
        "text2 = \"\"\"\n",
        "Casandra BrenÃ© Brown (born November 18, 1965) is an American academic and podcaster who is the Huffington Foundation's BrenÃ© Brown Endowed Chair at the University of Houston's Graduate College of Social Work and a visiting professor in management at the McCombs School of Business in the University of Texas at Austin. Brown is known for her work on shame, vulnerability, and leadership, and for her widely viewed 2010 TEDx talk.[2] She has written six number-one New York Times bestselling books and hosted two podcasts on Spotify.[3]\n",
        "\n",
        "She appears in the 2019 documentary BrenÃ© Brown: The Call to Courage on Netflix. In 2022, HBO Max released a documentary series based on her book Atlas of the Heart.\n",
        "\n",
        "Early life and education\n",
        "Brown was born on November 18, 1965,[4] in San Antonio, Texas, where her parents, Charles Arthur Brown and Casandra Deanne Rogers,[4] had her baptized in the Episcopal Church. She is the eldest of four children.[5] Her family then moved to New Orleans, Louisiana.[6]\n",
        "\n",
        "Brown completed a Bachelor of Social Work degree at the University of Texas at Austin in 1995, a Master of Social Work degree in 1996,[7] and a Doctor of Philosophy degree in social work at the University of Houston Graduate School of Social Work in 2002.[8]\n",
        "\n",
        "Career\n",
        "Research and teaching\n",
        "Brown has studied the topics of courage, vulnerability, shame, empathy, and leadership, which she has used to look at human connection and how it works.[9] She has spent her research career as a professor at her alma mater, the University of Houston's Graduate College of Social Work.[10]\n",
        "\n",
        "Public speaking\n",
        "Brown's TEDx talk from Houston in 2010, \"The Power of Vulnerability\", is one of the five most viewed TED talks. Its popularity shifted her work from relative obscurity in academia into the mainstream spotlight.[11][12][13][14] The talk \"summarizes a decade of Brown's research on shame, framing her weightiest discoveries in self-deprecating and personal terms.\"[14] Reggie Ugwu for The New York Times said that this event gave the world \"a new star of social psychology.\"[14] She went on to follow this popular TED talk with another titled \"Listening to Shame\" in 2012. In the second talk she talks about how her life has changed since the first talk and explains the connection between shame and vulnerability, building on the thesis of her first TED talk.[15]\n",
        "\n",
        "She also has a less well-known talk from 2010 given at TEDxKC titled \"The Price of Invulnerability.\" In it she explains that when numbing hard and difficult feelings, essentially feeling vulnerable, we also numb positive emotions, like joy.[16] This led to the creation of her filmed lecture, BrenÃ© Brown: The Call to Courage, which debuted on Netflix in 2019.[17] USA Today called it \"a mix of a motivational speech and stand-up comedy special.\"[17] Brown discusses how and why to choose courage over comfort, equating being brave to being vulnerable. According to her research, doing this opens people to love, joy, and belonging by allowing them to better know themselves and more deeply connect with other people.[18]\n",
        "\n",
        "Brown regularly works as a public speaker at private events and businesses, such as at Alain de Botton's School of Life[13] and at Google and Disney.[14]\n",
        "\"\"\"\n",
        "\n",
        "## For non-alphabet characters and for a more general purpose code, use this:\n",
        "#tokens = text.encode(\"utf-8\") # raw bytes\n",
        "#tokens = list(map(int, tokens)) # convert to a list of integers in range 0..255 for convenience\n",
        "\n",
        "# For sake of simplicity, we are only using ASCII character encoding:\n",
        "tokens = [ord(ch) for ch in text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "BtVzO_tlRqli"
      },
      "outputs": [],
      "source": [
        "ids = list(tokens)  # copy so we don't destroy the original list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cc51eSTRrhd",
        "outputId": "559052d9-2c38-4699-b31a-cb65f2d13298"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[84, 104, 101, 32, 68, 97, 114, 107, 32, 75, 110, 105, 103, 104, 116, 32, 82, 105, 115, 101, 115, 32, 105, 115, 32, 97, 32, 115, 117, 112, 101, 114, 104, 101, 114, 111, 32, 109, 111, 118, 105, 101, 32, 114, 101, 108, 101, 97, 115, 101, 100, 32, 105, 110, 32, 50, 48, 49, 50, 46, 32, 73, 116, 32, 105, 115, 32, 116, 104, 101, 32, 102, 105, 110, 97, 108, 32, 112, 97, 114, 116, 32, 111, 102, 32, 67, 104, 114, 105, 115, 116, 111, 112, 104, 101, 114, 32, 78, 111, 108, 97, 110, 32, 68, 97, 114, 107, 32, 75, 110, 105, 103, 104, 116, 32, 116, 114, 105, 108, 111, 103, 121, 44, 32, 102, 111, 108, 108, 111, 119, 105, 110, 103, 32, 66, 97, 116, 109, 97, 110, 32, 66, 101, 103, 105, 110, 115, 32, 97, 110, 100, 32, 84, 104, 101, 32, 68, 97, 114, 107, 32, 75, 110, 105, 103, 104, 116, 46, 32, 84, 104, 101, 32, 102, 105, 108, 109, 32, 115, 116, 97, 114, 115, 32, 67, 104, 114, 105, 115, 116, 105, 97, 110, 32, 66, 97, 108, 101, 32, 97, 115, 32, 66, 114, 117, 99, 101, 32, 87, 97, 121, 110, 101, 32, 66, 97, 116, 109, 97, 110, 44, 32, 119, 104, 111, 32, 104, 97, 115, 32, 98, 101, 101, 110, 32, 114, 101, 116, 105, 114, 101, 100, 32, 97, 115, 32, 66, 97, 116, 109, 97, 110, 32, 102, 111, 114, 32, 101, 105, 103, 104, 116, 32, 121, 101, 97, 114, 115, 32, 97, 102, 116, 101, 114, 32, 116, 104, 101, 32, 101, 118, 101, 110, 116, 115, 32, 111, 102, 32, 116, 104, 101, 32, 112, 114, 101, 118, 105, 111, 117, 115, 32, 109, 111, 118, 105, 101, 46, 10]\n"
          ]
        }
      ],
      "source": [
        "print(ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max = 121 \n",
            "\n",
            "second max = 119\n"
          ]
        }
      ],
      "source": [
        "print(f\"max = {max(ids)} \\n\")\n",
        "second_max = sorted(set(ids), reverse=True)[1]  # Remove duplicates and sort\n",
        "print(f\"second max = {second_max}\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "# checking if any id is greater than 128\n",
        "print([{id:chr(id)} for id in ids if id > 128])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhtGo95DVW58"
      },
      "source": [
        "### Step 2: Write a function to count the frequency of the adjacent pairs of characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwQ_jZmJR0Am",
        "outputId": "a339d707-0e3c-4e6e-d1e4-368b0c1508c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{(84, 104): 3, (104, 101): 8, (101, 32): 10, (32, 68): 3, (68, 97): 3, (97, 114): 6, (114, 107): 3, (107, 32): 3, (32, 75): 3, (75, 110): 3, (110, 105): 3, (105, 103): 4, (103, 104): 4, (104, 116): 4, (116, 32): 5, (32, 82): 1, (82, 105): 1, (105, 115): 5, (115, 101): 2, (101, 115): 1, (115, 32): 11, (32, 105): 3, (32, 97): 5, (97, 32): 1, (32, 115): 2, (115, 117): 1, (117, 112): 1, (112, 101): 1, (101, 114): 4, (114, 104): 1, (114, 111): 1, (111, 32): 2, (32, 109): 2, (109, 111): 2, (111, 118): 2, (118, 105): 3, (105, 101): 2, (32, 114): 2, (114, 101): 4, (101, 108): 1, (108, 101): 2, (101, 97): 2, (97, 115): 4, (101, 100): 2, (100, 32): 3, (105, 110): 4, (110, 32): 6, (32, 50): 1, (50, 48): 1, (48, 49): 1, (49, 50): 1, (50, 46): 1, (46, 32): 2, (32, 73): 1, (73, 116): 1, (32, 116): 4, (116, 104): 3, (32, 102): 4, (102, 105): 2, (110, 97): 1, (97, 108): 2, (108, 32): 1, (32, 112): 2, (112, 97): 1, (114, 116): 1, (32, 111): 2, (111, 102): 2, (102, 32): 2, (32, 67): 2, (67, 104): 2, (104, 114): 2, (114, 105): 3, (115, 116): 3, (116, 111): 1, (111, 112): 1, (112, 104): 1, (114, 32): 3, (32, 78): 1, (78, 111): 1, (111, 108): 2, (108, 97): 1, (97, 110): 6, (116, 114): 1, (105, 108): 2, (108, 111): 2, (111, 103): 1, (103, 121): 1, (121, 44): 1, (44, 32): 2, (102, 111): 2, (108, 108): 1, (111, 119): 1, (119, 105): 1, (110, 103): 1, (103, 32): 1, (32, 66): 6, (66, 97): 4, (97, 116): 3, (116, 109): 3, (109, 97): 3, (66, 101): 1, (101, 103): 1, (103, 105): 1, (110, 115): 1, (110, 100): 1, (32, 84): 2, (116, 46): 1, (108, 109): 1, (109, 32): 1, (116, 97): 1, (114, 115): 2, (116, 105): 2, (105, 97): 1, (66, 114): 1, (114, 117): 1, (117, 99): 1, (99, 101): 1, (32, 87): 1, (87, 97): 1, (97, 121): 1, (121, 110): 1, (110, 101): 1, (110, 44): 1, (32, 119): 1, (119, 104): 1, (104, 111): 1, (32, 104): 1, (104, 97): 1, (32, 98): 1, (98, 101): 1, (101, 101): 1, (101, 110): 2, (101, 116): 1, (105, 114): 1, (111, 114): 1, (32, 101): 2, (101, 105): 1, (32, 121): 1, (121, 101): 1, (97, 102): 1, (102, 116): 1, (116, 101): 1, (101, 118): 2, (118, 101): 1, (110, 116): 1, (116, 115): 1, (112, 114): 1, (105, 111): 1, (111, 117): 1, (117, 115): 1, (101, 46): 1, (46, 10): 1}\n"
          ]
        }
      ],
      "source": [
        "# 1) Count all adjacent pairs in our current sequence 'ids'.\n",
        "\n",
        "def get_stats(ids):\n",
        "    counts = {}\n",
        "    for pair in zip(ids, ids[1:]):\n",
        "        counts[pair] = counts.get(pair, 0) + 1\n",
        "    return counts\n",
        "\n",
        "stats = get_stats(ids)\n",
        "print(stats)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-voL-MOdVdAN"
      },
      "source": [
        "### Step 3: Select the pair with the highest frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THZ0crZlR-dC",
        "outputId": "c0b7bac2-b734-403b-8168-e2b2c4d5f23a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(115, 32)\n"
          ]
        }
      ],
      "source": [
        "# 2) Select the pair with the highest frequency.\n",
        "pair = max(stats, key=stats.get)\n",
        "print(pair)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pzhu1x73Viqg"
      },
      "source": [
        "### Step 4: Define the new token's ID (ID of the merged token is added to vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saZaHgdXSIP6",
        "outputId": "bcdad139-1609-44d4-f01d-e0457286fd8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "128\n"
          ]
        }
      ],
      "source": [
        "# 3) Define the new token's ID as 128 + i.\n",
        "i = 0\n",
        "idx = 128 + i\n",
        "print(idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\x80'"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chr(128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwFZNOtSSXJJ",
        "outputId": "586d0e57-c0e2-4821-f152-9c9be321502d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('s', ' ')\n"
          ]
        }
      ],
      "source": [
        "# For readability, decode the original token IDs (pair[0], pair[1]) into characters\n",
        "    # just for a nice printout. (Assumes these IDs map to ASCII, etc.)\n",
        "char_pair = (chr(pair[0]), chr(pair[1]))\n",
        "print(char_pair)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1uL6Et9V6_X"
      },
      "source": [
        "### Step 5: Show which pair we are merging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjLr4KISSfF-",
        "outputId": "f7f6e0c6-67cb-4caa-9bfe-5d771000a80b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "merging (115, 32) (s ) into a new token 128\n"
          ]
        }
      ],
      "source": [
        "# Show which pair we are merging.\n",
        "print(f\"merging {pair} ({char_pair[0]}{char_pair[1]}) into a new token {idx}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7npSNo-dV-YN"
      },
      "source": [
        "### Step 6: Peform the merge: replace all occurences of the most frequent pair with the new token ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHw5ObGoSmcG",
        "outputId": "9c92ddd5-a965-427c-9f39-899760d27efb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "128 \n",
            "\n",
            "[84, 104, 101, 32, 68, 97, 114, 107, 32, 75, 110, 105, 103, 104, 116, 32, 82, 105, 115, 101, 147, 105, 147, 97, 32, 115, 117, 112, 101, 114, 104, 101, 114, 111, 32, 109, 111, 118, 105, 101, 32, 114, 101, 108, 101, 97, 115, 101, 100, 32, 105, 110, 32, 50, 48, 49, 50, 46, 32, 73, 116, 32, 105, 147, 116, 104, 101, 32, 102, 105, 110, 97, 108, 32, 112, 97, 114, 116, 32, 111, 102, 32, 67, 104, 114, 105, 115, 116, 111, 112, 104, 101, 114, 32, 78, 111, 108, 97, 110, 32, 68, 97, 114, 107, 32, 75, 110, 105, 103, 104, 116, 32, 116, 114, 105, 108, 111, 103, 121, 44, 32, 102, 111, 108, 108, 111, 119, 105, 110, 103, 32, 66, 97, 116, 109, 97, 110, 32, 66, 101, 103, 105, 110, 147, 97, 110, 100, 32, 84, 104, 101, 32, 68, 97, 114, 107, 32, 75, 110, 105, 103, 104, 116, 46, 32, 84, 104, 101, 32, 102, 105, 108, 109, 32, 115, 116, 97, 114, 147, 67, 104, 114, 105, 115, 116, 105, 97, 110, 32, 66, 97, 108, 101, 32, 97, 147, 66, 114, 117, 99, 101, 32, 87, 97, 121, 110, 101, 32, 66, 97, 116, 109, 97, 110, 44, 32, 119, 104, 111, 32, 104, 97, 147, 98, 101, 101, 110, 32, 114, 101, 116, 105, 114, 101, 100, 32, 97, 147, 66, 97, 116, 109, 97, 110, 32, 102, 111, 114, 32, 101, 105, 103, 104, 116, 32, 121, 101, 97, 114, 147, 97, 102, 116, 101, 114, 32, 116, 104, 101, 32, 101, 118, 101, 110, 116, 147, 111, 102, 32, 116, 104, 101, 32, 112, 114, 101, 118, 105, 111, 117, 147, 109, 111, 118, 105, 101, 46, 10]\n",
            "128\n"
          ]
        }
      ],
      "source": [
        "# 4) Perform the merge, replacing all occurrences of 'pair' with 'idx'.\n",
        "print (f\"{idx} \\n\")\n",
        "def merge(ids, pair, idx):\n",
        "    newids = []\n",
        "    i = 0\n",
        "    while i < len(ids):\n",
        "        if i < len(ids) - 1 and ids[i] == pair[0] and ids[i + 1] == pair[1]:\n",
        "            newids.append(idx)\n",
        "            i += 2\n",
        "        else:\n",
        "            newids.append(ids[i])\n",
        "            i += 1\n",
        "    return newids\n",
        "\n",
        "ids = merge(ids, pair, idx)\n",
        "print(ids)\n",
        "print(idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOhi9-76WJsE"
      },
      "source": [
        "### Step 7: Write all functions together and define number of iterations to run.\n",
        "\n",
        "Here, we have to select how many merges we do. If we do 20 merges, the vocabulary size increases from 128 to 148."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE5Hq2TARB69",
        "outputId": "6f5658b7-371b-4ca0-9f08-aa86b2187428"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "merging (115, 32) (s ) into a new token 128\n",
            "merging (101, 32) (e ) into a new token 129\n",
            "merging (104, 129) (hÂ) into a new token 130\n",
            "merging (97, 114) (ar) into a new token 131\n",
            "merging (110, 32) (n ) into a new token 132\n",
            "merging (116, 32) (t ) into a new token 133\n",
            "merging (105, 103) (ig) into a new token 134\n",
            "merging (134, 104) (Â†h) into a new token 135\n",
            "merging (101, 114) (er) into a new token 136\n",
            "merging (114, 101) (re) into a new token 137\n",
            "merging (97, 132) (aÂ„) into a new token 138\n",
            "merging (66, 97) (Ba) into a new token 139\n",
            "merging (84, 130) (TÂ‚) into a new token 140\n",
            "merging (68, 131) (DÂƒ) into a new token 141\n",
            "merging (141, 107) (Âk) into a new token 142\n",
            "merging (142, 32) (ÂŽ ) into a new token 143\n",
            "merging (143, 75) (ÂK) into a new token 144\n",
            "merging (144, 110) (Ân) into a new token 145\n",
            "merging (145, 135) (Â‘Â‡) into a new token 146\n",
            "merging (105, 115) (is) into a new token 147\n"
          ]
        }
      ],
      "source": [
        "def get_stats(ids):\n",
        "    counts = {}\n",
        "    for pair in zip(ids, ids[1:]):\n",
        "        counts[pair] = counts.get(pair, 0) + 1\n",
        "    return counts\n",
        "\n",
        "def merge(ids, pair, idx):\n",
        "    newids = []\n",
        "    i = 0\n",
        "    while i < len(ids):\n",
        "        if i < len(ids) - 1 and ids[i] == pair[0] and ids[i + 1] == pair[1]:\n",
        "            newids.append(idx)\n",
        "            i += 2\n",
        "        else:\n",
        "            newids.append(ids[i])\n",
        "            i += 1\n",
        "    return newids\n",
        "\n",
        "# ---\n",
        "vocab_size = 148  # the desired final vocabulary size\n",
        "num_merges = vocab_size - 128\n",
        "ids = list(tokens)  # copy so we don't destroy the original list\n",
        "\n",
        "merges = {}  # (int, int) -> int\n",
        "for i in range(num_merges):\n",
        "    # 1) Count all adjacent pairs in our current sequence 'ids'.\n",
        "    stats = get_stats(ids)\n",
        "    pair = max(stats, key=stats.get)\n",
        "    idx = 128 + i\n",
        "    # Decode the characters of the pair for display\n",
        "    char_pair = (chr(pair[0]), chr(pair[1]))\n",
        "    print(f\"merging {pair} ({char_pair[0]}{char_pair[1]}) into a new token {idx}\")\n",
        "    ids = merge(ids, pair, idx)\n",
        "    merges[pair] = idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_ZnnFtIRle_",
        "outputId": "33e5ee1f-e28c-49a6-9119-f0f814f78d2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[84, 104, 101, 32, 68, 97, 114, 107, 32, 75, 110, 105, 103, 104, 116, 32, 82, 105, 115, 101, 115, 32, 105, 115, 32, 97, 32, 115, 117, 112, 101, 114, 104, 101, 114, 111, 32, 109, 111, 118, 105, 101, 32, 114, 101, 108, 101, 97, 115, 101, 100, 32, 105, 110, 32, 50, 48, 49, 50, 46, 32, 73, 116, 32, 105, 115, 32, 116, 104, 101, 32, 102, 105, 110, 97, 108, 32, 112, 97, 114, 116, 32, 111, 102, 32, 67, 104, 114, 105, 115, 116, 111, 112, 104, 101, 114, 32, 78, 111, 108, 97, 110, 32, 68, 97, 114, 107, 32, 75, 110, 105, 103, 104, 116, 32, 116, 114, 105, 108, 111, 103, 121, 44, 32, 102, 111, 108, 108, 111, 119, 105, 110, 103, 32, 66, 97, 116, 109, 97, 110, 32, 66, 101, 103, 105, 110, 115, 32, 97, 110, 100, 32, 84, 104, 101, 32, 68, 97, 114, 107, 32, 75, 110, 105, 103, 104, 116, 46, 32, 84, 104, 101, 32, 102, 105, 108, 109, 32, 115, 116, 97, 114, 115, 32, 67, 104, 114, 105, 115, 116, 105, 97, 110, 32, 66, 97, 108, 101, 32, 97, 115, 32, 66, 114, 117, 99, 101, 32, 87, 97, 121, 110, 101, 32, 66, 97, 116, 109, 97, 110, 44, 32, 119, 104, 111, 32, 104, 97, 115, 32, 98, 101, 101, 110, 32, 114, 101, 116, 105, 114, 101, 100, 32, 97, 115, 32, 66, 97, 116, 109, 97, 110, 32, 102, 111, 114, 32, 101, 105, 103, 104, 116, 32, 121, 101, 97, 114, 115, 32, 97, 102, 116, 101, 114, 32, 116, 104, 101, 32, 101, 118, 101, 110, 116, 115, 32, 111, 102, 32, 116, 104, 101, 32, 112, 114, 101, 118, 105, 111, 117, 115, 32, 109, 111, 118, 105, 101, 46, 10]\n",
            "[140, 146, 133, 82, 147, 101, 128, 105, 128, 97, 32, 115, 117, 112, 136, 104, 136, 111, 32, 109, 111, 118, 105, 129, 137, 108, 101, 97, 115, 101, 100, 32, 105, 132, 50, 48, 49, 50, 46, 32, 73, 133, 105, 128, 116, 130, 102, 105, 110, 97, 108, 32, 112, 131, 133, 111, 102, 32, 67, 104, 114, 147, 116, 111, 112, 104, 136, 32, 78, 111, 108, 138, 146, 133, 116, 114, 105, 108, 111, 103, 121, 44, 32, 102, 111, 108, 108, 111, 119, 105, 110, 103, 32, 139, 116, 109, 138, 66, 101, 103, 105, 110, 128, 97, 110, 100, 32, 140, 146, 116, 46, 32, 140, 102, 105, 108, 109, 32, 115, 116, 131, 128, 67, 104, 114, 147, 116, 105, 138, 139, 108, 129, 97, 128, 66, 114, 117, 99, 129, 87, 97, 121, 110, 129, 139, 116, 109, 97, 110, 44, 32, 119, 104, 111, 32, 104, 97, 128, 98, 101, 101, 132, 137, 116, 105, 137, 100, 32, 97, 128, 139, 116, 109, 138, 102, 111, 114, 32, 101, 135, 133, 121, 101, 131, 128, 97, 102, 116, 136, 32, 116, 130, 101, 118, 101, 110, 116, 128, 111, 102, 32, 116, 130, 112, 137, 118, 105, 111, 117, 128, 109, 111, 118, 105, 101, 46, 10]\n",
            "tokens length: 309\n",
            "ids length: 217\n",
            "compression ratio: 1.42X\n"
          ]
        }
      ],
      "source": [
        "print(tokens)\n",
        "print(ids)\n",
        "print(\"tokens length:\", len(tokens))\n",
        "print(\"ids length:\", len(ids))\n",
        "print(f\"compression ratio: {len(tokens) / len(ids):.2f}X\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn555CG7XW7B"
      },
      "source": [
        "### In class activity: Take any text of your choice and implement the BPE algorithm. Report the compression ratio achieved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHJT8Uczcngk"
      },
      "source": [
        "## Using the tiktoken library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUm2SdUcXblG",
        "outputId": "53df028f-b27a-4ef0-d162-c88c4ad6b492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tiktoken in c:\\github\\samratkar.github.io\\.venv\\lib\\site-packages (0.8.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\github\\samratkar.github.io\\.venv\\lib\\site-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in c:\\github\\samratkar.github.io\\.venv\\lib\\site-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\github\\samratkar.github.io\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\github\\samratkar.github.io\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\github\\samratkar.github.io\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\github\\samratkar.github.io\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
            "=== GPT-2 Encoding ===\n",
            "Original Text:  The lion roams in the jungle\n",
            "Token IDs:      [464, 18744, 686, 4105, 287, 262, 20712]\n",
            "Tokens:         ['The', ' lion', ' ro', 'ams', ' in', ' the', ' jungle']\n",
            "Decoded Text:   The lion roams in the jungle\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "! pip install tiktoken\n",
        "\n",
        "import tiktoken\n",
        "\n",
        "# Text to encode and decode\n",
        "text = \"The lion roams in the jungle\"\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 1. GPT-2 Encoding/Decoding\n",
        "#    Using the \"gpt2\" encoding\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "tokenizer_gpt2 = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "# Encode: text -> list of token IDs\n",
        "token_ids_gpt2 = tokenizer_gpt2.encode(text)\n",
        "\n",
        "# Decode: list of token IDs -> original text (just to verify correctness)\n",
        "decoded_text_gpt2 = tokenizer_gpt2.decode(token_ids_gpt2)\n",
        "\n",
        "# We can also get each token string by decoding the IDs one by one\n",
        "tokens_gpt2 = [tokenizer_gpt2.decode([tid]) for tid in token_ids_gpt2]\n",
        "\n",
        "print(\"=== GPT-2 Encoding ===\")\n",
        "print(\"Original Text: \", text)\n",
        "print(\"Token IDs:     \", token_ids_gpt2)\n",
        "print(\"Tokens:        \", tokens_gpt2)\n",
        "print(\"Decoded Text:  \", decoded_text_gpt2)\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVHkblCLc2mG",
        "outputId": "d56cba04-60f0-4898-fb36-eed614c6956c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== GPT-3.5 Encoding ===\n",
            "Original Text:  The lion roams in the jungle\n",
            "Token IDs:      [791, 40132, 938, 4214, 304, 279, 45520]\n",
            "Tokens:         ['The', ' lion', ' ro', 'ams', ' in', ' the', ' jungle']\n",
            "Decoded Text:   The lion roams in the jungle\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 2. GPT-3.5 Encoding\n",
        "#    Using the encoding_for_model(\"gpt-3.5-turbo\")\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "tokenizer_gpt35 = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "\n",
        "token_ids_gpt35 = tokenizer_gpt35.encode(text)\n",
        "decoded_text_gpt35 = tokenizer_gpt35.decode(token_ids_gpt35)\n",
        "tokens_gpt35 = [tokenizer_gpt35.decode([tid]) for tid in token_ids_gpt35]\n",
        "\n",
        "print(\"=== GPT-3.5 Encoding ===\")\n",
        "print(\"Original Text: \", text)\n",
        "print(\"Token IDs:     \", token_ids_gpt35)\n",
        "print(\"Tokens:        \", tokens_gpt35)\n",
        "print(\"Decoded Text:  \", decoded_text_gpt35)\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "wnhXtYvwc3PF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== GPT-4 Encoding ===\n",
            "Original Text:  The lion roams in the jungle\n",
            "Token IDs:      [791, 40132, 938, 4214, 304, 279, 45520]\n",
            "Tokens:         ['The', ' lion', ' ro', 'ams', ' in', ' the', ' jungle']\n",
            "Decoded Text:   The lion roams in the jungle\n"
          ]
        }
      ],
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 3. GPT-4 Encoding\n",
        "#    Using the encoding_for_model(\"gpt-4\")\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "tokenizer_gpt4 = tiktoken.encoding_for_model(\"gpt-4\")\n",
        "\n",
        "token_ids_gpt4 = tokenizer_gpt4.encode(text)\n",
        "decoded_text_gpt4 = tokenizer_gpt4.decode(token_ids_gpt4)\n",
        "tokens_gpt4 = [tokenizer_gpt4.decode([tid]) for tid in token_ids_gpt4]\n",
        "\n",
        "print(\"=== GPT-4 Encoding ===\")\n",
        "print(\"Original Text: \", text)\n",
        "print(\"Token IDs:     \", token_ids_gpt4)\n",
        "print(\"Tokens:        \", tokens_gpt4)\n",
        "print(\"Decoded Text:  \", decoded_text_gpt4)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
