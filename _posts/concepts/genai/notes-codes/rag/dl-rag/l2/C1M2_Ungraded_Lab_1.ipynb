{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d3d0a9c-9ac4-481d-997b-8ddc88e1ebb7",
   "metadata": {},
   "source": [
    "# Ungraded Lab - Vector Embeddings in RAG\n",
    "\n",
    "---\n",
    "\n",
    "In this ungraded lab, you will explore vector embeddings using an embedding model. You will learn:\n",
    "\n",
    "- How to use vector embeddings to find and understand contextual information.\n",
    "- The basics of cosine similarity and Euclidean distance for comparing embeddings.\n",
    "- Practical implementation of embeddings with a transformer-based model.\n",
    "- Visualization of high-dimensional embeddings using PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d67f30",
   "metadata": {},
   "source": [
    "\n",
    "# Table of Contents\n",
    "- [ 1 - Introduction](#1)\n",
    "  - [ 1.1 A Bit of Theory](#1-1)\n",
    "  - [ 1.2 The framework:](#1-2)\n",
    "- [ 2 - The Embedding Model](#2)\n",
    "  - [ 2.1 Introduction](#2-1)\n",
    "  - [ 2.2 Loading the model](#2-2)\n",
    "  - [ 2.3 Embeddings in Practice](#2-3)\n",
    "  - [ 2.4 Visualizing Word Embeddings](#2-4)\n",
    "- [ 3 - Embeddings and Input Size](#3)\n",
    "  - [ 3.1 An Example](#3-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a940695-e2ff-48f6-bf3c-7952787ef211",
   "metadata": {},
   "source": [
    "---\n",
    "<h4 style=\"color:black; font-weight:bold;\">USING THE TABLE OF CONTENTS</h4>\n",
    "\n",
    "JupyterLab provides an easy way for you to navigate through your assignment. It's located under the Table of Contents tab, found in the left panel, as shown in the picture below.\n",
    "\n",
    "![TOC Location](images/toc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11df6022-0460-4966-af4d-01ab902fb199",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "## 1 - Introduction\n",
    "\n",
    "---\n",
    "\n",
    "In the context of RAG, vector embeddings are used for: \n",
    "\n",
    "1. **Powering Search:**\n",
    "   - **Capturing Meaning:** Vector embeddings act like a map for text. They convert words and sentences into positions in vector space that capture meaning. These vectors can then be used to locate information matching a query.\n",
    "   - **Comparing Similarity:** When a prompt is received, it is converted into an embedding vector of its own. Then, the similarity between this prompt's vector and other vectors in the database can be calculated. This helps identify texts closest in meaning to the prompt.\n",
    "\n",
    "2. **Understanding Context:**\n",
    "   - **Context Matters:** They help in understanding the context of words in a query, ensuring that the best-matched information is found.\n",
    "   - **Flexibility:** Contextual embeddings allow for adapting to different meanings and capturing details that might otherwise be overlooked.\n",
    "\n",
    "In essence, vector embeddings are a behind-the-scenes technology that facilitates smarter, more helpful, and accurate data retrieval by capturing nuances in a way that no other search technique provides."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b468c62-fdbb-42f0-92cf-5c1c5692be59",
   "metadata": {},
   "source": [
    "<a id='1-1'></a>\n",
    "### 1.1 A Bit of Theory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2045450-ea41-4315-892f-eb9487c08887",
   "metadata": {},
   "source": [
    "In vector retrieval, you use an embedding model to convert prompts and documents into vectors. To find the most relevant documents for a query, you check their similarity using distance measures:\n",
    "\n",
    "1. **Cosine Similarity**: This evaluates how close two vectors are based on their angle. For a query vector $ \\mathbf{q} $ and a document vector $ \\mathbf{d}_i $:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"images/cosine.png\" alt=\"Description\" style=\"width: 300px;\">\n",
    "</div>\n",
    "\n",
    "   $$\n",
    "   \\text{Cosine Similarity}(\\mathbf{q}, \\mathbf{d}_i) = \\frac{\\mathbf{q} \\cdot \\mathbf{d}_i}{\\|\\mathbf{q}\\| \\|\\mathbf{d}_i\\|}\n",
    "   $$\n",
    "\n",
    "   A value close to 1 indicates that the vectors, and thus the texts, are very similar.\n",
    "\n",
    "2. **Euclidean Distance**: This calculates the \"straight-line\" distance between two vectors in the embedding space:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"images/euclidean.png\" alt=\"Description\" style=\"width: 300px;\">\n",
    "</div>\n",
    "\n",
    "   $$\n",
    "   \\text{Euclidean Distance}(\\mathbf{q}, \\mathbf{d}_i) = \\sqrt{\\sum_{j=1}^{n}(q_j - d_{ij})^2}\n",
    "   $$\n",
    "\n",
    "   Smaller distances suggest more closely related content.\n",
    "\n",
    "<a id='1-2'></a>\n",
    "### 1.2 The framework:\n",
    "\n",
    "1. **Create the embedding**: Use an embedding method to convert your query and documents into vectors.\n",
    "2. **Metric measurement**: Use a similarity metric to determine how close each document is to your query.\n",
    "3. **Sorting**: Sort the documents by their similarity score and select the top few as the most relevant. Be mindful that for some metrics, a higher score indicates greater similarity between two vectors (as with cosine similarity), while for others, a lower score indicates greater similarity (as with Euclidean distance).\n",
    "\n",
    "---\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"images/documents.png\" alt=\"Description\" style=\"width: 80%;\">\n",
    "</div>\n",
    "\n",
    "This gives us an easy way to query a database!\n",
    "\n",
    "Let's explore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75513446-26fb-4bfb-a643-ed8bfffdefbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from utils import (\n",
    "    display_widget,\n",
    "    plot_vectors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca1c037-1fb2-4aeb-9d92-6f9b56e75838",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Distance formulas. \n",
    "# In this ungraded lab, distance formulas are implemented here. In future assignments, you will import functions from specialized libraries.\n",
    "def cosine_similarity(v1, array_of_vectors):\n",
    "    \"\"\"\n",
    "    Compute the cosine similarity between a vector and an array of vectors.\n",
    "    \n",
    "    Parameters:\n",
    "    v1 (array-like): The first vector.\n",
    "    array_of_vectors (array-like): An array of vectors or a single vector.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of cosine similarities between v1 and each vector in array_of_vectors.\n",
    "    \"\"\"\n",
    "    # Ensure that v1 is a numpy array\n",
    "    v1 = np.array(v1)\n",
    "    # Initialize a list to store similarities\n",
    "    similarities = []\n",
    "    \n",
    "    # Check if array_of_vectors is a single vector\n",
    "    if len(np.shape(array_of_vectors)) == 1:\n",
    "        array_of_vectors = [array_of_vectors]\n",
    "    \n",
    "    # Iterate over each vector in the array\n",
    "    for v2 in array_of_vectors:\n",
    "        # Convert the current vector to a numpy array\n",
    "        v2 = np.array(v2)\n",
    "        # Compute the dot product of v1 and v2\n",
    "        dot_product = np.dot(v1, v2)\n",
    "        # Compute the norms of the vectors\n",
    "        norm_v1 = np.linalg.norm(v1)\n",
    "        norm_v2 = np.linalg.norm(v2)\n",
    "        # Compute the cosine similarity and append to the list\n",
    "        similarity = dot_product / (norm_v1 * norm_v2)\n",
    "        similarities.append(similarity)\n",
    "    return [float(x) for x in similarities]\n",
    "\n",
    "def euclidean_distance(v1, array_of_vectors):\n",
    "    \"\"\"\n",
    "    Compute the Euclidean distance between a vector and an array of vectors.\n",
    "    \n",
    "    Parameters:\n",
    "    v1 (array-like): The first vector.\n",
    "    array_of_vectors (array-like): An array of vectors or a single vector.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of Euclidean distances between v1 and each vector in array_of_vectors.\n",
    "    \"\"\"\n",
    "    # Ensure that v1 is a numpy array\n",
    "    v1 = np.array(v1)\n",
    "    # Initialize a list to store distances\n",
    "    distances = []\n",
    "    \n",
    "    # Check if array_of_vectors is a single vector\n",
    "    if len(np.shape(array_of_vectors)) == 1:\n",
    "        array_of_vectors = [array_of_vectors]\n",
    "    \n",
    "    # Iterate over each vector in the array\n",
    "    for v2 in array_of_vectors:\n",
    "        # Convert the current vector to a numpy array\n",
    "        v2 = np.array(v2)\n",
    "        # Check if the input arrays have the same shape\n",
    "        if v1.shape != v2.shape:\n",
    "            raise ValueError(f\"Shapes don't match: v1 shape: {v1.shape}, v2 shape: {v2.shape}\")\n",
    "        # Calculate the Euclidean distance and append to the list\n",
    "        dist = np.sqrt(np.sum((v1 - v2) ** 2))\n",
    "        distances.append(dist)\n",
    "    return [float(x) for x in distances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48363d8-b623-4d9c-bf6e-4eea6d67e35d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example \n",
    "v1 = [1, 2]\n",
    "v2 = [1, 1]\n",
    "array_v = [[3, 2], [5, 6]]\n",
    "cosine_v1_v2 = cosine_similarity(v1, v2)\n",
    "cosine_v1_array_v = cosine_similarity(v1, array_v)\n",
    "euclidean_v1_v2 = euclidean_distance(v1, v2)\n",
    "euclidean_v1_array_v = euclidean_distance(v1, array_v)\n",
    "print(f\"Cosine Similarity between v1 and v2: {cosine_v1_v2}\")\n",
    "print(f\"Cosine Similarities between v1 and array_v: {cosine_v1_array_v}\")\n",
    "print(f\"Euclidean Distance between v1 and v2: {euclidean_v1_v2}\")\n",
    "print(f\"Euclidean Distances between v1 and array_v: {euclidean_v1_array_v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1992a3e7-1588-4aca-8275-e528f5b77119",
   "metadata": {
    "tags": []
   },
   "source": [
    "Notice that the output is always a `list`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a03abb-a4c2-419f-8d1b-f376b58a7472",
   "metadata": {},
   "source": [
    "Observe the following: In terms of **cosine similarity**, the vector closest to v1 is the **second vector** in the array. However, when considering **Euclidean distance**, the closest vector is the **first vector**. This occurs because these metrics evaluate different attributes. Cosine similarity measures **the angle between two vectors**, while **Euclidean distance** measures the actual distance between them as we typically understand it. Consequently, with cosine similarity, the actual distances between the points forming the vectors are irrelevant. Let's plot them to investigate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fb60b0-123f-4140-8ef7-f4a17edf4a60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_vectors()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5686d7-3ed1-473f-a8b1-84a7f8c00b89",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "## 2 - The Embedding Model\n",
    "---\n",
    "<a id='2-1'></a>\n",
    "### 2.1 Introduction\n",
    "\n",
    "The embedding model is responsible for converting a word or sentence into a fixed-size vector. It is trained on millions of samples and is specialized in grouping semantically related sentences.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"images/embedding.png\" alt=\"Description\" style=\"width: 80%;\">\n",
    "</div>\n",
    "\n",
    "<a id='2-2'></a>\n",
    "### 2.2 Loading the model\n",
    "\n",
    "Now, let's load the model to generate the embeddings. It is the [BAAI/bge-base-en-v1.5](https://huggingface.co/BAAI/bge-base-en-v1.5) model, a transformer-based model capable of embedding entire sentences. It generates an embedding with 768 dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329459e2-500c-41c7-b660-8fb484e06093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the pre-trained sentence transformer model using the method .encode\n",
    "model_name =  \"BAAI/bge-base-en-v1.5\"\n",
    "model = SentenceTransformer(os.path.join(os.environ['MODEL_PATH'],model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4e0c18-4a76-4f30-bc6e-f0332c11dae1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To get a string embedded, just pass it to the model.\n",
    "res = model.encode(\"RAG is awesome\")\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6f3490-80ee-4c87-94ba-c91f8a019244",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# An array of strings can be passed, and the output will be an array of vectors, each with 768 dimensions.\n",
    "model.encode(['apple', 'car'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e87502c-dfa6-4012-b9f9-9a5a77100702",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the first 100 elements of the embedding.\n",
    "print(res[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de0da26-dcc7-4e31-a063-02276ced0277",
   "metadata": {},
   "source": [
    "The sentence is converted into a point in a 768-dimensional vector space, where various metrics can be used to measure the distance between sentences or words. The idea is that closer vectors imply semantically similar sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b36918d-04c6-44cf-beb0-b71aecedc6ee",
   "metadata": {},
   "source": [
    "<a id='2-3'></a>\n",
    "### 2.3 Embeddings in Practice\n",
    "\n",
    "In this section, you will see why embeddings are useful and how they capture semantic information by comparing words/sentences using two metrics: Cosine Similarity and Euclidean Distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c482cb52-1137-410d-94a7-09fc94fa4829",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = ['apple', 'car', 'fruit', 'automobile', 'love', 'sentiment']\n",
    "vectorized_words = model.encode(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb3ab33-cb1a-4721-a7ed-bb623b4d84da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word = 'apple'\n",
    "print(f\"{word}:\")\n",
    "for i, w in enumerate(words):\n",
    "    # Get the vectorized word for the word defined above\n",
    "    vectorized_word = vectorized_words[words.index(word)]\n",
    "    print(f\"\\t{w}:\\t\\tCosine Similarity: {cosine_similarity(vectorized_word, vectorized_words[i])[0]:.4f}\")\n",
    "print(\"\\n\\n\\n\")\n",
    "for i, w in enumerate(words):\n",
    "    # Get the vectorized word for the word defined above\n",
    "    vectorized_word = vectorized_words[words.index(word)]\n",
    "    print(f\"\\t{w}:\\t\\tEuclidean Distance: {euclidean_distance(vectorized_word, vectorized_words[i])[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381e1429-93e1-4523-87d4-5b6cb969e493",
   "metadata": {},
   "source": [
    "Note that for cosine similarity, the closer to 1, the more similar two words are, whereas for Euclidean distance, similar words have a smaller distance! Now, given the words above, let's create a function to sort them by similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb433fe7-67c5-4093-8959-b90eb056cdca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieve_relevant(query, documents, metric='cosine_similarity'):\n",
    "    \"\"\"\n",
    "    Retrieves and ranks documents based on their similarity to a given query using the specified metric.\n",
    "    \n",
    "    Parameters:\n",
    "    query (str): The query string for which relevant documents are to be retrieved.\n",
    "    documents (list of str): A list of documents to be compared against the query.\n",
    "    metric (str, optional): The similarity measurement metric to be used. It supports 'cosine_similarity'\n",
    "                            and 'euclidean'. Defaults to 'cosine_similarity'.\n",
    "    \n",
    "    Returns:\n",
    "    list of tuples: A list of tuples where each tuple contains a document and its similarity or distance\n",
    "                    score with respect to the query. The list is sorted based on these scores, with\n",
    "                    descending order for 'cosine_similarity' and ascending order for 'euclidean'.\n",
    "    \"\"\"\n",
    "    query_emb = model.encode(query)\n",
    "    documents_emb = model.encode(documents)\n",
    "    vals = []\n",
    "\n",
    "    if metric == 'cosine_similarity':\n",
    "        distances = cosine_similarity(query_emb, documents_emb)\n",
    "        vals = [(doc, dist) for doc, dist in zip(documents, distances)]\n",
    "        # Sort in descending order\n",
    "        vals.sort(reverse=True, key=lambda x: x[1])\n",
    "        \n",
    "    elif metric == 'euclidean':\n",
    "        distances = euclidean_distance(query_emb, documents_emb)\n",
    "        vals = [(doc, dist) for doc, dist in zip(documents, distances)]\n",
    "        # Sort in ascending order\n",
    "        vals.sort(key=lambda x: x[1])\n",
    "        \n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7343f07f-8285-4fe5-a317-656054865c7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Mt. Fuji is a breathtaking place to explore during autumn.\",\n",
    "    \"Santorini offers stunning views to admire during spring.\",\n",
    "    \"Banff National Park is a picturesque destination to visit in the summer.\",\n",
    "    \"The Great Wall of China is a spectacular site to experience during winter.\",\n",
    "    \"The fjords of Norway are a magical place to cruise through in the spring.\",\n",
    "    \"Prague is an enchanting city to wander through in winter.\",\n",
    "    \"Kyoto's cherry blossoms create a beautiful scene to witness during spring.\",\n",
    "    \"Marrakech offers vibrant markets and culture to enjoy in the fall.\",\n",
    "    \"The Maldives are a paradisiacal getaway to savor during summer.\",\n",
    "    \"The Christmas markets in Vienna are a festive delight to explore in winter.\"\n",
    "]\n",
    "\n",
    "query = \"Suggest to me great places to visit in Asia.\"\n",
    "score = retrieve_relevant(query, documents, metric='cosine_similarity')\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bea9c3-20f2-4fc1-b682-dabcb06c670f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score = retrieve_relevant(query, documents, metric='euclidean')\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f80905-9cb4-4dba-aa0e-b2e2a44add5e",
   "metadata": {},
   "source": [
    "While one might expect **\"Kyoto's cherry blossoms create a beautiful scene to witness during spring.\" to rank higher** given its relevance to the query, transformer embedding models capture similarity based on the **contexts in which words appear together** in the training data. Therefore, even though Kyoto is factually more relevant, the model may have learned **stronger associations between common travel-related sentences** (like \"places to visit\") and other destinations, like \"Santorini\" and \"Banff,\" due to their **frequent co-occurrence in travel contexts during the training phase**. This results in their higher ranking, as the embedding model captures is trained to capture these relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d3ca66-987f-4ff4-a7c2-34f4b03a03c4",
   "metadata": {},
   "source": [
    "<a id='2-4'></a>\n",
    "### 2.4 Visualizing Word Embeddings\n",
    "\n",
    "As you have seen, embeddings are a way of turning sentences or words into high-dimensional vectors that capture semantic properties. By doing so, it's possible to apply linear algebra tools like distances to measure how close the points are, reflecting their semantic relations.\n",
    "\n",
    "The embedding model you've worked with above embeds a sentence into a 768-dimensional vector, which is impossible to visualize in its entirety. In this section, you will visualize vector embeddings using a technique known as [PCA (Principal Component Analysis)](https://en.wikipedia.org/wiki/Principal_component_analysis), to reduce the dimensionality of these vectors to two, allowing us to visualize their distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fdb7ea-1404-4d75-ad12-eda47de9c300",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_widget(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec98a00-5ef7-4e9d-9ef4-b39d5a679424",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## 3 - Embeddings and Input Size\n",
    "---\n",
    "In this section, we explore how the size of input text impacts the generation of vector embeddings. Vector embeddings capture the semantic essence of a text. However, there is a limit to how much text these models can process at once, leading to truncation of text that exceeds this limit. When truncation occurs, all information beyond a certain point in the text is lost, potentially impacting the effectiveness and accuracy of the embedding.\n",
    "\n",
    "<a id='3-1'></a>\n",
    "### 3.1 An Example\n",
    "The example below illustrates how semantic meaning can be lost due to truncation. Any information beyond a certain point in the input text is not considered, leading to an incomplete representation in the embedding vector.\n",
    "\n",
    "Let's load a large text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b5b2cd-22e4-4fb1-8f0d-e05bad81acd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "big_text = open(\"large_text.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd11593a-be1e-44d5-817f-0a89305c2620",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(big_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86841dac-ae5f-491f-80d5-0ba38323a28f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Entire text\n",
    "big_text_embedding = model.encode(big_text)\n",
    "\n",
    "# Text with fewer characters\n",
    "big_text_embedding_few_characters = model.encode(big_text[:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b020c727-f055-42e0-af2a-eee7b2ba51f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checking if they are the same\n",
    "np.array_equal(big_text_embedding, big_text_embedding_few_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78b4102-6289-4bd9-b99f-2de870b3bafe",
   "metadata": {},
   "source": [
    "Note that they are the **same** vector, not even a single element different. This is because the context window for this model is 512 tokens, so **anything** beyond that is completely ignored. In the next modules, you will learn ways to handle large texts!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a78847c-9bf6-4a23-ab54-41078a4435b7",
   "metadata": {},
   "source": [
    "Keep it up! You have finished the ungraded lab on how embeddings work!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
