{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samratkar/samratkar.github.io/blob/main/_posts/concepts/genai/notes-codes/slm-from-scratch/slm-jc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijDG3IDqkjKx"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "Let us build a Small Language Model (SLM) from scratch. We will try to keep the parameter size to 10-15 million.\n",
        "\n",
        "Our goal is to generate creative and coherent text based on the input data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/samratkar/samratkar.github.io.git\n",
        "file_path = \"/content/samratkar.github.io/assets/genai/attention/data/julius-caesar.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFB11dcEzTGC",
        "outputId": "90cd2afa-f8bd-43e7-ec6f-2e47bc5a6b0f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'samratkar.github.io'...\n",
            "remote: Enumerating objects: 105070, done.\u001b[K\n",
            "remote: Counting objects: 100% (483/483), done.\u001b[K\n",
            "remote: Compressing objects: 100% (334/334), done.\u001b[K\n",
            "remote: Total 105070 (delta 300), reused 277 (delta 133), pack-reused 104587 (from 3)\u001b[K\n",
            "Receiving objects: 100% (105070/105070), 788.83 MiB | 54.51 MiB/s, done.\n",
            "Resolving deltas: 100% (2733/2733), done.\n",
            "Updating files: 100% (100760/100760), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPl23BNsRqfm"
      },
      "source": [
        "## Step 1: Import the Dataset\n",
        "\n",
        "TinyStories is a synthetic dataset of short stories that only contain words that a typical 3 to 4-year-olds usually understand, generated by GPT-3.5 and GPT-4. We can get it from HuggingFace."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vccyr4qKR6OH"
      },
      "source": [
        "## Step 2: Tokenize the Dataset\n",
        "\n",
        "In this step, we will do the following:\n",
        "\n",
        "(1) Tokenize the dataset into tokenIDs.\n",
        "\n",
        "(2) Create a file called \"train.bin\" and \"validtion.bin\" where we will store the tokenIDs from the entire dataset.\n",
        "\n",
        "(3) We make sure the tokenIDs are stored on a disk, rather than on the RAM for efficient computations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFkgAjyMR8fa",
        "outputId": "ce0bf81d-75ce-4a74-c5ee-ea5274e9de30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken\n",
        "import tiktoken\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "enc = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "# Some functions from https://github.com/karpathy/nanoGPT/blob/master/data/openwebtext/prepare.py\n",
        "\n",
        "def process(example):\n",
        "    ids = enc.encode_ordinary(example['text']) # encode_ordinary ignores any special tokens\n",
        "    out = {'ids': ids, 'len': len(ids)}\n",
        "    return out\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "        text = f.read()\n",
        "# Process the text using your process function\n",
        "processed_data = process({'text': text})\n",
        "\n",
        "# Extract token IDs and length\n",
        "ids = processed_data['ids']\n",
        "arr_len = processed_data['len']\n",
        "\n",
        "# Create and write to the memmap files\n",
        "for split in ['train', 'validation']:  # Or just 'train' if you only need one file\n",
        "    filename = f'{split}.bin'\n",
        "    dtype = np.uint16\n",
        "    arr = np.memmap(filename, dtype=dtype, mode='w+', shape=(arr_len,))\n",
        "    arr[:] = ids  # Write the token IDs to the memmap file\n",
        "    arr.flush()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_qRtn_WSbV4"
      },
      "source": [
        "## Step 3: Create Input-Output batches for the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gak79CZESkjN"
      },
      "outputs": [],
      "source": [
        "# Some functions from https://github.com/karpathy/nanoGPT/blob/master/train.py with slight modifications\n",
        "def get_batch(split):\n",
        "    # We recreate np.memmap every batch to avoid a memory leak, as per\n",
        "    # https://stackoverflow.com/questions/45132940/numpy-memmap-memory-usage-want-to-iterate-once/61472122#61472122\n",
        "    if split == 'train':\n",
        "        data = np.memmap('train.bin', dtype=np.uint16, mode='r')\n",
        "    else:\n",
        "        data = np.memmap('validation.bin', dtype=np.uint16, mode='r')\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n",
        "    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])\n",
        "    if device_type == 'cuda':\n",
        "        # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\n",
        "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
        "    else:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "    return x, y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA1SVp1hkjKy"
      },
      "source": [
        "## Step 4: Define the SLM Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9friaxWABOA-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from dataclasses import dataclass\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from contextlib import nullcontext\n",
        "import os\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, ndim, bias):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(ndim))\n",
        "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
        "    def forward(self, x):\n",
        "        return F.layer_norm(x, self.weight.shape, self.weight, self.bias, 1e-5)\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
        "        self.attn_dropout = nn.Dropout(config.dropout)\n",
        "        self.resid_dropout = nn.Dropout(config.dropout)\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "        self.flash = hasattr(F, 'scaled_dot_product_attention')\n",
        "        if not self.flash:\n",
        "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "                                       .view(1, 1, config.block_size, config.block_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size()\n",
        "        q, k, v = self.c_attn(x).split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "\n",
        "        if self.flash:\n",
        "            y = F.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.attn_dropout.p if self.training else 0.0, is_causal=True)\n",
        "        else:\n",
        "            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "            att = att.masked_fill(self.bias[:, :, :T, :T] == 0, float('-inf'))\n",
        "            att = F.softmax(att, dim=-1)\n",
        "            att = self.attn_dropout(att)\n",
        "            y = att @ v\n",
        "\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        y = self.resid_dropout(self.c_proj(y))\n",
        "        return y\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.c_fc = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.c_proj = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "    def forward(self, x):\n",
        "        return self.dropout(self.c_proj(self.gelu(self.c_fc(x))))\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln1 = LayerNorm(config.n_embd, config.bias)\n",
        "        self.attn = CausalSelfAttention(config)\n",
        "        self.ln2 = LayerNorm(config.n_embd, config.bias)\n",
        "        self.mlp = MLP(config)\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln1(x))\n",
        "        x = x + self.mlp(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "@dataclass\n",
        "class GPTConfig:\n",
        "    block_size: int\n",
        "    vocab_size: int\n",
        "    n_layer: int\n",
        "    n_head: int\n",
        "    n_embd: int\n",
        "    dropout: float = 0.0\n",
        "    bias: bool = True\n",
        "\n",
        "class GPT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte=nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            wpe=nn.Embedding(config.block_size, config.n_embd),\n",
        "            drop=nn.Dropout(config.dropout),\n",
        "            h=nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
        "            ln_f=LayerNorm(config.n_embd, config.bias),\n",
        "        ))\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "        self.transformer.wte.weight = self.lm_head.weight  # weight tying\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "        for pn, p in self.named_parameters():\n",
        "            if pn.endswith('c_proj.weight'):\n",
        "                nn.init.normal_(p, mean=0.0, std=0.02 / math.sqrt(2 * config.n_layer))\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        device = idx.device\n",
        "        b, t = idx.size()\n",
        "        assert t <= self.config.block_size\n",
        "        pos = torch.arange(0, t, dtype=torch.long, device=device)\n",
        "\n",
        "        tok_emb = self.transformer.wte(idx)\n",
        "        pos_emb = self.transformer.wpe(pos)\n",
        "        x = self.transformer.drop(tok_emb + pos_emb)\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "        x = self.transformer.ln_f(x)\n",
        "\n",
        "        if targets is not None:\n",
        "            logits = self.lm_head(x)\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
        "            return logits, loss\n",
        "        else:\n",
        "            logits = self.lm_head(x[:, [-1], :])\n",
        "            return logits, None\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
        "        \"\"\"\n",
        "        Generate tokens given a conditioning sequence.\n",
        "        idx: Tensor of shape (B, T)\n",
        "        \"\"\"\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
        "            logits, _ = self(idx_cond)\n",
        "            logits = logits[:, -1, :] / temperature\n",
        "            if top_k is not None:\n",
        "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
        "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-20T15:36:54.88378Z",
          "iopub.status.busy": "2024-06-20T15:36:54.883342Z",
          "iopub.status.idle": "2024-06-20T15:37:07.278493Z",
          "shell.execute_reply": "2024-06-20T15:37:07.277342Z",
          "shell.execute_reply.started": "2024-06-20T15:36:54.883753Z"
        },
        "id": "uRm6WlvfkjKz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "config = GPTConfig(\n",
        "    vocab_size=50257,     # use the tokenizer's vocab size\n",
        "    block_size=128,       # or whatever context size you're training with\n",
        "    #n_layer=6,\n",
        "    #n_layer=2,\n",
        "    #n_layer=12,\n",
        "    n_layer=4,\n",
        "    #n_head=6,\n",
        "    #n_head=2,\n",
        "    #n_head=12,\n",
        "    n_head=4,\n",
        "    #n_embd=384,\n",
        "    n_embd=768,\n",
        "    dropout=0.01,\n",
        "    bias=True\n",
        ")\n",
        "\n",
        "model = GPT(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_a8Rd-0S_WC"
      },
      "source": [
        "## Step 5: Define the loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "La2Aun_nTBzk"
      },
      "outputs": [],
      "source": [
        "def estimate_loss(model):\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for split in ['train', 'val']:\n",
        "            losses = torch.zeros(eval_iters)\n",
        "            for k in range(eval_iters):\n",
        "                X, Y = get_batch(split)\n",
        "                with ctx:\n",
        "                    logits, loss = model(X, Y)\n",
        "                losses[k] = loss.item()\n",
        "            out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvqWPUstTRXO"
      },
      "source": [
        "## Step 6: Define SLM Training Configuration Part 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QQyayhnkjK5",
        "outputId": "e38d61da-2195-4130-c3ea-625e2aacb999",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7dbeaff3d630>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Training Config\n",
        "import torch\n",
        "from contextlib import nullcontext\n",
        "\n",
        "learning_rate = 1e-4 #more stable training, earlier 1e-4\n",
        "# max_iters = 20000 #increase from 25000\n",
        "#max_iters = 2000\n",
        "max_iters = 10000\n",
        "warmup_steps = 1000 #smoother initial train, earlier 100\n",
        "min_lr = 5e-4 #lower rate, earlier 5e-4\n",
        "eval_iters = 500 # increased from 100\n",
        "#batch_size = 32 # changed from 16, better gradient estimate\n",
        "#batch_size = 2\n",
        "batch_size = 8\n",
        "block_size = 128 #changed from 64, capture longer range dependencies\n",
        "\n",
        "#gradient_accumulation_steps = 32 # reduced from 50\n",
        "gradient_accumulation_steps = 16\n",
        "\n",
        "device =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n",
        "# note: float16 data type will automatically use a GradScaler\n",
        "\n",
        "# How to use autocast https://wandb.ai/wandb_fc/tips/reports/How-To-Use-Autocast-in-PyTorch--VmlldzoyMTk4NTky\n",
        "#dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32', 'bfloat16', or 'float16', the latter will auto implement a GradScaler\n",
        "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32', 'bfloat16', or 'float16', the latter will auto implement a GradScaler\n",
        "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
        "\n",
        "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
        "\n",
        "torch.set_default_device(device)\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmWj6YcKTW_z"
      },
      "source": [
        "## Step 7: Define SLM Training Configuration Part 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMkO3FlNkjK6",
        "outputId": "af5da1aa-f81a-401a-ebe3-486baf69a5ad",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-a9032b47f003>:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n"
          ]
        }
      ],
      "source": [
        "from torch.optim.lr_scheduler import LinearLR,SequentialLR, CosineAnnealingLR\n",
        "\n",
        "##PUT IN WEIGHT DECAY, CHANGED BETA2 to 0.95\n",
        "optimizer =  torch.optim.AdamW(model.parameters(), lr=learning_rate, betas=(0.9, 0.95), weight_decay=0.1, eps=1e-9) #weight decay for regularization\n",
        "\n",
        "scheduler_warmup = LinearLR(optimizer, total_iters = warmup_steps) #Implement linear warmup\n",
        "scheduler_decay = CosineAnnealingLR(optimizer,T_max = max_iters - warmup_steps, eta_min = min_lr) #Implement lr decay\n",
        "scheduler = SequentialLR(optimizer, schedulers=[scheduler_warmup, scheduler_decay], milestones=[warmup_steps]) #Switching from warmup to decay\n",
        "\n",
        "# https://stackoverflow.com/questions/72534859/is-gradscaler-necessary-with-mixed-precision-training-with-pytorch\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nz8fPSKNTY3W"
      },
      "source": [
        "## Step 8: Pre-train the SLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798,
          "referenced_widgets": [
            "30e10947ef5e4cfd855e1279bb68689e",
            "2fe9c3b54ddb4cdb8d399d5bc5c2092f",
            "cd3cdc31979442e5a535f89982721abf",
            "4bf2e286968b45a3932fce1228b16c3a",
            "ba3d767ce7154183aff247215850898e",
            "fe6ff2f5c43f43f8aefd40b9910315ae",
            "79d320fc21d645aa93f3ae7ae54127b1",
            "1098f3a59e8e40eea74f9670e871384f",
            "1433fd1bcf6e4ede864d6713cb710642",
            "f034737c30a344608e77048c8dc903b3",
            "c407c67037024dbcb47ec3fe85c94134"
          ]
        },
        "id": "t0l-YhockjK6",
        "outputId": "431e8aac-7b14-4c7f-b944-253f99e4eab6",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30e10947ef5e4cfd855e1279bb68689e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500: train loss 7.9621, val loss 7.9819\n",
            "The current learning rate: 0.00007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1000: train loss 6.5684, val loss 6.5436\n",
            "The current learning rate: 0.00010\n",
            "Epoch 1500: train loss 5.4574, val loss 5.4734\n",
            "The current learning rate: 0.00010\n",
            "Epoch 2000: train loss 4.8074, val loss 4.7855\n",
            "The current learning rate: 0.00011\n",
            "Epoch 2500: train loss 4.3382, val loss 4.3428\n",
            "The current learning rate: 0.00013\n",
            "Epoch 3000: train loss 3.9862, val loss 3.9973\n",
            "The current learning rate: 0.00015\n",
            "Epoch 3500: train loss 3.6693, val loss 3.6878\n",
            "The current learning rate: 0.00017\n",
            "Epoch 4000: train loss 3.3601, val loss 3.3821\n",
            "The current learning rate: 0.00020\n",
            "Epoch 4500: train loss 3.0919, val loss 3.1072\n",
            "The current learning rate: 0.00023\n",
            "Epoch 5000: train loss 2.7396, val loss 2.7221\n",
            "The current learning rate: 0.00027\n",
            "Epoch 5500: train loss 2.4078, val loss 2.3935\n",
            "The current learning rate: 0.00030\n",
            "Epoch 6000: train loss 2.0272, val loss 2.0082\n",
            "The current learning rate: 0.00033\n",
            "Epoch 6500: train loss 1.6285, val loss 1.6104\n",
            "The current learning rate: 0.00037\n",
            "Epoch 7000: train loss 1.2475, val loss 1.2317\n",
            "The current learning rate: 0.00040\n",
            "Epoch 7500: train loss 0.9098, val loss 0.9091\n",
            "The current learning rate: 0.00043\n",
            "Epoch 8000: train loss 0.6062, val loss 0.6204\n",
            "The current learning rate: 0.00045\n",
            "Epoch 8500: train loss 0.4473, val loss 0.4423\n",
            "The current learning rate: 0.00047\n",
            "Epoch 9000: train loss 0.3293, val loss 0.3272\n",
            "The current learning rate: 0.00049\n",
            "Epoch 9500: train loss 0.2736, val loss 0.2703\n",
            "The current learning rate: 0.00050\n"
          ]
        }
      ],
      "source": [
        "best_val_loss = float('inf')\n",
        "best_model_params_path = \"best_model_params.pt\"\n",
        "train_loss_list, validation_loss_list = [], []\n",
        "\n",
        "# Ensure model is on the correct device\n",
        "model = model.to(device)\n",
        "\n",
        "# In your training loop\n",
        "for epoch in tqdm(range(max_iters)):\n",
        "    if epoch % eval_iters == 0 and epoch != 0:\n",
        "        # Ensure estimate_loss uses the correct device\n",
        "        losses = estimate_loss(model)\n",
        "        print(f\"Epoch {epoch}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "        print(f\"The current learning rate: {optimizer.param_groups[0]['lr']:.5f}\")\n",
        "        train_loss_list += [losses['train']]\n",
        "        validation_loss_list += [losses['val']]\n",
        "\n",
        "        if losses['val'] < best_val_loss:\n",
        "            best_val_loss = losses['val']\n",
        "            torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "    # Ensure X and y are on the correct device\n",
        "    X, y = get_batch(\"train\")\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    with ctx:\n",
        "        logits, loss = model(X, y)\n",
        "        loss = loss / gradient_accumulation_steps\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "    if ((epoch + 1) % gradient_accumulation_steps == 0) or (epoch + 1 == max_iters):\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdzhSo_7TcgI"
      },
      "source": [
        "## Step 9: Plot the SLM Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "KSWpvAnakjK6",
        "outputId": "2f8009dd-c328-4c4a-b7ff-051aef5b59ce",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "train_loss_list_converted = [i.cpu().detach() for i in train_loss_list]\n",
        "validation_loss_list_converted = [i.cpu().detach() for i in validation_loss_list]\n",
        "\n",
        "plt.plot(train_loss_list_converted, 'g', label='train_loss')\n",
        "plt.plot(validation_loss_list_converted, 'r', label='validation_loss')\n",
        "plt.xlabel(\"Steps - Every 100 epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2ocyyQwkjK6"
      },
      "source": [
        "## Step 10: Run SLM Inference on our trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-06-20T15:45:44.322237Z",
          "iopub.status.busy": "2024-06-20T15:45:44.321316Z",
          "iopub.status.idle": "2024-06-20T15:45:46.887084Z",
          "shell.execute_reply": "2024-06-20T15:45:46.886126Z",
          "shell.execute_reply.started": "2024-06-20T15:45:44.322203Z"
        },
        "id": "06NrdWKdkjK7",
        "outputId": "640a80e0-7aa1-43d4-99b6-fa6cc17fb2c2",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#Load the model\n",
        "model = GPT(config)  # re-create the model with same config\n",
        "device =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "best_model_params_path = \"best_model_params.pt\"\n",
        "model.load_state_dict(torch.load(best_model_params_path, map_location=torch.device(device))) # load best model states\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-06-20T15:44:36.64937Z",
          "iopub.status.busy": "2024-06-20T15:44:36.64896Z",
          "iopub.status.idle": "2024-06-20T15:45:14.425576Z",
          "shell.execute_reply": "2024-06-20T15:45:14.424712Z",
          "shell.execute_reply.started": "2024-06-20T15:44:36.649341Z"
        },
        "id": "K8PgWXb-kjK7",
        "outputId": "c259209b-722b-4b31-9c5e-2cf782d04921",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Friend, Romans, countrymen, but Basketball kind;\n",
            "And with me on your place Romans up atavius’d mantle. You,\n",
            "Low legal\n",
            " utter light onfs off,\n",
            " or hollow men,\n",
            "And I took them:\n",
            "Where Another part of the Extensionfully;\n",
            "ill then threatening clouds\n",
            "Fly Literary Archive Foundation’d us beyond all the world in the void the\n",
            "CLArows, and burn\n",
            "ANTONY.\n",
            "Not so great men year.\n",
            "BRUTUS.\n",
            "How course thouCTAVIUS.\n",
            "[_Aside._] safe enough. Oives him the stemming it with only tell hold skies. Is it she is:\n",
            "The exhalations,\n",
            "Shall I may be coronitable man, seek,\n",
            " resolv’d\n",
            "Thgan to break withray to Rome, and tax returns.\n",
            "\n",
            "[_Here in the Project Gutenberg™ words\n",
            "LIGProject Gutenberg™ eBooks, pleasing matter to conquestCOBBLER.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sentence = \"Friend, Romans, countrymen\"\n",
        "context = (torch.tensor(enc.encode_ordinary(sentence)).unsqueeze(dim = 0))\n",
        "y = model.generate(context, 200)\n",
        "print(enc.decode(y.squeeze().tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZsL_mONRZAO",
        "outputId": "dbb08bfb-ec53-446d-de0b-3d71a3e6ecc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You all did see that on the Lupercal nothingIZ DAM?\n",
            "What never? doth? ghosts ’tis your carr you so?\n",
            "\n",
            "CASSIUS.\n",
            "Army.\n",
            "\n",
            " trademark. What’d you humour?\n",
            "\n",
            "O cooling. Ever note, Lucilius, answer,\n",
            "And alone on your thigh: thenorough the i’ the shows a is be exalted with me.\n",
            "And I will expense\n",
            "Enter Pompey?\n",
            "\n",
            "LUCILIUS.\n",
            "Then, blow wind, swell!\n",
            "Theoller ne’er look you avoided, and instantly.\n",
            "Give me the true. Lucilius,\n",
            "Shall noble,\n",
            "This is the ambition shall Brutus,\n",
            "Come, and the Mark Antony.\n",
            "\n",
            "VANTONY.\n",
            "Where,Up to the empty ass, to covet,\n",
            "And are you shall, speech wereea, in his country in triumph catching; and,\n",
            "Shout. With this shall therefore shall find street\n"
          ]
        }
      ],
      "source": [
        "sentence = \"You all did see that on the Lupercal\"\n",
        "context = (torch.tensor(enc.encode_ordinary(sentence)).unsqueeze(dim = 0))\n",
        "y = model.generate(context, 200)\n",
        "print(enc.decode(y.squeeze().tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_2WjvUszhIe"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30732,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "30e10947ef5e4cfd855e1279bb68689e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2fe9c3b54ddb4cdb8d399d5bc5c2092f",
              "IPY_MODEL_cd3cdc31979442e5a535f89982721abf",
              "IPY_MODEL_4bf2e286968b45a3932fce1228b16c3a"
            ],
            "layout": "IPY_MODEL_ba3d767ce7154183aff247215850898e"
          }
        },
        "2fe9c3b54ddb4cdb8d399d5bc5c2092f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe6ff2f5c43f43f8aefd40b9910315ae",
            "placeholder": "​",
            "style": "IPY_MODEL_79d320fc21d645aa93f3ae7ae54127b1",
            "value": "100%"
          }
        },
        "cd3cdc31979442e5a535f89982721abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1098f3a59e8e40eea74f9670e871384f",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1433fd1bcf6e4ede864d6713cb710642",
            "value": 10000
          }
        },
        "4bf2e286968b45a3932fce1228b16c3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f034737c30a344608e77048c8dc903b3",
            "placeholder": "​",
            "style": "IPY_MODEL_c407c67037024dbcb47ec3fe85c94134",
            "value": " 10000/10000 [03:36&lt;00:00, 86.51it/s]"
          }
        },
        "ba3d767ce7154183aff247215850898e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe6ff2f5c43f43f8aefd40b9910315ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79d320fc21d645aa93f3ae7ae54127b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1098f3a59e8e40eea74f9670e871384f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1433fd1bcf6e4ede864d6713cb710642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f034737c30a344608e77048c8dc903b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c407c67037024dbcb47ec3fe85c94134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}