---
layout: mermaid
title: CLIP
---

#### Introduction 
**CLIP (Contrastive Language-Image Pretraining)** is a neural network architecture that learns to connect images and text by training on a large dataset of image-text pairs. It uses a contrastive loss function to align the representations of images and their corresponding textual descriptions in a shared embedding space.

[Vizuara substack CLIP text guidance for diffusion - Contrastive Learning](https://www.vizuaranewsletter.com/p/contrastive-learning-for-creating?utm_source=publication-search)