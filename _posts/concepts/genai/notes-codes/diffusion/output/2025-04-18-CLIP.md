---
layout: mermaid
title: CLIP
---

#### Introduction 
**CLIP (Contrastive Language-Image Pretraining)** is a neural network architecture that learns to connect images and text by training on a large dataset of image-text pairs. It uses a contrastive loss function to align the representations of images and their corresponding textual descriptions in a shared embedding space.

[Vizuara substack CLIP Multimodal embeddings](https://vizuara.substack.com/p/multimodal-embeddings-are-so-counter)
